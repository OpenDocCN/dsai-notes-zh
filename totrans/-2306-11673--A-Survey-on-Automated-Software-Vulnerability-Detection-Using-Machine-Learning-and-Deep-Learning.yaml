- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:38:53'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2306.11673] A Survey on Automated Software Vulnerability Detection Using Machine
    Learning and Deep Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2306.11673](https://ar5iv.labs.arxiv.org/html/2306.11673)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Survey on Automated Software Vulnerability Detection Using Machine Learning
    and Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nima Shiri harzevili [nshiri@yorku.ca](mailto:nshiri@yorku.ca) York University4700
    Keele St.North YorkOntarioCanadaM3J 1P3 ,  Alvine Boaye Belle York University4700
    Keele St.North YorkCanada [alvine.belle@lassonde.yorku.ca](mailto:alvine.belle@lassonde.yorku.ca)
    ,  Junjie Wang Institute of Software, Chinese Academy of SciencesBeijingChina
    [junjie@iscas.ac.cn](mailto:junjie@iscas.ac.cn) ,  Song Wang York University4700
    Keele St.North YorkCanada [wangsong@yorku.ca](mailto:wangsong@yorku.ca) ,  Zhen
    Ming (Jack) Jiang York University4700 Keele St.North YorkCanada [zmjiang@eecs.yorku.ca](mailto:zmjiang@eecs.yorku.ca)
     and  Nachiappan Nagappan MetaSeattleUSA [nachiappan.nagappan@gmail.com](mailto:nachiappan.nagappan@gmail.com)(2018)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Software vulnerability detection is critical in software security because it
    identifies potential bugs in software systems, enabling immediate remediation
    and mitigation measures to be implemented before they may be exploited. Automatic
    vulnerability identification is important because it can evaluate large codebases
    more efficiently than manual code auditing. Many Machine Learning (ML) and Deep
    Learning (DL) based models for detecting vulnerabilities in source code have been
    presented in recent years. However, a survey that summarises, classifies, and
    analyses the application of ML/DL models for vulnerability detection is missing.
    It may be difficult to discover gaps in existing research and potential for future
    improvement without a comprehensive survey. This could result in essential areas
    of research being overlooked or under-represented, leading to a skewed understanding
    of the state of the art in vulnerability detection. This work address that gap
    by presenting a systematic survey to characterize various features of ML/DL-based
    source code level software vulnerability detection approaches via five primary
    research questions (RQs). Specifically, our RQ1 examines the trend of publications
    that leverage ML/DL for vulnerability detection, including the evolution of research
    and the distribution of publication venues. RQ2 describes vulnerability datasets
    used by existing ML/DL-based models, including their sources, types, and representations,
    as well as analyses of the embedding techniques used by these approaches. RQ3
    explores the model architectures and design assumptions of ML/DL-based vulnerability
    detection approaches. RQ4 summarises the type and frequency of vulnerabilities
    that are covered by existing studies. Lastly, RQ5 presents a list of current challenges
    to be researched and an outline of a potential research roadmap that highlights
    crucial opportunities for future work.
  prefs: []
  type: TYPE_NORMAL
- en: 'source code, software security, software vulnerability detection, software
    bug detection, machine learning, deep learning^†^†copyright: acmcopyright^†^†journalyear:
    2018^†^†doi: XXXXXXX.XXXXXXX^†^†journal: JACM^†^†journalvolume: 37^†^†journalnumber:
    4^†^†article: 111^†^†publicationmonth: 8^†^†ccs: Security and privacy Software
    security engineering'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Automatic detection of software security vulnerabilities is a critical component
    of assuring software security. Machine Learning (ML) and Deep Learning (DL) breakthroughs
    have sparked great interest in employing these models to discover software vulnerabilities
    in general software systems.. (Wang et al., [2018](#bib.bib138); Cheng et al.,
    [2021](#bib.bib29); Li et al., [2021a](#bib.bib85); Le et al., [2021b](#bib.bib80);
    Yan et al., [2021](#bib.bib146)). ML/DL models excel at discovering subtle patterns
    and correlations from large datasets. They can automatically extract meaningful
    features from raw data, such as source code, and identify hidden patterns that
    may indicate software vulnerabilities. This capability is crucial in vulnerability
    detection, as vulnerabilities often involve subtle code characteristics and dependencies.
    Also, ML/DL models can handle a wide range of data types and formats, including
    source code (Dam et al., [2018](#bib.bib34), [2017](#bib.bib33); Shippey et al.,
    [2019](#bib.bib129); Wang et al., [2016](#bib.bib139); Jeon and Kim, [2021](#bib.bib65);
    Tian et al., [2020](#bib.bib135); Liu et al., [2020](#bib.bib96); Yamaguchi et al.,
    [2013](#bib.bib145)), textual information (Hoang et al., [2019](#bib.bib61)),
    and numerical features such as commit characteristics (Pascarella et al., [2019](#bib.bib114);
    Yang et al., [2017](#bib.bib148)). They can process and analyze these data representations
    to detect vulnerabilities effectively. This flexibility allows researchers to
    leverage various sources of data and incorporate different features for comprehensive
    vulnerability detection. The overall process to leverage ML/DL models for software
    vulnerability detection is as follows: Data collection: The first step toward
    building a vulnerability detection model is to collect relevant vulnerable data
    for training the models. There are multiple sources for vulnerability detection
    datasets (we elaborate on this in RQ2), the researchers either use benchmark data (Le
    et al., [2018](#bib.bib77); Zou et al., [2019](#bib.bib161); Cao et al., [2022](#bib.bib18);
    Ghaffarian and Shahriari, [2021](#bib.bib50); Wu et al., [2021](#bib.bib141);
    Ziems and Wu, [2021](#bib.bib159); Zhuang et al., [2020](#bib.bib158); Li et al.,
    [2021c](#bib.bib88); Filus et al., [2020](#bib.bib43); Li et al., [2018](#bib.bib89);
    Yang et al., [2017](#bib.bib148)) or collect from the open source (Fu and Tantithamthavorn,
    [2022](#bib.bib46); Chen et al., [2021](#bib.bib26); Perl et al., [2015](#bib.bib115);
    Riom et al., [2021](#bib.bib121); Ni et al., [2022](#bib.bib111)) based on the
    requirements and the type of vulnerabilities. Data representation: Once the data
    is collected, it needs to be preprocessed to prepare it for training. The preprocess
    includes using appropriate representation techniques, i.e., graph/tree representation (Zou
    et al., [2019](#bib.bib161); Cao et al., [2022](#bib.bib18); Ghaffarian and Shahriari,
    [2021](#bib.bib50); Wu et al., [2021](#bib.bib141); Lin et al., [2017](#bib.bib92);
    Zhuang et al., [2020](#bib.bib158); Li et al., [2017](#bib.bib83); Lin et al.,
    [2019](#bib.bib91); Li et al., [2021c](#bib.bib88); Duan et al., [2019](#bib.bib39);
    Zheng et al., [2021](#bib.bib154); Zhuang et al., [2022](#bib.bib157); Cheng et al.,
    [2022](#bib.bib31); Liu et al., [2021b](#bib.bib98)), token representation (Zou
    et al., [2021](#bib.bib162); Huo et al., [2018](#bib.bib63); Harer et al., [2018](#bib.bib56);
    Hin et al., [2022](#bib.bib59); Le et al., [2018](#bib.bib77); Chen et al., [2021](#bib.bib26);
    Scandariato et al., [2014](#bib.bib125); Ziems and Wu, [2021](#bib.bib159); Filus
    et al., [2020](#bib.bib43)), or using commit characteristics. Embedding: This
    step involves converting the source code representation into numerical format (Zou
    et al., [2021](#bib.bib162); Huo et al., [2018](#bib.bib63); Harer et al., [2018](#bib.bib56);
    Hin et al., [2022](#bib.bib59); Fu and Tantithamthavorn, [2022](#bib.bib46); Le
    et al., [2018](#bib.bib77); Cao et al., [2022](#bib.bib18); Ghaffarian and Shahriari,
    [2021](#bib.bib50); Lin et al., [2017](#bib.bib92); Scandariato et al., [2014](#bib.bib125);
    Perl et al., [2015](#bib.bib115))(vectors or embeddings) that can be utilized
    by machine learning or deep learning models for vulnerability detection. Model
    selection and architecture design: An suitable ML/DL model must be chosen based
    on the software vulnerability detection task. This can include everything from
    simple ML algorithms like SVM or Random Forests (Chen et al., [2020b](#bib.bib25);
    Sabetta and Bezzi, [2018](#bib.bib124); Zhou and Sharma, [2017](#bib.bib156))
    to more advanced DL architectures like CNNs (Hoang et al., [2019](#bib.bib61);
    Yan et al., [2021](#bib.bib146); Huo et al., [2018](#bib.bib63)) or RNNs. The
    architecture of the model is intended to extract significant characteristics and
    patterns from the input data. Training: In the training phase, the vulnerability
    detection dataset is separated into training and validation sets, and the model
    learns from labeled data. The model’s parameters are updated iteratively depending
    on the prediction errors, using optimization techniques such as gradient descent.
    Evaluation and validation: Once the training is finished, the model’s performance
    is evaluated using a separate test dataset. Various metrics such as accuracy,
    precision, recall, and F1 score are calculated to assess the model’s effectiveness
    in detecting vulnerabilities. The model may also be validated against real-world
    vulnerabilities to measure its practical utility.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Although many studies have utilized ML/DL to detect software vulnerabilities,
    there has not been a comprehensive review to consolidate the various approaches
    and characteristics of these techniques. Conducting such a systematic survey would
    be beneficial for practitioners and researchers to gain a better understanding
    of the current state-of-the-art tools for vulnerability detection, and could serve
    as inspiration for future studies. This study conducts a detailed and comprehensive
    survey to review, analyze, describe, and classify vulnerability detection papers
    from different perspectives. We analyzed 67 articles published in 37 flagship
    SE journals and conferences from 2011 to 2022\. We investigated the following
    research questions (RQs) in this study:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ1: What is the trend of studies using ML/DL models for vulnerability detection?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: RQ1.1\. What are the trends of studies in software vulnerability detection studies
    over time?
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: RQ1.2\. What is the distribution of the publication venues?
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ2: What are the characteristics of experiment datasets used in software vulnerability
    detection?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: RQ2.1\. What is the source of data?
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: RQ2.2\. What are the types of data used in primary studies?
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: RQ2.3\. How input data are represented?
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: RQ2.4\. How input data are embedded for feature space?
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RQ3\. What are the different ML/DL models used for vulnerability detection?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RQ4\. What are the most frequent type of vulnerabilities covered in these studies?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RQ5\. What are possible challenges and open directions in software vulnerability
    detection?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'This paper makes the following contributions:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We thoroughly analyzed 67 relevant studies that used ML/DL techniques to detect
    security vulnerabilities regarding publication trends, distribution of publication
    venues, and types of contributions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We conducted a comprehensive analysis to understand the dataset, the processing
    of data, data representation, model architecture, model interpretability, and
    the types of involved vulnerabilities of these ML/DL-based vulnerability detection
    techniques.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We provided a classification of ML/DL models used in vulnerability detection
    based on their architectures and analysis of technique selection strategy on these
    models.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We discuss distinct technical challenges of using ML/DL techniques in vulnerability
    detection and outline key future directions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have shared our results and analysis data as a replication package¹¹1https://colab.research.google.com/drive/1O42duwz34H3fRoyfA37EU6Ig2u16R1Lb?usp=sharing
    to allow other researchers easily follow this paper and extend it.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We believe that this work is useful for researchers and practitioners in the
    field of software engineering and cybersecurity, particularly those with an interest
    in software vulnerability detection and mitigation. In addition, the findings
    of our systematic survey may also be useful to policymakers, software vendors,
    and other stakeholders who are concerned with improving software security and
    reducing the risk of cyberattacks. These individuals may use the insights provided
    by the review to inform their decisions about software development, procurement,
    and risk management.
  prefs: []
  type: TYPE_NORMAL
- en: 'The remaining part of this paper is organized as follows: Section [2](#S2 "2\.
    Background and Related Work ‣ A Survey on Automated Software Vulnerability Detection
    Using Machine Learning and Deep Learning") summarizes existing studies focusing
    on proposing a systematic survey for software vulnerability detection. Section
    2 presents related work on systematic surveys for software vulnerability detection
    using ML/DL techniques. Section 3 presents the research methodology proposed in
    this paper for paper collection and criteria for including and excluding studies.
    Section 4 addresses research questions and corresponding results. Section 5 discusses
    the possible limitations of this systematic survey. Finally, section 6 discusses
    the conclusion and future directions.'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Background and Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section of the paper, we first provide a background on the definition
    of vulnerability and the different steps in software vulnerability detection.
    Then we discuss the related surveys and highlight their differences compared to
    our survey.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. Background
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Software vulnerability management is now essential for guaranteeing the security
    and integrity of software systems (Chang et al., [2011](#bib.bib21); Foreman,
    [2019](#bib.bib44); Raza and Ahmed, [2022](#bib.bib120); Walkowski et al., [2021](#bib.bib136)).
    Given the increasing reliance on software for many critical processes such as
    financial transactions, the frequency of vulnerabilities poses serious risks.. (Lu
    et al., [2021](#bib.bib100); He et al., [2020](#bib.bib58)), autonomous driving (Gao
    et al., [2021](#bib.bib47); Luo et al., [2019](#bib.bib101)), and mission-critical
    systems (Goseva-Popstojanova and Tyo, [2017](#bib.bib54); Harzevili et al., [2022](#bib.bib57)).
    Software vulnerabilities can be exploited by malicious entities to gain unauthorized
    access, compromise sensitive information, or disrupt services if they go undetected
    or ignored. (Harzevili et al., [2022](#bib.bib57)). As a result, excellent software
    vulnerability management is crucial to handling these risks, preserving user privacy (Anthonysamy
    et al., [2017](#bib.bib6)), maintaining system availability, and assuring software
    application trustworthiness (Medeiros et al., [2023](#bib.bib105)). By proactively
    detecting, analyzing, and remediating vulnerabilities, organizations may strengthen
    their software systems against changing cybersecurity threats (Aslan et al., [2023](#bib.bib7))
    and adhere to industry best practices for safe software development and deployment.
  prefs: []
  type: TYPE_NORMAL
- en: There are multiple steps in software vulnerability management including vulnerability
    detection (Cao et al., [2022](#bib.bib18)), vulnerability analysis (Kudjo et al.,
    [2020](#bib.bib74)), and vulnerability remediation (Le et al., [2021a](#bib.bib78)).
    In the following subsections, we elaborate on each step in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.1\. Vulnerability detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Vulnerability detection is critical in the overall process of managing software
    vulnerabilities (Cao et al., [2022](#bib.bib18); Jeon and Kim, [2021](#bib.bib65);
    Tian et al., [2020](#bib.bib135); Liu et al., [2020](#bib.bib96); Wang et al.,
    [2020](#bib.bib137); Cheng et al., [2021](#bib.bib29); Zou et al., [2019](#bib.bib161);
    Cao et al., [2022](#bib.bib18); Ziems and Wu, [2021](#bib.bib159); Lin et al.,
    [2019](#bib.bib91); Li et al., [2021c](#bib.bib88)). It comprises detecting and
    investigating possible security weaknesses in software systems that attackers
    may exploit. There are several traditional techniques commonly used for vulnerability
    detection:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Manual Code Auditing (Staron et al., [2020](#bib.bib131); Bacchelli and Bird,
    [2013](#bib.bib8); Carlsson and Baca, [2005](#bib.bib19); Shar and Tan, [2012](#bib.bib128),
    [2010](#bib.bib127)): In this method, human experts examine the source thoroughly
    with the goal of manually detecting coding flaws, unsafe procedures, and possible
    vulnerabilities. Manual code review is time-consuming and requires the knowledge
    of qualified developers or security analysts. However, it provides for a thorough
    grasp of the code and can reveal subtle bugs that automated tools may overlook.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Static Analysis (Facebook, [2013](#bib.bib42); Wheeler, [2013](#bib.bib140);
    Dunham, [2009](#bib.bib40); Marjamäki, [2016](#bib.bib104); SpotBugs., [2021](#bib.bib130);
    Lattner, [2008](#bib.bib76)): Static analysis involves using automated tools to
    analyze the source code or compiled binaries without executing the software. It
    examines the code structure, identifies potential coding issues, and detects common
    vulnerabilities such as buffer overflows (Harzevili et al., [2022](#bib.bib57)),
    injection attacks, and insecure data handling. Static analysis tools employ various
    techniques like data flow analysis, control flow analysis, and pattern matching
    to identify potential vulnerabilities. They can help scale vulnerability detection
    efforts by analyzing large codebases efficiently.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Dynamic Analysis (Nethercote and Seward, [2007](#bib.bib107); Lehmann and Pradel,
    [2019](#bib.bib82); Cadar et al., [2008](#bib.bib16)): The goal of dynamic analysis
    is to evaluate the behavior of software while it is running. Running the software
    in a controlled environment or through automated tests while monitoring its execution
    and interactions with system resources is what it entails. Dynamic analysis can
    detect bugs in input validation (Kim et al., [2019](#bib.bib71)), access control,
    and error handling. This approach can identify vulnerabilities that static analysis
    alone cannot detect by analyzing the real-time behavior of the software. However,
    the dynamic analysis may have constraints in terms of significant system overhead (Yong
    and Horwitz, [2005](#bib.bib150)).'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.2\. Vulnerability analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: After the detection of vulnerabilities, the subsequent step in software vulnerability
    management is vulnerability analysis and assessment (Le et al., [2019](#bib.bib81);
    Suciu et al., [2022](#bib.bib132); Jacobs et al., [2023](#bib.bib64); Yin et al.,
    [2022](#bib.bib149); Le et al., [2022](#bib.bib79); Mahor et al., [2022](#bib.bib102);
    Frei et al., [2006](#bib.bib45)). This step involves further examining the identified
    vulnerabilities to assess their severity, impact, and potential exploitability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Severity: Accurately assessing software vulnerabilities is vital for several
    reasons. Firstly, it allows organizations to prioritize their response based on
    the severity of the vulnerabilities. Severity refers to the potential impact a
    vulnerability could have if exploited (Kudjo et al., [2019](#bib.bib75); Chen
    et al., [2020a](#bib.bib24); Kudjo et al., [2020](#bib.bib74); Tan et al., [2020](#bib.bib134)).
    By accurately assessing the severity, organizations can focus their attention
    on high-severity vulnerabilities that pose significant risks to the security and
    functionality of the software system.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Impact: Secondly, accurately assessing vulnerabilities helps determine the
    potential impact they may have on the organization (Gawron et al., [2018](#bib.bib48);
    Gong et al., [2019](#bib.bib52); Chen et al., [2010](#bib.bib28); Jiang and Atif,
    [2020](#bib.bib66)). The term impact refers to the repercussions of exploiting
    a vulnerability, such as denial of service (Harzevili et al., [2022](#bib.bib57))
    or data breaches (Aaltonen and Gao, [2021](#bib.bib2)). By understanding the potential
    impact, organizations can make informed decisions regarding the urgency and priority
    of remediation efforts.'
  prefs: []
  type: TYPE_NORMAL
- en: 'exploitability: Furthermore, accurately assessing vulnerabilities aids in understanding
    their potential exploitability (Chen et al., [2019b](#bib.bib23), [a](#bib.bib22);
    Bozorgi et al., [2010](#bib.bib14)). This entails determining the possibility
    that an attacker will be successful in exploiting the vulnerability to infiltrate
    the software system. Organizations can estimate the amount of risk associated
    with each vulnerability and invest resources accordingly by evaluating criteria
    such as the ease of exploitation and the availability of exploit techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.3\. Vulnerability remediation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The process of addressing detected software vulnerabilities by different techniques
    such as patching, code modification, and repairing is referred to as software
    vulnerability remediation (Canfora et al., [2022](#bib.bib17); Piantadosi et al.,
    [2019](#bib.bib118); Chen et al., [2022](#bib.bib27); Bhandari et al., [2021](#bib.bib9)).
    The fundamental goal of remediation is to eliminate or mitigate vulnerabilities
    in order to improve the software system’s security and dependability. One common
    approach to vulnerability remediation is applying patches provided by software
    vendors or open-source communities (Xia et al., [2023](#bib.bib142); Li et al.,
    [2022](#bib.bib84); Gissurarson et al., [2022](#bib.bib51)). Patches are updates
    or fixes that address specific vulnerabilities or weaknesses identified in a software
    system.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.4\. ML/DL for software vulnerability detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: By utilizing data analysis, pattern recognition, and machine-driven learning
    for finding software security vulnerabilities, ML/DL approaches have revolutionized
    software vulnerability detection. (Wang et al., [2018](#bib.bib138); Cheng et al.,
    [2021](#bib.bib29); Li et al., [2021a](#bib.bib85); Le et al., [2021b](#bib.bib80);
    Yan et al., [2021](#bib.bib146)). These techniques improve the accuracy and efficiency
    of vulnerability detection, potentially allowing for automated detection, faster
    analysis, and the identification of previously undisclosed vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: One common application of ML/DL in vulnerability detection is the classification
    of code snippets (Dam et al., [2017](#bib.bib33); Shippey et al., [2019](#bib.bib129);
    Wang et al., [2016](#bib.bib139); Jeon and Kim, [2021](#bib.bib65)), software
    binaries (Phan et al., [2017](#bib.bib117); Nguyen et al., [2020](#bib.bib110);
    Yan et al., [2021](#bib.bib146); Huang et al., [2021](#bib.bib62)), or code changes
    mined from open-source repositories such as GitHub or CVE (Sabetta and Bezzi,
    [2018](#bib.bib124); Wang et al., [2020](#bib.bib137); Liu et al., [2019a](#bib.bib95);
    Pradel and Sen, [2018](#bib.bib119); Hoang et al., [2019](#bib.bib61); Zhou et al.,
    [2019](#bib.bib155); Dinella et al., [2020](#bib.bib36); Li et al., [2019](#bib.bib86)).
    ML models can be trained on labeled datasets, where each sample represents a known
    vulnerability or non-vulnerability. These models then learn to generalize from
    the provided examples and classify new instances based on the patterns they have
    learned. This method allows for automatic vulnerability discovery without the
    need for manual examination, considerably lowering the time and effort necessary
    for analysis.
  prefs: []
  type: TYPE_NORMAL
- en: ML/DL models for detecting software vulnerabilities have promising advantages
    over traditional methodologies. Each benefit is discussed in depth in the next
    paragraph.
  prefs: []
  type: TYPE_NORMAL
- en: 'Automation: Automation is a significant advantage. ML models can automatically
    scan and analyze large codebases, network traffic logs, or system configurations,
    flagging potential vulnerabilities without requiring human intervention for each
    individual case (Chakraborty et al., [2021](#bib.bib20)). This automation speeds
    up the detection process, allowing security teams to focus on verifying and mitigating
    vulnerabilities rather than manual analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Performance: ML/DL approaches offer faster analysis. Traditional vulnerability
    detection methods rely on manual inspection or the application of predefined rules (Staron
    et al., [2020](#bib.bib131); Bacchelli and Bird, [2013](#bib.bib8); Carlsson and
    Baca, [2005](#bib.bib19); Shar and Tan, [2012](#bib.bib128), [2010](#bib.bib127)).
    In contrast, ML/DL approaches can evaluate enormous volumes of data in parallel
    and generate predictions fast, dramatically shortening the time necessary to find
    vulnerabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Detection effectiveness: ML/DL models can uncover previously unknown vulnerabilities,
    commonly known as zero-day vulnerabilities (Bilge and Dumitraş, [2012](#bib.bib11)).
    These models may uncover signs of vulnerabilities even when they have not been
    specifically trained on them by learning patterns and generalizing from labeled
    data. This capability improves the overall security posture by helping to identify
    and address unknown weaknesses in software before they are exploited by attackers (Abri
    et al., [2019](#bib.bib3)).'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Related work
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There have been several existing survey papers on software vulnerabilities in
    the literature. In this section, we analyze the existing papers based on different
    aspects as shown in Table [1](#S2.T1 "Table 1 ‣ 2.2\. Related work ‣ 2\. Background
    and Related Work ‣ A Survey on Automated Software Vulnerability Detection Using
    Machine Learning and Deep Learning").
  prefs: []
  type: TYPE_NORMAL
- en: Table 1. Comparison of contributions between our survey and the existing related
    surveys/reviews.
  prefs: []
  type: TYPE_NORMAL
- en: '| No | Studies | Data Source | Representation | Embedding | Models | Vulnerability
    Types | Interpretability |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Triet et al. (Le et al., [2021a](#bib.bib78)) | ✓ | $\times$ | $\checkmark$
    | $\checkmark$ | $\times$ | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Ghaffarian et al. (Ghaffarian and Shahriari, [2017](#bib.bib49)) | $\checkmark$
    | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\times$ | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Lin et al. (Lin et al., [2020](#bib.bib90)) | $\checkmark$ | $\checkmark$
    | $\checkmark$ | $\checkmark$ | $\times$ | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Zeng et al. (Zeng et al., [2020](#bib.bib152)) | $\checkmark$ | $\checkmark$
    | $\checkmark$ | $\checkmark$ | $\times$ | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | Semasaba et al. (Semasaba et al., [2020](#bib.bib126)) | $\checkmark$
    | $\checkmark$ | $\times$ | $\checkmark$ | $\checkmark$ | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | Sun et al. (Sun et al., [2018](#bib.bib133)) | $\checkmark$ | $\times$
    | $\times$ | $\times$ | $\checkmark$ | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | Kritikos et al. (Kritikos et al., [2019](#bib.bib72)) | $\checkmark$
    | $\times$ | $\times$ | $\times$ | $\checkmark$ | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | Khan et al. (Khan and Parkinson, [2018](#bib.bib70)) | $\times$ | $\times$
    | $\times$ | $\times$ | $\times$ | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | Nong et al. (Nong et al., [2022](#bib.bib112)) | $\times$ | $\times$
    | $\times$ | $\times$ | $\times$ | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | Chakraborty et al. (Chakraborty et al., [2021](#bib.bib20)) | $\times$
    | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | Liu et al. (Liu et al., [2021a](#bib.bib94)) | $\times$ | $\times$ |
    $\times$ | $\times$ | $\times$ | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | Bi et al. (Bi et al., [2023](#bib.bib10)) | $\times$ | $\times$ | $\times$
    | $\times$ | $\times$ | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | Our survey | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\checkmark$
    | $\checkmark$ | $\checkmark$ |'
  prefs: []
  type: TYPE_TB
- en: The columns in the table represent different aspects of the surveys, such as
    the data source used, representation, feature embedding, ML/DL models, vulnerability
    types, and interpretability of ML/DL models. Data Source indicates whether the
    survey reviewed vulnerability detection data sources. Representation discusses
    whether the survey considered source code representation in its analysis. Embedding
    deals with whether the survey is analyzed feature embedding in its analysis. The
    table also considers ML/DL models in the sixth column as ML Models. The table
    also checks whether the survey considers vulnerability types based on Common Weakness
    Enumeration (CWE) number. The last column indicates whether the survey takes into
    account the interpretability of ML/DL models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ghaffarian et al. (Ghaffarian and Shahriari, [2017](#bib.bib49)) is the closest
    survey to ours when it comes to data-driven security vulnerability detection.
    In their survey, they analyzed data-driven software vulnerability detection from
    various aspects including Data Sources, Representation, Embedding types, and different
    ML/DL models as shown in Table [1](#S2.T1 "Table 1 ‣ 2.2\. Related work ‣ 2\.
    Background and Related Work ‣ A Survey on Automated Software Vulnerability Detection
    Using Machine Learning and Deep Learning"). However, there are a couple of differences
    compared to our work. Specifically, this work also surveys vulnerability detection
    from the following aspects: Comprehensive Coverage: Understanding the many sorts
    of vulnerabilities allows researchers to create and develop effective vulnerability
    detection models that can thoroughly discover security vulnerabilities. To guarantee
    that their detection systems cover as many vulnerability types as possible, researchers
    must be familiar with the various methods of attack and potential weaknesses in
    software systems. Customization of Detection Techniques: Different sorts of vulnerabilities
    necessitate distinct detection methods. To build specialized detection systems
    that can discover certain types of vulnerabilities, researchers must first understand
    the subtleties of each vulnerability type. Prioritization of Mitigation Efforts:
    Researchers can prioritize mitigation efforts depending on the severity and effect
    of each vulnerability by understanding the many types of vulnerabilities. Critical
    vulnerabilities that pose the greatest danger to the system or organization can
    be prioritized by researchers. Better Understanding of Attack Patterns: Understanding
    the different types of vulnerabilities provides researchers with insights into
    the different attack patterns used by attackers. This knowledge helps researchers
    design detection techniques that can detect not only known attack patterns but
    also new, unknown patterns. Interpretability refers to the ability to explain
    how a model makes a particular decision or prediction. This is particularly important
    in the context of software vulnerability detection because security researchers
    need to be able to understand why a model is flagging a particular piece of code
    as potentially vulnerable. Additionally, interpretability can help improve trust
    in the model’s predictions. If developers and security researchers can understand
    how a model is making its decisions, they are more likely to trust its output
    and take appropriate actions based on its recommendations.'
  prefs: []
  type: TYPE_NORMAL
- en: Triet et al. (Le et al., [2021a](#bib.bib78)) reviewed data-driven vulnerability
    assessment and prioritization studies. They conduct a review of prior research
    on software assessment and prioritization that leverages machine learning and
    data mining methods. They examine various types of research in this area, discuss
    the strengths and weaknesses of each approach, and highlight some unresolved issues
    and potential areas for future research. The major difference to ours is that
    we review vulnerability detection approaches while they survey assessment and
    prioritization techniques. Vulnerability detection, vulnerability assessment,
    and vulnerability prioritization are all important components of the vulnerability
    management life-cycle, but they involve different stages of the vulnerability
    management process. Our work focuses on Vulnerability detection which refers to
    the process of identifying potential vulnerabilities in software systems. The
    goal of vulnerability detection is to identify all vulnerabilities that exist
    within the system, regardless of their severity. Vulnerability assessment, on
    the other hand, involves evaluating the severity and potential impact of each
    identified vulnerability. This assessment can involve analyzing factors such as
    the likelihood of the vulnerability being exploited and the potential harm that
    could result. Vulnerability prioritization involves ranking the identified vulnerabilities
    based on their level of risk or criticality. This ranking is typically based on
    the results of the vulnerability assessment, as well as other factors such as
    the availability of resources to address the vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Lin et al. (Lin et al., [2020](#bib.bib90)) examined the literature on using
    deep learning and neural network-based approaches for detecting software vulnerabilities.
    There are a couple of differences compared to our survey. First, the study of
    conventional source code representation techniques (Static code attributes) for
    software vulnerability detection. In our survey, we neglect to review such representation
    techniques for a couple of reasons. Static code attributes, such as code length
    or complexity, may not be effective for vulnerability detection because they do
    not capture the dynamic behavior of the code at runtime. Vulnerabilities can manifest
    themselves in unexpected ways that are not apparent in the static code, making
    it difficult to detect them through static analysis alone. Additionally, static
    code attributes may not be able to capture the context of the code, which is important
    for understanding how the code interacts with other components in a system. Finally,
    static analysis tools may produce a high rate of false positives, which can be
    time-consuming to verify and may cause developers to ignore important vulnerabilities.
    Second, we examine the trend analysis of papers published in software vulnerability
    detection in a journal and conference papers because it provides a comprehensive
    understanding of the publishing patterns in a particular field or area of research.
    The trend analysis can shed light on the distribution of research output across
    various publication venues and the shifting preferences of researchers and authors.
    This information can be useful for stakeholders such as publishers, academic institutions,
    and researchers in making strategic decisions related to publishing, funding,
    and research collaborations.
  prefs: []
  type: TYPE_NORMAL
- en: Zeng et al. (Zeng et al., [2020](#bib.bib152)) discussed the increasing attention
    towards exploitable vulnerabilities in software and the development of vulnerability
    detection methods, specifically the application of ML techniques. The paper reviews
    22 recent studies that use deep learning to detect vulnerabilities and identifies
    four game changers that have significantly impacted this field. The survey further
    compares the game changers based on different aspects in software vulnerability
    detection including data source, feature representation, DL models, and detection
    granularity. There are a couple of differences compared to our survey. First,
    we analyze the trend patterns of papers on software vulnerability detection that
    have been published in journals and conferences. This analysis helps us gain a
    thorough comprehension of the publication trends in a specific area of research
    or field. Second, we cover more aspects of software vulnerability detection. While
    they only cover data source, feature representation, DL models, and detection
    granularity, we cover more aspects including vulnerability types and interpretability
    of ML/DL models. Additionally, we provide a more granular analysis of different
    aspects.
  prefs: []
  type: TYPE_NORMAL
- en: Kritikos et al. (Kritikos et al., [2019](#bib.bib72)) and Sun et al. (Sun et al.,
    [2018](#bib.bib133)) focused on cybersecurity and aim to improve cyber resilience.
    Sun et al. (Sun et al., [2018](#bib.bib133)) discussed the paradigm change in
    understanding and protecting against cyber threats from reactive detection to
    proactive prediction, with an emphasis on new research on cybersecurity incident
    prediction systems that use many types of data sources. Kritikos et al. (Kritikos
    et al., [2019](#bib.bib72)) discusses the challenges of migrating applications
    to the cloud and ensuring their security, with a focus on vulnerability management
    during the application lifecycle and the use of open-source tools and databases
    to better secure applications. While the topics of the two abstracts are different,
    they share a common goal of improving cybersecurity and resilience. Both highlight
    the importance of proactive measures to prevent or mitigate cyber threats, rather
    than relying solely on reactive detection and response. Additionally, both highlight
    the importance of utilizing various data sources and tools to improve cybersecurity
    measures. While both approaches aim to improve the security of applications, they
    differ in their focus and techniques used. They mainly focus on providing guidance
    and tools to support vulnerability management during the application lifecycle,
    while in our survey, we focus on software vulnerability detection using ML/DL
    techniques on source code which aim at automating the identification of vulnerabilities
    in the source code.
  prefs: []
  type: TYPE_NORMAL
- en: Khan et al. (Khan and Parkinson, [2018](#bib.bib70)) focused on Vulnerability
    Assessment, which is the process of finding and fixing vulnerabilities in a computer
    system before they can be exploited by hackers. This highlights the necessity
    for more studies into automated vulnerability mitigation strategies that can effectively
    secure software systems. On the other hand, vulnerability identification with
    ML/DL approaches on source code entails analyzing an application’s source code
    in order to spot security flaws. Instead of evaluating the safety of the entire
    system, this method concentrates on finding vulnerabilities in the code itself.
  prefs: []
  type: TYPE_NORMAL
- en: Nong et al.(Nong et al., [2022](#bib.bib112)) explored the open-science aspects
    of studies on software vulnerability detection and argued there is a dearth of
    research on problems of open science in software engineering, particularly with
    regard to software vulnerability detection. The authors conducted an exhaustive
    literature study and identify 55 relevant works that propose deep learning-based
    vulnerability detection approaches. They investigated open science aspects including
    availability, executability, reproducibility, and replicability. The study reveals
    that 25.5% of the examined approaches provide open-source tools. Furthermore,
    some open-source tools lack adequate documentation and thorough implementation,
    rendering them inoperable or unreplicable. The use of unbalanced or intentionally
    produced datasets causes the approaches’ performance to be overstated, rendering
    them unreplicable.
  prefs: []
  type: TYPE_NORMAL
- en: Chakraborty et al. (Chakraborty et al., [2021](#bib.bib20)) investigated the
    performance of cutting-edge DL-based vulnerability prediction approaches in real-world
    vulnerability prediction scenarios. They find that the performance of the state-of-the-art
    DL-based techniques drops by more than 50 percent in real-world scenarios. They
    also discover problems with training data (for example, data duplication and an
    unrealistic distribution of vulnerable classes) and model selection (for example,
    simplistic token-based models). Existing DL-based approaches often learn unrelated
    artifacts instead of features related to the cause of vulnerabilities. The significant
    difference compared to our survey study is that in our work, we focus on the usage
    of ML/DL models for software vulnerability detection and characterize the different
    stages in the pipeline of vulnerability detection. On the other hand, they focus
    on the issues related to the usage of state-of-the-art DL models for software
    vulnerability detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Liu et al. (Liu et al., [2021a](#bib.bib94)) discussed the increasing popularity
    of DL techniques in software engineering research due to their ability to address
    SE challenges without extensive manual feature engineering. The authors highlight
    two important factors often overlooked in DL studies: reproducibility and replicability.
    Reproducibility refers to whether other researchers can obtain the same results
    using the authors’ artifacts, while replicability refers to obtaining similar
    results with re-implemented artifacts and a different experimental setup. The
    major difference compared to our study is that we focus on the usage of ML/DL
    techniques in software vulnerability detection pipelines, while they emphasize
    replicability and reproducibility of the results reported in software engineering
    research studies.'
  prefs: []
  type: TYPE_NORMAL
- en: Bi et al. (Bi et al., [2023](#bib.bib10)) emphasizes the importance of software
    vulnerability detection techniques as well as the absence of a systematic methodology
    to evaluate these approaches. The research is the first to look into and describe
    the current state of software vulnerability detection benchmarking. The assessment
    examines current literature on vulnerability detection benchmarking, including
    methodologies employed in technique-proposing publications and empirical research.
    The survey examines the difficulties associated with benchmarking software vulnerability
    detection approaches and suggests alternative solutions to these difficulties.
    They do not, however, give a characterization of datasets, representations, embedding
    techniques, and models employed in software vulnerability identification, unlike
    our work.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Methodology of Systematic Survey
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 3.1\. Sources of Information
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this paper, we conducted an empirical study following (Keele et al., [2007](#bib.bib69);
    Petersen et al., [2015](#bib.bib116)). The purpose of this study is to collect
    and examine papers from the year 2011 to 2022 focusing on vulnerability detection
    across various programming languages and source codes using machine learning and
    deep learning techniques. The period between 2011 and 2022 is an appropriate time
    interval for reviewing data-driven vulnerability detection for several reasons:
    a) Increase in the volume and diversity of software vulnerabilities: Over the
    past decade, there has been a significant increase in the number and diversity
    of software vulnerabilities that have been discovered and reported ²²2https://nvd.nist.gov/general/news.
    As of 2021, there exist 150,000 CVE records in the National Vulnerability Database
    (NVD)³³3https://nvd.nist.gov/general/brief-history. This increase has created
    a need for more sophisticated and effective methods for vulnerability detection,
    which has led to the development of new data-driven techniques. b) Advancements
    in ML/DL and data analytics: The past decade has seen significant advancements
    in machine learning, including the development of deep learning algorithms (Goodfellow
    et al., [2020](#bib.bib53); Hinton et al., [2006](#bib.bib60)), natural language
    processing techniques (Devlin et al., [2018](#bib.bib35); Liu et al., [2019b](#bib.bib97)),
    and other data-driven approaches that are highly effective in detecting software
    vulnerabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: While we start collecting papers, we search for relevant research papers from
    four available databases, which are ScienceDirect, IEEE Xplore, ACM digital library,
    and Google Scholar.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2\. Search Terms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'From earlier work, we identify key phrases used in the search (Le et al., [2021a](#bib.bib78);
    Lin et al., [2020](#bib.bib90); Zeng et al., [2020](#bib.bib152); Semasaba et al.,
    [2020](#bib.bib126)) and our experience with the subject area. The following are
    the search terms:'
  prefs: []
  type: TYPE_NORMAL
- en: vulnerability detection OR security vulnerability detection OR vulnerability
    detection using machine learning OR vulnerability detection using deep learning
    OR source code security bug prediction OR source code vulnerability detection
    OR source code bug prediction
  prefs: []
  type: TYPE_NORMAL
- en: 3.3\. Study Selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The process of selecting studies to be included in our survey involves the
    following stages: (1) initially choosing studies based on their title, (2) selecting
    studies after reviewing their abstracts, and (3) making further selections after
    reading the full papers. Note that, the initial search results contain entries
    that are not related to security vulnerability detection. This might be caused
    by accidental keyword matching. We manually check each paper and remove these
    irrelevant papers to ensure the quality of our survey dataset. We also observe
    that there exist duplicate papers among search results since the same study could
    be indexed by multiple databases. We then discarded duplicate studies manually.
    To assist the selection of papers that have presented new ML or DL-based models
    for software vulnerability identification, we provide the following inclusion
    and exclusion criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The studies should have been peer-reviewed
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The studies should have experimental results
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The studies should employ an ML or DL technique
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The studies improve existing data-driven vulnerability detection techniques
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The input to ML/DL models should be either source code, commit, or byte-codes
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Also, we have the following exclusion criteria to filter out irrelevant papers:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Studies focusing on other engineering domains
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Studies addressing static analysis, dynamic analysis, mutation testing, fault
    localization
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Review papers
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Studies focusing on vulnerability detection of web and Android applications
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Studies belonging to one of the following categories: books, chapters, tutorials,
    technical reports'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Studies using code similarity or clone detection tools
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Studies focusing on malware detection on mobile devices, intrusion detection,
    and bug detection using static code attributes
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Using these criteria, we narrow down our findings by examining each paper’s
    title, abstract, and contents to get the most relevant and high-quality research
    papers. To make human effort manageable, we developed a script to automatically
    get high-quality records close to the software vulnerability detection problem.
    To summarize, in the first stage, we began with a total of 3,154 papers obtained
    from the database search. From this initial pool, 880 papers were chosen for further
    evaluation in the second stage. During the second stage, these papers were reviewed
    based on their abstracts, resulting in the selection of 116 papers with relevant
    abstracts. Finally, in the third stage, after reading the full papers, 67 papers
    were ultimately chosen for inclusion in the study.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4\. Study Quality Assessment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For each of the final selected studies, we answered the questions below to
    assess its quality:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there a clearly stated research goal related to software vulnerability detection?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the proposed vulnerability detection approach used ML or DL techniques?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there a defined and repeatable technique?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there any explicit contribution to vulnerability detection?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there a clear methodology for validating the technique?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are the subject projects selected for validation suitable for the research goals?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there control techniques or baselines to demonstrate the effectiveness of
    the vulnerability detection technique?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are the evaluation metrics relevant (e.g., evaluate the effectiveness of the
    proposed technique) to the research objectives?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do the results presented in the study align with the research objectives and
    are they presented in a clear and relevant manner?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3.5\. Selection Verification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The process of creating a taxonomy for the selected 67 primary studies involves
    several steps. Initially, the lead author establishes a preliminary taxonomy that
    groups the studies together based on their research questions. This taxonomy provides
    a basic framework for organizing the studies in a meaningful and systematic manner.
    Next, the lead author expands the taxonomy by assigning new papers to the preliminary
    taxonomy. If a new paper cannot fit into any of the existing categories within
    the taxonomy, a new category is created that reflects the unique characteristics
    of that paper. To ensure the accuracy of the taxonomy, the second and third authors
    (who are not involved in the taxonomy creation process) randomly select 20 papers
    from the workflow and check the created taxonomies for any discrepancies. They
    then mark any disagreements they find, and all three authors discuss and resolve
    these disagreements. Initially, the disagreement rate was 30%, but after a second
    round of review and cross-checking of the papers, the authors were able to eliminate
    all disagreements.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7283c42516e7cf1463a0cf8512b5f688.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1. The workflow of our survey.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We present our analyses and findings in this section to address the research
    questions we devised in Section [1](#S1 "1\. Introduction ‣ A Survey on Automated
    Software Vulnerability Detection Using Machine Learning and Deep Learning").
  prefs: []
  type: TYPE_NORMAL
- en: 4.1\. RQ1\. What is the trend of studies using ML/DL models for vulnerability
    detection?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To comprehend the trend of publications, we examined the publication dates along
    with the venues in which they were presented.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.1\. RQ1.1\. What are the trends of studies in software vulnerability detection
    over time?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Figure [2](#S4.F2 "Figure 2 ‣ 4.1.1\. RQ1.1\. What are the trends of studies
    in software vulnerability detection over time? ‣ 4.1\. RQ1\. What is the trend
    of studies using ML/DL models for vulnerability detection? ‣ 4\. Results ‣ A Survey
    on Automated Software Vulnerability Detection Using Machine Learning and Deep
    Learning") demonstrates the publication trend of vulnerability detection studies
    published in eleven years, i.e., between 2011 and 2022\. It is observable that
    the number of publications has increased gradually over the years. There is only
    one publication from 2011 to 2016, and the number of publications increased to
    18 in 2021\. However, there is a decrease in the number of publications in 2022
    compared to the previous year. We have also examined the cumulative number of
    publications shown in Figure [2](#S4.F2 "Figure 2 ‣ 4.1.1\. RQ1.1\. What are the
    trends of studies in software vulnerability detection over time? ‣ 4.1\. RQ1\.
    What is the trend of studies using ML/DL models for vulnerability detection? ‣
    4\. Results ‣ A Survey on Automated Software Vulnerability Detection Using Machine
    Learning and Deep Learning"). It is noticeable that the curve fitting the distribution
    shows a significant increase in slope between 2018 and 2022 suggesting that the
    use of ML/DL techniques for software vulnerability detection has become a prevalent
    trend since 2017, and a broad range of studies have utilized ML/DL models to address
    challenges in this field.
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S4.F2.1.pic1" class="ltx_picture" height="100.52" overflow="visible"
    version="1.1" width="248.12"><g transform="translate(0,100.52) matrix(1 0 0 -1
    0 0) translate(25.47,0) translate(0,25.97) matrix(0.6 0.0 0.0 0.6 -25.47 -25.97)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0) translate(85.23,0) translate(0,54.26)"><g stroke="#000000"
    fill="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 271.4
    -30.7)" fill="#000000" stroke="#000000"><foreignobject width="27.67" height="8.92"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2022</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 242.88 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2021</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 214.35 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2020</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 185.83 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2019</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 157.31 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2018</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 128.78 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2017</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 100.26 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2016</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 71.73 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2015</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 43.21 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2014</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 14.69 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2013</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -13.84 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2011</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -54.59 -8.77)" fill="#000000" stroke="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -54.59 12.78)" fill="#000000" stroke="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$5$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -61.51 34.32)" fill="#000000" stroke="#000000"><foreignobject
    width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -61.51 55.86)" fill="#000000" stroke="#000000"><foreignobject
    width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$15$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -61.51 77.4)" fill="#000000" stroke="#000000"><foreignobject
    width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 278.32 60.9)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="13.84" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$14$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 249.8 78.13)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$18$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 224.73 26.43)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$6$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 196.21 39.36)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$9$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 167.68 39.36)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$9$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 139.16 26.43)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$6$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 110.64 4.89)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 82.11 4.89)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 53.59 4.89)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 25.06 4.89)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -3.46 4.89)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 128.76 -49.65)" fill="#000000" stroke="#000000"><foreignobject width="27.71"
    height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Year</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 -71.01 -35.41)" fill="#000000" stroke="#000000"><foreignobject
    width="143.67" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Number
    of Publications</foreignobject></g></g></g></g></svg><svg id="S4.F2.2.pic1" class="ltx_picture"
    height="101.67" overflow="visible" version="1.1" width="251.81"><g transform="translate(0,101.67)
    matrix(1 0 0 -1 0 0) translate(29.16,0) translate(0,25.97) matrix(0.6 0.0 0.0
    0.6 -29.16 -25.97)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0) translate(91.38,0) translate(0,54.26)"><g stroke="#000000"
    fill="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -13.84
    -30.7)" fill="#000000" stroke="#000000"><foreignobject width="27.67" height="8.92"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2011</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 14.69 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2013</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 43.21 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2014</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 71.73 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2015</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 100.26 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2016</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 128.78 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2017</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 157.31 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2018</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 185.83 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2019</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 214.35 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2020</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 242.88 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2021</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 271.4 -30.7)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2022</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -54.59 -5.2)" fill="#000000" stroke="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -67.66 31.79)" fill="#000000" stroke="#000000"><foreignobject
    width="19.99" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0.5$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -54.59 68.78)" fill="#000000" stroke="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -18.6 4.89)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="37.21" height="11.41" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1\cdot 10^{-2}$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 9.92 5.63)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="37.21" height="11.41" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$2\cdot
    10^{-2}$</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 38.44 7.11)"
    fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject width="37.21" height="11.41"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$4\cdot 10^{-2}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 66.97 7.85)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="37.21" height="11.41" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$5\cdot 10^{-2}$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 95.49 9.33)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="37.21" height="11.41" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$7\cdot
    10^{-2}$</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 129.17 15.99)"
    fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject width="26.91" height="8.92"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0.16$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 157.69 25.6)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="26.91" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$0.29$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 186.21 35.96)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="26.91" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0.43$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 214.74 42.62)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="26.91" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$0.52$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 243.26 62.59)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="26.91" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0.79$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 281.78 78.13)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 128.76 -49.65)" fill="#000000" stroke="#000000"><foreignobject width="27.71"
    height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Year</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 -77.16 -37.33)" fill="#000000" stroke="#000000"><foreignobject
    width="148.67" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Cumulative
    Distribution</foreignobject></g></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2. Publication trend of vulnerability detection studies.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2. Conference publication venues for manual search.
  prefs: []
  type: TYPE_NORMAL
- en: '| No | Acronym | Full name |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | ICSE | International Conference on Software Engineering |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | ECSE/FSE | ACM SIGSOFT Symposium on the Foundation of Software Engineering
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | ASE | IEEE/ACM International Conference on Automated Software Engineering
    |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | USENIX | USENIX |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | OOPSLA | Object-oriented Programming, Systems, Languages, and Applications
    |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | ISSTA | ACM SIGSOFT International Symposium on Software Testing and Analysis
    |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | MSR | IEEE Working Conference on Mining Software Repositories |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | SANER | IEEE International Conference on Software Analysis, Evolution
    and Reengineering |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | ISSRE | IEEE International Symposium on Software Reliability Engineering
    |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | ICSME | IEEE International Conference on Software Maintenance and Evolution
    |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | IJCAI | International Joint Conferences on Artificial Intelligence Organization
    |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | CCS | ACM SIGSAC Conference on Computer and Communications Security
    |'
  prefs: []
  type: TYPE_TB
- en: '| 13 | ICLR | International Conference on Learning Representations |'
  prefs: []
  type: TYPE_TB
- en: '| 14 | NIPS | International Conference on Neural Information Processing Systems
    |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | MASCOT | Modelling, Analysis, and Simulation of Computer and Telecommunication
    Systems |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | QRS | IEEE International Conference on Software Security and Reliability
    |'
  prefs: []
  type: TYPE_TB
- en: '| 17 | KDDM | Pacific-Asia Conference on Knowledge Discovery and Data Mining
    |'
  prefs: []
  type: TYPE_TB
- en: '| 18 | NDSS | Network and Distributed Systems Security Symposium |'
  prefs: []
  type: TYPE_TB
- en: '| 19 | ARES | ACM International Conference on Availability, Reliability and
    Security |'
  prefs: []
  type: TYPE_TB
- en: '| 20 | INFOCOM | IEEE International Workshop on Security and Privacy in Big
    Data |'
  prefs: []
  type: TYPE_TB
- en: '| 21 | ICTAI | IEEE International Conference on Tools with Artificial Intelligence
    |'
  prefs: []
  type: TYPE_TB
- en: '| 22 | ICDM | IEEE International Conference on Data Mining |'
  prefs: []
  type: TYPE_TB
- en: '| 23 | GLOBCOM | IEEE Global Communications Conference |'
  prefs: []
  type: TYPE_TB
- en: '| 24 | TrustCom | IEEE International Conference on Trust, Security and Privacy
    in Computing and Communications |'
  prefs: []
  type: TYPE_TB
- en: '| 25 | DSAA | IEEE International Conference on Data Science and Advanced Analytic
    |'
  prefs: []
  type: TYPE_TB
- en: Table 3. Journal publication venues for manual search.
  prefs: []
  type: TYPE_NORMAL
- en: '| No | Journal Acronym | Full Name |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | TSE | IEEE Transaction on Software Engineering |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | TOSEM | ACM Transaction on Software Engineering and Methodology |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | IST | Information and Software Technology |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | ESM | Empirical Software Engineering |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | JSS | Journal of System and Software |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | TDSC | IEEE Transaction on Dependable and Secure Computing |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | CSJ | Computer and Security Journal |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | TIFS | IEEE Transactions on Information Forensics and Security |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | ISJ | Information Sciences Journal |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | TFS | IEEE Transaction on Fuzzy Systems |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | TKDE | IEEE Transaction on Knowledge and Data Engineering |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | KBS | Knowledge-Based Systems |'
  prefs: []
  type: TYPE_TB
- en: '4.1.2\. RQ1.2: What is the distribution of the publication venues?'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this study, overall, we analyzed and reviewed 67 papers from various publication
    venues including 43 conference and symposium papers along with 24 journal papers.
    We have included the conference and journal acronyms and their complete names
    for reference in Table [2](#S4.T2 "Table 2 ‣ 4.1.1\. RQ1.1\. What are the trends
    of studies in software vulnerability detection over time? ‣ 4.1\. RQ1\. What is
    the trend of studies using ML/DL models for vulnerability detection? ‣ 4\. Results
    ‣ A Survey on Automated Software Vulnerability Detection Using Machine Learning
    and Deep Learning") and Table [3](#S4.T3 "Table 3 ‣ 4.1.1\. RQ1.1\. What are the
    trends of studies in software vulnerability detection over time? ‣ 4.1\. RQ1\.
    What is the trend of studies using ML/DL models for vulnerability detection? ‣
    4\. Results ‣ A Survey on Automated Software Vulnerability Detection Using Machine
    Learning and Deep Learning"). Table [4](#S4.T4 "Table 4 ‣ 4.1.2\. RQ1.2: What
    is the distribution of the publication venues? ‣ 4.1\. RQ1\. What is the trend
    of studies using ML/DL models for vulnerability detection? ‣ 4\. Results ‣ A Survey
    on Automated Software Vulnerability Detection Using Machine Learning and Deep
    Learning") shows the distribution of primary studies for each publication venue.
    64.1% of publications are published in conferences and symposiums while 35.8%
    of papers have been published as journal papers. It is observable that MSR, IJCAI,
    and ECSE/FSE are the most popular venues that have the highest number of primary
    studies, each of which contains 4 papers. Meanwhile, among the journals, TDSC
    and TSE include the highest number of studies, i.e., 6 and 4 studies respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S4.SS1.SSS2.1.pic1" class="ltx_picture" height="151.41" overflow="visible"
    version="1.1" width="593.51"><g transform="translate(0,151.41) matrix(1 0 0 -1
    0 0) translate(20.38,0) translate(0,110.32)"><g stroke="#000000"><g stroke-width="1.0pt"
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 0 0)"><foreignobject
    width="552.76" height="99.63" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">(1)
    The results indicate that the application of ML/DL techniques for software vulnerability
    detection has had a remarkable rising trend in the past few years. (2) A large
    proportion of papers are published in recent two years, i.e., 2021 and 2022. (3)
    MSR, IJCAI, and ECSE/FSE are the most popular conference venues. On the other
    hand, TDSC and TSE are the most popular journal venues. <g stroke-width="0.5pt"
    fill="#FF9999"><path d="M 97.05 40.75 L 5.19 40.75 C 2.13 40.75 -0.35 38.27 -0.35
    35.21 L -0.35 24.91 C -0.35 21.86 2.13 19.38 5.19 19.38 L 97.05 19.38 C 100.11
    19.38 102.59 21.86 102.59 24.91 L 102.59 35.21 C 102.59 38.27 100.11 40.75 97.05
    40.75 Z M -0.35 19.38"></path></g><g stroke-width="0.5pt" fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 4.27 26.68)"><foreignobject width="94.09" height="12.15"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Answer to RQ1</foreignobject></g>
  prefs: []
  type: TYPE_NORMAL
- en: Table 4. Distribution of publications based on conference and journal venues.
  prefs: []
  type: TYPE_NORMAL
- en: '| Conference Venue | # Studies | References | Journal Venue | # Studies | References
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| MSR | 4 | (Chen et al., [2020b](#bib.bib25); Hoang et al., [2019](#bib.bib61);
    Hin et al., [2022](#bib.bib59); Fu and Tantithamthavorn, [2022](#bib.bib46)) |
    TDSC | 6 | (Liu et al., [2020](#bib.bib96); Zou et al., [2019](#bib.bib161); Lin
    et al., [2019](#bib.bib91); Li et al., [2021c](#bib.bib88), [b](#bib.bib87); Zou
    et al., [2022](#bib.bib160)) |'
  prefs: []
  type: TYPE_TB
- en: '| IJCAI | 4 | (Choi et al., [2017](#bib.bib32); Zhuang et al., [2020](#bib.bib158);
    Duan et al., [2019](#bib.bib39); Liu et al., [2021b](#bib.bib98)) | TSE | 4 |
    (Dam et al., [2018](#bib.bib34), [2017](#bib.bib33); Chen et al., [2021](#bib.bib26);
    Scandariato et al., [2014](#bib.bib125)) |'
  prefs: []
  type: TYPE_TB
- en: '| ECSE/FSE | 4 | (Zhou and Sharma, [2017](#bib.bib156); Li et al., [2021a](#bib.bib85);
    Ni et al., [2022](#bib.bib111); Nguyen et al., [2022b](#bib.bib109)) | CSJ | 2
    | (Jeon and Kim, [2021](#bib.bib65); Yan et al., [2021](#bib.bib146)) |'
  prefs: []
  type: TYPE_TB
- en: '| CCS | 3 | (Yamaguchi et al., [2013](#bib.bib145); Lin et al., [2017](#bib.bib92);
    Perl et al., [2015](#bib.bib115); Cheng et al., [2019](#bib.bib30)) | IST | 2
    | (Shippey et al., [2019](#bib.bib129); Tian et al., [2020](#bib.bib135)) |'
  prefs: []
  type: TYPE_TB
- en: '| ISSRE | 3 | (Zheng et al., [2021](#bib.bib154); Wu et al., [2021](#bib.bib141);
    Zeng et al., [2021](#bib.bib151)) | TIFS | 2 | (Wang et al., [2020](#bib.bib137);
    Huang et al., [2021](#bib.bib62)) |'
  prefs: []
  type: TYPE_TB
- en: '| ICLR | 2 | (Dinella et al., [2020](#bib.bib36); Le et al., [2018](#bib.bib77))
    | TOSEM | 2 | (Cheng et al., [2021](#bib.bib29); Zou et al., [2021](#bib.bib162))
    |'
  prefs: []
  type: TYPE_TB
- en: '| ICSE | 2 | (Cao et al., [2022](#bib.bib18); Wang et al., [2016](#bib.bib139))
    | ESM | 1 | (Riom et al., [2021](#bib.bib121)) |'
  prefs: []
  type: TYPE_TB
- en: '| OOPSLA | 2 | (Pradel and Sen, [2018](#bib.bib119); Li et al., [2019](#bib.bib86))
    | ISJ | 1 | (Ghaffarian and Shahriari, [2021](#bib.bib50)) |'
  prefs: []
  type: TYPE_TB
- en: '| NIPS | 2 | (Harer et al., [2018](#bib.bib56); Zhou et al., [2019](#bib.bib155))
    | JSS | 1 | (Pascarella et al., [2019](#bib.bib114)) |'
  prefs: []
  type: TYPE_TB
- en: '| ASE | 2 | (Le et al., [2021b](#bib.bib80); Zhang et al., [2022](#bib.bib153))
    | TFS | 1 | (Liu et al., [2019a](#bib.bib95)) |'
  prefs: []
  type: TYPE_TB
- en: '| QRS | 1 | (Li et al., [2017](#bib.bib83)) | TKDE | 1 | (Liu et al., [2021c](#bib.bib99))
    |'
  prefs: []
  type: TYPE_TB
- en: '| KDDM | 1 | (Nguyen et al., [2020](#bib.bib110)) | KBS | 1 | (Zhuang et al.,
    [2022](#bib.bib157)) |'
  prefs: []
  type: TYPE_TB
- en: '| NDSS | 1 | (Li et al., [2018](#bib.bib89)) | SUM | 24 |  |'
  prefs: []
  type: TYPE_TB
- en: '| ARES | 1 | (Kronjee et al., [2018](#bib.bib73)) |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| INFOCOM | 1 | (Ziems and Wu, [2021](#bib.bib159)) |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| MASCOT | 1 | (Filus et al., [2020](#bib.bib43)) |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| ICTAI | 1 | (Phan et al., [2017](#bib.bib117)) |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| ICSME | 1 | (Sabetta and Bezzi, [2018](#bib.bib124)) |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| ICDM | 1 | (Huo et al., [2018](#bib.bib63)) |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| GLOBCOM | 1 | (Yang et al., [2017](#bib.bib148)) |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| USENIX | 1 | (Yamaguchi et al., [2011](#bib.bib144)) |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| DSAA | 1 | (Nguyen et al., [2022b](#bib.bib109)) |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| ISSTA | 1 | (Cheng et al., [2022](#bib.bib31)) |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| SANER | 1 | (Ding et al., [2022](#bib.bib37)) |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| TrustCom | 1 | (Yang et al., [2022](#bib.bib147)) |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| SUM | 43 |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: 4.2\. RQ2\. What are the characteristics of software vulnerability detection
    datasets?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data is important for building and evaluating ML/DL-based software vulnerability
    detection models (Lin et al., [2019](#bib.bib91); Cheng et al., [2022](#bib.bib31);
    Lin et al., [2018](#bib.bib93); Du et al., [2020](#bib.bib38); Dam et al., [2017](#bib.bib33)).
    The quality of datasets can be assessed by different factors such as the source
    of data, data size and scale, data types, and preprocessing steps performed on
    data. For example, inappropriate preprocessing (representation) on data may result
    in poor performance of DL models (Ruospo et al., [2020](#bib.bib122)). In this
    section, we examine data used in vulnerability detection studies and conducted
    a comprehensive analysis of the steps of data source, data type, and data representation.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1\. RQ2.1\. What are the sources of datasets?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the main challenges in ML/DL-based software vulnerability detection is
    the insufficient amount of data available for training operations (Chen et al.,
    [2020b](#bib.bib25); Lin et al., [2018](#bib.bib93)). Consequently, there exists
    a gap in research on how to obtain sufficient datasets to facilitate the training
    of ML/DL models for software security vulnerability detection. To this end, we
    analyze the sources of datasets in the studied 67 primary studies. Our analysis
    reveals that datasets for this purpose can be broadly classified into three categories,
    i.e., Benchmark, Collected, and Hybrid sources. Benchmark contains standardized
    datasets used to evaluate the performance of vulnerability detection methods and
    techniques (Sabetta and Bezzi, [2018](#bib.bib124); Dam et al., [2018](#bib.bib34),
    [2017](#bib.bib33); Wang et al., [2016](#bib.bib139); Jeon and Kim, [2021](#bib.bib65);
    Tian et al., [2020](#bib.bib135); Liu et al., [2020](#bib.bib96); Yamaguchi et al.,
    [2013](#bib.bib145); Liu et al., [2021c](#bib.bib99); Phan et al., [2017](#bib.bib117);
    Nguyen et al., [2020](#bib.bib110); Hoang et al., [2019](#bib.bib61); Kronjee
    et al., [2018](#bib.bib73); Zeng et al., [2021](#bib.bib151); Yan et al., [2021](#bib.bib146);
    Zou et al., [2021](#bib.bib162); Huo et al., [2018](#bib.bib63); Harer et al.,
    [2018](#bib.bib56)).
  prefs: []
  type: TYPE_NORMAL
- en: Benchmark datasets for software vulnerability detection are often built from
    three main sources. The first source of data is collecting code snippets from
    open sources. This can include open-source software projects (Jimenez et al.,
    [2016](#bib.bib68)), public vulnerability databases (Black, [2017](#bib.bib12)),
    and bug repositories (Bugzilla’s, [2021](#bib.bib15)). The goal is to gather a
    diverse set of programs or code snippets that represent different application
    domains, programming languages, and vulnerability types. From the collected data,
    specific programs or code snippets are selected to be included in the benchmark
    dataset. The selection process considers factors such as program complexity, vulnerability
    diversity, and code quality. The aim is to create a dataset that covers a wide
    range of vulnerabilities and represents real-world scenarios. In some cases, benchmark
    datasets may include automatically generated synthetic programs (Booth et al.,
    [2013](#bib.bib13)). These programs are typically created using code generation
    techniques and follow certain patterns or templates. Synthetic generation allows
    for the creation of large-scale datasets and can help cover a broader range of
    vulnerabilities systematically. Alongside synthetic programs, benchmark datasets
    often include real-world software applications or code snippets written by hand.
    These manually created cases ensure that the dataset contains realistic vulnerabilities
    that reflect actual coding practices. Manual creation involves identifying vulnerable
    points in the code, introducing appropriate weaknesses, and maintaining a balance
    between code quality and realism.
  prefs: []
  type: TYPE_NORMAL
- en: Collected datasets are gathered from publicly available projects hosted on repository
    websites such as Github or Stack Overflow (Chen et al., [2020b](#bib.bib25); Zhou
    and Sharma, [2017](#bib.bib156); Liu et al., [2019a](#bib.bib95); Pradel and Sen,
    [2018](#bib.bib119); Cheng et al., [2021](#bib.bib29); Zhou et al., [2019](#bib.bib155)).
    Also, some studies use the combination of different sources for vulnerability
    detection to increase the external validity of their findings (Chen et al., [2020b](#bib.bib25);
    Zhou and Sharma, [2017](#bib.bib156); Russell et al., [2018](#bib.bib123); Wang
    et al., [2020](#bib.bib137); Le et al., [2021b](#bib.bib80); Hin et al., [2022](#bib.bib59);
    Li et al., [2021a](#bib.bib85)), which refers to Hybrid source in this work.
  prefs: []
  type: TYPE_NORMAL
- en: The distribution of dataset sources in the primary studies is illustrated in
    figure [3](#S4.F3 "Figure 3 ‣ 4.2.1\. RQ2.1\. What are the sources of datasets?
    ‣ 4.2\. RQ2\. What are the characteristics of software vulnerability detection
    datasets? ‣ 4\. Results ‣ A Survey on Automated Software Vulnerability Detection
    Using Machine Learning and Deep Learning"). As we can see, 65.7% of primary studies
    have utilized Benchmark datasets for software vulnerability detection. The rationale
    behind this trend is that benchmark datasets are readily accessible to all researchers
    and can facilitate the reproducibility of prior studies. Researchers often used
    Collected datasets in evaluating the proposed ML or DL-based security vulnerability
    detection models. According to our observation, 25.4% of studies build vulnerability
    detection models using collected datasets. There are a couple of reasons, first
    of all, open-source repositories like GitHub contain a vast amount of real-world
    code written by developers from diverse backgrounds. This data reflects the real-world
    coding practices, patterns, and vulnerabilities present in software projects.
    By analyzing such data, researchers can gain insights into the prevalent types
    of vulnerabilities and their occurrence frequencies in real-world software. Second,
    open-source repositories offer the opportunity to identify new vulnerabilities
    that may not be present in benchmark datasets. By analyzing diverse codebases,
    researchers can uncover previously unknown vulnerabilities or variations of known
    vulnerabilities, which helps in advancing the state-of-the-art in vulnerability
    detection and expanding the knowledge base of software security.
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S4.F3.pic1" class="ltx_picture ltx_centering" height="1" overflow="visible"
    version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><foreignobject width="0" height="0" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">\pie</foreignobject></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3. The source of the datasets used in primary study papers.
  prefs: []
  type: TYPE_NORMAL
- en: The third major source of data is Hybrid accounting for 9% of primary studies
    which is the combination of different sources. Researchers often use hybrid sources
    for software vulnerability detection to address some of the limitations of individual
    data sources and to obtain more diverse and comprehensive datasets. For example,
    researchers may combine data from benchmark datasets with data from other sources
    such as Github, open-source projects, or data from commercial companies to create
    a hybrid dataset that is more representative of real-world scenarios. By doing
    so, they can improve the generalizability of their models and increase their chances
    of detecting a wider range of vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Table [5](#S4.T5 "Table 5 ‣ 4.2.1\. RQ2.1\. What are the sources of datasets?
    ‣ 4.2\. RQ2\. What are the characteristics of software vulnerability detection
    datasets? ‣ 4\. Results ‣ A Survey on Automated Software Vulnerability Detection
    Using Machine Learning and Deep Learning") shows the detailed distribution of
    benchmark data used in the primary studies. As it is observable, NVD and SARD
    is the most widely used source of data in the Benchmark category. This is because
    SARD and NVD are publicly available benchmark sources to which researchers have
    unrestricted access. They give a lot of vulnerability data, allowing researchers
    to get a broad variety of vulnerabilities for their experiments and analyses.
    The availability of these materials promotes repeatability and collaboration among
    researchers in software vulnerability detection. Overall, there are 35 unique
    primary studies that use benchmark datasets from different sources.
  prefs: []
  type: TYPE_NORMAL
- en: Table [6](#S4.T6 "Table 6 ‣ 4.2.1\. RQ2.1\. What are the sources of datasets?
    ‣ 4.2\. RQ2\. What are the characteristics of software vulnerability detection
    datasets? ‣ 4\. Results ‣ A Survey on Automated Software Vulnerability Detection
    Using Machine Learning and Deep Learning") shows the detailed distribution of
    the Collected source of data. As shown, Github is the most popular source of data
    for software vulnerability detection, accounting for 14 primary studies. Researchers
    can collect datasets from Github by crawling the platform and extracting relevant
    code repositories or by using Github’s API to access data programmatically. One
    advantage of using GitHub as a source of data is that it provides access to real-world
    code written by developers, which can be used to train and test vulnerability
    detection models. This data can be particularly useful for detecting new and emerging
    vulnerabilities that may not be covered by benchmark datasets. Jira, CVE, and
    Bugzilla come after with 2 primary studies for each. Overall, there are 17 unique
    primary studies that use collected sources of data for software vulnerability
    detection.
  prefs: []
  type: TYPE_NORMAL
- en: Table 5. Detailed distribution of benchmark sources.
  prefs: []
  type: TYPE_NORMAL
- en: '| No | Source | # Studies | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | SARD | 17 | (Jeon and Kim, [2021](#bib.bib65); Tian et al., [2020](#bib.bib135);
    Liu et al., [2020](#bib.bib96); Wang et al., [2020](#bib.bib137); Cheng et al.,
    [2021](#bib.bib29); Zou et al., [2019](#bib.bib161); Cao et al., [2022](#bib.bib18);
    Ziems and Wu, [2021](#bib.bib159); Lin et al., [2019](#bib.bib91); Li et al.,
    [2021c](#bib.bib88); Filus et al., [2020](#bib.bib43); Li et al., [2021b](#bib.bib87);
    Zou et al., [2019](#bib.bib161); Li et al., [2021a](#bib.bib85); Duan et al.,
    [2019](#bib.bib39); Zheng et al., [2021](#bib.bib154); Yang et al., [2022](#bib.bib147))
    |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | NVD | 13 | (Jeon and Kim, [2021](#bib.bib65); Liu et al., [2020](#bib.bib96);
    Wang et al., [2020](#bib.bib137); Le et al., [2021b](#bib.bib80); Kronjee et al.,
    [2018](#bib.bib73); Hin et al., [2022](#bib.bib59); Zou et al., [2019](#bib.bib161);
    Cao et al., [2022](#bib.bib18); Li et al., [2021c](#bib.bib88); Filus et al.,
    [2020](#bib.bib43); Li et al., [2021b](#bib.bib87); Zou et al., [2019](#bib.bib161);
    Zheng et al., [2021](#bib.bib154)) |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | ESC and VSC | 3 | (Liu et al., [2021c](#bib.bib99); Zhuang et al., [2020](#bib.bib158);
    Liu et al., [2021b](#bib.bib98)) |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | SmartBugs Wild | 3 | (Wu et al., [2021](#bib.bib141); Nguyen et al.,
    [2022b](#bib.bib109), [a](#bib.bib108)) |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | Juliet test suit | 3 | (Yan et al., [2021](#bib.bib146); Li et al., [2021a](#bib.bib85);
    Ding et al., [2022](#bib.bib37)) |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | SmartBugs | 2 | (Nguyen et al., [2022b](#bib.bib109), [a](#bib.bib108))
    |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | PROMISE | 2 | (Wang et al., [2016](#bib.bib139); Zeng et al., [2021](#bib.bib151))
    |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | D2A | 2 | (Cheng et al., [2022](#bib.bib31); Ding et al., [2022](#bib.bib37))
    |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | NDSS | 2 | (Le et al., [2018](#bib.bib77); Nguyen et al., [2020](#bib.bib110))
    |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | NIST | 1 | (Harer et al., [2018](#bib.bib56)) |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | OWASP | 1 | (Harer et al., [2018](#bib.bib56)) |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | SAMATE | 1 | (Kronjee et al., [2018](#bib.bib73)) |'
  prefs: []
  type: TYPE_TB
- en: '| 13 | Mozilla Firefox projects | 1 | (Yang et al., [2017](#bib.bib148)) |'
  prefs: []
  type: TYPE_TB
- en: '| 14 | ICLR2019 | 1 | (Yang et al., [2017](#bib.bib148)) |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | FQ | 1 | (Cheng et al., [2022](#bib.bib31)) |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | Bugs Wild Dataset | 1 | (Zhang et al., [2022](#bib.bib153)) |'
  prefs: []
  type: TYPE_TB
- en: '| 17 | Others | 1 | (Nguyen et al., [2020](#bib.bib110)) |'
  prefs: []
  type: TYPE_TB
- en: '| - | SUM | 53 (35) | - |'
  prefs: []
  type: TYPE_TB
- en: Table 6. Detailed distribution of Collected sources.
  prefs: []
  type: TYPE_NORMAL
- en: '| No | Source | # Studies | References |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Github | 14 | (Chen et al., [2020b](#bib.bib25); Zhou and Sharma, [2017](#bib.bib156);
    Liu et al., [2019a](#bib.bib95); Pradel and Sen, [2018](#bib.bib119); Cheng et al.,
    [2021](#bib.bib29); Zhou et al., [2019](#bib.bib155); Pascarella et al., [2019](#bib.bib114);
    Dinella et al., [2020](#bib.bib36); Li et al., [2019](#bib.bib86); Fu and Tantithamthavorn,
    [2022](#bib.bib46); Chen et al., [2021](#bib.bib26); Perl et al., [2015](#bib.bib115);
    Riom et al., [2021](#bib.bib121); Ni et al., [2022](#bib.bib111)) |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Jira | 2 | (Chen et al., [2020b](#bib.bib25); Zhou and Sharma, [2017](#bib.bib156))
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | CVE | 2 | (Chen et al., [2020b](#bib.bib25); Zou et al., [2022](#bib.bib160))
    |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Bugzilla | 2 | (Chen et al., [2020b](#bib.bib25); Zhou and Sharma, [2017](#bib.bib156))
    |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | Others | 2 | (Huang et al., [2021](#bib.bib62); Hoang et al., [2019](#bib.bib61))
    |'
  prefs: []
  type: TYPE_TB
- en: '| - | SUM | 22 (17) | - |'
  prefs: []
  type: TYPE_TB
- en: 4.2.2\. RQ2.2\. What are the types of software vulnerability detection datasets
    used in prior studies?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When it comes to detecting software vulnerabilities, datasets can have varying
    data types, e.g., existing software vulnerability detection models can find vulnerabilities
    in source code or commits. It is crucial to carefully examine the data types,
    as they require different preprocessing techniques and must be represented differently
    when using ML/DL models. Additionally, distinct data types necessitate different
    architectural approaches for ML/DL models. This section provides an overview of
    the various data types and their distributions. We classified the data types of
    employed datasets into three broad categories, i.e., code-based, repository-based,
    and hybrid.
  prefs: []
  type: TYPE_NORMAL
- en: Figure [4](#S4.F4 "Figure 4 ‣ 4.2.2\. RQ2.2\. What are the types of software
    vulnerability detection datasets used in prior studies? ‣ 4.2\. RQ2\. What are
    the characteristics of software vulnerability detection datasets? ‣ 4\. Results
    ‣ A Survey on Automated Software Vulnerability Detection Using Machine Learning
    and Deep Learning") shows the distribution of the data types in primary studies.
    We can observe that the majority of primary studies (70.1%) primarily focus on
    analyzing the source code for software vulnerability detection. This indicates
    the significance of code-level analysis in identifying vulnerabilities. The utilization
    of repository-level data, such as commit history and change logs, is also prominent,
    representing a substantial portion (25.4%) of primary studies. This suggests that
    repository-level information is considered valuable in vulnerability detection.
    Additionally, a smaller portion (4.5%) of the studies adopt a hybrid approach,
    combining both code-level analysis and repository-level information. These techniques
    leverage the strengths of both data sources to improve the accuracy and effectiveness
    of vulnerability detection.
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S4.F4.pic1" class="ltx_picture ltx_centering" height="1" overflow="visible"
    version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><foreignobject width="0" height="0" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">\pie</foreignobject></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4. The type of datasets in primary studies.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7. Data types of datasets involved in primary studies.
  prefs: []
  type: TYPE_NORMAL
- en: '| Category | Data Type | #Studies | Total | References |'
  prefs: []
  type: TYPE_TB
- en: '| Code-based | Source code | 42 | 47 | (Dam et al., [2018](#bib.bib34), [2017](#bib.bib33);
    Shippey et al., [2019](#bib.bib129); Wang et al., [2016](#bib.bib139); Jeon and
    Kim, [2021](#bib.bib65); Tian et al., [2020](#bib.bib135); Liu et al., [2020](#bib.bib96);
    Yamaguchi et al., [2013](#bib.bib145); Liu et al., [2021c](#bib.bib99); Kronjee
    et al., [2018](#bib.bib73); Choi et al., [2017](#bib.bib32); Zeng et al., [2021](#bib.bib151);
    Zou et al., [2021](#bib.bib162); Huo et al., [2018](#bib.bib63); Harer et al.,
    [2018](#bib.bib56); Zou et al., [2019](#bib.bib161); Cao et al., [2022](#bib.bib18);
    Ghaffarian and Shahriari, [2021](#bib.bib50); Wu et al., [2021](#bib.bib141);
    Lin et al., [2017](#bib.bib92); Scandariato et al., [2014](#bib.bib125); Ziems
    and Wu, [2021](#bib.bib159); Zhuang et al., [2020](#bib.bib158); Li et al., [2017](#bib.bib83);
    Lin et al., [2019](#bib.bib91); Li et al., [2021c](#bib.bib88); Filus et al.,
    [2020](#bib.bib43); Li et al., [2021b](#bib.bib87), [2018](#bib.bib89), [a](#bib.bib85);
    Yamaguchi et al., [2011](#bib.bib144); Duan et al., [2019](#bib.bib39); Zheng
    et al., [2021](#bib.bib154); Zhuang et al., [2022](#bib.bib157); Cheng et al.,
    [2022](#bib.bib31); Liu et al., [2021b](#bib.bib98); Ding et al., [2022](#bib.bib37);
    Zhang et al., [2022](#bib.bib153); Yang et al., [2022](#bib.bib147); Zou et al.,
    [2022](#bib.bib160); Nguyen et al., [2022b](#bib.bib109), [a](#bib.bib108)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Binary code | 5 |  | (Phan et al., [2017](#bib.bib117); Nguyen et al.,
    [2020](#bib.bib110); Yan et al., [2021](#bib.bib146); Huang et al., [2021](#bib.bib62);
    Le et al., [2018](#bib.bib77)) |'
  prefs: []
  type: TYPE_TB
- en: '| Repository-based | Code change | 8 | 13 | (Liu et al., [2019a](#bib.bib95);
    Pradel and Sen, [2018](#bib.bib119); Zhou et al., [2019](#bib.bib155); Dinella
    et al., [2020](#bib.bib36); Li et al., [2019](#bib.bib86); Hin et al., [2022](#bib.bib59);
    Fu and Tantithamthavorn, [2022](#bib.bib46); Chen et al., [2021](#bib.bib26))
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Commit | 5 |  | (Pascarella et al., [2019](#bib.bib114); Perl et al.,
    [2015](#bib.bib115); Riom et al., [2021](#bib.bib121); Yang et al., [2017](#bib.bib148);
    Ni et al., [2022](#bib.bib111)) |'
  prefs: []
  type: TYPE_TB
- en: '| Hybrid | Source Code+Code change | 3 | 7 | (Wang et al., [2020](#bib.bib137);
    Le et al., [2021b](#bib.bib80); Cheng et al., [2021](#bib.bib29)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Commits+Code Change | 2 |  | (Sabetta and Bezzi, [2018](#bib.bib124);
    Hoang et al., [2019](#bib.bib61)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Commits+Bug reports | 1 |  | (Zhou and Sharma, [2017](#bib.bib156)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Bug report+Commits+Emails | 1 |  | (Chen et al., [2020b](#bib.bib25))
    |'
  prefs: []
  type: TYPE_TB
- en: '| SUM | - | - | 67(67) | - |'
  prefs: []
  type: TYPE_TB
- en: Table [7](#S4.T7 "Table 7 ‣ 4.2.2\. RQ2.2\. What are the types of software vulnerability
    detection datasets used in prior studies? ‣ 4.2\. RQ2\. What are the characteristics
    of software vulnerability detection datasets? ‣ 4\. Results ‣ A Survey on Automated
    Software Vulnerability Detection Using Machine Learning and Deep Learning") elaborates
    the detailed data types categories used in primary studies. The table shows that
    42 primary studies used code-based category and the major data type of this category
    is Source code (Zheng et al., [2021](#bib.bib154); Duan et al., [2019](#bib.bib39);
    Yamaguchi et al., [2011](#bib.bib144); Li et al., [2021a](#bib.bib85); Zou et al.,
    [2019](#bib.bib161); Li et al., [2021b](#bib.bib87); Filus et al., [2020](#bib.bib43);
    Li et al., [2021c](#bib.bib88); Lin et al., [2019](#bib.bib91); Li et al., [2017](#bib.bib83);
    Zhuang et al., [2020](#bib.bib158); Ziems and Wu, [2021](#bib.bib159)). Binary
    code is the second major data type in code-based category (Phan et al., [2017](#bib.bib117);
    Huang et al., [2021](#bib.bib62); Yan et al., [2021](#bib.bib146); Nguyen et al.,
    [2020](#bib.bib110)) accounting for 5 primary studies. Regarding the Repository
    based category, 13 primary studies focused on extracting useful information and
    patterns by crawling different artifacts from software repositories from open
    source. The major artifact is Code change accounting for 8 primary studies (Chen
    et al., [2021](#bib.bib26); Fu and Tantithamthavorn, [2022](#bib.bib46); Hin et al.,
    [2022](#bib.bib59); Li et al., [2019](#bib.bib86); Dinella et al., [2020](#bib.bib36);
    Zhou et al., [2019](#bib.bib155); Pradel and Sen, [2018](#bib.bib119); Liu et al.,
    [2019a](#bib.bib95)), and Commit comes as the second with 5 primary studies. The
    last category of data types is Hybrid where the studies used a combination of
    different data types for software security vulnerability detection, accounting
    for 7 primary studies. As can be seen, Source code+Code change is the most dominant
    data type combination (Wang et al., [2020](#bib.bib137); Le et al., [2021b](#bib.bib80);
    Cheng et al., [2021](#bib.bib29)).
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.3\. RQ2.3\. How input data are represented?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As noted in earlier sections, research studies focused on software vulnerability
    detection rely on diverse sources of data and data types. This heterogeneity necessitates
    the use of varied representation techniques, which in turn requires different
    architectural approaches and design assumptions for ML/DL models. We classified
    the input representation of employed datasets into five broad categories, i.e.,
    Graph-based, Tree-based, Token-based, Metric-based and Hybrid. Figure [5](#S4.F5
    "Figure 5 ‣ 4.2.3\. RQ2.3\. How input data are represented? ‣ 4.2\. RQ2\. What
    are the characteristics of software vulnerability detection datasets? ‣ 4\. Results
    ‣ A Survey on Automated Software Vulnerability Detection Using Machine Learning
    and Deep Learning") shows the distribution of different input representations
    used in primary studies. From the pie chart, we can observe that the most popular
    input representation is the use of Graph/Tree-based representation, accounting
    for the largest slice (i.e., 38.8% for Graph-based and 16.4% for Tree-based).
    Token-based representation follows closely, representing a substantial portion
    (29.9%) of primary studies. Hybrid representation combines multiple representations
    or approaches, which makes up a smaller portion (10.4%). Finally, the use of Commit
    Metrics in vulnerability detection has the smallest portion (4.5%). In the following
    paragraphs, we elaborate on each category in detail. Graph/Tree-based representation (Jeon
    and Kim, [2021](#bib.bib65); Tian et al., [2020](#bib.bib135); Liu et al., [2021c](#bib.bib99);
    Phan et al., [2017](#bib.bib117); Cheng et al., [2021](#bib.bib29); Zhou et al.,
    [2019](#bib.bib155); Kronjee et al., [2018](#bib.bib73); Zeng et al., [2021](#bib.bib151);
    Huang et al., [2021](#bib.bib62); Li et al., [2019](#bib.bib86); Zou et al., [2019](#bib.bib161);
    Cao et al., [2022](#bib.bib18); Ghaffarian and Shahriari, [2021](#bib.bib50);
    Wu et al., [2021](#bib.bib141); Zhuang et al., [2020](#bib.bib158); Li et al.,
    [2021c](#bib.bib88); Zou et al., [2019](#bib.bib161); Duan et al., [2019](#bib.bib39);
    Zheng et al., [2021](#bib.bib154); Cheng et al., [2022](#bib.bib31); Liu et al.,
    [2021b](#bib.bib98); Ding et al., [2022](#bib.bib37); Yang et al., [2022](#bib.bib147);
    Zou et al., [2022](#bib.bib160); Nguyen et al., [2022b](#bib.bib109), [a](#bib.bib108)):
    allows for the detection of complex patterns and relationships between different
    code elements. By representing source code as a graph or tree, it becomes possible
    to capture not only the syntax and structure of the code but also its semantics,
    control flow, and data flow. There are many graph/tree-based representation techniques
    like Abstract Syntax Trees (AST) (Mao et al., [2020](#bib.bib103); Yamaguchi et al.,
    [2012](#bib.bib143); Dinella et al., [2020](#bib.bib36); Lin et al., [2017](#bib.bib92),
    [2019](#bib.bib91); Li et al., [2021b](#bib.bib87)) and Code Property Graph (CPG)
    (Zhou et al., [2019](#bib.bib155); Ghaffarian and Shahriari, [2021](#bib.bib50);
    Duan et al., [2019](#bib.bib39)) used to transform source code into AST and CPG
    representations.'
  prefs: []
  type: TYPE_NORMAL
- en: t! <svg id="S4.F5.1.pic1" class="ltx_picture ltx_centering" height="1" overflow="visible"
    version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><foreignobject width="0" height="0" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">\pie</foreignobject></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5. Different representation used by primary studies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Token-based representation (Aivatoglou et al., [2021](#bib.bib4); Zhou and
    Sharma, [2017](#bib.bib156); Russell et al., [2018](#bib.bib123); Dam et al.,
    [2018](#bib.bib34); Yamaguchi et al., [2013](#bib.bib145); Du et al., [2020](#bib.bib38);
    Nguyen et al., [2020](#bib.bib110); Liu et al., [2019a](#bib.bib95); Pradel and
    Sen, [2018](#bib.bib119); Le et al., [2021b](#bib.bib80); Hoang et al., [2019](#bib.bib61)):
    treat the source code as string token sequences and then transforms source code
    into tokens vectors. The input data is first split into a sequence of tokens,
    which are then converted into numerical vectors that can be processed by machine
    learning algorithms. Tokenization involves breaking down a string of text or source
    code into smaller units, or tokens, which can then be used as the basis for further
    analysis. In the case of source code, tokens might include keywords, operators,
    variables, and other elements of the programming language syntax.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Commit Metrics (Ni et al., [2022](#bib.bib111); Yang et al., [2017](#bib.bib148);
    Pascarella et al., [2019](#bib.bib114)): leverages the metrics extracted from
    commits to represent code commits. Features derived from commits, such as the
    size of code changes, the number of modified lines, the complexity of the changes,
    or the programming language used, can be used as inputs to train ML/DL models.
    These models can then learn patterns and relationships between commit characteristics
    and the presence of vulnerabilities, enabling automated detection based on new
    commits.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hybrid representation (Russell et al., [2018](#bib.bib123); Wang et al., [2020](#bib.bib137);
    Le et al., [2021b](#bib.bib80); Cheng et al., [2021](#bib.bib29); Sabetta and
    Bezzi, [2018](#bib.bib124); Hoang et al., [2019](#bib.bib61); Zhou and Sharma,
    [2017](#bib.bib156); Chen et al., [2020b](#bib.bib25)): uses a combination of
    different representations for software security vulnerability detection. Combining
    different representations of input data can lead to a more comprehensive and richer
    input representation of source code, which can improve the performance of vulnerability
    detection models in tasks such as prediction or detection. Combining different
    representations such as token-based representations and graph-based representations
    can help capture both the syntax and semantics of the code, as well as the relationships
    between different components of the code.'
  prefs: []
  type: TYPE_NORMAL
- en: Table [8](#S4.T8 "Table 8 ‣ 4.2.3\. RQ2.3\. How input data are represented?
    ‣ 4.2\. RQ2\. What are the characteristics of software vulnerability detection
    datasets? ‣ 4\. Results ‣ A Survey on Automated Software Vulnerability Detection
    Using Machine Learning and Deep Learning") shows the representation techniques
    distributed by different artifacts used by ML/DL models. It is observable that
    Graph/Tree-based representation is the most dominant technique used by primary
    studies, accounting for 32 unique primary studies in total. These studies represent
    the input to ML/DL models via Source code as a graph, Source code as a tree, and
    Binary code as a graph. Source code as a graph is the major representation technique
    used by primary studies (Jeon and Kim, [2021](#bib.bib65); Tian et al., [2020](#bib.bib135);
    Liu et al., [2021c](#bib.bib99); Phan et al., [2017](#bib.bib117); Cheng et al.,
    [2021](#bib.bib29); Zhou et al., [2019](#bib.bib155); Kronjee et al., [2018](#bib.bib73);
    Zeng et al., [2021](#bib.bib151); Huang et al., [2021](#bib.bib62); Li et al.,
    [2019](#bib.bib86); Zou et al., [2019](#bib.bib161); Cao et al., [2022](#bib.bib18);
    Ghaffarian and Shahriari, [2021](#bib.bib50); Wu et al., [2021](#bib.bib141);
    Zhuang et al., [2020](#bib.bib158); Li et al., [2021c](#bib.bib88); Zou et al.,
    [2019](#bib.bib161); Duan et al., [2019](#bib.bib39); Zheng et al., [2021](#bib.bib154);
    Cheng et al., [2022](#bib.bib31); Liu et al., [2021b](#bib.bib98); Ding et al.,
    [2022](#bib.bib37); Yang et al., [2022](#bib.bib147); Zou et al., [2022](#bib.bib160);
    Nguyen et al., [2022b](#bib.bib109), [a](#bib.bib108)) accounting for 22 studies.
    Source code as a tree (Dam et al., [2017](#bib.bib33); Shippey et al., [2019](#bib.bib129);
    Wang et al., [2016](#bib.bib139); Liu et al., [2020](#bib.bib96); Wang et al.,
    [2020](#bib.bib137); Dinella et al., [2020](#bib.bib36); Lin et al., [2017](#bib.bib92);
    Li et al., [2017](#bib.bib83); Lin et al., [2019](#bib.bib91); Li et al., [2021b](#bib.bib87);
    Zhuang et al., [2022](#bib.bib157)) is the second major representation technique
    accounting for 9 primary studies. Some researchers used Binary code as a graph (Phan
    et al., [2017](#bib.bib117); Huang et al., [2021](#bib.bib62)) to build binary-level
    vulnerability detection models, accounting for 2 primary studies. There are 14
    primary studies that used Token-based representation, in which 10 primary studies
    represented source code as a token sequence, three primary studies modeled binary
    code as a token, and one study represented text as token sequences (Zhou and Sharma,
    [2017](#bib.bib156)). Hybrid representation has 5 different types accounting for
    8 primary studies. Token Sequence+Commit Metrics is the major artifact used to
    enhance the input representation in software vulnerability detection, accounting
    for 4 primary studies. It combines information from the token sequence of the
    code and additional metrics derived from software commits. This approach leverages
    both the structural and historical aspects of the code to provide a more comprehensive
    representation for building vulnerability detection models.
  prefs: []
  type: TYPE_NORMAL
- en: Commits is the fourth least input representation used by 3 primary studies.
    In this representation, commit characteristics are used to build software vulnerability
    detection models.
  prefs: []
  type: TYPE_NORMAL
- en: Table 8. Distribution of input representations in primary studies.
  prefs: []
  type: TYPE_NORMAL
- en: '| Category | Artifact | #Studies | Total | References |'
  prefs: []
  type: TYPE_TB
- en: '| Graph/Tree-based | Source code as a graph | 22 | 32(32) | (Jeon and Kim,
    [2021](#bib.bib65); Tian et al., [2020](#bib.bib135); Liu et al., [2021c](#bib.bib99);
    Kronjee et al., [2018](#bib.bib73); Zeng et al., [2021](#bib.bib151); Li et al.,
    [2019](#bib.bib86); Zou et al., [2019](#bib.bib161); Cao et al., [2022](#bib.bib18);
    Ghaffarian and Shahriari, [2021](#bib.bib50); Wu et al., [2021](#bib.bib141);
    Zhuang et al., [2020](#bib.bib158); Li et al., [2021c](#bib.bib88), [2018](#bib.bib89);
    Duan et al., [2019](#bib.bib39); Zheng et al., [2021](#bib.bib154); Cheng et al.,
    [2022](#bib.bib31); Liu et al., [2021b](#bib.bib98); Ding et al., [2022](#bib.bib37);
    Yang et al., [2022](#bib.bib147); Zou et al., [2022](#bib.bib160); Nguyen et al.,
    [2022b](#bib.bib109), [a](#bib.bib108)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Source code as a tree | 9 |  | (Dam et al., [2017](#bib.bib33); Shippey
    et al., [2019](#bib.bib129); Wang et al., [2016](#bib.bib139); Liu et al., [2020](#bib.bib96);
    Lin et al., [2017](#bib.bib92); Li et al., [2017](#bib.bib83); Lin et al., [2019](#bib.bib91);
    Li et al., [2021b](#bib.bib87); Zhuang et al., [2022](#bib.bib157)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Binary code as graph | 2 |  | (Phan et al., [2017](#bib.bib117); Huang
    et al., [2021](#bib.bib62)) |'
  prefs: []
  type: TYPE_TB
- en: '| Token-based | Source code as a token | 10 | 14(14) | (Dam et al., [2018](#bib.bib34);
    Yamaguchi et al., [2013](#bib.bib145); Hoang et al., [2019](#bib.bib61); Zou et al.,
    [2021](#bib.bib162); Huo et al., [2018](#bib.bib63); Harer et al., [2018](#bib.bib56);
    Scandariato et al., [2014](#bib.bib125); Ziems and Wu, [2021](#bib.bib159); Filus
    et al., [2020](#bib.bib43); Yamaguchi et al., [2011](#bib.bib144)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Binary code as a token | 3 |  | (Nguyen et al., [2020](#bib.bib110); Yan
    et al., [2021](#bib.bib146); Le et al., [2018](#bib.bib77)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Text as a token | 1 |  | (Zhou and Sharma, [2017](#bib.bib156)) |'
  prefs: []
  type: TYPE_TB
- en: '| Hybrid | Token Sequence+Commit Metrics | 4 | 8(8) | (Chen et al., [2020b](#bib.bib25);
    Perl et al., [2015](#bib.bib115); Riom et al., [2021](#bib.bib121); Ni et al.,
    [2022](#bib.bib111)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Token Sequence+Term frequency | 1 |  | (Sabetta and Bezzi, [2018](#bib.bib124))
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Token Sequence+ Graph | 1 |  | (Fu and Tantithamthavorn, [2022](#bib.bib46))
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Graph+Tree+Token Sequence | 1 |  | (Li et al., [2021a](#bib.bib85)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Token+Tree | 1 |  | (Zhang et al., [2022](#bib.bib153)) |'
  prefs: []
  type: TYPE_TB
- en: '| Commits | Commit Metrics | 3 | 3 | (Pascarella et al., [2019](#bib.bib114);
    Yang et al., [2017](#bib.bib148); Ni et al., [2022](#bib.bib111)) |'
  prefs: []
  type: TYPE_TB
- en: '| SUM | - | - | 57(55) | (Pascarella et al., [2019](#bib.bib114); Yang et al.,
    [2017](#bib.bib148); Ni et al., [2022](#bib.bib111)) | <svg id="S4.F6.1.pic1"
    class="ltx_picture" height="154.3" overflow="visible" version="1.1" width="224.26"><g
    transform="translate(0,154.3) matrix(1 0 0 -1 0 0) translate(14,0) translate(0,14.36)
    matrix(0.6 0.0 0.0 0.6 -14 -14.36)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0) translate(45.82,0) translate(0,23.93)"><g
    stroke="#000000" fill="#000000" stroke-width="0.4pt"><g transform="matrix(0.90631
    0.42262 -0.42262 0.90631 -27.63 -17.8)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2011</foreignobject></g><g
    transform="matrix(0.90631 0.42262 -0.42262 0.90631 -5.14 -17.8)" fill="#000000"
    stroke="#000000"><foreignobject width="27.67" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">2013</foreignobject></g><g transform="matrix(0.90631
    0.42262 -0.42262 0.90631 17.34 -17.8)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2014</foreignobject></g><g
    transform="matrix(0.90631 0.42262 -0.42262 0.90631 39.83 -17.8)" fill="#000000"
    stroke="#000000"><foreignobject width="27.67" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">2015</foreignobject></g><g transform="matrix(0.90631
    0.42262 -0.42262 0.90631 62.31 -17.8)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2016</foreignobject></g><g
    transform="matrix(0.90631 0.42262 -0.42262 0.90631 84.8 -17.8)" fill="#000000"
    stroke="#000000"><foreignobject width="27.67" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">2017</foreignobject></g><g transform="matrix(0.90631
    0.42262 -0.42262 0.90631 107.28 -17.8)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2018</foreignobject></g><g
    transform="matrix(0.90631 0.42262 -0.42262 0.90631 129.77 -17.8)" fill="#000000"
    stroke="#000000"><foreignobject width="27.67" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">2019</foreignobject></g><g transform="matrix(0.90631
    0.42262 -0.42262 0.90631 152.25 -17.8)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2020</foreignobject></g><g
    transform="matrix(0.90631 0.42262 -0.42262 0.90631 174.74 -17.8)" fill="#000000"
    stroke="#000000"><foreignobject width="27.67" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">2021</foreignobject></g><g transform="matrix(0.90631
    0.42262 -0.42262 0.90631 197.22 -17.8)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2022</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -34.29 -4.46)" fill="#000000" stroke="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -34.29 51.58)" fill="#000000" stroke="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$5$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -41.21 107.62)" fill="#000000" stroke="#000000"><foreignobject
    width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -41.21 163.66)" fill="#000000" stroke="#000000"><foreignobject
    width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$15$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -41.21 219.7)" fill="#000000" stroke="#000000"><foreignobject
    width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 86.48 1.15)" fill="#660066" stroke="#660066"
    color="#660066"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 108.97 51.58)" fill="#660066" stroke="#660066" color="#660066"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 131.45 90.81)" fill="#660066" stroke="#660066"
    color="#660066"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 153.94 85.2)" fill="#660066" stroke="#660066" color="#660066"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 176.42 57.19)" fill="#660066" stroke="#660066"
    color="#660066"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 198.9 186.08)" fill="#660066" stroke="#660066" color="#660066"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 221.39 141.24)" fill="#660066" stroke="#660066"
    color="#660066"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 -3.46 1.15)" fill="#000000" stroke="#000000" color="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 19.03 1.15)" fill="#000000" stroke="#000000"
    color="#000000"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 41.51 1.15)" fill="#000000" stroke="#000000" color="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 108.97 29.17)" fill="#000000" stroke="#000000"
    color="#000000"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 131.45 62.79)" fill="#000000" stroke="#000000" color="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$4$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 153.94 57.19)" fill="#000000" stroke="#000000"
    color="#000000"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$3$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 176.42 40.37)" fill="#000000" stroke="#000000" color="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 198.9 152.45)" fill="#000000" stroke="#000000"
    color="#000000"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$4$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 221.39 118.83)" fill="#000000" stroke="#000000" color="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 64 1.15)" fill="#734D26" stroke="#734D26" color="#734D26"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 131.45 34.77)" fill="#734D26" stroke="#734D26"
    color="#734D26"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 176.42 23.56)" fill="#734D26" stroke="#734D26" color="#734D26"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 198.9 118.83)" fill="#734D26" stroke="#734D26"
    color="#734D26"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 221.39 96.41)" fill="#734D26" stroke="#734D26" color="#734D26"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 108.97 12.35)" fill="#FF0000" stroke="#FF0000"
    color="#FF0000"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 131.45 12.35)" fill="#FF0000" stroke="#FF0000" color="#FF0000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$3$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 153.94 23.56)" fill="#FF0000" stroke="#FF0000"
    color="#FF0000"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$3$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 176.42 6.75)" fill="#FF0000" stroke="#FF0000" color="#FF0000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 195.45 51.58)" fill="#FF0000" stroke="#FF0000"
    color="#FF0000"><foreignobject width="13.84" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$10$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 221.39 45.98)" fill="#FF0000" stroke="#FF0000" color="#FF0000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$7$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 108.97 1.15)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 153.94 1.15)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 221.39 1.15)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g fill="#FFFFFF" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 254.46 78.1)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 77.325)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 8.58)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    22.9 0) translate(16.05,0) matrix(1.0 0.0 0.0 1.0 -13.28 -3.69)" fill="#000000"
    stroke="#000000"><foreignobject width="26.56" height="9.46" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Tree</foreignobject></g></g><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 25.72)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 17.93 0) translate(21.02,0) matrix(1.0 0.0 0.0 1.0
    -18.26 -3.77)" fill="#000000" stroke="#000000"><foreignobject width="36.9" height="9.61"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Token</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 42.94)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 15.02 0) translate(23.93,0)
    matrix(1.0 0.0 0.0 1.0 -21.16 -3.77)" fill="#000000" stroke="#000000"><foreignobject
    width="42.32" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Hybrid</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 60.16)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 16.9 0) translate(22.05,0)
    matrix(1.0 0.0 0.0 1.0 -19.29 -3.77)" fill="#000000" stroke="#000000"><foreignobject
    width="38.57" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Graph</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 77.35)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 8.86 0) translate(30.1,0)
    matrix(1.0 0.0 0.0 1.0 -27.33 -3.69)" fill="#000000" stroke="#000000"><foreignobject
    width="54.66" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Commits</foreignobject></g></g></g></g></g></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6. Distribution of data type representations in software vulnerability
    detection studies over time.
  prefs: []
  type: TYPE_NORMAL
- en: Figure [6](#S4.F6 "Figure 6 ‣ 4.2.3\. RQ2.3\. How input data are represented?
    ‣ 4.2\. RQ2\. What are the characteristics of software vulnerability detection
    datasets? ‣ 4\. Results ‣ A Survey on Automated Software Vulnerability Detection
    Using Machine Learning and Deep Learning") shows the distribution of data type
    representation in software vulnerability detection studies over time. As shown
    in the figure, Graph-based representation shows a substantial presence compared
    to other input representation techniques. There are a couple of reasons for this
    trend. First, graphs provide a natural and intuitive way to represent the structural
    relationships within the source code. By modeling the code as a graph, the relationships
    between functions, classes, methods, and variables can be captured effectively.
    This allows vulnerability detection algorithms to analyze the code at a higher
    level of abstraction and capture complex dependencies and interactions between
    code elements. Second, graph-based representations enable a better understanding
    of the context in which vulnerabilities may exist. By considering the surrounding
    code structure and dependencies, graph-based approaches can capture the flow of
    information and identify potential paths that can lead to vulnerabilities. This
    contextual understanding helps in identifying code patterns, control flow paths,
    and data dependencies that may introduce security vulnerabilities. Token-based
    representation has also gained popularity, with a peak occurrence in 2021\. This
    is because it provides a fine-grained representation of the code. It simplifies
    the code analysis process by reducing the complexity of the code to a sequence
    of tokens, making it easier to apply traditional natural language processing techniques
    or ML models. It is also easily applicable to a wide range of programming languages.
    While the tokens themselves may differ across languages, the concept of breaking
    the code into discrete units remains the same. This versatility allows vulnerability
    detection techniques based on token representation to be applied to different
    programming languages and codebases, which further increases the external validity
    of vulnerability detection models. However, there is a slight decline in 2022,
    indicating potential shifts or diversification in the selection of input representations.
    Hybrid representation is gained attention since 2021, which suggests that combining
    different representations is favored by researchers in software vulnerability
    detection, potentially due to the complementary benefits provided by multiple
    representations.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.4\. RQ2.4\. How input data are embedded for feature space?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In the previous section, we discussed various representation techniques, and
    in this section, we further look at embedding methods that can transform these
    representations into inputs that can be understood by ML/DL models. The representation
    techniques are in a human-readable format, they cannot be directly interpreted
    by machines. Therefore, researchers use different embedding techniques to convert
    these representations into a numeric format. We discuss the embedding techniques
    in the following paragraphs based on the distribution shown in Figure [7](#S4.F7
    "Figure 7 ‣ 4.2.4\. RQ2.4\. How input data are embedded for feature space? ‣ 4.2\.
    RQ2\. What are the characteristics of software vulnerability detection datasets?
    ‣ 4\. Results ‣ A Survey on Automated Software Vulnerability Detection Using Machine
    Learning and Deep Learning"). The figure illustrates the distribution of feature
    embedding techniques used in primary studies. The chart shows the following categories
    and their corresponding percentages: Word2vec (25.4%), Graph embedding (25.4%),
    Token vector embedding (11.9%), Others (16.4%), Hybrid (7.5%), One hot embedding
    (6.0%), Code token embedding (4.5%), and N-gram features (3.0%).'
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S4.F7.pic1" class="ltx_picture ltx_centering" height="1" overflow="visible"
    version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><foreignobject width="0" height="0" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">\pie</foreignobject></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7. Different feature embedding techniques used in primary studies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Word2vec (Chen et al., [2020b](#bib.bib25); Sabetta and Bezzi, [2018](#bib.bib124);
    Zhou and Sharma, [2017](#bib.bib156); Jeon and Kim, [2021](#bib.bib65); Yamaguchi
    et al., [2013](#bib.bib145); Du et al., [2020](#bib.bib38); Lin et al., [2018](#bib.bib93);
    Liu et al., [2019a](#bib.bib95); Pradel and Sen, [2018](#bib.bib119); Zhou et al.,
    [2019](#bib.bib155); Yan et al., [2021](#bib.bib146); Li et al., [2019](#bib.bib86);
    Zou et al., [2021](#bib.bib162); Huo et al., [2018](#bib.bib63); Zou et al., [2019](#bib.bib161);
    Scandariato et al., [2014](#bib.bib125); Riom et al., [2021](#bib.bib121); Lin
    et al., [2019](#bib.bib91); Perl et al., [2015](#bib.bib115); Li et al., [2021a](#bib.bib85)):
    is one of the most widely-used embedding techniques for source code embedding
    in the examined papers, accounting for 25.4% of primary studies. This can be because
    it has been shown to be effective in capturing the semantics and relationships
    between different code components. Word2vec can be trained on code corpus to learn
    embeddings for different code components, such as variables, functions, and operators.
    By considering the context in which these components appear, Word2vec can capture
    the semantic relationships between them. Furthermore, Word2vec is a computationally
    efficient and scalable technique, which can be trained on large code corpora.
    This is important for source code embedding, as the code corpus can be much larger
    than the text corpus typically used in natural language processing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Graph embedding (Liu et al., [2021c](#bib.bib99); Wang et al., [2020](#bib.bib137);
    Phan et al., [2017](#bib.bib117); Zeng et al., [2021](#bib.bib151); Dinella et al.,
    [2020](#bib.bib36); Cao et al., [2022](#bib.bib18); Ghaffarian and Shahriari,
    [2021](#bib.bib50); Wu et al., [2021](#bib.bib141); Zhuang et al., [2020](#bib.bib158);
    Duan et al., [2019](#bib.bib39); Zheng et al., [2021](#bib.bib154)): is another
    widely-used embedding technique among the primary studies, accounting for 25.4%
    of primary studies, which is mostly used by graph neural networks. This can be
    because it can capture the structural relationships between different code components,
    such as functions, classes, and methods. In contrast to token-based representations
    or sequence-based representations, graph embedding can explicitly represent the
    connections and dependencies between different code components. In a graph-based
    representation, code components are represented as nodes, and the relationships
    between them are represented as edges. This allows for a more fine-grained representation
    of the code structure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Token vector embedding  (Dam et al., [2018](#bib.bib34), [2017](#bib.bib33);
    Liu et al., [2020](#bib.bib96); Wang et al., [2016](#bib.bib139); Hoang et al.,
    [2019](#bib.bib61); Mao et al., [2020](#bib.bib103); Yamaguchi et al., [2012](#bib.bib143);
    Hin et al., [2022](#bib.bib59); Fu and Tantithamthavorn, [2022](#bib.bib46); Chen
    et al., [2021](#bib.bib26); Lin et al., [2017](#bib.bib92); Yamaguchi et al.,
    [2011](#bib.bib144)): is also a popular technique used by primary studies accounting
    for 11.9% of examined papers. In this technique, input is converted into a sequence
    of tokens and each token is transformed into a numeric value. Then, these values
    are fed into ML/DL models for further computations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One hot embedding (Nguyen et al., [2020](#bib.bib110); Hoang et al., [2019](#bib.bib61);
    Harer et al., [2018](#bib.bib56); Le et al., [2018](#bib.bib77)): is a typical
    way for encoding categorical data, in which each category is represented by a
    binary vector of zeros and ones. This method can also be used to encode source
    code for vulnerability detection, which accounts for 6% of studies.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Code token embedding (Dam et al., [2018](#bib.bib34), [2017](#bib.bib33); Liu
    et al., [2020](#bib.bib96)): is used to represent source code tokens as dense
    vectors in a continuous vector space. Code token embedding captures the semantic
    and syntactic links between tokens by transferring them to a lower-dimensional
    vector space, as opposed to one hot encoding, which represents each token as a
    sparse binary vector.'
  prefs: []
  type: TYPE_NORMAL
- en: 'N-gram features (Shippey et al., [2019](#bib.bib129); Le et al., [2021b](#bib.bib80)):
    is a method of expressing code snippets as fixed-length dense vectors, each vector
    representing an n-gram of tokens. N-grams are sequences of `n` tokens, such as
    words or letters, that capture local context and interdependence between neighboring
    tokens. We observed that 3% of primary studies use N-gram features for embedding.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hybrid  (Jeon and Kim, [2021](#bib.bib65); Cheng et al., [2021](#bib.bib29);
    Zhou et al., [2019](#bib.bib155); Li et al., [2019](#bib.bib86), [2021a](#bib.bib85)):
    We find that 7.5% of primary studies use multiple embedding techniques to convert
    inputs to ML/DL models. Different embedding techniques capture different aspects
    of the data. By combining multiple techniques, researchers can leverage the complementary
    information provided by each technique. For example, some embedding techniques
    may focus on syntax, while others may capture semantic or contextual information.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Others (Sabetta and Bezzi, [2018](#bib.bib124); Kronjee et al., [2018](#bib.bib73);
    Pascarella et al., [2019](#bib.bib114); Huang et al., [2021](#bib.bib62); Ziems
    and Wu, [2021](#bib.bib159); Filus et al., [2020](#bib.bib43); Yang et al., [2017](#bib.bib148);
    Zhuang et al., [2022](#bib.bib157); Cheng et al., [2022](#bib.bib31); Zhang et al.,
    [2022](#bib.bib153); Ni et al., [2022](#bib.bib111)): The remaining 16.4% that
    emerge seldom and do not belong to any group are classified as Others. For example,
    Zhang et al. (Zhang et al., [2022](#bib.bib153)) customizes the graphCodeBERT (Guo
    et al., [2020](#bib.bib55)) to propose a graph-guided masked attention mechanism
    for vulnerability detection in which it captures variable dependency relationships
    and integrates the graph structure into the Transformer model.'
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S4.SS2.SSS4.1.pic1" class="ltx_picture" height="214.29" overflow="visible"
    version="1.1" width="593.51"><g transform="translate(0,214.29) matrix(1 0 0 -1
    0 0) translate(20.38,0) translate(0,173.2)"><g stroke="#000000"><g stroke-width="1.0pt"
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 0 0)"><foreignobject
    width="552.76" height="162.51" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">(1)
    65.7% of primary studies use benchmark data for software vulnerability detection.
    This can be because benchmark datasets are readily accessible to all researchers
    and can facilitate the reproducibility of studies. (2) The most common data type
    among the examined vulnerability detection studies is Code-based data type, accounting
    for 47 studies. In this category, Source code is the most prominent sub-type accounting
    for 42 studies. (3) Graph-based and Token-based input representations are the
    most popular input representation techniques used by primary studies accounting
    for 38.8% and 29.9% of primary studies respectively. (4) Graph embedding and Word2vec
    are the two most widely used embedding techniques used in primary studies accounting
    for 25.4% of studies respectively. <g stroke-width="0.5pt" fill="#FF9999"><path
    d="M 97.05 40.75 L 5.19 40.75 C 2.13 40.75 -0.35 38.27 -0.35 35.21 L -0.35 24.91
    C -0.35 21.86 2.13 19.38 5.19 19.38 L 97.05 19.38 C 100.11 19.38 102.59 21.86
    102.59 24.91 L 102.59 35.21 C 102.59 38.27 100.11 40.75 97.05 40.75 Z M -0.35
    19.38"></path></g><g stroke-width="0.5pt" fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 4.27 26.68)"><foreignobject width="94.09" height="12.15" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Answer to RQ2</foreignobject></g>
  prefs: []
  type: TYPE_NORMAL
- en: 4.3\. RQ3\. What are the ML/DL models used for software vulnerability detection?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we provide detailed information about the various ML/DL models
    utilized for software vulnerability detection. Initially, we present an analysis
    of the usage distribution of ML/DL models based on primary studies. Subsequently,
    we delve into the distribution of the usage of DL models used in primary studies
    over time. However, we have not extensively analyzed the distribution of ML models
    since their prevalence is relatively small compared to DL models. Nonetheless,
    we provide a comprehensive list of classic ML models that have been commonly employed
    in primary studies.
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S4.F8.pic1" class="ltx_picture ltx_centering" height="1" overflow="visible"
    version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><foreignobject width="0" height="0" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">\pie</foreignobject></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8. Distribution of models used in primary studies. DM stands for Distance
    Measure and LM stands for Language Model.
  prefs: []
  type: TYPE_NORMAL
- en: From Figure [8](#S4.F8 "Figure 8 ‣ 4.3\. RQ3\. What are the ML/DL models used
    for software vulnerability detection? ‣ 4\. Results ‣ A Survey on Automated Software
    Vulnerability Detection Using Machine Learning and Deep Learning"), it is observable
    that 79.1% of studies are using DL models for software vulnerability detection
    (Russell et al., [2018](#bib.bib123); Dam et al., [2018](#bib.bib34), [2017](#bib.bib33);
    Wang et al., [2016](#bib.bib139); Jeon and Kim, [2021](#bib.bib65); An et al.,
    [2020](#bib.bib5); Tian et al., [2020](#bib.bib135); Liu et al., [2020](#bib.bib96),
    [2021c](#bib.bib99); Wang et al., [2020](#bib.bib137); Phan et al., [2017](#bib.bib117);
    Lin et al., [2018](#bib.bib93); Liu et al., [2019a](#bib.bib95); Pradel and Sen,
    [2018](#bib.bib119); Le et al., [2021b](#bib.bib80); Hoang et al., [2019](#bib.bib61);
    Cheng et al., [2021](#bib.bib29); Zhou et al., [2019](#bib.bib155)) while merely
    16.4% of studies use classic ML models (Nguyen et al., [2020](#bib.bib110); Kronjee
    et al., [2018](#bib.bib73); Pascarella et al., [2019](#bib.bib114); Yamaguchi
    et al., [2012](#bib.bib143); Scandariato et al., [2014](#bib.bib125); Riom et al.,
    [2021](#bib.bib121); Perl et al., [2015](#bib.bib115); Yamaguchi et al., [2011](#bib.bib144)).
    Also, a limited number of studies use Language models denoted as LM (Shippey et al.,
    [2019](#bib.bib129); Pang et al., [2015](#bib.bib113)) and Distance Measures denoted
    as DM (Yamaguchi et al., [2013](#bib.bib145); Huang et al., [2021](#bib.bib62)).
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S4.F9.1.pic1" class="ltx_picture" height="154.3" overflow="visible"
    version="1.1" width="239.13"><g transform="translate(0,154.3) matrix(1 0 0 -1
    0 0) translate(14,0) translate(0,14.36) matrix(0.6 0.0 0.0 0.6 -14 -14.36)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(45.82,0) translate(0,23.93)"><g stroke="#000000" fill="#000000"
    stroke-width="0.4pt"><g transform="matrix(0.90631 0.42262 -0.42262 0.90631 -27.63
    -17.8)" fill="#000000" stroke="#000000"><foreignobject width="27.67" height="8.92"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2016</foreignobject></g><g
    transform="matrix(0.90631 0.42262 -0.42262 0.90631 9.85 -17.8)" fill="#000000"
    stroke="#000000"><foreignobject width="27.67" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">2017</foreignobject></g><g transform="matrix(0.90631
    0.42262 -0.42262 0.90631 47.32 -17.8)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2018</foreignobject></g><g
    transform="matrix(0.90631 0.42262 -0.42262 0.90631 84.8 -17.8)" fill="#000000"
    stroke="#000000"><foreignobject width="27.67" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">2019</foreignobject></g><g transform="matrix(0.90631
    0.42262 -0.42262 0.90631 122.27 -17.8)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2020</foreignobject></g><g
    transform="matrix(0.90631 0.42262 -0.42262 0.90631 159.74 -17.8)" fill="#000000"
    stroke="#000000"><foreignobject width="27.67" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">2021</foreignobject></g><g transform="matrix(0.90631
    0.42262 -0.42262 0.90631 197.22 -17.8)" fill="#000000" stroke="#000000"><foreignobject
    width="27.67" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2022</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -34.29 -4.46)" fill="#000000" stroke="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -34.29 40.37)" fill="#000000" stroke="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$5$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -41.21 85.2)" fill="#000000" stroke="#000000"><foreignobject
    width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -41.21 130.04)" fill="#000000" stroke="#000000"><foreignobject
    width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$15$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -41.21 174.87)" fill="#000000" stroke="#000000"><foreignobject
    width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -41.21 219.7)" fill="#000000" stroke="#000000"><foreignobject
    width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 183.91 197.28)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 221.39 107.62)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$3$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 34.02 26.92)" fill="#00FF00" stroke="#00FF00"
    color="#00FF00"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 71.49 35.89)" fill="#00FF00" stroke="#00FF00" color="#00FF00"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$3$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 108.96 49.34)" fill="#00FF00" stroke="#00FF00"
    color="#00FF00"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 146.44 49.34)" fill="#00FF00" stroke="#00FF00" color="#00FF00"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$6$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 183.91 156.93)" fill="#00FF00" stroke="#00FF00"
    color="#00FF00"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$8$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 221.39 80.72)" fill="#00FF00" stroke="#00FF00" color="#00FF00"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$3$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 71.49 17.96)" fill="#660066" stroke="#660066"
    color="#660066"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 108.96 35.89)" fill="#660066" stroke="#660066" color="#660066"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 146.44 17.96)" fill="#660066" stroke="#660066"
    color="#660066"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 183.91 112.1)" fill="#660066" stroke="#660066" color="#660066"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -3.46 0.02)" fill="#000000" stroke="#000000"
    color="#000000"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 34.02 17.96)" fill="#000000" stroke="#000000" color="#000000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 71.49 8.99)" fill="#000000" stroke="#000000"
    color="#000000"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 34.02 8.99)" fill="#734D26" stroke="#734D26" color="#734D26"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 108.96 26.92)" fill="#734D26" stroke="#734D26"
    color="#734D26"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 146.44 4.51)" fill="#734D26" stroke="#734D26" color="#734D26"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 180.45 53.82)" fill="#734D26" stroke="#734D26"
    color="#734D26"><foreignobject width="13.84" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$11$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 221.39 44.86)" fill="#734D26" stroke="#734D26" color="#734D26"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$5$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 34.02 0.02)" fill="#FF0000" stroke="#FF0000"
    color="#FF0000"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 71.49 0.02)" fill="#FF0000" stroke="#FF0000" color="#FF0000"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 108.96 17.96)" fill="#FF0000" stroke="#FF0000"
    color="#FF0000"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 108.96 4.51)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$2$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 183.91 0.02)" fill="#0000FF" stroke="#0000FF"
    color="#0000FF"><foreignobject width="6.92" height="8.92" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$1$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 221.39 8.99)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignobject
    width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$3$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 254.46 60.99)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 111.555)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.61)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 8.86 0) translate(42.49,0) matrix(1.0 0.0 0.0 1.0 -39.72
    -3.77)" fill="#000000" stroke="#000000"><foreignobject width="79.45" height="9.61"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Transformers</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 25.8)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 33.11 0) translate(18.24,0)
    matrix(1.0 0.0 0.0 1.0 -15.47 -3.69)" fill="#000000" stroke="#000000"><foreignobject
    width="30.94" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">RNN</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 42.94)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 27.42 0) translate(23.93,0)
    matrix(1.0 0.0 0.0 1.0 -21.16 -3.77)" fill="#000000" stroke="#000000"><foreignobject
    width="42.32" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Hybrid</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 60.16)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 25.07 0) translate(26.28,0)
    matrix(1.0 0.0 0.0 1.0 -23.51 -3.77)" fill="#000000" stroke="#000000"><foreignobject
    width="47.03" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">General</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 77.35)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 32.77 0) translate(18.57,0)
    matrix(1.0 0.0 0.0 1.0 -15.81 -3.69)" fill="#000000" stroke="#000000"><foreignobject
    width="31.61" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">GNN</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 94.46)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 33.2 0) translate(18.14,0)
    matrix(1.0 0.0 0.0 1.0 -15.37 -3.69)" fill="#000000" stroke="#000000"><foreignobject
    width="30.75" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">CNN</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 111.57)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 19.56 0) translate(31.79,0)
    matrix(1.0 0.0 0.0 1.0 -29.02 -3.69)" fill="#000000" stroke="#000000"><foreignobject
    width="58.42" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Attention</foreignobject></g></g></g></g></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9. Trend of DL models over time.
  prefs: []
  type: TYPE_NORMAL
- en: The graph in Figure [9](#S4.F9 "Figure 9 ‣ 4.3\. RQ3\. What are the ML/DL models
    used for software vulnerability detection? ‣ 4\. Results ‣ A Survey on Automated
    Software Vulnerability Detection Using Machine Learning and Deep Learning") illustrates
    the usage trend of DL models in detecting software vulnerabilities from 2016 to
    2022\. According to the trend, DL models were first introduced in 2016 for vulnerability
    detection, since then the use of RNNs for vulnerability detection showed an upward
    trend. The graph also demonstrates a rising trend in using GNNs for vulnerability
    detection from 2020 to 2022\. This can be because GNNs are more powerful than
    RNNs in detecting vulnerabilities, as they can capture more meaningful and semantic
    representations of input source code. Since vulnerability types often have complex
    structures, GNNs are an excellent fit for detecting hidden structural information.
  prefs: []
  type: TYPE_NORMAL
- en: Table [9](#S4.T9 "Table 9 ‣ 4.3\. RQ3\. What are the ML/DL models used for software
    vulnerability detection? ‣ 4\. Results ‣ A Survey on Automated Software Vulnerability
    Detection Using Machine Learning and Deep Learning") shows the distribution of
    DL models used in primary studies. As shown in the table, LSTM is the most frequently
    used recurrent model, appearing in 8 studies. BiLSTM and BGRU are also popular
    models with 8 and 6 studies respectively. It is also observable that GGNN is the
    most prevalent graph-based model, appearing in 4 studies. GCN, GAT, and DR-GCN
    are also commonly used accounting for 4, 3, and 2 studies respectively. The presence
    of these models highlights the importance of capturing graph structures and relationships
    between code elements in vulnerability detection. Attention models were also used
    in 7 primary studies. Attention mechanisms allow models to pay more attention
    to specific parts of the code or input that are more likely to contain vulnerability-related
    patterns. This ability to localize relevant information helps identify and understand
    the factors contributing to vulnerabilities more effectively. CNNs are used in
    6 studies. While not as prevalent as recurrent or graph models, CNNs are still
    considered effective for capturing local patterns and features in vulnerability
    detection tasks. General models like DBN, Auto Encoders, Memory Neural Networks,
    GAN, and Para2Vec are also used to a lesser extent, indicating the exploration
    of diverse deep learning techniques in vulnerability detection. Transformers are
    the least frequent family of DL models used in primary studies. This is because
    they have been recently introduced for software vulnerability detection. Transformers
    are effective in this domain since they generate contextualized representations
    for each token in the input sequence. By considering the surrounding tokens and
    their interactions, transformers capture rich contextual information, which is
    crucial for understanding vulnerabilities that depend on the overall context of
    the code or vulnerability-related text.
  prefs: []
  type: TYPE_NORMAL
- en: Table [10](#S4.T10 "Table 10 ‣ 4.3\. RQ3\. What are the ML/DL models used for
    software vulnerability detection? ‣ 4\. Results ‣ A Survey on Automated Software
    Vulnerability Detection Using Machine Learning and Deep Learning") shows the distribution
    of ML models used in primary studies. As shown in the figure, Random Forest is
    the most frequently used ML model, appearing in 7 studies. SVM, Naive Bayes, and
    Logistic Regression are popular choices, with 6, 5, and 4 occurrences, respectively.
    N-Gram models are used in 1 study, indicating their application in capturing sequential
    patterns and language-based features in vulnerability detection. N-Gram models
    are commonly used for text analysis and have been adapted for code analysis tasks.
    Distance measures are utilized in 2 studies for vulnerability detection. These
    metrics help quantify the similarity or dissimilarity between code elements or
    features, enabling the identification of potentially vulnerable code segments
    based on their proximity to known vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Table 9. Distribution of DL models in primary studies.
  prefs: []
  type: TYPE_NORMAL
- en: '| Category | Model Name | # Studies | Total | References |'
  prefs: []
  type: TYPE_TB
- en: '| Recurrent Models | LSTM | 8 | 31(21) | (Dam et al., [2018](#bib.bib34), [2017](#bib.bib33);
    Wang et al., [2016](#bib.bib139); Tian et al., [2020](#bib.bib135); Liu et al.,
    [2020](#bib.bib96), [2019a](#bib.bib95); Ziems and Wu, [2021](#bib.bib159); Zhuang
    et al., [2022](#bib.bib157)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | BiLSTM | 8 |  | (Jeon and Kim, [2021](#bib.bib65); Tian et al., [2020](#bib.bib135);
    Zou et al., [2021](#bib.bib162), [2019](#bib.bib161); Lin et al., [2017](#bib.bib92),
    [2019](#bib.bib91); Li et al., [2021b](#bib.bib87), [2018](#bib.bib89)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | BGRU | 6 |  | (Jeon and Kim, [2021](#bib.bib65); Tian et al., [2020](#bib.bib135);
    Yan et al., [2021](#bib.bib146); Zou et al., [2021](#bib.bib162); Li et al., [2021c](#bib.bib88),
    [b](#bib.bib87)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | GRU | 4 |  | (Jeon and Kim, [2021](#bib.bib65); Tian et al., [2020](#bib.bib135);
    Li et al., [2019](#bib.bib86); Hin et al., [2022](#bib.bib59)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | RNN | 3 |  | (Tian et al., [2020](#bib.bib135); Le et al., [2018](#bib.bib77);
    Filus et al., [2020](#bib.bib43)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | BRNN | 2 |  | (Tian et al., [2020](#bib.bib135); Le et al., [2018](#bib.bib77))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Graph Models | GGNN | 4 | 18(15) | (Wang et al., [2020](#bib.bib137); Dinella
    et al., [2020](#bib.bib36); Ding et al., [2022](#bib.bib37); Zou et al., [2022](#bib.bib160))
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | GCN | 4 |  | (Cheng et al., [2021](#bib.bib29); Zeng et al., [2021](#bib.bib151);
    Ghaffarian and Shahriari, [2021](#bib.bib50); Li et al., [2021a](#bib.bib85))
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | GAT | 3 |  | (Cheng et al., [2021](#bib.bib29); Fu and Tantithamthavorn,
    [2022](#bib.bib46); Ghaffarian and Shahriari, [2021](#bib.bib50)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | DR-GCN | 2 |  | (Liu et al., [2021c](#bib.bib99); Zhuang et al., [2020](#bib.bib158))
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | RGCN | 1 |  | (Zheng et al., [2021](#bib.bib154)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | FS-GNN | 1 |  | (Cao et al., [2022](#bib.bib18)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | K-GNN | 1 |  | (Cheng et al., [2021](#bib.bib29)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | DGCNN | 1 |  | (Phan et al., [2017](#bib.bib117)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | GGRN | 1 |  | (Zhou et al., [2019](#bib.bib155)) |'
  prefs: []
  type: TYPE_TB
- en: '| Attention Models | - | 7 | 7 | (Le et al., [2021b](#bib.bib80); Li et al.,
    [2019](#bib.bib86); Zou et al., [2019](#bib.bib161); Duan et al., [2019](#bib.bib39);
    Cheng et al., [2022](#bib.bib31); Liu et al., [2021b](#bib.bib98); Zhang et al.,
    [2022](#bib.bib153)) |'
  prefs: []
  type: TYPE_TB
- en: '| Convolutional Models | CNN | 6 | 6 | (Hoang et al., [2019](#bib.bib61); Yan
    et al., [2021](#bib.bib146); Zou et al., [2021](#bib.bib162); Huo et al., [2018](#bib.bib63);
    Li et al., [2017](#bib.bib83); Filus et al., [2020](#bib.bib43)) |'
  prefs: []
  type: TYPE_TB
- en: '| General Models | DBN | 1 | 5(4) | (Wang et al., [2016](#bib.bib139)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Auto Encoders | 1 |  | (Le et al., [2018](#bib.bib77)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Memory Neural Network | 1 |  | (Hoang et al., [2019](#bib.bib61)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | GAN | 1 |  | (Harer et al., [2018](#bib.bib56)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Para2Vec | 1 |  | (Le et al., [2018](#bib.bib77)) |'
  prefs: []
  type: TYPE_TB
- en: '| Transformers | Seq2Seq Transformer | 1 | 4(4) | (Chen et al., [2021](#bib.bib26))
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Graph CodeBERT | 1 |  | (Wu et al., [2021](#bib.bib141)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | CodeBERT | 1 |  | (Ni et al., [2022](#bib.bib111)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | HGT | 1 |  | (Yang et al., [2022](#bib.bib147)) |'
  prefs: []
  type: TYPE_TB
- en: '| SUM | - | - | 71(49) | - |'
  prefs: []
  type: TYPE_TB
- en: Table 10. Distribution of ML and other models in primary studies.
  prefs: []
  type: TYPE_NORMAL
- en: '| Category | Model Name | Studies | Total | References |'
  prefs: []
  type: TYPE_TB
- en: '| Classic ML Models | Random Forest | 7 | 35(11) | (Chen et al., [2020b](#bib.bib25);
    Sabetta and Bezzi, [2018](#bib.bib124); Zhou and Sharma, [2017](#bib.bib156);
    Kronjee et al., [2018](#bib.bib73); Pascarella et al., [2019](#bib.bib114); Scandariato
    et al., [2014](#bib.bib125); Yang et al., [2017](#bib.bib148)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | SVM | 6 |  | (Chen et al., [2020b](#bib.bib25); Sabetta and Bezzi, [2018](#bib.bib124);
    Zhou and Sharma, [2017](#bib.bib156); Scandariato et al., [2014](#bib.bib125);
    Perl et al., [2015](#bib.bib115); Riom et al., [2021](#bib.bib121)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Naive Bayes | 5 |  | (Chen et al., [2020b](#bib.bib25); Zhou and Sharma,
    [2017](#bib.bib156); Kronjee et al., [2018](#bib.bib73); Pascarella et al., [2019](#bib.bib114);
    Scandariato et al., [2014](#bib.bib125)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Logistic Regression | 4 |  | (Sabetta and Bezzi, [2018](#bib.bib124);
    Zhou and Sharma, [2017](#bib.bib156); Kronjee et al., [2018](#bib.bib73); Pascarella
    et al., [2019](#bib.bib114)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | K-NN | 3 |  | (Chen et al., [2020b](#bib.bib25); Zhou and Sharma, [2017](#bib.bib156);
    Scandariato et al., [2014](#bib.bib125)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Gradient Boosting | 2 |  | (Chen et al., [2020b](#bib.bib25); Zhou and
    Sharma, [2017](#bib.bib156)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Decision Tree | 2 |  | (Kronjee et al., [2018](#bib.bib73); Scandariato
    et al., [2014](#bib.bib125)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | AdaBoost | 2 |  | (Chen et al., [2020b](#bib.bib25); Zhou and Sharma,
    [2017](#bib.bib156)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | PCA | 1 |  | (Yamaguchi et al., [2011](#bib.bib144)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Kernel Machine | 1 |  | (Nguyen et al., [2020](#bib.bib110)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | ADTree | 1 |  | (Pascarella et al., [2019](#bib.bib114)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | MLP | 1 |  | (Pascarella et al., [2019](#bib.bib114)) |'
  prefs: []
  type: TYPE_TB
- en: '| Language Models | N-Gram | 1 | 1 | (Shippey et al., [2019](#bib.bib129))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Distance Metrics | Distance Measure | 2 | 2 | (Yamaguchi et al., [2013](#bib.bib145);
    Huang et al., [2021](#bib.bib62)) |'
  prefs: []
  type: TYPE_TB
- en: '| SUM | - | - | 38(14) | - |'
  prefs: []
  type: TYPE_TB
- en: <svg id="S4.SS3.1.pic1" class="ltx_picture" height="213.52" overflow="visible"
    version="1.1" width="593.51"><g transform="translate(0,213.52) matrix(1 0 0 -1
    0 0) translate(20.38,0) translate(0,172.43)"><g stroke="#000000"><g stroke-width="1.0pt"
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 0 0)"><foreignobject
    width="552.76" height="161.74" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">(1)
    79.1% of primary studies use DL models for vulnerability detection while merely
    16.4% of the primary studies use classic ML models. (2) RNNs and GNNs are by far
    the most popular DL-based models in software vulnerability detection accounting
    for 28% and 22% of primary studies. (3) LSTM is the most popular architecture
    in RNN-based models. (4) Graph-based models are the second most popular models
    used in software security vulnerability detection accounting for 15 studies. In
    this family, GGNN is the most popular architecture. (5) Besides DL models, ML
    models are popular for software vulnerability detection. Random Forest is the
    most popular model accounting for 7 studies. <g stroke-width="0.5pt" fill="#FF9999"><path
    d="M 97.05 40.75 L 5.19 40.75 C 2.13 40.75 -0.35 38.27 -0.35 35.21 L -0.35 24.91
    C -0.35 21.86 2.13 19.38 5.19 19.38 L 97.05 19.38 C 100.11 19.38 102.59 21.86
    102.59 24.91 L 102.59 35.21 C 102.59 38.27 100.11 40.75 97.05 40.75 Z M -0.35
    19.38"></path></g><g stroke-width="0.5pt" fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 4.27 26.68)"><foreignobject width="94.09" height="12.15" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Answer to RQ3</foreignobject></g>
  prefs: []
  type: TYPE_NORMAL
- en: 4.4\. RQ4\. What is the most frequent type of vulnerability covered in primary
    studies?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Software vulnerability detection datasets support different vulnerability types.
    For example, NVD and SARD benchmark together support 96 types of vulnerabilities.
    This research question intends to summarize what is the most popular vulnerability
    types covered by primary studies and what is their frequency. Table [11](#S4.T11
    "Table 11 ‣ 4.4\. RQ4\. What is the most frequent type of vulnerability covered
    in primary studies? ‣ 4\. Results ‣ A Survey on Automated Software Vulnerability
    Detection Using Machine Learning and Deep Learning") shows the statistics regarding
    the vulnerability types. The column CWE-Type indicates the type of CWE⁴⁴4[https://cwe.mitre.org/](https://cwe.mitre.org/).
    There also exists a numerical score for some types of CWEs, which indicate the
    weakness’ severity. A larger value indicates a higher level of dangerousness and
    severity⁵⁵5[https://cwe.mitre.org/top25/archive/2021/2021_cwe_top25.html](https://cwe.mitre.org/top25/archive/2021/2021_cwe_top25.html).
    Please note that some frequent types do not have a CWE score, so we denote them
    as “-”. There are many categories on the CWE website for vulnerability categorization
    including categorization by software development, categorization by Hardware design,
    and categorization by research concepts. The categorization shown in Table [11](#S4.T11
    "Table 11 ‣ 4.4\. RQ4\. What is the most frequent type of vulnerability covered
    in primary studies? ‣ 4\. Results ‣ A Survey on Automated Software Vulnerability
    Detection Using Machine Learning and Deep Learning") is based on categorization
    by research concepts as this categorization is a perfect match for vulnerability
    types reported in primary studies.
  prefs: []
  type: TYPE_NORMAL
- en: Table [11](#S4.T11 "Table 11 ‣ 4.4\. RQ4\. What is the most frequent type of
    vulnerability covered in primary studies? ‣ 4\. Results ‣ A Survey on Automated
    Software Vulnerability Detection Using Machine Learning and Deep Learning") indicates
    that the vulnerability category that receives the highest attendance is related
    to the improper control of a resource through its lifetime (CWE-664), with a total
    of 42 studies (18 unique studies). This category primarily involves managing a
    system’s resources, which are created, utilized, and disposed of according to
    a predefined set of instructions. When a software system fails to follow these
    guidelines for resource usage, it can lead to unexpected behaviors that create
    potentially hazardous situations. Attackers can take advantage of these situations
    to exploit the software system for their own purposes. It is observable that CWE-119
    (Russell et al., [2018](#bib.bib123); Liu et al., [2020](#bib.bib96); Nguyen et al.,
    [2020](#bib.bib110); Cheng et al., [2021](#bib.bib29); Yan et al., [2021](#bib.bib146);
    Fu and Tantithamthavorn, [2022](#bib.bib46); Le et al., [2018](#bib.bib77); Cao
    et al., [2022](#bib.bib18); Chen et al., [2021](#bib.bib26); Lin et al., [2019](#bib.bib91);
    Filus et al., [2020](#bib.bib43); Li et al., [2018](#bib.bib89); Duan et al.,
    [2019](#bib.bib39); Wang et al., [2020](#bib.bib137)) is the most frequent vulnerability
    type addressed by the primary studies. This vulnerability occurs when a software
    system attempts to access or write to a memory location outside the permitted
    boundary of the system’s buffer. Attackers can exploit this vulnerability by controlling
    memory locations and executing their own code or commands, effectively manipulating
    the system’s memory. Although the score for this vulnerability type is not high,
    the frequency of primary studies addressing it can be a valuable indicator of
    its significance in terms of detecting and addressing the vulnerability. Within
    this category, the most severe vulnerability type with a score of 65.93 is CWE-787,
    which is discussed in 5 primary studies. This vulnerability is considered severe
    and critical because it can result in the corruption of data, system crashes,
    or the execution of malicious code. It occurs when a software system attempts
    to write data beyond the intended buffer, either before the beginning or past
    the end of the buffer. CWE-22 is another frequent vulnerability type addressed
    by primary studies accounting for 4 primary studies (Fu and Tantithamthavorn,
    [2022](#bib.bib46); Ghaffarian and Shahriari, [2021](#bib.bib50); Cheng et al.,
    [2021](#bib.bib29); Cao et al., [2022](#bib.bib18)). This vulnerability is referred
    to as “Path Traversal”, where attackers exploit special elements, such as “..”
    or “/”, to construct their own path and gain unauthorized access to restricted
    locations. This vulnerability is particularly critical because attackers can use
    it to modify restricted files or directories in vulnerable software systems, potentially
    leading to system crashes by uploading malicious code or commands. In critical
    financial software systems, attackers can even gain access to customers’ bank
    account information. Given the severity of this vulnerability type with a score
    of 14.69 and the frequency of papers covering it, detecting and addressing this
    vulnerability is of utmost importance. Therefore, more advanced ML/DL models are
    needed to effectively detect this type of vulnerability. The least frequent vulnerability
    type of this family is CWE-120 (Russell et al., [2018](#bib.bib123); Cao et al.,
    [2022](#bib.bib18)) which is a classic buffer overflow, accounting for 2 primary
    studies. This vulnerability occurs when the software attempts to copy a value
    to the output buffer without first validating its size. If the range of the value
    is too large for the length of the output buffer, a buffer overflow can occur.
    While the detection of buffer overflow can be challenging in some cases, static
    bug detection tools have already addressed this vulnerability, and detection methods
    are currently available.
  prefs: []
  type: TYPE_NORMAL
- en: Table 11. Different vulnerability types covered in primary studies.
  prefs: []
  type: TYPE_NORMAL
- en: '| Category | CWE-Type | Severity Score | #Studies | Total | References |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-664 | CWE-119 | 5.84 | 14 | 42(18) | (Russell et al., [2018](#bib.bib123);
    Liu et al., [2020](#bib.bib96); Nguyen et al., [2020](#bib.bib110); Cheng et al.,
    [2021](#bib.bib29); Yan et al., [2021](#bib.bib146); Fu and Tantithamthavorn,
    [2022](#bib.bib46); Le et al., [2018](#bib.bib77); Cao et al., [2022](#bib.bib18);
    Chen et al., [2021](#bib.bib26); Lin et al., [2019](#bib.bib91); Filus et al.,
    [2020](#bib.bib43); Li et al., [2018](#bib.bib89); Duan et al., [2019](#bib.bib39);
    Wang et al., [2020](#bib.bib137)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | CWE-787 | 65.93 | 5 |  | (Wang et al., [2020](#bib.bib137); Cheng et al.,
    [2021](#bib.bib29); Fu and Tantithamthavorn, [2022](#bib.bib46); Cao et al., [2022](#bib.bib18);
    Yang et al., [2022](#bib.bib147)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | CWE-22 | 14.69 | 4 |  | (Wang et al., [2020](#bib.bib137); Cheng et al.,
    [2021](#bib.bib29); Fu and Tantithamthavorn, [2022](#bib.bib46); Ghaffarian and
    Shahriari, [2021](#bib.bib50)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | CWE-125 | 24.9 | 4 |  | (Wang et al., [2020](#bib.bib137); Cheng et al.,
    [2021](#bib.bib29); Cao et al., [2022](#bib.bib18); Chen et al., [2021](#bib.bib26))
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | CWE-400 | - | 4 |  | (Wang et al., [2020](#bib.bib137); Zou et al., [2019](#bib.bib161);
    Cheng et al., [2021](#bib.bib29); Yang et al., [2022](#bib.bib147)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | CWE-200 | 4.74 | 3 |  | (Wang et al., [2020](#bib.bib137); Fu and Tantithamthavorn,
    [2022](#bib.bib46); Chen et al., [2021](#bib.bib26)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | CWE-121 | - | 3 |  | (Russell et al., [2018](#bib.bib123); Yan et al.,
    [2021](#bib.bib146); Cao et al., [2022](#bib.bib18)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | CWE-122 | - | 3 |  | (Choi et al., [2017](#bib.bib32); Cao et al., [2022](#bib.bib18);
    Russell et al., [2018](#bib.bib123)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | CWE-120 | - | 2 |  | (Russell et al., [2018](#bib.bib123); Cao et al.,
    [2022](#bib.bib18)) |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-707 | CWE-20 | 20.47 | 6 | 16(9) | (Russell et al., [2018](#bib.bib123);
    Wang et al., [2020](#bib.bib137); Cheng et al., [2021](#bib.bib29); Fu and Tantithamthavorn,
    [2022](#bib.bib46); Chen et al., [2021](#bib.bib26); Yang et al., [2022](#bib.bib147))
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | CWE-78 | 19.55 | 5 |  | (Wang et al., [2020](#bib.bib137); Cheng et al.,
    [2021](#bib.bib29); Ghaffarian and Shahriari, [2021](#bib.bib50); Li et al., [2021b](#bib.bib87);
    Yang et al., [2022](#bib.bib147)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | CWE-89 | 19.54 | 3 |  | (Ghaffarian and Shahriari, [2021](#bib.bib50);
    Kronjee et al., [2018](#bib.bib73); Wang et al., [2020](#bib.bib137)) |'
  prefs: []
  type: TYPE_TB
- en: '|  | CWE-79 | 46.84 | 2 |  | (Kronjee et al., [2018](#bib.bib73); Wang et al.,
    [2020](#bib.bib137)) |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-682 | CWE-190 | 7.12 | 5 | 5 | (Wang et al., [2020](#bib.bib137); Cheng
    et al., [2021](#bib.bib29); Fu and Tantithamthavorn, [2022](#bib.bib46); Zou et al.,
    [2019](#bib.bib161); Yang et al., [2022](#bib.bib147)) |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-703 | CWE-476 | 6.54 | 4 | 4 | (Russell et al., [2018](#bib.bib123);
    Wang et al., [2020](#bib.bib137); Cao et al., [2022](#bib.bib18); Chen et al.,
    [2021](#bib.bib26)) |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-284 | CWE-284 | - | 2 | 2 | (Aivatoglou et al., [2021](#bib.bib4); Chen
    et al., [2021](#bib.bib26)) |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-691 | CWE-362 | - | 2 | 2 | (Chen et al., [2021](#bib.bib26); Zou et al.,
    [2019](#bib.bib161)) |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-1215 | CWE-129 | - | 1 | 1 | (Yang et al., [2022](#bib.bib147)) |'
  prefs: []
  type: TYPE_TB
- en: '| - | CWE-789 | - | 1 | 1 | (Yang et al., [2022](#bib.bib147)) |'
  prefs: []
  type: TYPE_TB
- en: '| SUM | - | - | - | 73(21) | - |'
  prefs: []
  type: TYPE_TB
- en: Improper Neutralization - (CWE-707) Is the second major family of vulnerability
    types covered by 16 primary studies, including 9 unique primary studies. In this
    type, the attackers exploit input and output data when they are malformed or not
    validated properly. There are several scenarios that can lead to data neutralization
    weaknesses. The first scenario involves checking whether input and output data
    are safe, while the second scenario involves filtering the input and output data
    to ensure that any data transformation is done safely. The third scenario involves
    preventing external attackers from directly manipulating the input and output
    data, while the fourth scenario relates to the lack of processing input and output
    data in any circumstances. All of these scenarios can be the root causes of data
    neutralization weaknesses. As can be seen, CWE-20 is the most frequent type of
    vulnerability accounting for 6 primary studies. CWE-20 refers to a situation where
    input validation is not done properly in software systems, making them vulnerable
    to attacks by malicious individuals who can exploit input data. This occurs when
    the input data is not verified to be safe or in line with the predefined specifications.
    The severity and occurrence of this issue are significant, highlighting the need
    for its detection as it can pose critical risks. CWE-78 is the second major vulnerability
    type covered by 5 primary studies (Wang et al., [2020](#bib.bib137); Cheng et al.,
    [2021](#bib.bib29); Ghaffarian and Shahriari, [2021](#bib.bib50); Li et al., [2021b](#bib.bib87);
    Yang et al., [2022](#bib.bib147)). This category of security vulnerability pertains
    to OS command injection, in which an external attacker can construct an OS command
    by using input data from components that have not been adequately verified. The
    attacker can then execute harmful commands, potentially causing the system to
    behave unexpectedly or crash, and putting it in a hazardous state.
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="S4.SS4.1.pic1" class="ltx_picture" height="261.95" overflow="visible"
    version="1.1" width="593.51"><g transform="translate(0,261.95) matrix(1 0 0 -1
    0 0) translate(20.38,0) translate(0,220.86)"><g stroke="#000000"><g stroke-width="1.0pt"
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 0 0)"><foreignobject
    width="552.76" height="210.17" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">(1)
    The most frequent type of vulnerabilities covered in primary studies is Improper
    Control of a Resource Through its Lifetime-(CWE-664) accounting for 18 unique
    primary studies. CWE-119: Improper Restriction of Operations within the Bounds
    of a Memory Buffer is the most frequent type of vulnerability in this category
    accounting for 14 primary studies, and CWE-787: Out-of-bounds Write comes subsequently
    covered by 5 primary studies. The least frequent type of vulnerability is CWE-120
    covered by 2 studies. (2) Improper Neutralization(CWE-707) is the second major
    family of vulnerability types covered by 9 unique primary studies in total. In
    this family, CWE-20: Improper Input Validation is the most frequent type covered
    by 6 primary studies, and CWE-78: Improper Neutralization of Special Elements
    used in an OS Command (‘OS Command Injection’) comes next with 5 primary studies.
    (3) Some vulnerability types have a high CVSS score while not sufficiently addressed
    by existing vulnerability detection studies including but not limited to CWE-79
    and CWE-89. <g stroke-width="0.5pt" fill="#FF9999"><path d="M 97.05 40.75 L 5.19
    40.75 C 2.13 40.75 -0.35 38.27 -0.35 35.21 L -0.35 24.91 C -0.35 21.86 2.13 19.38
    5.19 19.38 L 97.05 19.38 C 100.11 19.38 102.59 21.86 102.59 24.91 L 102.59 35.21
    C 102.59 38.27 100.11 40.75 97.05 40.75 Z M -0.35 19.38"></path></g><g stroke-width="0.5pt"
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 4.27 26.68)"><foreignobject
    width="94.09" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Answer
    to RQ4</foreignobject></g>'
  prefs: []
  type: TYPE_NORMAL
- en: 4.5\. RQ5\. What are possible challenges and open directions in software vulnerability
    detection?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have summarized the challenges from previous studies into five different
    categories, which are discussed as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Challenge 1: Semantic Representation. The biggest challenge in vulnerability
    detection through learning is the inadequate modeling of the comprehensive semantics
    of complex vulnerabilities by current models (Dam et al., [2018](#bib.bib34),
    [2017](#bib.bib33); Shippey et al., [2019](#bib.bib129); Wang et al., [2016](#bib.bib139);
    Jeon and Kim, [2021](#bib.bib65); Phan et al., [2017](#bib.bib117); Hoang et al.,
    [2019](#bib.bib61); Cheng et al., [2021](#bib.bib29); Zhou et al., [2019](#bib.bib155);
    Wu et al., [2021](#bib.bib141); Li et al., [2017](#bib.bib83), [2021c](#bib.bib88),
    [2021b](#bib.bib87); Duan et al., [2019](#bib.bib39); Zheng et al., [2021](#bib.bib154);
    Zhuang et al., [2022](#bib.bib157); Cheng et al., [2022](#bib.bib31); Liu et al.,
    [2021b](#bib.bib98); Yang et al., [2022](#bib.bib147); Nguyen et al., [2022b](#bib.bib109),
    [a](#bib.bib108)). These vulnerabilities often exhibit intricate characteristics
    and patterns that are not fully captured by existing ML/DL models that treat source
    code snippets as a linear sequence like natural language, or only partially represent
    source code snippets. Unlike natural language, the source code of real-world projects
    contains structural and logical information that must be considered by ML/DL models
    using AST, data flow, and control flow. Therefore, current ML/DL approaches fall
    short of identifying complex vulnerability patterns.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Challenge 2: Prediction Granularity. The ability of DL models to identify the
    location of vulnerabilities is influenced by the level of granularity in their
    inputs. Current DL models use a coarser level of granularity, such as method and
    file, for vulnerability detection. To achieve finer-grained inputs, program slicing
    is necessary, but it poses a challenge. The crucial question is how to perform
    program slicing effectively to eliminate unwanted noise in input data and provide
    more specific inputs. Current tools (Pascarella et al., [2019](#bib.bib114); Dinella
    et al., [2020](#bib.bib36); Fu and Tantithamthavorn, [2022](#bib.bib46); Zou et al.,
    [2019](#bib.bib161); Cao et al., [2022](#bib.bib18); Lin et al., [2017](#bib.bib92);
    Li et al., [2021a](#bib.bib85); Ding et al., [2022](#bib.bib37); Zou et al., [2022](#bib.bib160))
    concentrate on library/API function calls, arithmetic operations, and pointer
    usages, but this approach is not sufficient since not all vulnerabilities originate
    from these slicing criteria.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Challenge 3: False Positive Removal. The most commonly used tools for detecting
    software vulnerabilities and bugs are static analyzers (Zhou and Sharma, [2017](#bib.bib156);
    Kronjee et al., [2018](#bib.bib73); Zeng et al., [2021](#bib.bib151); Li et al.,
    [2019](#bib.bib86); Harer et al., [2018](#bib.bib56); Ziems and Wu, [2021](#bib.bib159);
    Zou et al., [2019](#bib.bib161)). These tools utilize hard-coded rules that are
    defined by experts to model the runtime behavior of a program without the need
    for compilation. This approach has several benefits, such as effectively identifying
    the location of vulnerabilities in source codes, which is challenging in large-scale
    projects with thousands of files and artifacts. Additionally, static analyzers
    are used at the early stage of the software development process, which helps reduce
    software maintenance costs. However, relying on expert-defined rules comes with
    a high false-positive rate, as these rules may not be generalizable to new vulnerabilities
    that have intricate and sophisticated program semantics. Another significant issue
    is that defining and updating rules is a labor-intensive and time-consuming process
    that requires experts to have in-depth knowledge of emerging vulnerabilities.
    That is why data-driven vulnerability detection has emerged to overcome the aforementioned
    challenges (Zhou and Sharma, [2017](#bib.bib156); Kronjee et al., [2018](#bib.bib73);
    Zeng et al., [2021](#bib.bib151); Li et al., [2019](#bib.bib86); Harer et al.,
    [2018](#bib.bib56); Ziems and Wu, [2021](#bib.bib159); Zou et al., [2019](#bib.bib161)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Challenge 4: Lack of Training Data. A significant weakness of DL models, particularly
    in software vulnerability detection, is their insatiable need for data (Chen et al.,
    [2020b](#bib.bib25); Liu et al., [2020](#bib.bib96); Lin et al., [2019](#bib.bib91);
    Yang et al., [2017](#bib.bib148); Ni et al., [2022](#bib.bib111)). In domains
    such as image classification, there is an ample supply of labeled data, making
    it possible to train DL models effectively. Furthermore, there are many pre-trained
    models available that can be fine-tuned for detection tasks. However, in software
    vulnerability detection, data scarcity is a major problem since labeling ground
    truth information is a challenging task. To obtain training data, multiple online
    platforms such as Stack Overflow, GitHub, and issue tracking or bug tracking systems
    are used. While these platforms contain billions of records, the labeling process
    is difficult and is often done manually. One possible solution is the automatic
    labeling of data, but this approach is challenging as it often generates many
    false positives. Additionally, some researchers use unsupervised classification
    for vulnerability detection, but this method also suffers from limited precision.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Challenge 5: Lack of Model Interpretability. Interpretability in DL models
    refers to the ability to understand and explain the decisions made by the model (Dwivedi
    et al., [2023](#bib.bib41); Minh et al., [2022](#bib.bib106)). In the context
    of software vulnerability detection (Zou et al., [2021](#bib.bib162); Li et al.,
    [2021a](#bib.bib85); Liu et al., [2021b](#bib.bib98)), there are several challenges
    that make interpretability challenging for DL models. First, source code can be
    highly complex, especially in large software projects. It often consists of multiple
    files, functions, and dependencies, making it difficult to extract meaningful
    and concise explanations from the code (Jiang et al., [2022](#bib.bib67)). Software
    systems are dynamic and undergo changes over time. Code is often maintained, updated,
    and refactored, which can introduce complexities in interpreting the decisions
    made by AI models. The model’s explanations may not be applicable to the current
    version of the code if it has evolved since the model’s training.'
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S4.SS5.1.pic1" class="ltx_picture" height="252.5" overflow="visible"
    version="1.1" width="593.51"><g transform="translate(0,252.5) matrix(1 0 0 -1
    0 0) translate(20.38,0) translate(0,211.4)"><g stroke="#000000"><g stroke-width="1.0pt"
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 0 0)"><foreignobject
    width="552.76" height="200.71" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">(1)
    Current models inadequately capture the comprehensive semantics of complex vulnerabilities,
    as they fail to consider the structural and logical information present in source
    code snippets. Existing ML/DL models treat source code as a linear sequence, which
    limits their ability to identify intricate vulnerability patterns. (2) DL models
    often use a coarse level of granularity for vulnerability detection, such as method
    and file level. Achieving finer-grained inputs requires effective program-slicing
    techniques to eliminate noise and provide more specific inputs. Current approaches
    focus on certain slicing criteria, but vulnerabilities can originate from other
    sources as well. (3) DL models require a significant amount of labeled data for
    effective training. However, in software vulnerability detection, there is a scarcity
    of labeled data due to the challenging task of manual labeling. Automatic labeling
    approaches often generate false positives, and unsupervised classification suffers
    from limited precision. <g stroke-width="0.5pt" fill="#FF9999"><path d="M 97.05
    40.75 L 5.19 40.75 C 2.13 40.75 -0.35 38.27 -0.35 35.21 L -0.35 24.91 C -0.35
    21.86 2.13 19.38 5.19 19.38 L 97.05 19.38 C 100.11 19.38 102.59 21.86 102.59 24.91
    L 102.59 35.21 C 102.59 38.27 100.11 40.75 97.05 40.75 Z M -0.35 19.38"></path></g><g
    stroke-width="0.5pt" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0
    0.0 1.0 4.27 26.68)"><foreignobject width="94.09" height="12.15" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Answer to RQ5</foreignobject></g>
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Threats to validity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: External Validity. One of the major threats to the external validity of our
    work is the data collection internal. We collect data in an 11 years old period
    from 2011 to 2022 to coverall all possible studies published during this period.
    Another source of threat to external validity is the coverage of the input data
    types in software vulnerability detection. To tackle this threat, we focused on
    source code snippets as well as repository data, i.e., data that can be extracted
    from open source including GitHub and CVE.
  prefs: []
  type: TYPE_NORMAL
- en: Internal Validity. One of the major threats to the internal validity of our
    work is the automatic collection of data for analysis. Our technique for data
    collection is automated at its initial steps in which we may miss some important
    vulnerability detection papers. In fact, we developed a set of scripts that allowed
    us to extract papers given an 11-year period. Even though the subsequent steps
    are manually supervised, still the automatic filtering suffers from this issue.
    The second important issue with our data collection is possible bias. The root
    cause of bias is unavoidable disagreements during paper classification as two
    researchers have worked together to categorize papers based on title, abstract,
    and content of papers. In case the researchers could not come up with an agreement,
    the third researcher join to resolve the differences which somehow relaxes the
    issue.
  prefs: []
  type: TYPE_NORMAL
- en: Construct Validity. The major threat to the construct validity of our survey
    is the level of granularity of the analysis we conducted for each primary study.
    For each study, we deeply analyzed the artifacts explained in the paper and show
    their distribution as tables and graphs. For example, in terms of sources for
    benchmark data, we deeply analyzed 17 sources accounting for 53 primary studies
    overall. The second threat to the construct validity is the degree of coverage
    for each primary study. We analyzed each primary study from 5 aspects including
    input data, input representation, embedding techniques, models, vulnerability
    types, and whether the study supports the interpretability of vulnerability detection
    models or not.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this study, we conducted a systematic survey on 67 primary studies using
    ML/DL models for software security vulnerability detection. We collected the papers
    from different journals and conference venues including 25 conferences and 12
    journals. Our review is established based on five major research questions and
    a set of sub-research questions. We devised the research questions in a comprehensive
    manner where to cover various dimensions of software vulnerability detection.
    Our analysis of primary studies indicated that there is a booming trend in the
    growth of using ML/DL models for software vulnerability detection. Our deep analysis
    of data sources of primary studies revealed that 65.7% of studies use benchmark
    data for software vulnerability detection. We also find 6 broad categories of
    DL models along with 14 classic ML models used in software vulnerability detection.
    The categories of DL models are classified as recurrent models, graph models,
    attention models, convolutional models, general models, and transformer models.
    RNNs are by far the most popular DNNs in software vulnerability detection. Our
    analysis also finds that RNNs with LSTM cells are the most popular network architectures
    in recurrent models, accounting for 8 primary studies. In the category of graph
    models, GGNN is the most popular DL model used by 4 primary studies. Our results
    on vulnerability types reveal that the most frequent type of vulnerability covered
    in existing studies is Improper Control of a Resource Through its Lifetime - (CWE-664)
    accounting for 18 primary studies. In conclusion, we have identified a collection
    of ongoing challenges that necessitate further exploration in future studies involving
    the utilization of ML/DL models for software vulnerability detection.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aaltonen and Gao (2021) Aleksi Aaltonen and Yiwen Gao. 2021. Does the Outsider
    Help? The Impact of Bug Bounty Programs on Data Breaches. *The Impact of Bug Bounty
    Programs on Data Breaches (August 20, 2021). Fox School of Business Research Paper*
    (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abri et al. (2019) Faranak Abri, Sima Siami-Namini, Mahdi Adl Khanghah, Fahimeh Mirza
    Soltani, and Akbar Siami Namin. 2019. Can machine/deep learning classifiers detect
    zero-day malware with high accuracy?. In *2019 IEEE international conference on
    big data (Big Data)*. IEEE, 3252–3259.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aivatoglou et al. (2021) Georgios Aivatoglou, Mike Anastasiadis, Georgios Spanos,
    Antonis Voulgaridis, Konstantinos Votis, and Dimitrios Tzovaras. 2021. A tree-based
    machine learning methodology to automatically classify software vulnerabilities.
    In *2021 IEEE International Conference on Cyber Security and Resilience (CSR)*.
    IEEE, 312–317.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An et al. (2020) Wenyan An, Liwei Chen, Jinxin Wang, Gewangzi Du, Gang Shi,
    and Dan Meng. 2020. AVDHRAM: Automated Vulnerability Detection based on Hierarchical
    Representation and Attention Mechanism. In *2020 IEEE Intl Conf on Parallel &
    Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable
    Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)*.
    IEEE, 337–344.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Anthonysamy et al. (2017) Pauline Anthonysamy, Awais Rashid, and Ruzanna Chitchyan.
    2017. Privacy requirements: present & future. In *2017 IEEE/ACM 39th international
    conference on software engineering: software engineering in society track (ICSE-SEIS)*.
    IEEE, 13–22.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aslan et al. (2023) Ömer Aslan, Semih Serkant Aktuğ, Merve Ozkan-Okay, Abdullah Asim
    Yilmaz, and Erdal Akin. 2023. A comprehensive review of cyber security vulnerabilities,
    threats, attacks, and solutions. *Electronics* 12, 6 (2023), 1333.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bacchelli and Bird (2013) Alberto Bacchelli and Christian Bird. 2013. Expectations,
    outcomes, and challenges of modern code review. In *2013 35th International Conference
    on Software Engineering (ICSE)*. IEEE, 712–721.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bhandari et al. (2021) Guru Bhandari, Amara Naseer, and Leon Moonen. 2021.
    CVEfixes: automated collection of vulnerabilities and their fixes from open-source
    software. In *Proceedings of the 17th International Conference on Predictive Models
    and Data Analytics in Software Engineering*. 30–39.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bi et al. (2023) Yingzhou Bi, Jiangtao Huang, Penghui Liu, and Lianmei Wang.
    2023. Benchmarking Software Vulnerability Detection Techniques: A Survey. *arXiv
    preprint arXiv:2303.16362* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bilge and Dumitraş (2012) Leyla Bilge and Tudor Dumitraş. 2012. Before we knew
    it: an empirical study of zero-day attacks in the real world. In *Proceedings
    of the 2012 ACM conference on Computer and communications security*. 833–844.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Black (2017) Paul E Black. 2017. Sard: a software assurance reference dataset.
    (2017).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Booth et al. (2013) Harold Booth, Doug Rike, and Gregory A Witte. 2013. The
    national vulnerability database (nvd): Overview. (2013).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bozorgi et al. (2010) Mehran Bozorgi, Lawrence K Saul, Stefan Savage, and Geoffrey M
    Voelker. 2010. Beyond heuristics: learning to classify vulnerabilities and predict
    exploits. In *Proceedings of the 16th ACM SIGKDD international conference on Knowledge
    discovery and data mining*. 105–114.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bugzilla’s (2021) UI Bugzilla’s. 2021. Bugzilla. (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cadar et al. (2008) Cristian Cadar, Daniel Dunbar, Dawson R Engler, et al.
    2008. Klee: unassisted and automatic generation of high-coverage tests for complex
    systems programs.. In *OSDI*, Vol. 8. 209–224.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Canfora et al. (2022) Gerardo Canfora, Andrea Di Sorbo, Sara Forootani, Matias
    Martinez, and Corrado A Visaggio. 2022. Patchworking: Exploring the code changes
    induced by vulnerability fixing activities. *Information and Software Technology*
    142 (2022), 106745.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cao et al. (2022) Sicong Cao, Xiaobing Sun, Lili Bo, Rongxin Wu, Bin Li, and
    Chuanqi Tao. 2022. MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive
    Graph Neural Networks. *arXiv preprint arXiv:2203.02660* (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Carlsson and Baca (2005) Bengt Carlsson and Dejan Baca. 2005. Software security
    analysis-execution phase audit. In *31st EUROMICRO Conference on Software Engineering
    and Advanced Applications*. IEEE, 240–247.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chakraborty et al. (2021) Saikat Chakraborty, Rahul Krishna, Yangruibo Ding,
    and Baishakhi Ray. 2021. Deep learning based vulnerability detection: Are we there
    yet. *IEEE Transactions on Software Engineering* (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chang et al. (2011) Yung-Yu Chang, Pavol Zavarsky, Ron Ruhl, and Dale Lindskog.
    2011. Trend analysis of the cve for software vulnerability management. In *2011
    IEEE third international conference on privacy, security, risk and trust and 2011
    IEEE third international conference on social computing*. IEEE, 1290–1293.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2019a) Haipeng Chen, Jing Liu, Rui Liu, Noseong Park, and VS Subrahmanian.
    2019a. VEST: A System for Vulnerability Exploit Scoring & Timing.. In *IJCAI*.
    6503–6505.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2019b) Haipeng Chen, Rui Liu, Noseong Park, and VS Subrahmanian.
    2019b. Using twitter to predict when vulnerabilities will be exploited. In *Proceedings
    of the 25th ACM SIGKDD international conference on knowledge discovery & data
    Mining*. 3143–3152.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2020a) Jinfu Chen, Patrick Kwaku Kudjo, Solomon Mensah, Selasie Aformaley
    Brown, and George Akorfu. 2020a. An automatic software vulnerability classification
    framework using term frequency-inverse gravity moment and feature selection. *Journal
    of Systems and Software* 167 (2020), 110616.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2020b) Yang Chen, Andrew E Santosa, Ang Ming Yi, Abhishek Sharma,
    Asankhaya Sharma, and David Lo. 2020b. A machine learning approach for vulnerability
    curation. In *Proceedings of the 17th International Conference on Mining Software
    Repositories*. 32–42.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2021) Zimin Chen, Steve Kommrusch, and Martin Monperrus. 2021.
    Neural Transfer Learning for Repairing Security Vulnerabilities in C Code. *arXiv
    preprint arXiv:2104.08308* (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2022) Zimin Chen, Steve Kommrusch, and Martin Monperrus. 2022.
    Neural transfer learning for repairing security vulnerabilities in c code. *IEEE
    Transactions on Software Engineering* 49, 1 (2022), 147–165.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2010) Zhongqiang Chen, Yuan Zhang, and Zhongrong Chen. 2010. A
    categorization framework for common computer vulnerabilities and exposures. *Comput.
    J.* 53, 5 (2010), 551–580.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cheng et al. (2021) Xiao Cheng, Haoyu Wang, Jiayi Hua, Guoai Xu, and Yulei
    Sui. 2021. DeepWukong: Statically detecting software vulnerabilities using deep
    graph neural network. *ACM Transactions on Software Engineering and Methodology
    (TOSEM)* 30, 3 (2021), 1–33.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cheng et al. (2019) Xiao Cheng, Haoyu Wang, Jiayi Hua, Miao Zhang, Guoai Xu,
    Li Yi, and Yulei Sui. 2019. Static detection of control-flow-related vulnerabilities
    using graph embedding. In *2019 24th International Conference on Engineering of
    Complex Computer Systems (ICECCS)*. IEEE, 41–50.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cheng et al. (2022) Xiao Cheng, Guanqin Zhang, Haoyu Wang, and Yulei Sui. 2022.
    Path-sensitive code embedding via contrastive learning for software vulnerability
    detection. In *Proceedings of the 31st ACM SIGSOFT International Symposium on
    Software Testing and Analysis*. 519–531.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choi et al. (2017) Min-Je Choi, Sehun Jeong, Hakjoo Oh, and Jaegul Choo. 2017.
    End-to-End Prediction of Buffer Overruns from Raw Source Code via Neural Memory
    Networks. In *Proceedings of the 26th International Joint Conference on Artificial
    Intelligence* (Melbourne, Australia) *(IJCAI’17)*. AAAI Press, 1546–1553.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dam et al. (2017) Hoa Khanh Dam, Truyen Tran, Trang Pham, Shien Wee Ng, John
    Grundy, and Aditya Ghose. 2017. Automatic feature learning for vulnerability prediction.
    *arXiv preprint arXiv:1708.02368* (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dam et al. (2018) Hoa Khanh Dam, Truyen Tran, Trang Pham, Shien Wee Ng, John
    Grundy, and Aditya Ghose. 2018. Automatic feature learning for predicting vulnerable
    software components. *IEEE Transactions on Software Engineering* 47, 1 (2018),
    67–85.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. (2018) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language
    understanding. *arXiv preprint arXiv:1810.04805* (2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dinella et al. (2020) Elizabeth Dinella, Hanjun Dai, Ziyang Li, Mayur Naik,
    Le Song, and Ke Wang. 2020. Hoppity: Learning graph transformations to detect
    and fix bugs in programs. In *International Conference on Learning Representations
    (ICLR)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ding et al. (2022) Yangruibo Ding, Sahil Suneja, Yunhui Zheng, Jim Laredo,
    Alessandro Morari, Gail Kaiser, and Baishakhi Ray. 2022. VELVET: a noVel Ensemble
    Learning approach to automatically locate VulnErable sTatements. In *2022 IEEE
    International Conference on Software Analysis, Evolution and Reengineering (SANER)*.
    IEEE, 959–970.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Du et al. (2020) Xiaoting Du, Zenghui Zhou, Beibei Yin, and Guanping Xiao. 2020.
    Cross-project bug type prediction based on transfer learning. *Software Quality
    Journal* 28, 1 (2020), 39–57.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Duan et al. (2019) Xu Duan, Jingzheng Wu, Shouling Ji, Zhiqing Rui, Tianyue
    Luo, Mutian Yang, and Yanjun Wu. 2019. VulSniper: Focus Your Attention to Shoot
    Fine-Grained Vulnerabilities.. In *IJCAI*. 4665–4671.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dunham (2009) Andrew Dunham. 2009. *rough-auditing-tool-for-security*. [https://github.com/andrew-d/rough-auditing-tool-for-security](https://github.com/andrew-d/rough-auditing-tool-for-security)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dwivedi et al. (2023) Rudresh Dwivedi, Devam Dave, Het Naik, Smiti Singhal,
    Rana Omer, Pankesh Patel, Bin Qian, Zhenyu Wen, Tejal Shah, Graham Morgan, et al.
    2023. Explainable AI (XAI): Core ideas, techniques, and solutions. *Comput. Surveys*
    55, 9 (2023), 1–33.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Facebook (2013) Facebook. 2013. *Infer*. [https://fbinfer.com/](https://fbinfer.com/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filus et al. (2020) Katarzyna Filus, Miltiadis Siavvas, Joanna Domańska, and
    Erol Gelenbe. 2020. The random neural network as a bonding model for software
    vulnerability prediction. In *Symposium on Modelling, Analysis, and Simulation
    of Computer and Telecommunication Systems*. Springer, 102–116.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Foreman (2019) Park Foreman. 2019. *Vulnerability management*. CRC Press.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frei et al. (2006) Stefan Frei, Martin May, Ulrich Fiedler, and Bernhard Plattner.
    2006. Large-scale vulnerability analysis. In *Proceedings of the 2006 SIGCOMM
    workshop on Large-scale attack defense*. 131–138.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fu and Tantithamthavorn (2022) Michael Fu and Chakkrit Tantithamthavorn. 2022.
    LineVul: A Transformer-based Line-Level Vulnerability Prediction. (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. (2021) Cong Gao, Geng Wang, Weisong Shi, Zhongmin Wang, and Yanping
    Chen. 2021. Autonomous driving security: State of the art and challenges. *IEEE
    Internet of Things Journal* 9, 10 (2021), 7572–7595.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gawron et al. (2018) Marian Gawron, Feng Cheng, and Christoph Meinel. 2018.
    Automatic vulnerability classification using machine learning. In *Risks and Security
    of Internet and Systems: 12th International Conference, CRiSIS 2017, Dinard, France,
    September 19-21, 2017, Revised Selected Papers 12*. Springer, 3–17.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ghaffarian and Shahriari (2017) Seyed Mohammad Ghaffarian and Hamid Reza Shahriari.
    2017. Software vulnerability analysis and discovery using machine-learning and
    data-mining techniques: A survey. *ACM Computing Surveys (CSUR)* 50, 4 (2017),
    1–36.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ghaffarian and Shahriari (2021) Seyed Mohammad Ghaffarian and Hamid Reza Shahriari.
    2021. Neural software vulnerability analysis using rich intermediate graph representations
    of programs. *Information Sciences* 553 (2021), 189–207.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gissurarson et al. (2022) Matthías Páll Gissurarson, Leonhard Applis, Annibale
    Panichella, Arie van Deursen, and David Sands. 2022. PropR: property-based automatic
    program repair. In *Proceedings of the 44th International Conference on Software
    Engineering*. 1768–1780.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gong et al. (2019) Xi Gong, Zhenchang Xing, Xiaohong Li, Zhiyong Feng, and Zhuobing
    Han. 2019. Joint prediction of multiple vulnerability characteristics through
    multi-task learning. In *2019 24th International Conference on Engineering of
    Complex Computer Systems (ICECCS)*. IEEE, 31–40.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2020) Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
    Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020.
    Generative adversarial networks. *Commun. ACM* 63, 11 (2020), 139–144.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Goseva-Popstojanova and Tyo (2017) Katerina Goseva-Popstojanova and Jacob Tyo.
    2017. Experience report: Security vulnerability profiles of mission critical software:
    Empirical analysis of security related bug reports. In *2017 IEEE 28th International
    Symposium on Software Reliability Engineering (ISSRE)*. IEEE, 152–163.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guo et al. (2020) Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie
    Liu, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, et al. 2020. Graphcodebert:
    Pre-training code representations with data flow. *arXiv preprint arXiv:2009.08366*
    (2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Harer et al. (2018) Jacob A. Harer, Onur Ozdemir, Tomo Lazovich, Christopher P.
    Reale, Rebecca L. Russell, Louis Y. Kim, and Peter Chin. 2018. Learning to Repair
    Software Vulnerabilities with Generative Adversarial Networks. In *Proceedings
    of the 32nd International Conference on Neural Information Processing Systems*
    (Montréal, Canada) *(NIPS’18)*. Curran Associates Inc., Red Hook, NY, USA, 7944–7954.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Harzevili et al. (2022) Nima Shiri Harzevili, Jiho Shin, Junjie Wang, and Song
    Wang. 2022. Characterizing and Understanding Software Security Vulnerabilities
    in Machine Learning Libraries. *arXiv preprint arXiv:2203.06502* (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2020) Daojing He, Zhi Deng, Yuxing Zhang, Sammy Chan, Yao Cheng,
    and Nadra Guizani. 2020. Smart contract vulnerability analysis and security audit.
    *IEEE Network* 34, 5 (2020), 276–282.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hin et al. (2022) David Hin, Andrey Kan, Huaming Chen, and M Ali Babar. 2022.
    LineVD: Statement-level Vulnerability Detection using Graph Neural Networks. *arXiv
    preprint arXiv:2203.05181* (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hinton et al. (2006) Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh. 2006.
    A fast learning algorithm for deep belief nets. *Neural computation* 18, 7 (2006),
    1527–1554.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hoang et al. (2019) Thong Hoang, Hoa Khanh Dam, Yasutaka Kamei, David Lo, and
    Naoyasu Ubayashi. 2019. DeepJIT: an end-to-end deep learning framework for just-in-time
    defect prediction. In *2019 IEEE/ACM 16th International Conference on Mining Software
    Repositories (MSR)*. IEEE, 34–45.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2021) Jianjun Huang, Songming Han, Wei You, Wenchang Shi, Bin
    Liang, Jingzheng Wu, and Yanjun Wu. 2021. Hunting vulnerable smart contracts via
    graph embedding based bytecode matching. *IEEE Transactions on Information Forensics
    and Security* 16 (2021), 2144–2156.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huo et al. (2018) Xuan Huo, Yang Yang, Ming Li, and De-Chuan Zhan. 2018. Learning
    Semantic Features for Software Defect Prediction by Code Comments Embedding. In
    *2018 IEEE International Conference on Data Mining (ICDM)*. 1049–1054. [https://doi.org/10.1109/ICDM.2018.00133](https://doi.org/10.1109/ICDM.2018.00133)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jacobs et al. (2023) Jay Jacobs, Sasha Romanosky, Octavian Suciuo, Benjamin
    Edwards, and Armin Sarabi. 2023. Enhancing Vulnerability Prioritization: Data-Driven
    Exploit Predictions with Community-Driven Insights. *arXiv preprint arXiv:2302.14172*
    (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jeon and Kim (2021) Sanghoon Jeon and Huy Kang Kim. 2021. AutoVAS: An automated
    vulnerability analysis system with a deep learning approach. *Computers & Security*
    106 (2021), 102308.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang and Atif (2020) Yuning Jiang and Yacine Atif. 2020. An approach to discover
    and assess vulnerability severity automatically in cyber-physical systems. In
    *13th international conference on security of information and networks*. 1–8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2022) Yanjie Jiang, Hui Liu, Yuxia Zhang, Weixing Ji, Hao Zhong,
    and Lu Zhang. 2022. Do bugs lead to unnaturalness of source code?. In *Proceedings
    of the 30th ACM Joint European Software Engineering Conference and Symposium on
    the Foundations of Software Engineering*. 1085–1096.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jimenez et al. (2016) Matthieu Jimenez, Mike Papadakis, and Yves Le Traon. 2016.
    An empirical analysis of vulnerabilities in openssl and the linux kernel. In *2016
    23rd Asia-Pacific Software Engineering Conference (APSEC)*. IEEE, 105–112.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keele et al. (2007) Staffs Keele et al. 2007. *Guidelines for performing systematic
    literature reviews in software engineering*. Technical Report. Technical report,
    Ver. 2.3 EBSE Technical Report. EBSE.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Khan and Parkinson (2018) Saad Khan and Simon Parkinson. 2018. Review into state
    of the art of vulnerability assessment using artificial intelligence. In *Guide
    to Vulnerability Analysis for Computer Networks and Systems*. Springer, 3–32.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2019) Taegyu Kim, Chung Hwan Kim, Junghwan Rhee, Fan Fei, Zhan
    Tu, Gregory Walkup, Xiangyu Zhang, Xinyan Deng, and Dongyan Xu. 2019. RVFuzzer:
    Finding Input Validation Bugs in Robotic Vehicles through Control-Guided Testing..
    In *USENIX Security Symposium*. 425–442.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kritikos et al. (2019) Kyriakos Kritikos, Kostas Magoutis, Manos Papoutsakis,
    and Sotiris Ioannidis. 2019. A survey on vulnerability assessment tools and databases
    for cloud-based web applications. *Array* 3 (2019), 100011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kronjee et al. (2018) Jorrit Kronjee, Arjen Hommersom, and Harald Vranken. 2018.
    Discovering software vulnerabilities using data-flow analysis and machine learning.
    In *Proceedings of the 13th international conference on availability, reliability
    and security*. 1–10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kudjo et al. (2020) Patrick Kwaku Kudjo, Jinfu Chen, Solomon Mensah, Richard
    Amankwah, and Christopher Kudjo. 2020. The effect of Bellwether analysis on software
    vulnerability severity prediction models. *Software Quality Journal* 28 (2020),
    1413–1446.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kudjo et al. (2019) Patrick Kwaku Kudjo, Jinfu Chen, Minmin Zhou, Solomon Mensah,
    and Rubing Huang. 2019. Improving the accuracy of vulnerability report classification
    using term frequency-inverse gravity moment. In *2019 IEEE 19th International
    Conference on Software Quality, Reliability and Security (QRS)*. IEEE, 248–259.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lattner (2008) Chris Lattner. 2008. *LLVM and Clang: Next generation compiler
    technology*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Le et al. (2018) Tue Le, Tuan Nguyen, Trung Le, Dinh Phung, Paul Montague, Olivier
    De Vel, and Lizhen Qu. 2018. Maximal divergence sequential autoencoder for binary
    software vulnerability detection. In *International Conference on Learning Representations*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Le et al. (2021a) Triet HM Le, Huaming Chen, and M Ali Babar. 2021a. A survey
    on data-driven software vulnerability assessment and prioritization. *arXiv preprint
    arXiv:2107.08364* (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Le et al. (2022) Triet HM Le, Huaming Chen, and M Ali Babar. 2022. A survey
    on data-driven software vulnerability assessment and prioritization. *Comput.
    Surveys* 55, 5 (2022), 1–39.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Le et al. (2021b) Triet Huynh Minh Le, David Hin, Roland Croft, and M Ali Babar.
    2021b. Deepcva: Automated commit-level vulnerability assessment with deep multi-task
    learning. In *2021 36th IEEE/ACM International Conference on Automated Software
    Engineering (ASE)*. IEEE, 717–729.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Le et al. (2019) Triet Huynh Minh Le, Bushra Sabir, and Muhammad Ali Babar.
    2019. Automated software vulnerability assessment with concept drift. In *2019
    IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)*.
    IEEE, 371–382.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lehmann and Pradel (2019) Daniel Lehmann and Michael Pradel. 2019. Wasabi:
    A framework for dynamically analyzing webassembly. In *Proceedings of the Twenty-Fourth
    International Conference on Architectural Support for Programming Languages and
    Operating Systems*. 1045–1058.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2017) Jian Li, Pinjia He, Jieming Zhu, and Michael R Lyu. 2017. Software
    defect prediction via convolutional neural network. In *2017 IEEE International
    Conference on Software Quality, Reliability and Security (QRS)*. IEEE, 318–328.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2022) Leping Li, Hui Liu, Kejun Li, Yanjie Jiang, and Rui Sun. 2022.
    Generating Concise Patches for Newly Released Programming Assignments. *IEEE Transactions
    on Software Engineering* (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2021a) Yi Li, Shaohua Wang, and Tien N Nguyen. 2021a. Vulnerability
    detection with fine-grained interpretations. In *Proceedings of the 29th ACM Joint
    Meeting on European Software Engineering Conference and Symposium on the Foundations
    of Software Engineering*. 292–303.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2019) Yi Li, Shaohua Wang, Tien N. Nguyen, and Son Van Nguyen. 2019.
    Improving Bug Detection via Context-Based Code Representation Learning and Attention-Based
    Neural Networks. *Proc. ACM Program. Lang.* 3, OOPSLA, Article 162 (oct 2019),
    30 pages. [https://doi.org/10.1145/3360588](https://doi.org/10.1145/3360588)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2021b) Zhen Li, Deqing Zou, Shouhuai Xu, Zhaoxuan Chen, Yawei Zhu,
    and Hai Jin. 2021b. Vuldeelocator: a deep learning-based fine-grained vulnerability
    detector. *IEEE Transactions on Dependable and Secure Computing* (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2021c) Zhen Li, Deqing Zou, Shouhuai Xu, Hai Jin, Yawei Zhu, and
    Zhaoxuan Chen. 2021c. Sysevr: A framework for using deep learning to detect software
    vulnerabilities. *IEEE Transactions on Dependable and Secure Computing* (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2018) Zhen Li, Deqing Zou, Shouhuai Xu, Xinyu Ou, Hai Jin, Sujuan
    Wang, Zhijun Deng, and Yuyi Zhong. 2018. Vuldeepecker: A deep learning-based system
    for vulnerability detection. *arXiv preprint arXiv:1801.01681* (2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. (2020) Guanjun Lin, Sheng Wen, Qing-Long Han, Jun Zhang, and Yang
    Xiang. 2020. Software vulnerability detection using deep neural networks: a survey.
    *Proc. IEEE* 108, 10 (2020), 1825–1848.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. (2019) Guanjun Lin, Jun Zhang, Wei Luo, Lei Pan, Olivier De Vel,
    Paul Montague, and Yang Xiang. 2019. Software vulnerability discovery via learning
    multi-domain knowledge bases. *IEEE Transactions on Dependable and Secure Computing*
    18, 5 (2019), 2469–2485.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. (2017) Guanjun Lin, Jun Zhang, Wei Luo, Lei Pan, and Yang Xiang.
    2017. POSTER: Vulnerability discovery with function representation learning from
    unlabeled projects. In *Proceedings of the 2017 ACM SIGSAC Conference on Computer
    and Communications Security*. 2539–2541.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. (2018) Guanjun Lin, Jun Zhang, Wei Luo, Lei Pan, Yang Xiang, Olivier
    De Vel, and Paul Montague. 2018. Cross-project transfer representation learning
    for vulnerable function discovery. *IEEE Transactions on Industrial Informatics*
    14, 7 (2018), 3289–3297.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2021a) Chao Liu, Cuiyun Gao, Xin Xia, David Lo, John Grundy, and
    Xiaohu Yang. 2021a. On the reproducibility and replicability of deep learning
    in software engineering. *ACM Transactions on Software Engineering and Methodology
    (TOSEM)* 31, 1 (2021), 1–46.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019a) Shigang Liu, Guanjun Lin, Qing-Long Han, Sheng Wen, Jun
    Zhang, and Yang Xiang. 2019a. DeepBalance: Deep-learning and fuzzy oversampling
    for vulnerability detection. *IEEE Transactions on Fuzzy Systems* 28, 7 (2019),
    1329–1343.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2020) Shigang Liu, Guanjun Lin, Lizhen Qu, Jun Zhang, Olivier De Vel,
    Paul Montague, and Yang Xiang. 2020. CD-VulD: Cross-domain vulnerability discovery
    based on deep domain adaptation. *IEEE Transactions on Dependable and Secure Computing*
    (2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019b) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019b.
    Roberta: A robustly optimized bert pretraining approach. *arXiv preprint arXiv:1907.11692*
    (2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2021b) Zhenguang Liu, Peng Qian, Xiang Wang, Lei Zhu, Qinming He,
    and Shouling Ji. 2021b. Smart contract vulnerability detection: from pure neural
    network to interpretable graph feature and expert pattern fusion. *arXiv preprint
    arXiv:2106.09282* (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2021c) Zhenguang Liu, Peng Qian, Xiaoyang Wang, Yuan Zhuang, Lin
    Qiu, and Xun Wang. 2021c. Combining graph neural networks with expert knowledge
    for smart contract vulnerability detection. *IEEE Transactions on Knowledge and
    Data Engineering* (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2021) Ning Lu, Bin Wang, Yongxin Zhang, Wenbo Shi, and Christian
    Esposito. 2021. NeuCheck: A more practical Ethereum smart contract security analysis
    tool. *Software: Practice and Experience* 51, 10 (2021), 2065–2084.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Luo et al. (2019) Qian Luo, Yurui Cao, Jiajia Liu, and Abderrahim Benslimane.
    2019. Localization and navigation in autonomous driving: Threats and countermeasures.
    *IEEE Wireless Communications* 26, 4 (2019), 38–45.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mahor et al. (2022) Vinod Mahor, Kiran Pachlasiya, Bhagwati Garg, Mukesh Chouhan,
    Shrikant Telang, and Romil Rawat. 2022. Mobile Operating System (Android) Vulnerability
    Analysis Using Machine Learning. In *Proceedings of International Conference on
    Network Security and Blockchain Technology: ICNSBT 2021*. Springer, 159–169.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mao et al. (2020) Yi Mao, Yun Li, Jiatai Sun, and Yixin Chen. 2020. Explainable
    Software vulnerability detection based on Attention-based Bidirectional Recurrent
    Neural Networks. In *2020 IEEE International Conference on Big Data (Big Data)*.
    IEEE, 4651–4656.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marjamäki (2016) Daniel Marjamäki. 2016. *Cppcheck*. [https://cppcheck.sourceforge.io/](https://cppcheck.sourceforge.io/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Medeiros et al. (2023) Nadia Medeiros, Naghmeh Ivaki, Pedro Costa, and Marco
    Vieira. 2023. Trustworthiness models to categorize and prioritize code for security
    improvement. *Journal of Systems and Software* (2023), 111621.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Minh et al. (2022) Dang Minh, H Xiang Wang, Y Fen Li, and Tan N Nguyen. 2022.
    Explainable artificial intelligence: a comprehensive review. *Artificial Intelligence
    Review* (2022), 1–66.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nethercote and Seward (2007) Nicholas Nethercote and Julian Seward. 2007. Valgrind:
    a framework for heavyweight dynamic binary instrumentation. *ACM Sigplan notices*
    42, 6 (2007), 89–100.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nguyen et al. (2022a) Hoang H Nguyen, Nhat-Minh Nguyen, Hong-Phuc Doan, Zahra
    Ahmadi, Thanh-Nam Doan, and Lingxiao Jiang. 2022a. MANDO-GURU: vulnerability detection
    for smart contract source code by heterogeneous graph embeddings. In *Proceedings
    of the 30th ACM Joint European Software Engineering Conference and Symposium on
    the Foundations of Software Engineering*. 1736–1740.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nguyen et al. (2022b) Hoang H Nguyen, Nhat-Minh Nguyen, Chunyao Xie, Zahra
    Ahmadi, Daniel Kudendo, Thanh-Nam Doan, and Lingxiao Jiang. 2022b. MANDO: Multi-Level
    Heterogeneous Graph Embeddings for Fine-Grained Detection of Smart Contract Vulnerabilities.
    *arXiv preprint arXiv:2208.13252* (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nguyen et al. (2020) Tuan Nguyen, Trung Le, Khanh Nguyen, Olivier de Vel, Paul
    Montague, John Grundy, and Dinh Phung. 2020. Deep cost-sensitive kernel machine
    for binary software vulnerability detection. In *Pacific-Asia Conference on Knowledge
    Discovery and Data Mining*. Springer, 164–177.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ni et al. (2022) Chao Ni, Wei Wang, Kaiwen Yang, Xin Xia, Kui Liu, and David
    Lo. 2022. The best of both worlds: integrating semantic features with expert features
    for defect prediction and localization. In *Proceedings of the 30th ACM Joint
    European Software Engineering Conference and Symposium on the Foundations of Software
    Engineering*. 672–683.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nong et al. (2022) Yu Nong, Rainy Sharma, Abdelwahab Hamou-Lhadj, Xiapu Luo,
    and Haipeng Cai. 2022. Open Science in Software Engineering: A Study on Deep Learning-Based
    Vulnerability Detection. *IEEE Transactions on Software Engineering* (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pang et al. (2015) Yulei Pang, Xiaozhen Xue, and Akbar Siami Namin. 2015. Predicting
    vulnerable software components through n-gram analysis and statistical feature
    selection. In *2015 IEEE 14th International Conference on Machine Learning and
    Applications (ICMLA)*. IEEE, 543–548.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pascarella et al. (2019) Luca Pascarella, Fabio Palomba, and Alberto Bacchelli.
    2019. Fine-grained just-in-time defect prediction. *Journal of Systems and Software*
    150 (2019), 22–36.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Perl et al. (2015) Henning Perl, Sergej Dechand, Matthew Smith, Daniel Arp,
    Fabian Yamaguchi, Konrad Rieck, Sascha Fahl, and Yasemin Acar. 2015. Vccfinder:
    Finding potential vulnerabilities in open-source projects to assist code audits.
    In *Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications
    Security*. 426–437.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Petersen et al. (2015) Kai Petersen, Sairam Vakkalanka, and Ludwik Kuzniarz.
    2015. Guidelines for conducting systematic mapping studies in software engineering:
    An update. *Information and software technology* 64 (2015), 1–18.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phan et al. (2017) Anh Viet Phan, Minh Le Nguyen, and Lam Thu Bui. 2017. Convolutional
    neural networks over control flow graphs for software defect prediction. In *2017
    IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)*.
    IEEE, 45–52.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Piantadosi et al. (2019) Valentina Piantadosi, Simone Scalabrino, and Rocco
    Oliveto. 2019. Fixing of security vulnerabilities in open source projects: A case
    study of apache http server and apache tomcat. In *2019 12th IEEE Conference on
    software testing, validation and verification (ICST)*. IEEE, 68–78.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pradel and Sen (2018) Michael Pradel and Koushik Sen. 2018. Deepbugs: A learning
    approach to name-based bug detection. *Proceedings of the ACM on Programming Languages*
    2, OOPSLA (2018), 1–25.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raza and Ahmed (2022) Ali Raza and Waseem Ahmed. 2022. Threat and Vulnerability
    management life cycle in operating systems. A systematic review. *Journal of Multidisciplinary
    Engineering Science and Technology (JMEST)* 9, 1 (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Riom et al. (2021) Timothé Riom, Arthur Sawadogo, Kevin Allix, Tegawendé F Bissyandé,
    Naouel Moha, and Jacques Klein. 2021. Revisiting the VCCFinder approach for the
    identification of vulnerability-contributing commits. *Empirical Software Engineering*
    26, 3 (2021), 1–30.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ruospo et al. (2020) Annachiara Ruospo, Alberto Bosio, Alessandro Ianne, and
    Ernesto Sanchez. 2020. Evaluating convolutional neural networks reliability depending
    on their data representation. In *2020 23rd Euromicro Conference on Digital System
    Design (DSD)*. IEEE, 672–679.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Russell et al. (2018) Rebecca Russell, Louis Kim, Lei Hamilton, Tomo Lazovich,
    Jacob Harer, Onur Ozdemir, Paul Ellingwood, and Marc McConley. 2018. Automated
    vulnerability detection in source code using deep representation learning. In
    *2018 17th IEEE international conference on machine learning and applications
    (ICMLA)*. IEEE, 757–762.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sabetta and Bezzi (2018) Antonino Sabetta and Michele Bezzi. 2018. A practical
    approach to the automatic classification of security-relevant commits. In *2018
    IEEE International conference on software maintenance and evolution (ICSME)*.
    IEEE, 579–582.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scandariato et al. (2014) Riccardo Scandariato, James Walden, Aram Hovsepyan,
    and Wouter Joosen. 2014. Predicting vulnerable software components via text mining.
    *IEEE Transactions on Software Engineering* 40, 10 (2014), 993–1006.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semasaba et al. (2020) Abubakar Omari Abdallah Semasaba, Wei Zheng, Xiaoxue
    Wu, and Samuel Akwasi Agyemang. 2020. Literature survey of deep learning-based
    vulnerability analysis on source code. *IET Software* 14, 6 (2020), 654–664.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shar and Tan (2010) Lwin Khin Shar and Hee Beng Kuan Tan. 2010. Auditing the
    defense against cross site scripting in web applications. In *2010 International
    Conference on Security and Cryptography (SECRYPT)*. IEEE, 1–7.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shar and Tan (2012) Lwin Khin Shar and Hee Beng Kuan Tan. 2012. Auditing the
    XSS defence features implemented in web application programs. *IET software* 6,
    4 (2012), 377–390.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shippey et al. (2019) Thomas Shippey, David Bowes, and Tracy Hall. 2019. Automatically
    identifying code features for software defect prediction: Using AST N-grams. *Information
    and Software Technology* 106 (2019), 142–160.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SpotBugs. (2021) SpotBugs. 2021. *SpotBugs*. [.https://spotbugs.github.io/](.https://spotbugs.github.io/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Staron et al. (2020) Miroslaw Staron, Mirosław Ochodek, Wilhelm Meding, and
    Ola Söder. 2020. Using machine learning to identify code fragments for manual
    review. In *2020 46th Euromicro Conference on Software Engineering and Advanced
    Applications (SEAA)*. IEEE, 513–516.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Suciu et al. (2022) Octavian Suciu, Connor Nelson, Zhuoer Lyu, Tiffany Bao,
    and Tudor Dumitraș. 2022. Expected exploitability: Predicting the development
    of functional vulnerability exploits. In *31st USENIX Security Symposium (USENIX
    Security 22)*. 377–394.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2018) Nan Sun, Jun Zhang, Paul Rimba, Shang Gao, Leo Yu Zhang,
    and Yang Xiang. 2018. Data-driven cybersecurity incident prediction: A survey.
    *IEEE communications surveys & tutorials* 21, 2 (2018), 1744–1772.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tan et al. (2020) Youshuai Tan, Sijie Xu, Zhaowei Wang, Tao Zhang, Zhou Xu,
    and Xiapu Luo. 2020. Bug severity prediction using question-and-answer pairs from
    Stack Overflow. *Journal of Systems and Software* 165 (2020), 110567.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tian et al. (2020) Junfeng Tian, Wenjing Xing, and Zhen Li. 2020. BVDetector:
    A program slice-based binary code vulnerability intelligent detection system.
    *Information and Software Technology* 123 (2020), 106289.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Walkowski et al. (2021) Michał Walkowski, Jacek Oko, and Sławomir Sujecki. 2021.
    Vulnerability Management Models Using a Common Vulnerability Scoring System. *Applied
    Sciences* 11, 18 (2021), 8735.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2020) Huanting Wang, Guixin Ye, Zhanyong Tang, Shin Hwei Tan, Songfang
    Huang, Dingyi Fang, Yansong Feng, Lizhong Bian, and Zheng Wang. 2020. Combining
    graph-based learning with automated data collection for code vulnerability detection.
    *IEEE Transactions on Information Forensics and Security* 16 (2020), 1943–1958.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2018) Song Wang, Taiyue Liu, Jaechang Nam, and Lin Tan. 2018. Deep
    semantic feature learning for software defect prediction. *IEEE Transactions on
    Software Engineering* 46, 12 (2018), 1267–1293.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2016) Song Wang, Taiyue Liu, and Lin Tan. 2016. Automatically learning
    semantic features for defect prediction. In *2016 IEEE/ACM 38th International
    Conference on Software Engineering (ICSE)*. IEEE, 297–308.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wheeler (2013) David A. Wheeler. 2013. *Dlawfinder*. [http://dwheeler.com/flawfinder/](http://dwheeler.com/flawfinder/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2021) Hongjun Wu, Zhuo Zhang, Shangwen Wang, Yan Lei, Bo Lin, Yihao
    Qin, Haoyu Zhang, and Xiaoguang Mao. 2021. Peculiar: Smart Contract Vulnerability
    Detection Based on Crucial Data Flow Graph and Pre-training Techniques. In *2021
    IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE).
    IEEE*. 378–389.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xia et al. (2023) Chunqiu Steven Xia, Yuxiang Wei, and Lingming Zhang. 2023.
    Automated program repair in the era of large pre-trained language models. In *Proceedings
    of the 45th International Conference on Software Engineering (ICSE 2023). Association
    for Computing Machinery*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yamaguchi et al. (2012) Fabian Yamaguchi, Markus Lottmann, and Konrad Rieck.
    2012. Generalized vulnerability extrapolation using abstract syntax trees. In
    *Proceedings of the 28th Annual Computer Security Applications Conference*. 359–368.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yamaguchi et al. (2011) Fabian Yamaguchi, Konrad Rieck, et al. 2011. Vulnerability
    extrapolation: Assisted discovery of vulnerabilities using machine learning. In
    *5th USENIX Workshop on Offensive Technologies (WOOT 11)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yamaguchi et al. (2013) Fabian Yamaguchi, Christian Wressnegger, Hugo Gascon,
    and Konrad Rieck. 2013. Chucky: Exposing missing checks in source code for vulnerability
    discovery. In *Proceedings of the 2013 ACM SIGSAC conference on Computer & communications
    security*. 499–510.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yan et al. (2021) Han Yan, Senlin Luo, Limin Pan, and Yifei Zhang. 2021. HAN-BSVD:
    a hierarchical attention network for binary software vulnerability detection.
    *Computers & Security* 108 (2021), 102286.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2022) Hongyu Yang, Haiyun Yang, Liang Zhang, and Xiang Cheng. 2022.
    Source Code Vulnerability Detection Using Vulnerability Dependency Representation
    Graph. In *2022 IEEE International Conference on Trust, Security and Privacy in
    Computing and Communications (TrustCom)*. IEEE, 457–464.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2017) Limin Yang, Xiangxue Li, and Yu Yu. 2017. Vuldigger: A just-in-time
    and cost-aware tool for digging vulnerability-contributing changes. In *GLOBECOM
    2017-2017 IEEE Global Communications Conference*. IEEE, 1–7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yin et al. (2022) Jiao Yin, MingJian Tang, Jinli Cao, Hua Wang, and Mingshan
    You. 2022. A real-time dynamic concept adaptive learning algorithm for exploitability
    prediction. *Neurocomputing* 472 (2022), 252–265.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yong and Horwitz (2005) Suan Hsi Yong and Susan Horwitz. 2005. Using static
    analysis to reduce dynamic analysis overhead. *Formal Methods in System Design*
    27 (2005), 313–334.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zeng et al. (2021) Cheng Zeng, Chun Ying Zhou, Sheng Kai Lv, Peng He, and Jie
    Huang. 2021. GCN2defect: Graph Convolutional Networks for SMOTETomek-based Software
    Defect Prediction. In *2021 IEEE 32nd International Symposium on Software Reliability
    Engineering (ISSRE)*. IEEE, 69–79.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zeng et al. (2020) Peng Zeng, Guanjun Lin, Lei Pan, Yonghang Tai, and Jun Zhang.
    2020. Software vulnerability analysis and discovery using deep learning techniques:
    A survey. *IEEE Access* 8 (2020), 197158–197172.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2022) Zhuo Zhang, Yan Lei, Meng Yan, Yue Yu, Jiachi Chen, Shangwen
    Wang, and Xiaoguang Mao. 2022. Reentrancy Vulnerability Detection and Localization:
    A Deep Learning Based Two-phase Approach. In *37th IEEE/ACM International Conference
    on Automated Software Engineering*. 1–13.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zheng et al. (2021) Weining Zheng, Yuan Jiang, and Xiaohong Su. 2021. VulSPG:
    Vulnerability detection based on slice property graph representation learning.
    *arXiv preprint arXiv:2109.02527* (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2019) Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, and
    Yang Liu. 2019. Devign: Effective vulnerability identification by learning comprehensive
    program semantics via graph neural networks. *Advances in neural information processing
    systems* 32 (2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou and Sharma (2017) Yaqin Zhou and Asankhaya Sharma. 2017. Automated identification
    of security issues from commit messages and bug reports. In *Proceedings of the
    2017 11th joint meeting on foundations of software engineering*. 914–919.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhuang et al. (2022) Weiyuan Zhuang, Hao Wang, and Xiaofang Zhang. 2022. Just-in-time
    defect prediction based on AST change embedding. *Knowledge-Based Systems* 248
    (2022), 108852.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhuang et al. (2020) Yuan Zhuang, Zhenguang Liu, Peng Qian, Qi Liu, Xiang Wang,
    and Qinming He. 2020. Smart Contract Vulnerability Detection using Graph Neural
    Network.. In *IJCAI*. 3283–3290.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ziems and Wu (2021) Noah Ziems and Shaoen Wu. 2021. Security Vulnerability Detection
    Using Deep Learning Natural Language Processing. In *IEEE INFOCOM 2021-IEEE Conference
    on Computer Communications Workshops (INFOCOM WKSHPS)*. IEEE, 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zou et al. (2022) Deqing Zou, Yutao Hu, Wenke Li, Yueming Wu, Haojun Zhao,
    and Hai Jin. 2022. mVulPreter: A Multi-Granularity Vulnerability Detection System
    With Interpretations. *IEEE Transactions on Dependable and Secure Computing* (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zou et al. (2019) Deqing Zou, Sujuan Wang, Shouhuai Xu, Zhen Li, and Hai Jin.
    2019. muVulDeePecker: A Deep Learning-Based System for Multiclass Vulnerability
    Detection. *IEEE Transactions on Dependable and Secure Computing* 18, 5 (2019),
    2224–2236.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zou et al. (2021) Deqing Zou, Yawei Zhu, Shouhuai Xu, Zhen Li, Hai Jin, and
    Hengkai Ye. 2021. Interpreting Deep Learning-Based Vulnerability Detector Predictions
    Based on Heuristic Searching. 30, 2, Article 23 (mar 2021), 31 pages. [https://doi.org/10.1145/3429444](https://doi.org/10.1145/3429444)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
