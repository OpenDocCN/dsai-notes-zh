- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:37:01'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2309.04761] A Comprehensive Survey on Deep Learning Techniques in Educational
    Data Mining'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2309.04761](https://ar5iv.labs.arxiv.org/html/2309.04761)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[style=chinese] \fnmark[1]'
  prefs: []
  type: TYPE_NORMAL
- en: '[style=chinese] \fnmark[1]'
  prefs: []
  type: TYPE_NORMAL
- en: '[style=chinese]'
  prefs: []
  type: TYPE_NORMAL
- en: '[style=chinese] \cormark[1]'
  prefs: []
  type: TYPE_NORMAL
- en: '[style=chinese] \cormark[1]'
  prefs: []
  type: TYPE_NORMAL
- en: \fntext
  prefs: []
  type: TYPE_NORMAL
- en: '[1]Co-first authors \cortext[1]Corresponding author'
  prefs: []
  type: TYPE_NORMAL
- en: A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Yuanguo Lin xdlyg@jmu.edu.cn    Hong Chen zoharchen30@gmail.com    Wei Xia xiawei24@huawei.com
       Fan Lin iamafan@xmu.edu.cn    Zongyue Wang wangzongyue@jmu.edu.cn    Yong Liu
    stephenliu@ntu.edu.sg School of Computer Engineering, Jimei University, Xiamen,
    China School of Informatics, Xiamen University, Xiamen, China Pingtan Research
    Institute of Xiamen University, Fuzhou, China Huawei Noah’s Ark Lab, Shenzhen,
    China Huawei Noah’s Ark Lab, Singapore
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Educational Data Mining (EDM) has emerged as a vital field of research, which
    harnesses the power of computational techniques to analyze educational data. With
    the increasing complexity and diversity of educational data, Deep Learning techniques
    have shown significant advantages in addressing the challenges associated with
    analyzing and modeling this data. This survey aims to systematically review the
    state-of-the-art in EDM with Deep Learning. We begin by providing a brief introduction
    to EDM and Deep Learning, highlighting their relevance in the context of modern
    education. Next, we present a detailed review of Deep Learning techniques applied
    in four typical educational scenarios, including knowledge tracing, student behavior
    detection, performance prediction, and personalized recommendation. Furthermore,
    a comprehensive overview of public datasets and processing tools for EDM is provided.
    Finally, we point out emerging trends and future directions in this research area.
  prefs: []
  type: TYPE_NORMAL
- en: 'keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Educational data mining \sepDeep learning \sepReinforcement learning \sepEducational
    datasets
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Deep Learning has experienced remarkable advancements in recent years, revolutionizing
    diverse domains, including education. Deep Learning, a form of machine learning,
    relies on artificial neural networks to facilitate the discovery of hierarchical
    features, which enhances the ability to recognize patterns [[42](#bib.bib42)].
    In contrast to conventional machine learning approaches that require manual feature
    engineering, Deep Learning allows a machine to automatically discover intricate
    structures in large data by using multiple layers of abstraction. This layered
    feature learning process enables Deep Learning models to learn complicated patterns
    in data and achieve state-of-the-art performance across domains such as speech
    recognition [[44](#bib.bib44)], image classification [[104](#bib.bib104)], and
    natural language processing [[42](#bib.bib42)]. In general, three primary categories
    of algorithms exist in the domain of Deep Learning: supervised learning, unsupervised
    learning, and reinforcement learning [[67](#bib.bib67)]. Applying Deep Learning
    algorithms suitable for different application scenarios can greatly increase their
    performance. With increasing computing power, Deep Learning has achieved major
    breakthroughs and outstanding results in many fields.'
  prefs: []
  type: TYPE_NORMAL
- en: Education fields have been revolutionized by traditional machine learning and
    Deep Learning algorithms, and exploring previous research is key to understanding
    its applications. There are two main terms which are currently used in education,
    Educational Data Mining (EDM) and Learning Analytics (LA) [[87](#bib.bib87)].
    These two fields are typically interdisciplinary, including but not limited to
    information retrieval, data analysis, psycho-pedagogy, cognitive psychology, etc.
    EDM encompasses computerized techniques and tools that facilitate the automated
    identification and extraction of meaningful patterns and valuable information
    from extensive datasets obtained within educational settings [[41](#bib.bib41),
    [21](#bib.bib21)]. On the other hand, LA involves the systematic gathering, examination,
    and presentation of data pertaining to learners and their learning environments
    [[96](#bib.bib96)].
  prefs: []
  type: TYPE_NORMAL
- en: In fact, researchers have also utilized diverse traditional machine learning
    algorithms for educational data mining across varied educational contexts [[45](#bib.bib45)].
    For instance, the TLBO-ML model [[6](#bib.bib6)] constructed by Artificial Neural
    Network (ANN) and Support Vector Machine (SVM) can be used to predict grades of
    students in final exam. However, the traditional machine learning algorithms come
    with certain limitations. These conventional models often rely on manual feature
    engineering, necessitating expert knowledge in the field to design effective features.
    This process can be laborious and time-consuming. Besides, handling the complex
    and high-dimensional data, such as natural language text and multimedia content
    that are prevalent in educational settings, can pose challenges for traditional
    machine learning methods.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating Deep Learning into educational scenarios is driven by the aspiration
    to harness the potential of Artificial Intelligence and machine learning, thereby
    enriching the teaching and learning experience [[42](#bib.bib42), [33](#bib.bib33)].
    Deep Learning models possess remarkable capabilities, enabling them to effectively
    process and analyze vast amounts of educational data. By uncovering meaningful
    patterns and making accurate predictions, these models provide valuable insights
    that can inform and enhance educational practices [[97](#bib.bib97), [99](#bib.bib99),
    [88](#bib.bib88)]. Educators and researchers can leverage these insights to adapt
    teaching strategies, personalize instruction, and optimize learning outcomes.
    By harnessing the power of Deep Learning, the educational community can unlock
    new opportunities for improved efficiency, effectiveness, and adaptability in
    education through intelligent data processing and adaptive methodologies [[79](#bib.bib79)].
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, Deep Learning has also made significant achievements in completing
    specific scenario tasks in EDM. Currently, EDM scenarios are often divided into:
    knowledge tracing, student behavior detection, performance prediction, and personalized
    recommendation. Each subfield has distinct specific data input patterns and task
    requirements. Deep Learning based knowledge tracing algorithms can be classified
    into Deep Knowledge Tracking (DKT) and its variants, *e.g.*, DKT based on Memory
    networks, Attention mechanisms and Graph structures [[97](#bib.bib97)]. Complex
    neural network models can be applied to Student Dropout Prediction (SDP), which
    is a task of student behavior detection [[81](#bib.bib81)]. Similarly, neural
    networks can also provide quite reliable accuracy in the EDM scenario of performance
    prediction [[85](#bib.bib85)]. In the field of personalized recommendation, hybrid
    techniques-based recommendation algorithms may be gradually taking the dominant
    position, but the emerging privacy issues also need close attention [[37](#bib.bib37)].'
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning techniques offer numerous advantages over traditional machine
    learning methods when applied in educational scenarios. One notable advantage
    is the automatic learning of hierarchical representations from raw data, eliminating
    the need for manual feature engineering. This characteristic makes Deep Learning
    models highly suitable for analyzing various types of educational data, including
    student performance data, educational videos, and text-based learning materials.
    The capability of Deep Learning models to detect complex connections and intricate
    patterns within the data leads to more accurate predictions and personalized recommendations.
    A telling difference is shown by a research [[33](#bib.bib33)] that approximate
    67% of papers report Deep Learning demonstrated superior performance compared
    to the ”traditional” machine learning baselines in all conducted experiments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data Collection Methodology. Followings are rules we applied to include or
    exclude papers:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Search terms: Deep Learning and Educational Data Mining are the two keywords
    mainly involved in our survey. In order to access more related publications, we
    also used specific educational scenarios as our search terms (*e.g.*, knowledge
    tracing, performance prediction etc.).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Search Sources: We searched for articles containing the above keywords through
    Google Scholar and downloaded the articles that matched the requirements from
    the corresponding major databases.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The articles we have studied include only high-level publications from international
    conferences and top journals based on the application of Deep Learning to educational
    scenarios.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We plotted the collected papers according to their publication years and corresponding
    application scenarios as shown in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣
    A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining"),
    and to ensure the frontiers of research, it can be seen that EDM based on Deep
    Learning has emerged since 2018.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2d3a99c24a079571307898f256d2752a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Distribution of year-wise publications (until 2023) according to
    different educational scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: Related Work. Ahmad et al. [[2](#bib.bib2)] examine the application of artificial
    intelligence in Educational Data Mining, specifically focusing on the use of standard
    machine learning techniques for student assessment and prediction. Besides, Sun
    et al. [[100](#bib.bib100)] explore the application of deep learning in MOOCs
    for dropout prediction, focusing on the trends in using deep learning techniques,
    including feature processing and model design. Zhang et al. [[126](#bib.bib126)]
    also provide an overview of the educational data field, covering a range of classic
    Deep Learning models such as Stacked Auto-Encoder (SAE), Deep Belief Network (DBN),
    and various Deep Neural Networks (DNN). It further investigates distinct Deep
    Learning techniques tailored for different types of educational data, including
    large-scale, heterogeneous, real-time, and low-quality data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our Contribution. This survey encompasses a diverse collection of state-of-the-art
    studies that categorize Deep Learning algorithms based on their application in
    educational settings. The articles are classified into three types: supervised
    learning, unsupervised learning, and reinforcement learning. Furthermore, the
    articles are further categorized based on the specific educational scenarios where
    Deep Learning techniques are employed. These scenarios encompass knowledge tracing,
    student behavior detection, performance prediction, and personalized recommendation.
    By adopting this systematic approach, we provides a structured and in-depth analysis
    of the wide range of research conducted on the intersection of Deep Learning and
    education.'
  prefs: []
  type: TYPE_NORMAL
- en: This survey not only summarizes the latest Deep Learning algorithms, but also
    includes a discussion of relevant datasets and data tools. By including a comprehensive
    analysis of datasets and data tools, the main objective of this survey is to offer
    the reader a thorough understanding of the considerations and challenges when
    implementing Deep Learning solutions in EDM. Furthermore, we put forward some
    promising areas for further research in Deep Learning-based EDM. The potential
    directions contain learning analysis and intervention, social network analysis
    and collaboration, explainable AI in EDM, Large Language Models for education,
    multimodal learning analytics, benchmark datasets and evaluation metrics, fairness
    and privacy.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, the application of Deep Learning to education has the potential
    to revolutionize the way traditional teaching and learning. By leveraging the
    benefits of Deep Learning, educators can gain valuable insights, make data-based
    decisions, and create personalized learning experiences. This survey aims to provide
    an integrate overview of Deep Learning applications in education, covering various
    algorithms and educational scenarios while considering the available datasets
    and data tools.
  prefs: []
  type: TYPE_NORMAL
- en: 2 Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In recent years, Deep Learning has emerged as a state-of-the-art technology
    that can be applied to various fields.
  prefs: []
  type: TYPE_NORMAL
- en: The ability of neural networks to extract higher-level abstract features by
    learning the features of data has made Deep Learning a highly successful method.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning is a technology derived from machine learning. It mimics the structure
    and working mode of the human brain neural network. It realizes the recognition
    and classification tasks through model training. Compared to conventional machine
    learning algorithms, Deep Learning is able to handle more complicated tasks and
    datasets which brings a higher performance and generalization abilities.
  prefs: []
  type: TYPE_NORMAL
- en: The development of Deep Learning has gone through many stages, from the initial
    DBN [[34](#bib.bib34)] to the subsequent emerging Multilayer Perceptron (MLP),
    Convolutional Neural Network (CNN), Recurrent Neural Networks (RNN), etc, which
    have led to the Deep Learning that we care about and use today. With the progress
    of Deep Learning algorithms and computing power, Deep Learning has been widely
    applied to areas such as image recognition, speech recognition, and so on. In
    this survey, we will mainly focus on the Deep Learning algorithms that contribute
    to educational scenarios like course recommendation, student behavior detection
    and knowledge tracing.
  prefs: []
  type: TYPE_NORMAL
- en: 'We divide those models into three parts according to the current mainstream
    classification method: supervised learning, unsupervised learning and reinforcement
    learning [[4](#bib.bib4)].'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Supervised Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Supervised learning usually refers to those models which apply labeled data
    for training process. These data can be used to train supervised learning models
    to establish mappings between inputs and outputs and predict the result of the
    new unlabeled data.
  prefs: []
  type: TYPE_NORMAL
- en: CNN stands as a representative example of Deep Learning models which be widely
    used in computer vision and image process fields. The theory of CNN is to extract
    feature and reduce the dimension of the image through convolution and pooling
    operations. Finally, the high-dimensional image is converted into the one-dimensional
    vector data which can be used for the classification and regression tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The difference between CNN and other neural networks is the former applies
    convoluted layer to extract features as the following formula [[4](#bib.bib4)]:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $h^{k}=f(W^{k}*x+b^{k})$ |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: where $h^{k}$ refers to the feature map generated by $k_{th}$ convoluted kernel,
    $W^{k}$ represents the weight of $k_{th}$ convoluted kernel, $b^{k}$ is the corresponding
    bias term and $f(\cdot)$ stands for activation function. CNN has been applied
    for knowledge tracing. A model called Deep Knowledge Tracing based on Spatial
    and Temporal Deep Representation Learning for Learning Performance Prediction
    (DKT-STDRL) proposed by Lyu et al. [[63](#bib.bib63)]. In this model, CNN plays
    the role of extracting the spatial features information from students’ exercise
    sequences.
  prefs: []
  type: TYPE_NORMAL
- en: 'RNN is primarily employed for handling sequential data, such as text and speech,
    in various applications. The neural nodes of RNN are able to receive the former
    status information to realize the memorability. The special property allows RNN
    to be applied to knowledge tracing, student behaviors detection and similar educational
    scenarios. The following is a basic RNN equation for it to be able to implement
    cycling:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $h_{t}=\sigma(W_{ih}x_{t}+W_{hh}h_{t-1}+b_{h}),$ |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: where $x_{t}$ refers to the input vector, The $h_{t}$ is the hidden state vector,
    $W_{ih}$ and $W_{hh}$ are the weight matrices connecting the input to the hidden
    state and the hidden state to the hidden state, $b_{h}$ is the bias vector, and
    $\sigma$ is a nonlinear activation function.
  prefs: []
  type: TYPE_NORMAL
- en: Fig. [2](#S2.F2 "Figure 2 ‣ 2.1 Supervised Learning ‣ 2 Methodology ‣ A Comprehensive
    Survey on Deep Learning Techniques in Educational Data Mining") simply shows the
    work process of RNN. Based on that, a Deep Knowledge Tracing model (DKT) implemented
    with RNN was proposed by Piech et al. [[80](#bib.bib80)] This DKT model employs
    a significant number of artificial neuron vectors to represent potential knowledge
    states and temporal dynamics.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/13a2d4a0f09ad6a6165ebe17ac9229b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The process of Recurrent Neural Network [[80](#bib.bib80)], taking
    knowledge tracing as an example.'
  prefs: []
  type: TYPE_NORMAL
- en: Long Short-Term Memory (LSTM) [[35](#bib.bib35)] is a special RNN that contains
    three gate units and a memory cell. The memory and processing of sequential data
    are realized through the control of information flow by gated units. Importantly,
    the design of LSTM, with its gates and cell states, addresses the gradient vanishing
    problem more effectively than conventional RNNs. This is achieved by allowing
    gradients to flow through the network with less restriction, thereby preserving
    the necessary information over longer sequences. The forgetting gate is a key
    component in LSTM to control whether the previous moment’s memory cell state is
    forgotten, shown in Eq. [3](#S2.E3 "In 2.1 Supervised Learning ‣ 2 Methodology
    ‣ A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining").
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $f_{t}=\sigma(W_{f}\cdot[h_{t-1},x_{t}]+b_{f}),$ |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: where $f_{t}$ denotes the state of the forgotten gate, $W_{f}$ is the weight
    matrix, $[h_{t-1},x_{t}]$ denotes the connection between the output from the previous
    moment and the input from the current moment, $b_{f}$ is the bias vector, and
    $\sigma$ is the sigmoid function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Graph Neural Network (GNN) [[115](#bib.bib115)] is a Deep Learning model used
    to process graph structure data (*e.g.*, Knowledge Graph). Building on this, GNNs
    are particularly adept at discerning intricate patterns and dependencies within
    the graph, enabling more precise and context-aware course recommendations [[112](#bib.bib112)].
    Take Recurrent GNN as an example, the recurrently update formula of a node’s hidden
    state can be defined by [[116](#bib.bib116)]:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{h}^{(t)}_{v}=\sum_{u\in N(v)}f(\mathbf{X}_{v},\mathbf{X}_{(v,u)}^{\mathbf{e}},\mathbf{X}_{u},\mathbf{h}_{u}^{(t-1)}),$
    |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: where $f$ represents the parametric function and $\mathbf{h}_{u}^{(t-1)}$ is
    initialized randomly. $\mathbf{X}_{v}$ refers to feature vector of node $v$, $\mathbf{X}_{(v,u)}^{\mathbf{e}}$
    denotes edge vector of node $(v,u)$.
  prefs: []
  type: TYPE_NORMAL
- en: Because of its excellent graph structure processing capability, GNN has been
    used by the Knowledge Augmented User Representation (KAUR) [[65](#bib.bib65)]
    model to obtain the initial representation of a specific node within the Collaborative
    Knowledge Graph (CKG), for the message aggregation and propagation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Attention is mainly used to enhance the model’s focus and understanding of
    key information. The core idea is to assign weights to different parts of the
    input according to task requirements, allowing the model to selectively focus
    on specific information [[53](#bib.bib53)]. The typical Self-Attention mechanism
    can be expressed by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{Attention}(Q,K,V)=\text{Softmax}(\frac{QK^{T}}{\sqrt{d_{k}}})V,$
    |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: where $Q$ means a matrix packaged from queries, $K$ refers to the key, $V$ means
    value, and $d_{k}$ is the key dimension. By calculating the similarity between
    the query and the key and normalizing it, the Attention weight distribution is
    calculated and ultimately used to weight the sum values to obtain the final representation.
    Attention-based networks [[106](#bib.bib106)], dispensing with recurrence and
    convolutions operation. It can be trained in parallel and achieve better performance.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Unsupervised Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unsupervised learning’s aptitude for handling unlabeled data empowers it to
    uncover latent patterns in student behavior and learning processes. While algorithms
    like Generative Adversarial Networks and Autoencoders are not commonly employed
    in education, they still hold promise for enhancing educational insights by extracting
    valuable information from unlabeled data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generative Adversarial Network (GAN) is a combination of generator neural network
    and discrimination neural network. The target of GAN is to learn and generate
    samples that resemble real data, and with a high degree of diversity. The loss
    function of the discriminator is listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}L_{D}&amp;=-[\log(D(x))+\log(1-D(G(z)))]\\ L_{G}&amp;=-\log(D(G(z))),\end{split}$
    |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: where $x$ denotes real samples, $D(x)$ is the output of discriminator towards
    real sample, $G(z)$ is the sample generated by generator and $1-D(G(z))$ is the
    output of discriminator towards generative samples. Similarly, the lost function
    of the generator is as follows, $z$ is a random sample get from noise distribution,
    $G(z)$ is the sample generated by the generator, and $D(x)$ is the output of the
    discriminator towards sample $x$.
  prefs: []
  type: TYPE_NORMAL
- en: The most common use of GAN in education scenarios is a personalized recommendation
    because of its ability to generate samples. For instance, a Recurrent Generative
    Adversarial Network (RecGAN) that leverages tailored GRU to obtain latent features
    of users and items from short/long-term temporal profiles was introduced by Bharadhwaj
    et al. [[9](#bib.bib9)]. By evaluation, this method has improved the relevance
    of recommended items.
  prefs: []
  type: TYPE_NORMAL
- en: 'AutoEncoders (AEs) are neural networks used for unsupervised learning, focusing
    on encoding and then reconstructing input data. The key formula involves two parts [[121](#bib.bib121)]:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}&amp;\text{Encoder:}z=f(x)\\ &amp;\text{Decoder:}\hat{x}=g(z),\end{split}$
    |  | (7) |'
  prefs: []
  type: TYPE_TB
- en: where $x$ is the input, $z$ represents the encoded representation, $\hat{x}$
    stands for the reconstructed output, $f(\cdot)$ represents the encoding function,
    and $g(\cdot)$ is the decoding function. The aim is to minimize the difference
    between $x$ and $\hat{x}$, enhancing data compression and feature learning capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Reinforcement Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In contrast to supervised and unsupervised learning, the training data used
    in reinforcement learning is traditionally generated through the interaction of
    an agent with its environment. Therefore, reinforcement learning is suitable for
    personalized recommendation, which can be considered as an intelligent tutoring
    task. It allows the model to interact dynamically and continuously adjust recommendation
    strategies to maximize long-term rewards. It can optimize recommendation effectiveness
    based on real-time user feedback.
  prefs: []
  type: TYPE_NORMAL
- en: In reinforcement learning [[128](#bib.bib128)], an agent takes a specific action
    by observing the state of the environment and evaluates its behavior based on
    the reward or punishment given by the environment. The goal of the agent is to
    optimize the cumulative reward. Generally, the reinforcement learning algorithms
    can be divided into the following three styles.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.1 Value Function Approach
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Value function approach refers to the algorithm’s ability to achieve the global
    optimal payoff by obtaining the best action. That is, the optimal gain is produced
    through the optimal action $a^{*}$ under the optimal strategy $\pi^{*}$. This
    strategy can be represented by the Bellman optimality equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}v^{*}_{\pi}(s)\ =\ &amp;\underset{a}{\text{max}}\ \mathbb{E}[R_{t+1}+\gamma
    v^{*}_{\pi}(S_{t}+1)&#124;S_{t}=s,A_{t}=a]\\ =\ &amp;\underset{a}{\text{max}}\sum_{s^{\prime},r}p(s^{\prime},r&#124;s,a)[r+\gamma
    v^{*}_{\pi}(s^{\prime})],\end{split}$ |  | (8) |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbb{E[\cdot]}$ denotes the expectation of the reward $R_{t+1}$ and
    value function $\gamma v^{*}_{\pi}(S_{t}+1)$ for the next state in the case of
    the current state $s$ and taking action $a$.
  prefs: []
  type: TYPE_NORMAL
- en: The ability of the value function to take into account long-term benefits allows
    the model to make more informed decisions, not just localized immediate rewards.
    However, the solution of certain value function methods may take a longer time
    to reach convergence. Especially in complex environments or large-scale problems,
    more iterations and samples may be required to obtain accurate value function
    estimates and optimal strategies.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.2 Policy Search Method
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The policy search method maximizes the expected return in a direct optimization
    of strategies that are influenced by a set of policy parameters $\theta_{t}$.
    As an example, the gradient-based policy search method uses the Gradient Ascent
    method, which maximizes the strategy performance $J$ with respect to the parameter
    $\theta$ by iteratively updating the strategy parameters, and the equation can
    be simply expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\theta_{t+1}\ =\ \theta_{t}+\alpha\nabla J(\theta),$ |  | (9) |'
  prefs: []
  type: TYPE_TB
- en: where $\theta_{t+1}$ refers to the parameter of policy at time $t+1$, $\nabla
    J(\theta)$ is the gradient of $\theta_{t}$-based policy’s performance. $\alpha$
    is a learning rate that controls the step size of each parameter update.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to gradient-based policy search algorithms, there is a Monte Carlo
    policy gradient-based method called REINFORCE for optimizing policies in reinforcement
    learning. It estimates the policy gradient by Monte Carlo sampling and uses the
    gradient ascent method to update the policy parameters. Specifically, the REINFORCE
    algorithm can be implemented by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\nabla J(\theta)\ &amp;\propto\ \sum_{s}\mu(s)\sum_{a}\nabla_{\theta}\pi(a&#124;s,\theta)q_{\pi}(s,a)\\
    &amp;\doteq\ \mathbb{E}_{\pi}\left[\sum_{a}\nabla_{\theta}\pi(a&#124;S_{t},\theta)q_{\pi}(S_{t},a)\right],\end{split}$
    |  | (10) |'
  prefs: []
  type: TYPE_TB
- en: where $\propto$ denotes "be proportional to", $\mu(s)$ is called "on-policy"
    under the policy $\pi$. $q_{\pi}(s,a)$ refers to the value function of policy
    $\pi$ choosing action $a$ in state $s$.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.3 Actor-Critic Algorithm
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Actor-Critic algorithm is a reinforcement learning algorithm for solving
    the problem of learning optimal policies in unknown environments. The core idea
    of the Actor-Critic algorithm is to guide Actor’s policy improvement through the
    estimation of value functions provided by the Critic, which in turn estimates
    the value of a state or state action pair based on the current policy and environment
    interaction data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take one-step Actor-Critic algorithm as an example, the equation of $\theta$
    update can be expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  $\theta_{t+1}\doteq\theta_{t}+\alpha(R_{t+1}+\gamma\hat{v}(S_{t+1},w)-\hat{v}(S_{t},w))\frac{\nabla_{\theta}\pi(A_{t}&#124;S_{t},\theta_{t})}{\pi(A_{t}&#124;S_{t},\theta_{t})},$  |  |
    (11) |'
  prefs: []
  type: TYPE_TB
- en: where $R_{t+1}$ denotes the reward at time $t+1$, $\gamma$ is the discount factor
    that controls the importance of future rewards, and $\hat{v}(S_{t},w)$ refers
    to the state value function learned by the Critic and will be used as baseline.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Educational Scenarios and Corresponding Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To provide a comprehensive overview of the literature on Deep Learning for different
    application scenarios, we have included information on the algorithms and models
    used in each paper for four educational scenarios in Table [1](#S3.T1 "Table 1
    ‣ 3 Educational Scenarios and Corresponding Algorithms ‣ A Comprehensive Survey
    on Deep Learning Techniques in Educational Data Mining"). This table also lists
    the evaluation metrics and datasets employed in each study.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Overview of Deep Learning Algorithms for Different Educational Scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Scenario | Model | Algorithm Classification | Method | Evaluation Metric
    | Dataset | Year |'
  prefs: []
  type: TYPE_TB
- en: '| Knowledge Tracing | GFLDKT  [[133](#bib.bib133)] | Supervised Learning |
    LSTM | AUC/ACC | ASSISTments15/17/JunyiAcademy | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| LFBKT  [[13](#bib.bib13)] | LSTM | AUC/ACC | ASSISTment12 | 2022 |'
  prefs: []
  type: TYPE_TB
- en: '| DFKT  [[73](#bib.bib73)] | LSTM | AUC/ACC/MAP | ASSISTment12 | 2019 |'
  prefs: []
  type: TYPE_TB
- en: '| PGN  [[49](#bib.bib49)] | RNN | AUC/ACC/RMSE | ASSISTment15/17/Statics2011
    | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| DKT  [[80](#bib.bib80)] | RNN | AUC | ASSISTment09/10 | 2015 |'
  prefs: []
  type: TYPE_TB
- en: '| DKT-STDRL  [[63](#bib.bib63)] | CNN | AUC/ACC/RMSE/$r^{2}$ | ASSISTment09/15/Statics2011
    | 2022 |'
  prefs: []
  type: TYPE_TB
- en: '| HHSKT  [[76](#bib.bib76)] | GNN | AUC/ACC | ASSISTment09/17/Junyi15 | 2023
    |'
  prefs: []
  type: TYPE_TB
- en: '| GIKT  [[120](#bib.bib120)] | GCN | AUC | ASSISTment09/12/EdNet | 2021 |'
  prefs: []
  type: TYPE_TB
- en: '| MRTKT  [[18](#bib.bib18)] | Attention | AUC/ACC | ASSISTment09/10/12/13 |
    2023 |'
  prefs: []
  type: TYPE_TB
- en: '| KTMFF  [[117](#bib.bib117)] | Attention | AUC | ASSISTment09/15/Statics2011
    | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| AKT  [[28](#bib.bib28)] | Attention | AUC | ASSISTment09/10/12/13/KDD Cup2012
    | 2020 |'
  prefs: []
  type: TYPE_TB
- en: '| SAKT  [[77](#bib.bib77)] | Attention | AUC | ASSISTment09/15/Statis2011 |
    2019 |'
  prefs: []
  type: TYPE_TB
- en: '| AdaptKT  [[16](#bib.bib16)] | Unsupervised Learning | Autoencoder | AUC |
    zx.math/ax.physics | 2022 |'
  prefs: []
  type: TYPE_TB
- en: '| KTM  [[11](#bib.bib11)] | Reinforcement Learning | AC | AUC | ASSISTment09/10
    | 2019 |'
  prefs: []
  type: TYPE_TB
- en: '| RL-KTNet  [[19](#bib.bib19)] | AC | AUC/$r^{2}$ | ASSISTment09/10/KKD2010
    | 2020 |'
  prefs: []
  type: TYPE_TB
- en: '| IEKT  [[62](#bib.bib62)] | Policy Gradient | AUC/ACC | ASSISTment09/12/EdNet/Junyi
    | 2021 |'
  prefs: []
  type: TYPE_TB
- en: '| KADT  [[1](#bib.bib1)] | DPG | AUC | ASSITment09/IMDB/MovieLens/CIFAR-100
    | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| Student Behavior Detection | VB-DTW  [[109](#bib.bib109)] | Supervised Learning
    | CNN | ACC/VSE | SCB-13 | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| DCNN  [[32](#bib.bib32)] | CNN | Recall/Precision/F1 | FER2013 | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| ATGCN  [[82](#bib.bib82)] | CNN | ACC | N/A | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| Faster R-CNN  [[38](#bib.bib38)] | CNN | ACC/Precision/DR/FDR | TCE Classroom
    | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| CFIN  [[24](#bib.bib24)] | CNN | AUC/F1 | KDD Cup2015/XuetangX | 2019 |'
  prefs: []
  type: TYPE_TB
- en: '| EDLN  [[40](#bib.bib40)] | CNN | AUC/Recall/Precision/F1 | KDD Cup2015 |
    2023 |'
  prefs: []
  type: TYPE_TB
- en: '| ABDM  [[135](#bib.bib135)] | CNN | ACC | N/A | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| LBDL  [[58](#bib.bib58)] | LSTM | AUC/F1 | MOOCCube | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| CDLSTM  [[3](#bib.bib3)] | LSTM | AUC/Recall/Precision/F1 | 7WiseUp | 2023
    |'
  prefs: []
  type: TYPE_TB
- en: '| EVA-MLP  [[101](#bib.bib101)] | MLP | Recall/Precision/F1 | Student Journals
    | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| FTGAN  [[98](#bib.bib98)] | Unsupervised Learning | GAN | AUC/ACC/Recall/Precision/F1
    | N/A | 2021 |'
  prefs: []
  type: TYPE_TB
- en: '| Performance Prediction | DL-MLP  [[14](#bib.bib14)] | Supervised Learning
    | MLP | ACC | Pennsylvania School Performance Profile | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| CRN  [[74](#bib.bib74)] | CNN | FDR/Sens/FPR/MCC/F1/NPV/FNR | Kaggle | 2023
    |'
  prefs: []
  type: TYPE_TB
- en: '| SDPNN  [[75](#bib.bib75)] | DNN | ACC | N/A | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| MLP-12Ns  [[8](#bib.bib8)] | MLP | RMSE | Kaggle | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| TLBO-ML  [[6](#bib.bib6)] | ANN | ACC/Recall/Precision/FM/F1/MCC | OULAD
    | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| SAPP  [[39](#bib.bib39)] | LSTM | ACC/Recall/Precision/F-measure | OULAD
    | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| MSH-MD  [[15](#bib.bib15)] | Attention | Recall/Precision/F1/MSE/MAE/RSME
    | Self-Collected | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| CGAN  [[92](#bib.bib92)] | Unsupervised Learning | GAN | AUC | Self-collected
    | 2022 |'
  prefs: []
  type: TYPE_TB
- en: '| ADSLS  [[20](#bib.bib20)] | Reinforcement Learning | Q-Learning | N/A | N/A
    | 2013 |'
  prefs: []
  type: TYPE_TB
- en: '| NCAT  [[137](#bib.bib137)] | Q-Learning | AUC/ACC | ASSISTment09/12/15/KDD
    Cup2010 | 2022 |'
  prefs: []
  type: TYPE_TB
- en: '| Peronalized Recommendation | BERT  [[43](#bib.bib43)] | Supervised Learning
    | Attention | Recall/Precision/F1 | MOOCCube | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| MCR-C-FGM  [[90](#bib.bib90)] | DNN | Precision | edX Learning Data | 2022
    |'
  prefs: []
  type: TYPE_TB
- en: '| SODNN  [[88](#bib.bib88)] | DNN | Precision | UBOB | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM-CNN  [[107](#bib.bib107)] | CNN | Recall/Precision/F1 | Kaggle | 2023
    |'
  prefs: []
  type: TYPE_TB
- en: '| CSEM-BCR  [[26](#bib.bib26)] | CNN | Recall/Precision/MAP/AP | CourseTalk
    | 2022 |'
  prefs: []
  type: TYPE_TB
- en: '| ARGE  [[132](#bib.bib132)] | RNN | AUC | LastFM/Movielens-100K/Yelp | 2023
    |'
  prefs: []
  type: TYPE_TB
- en: '| KALUR  [[65](#bib.bib65)] | GNN | Recall/NDCG | MovieLens-100K/Amazon-book/LFM-1B
    | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| TCRKDS  [[93](#bib.bib93)] | LSTM | ACC/Recall/Precision/F-measure/FDR |
    Kaggle | 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| FRS  [[136](#bib.bib136)] | LSTM | AUC/Precision/RSME | ASSISTment | 2018
    |'
  prefs: []
  type: TYPE_TB
- en: '| MRCRec  [[30](#bib.bib30)] | GCN | HR/HR/NDCG/MRR | MOOCCube/XuetangX | 2023
    |'
  prefs: []
  type: TYPE_TB
- en: '| RecGAN  [[9](#bib.bib9)] | Unsupervised Learning | GAN | NDCG/MRR/MAP | MPF
    | 2018 |'
  prefs: []
  type: TYPE_TB
- en: '| DBNLS  [[123](#bib.bib123)] | DBN | Act/Ref/Sen/Int | StarC | 2020 |'
  prefs: []
  type: TYPE_TB
- en: '| RLALS  [[94](#bib.bib94)] | Reinforcement Learning | AC | N/A | N/A | 2018
    |'
  prefs: []
  type: TYPE_TB
- en: '| CSEAL  [[60](#bib.bib60)] | AC | AUC/Recall/F1/MAP | Junyi | 2019 |'
  prefs: []
  type: TYPE_TB
- en: '| MEUR  [[50](#bib.bib50)] | Q-Learning | IR/HR/NDCG/MRR | MOOCCube | 2023
    |'
  prefs: []
  type: TYPE_TB
- en: '| QLearnRec  [[102](#bib.bib102)] | Q-Learning | N/A | Self-Collected | 2019
    |'
  prefs: []
  type: TYPE_TB
- en: '| RILS  [[83](#bib.bib83)] | Q-Learning | N/A | Self-Collected | 2014 |'
  prefs: []
  type: TYPE_TB
- en: '| RPPR  [[52](#bib.bib52)] | REINFORCE | HR/NDCG | MOOCCourse/XuetangX | 2023
    |'
  prefs: []
  type: TYPE_TB
- en: '| HELAR  [[55](#bib.bib55)] | REINFORCE | HR/NDCG | MOOCCourse/XuetangX | 2022
    |'
  prefs: []
  type: TYPE_TB
- en: '| HRRL  [[54](#bib.bib54)] | REINFORCE | HR/NDCG | MOOCCourse/XuetangX | 2022
    |'
  prefs: []
  type: TYPE_TB
- en: '| HRL-NAIS  [[125](#bib.bib125)] | REINFORCE | HR/NDCG | XuetangX | 2019 |'
  prefs: []
  type: TYPE_TB
- en: '| KRRL  [[57](#bib.bib57)] |  | AC | HR/NDCG | MOOCCourse/XuetangX | 2023 |'
  prefs: []
  type: TYPE_TB
- en: 3.1 Knowledge Tracing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Knowledge tracing is an educational assessment technology that tracks students’
    learning process and predicts their mastery of knowledge points. In a knowledge
    tracing scenario, students’ learning process is usually recorded, including learning
    time, answer status, homework completion, etc.
  prefs: []
  type: TYPE_NORMAL
- en: 'According to previous studies proposed by Song et al. [[97](#bib.bib97)], the
    problem of knowledge tracing in intelligent education systems involves three main
    elements: the student $S$, the exercise $E$, and the corresponding knowledge concept
    $C$. The interactions $X$ among these elements are the main activities in such
    systems. Specifically, given a student’s historical exercise interactions $s\in
    S$, where each interaction $X_{t}\in X$ corresponds to an exercise $e\in E$ and
    denotes the correctness $a_{t}\in\{0,1\}$ of the result obtained at step $t$,
    the knowledge tracing task aims to predict the next interaction $X_{t+1}$ for
    a specific concept $c\in C$ [[97](#bib.bib97)].'
  prefs: []
  type: TYPE_NORMAL
- en: A simple schema of knowledge tracing is shown as Fig. [3](#S3.F3 "Figure 3 ‣
    3.1 Knowledge Tracing ‣ 3 Educational Scenarios and Corresponding Algorithms ‣
    A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining").
    The correct rate of a student in a certain exercise on a specific knowledge point
    can affect the model’s judgment of the proficiency level of students on this knowledge
    point. For example, in Fig. [3](#S3.F3 "Figure 3 ‣ 3.1 Knowledge Tracing ‣ 3 Educational
    Scenarios and Corresponding Algorithms ‣ A Comprehensive Survey on Deep Learning
    Techniques in Educational Data Mining"), the student’s correct rate on the derivative
    knowledge point is 100%, so his/her mastery level on that knowledge point is much
    higher than other knowledge points.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7f27d120ba815a0d115102e40596fbd0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: A simple knowledge tracing schema. Different exercises contains multiple
    types of concepts with different colors. Whether the exercises are correct or
    not will affect knowledge tracing’s judgment of the student’s mastery of a certain
    knowledge point or exercise [[59](#bib.bib59)].'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 Supervised Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The application of supervised learning in the field of knowledge tracing is
    mainly focused on various kinds of neural networks, *e.g.*, LSTM, CNN, GNN and
    RNN.
  prefs: []
  type: TYPE_NORMAL
- en: LSTM is primarily used to simulate the forgetting and learning processes of
    students, updating their knowledge states accordingly, thereby enabling effective
    knowledge tracing. A GFLDKT model based on LSTM was presented by Zhao et al. [[133](#bib.bib133)],
    in which a Gating-controlled Forgetting and Learning mechanism was employed to
    effectively update the knowledge state and facilitate accurate prediction of subsequent
    student responses.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, Nagatani et al. [[73](#bib.bib73)] proposed a DFKT model considering
    forgetting processes of student. Specifically, DFKT applies LSTM and Neural Factorization
    Machine (NFM), the former is used to represent the knowledge state of the student
    as low dimensional dense vectors, and the latter combines student knowledge states
    and other related information including relevant forgetting data, to predict student
    performance. Compared to another LSTM-based knowledge tracing model tested on
    the same ASSISTment12 dataset, LFBKT [[13](#bib.bib13)] distinguishes itself in
    its approach to handling forgetting behavior. Unlike the DFKT model, which integrates
    forgetting data as part of its input, LFBKT opts for a more nuanced treatment
    by incorporating a dedicated Knowledge Forgetting Layer. This strategic design
    choice enables LFBKT to more effectively model the dynamics of knowledge decay
    over time. The impact of this approach is evident in the performance enhancement,
    with LFBKT’s accuracy improving by 6.34% compared to the DFKT model on the ASSISTment12
    dataset, demonstrating an advancement in knowledge tracing efficacy.
  prefs: []
  type: TYPE_NORMAL
- en: CNN also plays an essential role in knowledge tracing by being able to process
    the spatial sequence data. Lyu et al. [[63](#bib.bib63)] introduced a DKT-STDRL
    model that employs CNN to extract spatial features from students’ learning sequences
    and LSTM to process temporal features.
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge Graph (KG) is a crucial component of knowledge tracing, as it accounts
    for the interplay between a student’s learning history and specific areas of expertise.
    By leveraging the power of the KG, models can more accurately capture learning
    trajectories and interactions between different points of knowledge. Yang et al. [[120](#bib.bib120)]
    put forth a Graph-based Interaction model for Knowledge Tracing (GIKT) constructed
    using Graph Convolutional Network (GCN). The proposed model addresses data sparsity
    and multi-skills challenges by harnessing high-order question-skill correlations,
    thus improving model performance.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, a heterogeneous graph-based algorithm called HHKST proposed by Ni
    et al. [[76](#bib.bib76)], which utilizes a GNN-based Base Feature Extractor (BFE)
    to extract interaction and knowledge structure features from the heterogeneous
    graph.
  prefs: []
  type: TYPE_NORMAL
- en: As a neural network architecture designed for handling sequential data, RNN
    also holds a significant position in the field of knowledge tracing. DKT [[80](#bib.bib80)]
    utilized considerable amounts of artificial neurons from RNN to construct knowledge
    tracing model. The principle contribution of this article is the introduction
    of a novel method that encoding student interactions into RNN inputs and improved
    the AUC by 17% to 21% approximately compared to the Bayesian Knowledge Tracing
    (BKT) [[17](#bib.bib17)] model on three public datasets.
  prefs: []
  type: TYPE_NORMAL
- en: In knowledge tracing, the application of Attention mechanisms has been explored.
    Ghosh et al. [[28](#bib.bib28)] introduced a method called Context-Aware Attentive
    Knowledge Tracing (AKT), which combines a flexible DNN with heuristic cognitive
    and psychometric models. The proposed Attention mechanism is used to dynamically
    adjust predictions based on contextual information about learners. This integration
    of Attention allows the model to adapt its predictions according to the specific
    context of each learner.
  prefs: []
  type: TYPE_NORMAL
- en: Building on the concept of attention mechanisms, Cui et al. [[18](#bib.bib18)]
    proposed the MRTKT model as an innovative approach for knowledge tracing. Achieving
    an AUC of 82.23% on the ASSISTment09 task, MRTKT slightly outperforms the AKT
    model, which scored 81.69%. Unlike AKT, which emphasizes context-aware dynamic
    adjustments using attention mechanisms, MRT-KT employs a multi-relational attention
    mechanism along with a relation encoding schema to enhance its predictive accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, Pandey and Karypis [[77](#bib.bib77)] proposed the Self-Attentive
    Knowledge Tracing model (SAKT), which leverages a self-attentive mechanism to
    identify and predict the mastery level of students for specific knowledge points.
    The experimental results demonstrate that SAKT outperforms traditional methods
    and RNN-based models, achieving significantly faster performance by an order of
    magnitude.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 Unsupervised Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although the preceding sections of our text have listed numerous knowledge tracing
    methods based on supervised learning, strictly classifying scenes into specific
    algorithm categories (Supervised, Unsupervised, Reinforcement Learning) is often
    challenging. While traditional methods like BKT [[17](#bib.bib17)] are seen as
    unsupervised learning, they don’t incorporate Deep Learning techniques. Hence,
    applying unsupervised Deep Learning in knowledge tracing is a relatively new and
    developing area. However, in recent years, with the rapid development of Deep
    Learning, some researchers have started to explore the use of unsupervised learning
    in knowledge tracing. For instance, Cheng et al. [[16](#bib.bib16)] proposed a
    Autoencoder based DKT, which combines knowledge tracing and transfer learning.
    The Autoencoder here is used to convert question text to high-level semantic embedding.
    In addition, the model also applies Bi-LSTM and Attention mechanism to capture
    knowledge state of student and predicts next answer of learner by Softmax.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.3 Reinforcement Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Reinforcement learning is able to learn the knowledge status and level of students
    by rewarding or punishing through decisions and actions they make. The learning
    process in knowledge tracing can be considered as a sequential decision problem,
    students need to make different decisions according to different knowledge points,
    which might affect the future learning process.
  prefs: []
  type: TYPE_NORMAL
- en: Ding et al. [[19](#bib.bib19)] considered that some supervised learning such
    as LSTM or GRU, are heavily influence by NLP but not specially designed for knowledge
    tracing. Thus, the authors design a RL-KTNet algorithm which applies reinforcement
    learning to automatically generate RNN cells used in knowledge tracing. It outperforms
    other models employing LSTM cells in terms of AUC.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, Long et al. [[62](#bib.bib62)] proposed a model called Individual
    Estimation Knowledge Tracing (IEKT), which incorporates reinforcement learning
    for auxiliary model training. Specifically, Long et al. employed Policy Gradient
    and $\epsilon$-greedy to update the model parameters. Additionally, reinforcement
    learning is utilized to estimate student knowledge states and sensitivity towards
    knowledge acquisition.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Student Behavior Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the current era, both traditional and online educational systems have been
    generating massive amounts of data. The extraction of useful knowledge and underlying
    patterns from this voluminous data can enable decision-makers to enhance teaching
    and learning by identifying student behaviors [[81](#bib.bib81)]. This educational
    data can be considered as an invaluable source of information that can facilitate
    data-driven educational research and innovation. The objective is to identify
    students’ behaviors like low motivation, low engagement, cheating, dropout and
    procrastination [[23](#bib.bib23)].
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8c263e555798aca4ea7b8510be9bcc5f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: A simple structure of ATGCN model [[82](#bib.bib82)] for student
    behavior detection.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/60bf4f77ff55bc52e03a48d917a3cb60.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: A simple structure of LBDL model [[58](#bib.bib58)] for dropout prediction.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.1 Supervised Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The applications of supervised learning in this field are relatively diverse,
    variety of neural networks are applied, such as CNN and LSTM.
  prefs: []
  type: TYPE_NORMAL
- en: CNNs are frequently used in applications that require spatial feature extraction
    from image or video data due to their effectiveness in such tasks. Wang et al. [[109](#bib.bib109)]
    implemented CNNs to analyze data obtained from motion sensors, leading to accurate
    recognition of 14 common classroom behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging CNN’s superior image processing, Hdioud et al. [[32](#bib.bib32)]
    developed a DCNN model for recognizing students’ faces with masks during the epidemic,
    showcasing adaptability under challenging conditions. Concurrently, Qiu et al. [[82](#bib.bib82)]
    proposed an ATGCN model, also based on CNN, to identify improper behaviors like
    napping in classrooms. This highlights the diverse applications of CNN in educational
    settings, where one model focuses on facial recognition under constraints and
    the other on behavior detection. The ATGCN leverages both CNN and GCN as its fundamental
    components and employs an attention mechanism to boost its performance. A concise
    representation of the ATGCN structure is depicted in Fig. [5](#S3.F5 "Figure 5
    ‣ 3.2 Student Behavior Detection ‣ 3 Educational Scenarios and Corresponding Algorithms
    ‣ A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining")
  prefs: []
  type: TYPE_NORMAL
- en: In education scenarios, student behaviors extend beyond simple actions such
    as napping and inattentiveness. An important part of this field is the detection
    of dropout tendencies, integral to understanding the full scope of student behaviors.
    Feng et al. [[24](#bib.bib24)] proposed a Context-aware Feature Interaction Network
    (CFIN) model for predicting students’ dropout behaviors in MOOCs. The CFIN model
    incorporates a context smoothing technique to enhance the feature values across
    different contexts and employs an attention mechanism to integrate user and course
    information within the modeling framework.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, Kumar et al. [[40](#bib.bib40)] developed an EDLN model that combines
    CNN and an attention mechanism for student dropout detection in online courses.
    The EDLN model employs ResNet-50 to extract local high-dimensional features and
    uses Faster R-CNN to analyze hidden long-term memory features in time series data.
    This model demonstrates notable performance, achieving an accuracy of 97.5% with
    a $5\times 7$ time series matrix as input.
  prefs: []
  type: TYPE_NORMAL
- en: Other deep neural networks can be also employed for dropout prediction. The
    LBDL model, as proposed by Liu et al. [[58](#bib.bib58)], integrates Bi-LSTM and
    a multi-head attention mechanism to analyze time series information extracted
    from video-based study behaviors. This model demonstrates performance with AUC
    and F1 scores of 82.39% and 74.89%, respectively, on the MOOCCube dataset. A simple
    structure of LBDL is shown as Fig. [5](#S3.F5 "Figure 5 ‣ 3.2 Student Behavior
    Detection ‣ 3 Educational Scenarios and Corresponding Algorithms ‣ A Comprehensive
    Survey on Deep Learning Techniques in Educational Data Mining"). Subsequently,
    the authors demonstrate the exceptional performance of this model.
  prefs: []
  type: TYPE_NORMAL
- en: With the advancement of online education, the detection of cheating has become
    a critical area of focus for EDM researchers. Alsabhan et al. [[3](#bib.bib3)]
    developed the CDLSTM model, which is based on the LSTM. This model incorporates
    a dropout layer, a dense layer, and the Adam optimizer. Owing to the LSTM’s ability
    to effectively process sequential data, the CDLSTM model achieved a notable accuracy
    of 90% in identifying cheating behaviors, using students’ online test activity
    logs as input.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2 Unsupervised Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this section, we delve into the application of unsupervised learning within
    EDM, particularly in detecting student behaviors. This approach, a facet of Deep
    Learning, processes educational data to autonomously identify patterns in student
    engagement, providing insights without relying on predefined labels or categories.
  prefs: []
  type: TYPE_NORMAL
- en: Stenton et al. [[98](#bib.bib98)] introduced a FTGAN which means Fine-Tuning
    GAN to predict the attrition rate of the student. The authors demonstrate that
    the more epochs the GAN classifier model is trained, the more its accuracy shows
    a certain level of increase.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.3 Reinforcement Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'While exploring the application of various algorithms in detecting student
    behaviors, it’s crucial to consider the complexity and multifaceted nature of
    these behaviors. Reinforcement learning, though powerful, faces challenges in
    this domain:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The complexity of student behavior, influenced by diverse factors like social
    background and personal circumstances, may not align well with the straightforward
    state-action framework typically used in reinforcement learning.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining appropriate rewards and punishments in the context of student behaviors
    and their long-term outcomes, such as dropout rates, presents a significant challenge.
    The dichotomy between short-term and long-term consequences complicates the application
    of reinforcement learning.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Based on the outlined reasons, our study does not include literature on the
    application of reinforcement learning for student behavior detection. However,
    we acknowledge the potential value and relevance of attempts to explore this method
    in such contexts.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Performance Prediction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Performance prediction [[85](#bib.bib85)] refers to the use of various data
    and analytic techniques to predict student performance in certain tasks or areas,
    such as test scores, academic performance, course completion rates, etc. The difference
    between it and the knowledge tracking task is that performance prediction focuses
    on predicting students’ overall future tasks or test performance based on historical
    learning data, while knowledge tracing focuses on students’ understanding and
    mastery of specific knowledge concepts during the learning process.
  prefs: []
  type: TYPE_NORMAL
- en: By predicting student performance, teachers and educational institutions can
    better understand students’ learning and needs to provide more effective support
    and guidance. Predictions can also help students understand their performance
    and potential difficulties and take steps to improve learning outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, cognitive diagnosis [[108](#bib.bib108)] is a related concept wherein
    the aim is to identify students’ level of mastery in specific knowledge domains
    by analyzing their performance on exercise records. This analysis facilitates
    providing tailored guidance for their subsequent studies [[27](#bib.bib27), [103](#bib.bib103)].
    In contrast, performance prediction focuses more on predicting students’ overall
    scores on tests. The former analyzes knowledge dimensions, while the latter emphasizes
    general ability. Cognitive diagnosis outputs concept proficiency levels, whereas
    performance prediction directly predicts total scores.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.1 Supervised Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Supervised learning algorithms can provide teachers and students with useful
    information to help them better understand student performance and needs. In addition
    to classic algorithms like SVM, Deep Learning models such as MLP, CNN, RNN, and
    LSTM have been applied to predict student performance in various educational contexts.
  prefs: []
  type: TYPE_NORMAL
- en: Nayani et al. [[74](#bib.bib74)] introduced a hybrid model called CRN which
    is a combination of CNN and RNN to predict the students’ grade, and improves the
    performance by tuning hyperparameters through Galactic Rider Swarm Optimization
    (GRSO) algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, Neha et al. [[75](#bib.bib75)] presented a SDPNN model that applied
    a linear classifier-based DNN to predict student academic performance. There are
    two hidden layers with 300 neurons defined. The activation function is ReLU and
    Softmax.
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{softmax}(z_{i})=\frac{e^{z_{i}}}{\sum_{j=1}^{K}e^{z_{j}}},\quad
    i=1,2,...,K,$ |  | (12) |'
  prefs: []
  type: TYPE_TB
- en: where $z_{i}$ represents the $i_{th}$ element of the input vector, and $K$ is
    the number of categories.
  prefs: []
  type: TYPE_NORMAL
- en: Kukkar et al. [[39](#bib.bib39)] proposed a SAPP system that utilize four layers
    of stacked LSTM, Random Forest and Gradient Boosting. Here, LSTM is used to extract
    features while Random Forest and Gradient Boosting are applied to predict. The
    proposed system has an accuracy rate of 96% and performs well to some extent.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, Chen et al. [[15](#bib.bib15)] introduced the MSH-MD model, which
    also utilizes LSTM. The core of MSH-MD is its self-attention mechanism, integrating
    LSTM’s capacity for processing time series with the efficient feature extraction
    of the self-attention mechanism. Compared to the SAPP model [[39](#bib.bib39)],
    the MSH-MD focuses more on predicting student performance through pattern differences,
    whereas the SAPP model emphasizes feature extraction more prominently.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.2 Unsupervised Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although the grade prediction usually relies on labeled datasets for supervised
    learning, some unsupervised learning algorithms, such as GAN, can also be used
    for grade prediction tasks. GAN can perform grade prediction by taking a student’s
    historical grades as input and using generators and discriminators to generate
    predicted values for future grades. The generator can use the student’s prior
    grades and other relevant factors to generate predictions of future grades, and
    the discriminator is used to determine whether the generated predictions are similar
    to the true grades.
  prefs: []
  type: TYPE_NORMAL
- en: Sarwat et al. [[92](#bib.bib92)] proposed a model combined with Conditional
    GAN (CGAN) and Deep-Layer-Based SVM to predict students’ grades according to school
    or home tutoring. CGAN was used to generate performance score data to address
    the issue of small dataset size, and the model using a combination of CGAN and
    SVM was experimentally shown to have a positive effect on the prediction results.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.3 Reinforcement Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Generally speaking, while reinforcement learning may not be traditionally used
    for student performance prediction, it can be employed to optimize a student’s
    learning path by setting reward strategies based on student behavior. In this
    context, reinforcement learning would also involve assessing the current performance
    of students and considering potential improvements.
  prefs: []
  type: TYPE_NORMAL
- en: Dorça et al. [[20](#bib.bib20)] proposed an ADSLS model to automatically detect
    and precisely adjust students’ learning styles. An important part of this is that
    the model predicts and assesses student performance on a point and rewards performance
    while updating learning strategies. The proposed method’s efficacy and efficiency
    have been demonstrated by the results.
  prefs: []
  type: TYPE_NORMAL
- en: Zhuang et al.  [[137](#bib.bib137)] introduced an NCAT model that utilizes reinforcement
    learning to enhance the effectiveness of e-testing systems. The NCAT model employs
    deep reinforcement learning to dynamically optimize test terms based on given
    conditions. With the proposed algorithms, the e-testing system can provide more
    comprehensive and accurate performance predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Personalized Recommendation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the current era of explosive growth in online information, recommendation
    systems [[37](#bib.bib37)] undoubtedly offer an effective means of addressing
    this issue and providing necessary assistance to individual users. Even outside
    the educational context, recommendation systems remain one of the most widely
    studied technological approaches. Zhang et al. [[127](#bib.bib127)] gave a detailed
    definition of a recommendation system that: Assuming the presence of $M$ users
    and $N$ items, we denote the interaction matrix and predicted interaction matrix
    as $R$ and $\hat{R}$, respectively. The user preference for item $i$ is represented
    as $r_{ui}$, while the predicted score is denoted by $\hat{r}_{ui}$. There will
    also be two partially observed vectors, one represents a specific user $u$, *i.e.*,
    $r^{(u)}=\{r^{u1},...,r^{uN}\}$. The other one represents a specific item $i$,
    *i.e.*, $r^{(i)}=\{r^{1i},...,r^{Mi}\}$.'
  prefs: []
  type: TYPE_NORMAL
- en: In the education scenarios, the item is replaced with educational resources
    such as courses. The primary objective of a course recommendation system is to
    suggest the most suitable course to a user at time $t+1$, taking into account
    their past learning activities and learner profiles prior to time $t$. The primary
    challenge faced by such recommendation systems is to provide personalized recommendations
    by precisely depicting and conceptualizing user inclinations through analysis
    of user data [[61](#bib.bib61)]. Fig. [6](#S3.F6 "Figure 6 ‣ 3.4 Personalized
    Recommendation ‣ 3 Educational Scenarios and Corresponding Algorithms ‣ A Comprehensive
    Survey on Deep Learning Techniques in Educational Data Mining") demonstrates a
    simple schema of personalized recommendation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/33e3019d1791bc72e2f5e843e64d8bd7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: A general process framework for personalized recommendation in EDM.
    The recommendation system uses user data and course data for modeling. After recommending
    to users, the associated data between users and courses will be updated to improve
    accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.1 Supervised Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The application of supervised learning in course recommendation [[90](#bib.bib90)]
    focuses on a wide variety of neural network models, due to the greater flexibility
    and expressiveness of neural networks, which can better handle user behavior sequences
    and nonlinear features. At the same time, neural networks can automatically extract
    features from the data to more accurately predict users’ interests in the recommendation
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Some optimized neural network models play a role in the field of personalized
    recommendation. SODNN, a novel model consisting of synchronous sequences, heterogeneous
    features and DNN has been introduced by Safarov et al. [[88](#bib.bib88)]. At
    the same time, to solve the cold-start problem, *i.e.*, Large errors caused by
    missing user data during the initialization of the recommendation system, the
    authors tried to concatenate additional features to overcome it.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, classical neural networks can also be employed in recommendation
    systems. In contrast to the conventional positive sequence modeling approach,
    Gao et al. [[26](#bib.bib26)] proposed a novel CSEM-BCR model that adopts negative
    sequence modeling. Specifically, this model constructs the course-learning sequence
    as a negative sequence pattern, which the negative term refers to the principle
    that students should not select or operate courses inappropriately. The negative
    sequence pattern is then processed using CNN for feature learning, which generates
    a list of recommended courses for each user. The suggested approach presents a
    fresh perspective on personalized recommendation and offers a potential solution
    to the issue of recommending courses to learners with different needs and preferences.
  prefs: []
  type: TYPE_NORMAL
- en: KG is an important part of personalized recommendations. It can effectively
    address the sparsity issue in recommender systems. An ARGE model based on multiple
    paths RNN encoder is proposed by Zhao et al. [[132](#bib.bib132)]. The model solves
    the problem that traditional RNNs do not consider the association between paths
    for encoding, and the AUC and Precision in the experimental outcomes demonstrate
    the model’s capacity to effectively address the issue of sparse interaction between
    users and items.
  prefs: []
  type: TYPE_NORMAL
- en: GNN, as a neural network model specifically for processing graph structures,
    has also been applied by many scholars to deal with recommender systems. Ma et
    al. [[65](#bib.bib65)] presented a KAUR model that applies GNN to learn node representations
    for each node in the collaborative KG. The model treats the node information and
    its neighboring node information that has been propagated as positive contrastive
    pairs, and then leverages contrastive learning to improve the quality of the node
    representations.
  prefs: []
  type: TYPE_NORMAL
- en: Zhou et al. [[136](#bib.bib136)] proposed a Full-path Recommendation System
    (FRS) based on LSTM and a clustering algorithm. The clustering algorithm is utilized
    to categorize learners based on their similar learning features, which in turn
    helps classify the learning paths according to the previous results. Consequently,
    this approach effectively addresses the cold start problem. LSTM is employed for
    predicting learning performance, and if the result is unsatisfactory, the system
    will select the most relevant learning path for users based on their individual
    learning features.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.2 Unsupervised Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In recommender systems, user preferences and behaviors are often incomplete
    and inaccurate, and tagging data is very difficult and expensive to collect. On
    this basis, unsupervised learning is a great means to achieve personalized recommendations.
    Unsupervised learning can extract potential interests and preferences from users’
    historical behaviors and infer the similarity and interest relevance of users
    through clustering, and feature learning to achieve personalized recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: Bharadhwaj et al. [[9](#bib.bib9)] introduced a hybrid RecGAN model based on
    GAN and RNN. The generator and discriminator are both constructed with GRU-Based
    RNN. The generator is then allowed to play a Mini-Max game with the discriminator,
    *i.e.*, there exists a true distribution $D_{real|t}$ in time index $t$, and a
    probability distribution generated by the generator $D_{gen|t}$. The goal of this
    minimal-maximization game is to minimize the generation error of the generator,
    while maximizing the discriminator’s ability to distinguish false ratings from
    true ratings.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning can also be applied to classify different types of learning
    styles to recommend the most suitable education resources to distinct groups.
    A DBN-based DBNLS model proposed by Zhang et al. [[123](#bib.bib123)] is used
    to detect and classify learning styles. The core component of DBNLS is the multilayer
    RBM and Back Propagation network layer, where Back Propagation is used to fit
    the DBNLS model and to fine-tune and train the DBN.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.3 Reinforcement Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The application of reinforcement learning in personalized recommendation has
    high research value and development prospects. Reinforcement learning algorithms
    can learn the optimal recommendation strategy based on learner’ feedback to improve
    the recommendation performance.
  prefs: []
  type: TYPE_NORMAL
- en: A cognitive structure enhanced framework for adaptive learning named CSEAL was
    proposed by Liu et al. [[60](#bib.bib60)], to achieve personalized learning path
    recommendation. This framework views the learning path as a Markov Decision Process
    (MDP) and applies actor-critic to identify appropriate learning projects for individual
    learners. CSEAL comprehensively considers the learner’s knowledge level and the
    knowledge structure of the learning project. Experimental results demonstrate
    that CSEAL can enhance learners’ efficiency compared with current adaptive learning
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Liang et al. [[50](#bib.bib50)] presented a MEUR model based on Graph Convolution
    Network and reinforcement learning. The author considered the learning process
    as a MDP. Applying a user-centric reasoning method and maximizing cumulative reward
    $G$ by actor-critic algorithm, $G$ is defined as below:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $G(\theta)=\frac{1}{m}\sum_{u=1}^{m}\sum_{a,t=0}\pi(a&#124;s_{t},A(s_{t}))\gamma^{t}R(s_{t+1}),$
    |  | (13) |'
  prefs: []
  type: TYPE_TB
- en: where $\theta$ is the parameter of the Actor network, $m$ is the number of samples,
    $u$ is the sample index, $a$ and $t$ are the time step and action indexes, $\pi(a|s_{t},A(s_{t}))$
    is the probability of selecting action $a$ in state $s_{t}$, $R(s_{t+1})$ is the
    immediate reward obtained in state $s_{t+1}$, and $\gamma$ is the tuning parameter.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to propose explainable recommendation algorithms in MOOC for
    interpreting the recommendation results. To this end, Lin et al. [[57](#bib.bib57)]
    developed a KRRL model, combined KG and self-supervised reinforcement learning,
    for explainable MOOC recommendation. Specifically, a multi-granularity representation
    learning method enriches the perceptual information of semantic interactions in
    the KG, and a self-supervised reinforcement learning method guides the path reasoning
    over the KG, and finally recommends appropriate courses to the target learner.
    The experimental results show that KRRL performs better than some comparison methods,
    in terms of the recommendation accuracy and explainability.
  prefs: []
  type: TYPE_NORMAL
- en: Besides, reinforcement learning algorithms can be used to model learner preferences.
    For example, Zhang et al. [[125](#bib.bib125)] are the first to adopt the Hierarchical
    Reinforcement Learning (HRL) to modify learner profiles. Furthermore, the HRRL
    algorithm [[54](#bib.bib54)] integrates Recurrent Reinforcement Learning (RRL)
    with HRL as a profile reviser, which iteratively revises learner profiles to assist
    the MOOC recommendation model. Lin et al. [[52](#bib.bib52)] also proposed a RPPR
    model, in which a multi-scale reinforcement learning method constructs multi-dimensional
    learner profiles, thereby dealing with the adverse effects of insufficient semantic
    information on learner modeling.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Datasets and Processing Tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1 Datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table 2: Dataset Information'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset Name | Description | Application Scenario | Literature Applied |'
  prefs: []
  type: TYPE_TB
- en: '| ASSITments¹ | A knowledge tracing dataset based on knowledge decomposition
    theory in education, including problem-solving records. Aimed for developing and
    evaluating intelligent education systems. | Used for researching and evaluating
    intelligent education systems based on knowledge decomposition theory, such as
    knowledge tracing and personalized recommendation, using machine learning and
    Deep Learning techniques. |  [[80](#bib.bib80)] [[133](#bib.bib133)] [[76](#bib.bib76)] [[64](#bib.bib64)] [[49](#bib.bib49)]
    [[129](#bib.bib129)] [[13](#bib.bib13)] [[117](#bib.bib117)] [[63](#bib.bib63)] [[18](#bib.bib18)]
    [[137](#bib.bib137)] [[120](#bib.bib120)] [[108](#bib.bib108)] [[62](#bib.bib62)]
    [[28](#bib.bib28)] [[77](#bib.bib77)] [[29](#bib.bib29)] |'
  prefs: []
  type: TYPE_TB
- en: '| Junyi Academy Online Learning Activity Dataset² | Junyi dataset is an educational
    dataset that contains a large amount of online learning behavior data of primary
    and secondary school students, including learning and answering records, learning
    behavior features, and other information. | The dataset is designed to support
    data mining task, *e.g.*, knowledge tracing. |  [[133](#bib.bib133)] [[76](#bib.bib76)] [[64](#bib.bib64)] [[49](#bib.bib49)] [[60](#bib.bib60)]
    [[136](#bib.bib136)] [[62](#bib.bib62)] |'
  prefs: []
  type: TYPE_TB
- en: '| KDD Cup 2010³ | This dataset contains logs of student interactions with computer-aided-tutoring
    systems, including problem-solving transactions. Key terms include problem, step
    and knowledge component. | It can be applied to the development and evaluation
    of intelligent educational systems, personalized recommendation, knowledge tracing
    and Deep Learning-based educational technologies. |  [[129](#bib.bib129)] [[71](#bib.bib71)] [[114](#bib.bib114)] [[113](#bib.bib113)]
    [[25](#bib.bib25)] |'
  prefs: []
  type: TYPE_TB
- en: '| MOOCCube⁴ | MOOCCube is an open data warehouse for NLP, KG, and data mining
    researchers in large-scale online education. It includes 706 real online courses,
    38,181 instructional videos, 114,563 concepts, and 199,199 MOOC users’ hundreds
    of thousands of course selection and video-watching records. | The data set can
    be used to study learner behavior patterns, which can be utilized for personalized
    recommendation. |  [[124](#bib.bib124)] [[30](#bib.bib30)] [[111](#bib.bib111)] [[50](#bib.bib50)]
    [[58](#bib.bib58)] |'
  prefs: []
  type: TYPE_TB
- en: '| xAPI-Educational Mining Dataset⁵ | This dataset contains 480 student records
    and 16 features, including demographic attributes (gender, nationality), academic
    background information (educational stage, grade level, section), and behavioral
    indicators (raising hand in class, accessing resources, parental survey responses,
    school satisfaction). | xAPI-educational mining dataset can be used to develop
    and evaluate learning analytics models, to implement specific tasks such as personalized
    recommendation, performance prediction and student behavior detection in the education
    domain. |  [[9](#bib.bib9)] [[105](#bib.bib105)] [[10](#bib.bib10)] |'
  prefs: []
  type: TYPE_TB
- en: '| Open University Learning Analytics Dataset⁶ | The Open University Learning
    Analytics Dataset is a comprehensive educational dataset that includes over 300,000
    students’ demographic information, course information, interaction data, and achievement
    data from seven courses, and has been used in various educational research studies.
    | Predicting student success and dropout rates in higher education, as well as
    understanding learning behavior patterns in online courses. So as to develop personalized
    recommendation and performance prediction system. |  [[39](#bib.bib39)] [[93](#bib.bib93)] [[6](#bib.bib6)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Canvas Network Dataset⁷ | Online courses data collected from Canvas Network
    platform, including course metadata, enrollment, and interaction logs. | Predicting
    and understanding student performance in online courses, and designing personalized
    recommendation and student behavior detection model. |  [[119](#bib.bib119)] [[130](#bib.bib130)] [[89](#bib.bib89)] [[47](#bib.bib47)]
    [[7](#bib.bib7)] |'
  prefs: []
  type: TYPE_TB
- en: '| Learn Moodle⁸ | The Learn Moodle dataset is a collection of student activity
    logs, discussions, quizzes, and more from various Moodle courses. It is used for
    researching student behavior patterns, learning outcomes, course design, and Moodle
    platform functionality in online education. | This dataset is mainly used to study
    student behavior patterns, learning outcomes, course design, and Moodle platform
    functionalities in online education, aiming to improve teaching quality and efficiency
    in online education. |  [[86](#bib.bib86)] |'
  prefs: []
  type: TYPE_TB
- en: '| XuetangX⁹ | XuetangX is a Chinese dataset, which covers courses and learning
    behavior data of Chinese users on the online platform of XuetangX. This includes
    student registration information, course access records, video viewing behavior,
    homework submission, discussion participation, etc. | The data set can be used
    in the research and application of learner behavior analysis, knowledge tracing
    and personalized recommendation. |  [[125](#bib.bib125)] [[30](#bib.bib30)] [[50](#bib.bib50)] [[53](#bib.bib53)] [[55](#bib.bib55)]
    [[54](#bib.bib54)] [[110](#bib.bib110)] [[24](#bib.bib24)] |'
  prefs: []
  type: TYPE_TB
- en: '| EdNet^(10) | EdNet is a large-scale educational dataset collected from Santa,
    an AI tutoring service with over 780K users. It contains multivariate data on
    student interactions across platforms, including materials consumed, responses
    given, and time spent on learning activities. The key properties are its large
    scale, detailed student behavior data, and collection from a deployed system with
    numerous real users. | EdNet enables personalized recommendation, knowledge tracing
    and educational optimization through its large-scale, detailed data on student
    behaviors and interactions. |  [[18](#bib.bib18)] [[120](#bib.bib120)] [[62](#bib.bib62)]
    |'
  prefs: []
  type: TYPE_TB
- en: '1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://sites.google.com/view/assistmentsdatamining/home
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://www.kaggle.com/datasets/junyiacademy/learning-activity-public-dataset-by-junyi-academy
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://pslcdatashop.web.cmu.edu/KDDCup
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: http://moocdata.cn/data/MOOCCube
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://www.kaggle.com/datasets/aljarah/xAPI-Edu-Data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '6'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://analyse.kmi.open.ac.uk/open_dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '7'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://doi.org/10.7910/DVN/GVLFXO
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '8'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://research.moodle.org
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '9'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: http://moocdata.cn/data/user-activity
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '10'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://github.com/riiid/ednet
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To provide a more comprehensive overview of commonly used public datasets in
    educational settings, we have curated a selection of datasets, as presented in
    Table [2](#S4.T2 "Table 2 ‣ 4.1 Datasets ‣ 4 Datasets and Processing Tools ‣ A
    Comprehensive Survey on Deep Learning Techniques in Educational Data Mining").
    These datasets have been widely employed in various educational research studies
    and have contributed significantly to the advancement of the field. Table [2](#S4.T2
    "Table 2 ‣ 4.1 Datasets ‣ 4 Datasets and Processing Tools ‣ A Comprehensive Survey
    on Deep Learning Techniques in Educational Data Mining") offers essential information
    about each dataset, including its name, URL, description, application scenarios,
    and literature applied.
  prefs: []
  type: TYPE_NORMAL
- en: 'We classify the collected datasets by source into three categories: Datasets
    Used for Competitions, Datasets from Online Education Platforms, and Open Data
    Repository.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.1 Datasets Used for Competitions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: ASSISTments The ASSISTments dataset has many versions, such as Assistment 2009,
    2012 and 2017, which have been used in several educational data mining competitions
    to promote research and development on educational technology and learning analytics.
    One of the most well-known competitions is ASSISTments Data Mining Competition.
  prefs: []
  type: TYPE_NORMAL
- en: KDD Cup 2010 This dataset is used in the KDD Cup 2010 Educational Data Mining
    Challenge, which requires participants to use the student interaction logs contained
    in the provided dataset to train a new learning model and ultimately judge the
    results based on how accurately their model predicts student responses to new
    questions. This dataset is therefore also widely used for problems such as Knowledge
    Tracking.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.2 Datasets from Online Education Platforms
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Junyi Academy Online Learning Activity Dataset The dataset was sourced from
    the Junyi Academy online learning platform, which provides personalized learning
    resources and support for students. The dataset consists of over 72,000 students’
    records of more than 16 million practice attempts on the platform within one year,
    from August 2018 to July 2019.
  prefs: []
  type: TYPE_NORMAL
- en: Canvas Network Dataset The Canvas Network dataset is derived from the Canvas
    Network platform, which provides educational institutions and educators with the
    tools and resources to create and deliver online courses. The dataset contains
    a lot of course information as well as user interaction logs, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Learn Moodle Learn Moodle is derived from the Moodle Learning Management System,
    a widely used open source online learning platform that supports educational institutions
    and teachers in creating, managing and delivering online courses.
  prefs: []
  type: TYPE_NORMAL
- en: XuetangX The XuetangX dataset is derived from the online education platform
    XuetangX. It is a well-known online education platform in China, established in
    2013, which provides MOOCs and other online learning resources, video viewing
    behavior, assignment submission and discussion participation, etc.
  prefs: []
  type: TYPE_NORMAL
- en: EdNet EdNet is an extensive educational dataset amassed by Santa, an AI-based
    online teaching platform with a user base of 780,000 in South Korea. It encompasses
    two years’ worth of student learning behavior data and offers a plethora of information
    on student-system interaction, including knowledge tracking, cognitive processes,
    learning analysis data, and comprehensive records of students’ online learning
    activities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: Dataset Processing Tools Information'
  prefs: []
  type: TYPE_NORMAL
- en: '| Tool Name | Description |'
  prefs: []
  type: TYPE_TB
- en: '| GISMO¹ | Graphical Interactive Student Monitoring Tool for Moodle (GISMO)
    provides an intuitive graphical interface to visually display information about
    student learning activities, engagement, grades, and progress. |'
  prefs: []
  type: TYPE_TB
- en: '| Meerkat-ED² | Meerkat-ED is an educational data analysis tool designed to
    help educators and researchers conduct in-depth analysis of student learning data.
    It generates comprehensive summaries of participants’ engagement in discussion
    forums, illustrating their interactions, identifying discussion leaders and peripheral
    students, and providing various additional insights |'
  prefs: []
  type: TYPE_TB
- en: '| Datashop³ | DataShop is a collection of datasets and tools for educational
    mining. It not only collects and provides a large amount of educational data,
    including students’ interaction data, response records, learning trajectories,
    assessment results, etc. in online learning environments, but also provides a
    series of tools and APIs for processing and analyzing these data, facilitating
    researchers to perform data mining, model building and evaluation. |'
  prefs: []
  type: TYPE_TB
- en: '| SNAPP⁴ | Social Networks Adapting Pedagogical Practice (SNAPP) is a software
    tool that allows users to visualize the network of interactions generated by posts
    and responses in discussion forums. The network visualization of forum interactions
    will provide teachers with the opportunity to quickly identify patterns of user
    behavior. |'
  prefs: []
  type: TYPE_TB
- en: '| LOCO-Analyst⁵ | LOCO-Analyst is an advanced educational tool designed to
    support teachers in evaluating and improving web-based learning environments.
    It provides valuable insights and feedback covering all aspects of the learning
    process, helping educators enhance the content and structure of their online courses
    and providing targeted feedback and recommendations so they can optimize course
    design and pedagogy. |'
  prefs: []
  type: TYPE_TB
- en: '| StREAM⁶ | StREAM is a Student Engagement Analytics Platform which is also
    a predictive algorithm developed by Solutionpath that provides educators with
    visualization of student engagement levels and identification of students who
    need help with certain tasks. For students, it provides information about the
    progress and status of their learning, enabling students and educators to adjust
    their learning or teaching strategies in a timely manner to improve teaching effectiveness.
    |'
  prefs: []
  type: TYPE_TB
- en: '1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://gismo.sourceforge.net
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: http://www.reirab.com/MeerkatED
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://pslcdatashop.web.cmu.edu/index.jsp
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://web.archive.org/web/20120321212021
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: http://jelenajovanovic.net/LOCO-Analyst
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '6'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: https://www.solutionpath.co.uk/stream
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 4.1.3 Open Data Repository
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: MOOCCube MOOCCube is an open data repository for researchers in natural language
    processing, KG, and data mining related to large-scale online education, containing
    706 real online courses, 38,181 instructional videos, 114,563 concepts, hundreds
    of thousands of course selections from 199,199 MOOC users, video viewing records,
    and a supplemental repository containing hundreds of thousands of academic paper
    resources related to in-class concepts. The concept description data is from Baidu
    and Wikipedia, and the course data and student behavior data are from XuetangX.
    Academic paper data is obtained from Aminer, a large-scale academic search engine.
  prefs: []
  type: TYPE_NORMAL
- en: xAPI-Educational Mining Dataset xAPI-Educational Mining Dataset refers to a
    dataset based on the Experience API (xAPI) standard. xAPI is an open learning
    technology specification for recording learner behavior and interaction data in
    a variety of learning environments. The links in the table point to a publicly
    available xAPI-compliant database, Students’ Academic Performance Dataset, stored
    on Kaggle, which contains 480 samples with sixteen features.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Processing Tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are many commonly used tools for processing and analyzing educational
    data in educational scenarios to provide powerful support and insight for educational
    researchers and teachers. This section will focus on several representative tools,
    including LOCO-Analyst, Datashop, SNAPP, GISMO, and Meerkat-ED etc. These tools
    have unique functions and features in educational data processing that can help
    education practitioners better understand the learning process and optimize instructional
    design and practice. By using a combination of these tools, educational researchers
    and teachers can deeply analyze data on student learning behaviors, engagement,
    and learning outcomes, and gain valuable insights from them. The names, links,
    and detailed descriptions of these tools are provided in Table [3](#S4.T3 "Table
    3 ‣ 4.1.2 Datasets from Online Education Platforms ‣ 4.1 Datasets ‣ 4 Datasets
    and Processing Tools ‣ A Comprehensive Survey on Deep Learning Techniques in Educational
    Data Mining").
  prefs: []
  type: TYPE_NORMAL
- en: 5 Future Directions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Deep Learning has shown great promise in EDM. Successful techniques in EDM
    based on Deep Learning can provide valuable insights to improve teaching, learning,
    and assessment. Here are several potential insights into successful techniques
    for EDM using Deep Learning:'
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Learning Analysis and Intervention
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Existing EDM methods often involve offline analysis. Future work could investigate
    the use of real-time learning algorithms, *e.g.*, deep reinforcement learning [[56](#bib.bib56)]
    or real-time recurrent learning algorithms [[68](#bib.bib68)], to offer timely
    insights and interventions for a more responsive educational environment. In addition,
    we can combine Multi-Task Learning [[131](#bib.bib131)] with Attention mechanisms
    to analyze student interaction data from learning management systems or other
    educational platforms, providing knowledge tracing and option tracing [[5](#bib.bib5)]
    into engagement and learning patterns. Multi-Task Learning can also be used to
    identify learners at risk of struggling academically and dropping out, thus allowing
    for early interventions and support.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Social Network Analysis and Collaboration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By learning directly from the graph structure and node features, GCNs can capture
    complex patterns in social networks, helping to analyze social networks within
    educational settings, revealing patterns of collaboration and communication among
    students. These insights can help educators design group activities and assignments
    more effectively or identify students who may benefit from additional support
    or social engagement opportunities. Besides, future work should encourage collaborations
    between computer scientists, educators, and psychologists. Although this direction
    does not focus on a specific algorithm, it emphasizes the importance of interdisciplinary
    knowledge in refining existing algorithms or developing new ones for EDM. For
    example, to make cross-domain recommendations for users in the educational environment,
    we can use the preference-aware Graph Attention Network [[48](#bib.bib48)], which
    leverages collaborative KG to capture user preferences within-domain and across-domain.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Explainable AI in EDM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Given the ‘black box’ problem associated with Deep Learning models, efforts
    should be made to create more transparent and interpretable models. Especially
    in EDM, making these models explainable and transparent becomes increasingly important,
    since education usually places great emphasis on the scientific nature and causal
    relationships of things. Future research could aim to develop or improve methods
    for generating understandable explanations of model predictions, *e.g.*, Deep
    Learning Important FeaTures DeepLIFT) [[95](#bib.bib95)] for the interpretable
    models used in student performance prediction, and Local Interpretable Model-Agnostic
    Explanations (LIME) [[134](#bib.bib134)] or KGs for explainable recommendation
    systems. Moreover, for applications that involve sequential data, such as studying
    student interaction with a learning management system over time, models like LSTM
    or GRU could be enhanced with explainability features. To this end, sequence interpretation
    methods, *e.g.*, Layer-wise Relevance Propagation (LRP) [[70](#bib.bib70)], can
    be used to explain sequential learning patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4 Large Language Models for Education
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) [[69](#bib.bib69)] are transforming many fields,
    including EDM. Their capacity to understand, generate, and complete texts makes
    them a valuable tool in education. For instance, LLMs could be used to generate
    personalized educational content tailored to each learner’s needs, interests,
    and proficiency level. To this end, we could focus on in-context learning or task-specific
    prompt methods for LLMs, such as GPT-4, to achieve better performance in such
    tasks. Besides, LLMs could help create advanced Intelligent Tutoring Systems (ITSs) [[72](#bib.bib72)]
    that can understand and respond to student queries in a contextually appropriate
    manner. Future work should integrate LLMs into existing ITSs and examine their
    impact on student learning outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: It would be interesting that GPT-based architectures [[122](#bib.bib122), [91](#bib.bib91)]
    are employed to automatically score student essays or assess written responses,
    which can reduce the workload for educators and provide consistent evaluation.
    Such architectures are also competent to analyze and understand student language
    use, enabling educators to identify areas where students even teachers struggle
    with understanding or communication.
  prefs: []
  type: TYPE_NORMAL
- en: The LLM agent [[51](#bib.bib51)] represents a groundbreaking development in
    the realm of education technology. The LLM agent excels in generating high-quality
    educational content. Thus, learners can interact with the agent in a conversational
    manner, enabling a more personalized and adaptive learning experience tailored
    to individual needs. Moreover, the LLM agent promotes inclusivity in education
    by offering multilingual support. It can seamlessly communicate in various languages,
    breaking down language barriers and providing access to educational resources
    for a global audience.
  prefs: []
  type: TYPE_NORMAL
- en: 5.5 Multimodal Learning Analytics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many current EDM methods primarily rely on structured data. However, educational
    experiences produce a wealth of unstructured and semi-structured data (*e.g.*,
    image, audio, video, and even biometric data), which provide a more comprehensive
    understanding of student learning experiences. Deep Multimodal Learning algorithms [[84](#bib.bib84)],
    which combine CNNs for image/video data, RNNs or LSTMs for temporal data, and
    Transformers for textual data, could be used to leverage this wealth of information.
    These insights can inform the design of multimodal learning environments and interventions,
    accommodating diverse learning styles and preferences.
  prefs: []
  type: TYPE_NORMAL
- en: Based on the above representation of multimodal learning, multimodal affective
    computing and emotion recognition may be a promising line in EDM. To this end,
    we need well-designed models to analyze student facial expressions, speech, or
    physiological signals to infer emotional states and engagement during learning
    activities. In this way, they help educators adapt their teaching strategies to
    better meet students’ emotional needs and improve overall learning experiences.
    For instance, hybrid contrastive learning [[66](#bib.bib66)] can be employed for
    multimodal sentiment analysis, in which semi-contrastive learning and intra-/inter-modal
    contrastive learning learn multiple relationships from cross-modal interactions.
  prefs: []
  type: TYPE_NORMAL
- en: 5.6 Benchmark Datasets and Evaluation Metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Currently, there is a lack of universally accepted benchmark datasets in EDM.
    For future work, we should focus on creating large, diverse, and representative
    datasets that cover various aspects of the educational process. This task might
    involve techniques from data collection and preprocessing, data anonymization
    (for privacy concerns), and even synthetic data generation methods. Generative
    models (*e.g.*, GANs) could be useful for creating synthetic educational data
    that maintain the statistical properties of real-world data while ensuring student
    privacy. Additionally, different studies in EDM often employ different metrics
    for evaluation, making it difficult to compare results across studies. Future
    work should aim to define and standardize evaluation metrics that effectively
    reflect the performance of deep learning models in EDM. For example, deep meta-learning [[36](#bib.bib36)]
    could be employed to assess and compare the performance of different algorithms
    on EDM tasks. AutoML frameworks [[12](#bib.bib12)], which automatically search
    for the best machine learning pipelines for a given task, could also be utilized
    to identify the most suitable algorithms for specific datasets or tasks in EDM.
  prefs: []
  type: TYPE_NORMAL
- en: 5.7 Fairness and Privacy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dealing with student data brings ethical considerations and privacy concerns
    to the forefront. Firstly, ensuring that EDM models do not perpetuate or amplify
    biases is a significant challenge. For future work, we could focus on developing
    and implementing fairness algorithms, such as equality of opportunity in supervised
    learning [[31](#bib.bib31)], which can help to identify and rectify biases in
    predictive models. Additionally, research could aim to improve techniques for
    bias detection in training data and outcomes. Secondly, to protect students’ privacy,
    the development and application of privacy-preserving data mining techniques should
    be a key focus. Differential privacy [[22](#bib.bib22)], a framework that adds
    noise to the data or query results to ensure that individual records cannot be
    re-identified, offers a promising approach. For example, we can adopt Differential
    Privacy Stochastic Gradient Descent (DP-SGD) [[118](#bib.bib118)] or Private Aggregation
    of Teacher Ensembles (PATE) [[78](#bib.bib78)] to train models without directly
    accessing sensitive data. Lastly, future work could explore the implementation
    and optimization of federated learning algorithm [[46](#bib.bib46)] in EDM. It
    enables model training on local data without having to share it with a central
    server, thereby protecting student information.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, while Deep Learning has already demonstrated its potential in EDM,
    there are quantities of exciting opportunities for further exploration and innovation.
    By focusing on the future directions highlighted above, we hope to promote significant
    progress in the field, contributing to the transformation of educational practices
    and the improvement of educational experiences.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep Learning algorithms have been widely applied in various fields. They have
    shown great potential in EDM to assist in improving the quality of modern education.
    In this survey, we first offer an extensive outline of the current state-of-the-art
    in Deep Learning-based EDM, highlighting three categories of Deep Learning (*i.e.*,
    unsupervised learning, supervised learning, and reinforcement learning) applied
    to four main educational scenarios. Additionally, we draw designs for knowledge
    tracing schema, student behavior detection’s schema, and personalized recommendation
    framework, to demonstrate their principles intuitively. Secondly, a thorough overview
    of public datasets and processing tools for EDM is elaborated. Lastly, to provide
    new opportunities for innovation and improvement in this area, we put forward
    some promising future directions. This survey aims to inspire further research,
    collaboration, and progress toward broadening the application scope of EDM with
    Deep Learning.
  prefs: []
  type: TYPE_NORMAL
- en: \printcredits
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Abdelrahman and Wang [2023] Abdelrahman, G., Wang, Q., 2023. Learning data teaching
    strategies via knowledge tracing. Knowledge-Based Systems , 110511.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ahmad et al. [2023] Ahmad, K., Iqbal, W., El-Hassan, A., Qadir, J., Benhaddou,
    D., Ayyash, M., Al-Fuqaha, A., 2023. Data-driven artificial intelligence in education:
    A comprehensive review. IEEE Transactions on Learning Technologies .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alsabhan [2023] Alsabhan, W., 2023. Student cheating detection in higher education
    by implementing machine learning and lstm techniques. Sensors 23, 4149.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alzubaidi et al. [2021] Alzubaidi, L., Zhang, J., Humaidi, A.J., Al-Dujaili,
    A., Duan, Y., Al-Shamma, O., Santamaría, J., Fadhel, M.A., Al-Amidie, M., Farhan,
    L., 2021. Review of deep learning: Concepts, cnn architectures, challenges, applications,
    future directions. Journal of big Data 8, 1–74.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An et al. [2022] An, S., Kim, J., Kim, M., Park, J., 2022. No task left behind:
    Multi-task learning of knowledge tracing and option tracing for better student
    assessment, in: Proceedings of the AAAI Conference on Artificial Intelligence,
    pp. 4424–4431.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arashpour et al. [2023] Arashpour, M., Golafshani, E.M., Parthiban, R., Lamborn,
    J., Kashani, A., Li, H., Farzanehfar, P., 2023. Predicting individual learning
    performance using machine-learning hybridized with the teaching-learning-based
    optimization. Computer Applications in Engineering Education 31, 83–99.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assami et al. [2022] Assami, S., Daoudi, N., Ajhoun, R., 2022. Implementation
    of a machine learning-based mooc recommender system using learner motivation prediction.
    International Journal of Engineering Pedagogy 12.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beckham et al. [2023] Beckham, N.R., Akeh, L.J., Mitaart, G.N.P., Moniaga, J.V.,
    2023. Determining factors that affect student performance using various machine
    learning methods. Procedia Computer Science 216, 597–603.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bharadhwaj et al. [2018] Bharadhwaj, H., Park, H., Lim, B.Y., 2018. Recgan:
    recurrent generative adversarial networks for recommendation systems, in: Proceedings
    of the 12th ACM Conference on Recommender Systems, pp. 372–376.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buraimoh et al. [2021] Buraimoh, E.F., Ajoodha, R., Padayachee, K., 2021. ‘Predicting
    student success using student engagement in the online component of a blended-learning
    course. Ph.D. thesis. MS thesis, School Comput. Sci. Appl. Math., Dept. Sci.,
    Univ. Witwatersrand ….
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cai et al. [2019] Cai, D., Zhang, Y., Dai, B., 2019. Learning path recommendation
    based on knowledge tracing model and reinforcement learning, in: 2019 IEEE 5th
    international conference on computer and communications (ICCC), IEEE. pp. 1881–1885.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Celik et al. [2022] Celik, B., Singh, P., Vanschoren, J., 2022. Online automl:
    An adaptive automl framework for online learning. Machine Learning , 1–25.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. [2022] Chen, M., Guan, Q., He, Y., He, Z., Fang, L., Luo, W., 2022.
    Knowledge tracing model with learning and forgetting behavior, in: Proceedings
    of the 31st ACM International Conference on Information & Knowledge Management,
    pp. 3863–3867.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen and Ding [2023] Chen, S., Ding, Y., 2023. A machine learning approach to
    predicting academic performance in pennsylvania’s schools. Social Sciences 12,
    118.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2023] Chen, Y., Wei, G., Liu, J., Chen, Y., Zheng, Q., Tian, F.,
    Zhu, H., Wang, Q., Wu, Y., 2023. A prediction model of student performance based
    on self-attention mechanism. Knowledge and Information Systems 65, 733–758.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cheng et al. [2022] Cheng, S., Liu, Q., Chen, E., Zhang, K., Huang, Z., Yin,
    Y., Huang, X., Su, Y., 2022. Adaptkt: A domain adaptable method for knowledge
    tracing, in: Proceedings of the Fifteenth ACM International Conference on Web
    Search and Data Mining, pp. 123–131.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Corbett and Anderson [1994] Corbett, A.T., Anderson, J.R., 1994. Knowledge
    tracing: Modeling the acquisition of procedural knowledge. User modeling and user-adapted
    interaction 4, 253–278.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cui et al. [2023] Cui, J., Chen, Z., Zhou, A., Wang, J., Zhang, W., 2023. Fine-grained
    interaction modeling with multi-relational transformer for knowledge tracing.
    ACM Transactions on Information Systems .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ding and Larson [2020] Ding, X., Larson, E.C., 2020. Automatic rnn cell design
    for knowledge tracing using reinforcement learning, in: Proceedings of the Seventh
    ACM Conference on Learning@ Scale, pp. 285–288.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dorça et al. [2013] Dorça, F.A., Lima, L.V., Fernandes, M.A., Lopes, C.R.,
    2013. Comparing strategies for modeling students learning styles through reinforcement
    learning in adaptive and intelligent educational systems: An experimental analysis.
    Expert Systems with Applications 40, 2092–2101.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Du et al. [2020] Du, X., Yang, J., Hung, J.L., Shelton, B., 2020. Educational
    data mining: a systematic review of research and emerging trends. Information
    Discovery and Delivery 48, 225–236.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dwork [2008] Dwork, C., 2008. Differential privacy: A survey of results, in:
    International conference on theory and applications of models of computation,
    Springer. pp. 1–19.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'El Mourabit et al. [2022] El Mourabit, I., Jai-Andaloussi, S., Abghour, N.,
    2022. Educational data mining techniques for detecting undesirable students’ behaviors
    and predicting students’ performance: A comparative study, in: Advances on Smart
    and Soft Computing: Proceedings of ICACIn 2021, Springer. pp. 163–170.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Feng et al. [2019] Feng, W., Tang, J., Liu, T.X., 2019. Understanding dropouts
    in moocs, in: Proceedings of the AAAI Conference on Artificial Intelligence, pp.
    517–524.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fu et al. [2021] Fu, Q., Gao, Z., Zhou, J., Zheng, Y., 2021. Clsa: A novel
    deep learning model for mooc dropout prediction. Computers & Electrical Engineering
    94, 107315.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao et al. [2022] Gao, M., Luo, Y., Hu, X., 2022. Online course recommendation
    using deep convolutional neural network with negative sequence mining. Wireless
    Communications and Mobile Computing 2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. [2021] Gao, W., Liu, Q., Huang, Z., Yin, Y., Bi, H., Wang, M.C.,
    Ma, J., Wang, S., Su, Y., 2021. Rcd: Relation map driven cognitive diagnosis for
    intelligent education systems, in: Proceedings of the 44th international ACM SIGIR
    conference on research and development in information retrieval, pp. 501–510.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ghosh et al. [2020] Ghosh, A., Heffernan, N., Lan, A.S., 2020. Context-aware
    attentive knowledge tracing, in: Proceedings of the 26th ACM SIGKDD international
    conference on knowledge discovery & data mining, pp. 2330–2339.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Han et al. [2023] Han, X., Zhang, S., Zhou, J., Li, Z., Wang, J., 2023. Deep
    knowledge tracing with gru and learning state enhancement, in: Machine Learning
    for Cyber Security: 4th International Conference, ML4CS 2022, Guangzhou, China,
    December 2–4, 2022, Proceedings, Part III, Springer. pp. 677–686.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hao et al. [2023] Hao, P., Li, Y., Bai, C., 2023. Meta-relationship for course
    recommendation in moocs. Multimedia Systems 29, 235–246.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hardt et al. [2016] Hardt, M., Price, E., Srebro, N., 2016. Equality of opportunity
    in supervised learning. Advances in neural information processing systems 29.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hdioud and Tirari [2023] Hdioud, B., Tirari, M.E.H., 2023. Facial expression
    recognition of masked faces using deep learning. IAES International Journal of
    Artificial Intelligence 12, 921.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hernández-Blanco et al. [2019] Hernández-Blanco, A., Herrera-Flores, B., Tomás,
    D., Navarro-Colorado, B., 2019. A systematic review of deep learning approaches
    to educational data mining. Complexity 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hinton et al. [2006] Hinton, G.E., Osindero, S., Teh, Y.W., 2006. A fast learning
    algorithm for deep belief nets. Neural computation 18, 1527–1554.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hochreiter and Schmidhuber [1997] Hochreiter, S., Schmidhuber, J., 1997. Long
    short-term memory. Neural computation 9, 1735–1780.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huisman et al. [2021] Huisman, M., Van Rijn, J.N., Plaat, A., 2021. A survey
    of deep meta-learning. Artificial Intelligence Review 54, 4483–4541.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Khanal et al. [2020] Khanal, S.S., Prasad, P., Alsadoon, A., Maag, A., 2020.
    A systematic review: machine learning based recommendation systems for e-learning.
    Education and Information Technologies 25, 2635–2664.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Komagal and Yogameena [2023] Komagal, E., Yogameena, B., 2023. Ptz-camera-based
    facial expression analysis using faster r-cnn for student engagement recognition,
    in: Computer Vision and Machine Intelligence Paradigms for SDGs: Select Proceedings
    of ICRTAC-CVMIP 2021\. Springer, pp. 1–14.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kukkar et al. [2023] Kukkar, A., Mohana, R., Sharma, A., Nayyar, A., 2023. Prediction
    of student academic performance based on their emotional wellbeing and interaction
    on various e-learning platforms. Education and Information Technologies , 1–30.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kumar et al. [2023] Kumar, G., Singh, A., Sharma, A., 2023. Ensemble deep learning
    network model for dropout prediction in moocs. International journal of electrical
    and computer engineering systems 14, 187–196.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kumar and Sharma [2017] Kumar, R., Sharma, A., 2017. Data mining in education:
    a review. International Journal of Mechanical Engineering and Information Technology
    5, 1843–1845.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. [2015] LeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning.
    nature 521, 436–444.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2023a] Li, B., Li, G., Xu, J., Li, X., Liu, X., Wang, M., Lv, J.,
    2023a. A personalized recommendation framework based on mooc system integrating
    deep learning and big data. Computers and Electrical Engineering 106, 108571.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2021] Li, D., Zhou, Y., Wang, Z., Gao, D., 2021. Exploiting the potentialities
    of features for speech emotion recognition. Information Sciences 548, 328–343.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. [2022] Li, G., Shuai, J., Hu, Y., Zhang, Y., Wang, Y., Yang, T.,
    Xiong, N., 2022. Dkt-lcirt: A deep knowledge tracking model integrating learning
    capability and item response theory. Electronics 11, 3364.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. [2020] Li, T., Sahu, A.K., Talwalkar, A., Smith, V., 2020. Federated
    learning: Challenges, methods, and future directions. IEEE signal processing magazine
    37, 50–60.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li and Zhang [2019] Li, W., Zhang, L., 2019. Personalized learning path generation
    based on network embedding and learning effects, in: 2019 IEEE 10th international
    conference on software engineering and service science (ICSESS), IEEE. pp. 316–319.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2023b] Li, Y., Hou, L., Li, J., 2023b. Preference-aware graph attention
    networks for cross-domain recommendations with collaborative knowledge graph.
    ACM Transactions on Information Systems 41, 1–26.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. [2023c] Li, Z., Yu, S., Lu, Y., Chen, P., 2023c. Plastic gating network:
    Adapting to personal development and individual differences in knowledge tracing.
    Information Sciences .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. [2023] Liang, Z., Mu, L., Chen, J., Xie, Q., 2023. Graph path fusion
    and reinforcement reasoning for recommendation in moocs. Education and Information
    Technologies 28, 525–545.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liao et al. [2023] Liao, L., Yang, G.H., Shah, C., 2023. Proactive conversational
    agents in the post-chatgpt world, in: Proceedings of the 46th International ACM
    SIGIR Conference on Research and Development in Information Retrieval, pp. 3452–3455.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. [2023a] Lin, Y., Feng, S., Lin, F., Xiahou, J., Zeng, W., 2023a.
    Multi-scale reinforced profile for personalized recommendation with deep neural
    networks in moocs. Applied Soft Computing 148, 110905.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. [2021] Lin, Y., Feng, S., Lin, F., Zeng, W., Liu, Y., Wu, P., 2021.
    Adaptive course recommendation in moocs. Knowledge-Based Systems 224, 107085.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. [2022a] Lin, Y., Lin, F., Yang, L., Zeng, W., Liu, Y., Wu, P., 2022a.
    Context-aware reinforcement learning for course recommendation. Applied Soft Computing
    125, 109189.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. [2022b] Lin, Y., Lin, F., Zeng, W., Xiahou, J., Li, L., Wu, P., Liu,
    Y., Miao, C., 2022b. Hierarchical reinforcement learning with dynamic recurrent
    mechanism for course recommendation. Knowledge-Based Systems 244, 108546.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. [2023b] Lin, Y., Liu, Y., Lin, F., Zou, L., Wu, P., Zeng, W., Chen,
    H., Miao, C., 2023b. A survey on reinforcement learning for recommender systems.
    IEEE Transactions on Neural Networks and Learning Systems , 1–21.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. [2023c] Lin, Y., Zhang, W., Lin, F., Zeng, W., Zhou, X., Wu, P.,
    2023c. Knowledge-aware reasoning with self-supervised reinforcement learning for
    explainable recommendation in moocs. Neural Computing and Applications , 1–18.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2023] Liu, H., Chen, X., Zhao, F., 2023. Learning behavior feature
    fused deep learning network model for mooc dropout prediction. Education and Information
    Technologies , 1–22.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2021] Liu, Q., Shen, S., Huang, Z., Chen, E., Zheng, Y., 2021. A
    survey of knowledge tracing. arXiv preprint arXiv:2105.15106 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. [2019] Liu, Q., Tong, S., Liu, C., Zhao, H., Chen, E., Ma, H., Wang,
    S., 2019. Exploiting cognitive structure for adaptive learning, in: Proceedings
    of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data
    Mining, pp. 627–635.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2022] Liu, T., Wu, Q., Chang, L., Gu, T., 2022. A review of deep
    learning-based recommender system in e-learning environments. Artificial Intelligence
    Review 55, 5953–5980.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Long et al. [2021] Long, T., Liu, Y., Shen, J., Zhang, W., Yu, Y., 2021. Tracing
    knowledge state with individual cognition and acquisition estimation, in: Proceedings
    of the 44th International ACM SIGIR Conference on Research and Development in
    Information Retrieval, pp. 173–182.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lyu et al. [2022] Lyu, L., Wang, Z., Yun, H., Yang, Z., Li, Y., 2022. Deep knowledge
    tracing based on spatial and temporal representation learning for learning performance
    prediction. Applied Sciences 12, 7188.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lyu et al. [2023] Lyu, L., Wang, Z., Yun, H., Yang, Z., Li, Y., 2023. Dkt-stdrl:
    Spatial and temporal representation learning enhanced deep knowledge tracing for
    learning performance prediction. arXiv preprint arXiv:2302.11569 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ma et al. [2023] Ma, Y., Zhang, X., Gao, C., Tang, Y., Li, L., Zhu, R., Yin,
    C., 2023. Enhancing recommendations with contrastive learning from collaborative
    knowledge graph. Neurocomputing 523, 103–115.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mai et al. [2022] Mai, S., Zeng, Y., Zheng, S., Hu, H., 2022. Hybrid contrastive
    learning of tri-modal representation for multimodal sentiment analysis. IEEE Transactions
    on Affective Computing .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mathew et al. [2021] Mathew, A., Amudha, P., Sivakumari, S., 2021. Deep learning
    techniques: an overview. Advanced Machine Learning Technologies and Applications:
    Proceedings of AMLTA 2020 , 599–608.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Menick et al. [2020] Menick, J., Elsen, E., Evci, U., Osindero, S., Simonyan,
    K., Graves, A., 2020. Practical real time recurrent learning with a sparse approximation,
    in: International conference on learning representations, pp. 1–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Min et al. [2021] Min, B., Ross, H., Sulem, E., Veyseh, A.P.B., Nguyen, T.H.,
    Sainz, O., Agirre, E., Heintz, I., Roth, D., 2021. Recent advances in natural
    language processing via large pre-trained language models: A survey. ACM Computing
    Surveys .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Montavon et al. [2019] Montavon, G., Binder, A., Lapuschkin, S., Samek, W.,
    Müller, K.R., 2019. Layer-wise relevance propagation: an overview. Explainable
    AI: interpreting, explaining and visualizing deep learning , 193–209.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Montero et al. [2018] Montero, S., Arora, A., Kelly, S., Milne, B., Mozer, M.,
    2018. Does deep knowledge tracing model interactions among skills?. International
    Educational Data Mining Society .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mousavinasab et al. [2021] Mousavinasab, E., Zarifsanaiey, N., R. Niakan Kalhori,
    S., Rakhshan, M., Keikha, L., Ghazi Saeedi, M., 2021. Intelligent tutoring systems:
    a systematic review of characteristics, applications, and evaluation methods.
    Interactive Learning Environments 29, 142–163.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nagatani et al. [2019] Nagatani, K., Zhang, Q., Sato, M., Chen, Y.Y., Chen,
    F., Ohkuma, T., 2019. Augmenting knowledge tracing by considering forgetting behavior,
    in: The world wide web conference, pp. 3101–3107.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nayani [2023] Nayani, S., 2023. Combination of deep learning models for student’s
    performance prediction with a development of entropy weighted rough set feature
    mining. Cybernetics and Systems , 1–43.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Neha et al. [2023] Neha, K., Kumar, R., Jahangeer Sidiq, S., Zaman, M., 2023.
    Deep neural networks predicting student performance, in: Proceedings of International
    Conference on Data Science and Applications: ICDSA 2022, Volume 2, Springer. pp.
    71–79.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ni et al. [2023] Ni, Q., Wei, T., Zhao, J., He, L., Zheng, C., 2023. Hhskt:
    A learner–question interactions based heterogeneous graph neural network model
    for knowledge tracing. Expert Systems with Applications 215, 119334.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandey and Karypis [2019] Pandey, S., Karypis, G., 2019. A self-attentive model
    for knowledge tracing. arXiv preprint arXiv:1907.06837 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Papernot et al. [2016] Papernot, N., Abadi, M., Erlingsson, U., Goodfellow,
    I., Talwar, K., 2016. Semi-supervised knowledge transfer for deep learning from
    private training data. arXiv preprint arXiv:1610.05755 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Perrotta and Selwyn [2020] Perrotta, C., Selwyn, N., 2020. Deep learning goes
    to school: Toward a relational understanding of ai in education. Learning, Media
    and Technology 45, 251–269.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Piech et al. [2015] Piech, C., Bassen, J., Huang, J., Ganguli, S., Sahami, M.,
    Guibas, L.J., Sohl-Dickstein, J., 2015. Deep knowledge tracing. Advances in neural
    information processing systems 28.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prenkaj et al. [2020] Prenkaj, B., Velardi, P., Stilo, G., Distante, D., Faralli,
    S., 2020. A survey of machine learning approaches for student dropout prediction
    in online courses. ACM Computing Surveys (CSUR) 53, 1–34.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qiu et al. [2023] Qiu, Q., Wang, T., Chen, F., Wang, C., 2023. Ld-recognition:
    Classroom action recognition based on passive rfid. IEEE Transactions on Computational
    Social Systems .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Raghuveer et al. [2014] Raghuveer, V., Tripathy, B., Singh, T., Khanna, S.,
    2014. Reinforcement learning approach towards effective content recommendation
    in mooc environments, in: 2014 IEEE International Conference on MOOC, Innovation
    and Technology in Education (MITE), IEEE. pp. 285–289.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ramachandram and Taylor [2017] Ramachandram, D., Taylor, G.W., 2017. Deep multimodal
    learning: A survey on recent advances and trends. IEEE signal processing magazine
    34, 96–108.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rastrollo-Guerrero et al. [2020] Rastrollo-Guerrero, J.L., Gómez-Pulido, J.A.,
    Durán-Domínguez, A., 2020. Analyzing and predicting students’ performance by means
    of machine learning: A review. Applied sciences 10, 1042.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Romero et al. [2013] Romero, C., Olmo, J.L., Ventura, S., 2013. A meta-learning
    approach for recommending a subset of white-box classification algorithms for
    moodle datasets, in: Educational Data Mining 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Romero and Ventura [2020] Romero, C., Ventura, S., 2020. Educational data mining
    and learning analytics: An updated survey. Wiley Interdisciplinary Reviews: Data
    Mining and Knowledge Discovery 10, e1355.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Safarov et al. [2023] Safarov, F., Kutlimuratov, A., Abdusalomov, A.B., Nasimov,
    R., Cho, Y.I., 2023. Deep learning recommendations of e-education based on clustering
    and sequence. Electronics 12, 809.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sahebi and Brusilovsky [2018] Sahebi, S., Brusilovsky, P., 2018. Student performance
    prediction by discovering inter-activity relations. International Educational
    Data Mining Society .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sakboonyarat and Tantatsanawong [2022] Sakboonyarat, S., Tantatsanawong, P.,
    2022. Applied big data technique and deep learning for massive open online courses
    (moocs) recommendation system. ECTI Transactions on Computer and Information Technology
    (ECTI-CIT) 16, 436–447.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sanderson [2023] Sanderson, K., 2023. Gpt-4 is here: what scientists think.
    Nature 615, 773.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sarwat et al. [2022] Sarwat, S., Ullah, N., Sadiq, S., Saleem, R., Umer, M.,
    Eshmawi, A., Mohamed, A., Ashraf, I., 2022. Predicting students’ academic performance
    with conditional generative adversarial network and deep svm. Sensors 22, 4834.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shaw et al. [2023] Shaw, H., Deepak, G., Santhanavijayan, A., 2023. Tcrkds:
    Towards integration of semantic intelligence for course recommendation in support
    of a knowledge driven strategy, in: Machine Learning, Image Processing, Network
    Security and Data Sciences: Select Proceedings of 3rd International Conference
    on MIND 2021, Springer. pp. 693–702.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shawky and Badawi [2018] Shawky, D., Badawi, A., 2018. A reinforcement learning-based
    adaptive learning system, in: The international conference on advanced machine
    learning technologies and applications (AMLTA2018), Springer. pp. 221–231.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shrikumar et al. [2017] Shrikumar, A., Greenside, P., Kundaje, A., 2017. Learning
    important features through propagating activation differences, in: International
    conference on machine learning, PMLR. pp. 3145–3153.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Siemens and Baker [2012] Siemens, G., Baker, R.S.d., 2012. Learning analytics
    and educational data mining: towards communication and collaboration, in: Proceedings
    of the 2nd international conference on learning analytics and knowledge, pp. 252–254.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Song et al. [2022] Song, X., Li, J., Cai, T., Yang, S., Yang, T., Liu, C., 2022.
    A survey on deep learning based knowledge tracing. Knowledge-Based Systems 258,
    110036.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stenton and Rivas [2021] Stenton, E., Rivas, P., 2021. Fine tuning a generative
    adversarial network’s discriminator for student attrition prediction, in: Advances
    in Artificial Intelligence and Applied Cognitive Computing: Proceedings from ICAI’20
    and ACC’20, Springer. pp. 3–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. [2019] Sun, D., Mao, Y., Du, J., Xu, P., Zheng, Q., Sun, H., 2019.
    Deep learning for dropout prediction in moocs, in: 2019 eighth international conference
    on educational innovation through technology (EITT), IEEE. pp. 87–90.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. [2021] Sun, Z., Harit, A., Yu, J., Cristea, A.I., Shi, L., 2021.
    A brief survey of deep learning approaches for learning analytics on moocs, in:
    Intelligent Tutoring Systems: 17th International Conference, ITS 2021, Virtual
    Event, June 7–11, 2021, Proceedings 17, Springer. pp. 28–37.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tan et al. [2023] Tan, L., Tan, O.K., Sze, C.C., Goh, W.W.B., 2023. Emotional
    variance analysis: A new sentiment analysis feature set for artificial intelligence
    and machine learning applications. Plos one 18, e0274299.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tang et al. [2019] Tang, X., Chen, Y., Li, X., Liu, J., Ying, Z., 2019. A reinforcement
    learning approach to personalized learning recommendation systems. British Journal
    of Mathematical and Statistical Psychology 72, 108–135.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tong et al. [2022] Tong, S., Liu, J., Hong, Y., Huang, Z., Wu, L., Liu, Q.,
    Huang, W., Chen, E., Zhang, D., 2022. Incremental cognitive diagnosis for intelligent
    education, in: Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery
    and Data Mining, pp. 1760–1770.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. [2022] Touvron, H., Bojanowski, P., Caron, M., Cord, M., El-Nouby,
    A., Grave, E., Izacard, G., Joulin, A., Synnaeve, G., Verbeek, J., et al., 2022.
    Resmlp: Feedforward networks for image classification with data-efficient training.
    IEEE Transactions on Pattern Analysis and Machine Intelligence 45, 5314–5321.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Uzel et al. [2018] Uzel, V.N., Turgut, S.S., Özel, S.A., 2018. Prediction of
    students’ academic success using data mining methods, in: 2018 Innovations in
    Intelligent Systems and Applications Conference (ASYU), IEEE. pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vaswani et al. [2017] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,
    L., Gomez, A.N., Kaiser, Ł., Polosukhin, I., 2017. Attention is all you need.
    Advances in neural information processing systems 30.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vedavathi and Anil Kumar [2023] Vedavathi, N., Anil Kumar, K., 2023. Plrec:
    An efficient approach towards e-learning recommendation using lstm-cnn technique,
    in: Proceedings of the International Conference on Cognitive and Intelligent Computing:
    ICCIC 2021, Volume 2, Springer. pp. 541–556.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. [2020] Wang, F., Liu, Q., Chen, E., Huang, Z., Chen, Y., Yin, Y.,
    Huang, Z., Wang, S., 2020. Neural cognitive diagnosis for intelligent education
    systems, in: Proceedings of the AAAI conference on artificial intelligence, pp.
    6153–6161.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2023] Wang, H., Gao, C., Fu, H., Ma, C.Z.H., Wang, Q., He, Z.,
    Li, M., 2023. Automated student classroom behaviors’ perception and identification
    using motion sensors. Bioengineering 10, 127.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. [2017] Wang, W., Yu, H., Miao, C., 2017. Deep model for dropout
    prediction in moocs, in: Proceedings of the 2nd international conference on crowd
    science and engineering, pp. 26–32.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2022] Wang, X., Jia, L., Guo, L., Liu, F., 2022. Multi-aspect heterogeneous
    information network for mooc knowledge concept recommendation. Applied Intelligence
    , 1–15.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. [2021] Wang, Y., Liu, Z., Fan, Z., Sun, L., Yu, P.S., 2021. Dskreg:
    Differentiable sampling on knowledge graph for recommendation with relational
    gnn, in: Proceedings of the 30th ACM International Conference on Information &
    Knowledge Management, pp. 3513–3517.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wilson et al. [2016a] Wilson, K.H., Karklin, Y., Han, B., Ekanadham, C., 2016a.
    Back to the basics: Bayesian extensions of irt outperform neural networks for
    proficiency estimation. arXiv preprint arXiv:1604.02336 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wilson et al. [2016b] Wilson, K.H., Xiong, X., Khajah, M., Lindsey, R.V., Zhao,
    S., Karklin, Y., Van Inwegen, E.G., Han, B., Ekanadham, C., Beck, J.E., et al.,
    2016b. Estimating student proficiency: Deep learning is not the panacea, in: In
    Neural information processing systems, workshop on machine learning for education.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. [2022] Wu, S., Sun, F., Zhang, W., Xie, X., Cui, B., 2022. Graph
    neural networks in recommender systems: a survey. ACM Computing Surveys 55, 1–37.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. [2020] Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., Philip, S.Y.,
    2020. A comprehensive survey on graph neural networks. IEEE transactions on neural
    networks and learning systems 32, 4–24.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xiao et al. [2023] Xiao, Y., Xiao, R., Huang, N., Hu, Y., Li, H., Sun, B., 2023.
    Knowledge tracing based on multi-feature fusion. Neural Computing and Applications
    35, 1819–1833.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xie et al. [2021] Xie, Y., Li, P., Wu, C., Wu, Q., 2021. Differential privacy
    stochastic gradient descent with adaptive privacy budget allocation, in: 2021
    IEEE International Conference on Consumer Electronics and Computer Engineering
    (ICCECE), IEEE. pp. 227–231.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xing and Du [2019] Xing, W., Du, D., 2019. Dropout prediction in moocs: Using
    deep learning for personalized intervention. Journal of Educational Computing
    Research 57, 547–570.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. [2021] Yang, Y., Shen, J., Qu, Y., Liu, Y., Wang, K., Zhu, Y.,
    Zhang, W., Yu, Y., 2021. Gikt: a graph-based interaction model for knowledge tracing,
    in: Machine Learning and Knowledge Discovery in Databases: European Conference,
    ECML PKDD 2020, Ghent, Belgium, September 14–18, 2020, Proceedings, Part I, Springer.
    pp. 299–315.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhai et al. [2018] Zhai, J., Zhang, S., Chen, J., He, Q., 2018. Autoencoder
    and its various variants, in: 2018 IEEE international conference on systems, man,
    and cybernetics (SMC), IEEE. pp. 415–419.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. [2023a] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang,
    M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023a. A complete survey
    on generative ai (aigc): Is chatgpt from gpt-4 to gpt-5 all you need? arXiv preprint
    arXiv:2303.11717 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2020] Zhang, H., Huang, T., Liu, S., Yin, H., Li, J., Yang, H.,
    Xia, Y., 2020. A learning style classification approach based on deep belief network
    for large-scale online education. Journal of cloud computing 9, 1–17.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. [2023b] Zhang, H., Shen, X., Yi, B., Wang, W., Feng, Y., 2023b.
    Kgan: Knowledge grouping aggregation network for course recommendation in moocs.
    Expert Systems with Applications 211, 118344.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. [2019a] Zhang, J., Hao, B., Chen, B., Li, C., Chen, H., Sun, J.,
    2019a. Hierarchical reinforcement learning for course recommendation in moocs,
    in: Proceedings of the AAAI conference on artificial intelligence, pp. 435–442.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2018] Zhang, Q., Yang, L.T., Chen, Z., Li, P., 2018. A survey
    on deep learning for big data. Information Fusion 42, 146–157.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. [2019b] Zhang, S., Yao, L., Sun, A., Tay, Y., 2019b. Deep learning
    based recommender system: A survey and new perspectives. ACM computing surveys
    (CSUR) 52, 1–38.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2022a] Zhang, W., Lin, Y., Liu, Y., You, H., Wu, P., Lin, F.,
    Zhou, X., 2022a. Self-supervised reinforcement learning with dual-reward for knowledge-aware
    recommendation. Applied Soft Computing 131, 109745.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. [2022b] Zhang, W., Zhang, Y., Liu, S., Shang, X., 2022b. Online
    deep knowledge tracing, in: 2022 IEEE International Conference on Data Mining
    Workshops (ICDMW), IEEE. pp. 292–297.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2022c] Zhang, X., Li, M., Seng, D., Chen, X., Chen, X., 2022c.
    A novel precise personalized learning recommendation model regularized with trust
    and influence. Scientific Programming 2022, 1–15.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang and Yang [2021] Zhang, Y., Yang, Q., 2021. A survey on multi-task learning.
    IEEE Transactions on Knowledge and Data Engineering 34, 5586–5609.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. [2023a] Zhao, N., Long, Z., Wang, J., Zhao, Z.D., 2023a. Agre:
    A knowledge graph recommendation algorithm based on multiple paths embeddings
    rnn encoder. Knowledge-Based Systems 259, 110078.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. [2023b] Zhao, W., Xia, J., Jiang, X., He, T., 2023b. A novel framework
    for deep knowledge tracing via gating-controlled forgetting and learning mechanisms.
    Information Processing & Management 60, 103114.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. [2021] Zhao, X., Huang, W., Huang, X., Robu, V., Flynn, D., 2021.
    Baylime: Bayesian local interpretable model-agnostic explanations, in: Uncertainty
    in artificial intelligence, PMLR. pp. 887–896.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou and Herencsar [2023] Zhou, J., Herencsar, N., 2023. Abnormal behavior determination
    model of multimedia classroom students based on multi-task deep learning. Mobile
    Networks and Applications , 1–14.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. [2018] Zhou, Y., Huang, C., Hu, Q., Zhu, J., Tang, Y., 2018. Personalized
    learning full-path recommendation model based on lstm neural networks. Information
    sciences 444, 135–152.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhuang et al. [2022] Zhuang, Y., Liu, Q., Huang, Z., Li, Z., Shen, S., Ma,
    H., 2022. Fully adaptive framework: Neural computerized adaptive testing for online
    education, in: Proceedings of the AAAI Conference on Artificial Intelligence,
    pp. 4734–4742.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
