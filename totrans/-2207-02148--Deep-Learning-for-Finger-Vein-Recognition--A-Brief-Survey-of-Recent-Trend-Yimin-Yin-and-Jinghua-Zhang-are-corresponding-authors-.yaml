- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:45:25'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:45:25
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2207.02148] Deep Learning for Finger Vein Recognition: A Brief Survey of Recent
    Trend Yimin Yin and Jinghua Zhang are corresponding authors.'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2207.02148] 深度学习在指静脉识别中的应用：近年来趋势的简要调查 尹一敏和郑晶华为通讯作者。'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2207.02148](https://ar5iv.labs.arxiv.org/html/2207.02148)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2207.02148](https://ar5iv.labs.arxiv.org/html/2207.02148)
- en: 'Deep Learning for Finger Vein Recognition: A Brief Survey of Recent Trend'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在指静脉识别中的应用：近年来趋势的简要调查
- en: '^†^†thanks: Yimin Yin and Jinghua Zhang are corresponding authors.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ^†^†致谢：尹一敏和郑晶华为通讯作者。
- en: Renye Zhang School of Computer Science
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Renye Zhang 计算机科学学院
- en: Hunan First Normal University Changsha, China
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 湖南第一师范大学 中国长沙
- en: renyezhang2016@163.com    Yimin Yin School of Mathematics and Statistics
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: renyezhang2016@163.com    尹一敏 数学与统计学院
- en: Hunan First Normal University Changsha, China
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 湖南第一师范大学 中国长沙
- en: yinyimin16@nudt.edu.cn    Wanxia Deng College of Electronic Science
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: yinyimin16@nudt.edu.cn    Wanxia Deng 电子科学学院
- en: National University of Defense Technology Changsha, China
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 国防科技大学 中国长沙
- en: wanxiadeng@163.com    Chen Li College of Medicine and Biological Information
    Engineering
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: wanxiadeng@163.com    Chen Li 医学与生物信息工程学院
- en: Northeastern University Shenyang, China
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 东北大学 中国沈阳
- en: lichen201096@hotmail.com    Jinghua Zhang College of Intelligent Science and
    Technology
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: lichen201096@hotmail.com    Jinghua Zhang 智能科学与技术学院
- en: National University of Defense Technology Changsha, China
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 国防科技大学 中国长沙
- en: zhangjingh@foxmail.com
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: zhangjingh@foxmail.com
- en: Abstract
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Finger vein image recognition technology plays an important role in biometric
    recognition and has been successfully applied in many fields. Because veins are
    buried beneath the skin tissue, finger vein image recognition has an unparalleled
    advantage, which is not easily disturbed by external factors. This review summarizes
    46 papers about deep learning for finger vein image recognition from 2017 to 2021\.
    These papers are summarized according to the tasks of deep neural networks. Besides,
    we present the challenges and potential development directions of finger vein
    image recognition.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 指静脉图像识别技术在生物识别中发挥了重要作用，并已成功应用于许多领域。由于静脉埋藏在皮肤组织下，指静脉图像识别具有无与伦比的优势，不易受到外部因素的干扰。本文综述了2017年至2021年间46篇关于指静脉图像识别的深度学习论文。这些论文根据深度神经网络的任务进行了总结。此外，我们还介绍了指静脉图像识别的挑战和潜在发展方向。
- en: 'Index Terms:'
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Finger vein image recognition, Deep learning, Deep neural network
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 指静脉图像识别，深度学习，深度神经网络
- en: I Introduction
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: Biometric recognition aims to identify a person based on physical features,
    such as fingerprint, voice, and iris [[1](#bib.bib1)]. With the growing requirement
    of digital security verification systems, the biometric recognition plays a vital
    role in many fields, such as online payment, security, and other fields. Compared
    to the traditional secure identification process, biometric recognition technology
    is more efficient due to its convenience and steady security. Unfortunately, several
    representative biometric identification technologies are struck in some bottlenecks.
    For instance, the fingerprint recognition rate is significantly affected by the
    finger surface. Besides, the fingerprints inadvertently left on things may lead
    to security risks. Voice recognition usually requires a relatively quiet environment.
    The recognition rate of iris systems is outstanding, but it requires expensive
    sensors. Different from above technologies, the *Finger Vein Image Recognition*
    (FVIR) is efficient and low-cost. The finger vein is buried beneath the skin of
    the finger and is unique to each individual. It can be recognized through the
    near-infrared light [[2](#bib.bib2)] not the visible light which is vulnerable
    to external factors.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 生物识别旨在通过物理特征，如指纹、声音和虹膜，识别一个人[[1](#bib.bib1)]。随着数字安全验证系统需求的增长，生物识别在许多领域中扮演了至关重要的角色，如在线支付、安全等。与传统的安全识别过程相比，生物识别技术由于其便利性和稳定的安全性更加高效。不幸的是，几种具有代表性的生物识别技术遇到了瓶颈。例如，指纹识别率受到手指表面的显著影响。此外，无意间留在物体上的指纹可能导致安全风险。语音识别通常需要相对安静的环境。虹膜系统的识别率很高，但需要昂贵的传感器。不同于上述技术，*指静脉图像识别*（FVIR）高效且成本低。指静脉埋藏在手指的皮肤下，对每个人都是独特的。它可以通过近红外光[[2](#bib.bib2)]而非易受外部因素影响的可见光来识别。
- en: Artificial intelligence technology, especially *Deep Learning* (DL) technology,
    has developed rapidly in recent years. Compared with transitional image processing
    methods, DL achieves overwhelming performance in many tasks of computer vision,
    such as biometric recognition [[1](#bib.bib1)], biomedical image analysis [[6](#bib.bib6)],
    and autonomous driving [[7](#bib.bib7)]. DL-based methods are widely used in FVIR
    tasks. The traditional FVIR process usually includes image capture, image data
    pre-processing, feature extraction, and classification or other analysis tasks.
    The application of DL-based methods, especially *Convolutional Neural Networks*
    (CNNs), greatly changes the manual feature extraction process. The performance
    of conventional machine learning approaches is significantly influenced by feature
    engineering, in which the feature selection is based on human domain knowledge.
    Nevertheless, CNNs can extract abstract but efficient features by supervised or
    semi-supervised learning. The recognition process has been extremely simplified
    by DL-based methods.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能技术，尤其是*深度学习*（DL）技术，近年来发展迅速。与传统的图像处理方法相比，DL在计算机视觉的许多任务中表现出压倒性的性能，如生物特征识别[[1](#bib.bib1)]、生物医学图像分析[[6](#bib.bib6)]和自动驾驶[[7](#bib.bib7)]。基于DL的方法广泛应用于FVIR任务。传统的FVIR过程通常包括图像采集、图像数据预处理、特征提取以及分类或其他分析任务。基于DL的方法，特别是*卷积神经网络*（CNNs），极大地改变了手动特征提取的过程。传统机器学习方法的性能受特征工程的显著影响，其中特征选择基于人类领域知识。然而，CNNs可以通过有监督或半监督学习提取抽象但有效的特征。DL基于的方法极大地简化了识别过程。
- en: 'To illustrate the recent trend and potential direction of DL-based FVIR, we
    conduct this brief survey. We summarize 46 related papers from 2017 to 2021, which
    cover different finger vein image analysis tasks, including classification, feature
    extraction, image enhancement, image segmentation, encryption. These papers are
    collected from popular academic dataset or searching engine, which mainly includes
    IEEE, Springer, Elsevier, and Google Scholar. We use “finger vein image analysis”
    AND (“deep learning” OR “neural network” OR “ANN” OR “CNN”OR “GAN” OR “RNN” OR
    “LSTM”) as the searching keywords. The structure of this paper is as follows:
    In Sec. [II](#S2 "II Deep learning techniques ‣ Deep Learning for Finger Vein
    Recognition: A Brief Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding
    authors."), we briefly introduce the commonly used public datasets, some representative
    DL techniques, and existing survey papers. In Sec. [III](#S3 "III Finger vein
    recognition based on deep learning ‣ Deep Learning for Finger Vein Recognition:
    A Brief Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors."),
    the related papers are summarized according to the tasks of neural networks. In
    Sec. [IV](#S4 "IV Challenge and potential direction ‣ Deep Learning for Finger
    Vein Recognition: A Brief Survey of Recent Trend Yimin Yin and Jinghua Zhang are
    corresponding authors."), the challenges and potential directions of FVIR are
    talked. Finally, in Sec. [V](#S5 "V Conclusion and future work ‣ Deep Learning
    for Finger Vein Recognition: A Brief Survey of Recent Trend Yimin Yin and Jinghua
    Zhang are corresponding authors."), the conclusion and future work of this paper
    is provided.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '为了阐明基于DL的FVIR的最新趋势和潜在方向，我们进行了这项简要调查。我们总结了2017年至2021年间的46篇相关论文，涵盖了不同的指静脉图像分析任务，包括分类、特征提取、图像增强、图像分割和加密。这些论文来自流行的学术数据集或搜索引擎，主要包括IEEE、Springer、Elsevier和Google
    Scholar。我们使用“finger vein image analysis” AND（“deep learning” OR “neural network”
    OR “ANN” OR “CNN” OR “GAN” OR “RNN” OR “LSTM”）作为搜索关键词。本文的结构如下：在第[II](#S2 "II Deep
    learning techniques ‣ Deep Learning for Finger Vein Recognition: A Brief Survey
    of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors.")节，我们简要介绍了常用的公开数据集、一些代表性的DL技术和现有的综述论文。在第[III](#S3
    "III Finger vein recognition based on deep learning ‣ Deep Learning for Finger
    Vein Recognition: A Brief Survey of Recent Trend Yimin Yin and Jinghua Zhang are
    corresponding authors.")节，根据神经网络的任务总结相关论文。在第[IV](#S4 "IV Challenge and potential
    direction ‣ Deep Learning for Finger Vein Recognition: A Brief Survey of Recent
    Trend Yimin Yin and Jinghua Zhang are corresponding authors.")节，讨论了FVIR的挑战和潜在方向。最后，在第[V](#S5
    "V Conclusion and future work ‣ Deep Learning for Finger Vein Recognition: A Brief
    Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors.")节，提供了本文的结论和未来工作。'
- en: II Deep learning techniques
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 深度学习技术
- en: In this section, we first introduce the commonly used public datasets. Then,
    the most widely used networks in FVIR are summarized. Finally, we also discuss
    the difference between our survey and existing papers.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们首先介绍常用的公共数据集。然后，总结了FVIR中最广泛使用的网络。最后，我们还讨论了我们的调查与现有文献之间的差异。
- en: II-A Dataset
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 数据集
- en: 'Dataset is critical in developing FVIR technology. The image data capacity
    and quality in the dataset can directly affect the performance of DL model. Through
    the investigation of relevant papers, the most widely used datasets are FV-USM [[58](#bib.bib58)],
    HKPU [[59](#bib.bib59)], MMCBNU-6000 [[60](#bib.bib60)], SDUMLA-HMT [[61](#bib.bib61)],
    UTFVP [[62](#bib.bib62)]. The base information of these datasets are provided
    in Tab. [I](#S2.T1 "TABLE I ‣ II-A Dataset ‣ II Deep learning techniques ‣ Deep
    Learning for Finger Vein Recognition: A Brief Survey of Recent Trend Yimin Yin
    and Jinghua Zhang are corresponding authors.").'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '数据集在开发FVIR技术中至关重要。数据集中的图像数据容量和质量直接影响深度学习模型的性能。通过对相关文献的调查，使用最广泛的数据集有FV-USM [[58](#bib.bib58)],
    HKPU [[59](#bib.bib59)], MMCBNU-6000 [[60](#bib.bib60)], SDUMLA-HMT [[61](#bib.bib61)],
    UTFVP [[62](#bib.bib62)]。这些数据集的基本信息见表[I](#S2.T1 "TABLE I ‣ II-A Dataset ‣ II Deep
    learning techniques ‣ Deep Learning for Finger Vein Recognition: A Brief Survey
    of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors.").'
- en: 'TABLE I: The base information of finger vein datasets.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '表I: 指纹静脉数据集的基本信息。'
- en: '| Dataset | Data Source | Image Number | Resolution |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 数据来源 | 图像数量 | 分辨率 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| SDUMLA-HMT | 106 | 3816 | 320 $\times$ 240 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| SDUMLA-HMT | 106 | 3816 | 320 $\times$ 240 |'
- en: '| HKPU | 156 | 3132 | 513 $\times$ 256 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| HKPU | 156 | 3132 | 513 $\times$ 256 |'
- en: '| MMCBNU-6000 | 100 | 6000 | 320 $\times$ 240 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| MMCBNU-6000 | 100 | 6000 | 320 $\times$ 240 |'
- en: '| FV-USM | 123 | 5904 | 640 $\times$ 480 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| FV-USM | 123 | 5904 | 640 $\times$ 480 |'
- en: '| UTFVP | 60 | 1440 | 672 $\times$ 380 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| UTFVP | 60 | 1440 | 672 $\times$ 380 |'
- en: '| THU-FVFDT2 | 610 | 2440 | 720 $\times$ 576 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| THU-FFVDT2 | 610 | 2440 | 720 $\times$ 576 |'
- en: II-B Deep Neural Networks
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 深度神经网络
- en: 'AlexNet [[8](#bib.bib8)], ResNet [[9](#bib.bib9)], and GAN [[5](#bib.bib5)]
    are the most widely used networks in FVIR. The base characteristics of them are
    provided as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet [[8](#bib.bib8)], ResNet [[9](#bib.bib9)], 和GAN [[5](#bib.bib5)]是FVIR中最广泛使用的网络。它们的基本特征如下：
- en: II-B1 AlexNet
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B1 AlexNet
- en: 'AlexNet is a milestone in DL technology. Before it, the development of neural
    network technology was at a low ebb for many years. It is the first CNN to win
    the ILSVRC 2012\. After AlexNet, DL starts to be the mainstream technology in
    many computer vision tasks [[64](#bib.bib64)]. The structure of AlexNet contains
    five convolutional layers and three max-pooling layers. Additionally, it has three
    fully connected layers with 4096, 4096 and 1000 neurons, respectively. Its structure
    is provided in Fig. [1](#S2.F1 "Figure 1 ‣ II-B1 AlexNet ‣ II-B Deep Neural Networks
    ‣ II Deep learning techniques ‣ Deep Learning for Finger Vein Recognition: A Brief
    Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors.").
    This network adopts ReLU as activate function, and Dropout and data augmentation
    are applied to prevent over-fitting.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 'AlexNet是深度学习技术的一个里程碑。在它之前，神经网络技术的发展多年处于低迷状态。它是第一个赢得ILSVRC 2012的CNN。AlexNet之后，深度学习开始成为许多计算机视觉任务中的主流技术 [[64](#bib.bib64)]。AlexNet的结构包含五个卷积层和三个最大池化层。此外，它有三个全连接层，分别具有4096、4096和1000个神经元。其结构见图[1](#S2.F1
    "Figure 1 ‣ II-B1 AlexNet ‣ II-B Deep Neural Networks ‣ II Deep learning techniques
    ‣ Deep Learning for Finger Vein Recognition: A Brief Survey of Recent Trend Yimin
    Yin and Jinghua Zhang are corresponding authors.")。该网络采用ReLU作为激活函数，并应用Dropout和数据增强来防止过拟合。'
- en: '![Refer to caption](img/03c4d7773e46bebc5df6f1b506f3adbe.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/03c4d7773e46bebc5df6f1b506f3adbe.png)'
- en: 'Figure 1: The structure of AlexNet'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '图1: AlexNet的结构'
- en: II-B2 ResNet
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B2 ResNet
- en: 'ResNet is a deep neural network composed of several residual units connected
    in series. As shown in Fig. [2](#S2.F2 "Figure 2 ‣ II-B2 ResNet ‣ II-B Deep Neural
    Networks ‣ II Deep learning techniques ‣ Deep Learning for Finger Vein Recognition:
    A Brief Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors."),
    the residual unit is made up of convolutional layers and a shortcut connection.
    The shortcut connection can effectively guarantee the back propagation of gradient.
    Additionally, ResNet does not contain any fully connected layer, except for the
    output layer. This design dramatically reduces the number of network parameters.
    Owing to the excellent structure of ResNet, it is widely used as the backbone
    in many computer vision tasks.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ResNet是由若干残差单元串联而成的深度神经网络。如图 [2](#S2.F2 "图2 ‣ II-B2 ResNet ‣ II-B 深度神经网络 ‣ II
    深度学习技术 ‣ 指静脉识别的深度学习：最新趋势简要调查 相关作者：尹一民、张敬华")，残差单元由卷积层和快捷连接组成。快捷连接可以有效保证梯度的反向传播。此外，ResNet除了输出层外不包含任何全连接层。这种设计大大减少了网络参数的数量。由于ResNet的优秀结构，它被广泛用作许多计算机视觉任务的主干网络。
- en: '![Refer to caption](img/4f1bbca9048c3448d8a9dad604f0b6f1.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/4f1bbca9048c3448d8a9dad604f0b6f1.png)'
- en: 'Figure 2: The residual unit structure.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：残差单元结构。
- en: II-B3 GAN
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B3 GAN
- en: 'GAN is commonly used in the finger vein image restoration task. Its structure
    is shown in Fig. [3](#S2.F3 "Figure 3 ‣ II-B3 GAN ‣ II-B Deep Neural Networks
    ‣ II Deep learning techniques ‣ Deep Learning for Finger Vein Recognition: A Brief
    Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors.").
    Different from the neural networks used for classification, GAN is composed of
    the generator and discriminator. The task of generator is to generate the fake
    samples that can fool the discriminator. The discriminator aims to distinguish
    between true and false samples. This generative adversarial process can be modeled
    in the form of ([1](#S2.E1 "In II-B3 GAN ‣ II-B Deep Neural Networks ‣ II Deep
    learning techniques ‣ Deep Learning for Finger Vein Recognition: A Brief Survey
    of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors.")). $V$
    is the objective function of the entire model. $D$ is discriminator, $G$ is generator,
    $E_{x\sim P_{data}}$ represents the true data distribution, $E_{z\sim P_{z}(z)}$
    represents random noise distribution The entire formula reveals the GAN optimization
    process. As shown in Fig. [3](#S2.F3 "Figure 3 ‣ II-B3 GAN ‣ II-B Deep Neural
    Networks ‣ II Deep learning techniques ‣ Deep Learning for Finger Vein Recognition:
    A Brief Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors."),
    the generator network receives the noisy random input, while the discriminator
    network receives the true sample. The output of the generator network is then
    fed into the discriminator, which verifies if it is a genuine sample.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: GAN通常用于指静脉图像恢复任务。其结构如图 [3](#S2.F3 "图3 ‣ II-B3 GAN ‣ II-B 深度神经网络 ‣ II 深度学习技术
    ‣ 指静脉识别的深度学习：最新趋势简要调查 相关作者：尹一民、张敬华"). 与用于分类的神经网络不同，GAN由生成器和鉴别器组成。生成器的任务是生成可以欺骗鉴别器的假样本。鉴别器旨在区分真假样本。这种生成对抗过程可以用 ([1](#S2.E1
    "在 II-B3 GAN ‣ II-B 深度神经网络 ‣ II 深度学习技术 ‣ 指静脉识别的深度学习：最新趋势简要调查 相关作者：尹一民、张敬华")) 的形式建模。
    $V$ 是整个模型的目标函数。 $D$ 是鉴别器， $G$ 是生成器， $E_{x\sim P_{data}}$ 代表真实数据分布， $E_{z\sim P_{z}(z)}$ 代表随机噪声分布
    整个公式揭示了GAN优化过程。如图 [3](#S2.F3 "图3 ‣ II-B3 GAN ‣ II-B 深度神经网络 ‣ II 深度学习技术 ‣ 指静脉识别的深度学习：最新趋势简要调查
    相关作者：尹一民、张敬华")，生成器网络接收带有噪声的随机输入，而鉴别器网络接收真样本。然后生成器网络的输出被馈送到鉴别器，验证它是否是真实样本。
- en: '![Refer to caption](img/220799fa1aab2a90aff5dc11a197e918.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/220799fa1aab2a90aff5dc11a197e918.png)'
- en: 'Figure 3: The basic theory of GAN'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：GAN的基本理论
- en: '|  | $\displaystyle\mathop{min}\limits_{Gener}\mathop{max}\limits_{Discr}V(Gener,Discr)=E_{x\sim
    P_{data}}[logDiscr(x)]+$ |  | (1) |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathop{min}\limits_{Gener}\mathop{max}\limits_{Discr}V(Gener,Discr)=E_{x\sim
    P_{data}}[logDiscr(x)]+$ |  | (1) |'
- en: '|  | $\displaystyle E_{z\sim P_{z}(z)}[log[1-Discr(Gener(z))]]$ |  |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle E_{z\sim P_{z}(z)}[log[1-Discr(Gener(z))]]$ |  |'
- en: II-C Analysis of Existing Reviews
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 现有评论的分析
- en: We also analyse the existing reviews about FVIR. In [[10](#bib.bib10)], the
    main FVIR process is introduced, but the contributions of related papers are not
    discussed. In [[4](#bib.bib4)], the amount of literature summarized is limited.
    [[11](#bib.bib11)] classifies papers according to the network type, but it does
    not explain the tasks of networks. Different from these reviews, we conduct this
    survey by a detailed analysis of the neural network tasks, which can provide a
    new sight for the related research. Besides, our survey provides the introduction
    the open access datasets and the mainstream DL technologies. Additionally, a comprehensive
    summary table of state-of-the-art works is presented.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还分析了关于指静脉识别的现有综述。在[[10](#bib.bib10)]中，介绍了主要的指静脉识别过程，但没有讨论相关论文的贡献。在[[4](#bib.bib4)]中，总结的文献量有限。[[11](#bib.bib11)]按照网络类型对论文进行了分类，但没有解释网络的任务。与这些综述不同，我们通过对神经网络任务的详细分析来进行本次调查，这为相关研究提供了新的视角。此外，我们的调查提供了开放访问数据集和主流深度学习技术的介绍。此外，还呈现了前沿工作的综合总结表。
- en: III Finger vein recognition based on deep learning
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 基于深度学习的指静脉识别
- en: An overview of FVIR based on DL is presented in this section. According to the
    tasks of neural networks, the papers are divided into five parts. In each task,
    the representative methods are introduced. In the end, we provide a summary table.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 本节概述了基于深度学习的指静脉识别（FVIR）。根据神经网络的任务，将相关论文分为五个部分。在每个任务中，介绍了代表性的方法。最后，我们提供了一个总结表。
- en: III-A Classification
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 分类
- en: Classification is the main task in FVIR. Compared with traditional machine learning
    methods, DL technology shows overwhelming performance in finger vein image classification
    tasks. [[12](#bib.bib12), [13](#bib.bib13), [15](#bib.bib15), [16](#bib.bib16),
    [18](#bib.bib18), [19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22),
    [23](#bib.bib23), [24](#bib.bib24), [26](#bib.bib26), [28](#bib.bib28), [29](#bib.bib29),
    [30](#bib.bib30), [32](#bib.bib32), [33](#bib.bib33), [34](#bib.bib34), [35](#bib.bib35),
    [36](#bib.bib36), [37](#bib.bib37), [38](#bib.bib38), [39](#bib.bib39), [41](#bib.bib41),
    [43](#bib.bib43), [45](#bib.bib45), [53](#bib.bib53), [54](#bib.bib54)] focus
    on the finger vein classification task based on DL. Among them, most papers adopt
    similar CNN-based workflow to classify the finger vein data. For example, ResNet
    is directly applied on the image data to perform the classification task in [[18](#bib.bib18)].
    Similar workflows are used in [[20](#bib.bib20), [32](#bib.bib32), [37](#bib.bib37),
    [53](#bib.bib53)]. It is worth noting that [[39](#bib.bib39)] imports joint attention
    module to improve the contribution of vein patterns in feature extraction. Besides
    CNNs, there are some papers adopting different neural networks, such as [[21](#bib.bib21)]
    use *Graph Neural Network* (GNN) to perform the classification. The intricate
    vein texture can be described as a graph structure. Hence, GNN can quickly distinguish
    different finger vein images from limited data. Additionally, [[19](#bib.bib19)]
    utilizes supervised discrete hashing to increase matching speed. [[23](#bib.bib23)]
    uses bias filed correction and spatial attention to optimize the CNN-based FVIR
    task. The module of [[28](#bib.bib28)] had better rotation invariance than normal
    CNN by using the capsule network. [[30](#bib.bib30)] proposes a novel approach
    based on GAN. This method learns the joint distribution of finger vein images
    and pattern maps, which enhance the capacity for feature representation. [[41](#bib.bib41)]
    employs the triplet loss with hard triplet online mining approach to explore the
    similarity between different fingers of a person.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是 FVIR 中的主要任务。与传统机器学习方法相比，DL 技术在指静脉图像分类任务中展现了压倒性的性能。[[12](#bib.bib12), [13](#bib.bib13),
    [15](#bib.bib15), [16](#bib.bib16), [18](#bib.bib18), [19](#bib.bib19), [20](#bib.bib20),
    [21](#bib.bib21), [22](#bib.bib22), [23](#bib.bib23), [24](#bib.bib24), [26](#bib.bib26),
    [28](#bib.bib28), [29](#bib.bib29), [30](#bib.bib30), [32](#bib.bib32), [33](#bib.bib33),
    [34](#bib.bib34), [35](#bib.bib35), [36](#bib.bib36), [37](#bib.bib37), [38](#bib.bib38),
    [39](#bib.bib39), [41](#bib.bib41), [43](#bib.bib43), [45](#bib.bib45), [53](#bib.bib53),
    [54](#bib.bib54)] 专注于基于 DL 的指静脉分类任务。其中，大多数论文采用类似的基于 CNN 的工作流程来分类指静脉数据。例如，ResNet
    直接应用于图像数据以执行分类任务，在 [[18](#bib.bib18)] 中有所体现。类似的工作流程也被用于 [[20](#bib.bib20), [32](#bib.bib32),
    [37](#bib.bib37), [53](#bib.bib53)] 中。值得注意的是，[[39](#bib.bib39)] 引入了联合注意力模块，以提高特征提取中静脉模式的贡献。除了
    CNN，还有一些论文采用了不同的神经网络，例如 [[21](#bib.bib21)] 使用 *图神经网络* (GNN) 执行分类。复杂的静脉纹理可以被描述为图结构。因此，GNN
    能够在有限的数据中迅速区分不同的指静脉图像。此外，[[19](#bib.bib19)] 利用监督离散哈希来提高匹配速度。[[23](#bib.bib23)]
    使用偏差场校正和空间注意力来优化基于 CNN 的 FVIR 任务。[[28](#bib.bib28)] 的模块通过使用胶囊网络比普通 CNN 具有更好的旋转不变性。[[30](#bib.bib30)]
    提出了基于 GAN 的新方法，该方法学习指静脉图像和模式图的联合分布，从而增强了特征表示能力。[[41](#bib.bib41)] 使用硬三元组在线挖掘方法的三元组损失来探索一个人不同手指之间的相似性。
- en: III-B Feature Extraction
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 特征提取
- en: The application of DL-based methods drastically alters the feature extraction
    process in FVIR. CNNs can automatically extract features from images. [[14](#bib.bib14),
    [17](#bib.bib17), [25](#bib.bib25), [27](#bib.bib27), [31](#bib.bib31), [40](#bib.bib40),
    [44](#bib.bib44)] concentrate on DL-based feature extraction tasks. Some researches [[14](#bib.bib14),
    [25](#bib.bib25), [31](#bib.bib31)] adopt the analogous workflow, which usually
    uses CNN structure to extract features, and then adopts a traditional machine
    learning algorithm to analyse these features. Additionally, some studies use novel
    approaches to extract features, such as [[27](#bib.bib27)] uses the*Convolutional
    Auto-Encoder* (CAE) to learn the feature codes from finger vein images, [[40](#bib.bib40)]
    proposes a capsule neural network based region of interest extraction approach
    for finger veins, which can represent the relationship between the part and the
    whole image. [[17](#bib.bib17)] designs a lightweight two-channel network that
    has only three convolution layers to extract image features with an acceptable
    computation cost, and then support vector machine is adopted to perform the verification
    task. [[44](#bib.bib44)] proposes a deep fusion of electrocardiogram and finger
    vein image data based multi-modal biometric authentication system. This method
    reaches a very high recognition accuracy.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 基于深度学习（DL）的方法的应用极大地改变了指静脉识别（FVIR）中的特征提取过程。卷积神经网络（CNN）可以自动从图像中提取特征。[[14](#bib.bib14)、[17](#bib.bib17)、[25](#bib.bib25)、[27](#bib.bib27)、[31](#bib.bib31)、[40](#bib.bib40)、[44](#bib.bib44)]
    专注于基于深度学习的特征提取任务。一些研究[[14](#bib.bib14)、[25](#bib.bib25)、[31](#bib.bib31)] 采用类似的工作流程，这通常使用卷积神经网络结构来提取特征，然后采用传统的机器学习算法来分析这些特征。此外，一些研究采用了新颖的方法来提取特征，例如[[27](#bib.bib27)]
    使用*卷积自编码器*（CAE）从指静脉图像中学习特征编码，[[40](#bib.bib40)] 提出了基于胶囊神经网络的指静脉区域兴趣提取方法，该方法可以表示部分与整个图像之间的关系。[[17](#bib.bib17)]
    设计了一个轻量级的双通道网络，该网络仅有三层卷积层，可以以可接受的计算成本提取图像特征，然后采用支持向量机进行验证任务。[[44](#bib.bib44)]
    提出了一个深度融合心电图和指静脉图像数据的多模态生物识别认证系统。该方法达到了非常高的识别准确率。
- en: III-C Image Enhancement
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 图像增强
- en: Different finger vein image collection devices and user habits often lead to
    noisy image data in real scenarios [54], which seriously influence the performance
    of the DL model. To obtain high quality images sometimes, the original finger
    vein images must be enhanced. [[46](#bib.bib46), [47](#bib.bib47), [48](#bib.bib48),
    [49](#bib.bib49), [50](#bib.bib50), [51](#bib.bib51), [52](#bib.bib52)] introduce
    the application of DL technology in finger vein image enhancement. Among these
    papers, GAN has a wide range of applications. For instance, GAN is used to recover
    the missed vein patterns that are generated in the image capture process owing
    to various factors in [[48](#bib.bib48)]. To recover the severely damaged finger
    vein images, [[49](#bib.bib49)] proposes a modified GAN based on neighbors-based
    binary patterns texture loss. [[50](#bib.bib50)] proposes a modified DeblurGAN
    to increase identification performance by restoring motion blurred finger vein
    images to solve the problem of motion blur in FVIR. In addition to GANs, some
    other modules are applied in image restoration for FVIR. [[46](#bib.bib46)] proposes
    a finger vein image denoising method based on the deep CNN, the deconvolution
    sub-net recovers the original image based on the features, and the modified linear
    unit extract finger vein texture details. [[47](#bib.bib47)] uses a CAE to restore
    the venous networks of the finger vein images, thereby effectively extracting
    features. [[51](#bib.bib51)] proposes a new network architecture based on the
    pulse-coupled neural network to improved the finger vein image quality and increase
    the practicality of FVIR.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的指静脉图像采集设备和用户习惯常常导致实际场景中的图像数据噪声 [54]，这严重影响了深度学习（DL）模型的性能。为了获得高质量的图像，有时必须对原始指静脉图像进行增强。 [[46](#bib.bib46),
    [47](#bib.bib47), [48](#bib.bib48), [49](#bib.bib49), [50](#bib.bib50), [51](#bib.bib51),
    [52](#bib.bib52)] 介绍了 DL 技术在指静脉图像增强中的应用。在这些论文中，GAN 的应用范围非常广泛。例如，GAN 用于恢复由于各种因素在图像捕捉过程中产生的遗漏静脉模式
    [[48](#bib.bib48)]。为了恢复严重损坏的指静脉图像，[[49](#bib.bib49)] 提出了基于邻域二值模式纹理损失的修改版 GAN。[[50](#bib.bib50)]
    提出了修改版 DeblurGAN，通过恢复运动模糊的指静脉图像来提高识别性能，以解决 FVIR 中的运动模糊问题。除了 GAN，还有一些其他模块被应用于 FVIR
    的图像恢复中。[[46](#bib.bib46)] 提出了基于深度 CNN 的指静脉图像去噪方法，解卷积子网根据特征恢复原始图像，修改后的线性单元提取指静脉纹理细节。[[47](#bib.bib47)]
    使用 CAE 恢复指静脉图像的静脉网络，从而有效提取特征。[[51](#bib.bib51)] 提出了基于脉冲耦合神经网络的新网络架构，以提高指静脉图像质量，并增加
    FVIR 的实用性。
- en: III-D Image Segmentation
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-D 图像分割
- en: Finger vein image segmentation is an important stage in FVIR technology. The
    quality of segmentation has a direct impact on feature extraction and recognition.
    [[55](#bib.bib55)] proposes a finger vein segmentation algorithm based on LadderNet,
    it can obtain abundant semantic information from vein image by concatenating the
    feature channels of the expanding path and contracting path in the network. Additionally,
    the parameters of normal finger vein segmentation networks are overabundant, which
    makes they are challenging to use in mobile terminals. To overcome this problem,
    [[56](#bib.bib56)] proposes a lightweight real-time segmentation network in FVIR
    based on the embedded terminal. The performance of this network is not inferior
    to more complex networks and satisfied the needs of embedded mobile terminals.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 指静脉图像分割是 FVIR 技术中的一个重要阶段。分割的质量直接影响特征提取和识别。[[55](#bib.bib55)] 提出了基于 LadderNet
    的指静脉分割算法，通过连接网络中的扩展路径和收缩路径的特征通道，可以从静脉图像中获取丰富的语义信息。此外，正常的指静脉分割网络参数过多，使得它们在移动终端中使用具有挑战性。为了解决这个问题，[[56](#bib.bib56)]
    提出了基于嵌入式终端的轻量级实时分割网络。该网络的性能不亚于更复杂的网络，并满足了嵌入式移动终端的需求。
- en: III-E Encryption
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-E 加密
- en: Since biometric information is irreplaceable and unique for everyone, once the
    original biometric information is stolen, it may cause irreversible loss. To protect
    the privacy of users more effectively, encryption methods are used in FVIR. This
    technology masks the biometric information in the image by encrypting the original
    image. Even if the finger vein image is stolen, criminals cannot obtain valid
    information from it. However, the biggest challenge of encryption is how to keep
    the performance of the recognition system while protecting biometric data. To
    address this issue, [[57](#bib.bib57)] presented a novel FVIR algorithm by using
    a secure biometric template scheme based on DL and random projections. This algorithm
    randomly generates a secured template for the original biometric message by random
    projections. [[42](#bib.bib42)] proposes a deep CAE structure to reduce the dimension
    of the feature space and introduced the Biohashing algorithm to generate protected
    templates based on the features that were extracted at the CAE.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 由于生物特征信息对每个人都是不可替代且唯一的，一旦原始生物特征信息被盗取，可能会造成不可逆转的损失。为了更有效地保护用户隐私，FVIR 中使用了加密方法。这项技术通过加密原始图像来隐藏图像中的生物特征信息。即使指静脉图像被盗，犯罪分子也无法从中获得有效的信息。然而，加密的最大挑战是如何在保护生物数据的同时保持识别系统的性能。为了解决这个问题，[[57](#bib.bib57)]
    提出了一个新颖的 FVIR 算法，该算法使用基于 DL 和随机投影的安全生物特征模板方案。该算法通过随机投影为原始生物信息生成一个安全的模板。[[42](#bib.bib42)]
    提出了一个深度 CAE 结构来减少特征空间的维度，并引入了 Biohashing 算法，以基于 CAE 提取的特征生成保护模板。
- en: 'TABLE II: The summary table of surveyed papers. For short, Task, Dataset, Reference,
    Network, Performance, Classification, Feature extraction, Image enhancement, Image
    segmentation, encryption, SDUMLA-HMT, HKPU, MMCBNU-6000, FV-USM, UTFVP, THU-FVFDT2,
    SCUT, IDIAP, PLUSVein-FV3, private, VeinECG, ISPR, NJUST-FV, Accuracy, Equal Error
    Rate, Peak Signal-to-Noise Ratio, Structural Similarity, Presentation Classification
    Error Rate and Bona-fide Presentation Classification Error Rate are abbreviated
    to T, D, Ref, Net, Perf, C*, F*, IE*, S*, E*, SD*, HK*, MM*, US*, UT*, TH*, SC*,
    ID*, PL*, PR*, VE*, IS*, NJ*, ACC, EERE, PSNR, SSIM, APCER and BPCER.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '表 II: 调查论文的总结表。简写说明，任务、数据集、参考文献、网络、性能、分类、特征提取、图像增强、图像分割、加密、SDUMLA-HMT、HKPU、MMCBNU-6000、FV-USM、UTFVP、THU-FVFDT2、SCUT、IDIAP、PLUSVein-FV3、私有、VeinECG、ISPR、NJUST-FV、准确率、等误差率、峰值信噪比、结构相似性、展示分类错误率和真实展示分类错误率缩写为
    T、D、Ref、Net、Perf、C*、F*、IE*、S*、E*、SD*、HK*、MM*、US*、UT*、TH*、SC*、ID*、PL*、PR*、VE*、IS*、NJ*、ACC、EERE、PSNR、SSIM、APCER
    和 BPCER。'
- en: '| T. | D. | Ref. | Net. | Perf.(%) | T. | D. | Ref. | Net. | Perf.(%) | T.
    | D. | Ref. | Net. | Perf.(%) |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| T. | D. | 参考文献 | 网络 | 性能(%) | T. | D. | 参考文献 | 网络 | 性能(%) | T. | D. | 参考文献
    | 网络 | 性能(%) |'
- en: '| C* | SD* | [[18](#bib.bib18)] | ResNet-101 | EERE 3.3653 | C* | MM* | [[39](#bib.bib39)]
    | JAFVNet | EERE 0.23 | F* | SD* | [[40](#bib.bib40)] | Capsule Network | ACC
    97.5 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| C* | SD* | [[18](#bib.bib18)] | ResNet-101 | EERE 3.3653 | C* | MM* | [[39](#bib.bib39)]
    | JAFVNet | EERE 0.23 | F* | SD* | [[40](#bib.bib40)] | 胶囊网络 | ACC 97.5 |'
- en: '| [[28](#bib.bib28)] | Capsule Network | ACC 100 | [[38](#bib.bib38)] | ResNet
    |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| [[28](#bib.bib28)] | 胶囊网络 | ACC 100 | [[38](#bib.bib38)] | ResNet |'
- en: '&#124; EERE 0.090 &#124;'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; EERE 0.090 &#124;'
- en: '&#124; CIR 99.667 &#124;'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CIR 99.667 &#124;'
- en: '| HK* | [[14](#bib.bib14)] | Improved CNN | ACC 87.08 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| HK* | [[14](#bib.bib14)] | 改进型 CNN | ACC 87.08 |'
- en: '| [[19](#bib.bib19)] | Light CNN | EERE 0.1497 | [[45](#bib.bib45)] | two-branch
    CNN | EERE 0.17 | MM* | [[17](#bib.bib17)] | two-stream network | EERE 0.10 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| [[19](#bib.bib19)] | Light CNN | EERE 0.1497 | [[45](#bib.bib45)] | 双分支 CNN
    | EERE 0.17 | MM* | [[17](#bib.bib17)] | 双流网络 | EERE 0.10 |'
- en: '| [[26](#bib.bib26)] | RefineNet | EERE 2.45 | US* | [[15](#bib.bib15)] | Improved
    CNN | EERE 1.42 | US* | [[27](#bib.bib27)] | CAE |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| [[26](#bib.bib26)] | RefineNet | EERE 2.45 | US* | [[15](#bib.bib15)] | 改进型
    CNN | EERE 1.42 | US* | [[27](#bib.bib27)] | CAE |'
- en: '&#124; ACC 99.49 &#124;'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ACC 99.49 &#124;'
- en: '&#124; EERE 0.16 &#124;'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; EERE 0.16 &#124;'
- en: '|'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| [[30](#bib.bib30)] | GAN | EERE 0.94 | [[20](#bib.bib20)] | DBN | ACC 97.4
    | [[31](#bib.bib31)] | PCANet | ACC 99.49 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| [[30](#bib.bib30)] | GAN | EERE 0.94 | [[20](#bib.bib20)] | DBN | ACC 97.4
    | [[31](#bib.bib31)] | PCANet | ACC 99.49 |'
- en: '| [[21](#bib.bib21)] | GNN | ACC 99.98 | [[35](#bib.bib35)] | Sub-CNN | ACC
    95.1 | [[40](#bib.bib40)] | Capsule Network | ACC 99.7 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| [[21](#bib.bib21)] | GNN | ACC 99.98 | [[35](#bib.bib35)] | Sub-CNN | ACC
    95.1 | [[40](#bib.bib40)] | 胶囊网络 | ACC 99.7 |'
- en: '| [[32](#bib.bib32)] | DenseNet-201 | EERE 0.54 | [[37](#bib.bib37)] | Improved
    CNN |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| [[32](#bib.bib32)] | DenseNet-201 | EERE 0.54 | [[37](#bib.bib37)] | 改进型
    CNN |'
- en: '&#124; ACC 97.95 &#124;'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ACC 97.95 &#124;'
- en: '&#124; EERE 1.070 &#124;'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; EERE 1.070 &#124;'
- en: '| TH* | [[31](#bib.bib31)] | PCANet | ACC 100 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| TH* | [[31](#bib.bib31)] | PCANet | ACC 100 |'
- en: '| [[33](#bib.bib33)] | DenseNet-161 | EERE 2.35 | [[38](#bib.bib38)] | ResNet
    | EERE 0.091 | ID* | [[25](#bib.bib25)] | VGG-16 | EERE 0.0000 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| [[33](#bib.bib33)] | DenseNet-161 | EERE 2.35 | [[38](#bib.bib38)] | ResNet
    | EERE 0.091 | ID* | [[25](#bib.bib25)] | VGG-16 | EERE 0.0000 |'
- en: '| [[34](#bib.bib34)] | DenseNet-161 | EERE 1.65 | [[39](#bib.bib39)] | JAFVNet
    | EERE 0.49 | VE* | [[44](#bib.bib44)] | Improved CNN | EERE 0.12 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| [[34](#bib.bib34)] | DenseNet-161 | EERE 1.65 | [[39](#bib.bib39)] | JAFVNet
    | EERE 0.49 | VE* | [[44](#bib.bib44)] | 改进的 CNN | EERE 0.12 |'
- en: '| [[23](#bib.bib23)] | ResNet-50 | ACC 99.53 | [[24](#bib.bib24)] | NASNet
    | ACC 98.89 | IS* | [[25](#bib.bib25)] | VGG-16 | EERE 0.0311 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| [[23](#bib.bib23)] | ResNet-50 | ACC 99.53 | [[24](#bib.bib24)] | NASNet
    | ACC 98.89 | IS* | [[25](#bib.bib25)] | VGG-16 | EERE 0.0311 |'
- en: '| [[38](#bib.bib38)] | ResNet | EERE 2.137 | UT* | [[28](#bib.bib28)] | Capsule
    Network | ACC 94 | IE* | SD* | [[50](#bib.bib50)] | GAN | EERE 5.270 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| [[38](#bib.bib38)] | ResNet | EERE 2.137 | UT* | [[28](#bib.bib28)] | Capsule
    网络 | ACC 94 | IE* | SD* | [[50](#bib.bib50)] | GAN | EERE 5.270 |'
- en: '| [[39](#bib.bib39)] | JAFVNet | EERE 1.18 | [[41](#bib.bib41)] | SqueezeNet
    | EERE 2.5 | [[51](#bib.bib51)] | PCNN | - |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| [[39](#bib.bib39)] | JAFVNet | EERE 1.18 | [[41](#bib.bib41)] | SqueezeNet
    | EERE 2.5 | [[51](#bib.bib51)] | PCNN | - |'
- en: '| [[41](#bib.bib41)] | SqueezeNet | EERE 2.7 | [[26](#bib.bib26)] | U-Net |
    EERE 0.64 | [[52](#bib.bib52)] | GAN | EERE 0.87 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| [[41](#bib.bib41)] | SqueezeNet | EERE 2.7 | [[26](#bib.bib26)] | U-Net |
    EERE 0.64 | [[52](#bib.bib52)] | GAN | EERE 0.87 |'
- en: '| [[53](#bib.bib53)] | GoogleNet | ACC 92.22 | TH* | [[30](#bib.bib30)] | GAN
    |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| [[53](#bib.bib53)] | GoogleNet | ACC 92.22 | TH* | [[30](#bib.bib30)] | GAN
    |'
- en: '&#124; ACC 98.52 &#124;'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ACC 98.52 &#124;'
- en: '&#124; EERE 1.12 &#124;'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; EERE 1.12 &#124;'
- en: '| HK* | [[46](#bib.bib46)] | Improved CNN | PSNR 29.638 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| HK* | [[46](#bib.bib46)] | 改进的 CNN | PSNR 29.638 |'
- en: '| [[45](#bib.bib45)] | two-branch CNN | EERE 0.94 | [[23](#bib.bib23)] | ResNet-50
    | ACC 98.64 | [[50](#bib.bib50)] | GAN | EERE 4.536 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| [[45](#bib.bib45)] | 双分支 CNN | EERE 0.94 | [[23](#bib.bib23)] | ResNet-50
    | ACC 98.64 | [[50](#bib.bib50)] | GAN | EERE 4.536 |'
- en: '| HK* | [[15](#bib.bib15)] | Improved CNN | EERE 2.70 | SC* | [[12](#bib.bib12)]
    | FPNet | EERE 0.00 | [[51](#bib.bib51)] | PCNN | - |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| HK* | [[15](#bib.bib15)] | 改进的 CNN | EERE 2.70 | SC* | [[12](#bib.bib12)]
    | FPNet | EERE 0.00 | [[51](#bib.bib51)] | PCNN | - |'
- en: '| [[18](#bib.bib18)] | ResNet-101 | EERE 1.0799 | [[36](#bib.bib36)] | FVRASNet
    | EERE 2.02 | MM* | [[48](#bib.bib48)] | GAN | EERE 5.66 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| [[18](#bib.bib18)] | ResNet-101 | EERE 1.0799 | [[36](#bib.bib36)] | FVRASNet
    | EERE 2.02 | MM* | [[48](#bib.bib48)] | GAN | EERE 5.66 |'
- en: '| [[28](#bib.bib28)] | Capsule Network | ACC 88 | [[39](#bib.bib39)] | JAFVNet
    | EERE 0.86 | US* | [[48](#bib.bib48)] | GAN | EERE 2.37 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| [[28](#bib.bib28)] | Capsule 网络 | ACC 88 | [[39](#bib.bib39)] | JAFVNet |
    EERE 0.86 | US* | [[48](#bib.bib48)] | GAN | EERE 2.37 |'
- en: '| [[29](#bib.bib29)] | LSTM | EERE 0.95 | ID* | [[12](#bib.bib12)] | FPNet
    | EERE 0.25 | PR* | [[47](#bib.bib47)] | CAE | EERE 0.16 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| [[29](#bib.bib29)] | LSTM | EERE 0.95 | ID* | [[12](#bib.bib12)] | FPNet
    | EERE 0.25 | PR* | [[47](#bib.bib47)] | CAE | EERE 0.16 |'
- en: '| [[33](#bib.bib33)] | DenseNet-161 | EERE 0.33 | [[36](#bib.bib36)] | FVRASNet
    | EERE 4.26 | [[49](#bib.bib49)] | GAN |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| [[33](#bib.bib33)] | DenseNet-161 | EERE 0.33 | [[36](#bib.bib36)] | FVRASNet
    | EERE 4.26 | [[49](#bib.bib49)] | GAN |'
- en: '&#124; PSNR 30.42 &#124;'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PSNR 30.42 &#124;'
- en: '&#124; SSIM 98.85 &#124;'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SSIM 98.85 &#124;'
- en: '|'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| [[34](#bib.bib34)] | DenseNet-161 | EERE 0.05 | PL* | [[41](#bib.bib41)]
    | SqueezeNet | EERE 2.4 | NJ* | [[51](#bib.bib51)] | PCNN | - |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| [[34](#bib.bib34)] | DenseNet-161 | EERE 0.05 | PL* | [[41](#bib.bib41)]
    | SqueezeNet | EERE 2.4 | NJ* | [[51](#bib.bib51)] | PCNN | - |'
- en: '| [[38](#bib.bib38)] | ResNet | EERE 0.277 | [[43](#bib.bib43)] | Triplrt-SqNet
    | EERE 3 | S* | SD* | [[55](#bib.bib55)] | LadderNet | ACC 92.44 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| [[38](#bib.bib38)] | ResNet | EERE 0.277 | [[43](#bib.bib43)] | Triplrt-SqNet
    | EERE 3 | S* | SD* | [[55](#bib.bib55)] | LadderNet | ACC 92.44 |'
- en: '| [[41](#bib.bib41)] | SqueezeNet | EERE 3.7 | PR* | [[16](#bib.bib16)] | AlexNet
    |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| [[41](#bib.bib41)] | SqueezeNet | EERE 3.7 | PR* | [[16](#bib.bib16)] | AlexNet
    |'
- en: '&#124; APCER 0 &#124;'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; APCER 0 &#124;'
- en: '&#124; BPCER 0 &#124;'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BPCER 0 &#124;'
- en: '| [[56](#bib.bib56)] | DintyNet | ACC 91.93 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| [[56](#bib.bib56)] | DintyNet | ACC 91.93 |'
- en: '| [[54](#bib.bib54)] | Improved CNN | ACC 91.19 | [[20](#bib.bib20)] | DBN
    | ACC 97.8 | MM* | [[55](#bib.bib55)] | LadderNet | ACC 93.93 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| [[54](#bib.bib54)] | 改进的 CNN | ACC 91.19 | [[20](#bib.bib20)] | DBN | ACC
    97.8 | MM* | [[55](#bib.bib55)] | LadderNet | ACC 93.93 |'
- en: '| MM* | [[28](#bib.bib28)] | Capsule Network | ACC 100 | [[22](#bib.bib22)]
    | LSTM | ACC 99.13 | [[56](#bib.bib56)] | DintyNet | ACC 90.90 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| MM* | [[28](#bib.bib28)] | Capsule 网络 | ACC 100 | [[22](#bib.bib22)] | LSTM
    | ACC 99.13 | [[56](#bib.bib56)] | DintyNet | ACC 90.90 |'
- en: '| [[21](#bib.bib21)] | GNN | ACC 99.98 | F* | SD* | [[17](#bib.bib17)] | two-channel
    network | EERE 0.47 | E* | UT* | [[42](#bib.bib42)] | CAE | EERE 0.7 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| [[21](#bib.bib21)] | GNN | ACC 99.98 | F* | SD* | [[17](#bib.bib17)] | 双通道网络
    | EERE 0.47 | E* | UT* | [[42](#bib.bib42)] | CAE | EERE 0.7 |'
- en: '| [[37](#bib.bib37)] | Improved CNN |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| [[37](#bib.bib37)] | 改进的 CNN |'
- en: '&#124; ACC 99.05 &#124;'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ACC 99.05 &#124;'
- en: '&#124; EERE 0.503 &#124;'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; EERE 0.503 &#124;'
- en: '| [[31](#bib.bib31)] | PCANet | ACC 98.19 | PR* | [[57](#bib.bib57)] | CAE
    |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| [[31](#bib.bib31)] | PCANet | ACC 98.19 | PR* | [[57](#bib.bib57)] | CAE
    |'
- en: '&#124; GAR 96.9 &#124;'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GAR 96.9 &#124;'
- en: '&#124; FAR 1.5 &#124;'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FAR 1.5 &#124;'
- en: '|'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: IV Challenge and potential direction
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 挑战与潜在方向
- en: Compared with traditional biometric technology, FVIR has unparalleled advantages
    but it still faces some challenges, especially during image capture [[49](#bib.bib49)], [[63](#bib.bib63)], [[36](#bib.bib36)],
    which contains uneven illumination, light scattering in finger tissue, inappropriate
    ambient temperature, image displacement, presentation attacks, shading, etc. All
    of the aforementioned challenges have varying degrees of impact on the performance
    of FVIR. To overcome these challenges, [[12](#bib.bib12), [25](#bib.bib25), [16](#bib.bib16),
    [51](#bib.bib51), [52](#bib.bib52), [48](#bib.bib48), [36](#bib.bib36), [49](#bib.bib49)]
    try to propose solutions from different aspects. However, these technical difficulties
    have not been completely solved, and they will remain the focus of FVIR in the
    future.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的生物特征识别技术相比，FVIR 具有无与伦比的优势，但它仍面临一些挑战，特别是在图像捕捉[[49](#bib.bib49)], [[63](#bib.bib63)],
    [[36](#bib.bib36)]过程中，存在不均匀的光照、指纹组织中的光散射、不适当的环境温度、图像位移、展示攻击、阴影等问题。上述所有挑战对 FVIR
    的性能都有不同程度的影响。为了克服这些挑战，[[12](#bib.bib12), [25](#bib.bib25), [16](#bib.bib16), [51](#bib.bib51),
    [52](#bib.bib52), [48](#bib.bib48), [36](#bib.bib36), [49](#bib.bib49)]尝试从不同方面提出解决方案。然而，这些技术难题尚未完全解决，它们将继续成为
    FVIR 未来的关注重点。
- en: Besides, FVIR also has some potential directions. For instance, FVIR generally
    needs to be implemented on lightweight portable mobile terminals. However, most
    of the deep neural networks are not suitable for this kind of device. Therefore,
    DL-based FVIR faces some difficulties in practice. Knowledge distillation [[66](#bib.bib66)]
    can be utilized to overcome this challenge. Knowledge distillation can greatly
    condense complicated networks by teaching a small student model from a large model.
    This technology can greatly improve the application ability of FVIR in reality.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，FVIR 还有一些潜在的方向。例如，FVIR 通常需要在轻量级便携式移动终端上实现。然而，大多数深度神经网络不适合这种设备。因此，基于 DL 的
    FVIR 在实践中面临一些困难。可以利用知识蒸馏[[66](#bib.bib66)]来克服这一挑战。知识蒸馏通过从大模型中教导一个小的学生模型，能够大大精简复杂的网络。这项技术可以极大地提高
    FVIR 在实际应用中的能力。
- en: Furthermore, one of the conveniences of FVIR is that even if one finger is in
    an accident, the other fingers can still be used for identification. But registering
    ten fingers simultaneously in an identification system is a hassle for users.
    Therefore, it is necessary to explore whether the finger veins of the ten fingers
    of the same individual are similar in future FVIR research work. If there is some
    connections between different finger veins of the same person and they can be
    identified by FVIR systems, it will take the convenience of FVIR systems to a
    new level. Although [[32](#bib.bib32), [41](#bib.bib41)] focus on this problem,
    they still have some limitations.[[32](#bib.bib32)] considers the connection between
    the veins of different fingers of the same person is too weak to perform the recognition.
    [[41](#bib.bib41)] utilizes the triplet loss with hard triplet online mining for
    FVIR. This strategy successfully verified that symmetric fingers (the same sort
    of finger but from opposite hands in the same individual) have enough similarities
    to be recognized. The similarities of other asymmetric fingers is also proved
    in  [[41](#bib.bib41)], but the proposed recognition system is still unable to
    effectively identify these asymmetric finger veins. Therefore, related work can
    still be further explored in the future.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，FVIR 的一个便利之处在于，即使一个手指发生意外，其他手指仍然可以用于识别。但在识别系统中同时注册十个手指对用户来说是一个麻烦。因此，有必要在未来的
    FVIR 研究工作中探索同一人的十个手指的指静脉是否相似。如果同一人的不同手指的指静脉之间存在一些联系，并且可以通过 FVIR 系统进行识别，那么这将使 FVIR
    系统的便利性达到一个新水平。虽然[[32](#bib.bib32), [41](#bib.bib41)]关注了这个问题，但它们仍然存在一些局限性。[[32](#bib.bib32)]
    认为不同手指的静脉之间的联系过于微弱，无法进行识别。[[41](#bib.bib41)] 使用了带有困难三元组在线挖掘的三元组损失进行 FVIR。这一策略成功验证了对称手指（同一人左右手相同类型的手指）具有足够的相似性以进行识别。[[41](#bib.bib41)]
    还证明了其他不对称手指的相似性，但提出的识别系统仍然无法有效识别这些不对称的指静脉。因此，相关工作仍有进一步探索的空间。
- en: V Conclusion and future work
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 结论与未来工作
- en: In this brief survey, we summarize the DL technology for FVIR. First, we introduce
    the base information of widely used public datasets and some popular CNN structures.
    After that, we summarize 46 related research literature of FVIR based on DL from
    2017 to 2021, and classify them according to the tasks of neural networks, which
    includes classification, feature extraction, image enhancement, image segmentation,
    encryption. Finally, we discuss the current challenges and development directions
    of FVIR. From this review, it can be found that the tasks of neural networks are
    diverse in FVIR, and compared to other biometric recognition systems, FVIR has
    unique advantages. In the future, we will investigate more literature and DL techniques
    in FVIR to propose a comprehensive review.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次简要调查中，我们总结了用于**FVIR**的深度学习技术。首先，我们介绍了广泛使用的公共数据集的基本信息以及一些流行的**CNN**结构。之后，我们总结了2017年至2021年基于深度学习的46篇**FVIR**相关研究文献，并根据神经网络的任务将其分类，包括分类、特征提取、图像增强、图像分割和加密。最后，我们讨论了**FVIR**的当前挑战和发展方向。从这次综述中可以发现，**FVIR**中的神经网络任务多样化，相较于其他生物识别系统，**FVIR**具有独特的优势。未来，我们将深入研究更多文献和深度学习技术，以提出更全面的综述。
- en: References
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] U. B. Ghosh, R. Sharma, and A. Kesharwani, “Symptoms-based biometric pattern
    detection and recognition,” in Augmented Intelligence in Healthcare: A Pragmatic
    and Integrated Analysis. Springer, 2022.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] U. B. Ghosh, R. Sharma, and A. Kesharwani, “基于症状的生物特征模式检测与识别，”见于《医疗保健中的增强智能：务实与综合分析》。Springer，2022年。'
- en: '[2] M. Madhusudhan, V. Udaya Rani, and C. Hegde, “Finger vein recognition model
    for biometric authentication using intelligent deep learning,” International Journal
    of Image and Graphics, pp. 2240004, 2021.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] M. Madhusudhan, V. Udaya Rani, and C. Hegde, “用于生物识别认证的指静脉识别模型，基于智能深度学习，”国际图像与图形期刊，第2240004页，2021年。'
- en: '[3] S. Pandey, N. Prabhu, and A. S. Kumar, “Survey on finger vein recognition
    using convolutional neural network,” in Proc. of ICAIS. IEEE, 2022, pp. 162-166.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] S. Pandey, N. Prabhu, and A. S. Kumar, “使用卷积神经网络的指静脉识别调查，”见于 ICAIS 会议论文集。IEEE，2022，第162-166页。'
- en: '[4] B. Chawla, S. Tyagi, R. Jain, A. Talegaonkar, and S. Srivastava, “Finger
    vein recognition using deep learning,” in Proc. of ICAIA. Springer, 2021, pp.
    69-78.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] B. Chawla, S. Tyagi, R. Jain, A. Talegaonkar, and S. Srivastava, “使用深度学习的指静脉识别，”见于
    ICAIA 会议论文集。Springer，2021，第69-78页。'
- en: '[5] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, and Y. Bengio, “Generative adversarial nets,” in Proc. of NIPS,
    2014.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, and Y. Bengio, “生成对抗网络，”见于 NIPS 会议论文集，2014年。'
- en: '[6] J. Zhang, C. Li, S. Kosov, M. Grzegorzek, K. Shirahama, T. Jiang, C. Sun,
    Z. Li, and H. Li, “Lcu-net: A novel low-cost u-net for environmental microorganism
    image segmentation,” Pattern Recognition, vol. 115, pp. 107885, 2021.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] J. Zhang, C. Li, S. Kosov, M. Grzegorzek, K. Shirahama, T. Jiang, C. Sun,
    Z. Li, and H. Li, “Lcu-net: 一种用于环境微生物图像分割的新型低成本u-net，”模式识别，卷115，第107885页，2021年。'
- en: '[7] R Qian, X Lai, and X Li, “3D object detection for autonomous driving: a
    survey,” Pattern Recognition, vol. 130, pp. 108796, 2022.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] R Qian, X Lai, and X Li, “用于自动驾驶的3D物体检测：综述，”模式识别，卷130，第108796页，2022年。'
- en: '[8] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
    with deep convolutional neural networks,” in Proc. of NIPS, 2012.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “使用深度卷积神经网络进行ImageNet分类，”见于
    NIPS 会议论文集，2012年。'
- en: '[9] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
    recognition,” in Proc. of CVPR. IEEE, 2016, pp. 770-778.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] K. He, X. Zhang, S. Ren, and J. Sun, “用于图像识别的深度残差学习，”见于 CVPR 会议论文集。IEEE，2016，第770-778页。'
- en: '[10] S. Daas, M. Boughazi, M. Sedhane, and B. Bouledjfane, “A review of finger
    vein biometrics authentication system,” in Proc. of ICASS. IEEE, 2018, pp. 1-6.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] S. Daas, M. Boughazi, M. Sedhane, and B. Bouledjfane, “指静脉生物识别认证系统综述，”见于
    ICASS 会议论文集。IEEE，2018，第1-6页。'
- en: '[11] S. Pandey, N. Prabhu, and A. S. Kumar, “Survey on finger vein recognition
    using convolutional neural network,” in Proc. of ICAIS. IEEE, 2022, pp. 162-166.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] S. Pandey, N. Prabhu, and A. S. Kumar, “使用卷积神经网络的指静脉识别调查，”见于 ICAIS 会议论文集。IEEE，2022，第162-166页。'
- en: '[12] X. Qiu, S. Tian, W. Kang, W. Jia, and Q. Wu, “Finger vein presentation
    attack detection using convolutional neural networks,” in Proc. of CCBR. Springer,
    2017, pp. 296-305.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] X. Qiu, S. Tian, W. Kang, W. Jia, and Q. Wu, “使用卷积神经网络进行指静脉伪造攻击检测，”见于
    CCBR 会议论文集。Springer，2017，第296-305页。'
- en: '[13] C. Chen, Z. Wu, J. Zhang, P. Li, and F. Azmat, “A finger vein recognition
    algorithm based on deep learning,” International Journal of Embedded Systems,
    vol. 9, no. 3, pp. 220-228, 2017.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] C. Chen, Z. Wu, J. Zhang, P. Li, 和 F. Azmat，“基于深度学习的指静脉识别算法，” 嵌入式系统国际期刊，第9卷，第3期，第220-228页，2017年。'
- en: '[14] H. Qin and M. A. El-Yacoubi, “Deep representation for finger-vein image-quality
    assessment,” IEEE Trans. on Circuits and Systems for Video Technology, vol. 28,
    no. 8, pp. 1677-1693, 2017.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] H. Qin 和 M. A. El-Yacoubi，“用于指静脉图像质量评估的深度表示，” IEEE视频技术电路与系统汇刊，第28卷，第8期，第1677-1693页，2017年。'
- en: '[15] H. Qin and M. A. El-Yacoubi, “Deep representation-based feature extraction
    and recovering for finger-vein verification,” IEEE Trans. on Information Forensics
    and Security, vol. 12, no. 8, pp. 1816–1829, 2017.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] H. Qin 和 M. A. El-Yacoubi，“基于深度表示的特征提取和恢复，用于指静脉验证，” IEEE信息取证与安全汇刊，第12卷，第8期，第1816–1829页，2017年。'
- en: '[16] R. Raghavendra, S. Venkatesh, K. B. Raja, and C. Busch, “Transferable
    deep convolutional neural network features for fingervein presentation attack
    detection,” in Proc. of IWBF. IEEE, 2017, pp. 1-5.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] R. Raghavendra, S. Venkatesh, K. B. Raja, 和 C. Busch，“用于指静脉呈现攻击检测的可转移深度卷积神经网络特征，”
    在IWBF会议录。IEEE，2017年，第1-5页。'
- en: '[17] Y. Fang, Q. Wu, and W. Kang, “A novel finger vein verification system
    based on two-stream convolutional network learning,” Neurocomputing, vol. 290,
    pp. 100–107, 2018.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Y. Fang, Q. Wu, 和 W. Kang，“基于双流卷积网络学习的新型指静脉验证系统，” 神经计算，第290卷，第100–107页，2018年。'
- en: '[18] W. Kim, J. M. Song, and K. R. Park, “Multimodal biometric recognition
    based on convolutional neural network by the fusion of finger-vein and finger
    shape using near-infrared (nir) camera sensor,” Sensors, vol. 18, no. 7, pp. 2296,
    2018'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] W. Kim, J. M. Song, 和 K. R. Park，“基于卷积神经网络的多模态生物识别，通过融合指静脉和手指形状，使用近红外（NIR）相机传感器，”
    传感器，第18卷，第7期，第2296页，2018年。'
- en: '[19] C. Xie and A. Kumar, “Finger vein identification using convolutional neural
    network and supervised discrete hashing,” Pattern Recognition Letters, vol. 119,
    pp. 148–156, 2019.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] C. Xie 和 A. Kumar，“使用卷积神经网络和监督离散哈希的指静脉识别，” 模式识别快报，第119卷，第148–156页，2019年。'
- en: '[20] Z.-M. Fang and Z.-M. Lu, “Deep belief network based finger vein recognition
    using histograms of uniform local binary patterns of curvature gray images,” International
    Journal of Innovative Computing, Information and Control, vol. 15, no. 5, pp.
    1701–1715, 2019.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Z.-M. Fang 和 Z.-M. Lu，“基于深度信念网络的指静脉识别，使用弯曲灰度图像的均匀局部二值模式直方图，” 创新计算、信息与控制国际期刊，第15卷，第5期，第1701–1715页，2019年。'
- en: '[21] J. Li and P. Fang, “Fvgnn: A novel gnn to finger vein recognition from
    limited training data,” in Proc. of ITAIC. IEEE, 2019, pp. 144-148.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] J. Li 和 P. Fang，“Fvgnn：一种新型GNN，用于从有限训练数据中进行指静脉识别，” 在ITAIC会议录。IEEE，2019年，第144-148页。'
- en: '[22] R. S. Kuzu, E. Piciucco, E. Maiorana, and P. Campisi, “On-the-fly fingervein-based
    biometric recognition using deep neural networks,” IEEE Trans. on information
    Forensics and Security, vol. 15, pp. 2641–2654, 2020.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] R. S. Kuzu, E. Piciucco, E. Maiorana, 和 P. Campisi，“基于深度神经网络的即时指静脉生物识别，”
    IEEE信息取证与安全汇刊，第15卷，第2641–2654页，2020年。'
- en: '[23] Z. Huang and C. Guo, “Robust finger vein recognition based on deep cnn
    with spatial attention and bias field correction,” International Journal on Artificial
    Intelligence Tools, vol. 30, no. 01, p. 2140005, 2021.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Z. Huang 和 C. Guo，“基于深度CNN的鲁棒指静脉识别，具有空间注意力和偏置场校正，” 人工智能工具国际期刊，第30卷，第01期，第2140005页，2021年。'
- en: '[24] I. S. Wang, H.-T. Chan, and C.-H. Hsia, “Finger-vein recognition using
    a nasnet with a cutout,” in Proc. of ISPACS. IEEE, 2021, pp. 1–2.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] I. S. Wang, H.-T. Chan, 和 C.-H. Hsia，“使用NASNet和cutout的指静脉识别，” 在ISPACS会议录。IEEE，2021年，第1–2页。'
- en: '[25] D. T. Nguyen, H. S. Yoon, T. D. Pham, and K. R. Park, “Spoof detection
    for finger-vein recognition system using nir camera,” Sensors, vol. 17, no. 10,
    pp. 2261, 2017.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] D. T. Nguyen, H. S. Yoon, T. D. Pham, 和 K. R. Park，“使用NIR相机的指静脉识别系统欺骗检测，”
    传感器，第17卷，第10期，第2261页，2017年。'
- en: '[26] E. Jalilian and A. Uhl, “Finger-vein recognition using deep fully convolutional
    neural semantic segmentation networks: The impact of training data,” in Proc.
    of WIFS. IEEE, 2018, pp. 1-8.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] E. Jalilian 和 A. Uhl，“使用深度全卷积神经语义分割网络的指静脉识别：训练数据的影响，” 在WIFS会议录。IEEE，2018年，第1-8页。'
- en: '[27] B. Hou and R. Yan, “Convolutional auto-encoder based deep feature learning
    for finger-vein verification,” in Proc. of MeMeA. IEEE, 2018, pp. 1–5.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] B. Hou 和 R. Yan，“基于卷积自编码器的指静脉验证深度特征学习，” 在MeMeA会议录。IEEE，2018年，第1–5页。'
- en: '[28] D. Gumusbas, T. Yildirim, M. Kocakulak, and N. Acir, “Capsule network
    for finger-vein-based biometric identification,” in Proc. of SSCI. IEEE, 2019,
    pp. 437-441.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] D. Gumusbas, T. Yildirim, M. Kocakulak, 和 N. Acir，"基于指静脉的生物识别的胶囊网络"，见于SSCI会议论文集。IEEE，2019年，第437-441页。'
- en: '[29] H. Qin and P. Wang, “Finger-vein verification based on lstm recurrent
    neural networks,” Applied Sciences, vol. 9, no. 8, pp. 1687, 2019.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] H. Qin 和 P. Wang，"基于LSTM递归神经网络的指静脉验证"，应用科学，第9卷，第8期，第1687页，2019年。'
- en: '[30] W. Yang, C. Hui, Z. Chen, J.-H. Xue, and Q. Liao, “Fv-gan: Finger vein
    representation using generative adversarial networks,” IEEE Trans.Inf. Forensics
    Security, vol. 14, no. 9, pp. 2512–2524, 2019.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] W. Yang, C. Hui, Z. Chen, J.-H. Xue, 和 Q. Liao，"Fv-gan：使用生成对抗网络的指静脉表示"，IEEE信息取证与安全学报，第14卷，第9期，第2512–2524页，2019年。'
- en: '[31] N. M. Kamaruddin and B. A. Rosdi, “A new filter generation method in pcanet
    for finger vein recognition,” IEEE Access, vol. 7, pp. 132 966–132 978, 2019.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] N. M. Kamaruddin 和 B. A. Rosdi，"在PCANet中生成新滤波器的方法，用于指静脉识别"，IEEE Access，第7卷，第132
    966–132 978页，2019年。'
- en: '[32] E. Piciucco, R. S. Kuzu, E. Maiorana, and P. Campisi, “On the cross-finger
    similarity of vein patterns,” in Proc. of ICIAP. Springer, 2019, pp. 12–20.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] E. Piciucco, R. S. Kuzu, E. Maiorana, 和 P. Campisi，"关于指静脉图案的跨指相似性"，见于ICIAP会议论文集。Springer，2019年，第12–20页。'
- en: '[33] J. M. Song, W. Kim, and K. R. Park, “Finger-vein recognition based on
    deep densenet using composite image,” IEEE Access, vol. 7, pp. 66 845–66 863,
    2019.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] J. M. Song, W. Kim, 和 K. R. Park，"基于深度densenet的指静脉识别，采用复合图像"，IEEE Access，第7卷，第66
    845–66 863页，2019年。'
- en: '[34] K. J. Noh, J. Choi, J. S. Hong, and K. R. Park, “Finger-vein recognition
    based on densely connected convolutional network using score-level fusion with
    shape and texture images,” IEEE Access, vol. 8, pp. 96 748–96 766, 2020.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] K. J. Noh, J. Choi, J. S. Hong, 和 K. R. Park，"基于稠密连接卷积网络的指静脉识别，使用形状和纹理图像的得分级融合"，IEEE
    Access，第8卷，第96 748–96 766页，2020年。'
- en: '[35] Y. Zhang and Z. Liu, “Research on finger vein recognition based on sub-convolutional
    neural network,” in Proc. of ICCNEA. IEEE, 2020, pp. 211–216.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Y. Zhang 和 Z. Liu，"基于子卷积神经网络的指静脉识别研究"，见于ICCNEA会议论文集。IEEE，2020年，第211–216页。'
- en: '[36] W. Yang, W. Luo, W. Kang, Z. Huang, and Q. Wu, “Fvras-net: An embedded
    finger-vein recognition and antispoofing system using a unified cnn,” IEEE Trans.
    on Instrumentation and Measurement, vol. 69, no. 11, pp. 8690–8701, 2020.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] W. Yang, W. Luo, W. Kang, Z. Huang, 和 Q. Wu，"Fvras-net：使用统一卷积神经网络的嵌入式指静脉识别与防伪系统"，IEEE仪器与测量学报，第69卷，第11期，第8690–8701页，2020年。'
- en: '[37] D. Zhao, H. Ma, Z. Yang, J. Li, and W. Tian, “Finger vein recognition
    based on lightweight cnn combining center loss and dynamic regularization,” Infrared
    Physics & Technology, vol. 105, pp. 103221, 2020.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] D. Zhao, H. Ma, Z. Yang, J. Li, 和 W. Tian，"基于轻量级CNN结合中心损失和动态正则化的指静脉识别"，红外物理与技术，第105卷，第103221页，2020年。'
- en: '[38] H. Ren, L. Sun, J. Guo, C. Han, and F. Wu, “Finger vein recognition system
    with template protection based on convolutional neural network,” Knowledge-Based
    Systems, vol. 227, pp. 107159, 2021.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] H. Ren, L. Sun, J. Guo, C. Han, 和 F. Wu，"基于卷积神经网络的模板保护指静脉识别系统"，知识基础系统，第227卷，第107159页，2021年。'
- en: '[39] J. Huang, M. Tu, W. Yang, and W. Kang, “Joint attention network for finger
    vein authentication,” IEEE Trans. on Instrumentation and Measurement, vol. 70,
    pp. 1–11, 2021.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] J. Huang, M. Tu, W. Yang, 和 W. Kang，"用于指静脉认证的联合注意力网络"，IEEE仪器与测量学报，第70卷，第1–11页，2021年。'
- en: '[40] N. Ma, Y. Li, Y. Wang, S. Ma, and H. Lu, “Research on roi extraction algorithm
    for finger vein recognition based on capsule neural network,” in Proc. of ICFEICT.
    ACM, 2021, pp. 1–5.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] N. Ma, Y. Li, Y. Wang, S. Ma, 和 H. Lu，"基于胶囊神经网络的指静脉识别的ROI提取算法研究"，见于ICFEICT会议论文集。ACM，2021年，第1–5页。'
- en: '[41] G. Wimmer, B. Prommegger, and A. Uhl, “Finger vein recognition and intra-subject
    similarity evaluation of finger veins using the cnn triplet loss,” in Proc. of
    ICPR. IEEE, 2021, pp. 400–406.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] G. Wimmer, B. Prommegger, 和 A. Uhl，"指静脉识别及使用CNN三元组损失的指静脉 intra-subject
    相似性评估"，见于ICPR会议论文集。IEEE，2021年，第400–406页。'
- en: '[42] H. O. Shahreza and S. Marcel, “Towards protecting and enhancing vascular
    biometric recognition methods via biohashing and deep neural networks,” IEEE Trans,
    vol. 3, no. 3, pp. 394–404, 2021.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] H. O. Shahreza 和 S. Marcel，"通过生物哈希和深度神经网络保护和增强血管生物识别方法"，IEEE Transactions，第3卷，第3期，第394–404页，2021年。'
- en: '[43] B. Prommegger, G. Wimmer, and A. Uhl, “Rotation tolerant finger vein recognition
    using cnns,” in Proc. of BIOSIG. IEEE, 2021, pp. 1–5.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] B. Prommegger, G. Wimmer, 和 A. Uhl，"使用卷积神经网络的旋转容忍指静脉识别"，见于BIOSIG会议论文集。IEEE，2021年，第1–5页。'
- en: '[44] B. A. El-Rahiem, F. E. A. El-Samie, and M. Amin, “Multimodal biometric
    authentication based on deep fusion of electrocardiogram (ecg) and finger vein,”
    Multimedia Systems, pp. 1–13, 2021.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] L. Zhang, L. Sun, X. Dong, L. Yu, W. Li, and X. Ning, “An efficient joint
    bayesian model with soft biometric traits for finger vein recognition,” in Proc.
    of CCBR. Springer, 2021, pp. 248–258.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] C. Zhu, Y. Yang, and Y. Jang, “Research on denoising of finger vein image
    based on deep convolutional neural network,” in Proc. of ICCSE. IEEE, 2019, pp.
    374–378.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] X.-j. Guo, D. Li, H.-g. Zhang, and J.-f. Yang, “Image restoration of finger-vein
    networks based on encoder-decoder model,” Optoelectronics Letters, vol. 15, no.
    6, pp. 463–467, 2019.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] S. Yang, H. Qin, X. Liu, and J. Wang, “Finger-vein pattern restoration
    with generative adversarial network,” IEEE Access, vol. 8, pp. 141 080–141 089,
    2020.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] J. He, L. Shen, Y. Yao, H. Wang, G. Zhao, X. Gu, and W. Ding, “Finger
    vein image deblurring using neighbors-based binary-gan (nb-gan),” IEEE Trans.
    on Emerging Topics in Computational Intelligence. 2021.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] J. Choi, J. S. Hong, M. Owais, S. G. Kim, and K. R. Park, “Restoration
    of motion blurred image by modified deblurgan for enhancing the accuracies of
    finger-vein recognition,” Sensors, vol. 21, no. 14, pp. 4635, 2021.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] L. Lei, F. Xi, and S. Chen, “Finger-vein image enhancement based on pulse
    coupled neural network,” IEEE Access, vol. 7, pp. 57 226–57 237, 2019.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] J. Zhang, Z. Lu, M. Li, and H. Wu, “Gan-based image augmentation for finger-vein
    biometric recognition,” IEEE Access, vol. 7, pp. 183 118–183 132, 2019.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] S. Sharma and S. Lohchab, “Personal authentication using finger vein biometric
    technology with implementation of transfer learning cnn model,” Available at SSRN
    3993601, 2021.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] S. M. M. Najeeb, R. R. O. Al-Nima, and M. L. Al-Dabag, “Reinforced deep
    learning for verifying finger veins.” International Journal of Online & Biomedical
    Engineering, vol. 17, no. 7, 2021.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] J. Zeng, F. Wang, C. Qin, J. Gan, Y. Zhai, and B. Zhu, “A novel method
    for finger vein segmentation,” in Proc. of ISIRA. Springer, 2019, pp. 589–600.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] J. Zeng, B. Zhu, Y. Huang, C. Qin, J. Zhu, F. Wang, Y. Zhai, J. Gan, Y.
    Chen, Y. Wang et al., “Real-time segmentation method of lightweight network for
    finger vein using embedded terminal technique,” IEEE Access, vol. 9, pp. 303–316,
    2020.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] Y. Liu, J. Ling, Z. Liu, J. Shen, and C. Gao, “Finger vein secure biometric
    template generation based on deep learning,” Soft Computing, vol. 22, no. 7, pp.
    2257–2265, 2018.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] M. S. M. Asaari, S. A. Suandi, and B. A. Rosdi, “Fusion of band limited
    phase only correlation and width centroid contour distance for finger based biometrics,”
    Expert Systems with Applications, vol. 41, no. 7, pp. 3367–3382, 2014.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] A. Kumar and Y. Zhou, “Human identification using finger images,” IEEE
    Trans. on image processing, vol. 21, no. 4, pp. 2228–2244, 2011.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] J. Yang, W. Sun, N. Liu, Y. Chen, Y. Wang, and S. Han, “A novel multimodal
    biometrics recognition model based on stacked elm and cca methods,” Symmetry,
    vol. 10, no. 4, pp. 96, 2018.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] J. Yang, W. Sun, N. Liu, Y. Chen, Y. Wang 和 S. Han，“一种基于堆叠elm和cca方法的新型多模态生物识别模型，”《对称性》，第10卷，第4期，第96页，2018年。'
- en: '[61] Y. Yin, L. Liu, and X. Sun, “Sdumla-hmt: a multimodal biometric database,”
    in Proc. of CCBR. Springer, 2011, pp. 260–268.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] Y. Yin, L. Liu 和 X. Sun，“Sdumla-hmt：一个多模态生物特征数据库，” 见于CCBR会议论文集。Springer，2011年，第260–268页。'
- en: '[62] B. T. Ton and R. N. Veldhuis, “A high quality finger vascular pattern
    dataset collected using a custom designed capturing device,” in Proc. of ICB.
    IEEE, 2013, pp. 1–5.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] B. T. Ton 和 R. N. Veldhuis，“使用定制设计的采集设备收集的高质量指纹血管模式数据集，” 见于ICB会议论文集。IEEE，2013年，第1–5页。'
- en: '[63] X. Meng, X. Xi, G. Yang, and Y. Yin, “Finger vein recognition based on
    deformation information,” Science China Information Sciences, vol. 61, no. 5,
    pp. 1–15, 2018.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] X. Meng, X. Xi, G. Yang 和 Y. Yin，“基于变形信息的指静脉识别，”《中国科学：信息科学》，第61卷，第5期，第1–15页，2018年。'
- en: '[64] J. Zhang, C. Li, Y. Yin, J. Zhang, and M. Grzegorzek, “Applications of
    artificial neural networks in microorganism image analysis: a comprehensive review
    from conventional multilayer perceptron to popular convolutional neural network
    and potential visual transformer,” Artificial Intelligence Review, pp. 1–58, 2022.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] J. Zhang, C. Li, Y. Yin, J. Zhang 和 M. Grzegorzek，“人工神经网络在微生物图像分析中的应用：从传统的多层感知器到流行的卷积神经网络及潜在的视觉变换器的全面综述，”《人工智能评论》，第1–58页，2022年。'
- en: '[65] K. J. Noh, J. Choi, J. S. Hong, and K. R. Park, “Finger-vein recognition
    based on densely connected convolutional network using score-level fusion with
    shape and texture images,” IEEE Access, vol. 8, pp. 96 748–96 766, 2020.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] K. J. Noh, J. Choi, J. S. Hong 和 K. R. Park，“基于密集连接卷积网络的指静脉识别，使用与形状和纹理图像的分数级融合，”《IEEE
    Access》，第8卷，第96,748–96,766页，2020年。'
- en: '[66] J. Gou, B. Yu, S. J. Maybank, and D. Tao, “Knowledge distillation: A survey,”
    International Journal of Computer Vision, vol. 129, no. 6, pp. 1789–1819, 2021.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] J. Gou, B. Yu, S. J. Maybank 和 D. Tao，“知识蒸馏：综述，”《国际计算机视觉杂志》，第129卷，第6期，第1789–1819页，2021年。'
