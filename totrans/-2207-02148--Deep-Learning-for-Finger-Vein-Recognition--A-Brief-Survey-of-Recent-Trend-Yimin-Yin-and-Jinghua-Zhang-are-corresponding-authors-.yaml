- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:45:25'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2207.02148] Deep Learning for Finger Vein Recognition: A Brief Survey of Recent
    Trend Yimin Yin and Jinghua Zhang are corresponding authors.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2207.02148](https://ar5iv.labs.arxiv.org/html/2207.02148)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Deep Learning for Finger Vein Recognition: A Brief Survey of Recent Trend'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '^†^†thanks: Yimin Yin and Jinghua Zhang are corresponding authors.'
  prefs: []
  type: TYPE_NORMAL
- en: Renye Zhang School of Computer Science
  prefs: []
  type: TYPE_NORMAL
- en: Hunan First Normal University Changsha, China
  prefs: []
  type: TYPE_NORMAL
- en: renyezhang2016@163.com    Yimin Yin School of Mathematics and Statistics
  prefs: []
  type: TYPE_NORMAL
- en: Hunan First Normal University Changsha, China
  prefs: []
  type: TYPE_NORMAL
- en: yinyimin16@nudt.edu.cn    Wanxia Deng College of Electronic Science
  prefs: []
  type: TYPE_NORMAL
- en: National University of Defense Technology Changsha, China
  prefs: []
  type: TYPE_NORMAL
- en: wanxiadeng@163.com    Chen Li College of Medicine and Biological Information
    Engineering
  prefs: []
  type: TYPE_NORMAL
- en: Northeastern University Shenyang, China
  prefs: []
  type: TYPE_NORMAL
- en: lichen201096@hotmail.com    Jinghua Zhang College of Intelligent Science and
    Technology
  prefs: []
  type: TYPE_NORMAL
- en: National University of Defense Technology Changsha, China
  prefs: []
  type: TYPE_NORMAL
- en: zhangjingh@foxmail.com
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Finger vein image recognition technology plays an important role in biometric
    recognition and has been successfully applied in many fields. Because veins are
    buried beneath the skin tissue, finger vein image recognition has an unparalleled
    advantage, which is not easily disturbed by external factors. This review summarizes
    46 papers about deep learning for finger vein image recognition from 2017 to 2021\.
    These papers are summarized according to the tasks of deep neural networks. Besides,
    we present the challenges and potential development directions of finger vein
    image recognition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Finger vein image recognition, Deep learning, Deep neural network
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Biometric recognition aims to identify a person based on physical features,
    such as fingerprint, voice, and iris [[1](#bib.bib1)]. With the growing requirement
    of digital security verification systems, the biometric recognition plays a vital
    role in many fields, such as online payment, security, and other fields. Compared
    to the traditional secure identification process, biometric recognition technology
    is more efficient due to its convenience and steady security. Unfortunately, several
    representative biometric identification technologies are struck in some bottlenecks.
    For instance, the fingerprint recognition rate is significantly affected by the
    finger surface. Besides, the fingerprints inadvertently left on things may lead
    to security risks. Voice recognition usually requires a relatively quiet environment.
    The recognition rate of iris systems is outstanding, but it requires expensive
    sensors. Different from above technologies, the *Finger Vein Image Recognition*
    (FVIR) is efficient and low-cost. The finger vein is buried beneath the skin of
    the finger and is unique to each individual. It can be recognized through the
    near-infrared light [[2](#bib.bib2)] not the visible light which is vulnerable
    to external factors.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial intelligence technology, especially *Deep Learning* (DL) technology,
    has developed rapidly in recent years. Compared with transitional image processing
    methods, DL achieves overwhelming performance in many tasks of computer vision,
    such as biometric recognition [[1](#bib.bib1)], biomedical image analysis [[6](#bib.bib6)],
    and autonomous driving [[7](#bib.bib7)]. DL-based methods are widely used in FVIR
    tasks. The traditional FVIR process usually includes image capture, image data
    pre-processing, feature extraction, and classification or other analysis tasks.
    The application of DL-based methods, especially *Convolutional Neural Networks*
    (CNNs), greatly changes the manual feature extraction process. The performance
    of conventional machine learning approaches is significantly influenced by feature
    engineering, in which the feature selection is based on human domain knowledge.
    Nevertheless, CNNs can extract abstract but efficient features by supervised or
    semi-supervised learning. The recognition process has been extremely simplified
    by DL-based methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate the recent trend and potential direction of DL-based FVIR, we
    conduct this brief survey. We summarize 46 related papers from 2017 to 2021, which
    cover different finger vein image analysis tasks, including classification, feature
    extraction, image enhancement, image segmentation, encryption. These papers are
    collected from popular academic dataset or searching engine, which mainly includes
    IEEE, Springer, Elsevier, and Google Scholar. We use “finger vein image analysis”
    AND (“deep learning” OR “neural network” OR “ANN” OR “CNN”OR “GAN” OR “RNN” OR
    “LSTM”) as the searching keywords. The structure of this paper is as follows:
    In Sec. [II](#S2 "II Deep learning techniques ‣ Deep Learning for Finger Vein
    Recognition: A Brief Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding
    authors."), we briefly introduce the commonly used public datasets, some representative
    DL techniques, and existing survey papers. In Sec. [III](#S3 "III Finger vein
    recognition based on deep learning ‣ Deep Learning for Finger Vein Recognition:
    A Brief Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors."),
    the related papers are summarized according to the tasks of neural networks. In
    Sec. [IV](#S4 "IV Challenge and potential direction ‣ Deep Learning for Finger
    Vein Recognition: A Brief Survey of Recent Trend Yimin Yin and Jinghua Zhang are
    corresponding authors."), the challenges and potential directions of FVIR are
    talked. Finally, in Sec. [V](#S5 "V Conclusion and future work ‣ Deep Learning
    for Finger Vein Recognition: A Brief Survey of Recent Trend Yimin Yin and Jinghua
    Zhang are corresponding authors."), the conclusion and future work of this paper
    is provided.'
  prefs: []
  type: TYPE_NORMAL
- en: II Deep learning techniques
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we first introduce the commonly used public datasets. Then,
    the most widely used networks in FVIR are summarized. Finally, we also discuss
    the difference between our survey and existing papers.
  prefs: []
  type: TYPE_NORMAL
- en: II-A Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Dataset is critical in developing FVIR technology. The image data capacity
    and quality in the dataset can directly affect the performance of DL model. Through
    the investigation of relevant papers, the most widely used datasets are FV-USM [[58](#bib.bib58)],
    HKPU [[59](#bib.bib59)], MMCBNU-6000 [[60](#bib.bib60)], SDUMLA-HMT [[61](#bib.bib61)],
    UTFVP [[62](#bib.bib62)]. The base information of these datasets are provided
    in Tab. [I](#S2.T1 "TABLE I ‣ II-A Dataset ‣ II Deep learning techniques ‣ Deep
    Learning for Finger Vein Recognition: A Brief Survey of Recent Trend Yimin Yin
    and Jinghua Zhang are corresponding authors.").'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE I: The base information of finger vein datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Data Source | Image Number | Resolution |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| SDUMLA-HMT | 106 | 3816 | 320 $\times$ 240 |'
  prefs: []
  type: TYPE_TB
- en: '| HKPU | 156 | 3132 | 513 $\times$ 256 |'
  prefs: []
  type: TYPE_TB
- en: '| MMCBNU-6000 | 100 | 6000 | 320 $\times$ 240 |'
  prefs: []
  type: TYPE_TB
- en: '| FV-USM | 123 | 5904 | 640 $\times$ 480 |'
  prefs: []
  type: TYPE_TB
- en: '| UTFVP | 60 | 1440 | 672 $\times$ 380 |'
  prefs: []
  type: TYPE_TB
- en: '| THU-FVFDT2 | 610 | 2440 | 720 $\times$ 576 |'
  prefs: []
  type: TYPE_TB
- en: II-B Deep Neural Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'AlexNet [[8](#bib.bib8)], ResNet [[9](#bib.bib9)], and GAN [[5](#bib.bib5)]
    are the most widely used networks in FVIR. The base characteristics of them are
    provided as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: II-B1 AlexNet
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'AlexNet is a milestone in DL technology. Before it, the development of neural
    network technology was at a low ebb for many years. It is the first CNN to win
    the ILSVRC 2012\. After AlexNet, DL starts to be the mainstream technology in
    many computer vision tasks [[64](#bib.bib64)]. The structure of AlexNet contains
    five convolutional layers and three max-pooling layers. Additionally, it has three
    fully connected layers with 4096, 4096 and 1000 neurons, respectively. Its structure
    is provided in Fig. [1](#S2.F1 "Figure 1 ‣ II-B1 AlexNet ‣ II-B Deep Neural Networks
    ‣ II Deep learning techniques ‣ Deep Learning for Finger Vein Recognition: A Brief
    Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors.").
    This network adopts ReLU as activate function, and Dropout and data augmentation
    are applied to prevent over-fitting.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/03c4d7773e46bebc5df6f1b506f3adbe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The structure of AlexNet'
  prefs: []
  type: TYPE_NORMAL
- en: II-B2 ResNet
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'ResNet is a deep neural network composed of several residual units connected
    in series. As shown in Fig. [2](#S2.F2 "Figure 2 ‣ II-B2 ResNet ‣ II-B Deep Neural
    Networks ‣ II Deep learning techniques ‣ Deep Learning for Finger Vein Recognition:
    A Brief Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors."),
    the residual unit is made up of convolutional layers and a shortcut connection.
    The shortcut connection can effectively guarantee the back propagation of gradient.
    Additionally, ResNet does not contain any fully connected layer, except for the
    output layer. This design dramatically reduces the number of network parameters.
    Owing to the excellent structure of ResNet, it is widely used as the backbone
    in many computer vision tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4f1bbca9048c3448d8a9dad604f0b6f1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The residual unit structure.'
  prefs: []
  type: TYPE_NORMAL
- en: II-B3 GAN
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'GAN is commonly used in the finger vein image restoration task. Its structure
    is shown in Fig. [3](#S2.F3 "Figure 3 ‣ II-B3 GAN ‣ II-B Deep Neural Networks
    ‣ II Deep learning techniques ‣ Deep Learning for Finger Vein Recognition: A Brief
    Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors.").
    Different from the neural networks used for classification, GAN is composed of
    the generator and discriminator. The task of generator is to generate the fake
    samples that can fool the discriminator. The discriminator aims to distinguish
    between true and false samples. This generative adversarial process can be modeled
    in the form of ([1](#S2.E1 "In II-B3 GAN ‣ II-B Deep Neural Networks ‣ II Deep
    learning techniques ‣ Deep Learning for Finger Vein Recognition: A Brief Survey
    of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors.")). $V$
    is the objective function of the entire model. $D$ is discriminator, $G$ is generator,
    $E_{x\sim P_{data}}$ represents the true data distribution, $E_{z\sim P_{z}(z)}$
    represents random noise distribution The entire formula reveals the GAN optimization
    process. As shown in Fig. [3](#S2.F3 "Figure 3 ‣ II-B3 GAN ‣ II-B Deep Neural
    Networks ‣ II Deep learning techniques ‣ Deep Learning for Finger Vein Recognition:
    A Brief Survey of Recent Trend Yimin Yin and Jinghua Zhang are corresponding authors."),
    the generator network receives the noisy random input, while the discriminator
    network receives the true sample. The output of the generator network is then
    fed into the discriminator, which verifies if it is a genuine sample.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/220799fa1aab2a90aff5dc11a197e918.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: The basic theory of GAN'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathop{min}\limits_{Gener}\mathop{max}\limits_{Discr}V(Gener,Discr)=E_{x\sim
    P_{data}}[logDiscr(x)]+$ |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle E_{z\sim P_{z}(z)}[log[1-Discr(Gener(z))]]$ |  |'
  prefs: []
  type: TYPE_TB
- en: II-C Analysis of Existing Reviews
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We also analyse the existing reviews about FVIR. In [[10](#bib.bib10)], the
    main FVIR process is introduced, but the contributions of related papers are not
    discussed. In [[4](#bib.bib4)], the amount of literature summarized is limited.
    [[11](#bib.bib11)] classifies papers according to the network type, but it does
    not explain the tasks of networks. Different from these reviews, we conduct this
    survey by a detailed analysis of the neural network tasks, which can provide a
    new sight for the related research. Besides, our survey provides the introduction
    the open access datasets and the mainstream DL technologies. Additionally, a comprehensive
    summary table of state-of-the-art works is presented.
  prefs: []
  type: TYPE_NORMAL
- en: III Finger vein recognition based on deep learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An overview of FVIR based on DL is presented in this section. According to the
    tasks of neural networks, the papers are divided into five parts. In each task,
    the representative methods are introduced. In the end, we provide a summary table.
  prefs: []
  type: TYPE_NORMAL
- en: III-A Classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Classification is the main task in FVIR. Compared with traditional machine learning
    methods, DL technology shows overwhelming performance in finger vein image classification
    tasks. [[12](#bib.bib12), [13](#bib.bib13), [15](#bib.bib15), [16](#bib.bib16),
    [18](#bib.bib18), [19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22),
    [23](#bib.bib23), [24](#bib.bib24), [26](#bib.bib26), [28](#bib.bib28), [29](#bib.bib29),
    [30](#bib.bib30), [32](#bib.bib32), [33](#bib.bib33), [34](#bib.bib34), [35](#bib.bib35),
    [36](#bib.bib36), [37](#bib.bib37), [38](#bib.bib38), [39](#bib.bib39), [41](#bib.bib41),
    [43](#bib.bib43), [45](#bib.bib45), [53](#bib.bib53), [54](#bib.bib54)] focus
    on the finger vein classification task based on DL. Among them, most papers adopt
    similar CNN-based workflow to classify the finger vein data. For example, ResNet
    is directly applied on the image data to perform the classification task in [[18](#bib.bib18)].
    Similar workflows are used in [[20](#bib.bib20), [32](#bib.bib32), [37](#bib.bib37),
    [53](#bib.bib53)]. It is worth noting that [[39](#bib.bib39)] imports joint attention
    module to improve the contribution of vein patterns in feature extraction. Besides
    CNNs, there are some papers adopting different neural networks, such as [[21](#bib.bib21)]
    use *Graph Neural Network* (GNN) to perform the classification. The intricate
    vein texture can be described as a graph structure. Hence, GNN can quickly distinguish
    different finger vein images from limited data. Additionally, [[19](#bib.bib19)]
    utilizes supervised discrete hashing to increase matching speed. [[23](#bib.bib23)]
    uses bias filed correction and spatial attention to optimize the CNN-based FVIR
    task. The module of [[28](#bib.bib28)] had better rotation invariance than normal
    CNN by using the capsule network. [[30](#bib.bib30)] proposes a novel approach
    based on GAN. This method learns the joint distribution of finger vein images
    and pattern maps, which enhance the capacity for feature representation. [[41](#bib.bib41)]
    employs the triplet loss with hard triplet online mining approach to explore the
    similarity between different fingers of a person.
  prefs: []
  type: TYPE_NORMAL
- en: III-B Feature Extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The application of DL-based methods drastically alters the feature extraction
    process in FVIR. CNNs can automatically extract features from images. [[14](#bib.bib14),
    [17](#bib.bib17), [25](#bib.bib25), [27](#bib.bib27), [31](#bib.bib31), [40](#bib.bib40),
    [44](#bib.bib44)] concentrate on DL-based feature extraction tasks. Some researches [[14](#bib.bib14),
    [25](#bib.bib25), [31](#bib.bib31)] adopt the analogous workflow, which usually
    uses CNN structure to extract features, and then adopts a traditional machine
    learning algorithm to analyse these features. Additionally, some studies use novel
    approaches to extract features, such as [[27](#bib.bib27)] uses the*Convolutional
    Auto-Encoder* (CAE) to learn the feature codes from finger vein images, [[40](#bib.bib40)]
    proposes a capsule neural network based region of interest extraction approach
    for finger veins, which can represent the relationship between the part and the
    whole image. [[17](#bib.bib17)] designs a lightweight two-channel network that
    has only three convolution layers to extract image features with an acceptable
    computation cost, and then support vector machine is adopted to perform the verification
    task. [[44](#bib.bib44)] proposes a deep fusion of electrocardiogram and finger
    vein image data based multi-modal biometric authentication system. This method
    reaches a very high recognition accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: III-C Image Enhancement
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Different finger vein image collection devices and user habits often lead to
    noisy image data in real scenarios [54], which seriously influence the performance
    of the DL model. To obtain high quality images sometimes, the original finger
    vein images must be enhanced. [[46](#bib.bib46), [47](#bib.bib47), [48](#bib.bib48),
    [49](#bib.bib49), [50](#bib.bib50), [51](#bib.bib51), [52](#bib.bib52)] introduce
    the application of DL technology in finger vein image enhancement. Among these
    papers, GAN has a wide range of applications. For instance, GAN is used to recover
    the missed vein patterns that are generated in the image capture process owing
    to various factors in [[48](#bib.bib48)]. To recover the severely damaged finger
    vein images, [[49](#bib.bib49)] proposes a modified GAN based on neighbors-based
    binary patterns texture loss. [[50](#bib.bib50)] proposes a modified DeblurGAN
    to increase identification performance by restoring motion blurred finger vein
    images to solve the problem of motion blur in FVIR. In addition to GANs, some
    other modules are applied in image restoration for FVIR. [[46](#bib.bib46)] proposes
    a finger vein image denoising method based on the deep CNN, the deconvolution
    sub-net recovers the original image based on the features, and the modified linear
    unit extract finger vein texture details. [[47](#bib.bib47)] uses a CAE to restore
    the venous networks of the finger vein images, thereby effectively extracting
    features. [[51](#bib.bib51)] proposes a new network architecture based on the
    pulse-coupled neural network to improved the finger vein image quality and increase
    the practicality of FVIR.
  prefs: []
  type: TYPE_NORMAL
- en: III-D Image Segmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finger vein image segmentation is an important stage in FVIR technology. The
    quality of segmentation has a direct impact on feature extraction and recognition.
    [[55](#bib.bib55)] proposes a finger vein segmentation algorithm based on LadderNet,
    it can obtain abundant semantic information from vein image by concatenating the
    feature channels of the expanding path and contracting path in the network. Additionally,
    the parameters of normal finger vein segmentation networks are overabundant, which
    makes they are challenging to use in mobile terminals. To overcome this problem,
    [[56](#bib.bib56)] proposes a lightweight real-time segmentation network in FVIR
    based on the embedded terminal. The performance of this network is not inferior
    to more complex networks and satisfied the needs of embedded mobile terminals.
  prefs: []
  type: TYPE_NORMAL
- en: III-E Encryption
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since biometric information is irreplaceable and unique for everyone, once the
    original biometric information is stolen, it may cause irreversible loss. To protect
    the privacy of users more effectively, encryption methods are used in FVIR. This
    technology masks the biometric information in the image by encrypting the original
    image. Even if the finger vein image is stolen, criminals cannot obtain valid
    information from it. However, the biggest challenge of encryption is how to keep
    the performance of the recognition system while protecting biometric data. To
    address this issue, [[57](#bib.bib57)] presented a novel FVIR algorithm by using
    a secure biometric template scheme based on DL and random projections. This algorithm
    randomly generates a secured template for the original biometric message by random
    projections. [[42](#bib.bib42)] proposes a deep CAE structure to reduce the dimension
    of the feature space and introduced the Biohashing algorithm to generate protected
    templates based on the features that were extracted at the CAE.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE II: The summary table of surveyed papers. For short, Task, Dataset, Reference,
    Network, Performance, Classification, Feature extraction, Image enhancement, Image
    segmentation, encryption, SDUMLA-HMT, HKPU, MMCBNU-6000, FV-USM, UTFVP, THU-FVFDT2,
    SCUT, IDIAP, PLUSVein-FV3, private, VeinECG, ISPR, NJUST-FV, Accuracy, Equal Error
    Rate, Peak Signal-to-Noise Ratio, Structural Similarity, Presentation Classification
    Error Rate and Bona-fide Presentation Classification Error Rate are abbreviated
    to T, D, Ref, Net, Perf, C*, F*, IE*, S*, E*, SD*, HK*, MM*, US*, UT*, TH*, SC*,
    ID*, PL*, PR*, VE*, IS*, NJ*, ACC, EERE, PSNR, SSIM, APCER and BPCER.'
  prefs: []
  type: TYPE_NORMAL
- en: '| T. | D. | Ref. | Net. | Perf.(%) | T. | D. | Ref. | Net. | Perf.(%) | T.
    | D. | Ref. | Net. | Perf.(%) |'
  prefs: []
  type: TYPE_TB
- en: '| C* | SD* | [[18](#bib.bib18)] | ResNet-101 | EERE 3.3653 | C* | MM* | [[39](#bib.bib39)]
    | JAFVNet | EERE 0.23 | F* | SD* | [[40](#bib.bib40)] | Capsule Network | ACC
    97.5 |'
  prefs: []
  type: TYPE_TB
- en: '| [[28](#bib.bib28)] | Capsule Network | ACC 100 | [[38](#bib.bib38)] | ResNet
    |'
  prefs: []
  type: TYPE_TB
- en: '&#124; EERE 0.090 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; CIR 99.667 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| HK* | [[14](#bib.bib14)] | Improved CNN | ACC 87.08 |'
  prefs: []
  type: TYPE_TB
- en: '| [[19](#bib.bib19)] | Light CNN | EERE 0.1497 | [[45](#bib.bib45)] | two-branch
    CNN | EERE 0.17 | MM* | [[17](#bib.bib17)] | two-stream network | EERE 0.10 |'
  prefs: []
  type: TYPE_TB
- en: '| [[26](#bib.bib26)] | RefineNet | EERE 2.45 | US* | [[15](#bib.bib15)] | Improved
    CNN | EERE 1.42 | US* | [[27](#bib.bib27)] | CAE |'
  prefs: []
  type: TYPE_TB
- en: '&#124; ACC 99.49 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; EERE 0.16 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| [[30](#bib.bib30)] | GAN | EERE 0.94 | [[20](#bib.bib20)] | DBN | ACC 97.4
    | [[31](#bib.bib31)] | PCANet | ACC 99.49 |'
  prefs: []
  type: TYPE_TB
- en: '| [[21](#bib.bib21)] | GNN | ACC 99.98 | [[35](#bib.bib35)] | Sub-CNN | ACC
    95.1 | [[40](#bib.bib40)] | Capsule Network | ACC 99.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [[32](#bib.bib32)] | DenseNet-201 | EERE 0.54 | [[37](#bib.bib37)] | Improved
    CNN |'
  prefs: []
  type: TYPE_TB
- en: '&#124; ACC 97.95 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; EERE 1.070 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| TH* | [[31](#bib.bib31)] | PCANet | ACC 100 |'
  prefs: []
  type: TYPE_TB
- en: '| [[33](#bib.bib33)] | DenseNet-161 | EERE 2.35 | [[38](#bib.bib38)] | ResNet
    | EERE 0.091 | ID* | [[25](#bib.bib25)] | VGG-16 | EERE 0.0000 |'
  prefs: []
  type: TYPE_TB
- en: '| [[34](#bib.bib34)] | DenseNet-161 | EERE 1.65 | [[39](#bib.bib39)] | JAFVNet
    | EERE 0.49 | VE* | [[44](#bib.bib44)] | Improved CNN | EERE 0.12 |'
  prefs: []
  type: TYPE_TB
- en: '| [[23](#bib.bib23)] | ResNet-50 | ACC 99.53 | [[24](#bib.bib24)] | NASNet
    | ACC 98.89 | IS* | [[25](#bib.bib25)] | VGG-16 | EERE 0.0311 |'
  prefs: []
  type: TYPE_TB
- en: '| [[38](#bib.bib38)] | ResNet | EERE 2.137 | UT* | [[28](#bib.bib28)] | Capsule
    Network | ACC 94 | IE* | SD* | [[50](#bib.bib50)] | GAN | EERE 5.270 |'
  prefs: []
  type: TYPE_TB
- en: '| [[39](#bib.bib39)] | JAFVNet | EERE 1.18 | [[41](#bib.bib41)] | SqueezeNet
    | EERE 2.5 | [[51](#bib.bib51)] | PCNN | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[41](#bib.bib41)] | SqueezeNet | EERE 2.7 | [[26](#bib.bib26)] | U-Net |
    EERE 0.64 | [[52](#bib.bib52)] | GAN | EERE 0.87 |'
  prefs: []
  type: TYPE_TB
- en: '| [[53](#bib.bib53)] | GoogleNet | ACC 92.22 | TH* | [[30](#bib.bib30)] | GAN
    |'
  prefs: []
  type: TYPE_TB
- en: '&#124; ACC 98.52 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; EERE 1.12 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| HK* | [[46](#bib.bib46)] | Improved CNN | PSNR 29.638 |'
  prefs: []
  type: TYPE_TB
- en: '| [[45](#bib.bib45)] | two-branch CNN | EERE 0.94 | [[23](#bib.bib23)] | ResNet-50
    | ACC 98.64 | [[50](#bib.bib50)] | GAN | EERE 4.536 |'
  prefs: []
  type: TYPE_TB
- en: '| HK* | [[15](#bib.bib15)] | Improved CNN | EERE 2.70 | SC* | [[12](#bib.bib12)]
    | FPNet | EERE 0.00 | [[51](#bib.bib51)] | PCNN | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[18](#bib.bib18)] | ResNet-101 | EERE 1.0799 | [[36](#bib.bib36)] | FVRASNet
    | EERE 2.02 | MM* | [[48](#bib.bib48)] | GAN | EERE 5.66 |'
  prefs: []
  type: TYPE_TB
- en: '| [[28](#bib.bib28)] | Capsule Network | ACC 88 | [[39](#bib.bib39)] | JAFVNet
    | EERE 0.86 | US* | [[48](#bib.bib48)] | GAN | EERE 2.37 |'
  prefs: []
  type: TYPE_TB
- en: '| [[29](#bib.bib29)] | LSTM | EERE 0.95 | ID* | [[12](#bib.bib12)] | FPNet
    | EERE 0.25 | PR* | [[47](#bib.bib47)] | CAE | EERE 0.16 |'
  prefs: []
  type: TYPE_TB
- en: '| [[33](#bib.bib33)] | DenseNet-161 | EERE 0.33 | [[36](#bib.bib36)] | FVRASNet
    | EERE 4.26 | [[49](#bib.bib49)] | GAN |'
  prefs: []
  type: TYPE_TB
- en: '&#124; PSNR 30.42 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; SSIM 98.85 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| [[34](#bib.bib34)] | DenseNet-161 | EERE 0.05 | PL* | [[41](#bib.bib41)]
    | SqueezeNet | EERE 2.4 | NJ* | [[51](#bib.bib51)] | PCNN | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[38](#bib.bib38)] | ResNet | EERE 0.277 | [[43](#bib.bib43)] | Triplrt-SqNet
    | EERE 3 | S* | SD* | [[55](#bib.bib55)] | LadderNet | ACC 92.44 |'
  prefs: []
  type: TYPE_TB
- en: '| [[41](#bib.bib41)] | SqueezeNet | EERE 3.7 | PR* | [[16](#bib.bib16)] | AlexNet
    |'
  prefs: []
  type: TYPE_TB
- en: '&#124; APCER 0 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; BPCER 0 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| [[56](#bib.bib56)] | DintyNet | ACC 91.93 |'
  prefs: []
  type: TYPE_TB
- en: '| [[54](#bib.bib54)] | Improved CNN | ACC 91.19 | [[20](#bib.bib20)] | DBN
    | ACC 97.8 | MM* | [[55](#bib.bib55)] | LadderNet | ACC 93.93 |'
  prefs: []
  type: TYPE_TB
- en: '| MM* | [[28](#bib.bib28)] | Capsule Network | ACC 100 | [[22](#bib.bib22)]
    | LSTM | ACC 99.13 | [[56](#bib.bib56)] | DintyNet | ACC 90.90 |'
  prefs: []
  type: TYPE_TB
- en: '| [[21](#bib.bib21)] | GNN | ACC 99.98 | F* | SD* | [[17](#bib.bib17)] | two-channel
    network | EERE 0.47 | E* | UT* | [[42](#bib.bib42)] | CAE | EERE 0.7 |'
  prefs: []
  type: TYPE_TB
- en: '| [[37](#bib.bib37)] | Improved CNN |'
  prefs: []
  type: TYPE_TB
- en: '&#124; ACC 99.05 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; EERE 0.503 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| [[31](#bib.bib31)] | PCANet | ACC 98.19 | PR* | [[57](#bib.bib57)] | CAE
    |'
  prefs: []
  type: TYPE_TB
- en: '&#124; GAR 96.9 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; FAR 1.5 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: IV Challenge and potential direction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Compared with traditional biometric technology, FVIR has unparalleled advantages
    but it still faces some challenges, especially during image capture [[49](#bib.bib49)], [[63](#bib.bib63)], [[36](#bib.bib36)],
    which contains uneven illumination, light scattering in finger tissue, inappropriate
    ambient temperature, image displacement, presentation attacks, shading, etc. All
    of the aforementioned challenges have varying degrees of impact on the performance
    of FVIR. To overcome these challenges, [[12](#bib.bib12), [25](#bib.bib25), [16](#bib.bib16),
    [51](#bib.bib51), [52](#bib.bib52), [48](#bib.bib48), [36](#bib.bib36), [49](#bib.bib49)]
    try to propose solutions from different aspects. However, these technical difficulties
    have not been completely solved, and they will remain the focus of FVIR in the
    future.
  prefs: []
  type: TYPE_NORMAL
- en: Besides, FVIR also has some potential directions. For instance, FVIR generally
    needs to be implemented on lightweight portable mobile terminals. However, most
    of the deep neural networks are not suitable for this kind of device. Therefore,
    DL-based FVIR faces some difficulties in practice. Knowledge distillation [[66](#bib.bib66)]
    can be utilized to overcome this challenge. Knowledge distillation can greatly
    condense complicated networks by teaching a small student model from a large model.
    This technology can greatly improve the application ability of FVIR in reality.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, one of the conveniences of FVIR is that even if one finger is in
    an accident, the other fingers can still be used for identification. But registering
    ten fingers simultaneously in an identification system is a hassle for users.
    Therefore, it is necessary to explore whether the finger veins of the ten fingers
    of the same individual are similar in future FVIR research work. If there is some
    connections between different finger veins of the same person and they can be
    identified by FVIR systems, it will take the convenience of FVIR systems to a
    new level. Although [[32](#bib.bib32), [41](#bib.bib41)] focus on this problem,
    they still have some limitations.[[32](#bib.bib32)] considers the connection between
    the veins of different fingers of the same person is too weak to perform the recognition.
    [[41](#bib.bib41)] utilizes the triplet loss with hard triplet online mining for
    FVIR. This strategy successfully verified that symmetric fingers (the same sort
    of finger but from opposite hands in the same individual) have enough similarities
    to be recognized. The similarities of other asymmetric fingers is also proved
    in  [[41](#bib.bib41)], but the proposed recognition system is still unable to
    effectively identify these asymmetric finger veins. Therefore, related work can
    still be further explored in the future.
  prefs: []
  type: TYPE_NORMAL
- en: V Conclusion and future work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this brief survey, we summarize the DL technology for FVIR. First, we introduce
    the base information of widely used public datasets and some popular CNN structures.
    After that, we summarize 46 related research literature of FVIR based on DL from
    2017 to 2021, and classify them according to the tasks of neural networks, which
    includes classification, feature extraction, image enhancement, image segmentation,
    encryption. Finally, we discuss the current challenges and development directions
    of FVIR. From this review, it can be found that the tasks of neural networks are
    diverse in FVIR, and compared to other biometric recognition systems, FVIR has
    unique advantages. In the future, we will investigate more literature and DL techniques
    in FVIR to propose a comprehensive review.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] U. B. Ghosh, R. Sharma, and A. Kesharwani, “Symptoms-based biometric pattern
    detection and recognition,” in Augmented Intelligence in Healthcare: A Pragmatic
    and Integrated Analysis. Springer, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] M. Madhusudhan, V. Udaya Rani, and C. Hegde, “Finger vein recognition model
    for biometric authentication using intelligent deep learning,” International Journal
    of Image and Graphics, pp. 2240004, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] S. Pandey, N. Prabhu, and A. S. Kumar, “Survey on finger vein recognition
    using convolutional neural network,” in Proc. of ICAIS. IEEE, 2022, pp. 162-166.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] B. Chawla, S. Tyagi, R. Jain, A. Talegaonkar, and S. Srivastava, “Finger
    vein recognition using deep learning,” in Proc. of ICAIA. Springer, 2021, pp.
    69-78.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, and Y. Bengio, “Generative adversarial nets,” in Proc. of NIPS,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] J. Zhang, C. Li, S. Kosov, M. Grzegorzek, K. Shirahama, T. Jiang, C. Sun,
    Z. Li, and H. Li, “Lcu-net: A novel low-cost u-net for environmental microorganism
    image segmentation,” Pattern Recognition, vol. 115, pp. 107885, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] R Qian, X Lai, and X Li, “3D object detection for autonomous driving: a
    survey,” Pattern Recognition, vol. 130, pp. 108796, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
    with deep convolutional neural networks,” in Proc. of NIPS, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
    recognition,” in Proc. of CVPR. IEEE, 2016, pp. 770-778.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] S. Daas, M. Boughazi, M. Sedhane, and B. Bouledjfane, “A review of finger
    vein biometrics authentication system,” in Proc. of ICASS. IEEE, 2018, pp. 1-6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] S. Pandey, N. Prabhu, and A. S. Kumar, “Survey on finger vein recognition
    using convolutional neural network,” in Proc. of ICAIS. IEEE, 2022, pp. 162-166.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] X. Qiu, S. Tian, W. Kang, W. Jia, and Q. Wu, “Finger vein presentation
    attack detection using convolutional neural networks,” in Proc. of CCBR. Springer,
    2017, pp. 296-305.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] C. Chen, Z. Wu, J. Zhang, P. Li, and F. Azmat, “A finger vein recognition
    algorithm based on deep learning,” International Journal of Embedded Systems,
    vol. 9, no. 3, pp. 220-228, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] H. Qin and M. A. El-Yacoubi, “Deep representation for finger-vein image-quality
    assessment,” IEEE Trans. on Circuits and Systems for Video Technology, vol. 28,
    no. 8, pp. 1677-1693, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] H. Qin and M. A. El-Yacoubi, “Deep representation-based feature extraction
    and recovering for finger-vein verification,” IEEE Trans. on Information Forensics
    and Security, vol. 12, no. 8, pp. 1816–1829, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] R. Raghavendra, S. Venkatesh, K. B. Raja, and C. Busch, “Transferable
    deep convolutional neural network features for fingervein presentation attack
    detection,” in Proc. of IWBF. IEEE, 2017, pp. 1-5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Y. Fang, Q. Wu, and W. Kang, “A novel finger vein verification system
    based on two-stream convolutional network learning,” Neurocomputing, vol. 290,
    pp. 100–107, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] W. Kim, J. M. Song, and K. R. Park, “Multimodal biometric recognition
    based on convolutional neural network by the fusion of finger-vein and finger
    shape using near-infrared (nir) camera sensor,” Sensors, vol. 18, no. 7, pp. 2296,
    2018'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] C. Xie and A. Kumar, “Finger vein identification using convolutional neural
    network and supervised discrete hashing,” Pattern Recognition Letters, vol. 119,
    pp. 148–156, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Z.-M. Fang and Z.-M. Lu, “Deep belief network based finger vein recognition
    using histograms of uniform local binary patterns of curvature gray images,” International
    Journal of Innovative Computing, Information and Control, vol. 15, no. 5, pp.
    1701–1715, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] J. Li and P. Fang, “Fvgnn: A novel gnn to finger vein recognition from
    limited training data,” in Proc. of ITAIC. IEEE, 2019, pp. 144-148.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] R. S. Kuzu, E. Piciucco, E. Maiorana, and P. Campisi, “On-the-fly fingervein-based
    biometric recognition using deep neural networks,” IEEE Trans. on information
    Forensics and Security, vol. 15, pp. 2641–2654, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] Z. Huang and C. Guo, “Robust finger vein recognition based on deep cnn
    with spatial attention and bias field correction,” International Journal on Artificial
    Intelligence Tools, vol. 30, no. 01, p. 2140005, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] I. S. Wang, H.-T. Chan, and C.-H. Hsia, “Finger-vein recognition using
    a nasnet with a cutout,” in Proc. of ISPACS. IEEE, 2021, pp. 1–2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] D. T. Nguyen, H. S. Yoon, T. D. Pham, and K. R. Park, “Spoof detection
    for finger-vein recognition system using nir camera,” Sensors, vol. 17, no. 10,
    pp. 2261, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] E. Jalilian and A. Uhl, “Finger-vein recognition using deep fully convolutional
    neural semantic segmentation networks: The impact of training data,” in Proc.
    of WIFS. IEEE, 2018, pp. 1-8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] B. Hou and R. Yan, “Convolutional auto-encoder based deep feature learning
    for finger-vein verification,” in Proc. of MeMeA. IEEE, 2018, pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] D. Gumusbas, T. Yildirim, M. Kocakulak, and N. Acir, “Capsule network
    for finger-vein-based biometric identification,” in Proc. of SSCI. IEEE, 2019,
    pp. 437-441.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] H. Qin and P. Wang, “Finger-vein verification based on lstm recurrent
    neural networks,” Applied Sciences, vol. 9, no. 8, pp. 1687, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] W. Yang, C. Hui, Z. Chen, J.-H. Xue, and Q. Liao, “Fv-gan: Finger vein
    representation using generative adversarial networks,” IEEE Trans.Inf. Forensics
    Security, vol. 14, no. 9, pp. 2512–2524, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] N. M. Kamaruddin and B. A. Rosdi, “A new filter generation method in pcanet
    for finger vein recognition,” IEEE Access, vol. 7, pp. 132 966–132 978, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] E. Piciucco, R. S. Kuzu, E. Maiorana, and P. Campisi, “On the cross-finger
    similarity of vein patterns,” in Proc. of ICIAP. Springer, 2019, pp. 12–20.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] J. M. Song, W. Kim, and K. R. Park, “Finger-vein recognition based on
    deep densenet using composite image,” IEEE Access, vol. 7, pp. 66 845–66 863,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] K. J. Noh, J. Choi, J. S. Hong, and K. R. Park, “Finger-vein recognition
    based on densely connected convolutional network using score-level fusion with
    shape and texture images,” IEEE Access, vol. 8, pp. 96 748–96 766, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] Y. Zhang and Z. Liu, “Research on finger vein recognition based on sub-convolutional
    neural network,” in Proc. of ICCNEA. IEEE, 2020, pp. 211–216.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] W. Yang, W. Luo, W. Kang, Z. Huang, and Q. Wu, “Fvras-net: An embedded
    finger-vein recognition and antispoofing system using a unified cnn,” IEEE Trans.
    on Instrumentation and Measurement, vol. 69, no. 11, pp. 8690–8701, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] D. Zhao, H. Ma, Z. Yang, J. Li, and W. Tian, “Finger vein recognition
    based on lightweight cnn combining center loss and dynamic regularization,” Infrared
    Physics & Technology, vol. 105, pp. 103221, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] H. Ren, L. Sun, J. Guo, C. Han, and F. Wu, “Finger vein recognition system
    with template protection based on convolutional neural network,” Knowledge-Based
    Systems, vol. 227, pp. 107159, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] J. Huang, M. Tu, W. Yang, and W. Kang, “Joint attention network for finger
    vein authentication,” IEEE Trans. on Instrumentation and Measurement, vol. 70,
    pp. 1–11, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] N. Ma, Y. Li, Y. Wang, S. Ma, and H. Lu, “Research on roi extraction algorithm
    for finger vein recognition based on capsule neural network,” in Proc. of ICFEICT.
    ACM, 2021, pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] G. Wimmer, B. Prommegger, and A. Uhl, “Finger vein recognition and intra-subject
    similarity evaluation of finger veins using the cnn triplet loss,” in Proc. of
    ICPR. IEEE, 2021, pp. 400–406.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] H. O. Shahreza and S. Marcel, “Towards protecting and enhancing vascular
    biometric recognition methods via biohashing and deep neural networks,” IEEE Trans,
    vol. 3, no. 3, pp. 394–404, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] B. Prommegger, G. Wimmer, and A. Uhl, “Rotation tolerant finger vein recognition
    using cnns,” in Proc. of BIOSIG. IEEE, 2021, pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] B. A. El-Rahiem, F. E. A. El-Samie, and M. Amin, “Multimodal biometric
    authentication based on deep fusion of electrocardiogram (ecg) and finger vein,”
    Multimedia Systems, pp. 1–13, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] L. Zhang, L. Sun, X. Dong, L. Yu, W. Li, and X. Ning, “An efficient joint
    bayesian model with soft biometric traits for finger vein recognition,” in Proc.
    of CCBR. Springer, 2021, pp. 248–258.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] C. Zhu, Y. Yang, and Y. Jang, “Research on denoising of finger vein image
    based on deep convolutional neural network,” in Proc. of ICCSE. IEEE, 2019, pp.
    374–378.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] X.-j. Guo, D. Li, H.-g. Zhang, and J.-f. Yang, “Image restoration of finger-vein
    networks based on encoder-decoder model,” Optoelectronics Letters, vol. 15, no.
    6, pp. 463–467, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] S. Yang, H. Qin, X. Liu, and J. Wang, “Finger-vein pattern restoration
    with generative adversarial network,” IEEE Access, vol. 8, pp. 141 080–141 089,
    2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] J. He, L. Shen, Y. Yao, H. Wang, G. Zhao, X. Gu, and W. Ding, “Finger
    vein image deblurring using neighbors-based binary-gan (nb-gan),” IEEE Trans.
    on Emerging Topics in Computational Intelligence. 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] J. Choi, J. S. Hong, M. Owais, S. G. Kim, and K. R. Park, “Restoration
    of motion blurred image by modified deblurgan for enhancing the accuracies of
    finger-vein recognition,” Sensors, vol. 21, no. 14, pp. 4635, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] L. Lei, F. Xi, and S. Chen, “Finger-vein image enhancement based on pulse
    coupled neural network,” IEEE Access, vol. 7, pp. 57 226–57 237, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] J. Zhang, Z. Lu, M. Li, and H. Wu, “Gan-based image augmentation for finger-vein
    biometric recognition,” IEEE Access, vol. 7, pp. 183 118–183 132, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] S. Sharma and S. Lohchab, “Personal authentication using finger vein biometric
    technology with implementation of transfer learning cnn model,” Available at SSRN
    3993601, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] S. M. M. Najeeb, R. R. O. Al-Nima, and M. L. Al-Dabag, “Reinforced deep
    learning for verifying finger veins.” International Journal of Online & Biomedical
    Engineering, vol. 17, no. 7, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] J. Zeng, F. Wang, C. Qin, J. Gan, Y. Zhai, and B. Zhu, “A novel method
    for finger vein segmentation,” in Proc. of ISIRA. Springer, 2019, pp. 589–600.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] J. Zeng, B. Zhu, Y. Huang, C. Qin, J. Zhu, F. Wang, Y. Zhai, J. Gan, Y.
    Chen, Y. Wang et al., “Real-time segmentation method of lightweight network for
    finger vein using embedded terminal technique,” IEEE Access, vol. 9, pp. 303–316,
    2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] Y. Liu, J. Ling, Z. Liu, J. Shen, and C. Gao, “Finger vein secure biometric
    template generation based on deep learning,” Soft Computing, vol. 22, no. 7, pp.
    2257–2265, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] M. S. M. Asaari, S. A. Suandi, and B. A. Rosdi, “Fusion of band limited
    phase only correlation and width centroid contour distance for finger based biometrics,”
    Expert Systems with Applications, vol. 41, no. 7, pp. 3367–3382, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] A. Kumar and Y. Zhou, “Human identification using finger images,” IEEE
    Trans. on image processing, vol. 21, no. 4, pp. 2228–2244, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] J. Yang, W. Sun, N. Liu, Y. Chen, Y. Wang, and S. Han, “A novel multimodal
    biometrics recognition model based on stacked elm and cca methods,” Symmetry,
    vol. 10, no. 4, pp. 96, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] Y. Yin, L. Liu, and X. Sun, “Sdumla-hmt: a multimodal biometric database,”
    in Proc. of CCBR. Springer, 2011, pp. 260–268.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] B. T. Ton and R. N. Veldhuis, “A high quality finger vascular pattern
    dataset collected using a custom designed capturing device,” in Proc. of ICB.
    IEEE, 2013, pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] X. Meng, X. Xi, G. Yang, and Y. Yin, “Finger vein recognition based on
    deformation information,” Science China Information Sciences, vol. 61, no. 5,
    pp. 1–15, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] J. Zhang, C. Li, Y. Yin, J. Zhang, and M. Grzegorzek, “Applications of
    artificial neural networks in microorganism image analysis: a comprehensive review
    from conventional multilayer perceptron to popular convolutional neural network
    and potential visual transformer,” Artificial Intelligence Review, pp. 1–58, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] K. J. Noh, J. Choi, J. S. Hong, and K. R. Park, “Finger-vein recognition
    based on densely connected convolutional network using score-level fusion with
    shape and texture images,” IEEE Access, vol. 8, pp. 96 748–96 766, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] J. Gou, B. Yu, S. J. Maybank, and D. Tao, “Knowledge distillation: A survey,”
    International Journal of Computer Vision, vol. 129, no. 6, pp. 1789–1819, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
