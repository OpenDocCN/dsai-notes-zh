- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 19:47:26'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024年9月6日 19:47:26
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2203.14263] A General Survey on Attention Mechanisms in Deep Learning'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2203.14263] 关于深度学习中注意力机制的全面调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2203.14263](https://ar5iv.labs.arxiv.org/html/2203.14263)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2203.14263](https://ar5iv.labs.arxiv.org/html/2203.14263)
- en: \stackMath
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \stackMath
- en: A General Survey on Attention Mechanisms in Deep Learning
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于深度学习中注意力机制的全面调查
- en: 'Gianni Brauwers and Flavius Frasincar G. Brauwers and F. Frasincar are with
    the Erasmus School of Economics, Erasmus University Rotterdam, 3000 DR, Rotterdam,
    the Netherlands (e-mail: {frasincar, brauwers}@ese.eur.nl).Manuscript received
    July 6, 2020; revised June 21, 2021; Corresponding author: F. Frasincar'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Gianni Brauwers 和 Flavius Frasincar G. Brauwers 和 F. Frasincar 现为荷兰鹿特丹伊拉斯谟大学经济学院成员（电子邮件：{frasincar,
    brauwers}@ese.eur.nl）。手稿收到日期：2020年7月6日；修订日期：2021年6月21日；通讯作者：F. Frasincar
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Attention is an important mechanism that can be employed for a variety of deep
    learning models across many different domains and tasks. This survey provides
    an overview of the most important attention mechanisms proposed in the literature.
    The various attention mechanisms are explained by means of a framework consisting
    of a general attention model, uniform notation, and a comprehensive taxonomy of
    attention mechanisms. Furthermore, the various measures for evaluating attention
    models are reviewed, and methods to characterize the structure of attention models
    based on the proposed framework are discussed. Last, future work in the field
    of attention models is considered.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力是一个重要的机制，可用于各种深度学习模型，涉及多个不同领域和任务。本调查概述了文献中提出的最重要的注意力机制。通过一个由一般注意力模型、统一符号和全面的注意力机制分类法组成的框架来解释各种注意力机制。此外，还回顾了评估注意力模型的各种措施，并讨论了基于提出的框架来描述注意力模型结构的方法。最后，考虑了注意力模型领域的未来工作。
- en: 'Index Terms:'
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Attention models, deep learning, introductory and survey, neural nets, supervised
    learning
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力模型，深度学习，介绍和调查，神经网络，监督学习
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The idea of mimicking human attention first arose in the field of computer vision
    [[1](#bib.bib1), [2](#bib.bib2)] in an attempt to reduce the computational complexity
    of image processing while improving performance by introducing a model that would
    only focus on specific regions of images instead of the entire picture. Although,
    the true starting point of the attention mechanisms we know today is often attributed
    to originate in the field of natural language processing [[3](#bib.bib3)]. Bahdanau
    et al. [[3](#bib.bib3)] implement attention in a machine translation model to
    address certain issues with the structure of recurrent neural networks. After
    Bahdanau et al. [[3](#bib.bib3)] emphasized the advantages of attention, the attention
    techniques were refined [[4](#bib.bib4)] and quickly became popular for a variety
    of tasks, such as text classification [[5](#bib.bib5), [6](#bib.bib6)], image
    captioning [[7](#bib.bib7), [8](#bib.bib8)], sentiment analysis [[6](#bib.bib6),
    [9](#bib.bib9)], and speech recognition [[10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12)].
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 模仿人类注意力的想法最早出现在计算机视觉领域[[1](#bib.bib1), [2](#bib.bib2)]，旨在通过引入一个只关注图像特定区域而不是整个图像的模型来降低图像处理的计算复杂性，同时提高性能。虽然，今天我们所知的注意力机制的真正起点通常被认为来源于自然语言处理领域[[3](#bib.bib3)]。Bahdanau等人[[3](#bib.bib3)]在机器翻译模型中实现了注意力，以解决递归神经网络结构的一些问题。在Bahdanau等人[[3](#bib.bib3)]强调了注意力的优势后，注意力技术得到了改进[[4](#bib.bib4)]，并迅速在各种任务中流行，如文本分类[[5](#bib.bib5),
    [6](#bib.bib6)]，图像描述[[7](#bib.bib7), [8](#bib.bib8)]，情感分析[[6](#bib.bib6), [9](#bib.bib9)]，以及语音识别[[10](#bib.bib10),
    [11](#bib.bib11), [12](#bib.bib12)]。
- en: Attention has become a popular technique in deep learning for several reasons.
    Firstly, models that incorporate attention mechanisms attain state-of-the-art
    results for all of the previously mentioned tasks, and many others. Furthermore,
    most attention mechanisms can be trained jointly with a base model, such as a
    recurrent neural network or a convolutional neural network using regular backpropagation
    [[3](#bib.bib3)]. Additionally, attention introduces a certain type of interpretation
    into neural network models [[8](#bib.bib8)] that are generally known to be highly
    complicated to interpret. Moreover, the popularity of attention mechanisms was
    additionally boosted after the introduction of the Transformer model [[13](#bib.bib13)]
    that further proved how effective attention can be. Attention was originally introduced
    as an extension to recurrent neural networks [[14](#bib.bib14)]. However, the
    Transformer model proposed in [[13](#bib.bib13)] poses a major development in
    attention research as it demonstrates that the attention mechanism is sufficient
    to build a state-of-the-art model. This means that disadvantages, such as the
    fact that recurrent neural networks are particularly difficult to parallelize,
    can be circumvented. As was the case for the introduction of the original attention
    mechanism [[3](#bib.bib3)], the Transformer model was created for machine translation,
    but was quickly adopted to be used for other tasks, such as image processing [[15](#bib.bib15)],
    video processing [[16](#bib.bib16)], and recommender systems [[17](#bib.bib17)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制在深度学习中已成为一种流行技术，原因有几个。首先，包含注意力机制的模型在所有之前提到的任务以及许多其他任务上都达到了**最先进**的结果。此外，大多数注意力机制可以与基础模型（如递归神经网络或卷积神经网络）共同训练，使用常规的反向传播[[3](#bib.bib3)]。另外，注意力机制为神经网络模型引入了一种特定类型的解释[[8](#bib.bib8)]，这些模型通常被认为难以解释。此外，Transformer模型的引入[[13](#bib.bib13)]进一步证明了注意力机制的有效性，从而进一步提升了注意力机制的流行度。注意力机制最初是作为对递归神经网络的扩展[[14](#bib.bib14)]引入的。然而，[[13](#bib.bib13)]中提出的Transformer模型在注意力研究中标志着重大进展，因为它展示了注意力机制足以构建**最先进**的模型。这意味着诸如递归神经网络特别难以并行化等缺点可以被绕过。与最初引入注意力机制[[3](#bib.bib3)]的情况一样，Transformer模型最初是为机器翻译创建的，但很快被广泛应用于其他任务，如图像处理[[15](#bib.bib15)]、视频处理[[16](#bib.bib16)]和推荐系统[[17](#bib.bib17)]。
- en: The purpose of this survey is to explain the general form of attention, and
    provide a comprehensive overview of attention techniques in deep learning. Other
    surveys have already been published on the subject of attention models. For example,
    in [[18](#bib.bib18)], a survey is presented on attention in computer vision,
    [[19](#bib.bib19)] provides an overview of attention in graph models, and [[20](#bib.bib20),
    [21](#bib.bib21), [22](#bib.bib22)] are all surveys on attention in natural language
    processing. This paper partly builds on the information presented in the previously
    mentioned surveys. Yet, we provide our own significant contributions. The main
    difference between this survey and the previously mentioned ones is that the other
    surveys generally focus on attention models within a certain domain. This survey,
    however, provides a cross-domain overview of attention techniques. We discuss
    the attention techniques in a general way, allowing them to be understood and
    applied in a variety of domains. Furthermore, we found the taxonomies presented
    in previous surveys to be lacking the depth and structure needed to properly distinguish
    the various attention mechanisms. Additionally, certain significant attention
    techniques have not yet been properly discussed in previous surveys, while other
    presented attention mechanisms seem to be lacking either technical details or
    intuitive explanations. Therefore, in this paper, we present important attention
    techniques by means of a single framework using a uniform notation, a combination
    of both technical and intuitive explanations for each presented attention technique,
    and a comprehensive taxonomy of attention mechanisms.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查的目的是解释注意力的一般形式，并提供深度学习中注意力技术的全面概述。其他关于注意力模型的调查已经被发布。例如，在[[18](#bib.bib18)]中，提供了计算机视觉中注意力的调查；[[19](#bib.bib19)]概述了图模型中的注意力；[[20](#bib.bib20),
    [21](#bib.bib21), [22](#bib.bib22)]均为自然语言处理中的注意力调查。本文在部分基础上构建于上述调查的信息上。然而，我们提供了自己的重要贡献。本文与上述调查的主要区别在于，其他调查通常集中于某一领域内的注意力模型。本文则提供了跨领域的注意力技术概述。我们以一般方式讨论注意力技术，使其能够在各种领域中理解和应用。此外，我们发现以前调查中提出的分类法缺乏必要的深度和结构来正确区分各种注意力机制。此外，一些重要的注意力技术在以前的调查中尚未得到适当讨论，而其他提出的注意力机制似乎缺乏技术细节或直观解释。因此，在本文中，我们通过统一的符号表示、对每种注意力技术的技术和直观解释的结合，以及全面的注意力机制分类法，展示了重要的注意力技术。
- en: The structure of this paper is as follows. Section [2](#S2 "2 General Attention
    Model ‣ A General Survey on Attention Mechanisms in Deep Learning") introduces
    a general attention model that provides the reader with a basic understanding
    of the properties of attention and how it can be applied. One of the main contributions
    of this paper is the taxonomy of attention techniques presented in Section [3](#S3
    "3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning").
    In this section, attention mechanisms are explained and categorized according
    to the presented taxonomy. Section [4](#S4 "4 Evaluation of Attention Models ‣
    A General Survey on Attention Mechanisms in Deep Learning") provides an overview
    of performance measures and methods for evaluating attention models. Furthermore,
    the taxonomy is used to evaluate the structure of various attention models. Lastly,
    in Section [5](#S5 "5 Conclusion ‣ A General Survey on Attention Mechanisms in
    Deep Learning"), we give our conclusions and suggestions for further research.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的结构如下。第[2](#S2 "2 General Attention Model ‣ A General Survey on Attention
    Mechanisms in Deep Learning")节介绍了一般注意力模型，为读者提供了对注意力属性及其应用的基本理解。本文的主要贡献之一是第[3](#S3
    "3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")节中提出的注意力技术分类法。在这一节中，注意力机制按照提出的分类法进行解释和分类。第[4](#S4
    "4 Evaluation of Attention Models ‣ A General Survey on Attention Mechanisms in
    Deep Learning")节提供了性能测量和评估注意力模型的方法的概述。此外，分类法被用来评估各种注意力模型的结构。最后，在第[5](#S5 "5 Conclusion
    ‣ A General Survey on Attention Mechanisms in Deep Learning")节中，我们给出了结论和对进一步研究的建议。
- en: '![Refer to caption](img/4c75bb9a9ddfd0f9b31db49fd921bdcf.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/4c75bb9a9ddfd0f9b31db49fd921bdcf.png)'
- en: 'Figure 1: An illustration of the general structure of the task model.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：任务模型的一般结构示意图。
- en: 2 General Attention Model
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 一般注意力模型
- en: This section presents a general form of attention with corresponding notation.
    The notation introduced here is based on the notation that was introduced in [[23](#bib.bib23)]
    and popularized in [[13](#bib.bib13)]. The framework presented in this section
    is used throughout the rest of this paper.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了具有相应符号的一般注意力形式。这里介绍的符号基于在 [[23](#bib.bib23)] 中引入的符号，并在 [[13](#bib.bib13)]
    中普及。本文接下来的部分将使用本节介绍的框架。
- en: 'To implement a general attention model, it is necessary to first describe the
    general characteristics of a model that can employ attention. First of all, we
    will refer to the complete model as the task model, of which the structure is
    presented in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ A General Survey on
    Attention Mechanisms in Deep Learning"). This model simply takes an input, carries
    out the specified task, and produces the desired output. For example, the task
    model can be a language model that takes as input a piece of text, and produces
    as output a summary of the contents, a classification of the sentiment, or the
    text translated word for word to another language. Alternatively, the task model
    can take an image, and produce a caption or segmentation for that image. The task
    model consists of four submodels: the feature model, the query model, the attention
    model, and the output model. In Subsection [2.1](#S2.SS1 "2.1 Attention Input
    ‣ 2 General Attention Model ‣ A General Survey on Attention Mechanisms in Deep
    Learning"), the feature model and query model are discussed, which are used to
    prepare the input for the attention calculation. In Subsection [2.2](#S2.SS2 "2.2
    Attention Output ‣ 2 General Attention Model ‣ A General Survey on Attention Mechanisms
    in Deep Learning"), the attention model and output model are discussed, which
    are concerned with producing the output.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现一般的注意力模型，首先需要描述一个可以使用注意力的模型的一般特征。首先，我们将完整模型称为任务模型，其结构如图 [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ A General Survey on Attention Mechanisms in Deep Learning")
    所示。该模型简单地接受输入，执行指定的任务，并产生期望的输出。例如，任务模型可以是一个语言模型，它接受一段文本作为输入，并生成内容的摘要、情感分类，或逐字翻译成另一种语言的文本。或者，任务模型可以接受一张图像，并为该图像生成标题或分割。任务模型包括四个子模型：特征模型、查询模型、注意力模型和输出模型。在子节
    [2.1](#S2.SS1 "2.1 Attention Input ‣ 2 General Attention Model ‣ A General Survey
    on Attention Mechanisms in Deep Learning") 中，讨论了用于准备注意力计算输入的特征模型和查询模型。在子节 [2.2](#S2.SS2
    "2.2 Attention Output ‣ 2 General Attention Model ‣ A General Survey on Attention
    Mechanisms in Deep Learning") 中，讨论了注意力模型和输出模型，这些模型负责生成输出。
- en: 2.1 Attention Input
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 注意力输入
- en: Suppose the task model takes as input the matrix $\bm{X}\in\mathbb{R}^{d_{x}\times
    n_{x}}$, where $d_{x}$ represents the size of the input vectors and $n_{x}$ represents
    the amount of input vectors. The columns in this matrix can represent the words
    in a sentence, the pixels in an image, the characteristics of an acoustic sequence,
    or any other collection of inputs. The feature model is then employed to extract
    the $n_{f}$ feature vectors $\bm{f}_{1},\dots,\bm{f}_{n_{f}}\in\mathbb{R}^{d_{f}}$
    from $\bm{X}$, where $d_{f}$ represents the size of the feature vectors. The feature
    model can be a recurrent neural network (RNN), a convolutional neural network
    (CNN), a simple embedding layer, a linear transformation of the original data,
    or no transformation at all. Essentially, the feature model consists of all the
    steps that transform the original input $\bm{X}$ into the feature vectors $\bm{f}_{1},\dots,\bm{f}_{n_{f}}$
    that the attention model will attend to.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 假设任务模型的输入是矩阵 $\bm{X}\in\mathbb{R}^{d_{x}\times n_{x}}$，其中 $d_{x}$ 代表输入向量的大小，$n_{x}$
    代表输入向量的数量。这个矩阵中的列可以代表句子中的单词、图像中的像素、声学序列的特征，或任何其他的输入集合。接着，特征模型被用来从 $\bm{X}$ 中提取
    $n_{f}$ 个特征向量 $\bm{f}_{1},\dots,\bm{f}_{n_{f}}\in\mathbb{R}^{d_{f}}$，其中 $d_{f}$
    代表特征向量的大小。特征模型可以是递归神经网络（RNN）、卷积神经网络（CNN）、简单的嵌入层、对原始数据的线性变换，或根本没有任何变换。基本上，特征模型包括所有将原始输入
    $\bm{X}$ 转换为注意力模型将关注的特征向量 $\bm{f}_{1},\dots,\bm{f}_{n_{f}}$ 的步骤。
- en: To determine which vectors to attend to, the attention model requires the query
    $\bm{q}\in\mathbb{R}^{d_{q}}$, where $d_{q}$ indicates the size of the query vector.
    This query is extracted by the query model, and is generally designed based on
    the type of output that is desired of the model. A query tells the attention model
    which feature vectors to attend to. It can be interpreted literally as a query,
    or a question. For example, for the task of image captioning, suppose that one
    uses a decoder RNN model to produce the output caption based on feature vectors
    obtained from the image by a CNN. At each prediction step, the hidden state of
    the RNN model can be used as a query to attend to the CNN feature vectors. In
    each step, the query is a question in the sense that it asks for the necessary
    information from the feature vectors based on the current prediction context.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定要关注哪些向量，注意力模型需要查询 $\bm{q}\in\mathbb{R}^{d_{q}}$，其中 $d_{q}$ 表示查询向量的大小。该查询由查询模型提取，并通常根据模型所期望的输出类型进行设计。查询告诉注意力模型要关注哪些特征向量。它可以被字面理解为查询或问题。例如，对于图像描述任务，假设使用解码器
    RNN 模型根据 CNN 从图像中获得的特征向量生成输出描述。在每个预测步骤中，RNN 模型的隐藏状态可以用作查询，以关注 CNN 特征向量。在每一步中，查询是一个问题，因为它根据当前的预测上下文从特征向量中请求必要的信息。
- en: '![Refer to caption](img/8a03d8da158f8a83ae723033b66f62f7.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8a03d8da158f8a83ae723033b66f62f7.png)'
- en: 'Figure 2: The inner mechanisms of the general attention module.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：通用注意力模块的内部机制。
- en: 2.2 Attention Output
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 注意力输出
- en: 'The feature vectors and query are used as input for the attention model. This
    model consists of a single, or a collection of general attention modules. An overview
    of a general attention module is presented in Fig. [2](#S2.F2 "Figure 2 ‣ 2.1
    Attention Input ‣ 2 General Attention Model ‣ A General Survey on Attention Mechanisms
    in Deep Learning"). The input of the general attention module is the query $\bm{q}\in\mathbb{R}^{d_{q}}$,
    and the matrix of feature vectors $\bm{F}=[\bm{f}_{1},\dots,\bm{f}_{n_{f}}]\in\mathbb{R}^{d_{f}\times
    n_{f}}$. Two separate matrices are extracted from the matrix $\bm{F}$: the keys
    matrix $\bm{K}=[\bm{k}_{1},\dots,\bm{k}_{n_{f}}]\in\mathbb{R}^{d_{k}\times n_{f}}$,
    and the values matrix $\bm{V}=[\bm{v}_{1},\dots,\bm{v}_{n_{f}}]\in\mathbb{R}^{d_{v}\times
    n_{f}}$, where $d_{k}$ and $d_{v}$ indicate, respectively, the dimensions of the
    key vectors (columns of $\bm{K}$) and value vectors (columns of $\bm{V}$). The
    general way of obtaining these matrices is through a linear transformation of
    $\bm{F}$ using the weight matrices $\bm{W}_{K}\in\mathbb{R}^{d_{k}\times d_{f}}$
    and $\bm{W}_{V}\in\mathbb{R}^{d_{v}\times d_{f}}$, for $\bm{K}$ and $\bm{V}$,
    respectively. The calculations of $\bm{K}$ and $\bm{V}$ are presented in ([1](#S2.E1
    "In 2.2 Attention Output ‣ 2 General Attention Model ‣ A General Survey on Attention
    Mechanisms in Deep Learning")). Both weight matrices can be learned during training
    or predefined by the researcher. For example, one can choose to define both $\bm{W}_{K}$
    and $\bm{W}_{V}$ as equal to the identity matrix to retain the original feature
    vectors. Other ways of defining the keys and the values are also possible, such
    as using completely separate inputs for the keys and values. The only constraint
    to be obeyed is that the number of columns in $\bm{K}$ and $\bm{V}$ remains the
    same.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 特征向量和查询用作注意力模型的输入。该模型由一个或多个通用注意力模块组成。图 [2](#S2.F2 "图2 ‣ 2.1 注意力输入 ‣ 2 通用注意力模型
    ‣ 深度学习中注意力机制的一般调查") 展示了通用注意力模块的概述。通用注意力模块的输入是查询 $\bm{q}\in\mathbb{R}^{d_{q}}$
    和特征向量矩阵 $\bm{F}=[\bm{f}_{1},\dots,\bm{f}_{n_{f}}]\in\mathbb{R}^{d_{f}\times n_{f}}$。从矩阵
    $\bm{F}$ 中提取两个单独的矩阵：键矩阵 $\bm{K}=[\bm{k}_{1},\dots,\bm{k}_{n_{f}}]\in\mathbb{R}^{d_{k}\times
    n_{f}}$ 和值矩阵 $\bm{V}=[\bm{v}_{1},\dots,\bm{v}_{n_{f}}]\in\mathbb{R}^{d_{v}\times
    n_{f}}$，其中 $d_{k}$ 和 $d_{v}$ 分别表示键向量（$\bm{K}$ 的列）和值向量（$\bm{V}$ 的列）的维度。获得这些矩阵的通用方法是通过对
    $\bm{F}$ 进行线性变换，使用权重矩阵 $\bm{W}_{K}\in\mathbb{R}^{d_{k}\times d_{f}}$ 和 $\bm{W}_{V}\in\mathbb{R}^{d_{v}\times
    d_{f}}$，分别用于 $\bm{K}$ 和 $\bm{V}$。$\bm{K}$ 和 $\bm{V}$ 的计算在 ([1](#S2.E1 "在 2.2 注意力输出
    ‣ 2 通用注意力模型 ‣ 深度学习中注意力机制的一般调查")) 中给出。两个权重矩阵可以在训练过程中学习或由研究人员预定义。例如，可以选择将 $\bm{W}_{K}$
    和 $\bm{W}_{V}$ 定义为等于单位矩阵，以保留原始特征向量。定义键和值的其他方法也是可能的，例如为键和值使用完全独立的输入。唯一需要遵守的约束是
    $\bm{K}$ 和 $\bm{V}$ 的列数保持一致。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{K}}{\scriptscriptstyle d_{k}\times
    n_{f}}=\stackunder{\bm{W}_{K}}{\scriptscriptstyle d_{k}\times d_{f}}\times\stackunder{\bm{F}}{\scriptscriptstyle
    d_{f}\times n_{f}},\hskip 20.0pt\stackunder{\bm{V}}{\scriptscriptstyle d_{v}\times
    n_{f}}=\stackunder{\bm{W}_{V}}{\scriptscriptstyle d_{v}\times d_{f}}\times\stackunder{\bm{F}}{\scriptscriptstyle
    d_{f}\times n_{f}}.$ |  | (1) |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{K}}{\scriptscriptstyle d_{k}\times
    n_{f}}=\stackunder{\bm{W}_{K}}{\scriptscriptstyle d_{k}\times d_{f}}\times\stackunder{\bm{F}}{\scriptscriptstyle
    d_{f}\times n_{f}},\hskip 20.0pt\stackunder{\bm{V}}{\scriptscriptstyle d_{v}\times
    n_{f}}=\stackunder{\bm{W}_{V}}{\scriptscriptstyle d_{v}\times d_{f}}\times\stackunder{\bm{F}}{\scriptscriptstyle
    d_{f}\times n_{f}}.$ |  | (1) |'
- en: The goal of the attention module is to produce a weighted average of the value
    vectors in $\bm{V}$. The weights used to produce this output are obtained via
    an attention scoring and alignment step. The query $\bm{q}$ and the keys matrix
    $\bm{K}$ are used to calculate the vector of attention scores $\bm{e}=[e_{1},\dots,e_{n_{f}}]\in\mathbb{R}^{n_{f}}$.
    This is done via the score function $\text{score}()$, as illustrated in ([2](#S2.E2
    "In 2.2 Attention Output ‣ 2 General Attention Model ‣ A General Survey on Attention
    Mechanisms in Deep Learning")).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力模块的目标是生成 $\bm{V}$ 中值向量的加权平均。用于生成此输出的权重通过注意力评分和对齐步骤获得。查询 $\bm{q}$ 和键矩阵 $\bm{K}$
    用于计算注意力评分向量 $\bm{e}=[e_{1},\dots,e_{n_{f}}]\in\mathbb{R}^{n_{f}}$。这通过评分函数 $\text{score}()$
    完成，如 ([2](#S2.E2 "在 2.2 注意力输出 ‣ 2 一般注意力模型 ‣ 深度学习中的注意力机制概述")) 中所示。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{e_{l}}{\scriptscriptstyle 1\times 1}=\text{score}(\stackunder{\bm{q}}{\scriptscriptstyle
    d_{q}\times 1},\stackunder{\bm{k}_{l}}{\scriptscriptstyle d_{k}\times 1}).$ |  |
    (2) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{e_{l}}{\scriptscriptstyle 1\times 1}=\text{score}(\stackunder{\bm{q}}{\scriptscriptstyle
    d_{q}\times 1},\stackunder{\bm{k}_{l}}{\scriptscriptstyle d_{k}\times 1}).$ |  |
    (2) |'
- en: As discussed before, the query symbolizes a request for information. The attention
    score $e_{l}$ represents how important the information contained in the key vector
    $\bm{k}_{l}$ is according to the query. If the dimensions of the query and key
    vectors are the same, an example of a score function would be to take the dot-product
    of the vectors. The different types of score functions are further discussed in
    Section [3.2.1](#S3.SS2.SSS1 "3.2.1 Attention Scoring ‣ 3.2 General Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning").
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，查询表示对信息的请求。注意力评分 $e_{l}$ 表示根据查询，键向量 $\bm{k}_{l}$ 中包含的信息的重要性。如果查询和键向量的维度相同，评分函数的一个例子是取向量的点积。不同类型的评分函数将在
    [3.2.1](#S3.SS2.SSS1 "3.2.1 注意力评分 ‣ 3.2 一般注意力机制 ‣ 3 注意力分类 ‣ 深度学习中的注意力机制概述") 节中进一步讨论。
- en: Next, the attention scores are processed further through an alignment layer.
    The attention scores can generally have a wide range outside of $[0,1]$. However,
    since the goal is to produce a weighted average, the scores are redistributed
    via an alignment function $\text{align}()$ as defined in ([3](#S2.E3 "In 2.2 Attention
    Output ‣ 2 General Attention Model ‣ A General Survey on Attention Mechanisms
    in Deep Learning")).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，注意力评分通过对齐层进一步处理。注意力评分通常可能在 $[0,1]$ 之外有广泛的范围。然而，由于目标是生成加权平均，评分通过对齐函数 $\text{align}()$
    重新分配，如 ([3](#S2.E3 "在 2.2 注意力输出 ‣ 2 一般注意力模型 ‣ 深度学习中的注意力机制概述")) 中定义。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{a_{l}}{\scriptscriptstyle 1\times 1}=\text{align}(\stackunder{e_{l}}{\scriptscriptstyle
    1\times 1};\stackunder{\bm{e}}{\scriptscriptstyle n_{f}\times 1}),$ |  | (3) |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{a_{l}}{\scriptscriptstyle 1\times 1}=\text{align}(\stackunder{e_{l}}{\scriptscriptstyle
    1\times 1};\stackunder{\bm{e}}{\scriptscriptstyle n_{f}\times 1}),$ |  | (3) |'
- en: where $a_{l}\in\mathbb{R}^{1}$ is the attention weight corresponding to the
    $l$th value vector. One example of an alignment function would be to use a softmax
    function, but the various other alignment types are discussed in Section [3.2.2](#S3.SS2.SSS2
    "3.2.2 Attention Alignment ‣ 3.2 General Attention Mechanisms ‣ 3 Attention Taxonomy
    ‣ A General Survey on Attention Mechanisms in Deep Learning"). The attention weights
    provide a rather intuitive interpretation for the attention module. Each weight
    is a direct indication of how important each feature vector is relative to the
    others for this particular problem. This can provide us with a more in-depth understanding
    of the model behaviour, and the relations between inputs and outputs. The vector
    of attention weights $\bm{a}=[a_{1},\dots,a_{n_{f}}]\in\mathbb{R}^{n_{f}}$ is
    used to produce the context vector $\bm{c}\in\mathbb{R}^{d_{v}}$ by calculating
    a weighted average of the columns of the values matrix $\bm{V}$, as shown in ([4](#S2.E4
    "In 2.2 Attention Output ‣ 2 General Attention Model ‣ A General Survey on Attention
    Mechanisms in Deep Learning")).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $a_{l}\in\mathbb{R}^{1}$ 是对应于第 $l$ 个值向量的注意力权重。一个对齐函数的例子是使用 softmax 函数，但各种其他对齐类型在[3.2.2](#S3.SS2.SSS2
    "3.2.2 注意力对齐 ‣ 3.2 一般注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的综合调查")中讨论。注意力权重为注意力模块提供了相当直观的解释。每个权重直接表示了每个特征向量对于这个特定问题相对于其他特征向量的重要性。这可以让我们更深入地理解模型的行为，以及输入和输出之间的关系。注意力权重向量
    $\bm{a}=[a_{1},\dots,a_{n_{f}}]\in\mathbb{R}^{n_{f}}$ 用于通过计算值矩阵 $\bm{V}$ 列的加权平均来生成上下文向量
    $\bm{c}\in\mathbb{R}^{d_{v}}$，如 ([4](#S2.E4 "在 2.2 注意力输出 ‣ 2 一般注意力模型 ‣ 深度学习中注意力机制的综合调查"))
    所示。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{c}}{\scriptscriptstyle d_{v}\times
    1}=\sum^{n_{f}}_{l=1}\stackunder{a_{l}}{\scriptscriptstyle 1\times 1}\times\stackunder{\bm{v}_{l}}{\scriptscriptstyle
    d_{v}\times 1}.$ |  | (4) |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{c}}{\scriptscriptstyle d_{v}\times
    1}=\sum^{n_{f}}_{l=1}\stackunder{a_{l}}{\scriptscriptstyle 1\times 1}\times\stackunder{\bm{v}_{l}}{\scriptscriptstyle
    d_{v}\times 1}.$ |  | (4) |'
- en: As illustrated in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ A General Survey
    on Attention Mechanisms in Deep Learning"), the context vector is then used in
    the output model to create the output $\hat{\bm{y}}$. This output model translates
    the context vector into an output prediction. For example, it could be a simple
    softmax layer that takes as input the context vector $\bm{c}$, as shown in ([5](#S2.E5
    "In 2.2 Attention Output ‣ 2 General Attention Model ‣ A General Survey on Attention
    Mechanisms in Deep Learning")).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[1](#S1.F1 "图 1 ‣ 1 介绍 ‣ 深度学习中注意力机制的综合调查")所示，上下文向量随后在输出模型中用于创建输出 $\hat{\bm{y}}$。该输出模型将上下文向量转换为输出预测。例如，它可能是一个简单的
    softmax 层，该层以上下文向量 $\bm{c}$ 为输入，如 ([5](#S2.E5 "在 2.2 注意力输出 ‣ 2 一般注意力模型 ‣ 深度学习中注意力机制的综合调查"))
    所示。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\hat{\bm{y}}}{\scriptscriptstyle d_{y}\times
    1}=\text{softmax}(\stackunder{\bm{W}_{c}}{\scriptscriptstyle d_{y}\times d_{v}}\times\stackunder{\bm{c}}{\scriptscriptstyle
    d_{v}\times 1}+\stackunder{\bm{b}_{c}}{\scriptscriptstyle d_{y}\times 1}),$ |  |
    (5) |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\hat{\bm{y}}}{\scriptscriptstyle d_{y}\times
    1}=\text{softmax}(\stackunder{\bm{W}_{c}}{\scriptscriptstyle d_{y}\times d_{v}}\times\stackunder{\bm{c}}{\scriptscriptstyle
    d_{v}\times 1}+\stackunder{\bm{b}_{c}}{\scriptscriptstyle d_{y}\times 1}),$ |  |
    (5) |'
- en: where $d_{y}$ is the number of output choices or classes, and $\bm{W}_{c}\in\mathbb{R}^{d_{y}\times
    d_{v}}$ and $\bm{b}_{c}\in\mathbb{R}^{d_{y}}$ are trainable weights.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $d_{y}$ 是输出选择或类别的数量，$\bm{W}_{c}\in\mathbb{R}^{d_{y}\times d_{v}}$ 和 $\bm{b}_{c}\in\mathbb{R}^{d_{y}}$
    是可训练的权重。
- en: 2.3 Attention Applications
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 注意力应用
- en: Attention is a rather general mechanism that can be used in a wide variety of
    problem domains. Consider the task of machine translation using an RNN model.
    Also, consider the problem of image classification using a basic CNN model. While
    an RNN produces a sequence of hidden state vectors, a CNN creates feature maps,
    where each region in the image is represented by a feature vector. The RNN hidden
    states are organized sequentially, while the CNN feature maps are organized spatially.
    Yet, attention can still be applied in both situations, since the attention mechanism
    does not inherently depend on the organization of the feature vectors. This characteristic
    makes attention easy to implement in a wide variety of models in different domains.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制是一种相当通用的机制，可以在各种问题领域中使用。考虑使用RNN模型的机器翻译任务。此外，还要考虑使用基本CNN模型的图像分类问题。虽然RNN生成一系列隐藏状态向量，而CNN创建特征图，其中图像中的每个区域由一个特征向量表示。RNN隐藏状态是按顺序组织的，而CNN特征图是按空间组织的。然而，注意力机制仍然可以在这两种情况下应用，因为注意力机制本质上不依赖于特征向量的组织。这一特性使得在不同领域的各种模型中实现注意力机制变得容易。
- en: Another domain where attention can be applied is audio processing [[24](#bib.bib24),
    [25](#bib.bib25)]. Acoustic sequences can be represented by a sequence of feature
    vectors that relate to certain time periods of the audio sample. These vectors
    could simply be the raw input audio, or they can be extracted via, for example,
    an RNN or CNN. Video processing is another domain where attention can be applied
    intuitively [[26](#bib.bib26), [27](#bib.bib27)]. Video data consists of sequences
    of images, so attention can be applied to the individual images, as well as the
    entire sequence. Recommender systems often incorporate a user’s interaction history
    to produce recommendations. Feature vectors can be extracted based on, for example,
    the id’s or other characteristics of the products the user interacted with, and
    attention can be applied to them [[28](#bib.bib28)]. Attention can generally also
    be applied to many problems that use a time series as input, be it medical [[29](#bib.bib29)],
    financial [[30](#bib.bib30)], or anything else, as long as feature vectors can
    be extracted.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制可以应用于另一个领域，即音频处理 [[24](#bib.bib24), [25](#bib.bib25)]。声学序列可以通过一系列特征向量表示，这些向量与音频样本的特定时间段相关。这些向量可以是原始输入音频，也可以通过例如RNN或CNN进行提取。视频处理是另一个可以直观应用注意力机制的领域
    [[26](#bib.bib26), [27](#bib.bib27)]。视频数据由图像序列组成，因此注意力可以应用于单个图像以及整个序列。推荐系统通常结合用户的互动历史来生成推荐。可以根据例如用户互动的产品的id或其他特征提取特征向量，并对其应用注意力机制
    [[28](#bib.bib28)]。一般来说，注意力机制也可以应用于许多使用时间序列作为输入的问题，无论是医学 [[29](#bib.bib29)]、金融
    [[30](#bib.bib30)] 还是其他领域，只要能够提取特征向量。
- en: The fact that attention does not rely on the organization of the feature vectors
    allows it to be applied to various problems that each use data with different
    structures, as illustrated by the previous domain examples. Yet, this can be taken
    even further by applying attention to data where there is irregular structure.
    For example, protein structures, city traffic flows, and communication networks
    cannot always be represented using neatly structured organizations, such as sequences,
    like time series, or grids, like images. In such cases, the different aspects
    of the data are often represented as nodes in a graph. These nodes can be represented
    by feature vectors, meaning that attention can be applied in domains that use
    graph-structured data as well [[31](#bib.bib31), [19](#bib.bib19)].
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制不依赖于特征向量的组织结构，使其能够应用于各种具有不同数据结构的问题，这从前面的领域示例中可以看出。然而，这可以进一步拓展到对数据的不规则结构应用注意力机制。例如，蛋白质结构、城市交通流和通信网络不能总是使用整齐的结构组织来表示，例如时间序列这样的序列，或图像这样的网格。在这种情况下，数据的不同方面通常表示为图中的节点。这些节点可以用特征向量表示，这意味着注意力机制也可以应用于使用图结构数据的领域
    [[31](#bib.bib31), [19](#bib.bib19)]。
- en: In general, attention can be applied to any problem for which a set of feature
    vectors can be defined or extracted. As such, the general attention model presented
    in Fig. [2](#S2.F2 "Figure 2 ‣ 2.1 Attention Input ‣ 2 General Attention Model
    ‣ A General Survey on Attention Mechanisms in Deep Learning") is applicable to
    a wide range of domains. The problem, however, is that there is a large variety
    of different applications and extensions of the general attention module. As such,
    in Section [3](#S3 "3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning"), a comprehensive overview is provided of a collection of different
    attention mechanisms.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，注意力可以应用于任何可以定义或提取特征向量集的问题。因此，图 [2](#S2.F2 "Figure 2 ‣ 2.1 Attention Input
    ‣ 2 General Attention Model ‣ A General Survey on Attention Mechanisms in Deep
    Learning") 中展示的一般注意力模型适用于广泛的领域。然而，问题在于一般注意力模块有多种不同的应用和扩展。因此，在第 [3](#S3 "3 Attention
    Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning") 节中，提供了对各种不同注意力机制的全面概述。
- en: '![Refer to caption](img/9f84979effaab312f3bab80bbfdd9a19.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/9f84979effaab312f3bab80bbfdd9a19.png)'
- en: 'Figure 3: A taxonomy of attention mechanisms.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：注意力机制的分类法。
- en: 3 Attention Taxonomy
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 注意力分类法
- en: There are many different types of attention mechanisms and extensions, and a
    model can use different combinations of these attention techniques. As such, we
    propose a taxonomy that can be used to classify different types of attention mechanisms.
    Fig. [3](#S2.F3 "Figure 3 ‣ 2.3 Attention Applications ‣ 2 General Attention Model
    ‣ A General Survey on Attention Mechanisms in Deep Learning") provides a visual
    overview of the different categories and subcategories that the attention mechanisms
    can be organized in. The three major categories are based on whether an attention
    technique is designed to handle specific types of feature vectors (feature-related),
    specific types of model queries (query-related), or whether it is simply a general
    mechanism that is related to neither the feature model, nor the query model (general).
    Further explanations of these categories and their subcategories are provided
    in the following subsections. Each mechanism discussed in this section is either
    a modification to the existing inner mechanisms of the general attention module
    presented in Section [2](#S2 "2 General Attention Model ‣ A General Survey on
    Attention Mechanisms in Deep Learning"), or an extension of it.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多不同类型的注意力机制和扩展，一个模型可以使用这些注意力技术的不同组合。因此，我们提出了一种分类法，可以用于分类不同类型的注意力机制。图 [3](#S2.F3
    "Figure 3 ‣ 2.3 Attention Applications ‣ 2 General Attention Model ‣ A General
    Survey on Attention Mechanisms in Deep Learning") 提供了注意力机制可以组织成的不同类别和子类别的视觉概览。这三大类是基于注意力技术是否设计来处理特定类型的特征向量（特征相关）、特定类型的模型查询（查询相关），或者是否仅仅是一个与特征模型或查询模型都无关的一般机制（一般）。对这些类别及其子类别的进一步解释将在以下小节中提供。本节讨论的每种机制要么是对第
    [2](#S2 "2 General Attention Model ‣ A General Survey on Attention Mechanisms
    in Deep Learning") 节中展示的一般注意力模块的现有内部机制的修改，要么是其扩展。
- en: The presented taxonomy can also be used to analyze the architecture of attention
    models. Namely, the major categories and their subcategories can be interpreted
    as orthogonal dimensions of an attention model. An attention model can consist
    of a combination of techniques taken from any or all categories. Some characteristics,
    such as the scoring and alignment functions, are generally required for any attention
    model. Other mechanisms, such as multi-head attention or co-attention are not
    necessary in every situation. Lastly, in Table [I](#S3.T1 "TABLE I ‣ 3 Attention
    Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning"), an overview
    of used notation with corresponding descriptions is provided.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的分类法还可以用于分析注意力模型的架构。即，主要类别及其子类别可以被解释为注意力模型的正交维度。一个注意力模型可以由来自任何或所有类别的技术组合而成。一些特性，如评分和对齐函数，通常是任何注意力模型所必需的。其他机制，如多头注意力或共同注意力，在每种情况下并不是必需的。最后，在表
    [I](#S3.T1 "TABLE I ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning") 中，提供了使用的符号及其对应描述的概述。
- en: 'TABLE I: Notation.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：符号。
- en: '| Symbol | Description |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 符号 | 描述 |'
- en: '| --- | --- |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| $\bm{F}$ | Matrix of size $d_{f}\times n_{f}$ containing the feature vectors
    $\bm{f}_{1},\dots,\bm{f}_{n_{f}}\in\mathbb{R}^{d_{f}}$ as columns. These feature
    vectors are extracted by the feature model. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| $\bm{F}$ | 大小为 $d_{f}\times n_{f}$ 的矩阵，其中包含特征向量 $\bm{f}_{1},\dots,\bm{f}_{n_{f}}\in\mathbb{R}^{d_{f}}$
    作为列。这些特征向量由特征模型提取。 |'
- en: '| $\bm{K}$ | Matrix of size $d_{k}\times n_{f}$ containing the key vectors
    $\bm{k}_{1},\dots,\bm{k}_{n_{f}}\in\mathbb{R}^{d_{k}}$ as columns. These vectors
    are used to calculate the attention scores. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| $\bm{K}$ | 尺寸为 $d_{k}\times n_{f}$ 的矩阵，包含关键向量 $\bm{k}_{1},\dots,\bm{k}_{n_{f}}\in\mathbb{R}^{d_{k}}$
    作为列。这些向量用于计算注意力分数。 |'
- en: '| $\bm{V}$ | Matrix of size $d_{v}\times n_{f}$ containing the value vectors
    $\bm{v}_{1},\dots,\bm{v}_{n_{f}}\in\mathbb{R}^{d_{v}}$ as columns. These vectors
    are used to calculate the context vector. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| $\bm{V}$ | 尺寸为 $d_{v}\times n_{f}$ 的矩阵，包含值向量 $\bm{v}_{1},\dots,\bm{v}_{n_{f}}\in\mathbb{R}^{d_{v}}$
    作为列。这些向量用于计算上下文向量。 |'
- en: '| $\bm{W}_{K}$ | Weights matrix of size $d_{k}\times d_{f}$ used to create
    the $\bm{K}$ matrix from the $\bm{F}$ matrix. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| $\bm{W}_{K}$ | 尺寸为 $d_{k}\times d_{f}$ 的权重矩阵，用于从 $\bm{F}$ 矩阵中创建 $\bm{K}$
    矩阵。 |'
- en: '| $\bm{W}_{V}$ | Weights matrix of size $d_{v}\times d_{f}$ used to create
    the $\bm{V}$ matrix from the $\bm{F}$ matrix. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| $\bm{W}_{V}$ | 尺寸为 $d_{v}\times d_{f}$ 的权重矩阵，用于从 $\bm{F}$ 矩阵中创建 $\bm{V}$
    矩阵。 |'
- en: '| $\bm{q}$ | Query vector of size $d_{q}$. This vector essentially represents
    a question, and is used to calculate the attention scores. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| $\bm{q}$ | 尺寸为 $d_{q}$ 的查询向量。该向量本质上代表一个问题，并用于计算注意力分数。 |'
- en: '| $\bm{c}$ | Context vector of size $d_{v}$. This vector is the output of the
    attention model. |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| $\bm{c}$ | 尺寸为 $d_{v}$ 的上下文向量。该向量是注意力模型的输出。 |'
- en: '| $\bm{e}$ | Score vector of size $d_{n_{f}}$ containing the attention scores
    $e_{1},\dots,e_{n_{f}}\in\mathbb{R}^{1}$. These are used to calculate the attention
    weights. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| $\bm{e}$ | 尺寸为 $d_{n_{f}}$ 的分数向量，包含注意力分数 $e_{1},\dots,e_{n_{f}}\in\mathbb{R}^{1}$。这些用于计算注意力权重。
    |'
- en: '| $\bm{a}$ | Attention weights vector of size $d_{n_{f}}$ containing the attention
    weights $a_{1},\dots,a_{n_{f}}\in\mathbb{R}^{1}$. These are the weights used in
    the calculation of the context vector. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| $\bm{a}$ | 尺寸为 $d_{n_{f}}$ 的注意力权重向量，包含注意力权重 $a_{1},\dots,a_{n_{f}}\in\mathbb{R}^{1}$。这些是计算上下文向量时使用的权重。
    |'
- en: 3.1 Feature-Related Attention Mechanisms
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 特征相关的注意力机制
- en: 'Based on a particular set of input data, a feature model extracts feature vectors
    so that the attention model can attend to these various vectors. These features
    may have specific structures that require special attention mechanisms to handle
    them. These mechanisms can be categorized to deal with one of the following feature
    characteristics: the multiplicity of features, the levels of features, or the
    representations of features.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 基于特定的输入数据集，特征模型提取特征向量，以便注意力模型可以关注这些不同的向量。这些特征可能具有需要特殊注意力机制处理的特定结构。这些机制可以分类处理以下特征特性之一：特征的多样性、特征的层级或特征的表示。
    |
- en: 3.1.1 Multiplicity of Features
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 特征的多样性
- en: For most tasks, a model only processes a single input, such as an image, a sentence,
    or an acoustic sequence. We refer to such a mechanism as singular features attention.
    Other models are designed to use attention based on multiple inputs to allow one
    to introduce more information into the model that can be exploited in various
    ways. However, this does imply the presence of multiple feature matrices that
    require special attention mechanisms to be fully used. For example, [[32](#bib.bib32)]
    introduces a concept named co-attention to allow the proposed visual question
    answering (VQA) model to jointly attend to both an image and a question.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数任务，模型只处理单一输入，如图像、句子或声学序列。我们将这种机制称为单一特征注意力。其他模型则设计为基于多个输入来使用注意力，以便将更多信息引入模型中，且这些信息可以以多种方式加以利用。然而，这确实意味着存在多个特征矩阵，需要特殊的注意力机制才能充分使用。例如，[[32](#bib.bib32)]
    引入了一个名为共同注意力的概念，以允许所提出的视觉问答（VQA）模型同时关注图像和问题。 |
- en: 'Co-attention mechanisms can generally be split up into two groups [[33](#bib.bib33)]:
    coarse-grained co-attention and fine-grained co-attention. The difference between
    the two groups is the way attention scores are calculated based on the two feature
    matrices. Coarse-grained attention mechanisms use a compact representation of
    one feature matrix as a query when attending to the other feature vectors. Fine-grained
    co-attention, on the other hand, uses all feature vectors of one input as queries.
    As such, no information is lost, which is why these mechanisms are called fine-grained.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 共注意力机制通常可以分为两组 [[33](#bib.bib33)]：粗粒度共注意力和细粒度共注意力。这两组的区别在于根据两个特征矩阵计算注意力分数的方式。粗粒度注意力机制使用一个特征矩阵的紧凑表示作为查询来关注另一个特征向量。另一方面，细粒度共注意力使用一个输入的所有特征向量作为查询。因此，没有信息丢失，这就是这些机制被称为细粒度的原因。
- en: '![Refer to caption](img/38c2872c13042999921422dbcbd9ac06.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/38c2872c13042999921422dbcbd9ac06.png)'
- en: 'Figure 4: An illustration of alternating co-attention.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：交替共注意力的示意图。
- en: As an example of coarse-grained co-attention, [[32](#bib.bib32)] proposes an
    alternating co-attention mechanism that uses the context vector (which is a compact
    representation) from one attention module as the query for the other module, and
    vice versa. Alternating co-attention is presented in Fig. [4](#S3.F4 "Figure 4
    ‣ 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention Mechanisms ‣
    3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning").
    Given a set of two input matrices $\bm{X}^{(1)}$ and $\bm{X}^{(2)}$, features
    are extracted by a feature model to produce the feature matrices $\bm{F}^{(1)}\in\mathbb{R}^{d_{f}^{(1)}\times
    n_{f}^{(1)}}$ and $\bm{F}^{(2)}\in\mathbb{R}^{d_{f}^{(2)}\times n_{f}^{(2)}}$,
    where $d_{f}^{(1)}$ and $d_{f}^{(2)}$ represent, respectively, the dimension of
    the feature vectors extracted from the first and second inputs, while $n_{f}^{(1)}$
    and $n_{f}^{(2)}$ represent, respectively, the amount of feature vectors extracted
    from the first and second inputs. In [[32](#bib.bib32)], co-attention is used
    for VQA, so the two input matrices are the image data and the question data, for
    which the feature model for the image consists of a CNN model, and the feature
    model for the question consists of word embeddings, a convolutional layer, a pooling
    layer, and an LSTM model. Firstly, attention is calculated for the first set of
    features $\bm{F}^{(1)}$ without the use of a query (Attention Module[1] in Fig.
    [4](#S3.F4 "Figure 4 ‣ 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning")). In [[32](#bib.bib32)], an adjusted additive attention score
    function is used for this attention mechanism. The general form of the regular
    additive score function can be seen in ([6](#S3.E6 "In 3.1.1 Multiplicity of Features
    ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General
    Survey on Attention Mechanisms in Deep Learning")).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 作为粗粒度共注意力的一个例子，[[32](#bib.bib32)] 提出了一个交替共注意力机制，该机制使用来自一个注意力模块的上下文向量（即紧凑的表示）作为另一个模块的查询，反之亦然。交替共注意力机制在图
    [4](#S3.F4 "Figure 4 ‣ 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning") 中展示。给定一组两个输入矩阵 $\bm{X}^{(1)}$ 和 $\bm{X}^{(2)}$，特征通过特征模型提取，以生成特征矩阵
    $\bm{F}^{(1)}\in\mathbb{R}^{d_{f}^{(1)}\times n_{f}^{(1)}}$ 和 $\bm{F}^{(2)}\in\mathbb{R}^{d_{f}^{(2)}\times
    n_{f}^{(2)}}$，其中 $d_{f}^{(1)}$ 和 $d_{f}^{(2)}$ 分别表示从第一个和第二个输入中提取的特征向量的维度，而 $n_{f}^{(1)}$
    和 $n_{f}^{(2)}$ 分别表示从第一个和第二个输入中提取的特征向量的数量。在 [[32](#bib.bib32)] 中，共注意力用于视觉问答（VQA），因此两个输入矩阵是图像数据和问题数据，其中图像的特征模型由
    CNN 模型组成，问题的特征模型包括词嵌入、卷积层、池化层和 LSTM 模型。首先，计算第一组特征 $\bm{F}^{(1)}$ 的注意力，而不使用查询（图
    [4](#S3.F4 "Figure 4 ‣ 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning") 中的注意力模块[1]）。在 [[32](#bib.bib32)] 中，为该注意力机制使用了调整后的加性注意力分数函数。常规加性分数函数的一般形式可以参见
    ([6](#S3.E6 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning"))。
- en: '|  | $\setstackgap{L}{11pt}\text{score}(\stackunder{\bm{q}}{\scriptscriptstyle
    d_{q}\times 1},\stackunder{\bm{k}_{l}}{\scriptscriptstyle d_{k}\times 1})=\stackunder{\bm{w}^{T}}{\scriptscriptstyle
    1\times d_{w}}\times\text{act}(\stackunder{\bm{W}_{1}}{\scriptscriptstyle d_{w}\times
    d_{q}}\times\stackunder{\bm{q}}{\scriptscriptstyle d_{q}\times 1}+\stackunder{\bm{W}_{2}}{\scriptscriptstyle
    d_{w}\times d_{k}}\times\stackunder{\bm{k}_{l}}{\scriptscriptstyle d_{k}\times
    1}+\stackunder{\bm{b}}{\scriptscriptstyle d_{w}\times 1}),$ |  | (6) |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\text{score}(\stackunder{\bm{q}}{\scriptscriptstyle
    d_{q}\times 1},\stackunder{\bm{k}_{l}}{\scriptscriptstyle d_{k}\times 1})=\stackunder{\bm{w}^{T}}{\scriptscriptstyle
    1\times d_{w}}\times\text{act}(\stackunder{\bm{W}_{1}}{\scriptscriptstyle d_{w}\times
    d_{q}}\times\stackunder{\bm{q}}{\scriptscriptstyle d_{q}\times 1}+\stackunder{\bm{W}_{2}}{\scriptscriptstyle
    d_{w}\times d_{k}}\times\stackunder{\bm{k}_{l}}{\scriptscriptstyle d_{k}\times
    1}+\stackunder{\bm{b}}{\scriptscriptstyle d_{w}\times 1}),$ |  | (6) |'
- en: where $\text{act}()$ is a non-linear activation function, and $\bm{w}\in\mathbb{R}^{d_{w}}$,
    $\bm{W}_{1}\in\mathbb{R}^{d_{w}\times d_{q}}$, $\bm{W}_{2}\in\mathbb{R}^{d_{w}\times
    d_{k}}$, and $\bm{b}\in\mathbb{R}^{d_{w}}$ are trainable weights matrices, for
    which $d_{w}$ is a predefined dimension of the weight matrices. A variant of this
    score function adapted to be calculated without a query for the application at
    hand can be seen in ([7](#S3.E7 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning")).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\text{act}()$ 是一个非线性激活函数，$\bm{w}\in\mathbb{R}^{d_{w}}$、$\bm{W}_{1}\in\mathbb{R}^{d_{w}\times
    d_{q}}$、$\bm{W}_{2}\in\mathbb{R}^{d_{w}\times d_{k}}$ 和 $\bm{b}\in\mathbb{R}^{d_{w}}$
    是可训练的权重矩阵，其中 $d_{w}$ 是权重矩阵的预定义维度。可以在 ([7](#S3.E7 "在 3.1.1 特征的多样性 ‣ 3.1 特征相关注意力机制
    ‣ 3 注意力分类 ‣ 深度学习中注意力机制的总体调查")) 中看到这种得分函数的一个变体，它适应于在没有查询的情况下进行计算的实际应用。
- en: '|  | $\setstackgap{L}{11pt}\stackunder{e^{(0)}_{l}}{\scriptscriptstyle 1\times
    1}=\stackunder{\bm{w}^{(1)T}}{\scriptscriptstyle 1\times d_{w}}\times\text{act}(\stackunder{\bm{W}^{(1)}}{\scriptscriptstyle
    d_{w}\times d_{k}^{(1)}}\times\stackunder{\bm{k}_{l}^{(1)}}{\scriptscriptstyle
    d_{k}^{(1)}\times 1}+\stackunder{\bm{b}^{(1)}}{\scriptscriptstyle d_{w}\times
    1}),$ |  | (7) |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\stackunder{e^{(0)}_{l}}{\scriptscriptstyle 1\times
    1}=\stackunder{\bm{w}^{(1)T}}{\scriptscriptstyle 1\times d_{w}}\times\text{act}(\stackunder{\bm{W}^{(1)}}{\scriptscriptstyle
    d_{w}\times d_{k}^{(1)}}\times\stackunder{\bm{k}_{l}^{(1)}}{\scriptscriptstyle
    d_{k}^{(1)}\times 1}+\stackunder{\bm{b}^{(1)}}{\scriptscriptstyle d_{w}\times
    1}),$ |  | (7) |'
- en: where $\bm{w}^{(1)}\in\mathbb{R}^{d_{w}}$, $\bm{W}^{(1)}\in\mathbb{R}^{d_{w}\times
    d_{k}^{(1)}}$, and $\bm{b}^{(1)}\in\mathbb{R}^{d_{w}}$ are trainable weight matrices
    for Attention Module[1], $\bm{k}_{l}^{(1)}\in\mathbb{R}^{d_{k}^{(1)}}$ is the
    $l$th column of the keys matrix $\bm{K}^{(1)}$ that was obtained from $\bm{F}^{(1)}$
    via a linear transformation (see ([1](#S2.E1 "In 2.2 Attention Output ‣ 2 General
    Attention Model ‣ A General Survey on Attention Mechanisms in Deep Learning"))),
    for which $d_{w}$ is a prespecified dimension of the weight matrices and $d_{k}^{(1)}$
    is a prespecified dimension of the key vectors.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\bm{w}^{(1)}\in\mathbb{R}^{d_{w}}$、$\bm{W}^{(1)}\in\mathbb{R}^{d_{w}\times
    d_{k}^{(1)}}$ 和 $\bm{b}^{(1)}\in\mathbb{R}^{d_{w}}$ 是 Attention Module[1] 的可训练权重矩阵，$\bm{k}_{l}^{(1)}\in\mathbb{R}^{d_{k}^{(1)}}$
    是从 $\bm{F}^{(1)}$ 通过线性变换得到的键矩阵 $\bm{K}^{(1)}$ 的第 $l$ 列（见 ([1](#S2.E1 "在 2.2 注意力输出
    ‣ 2 一般注意力模型 ‣ 深度学习中注意力机制的总体调查"))），其中 $d_{w}$ 是权重矩阵的预指定维度，$d_{k}^{(1)}$ 是键向量的预指定维度。
- en: 'Perhaps one may wonder why the query is absent when calculating attention in
    this manner. Essentially, the query in this attention model is learned alongside
    the other trainable parameters. As such, the query can be interpreted as a general
    question: ”Which feature vectors contain the most important information?”. This
    is also known as a self-attentive mechanism, since attention is calculated based
    only on the feature vectors themselves. Self-attention is explained in more detail
    in Subsection [3.3.1](#S3.SS3.SSS1 "3.3.1 Type of Queries ‣ 3.3 Query-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning").'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 也许有人会想知道为什么在以这种方式计算注意力时查询是缺失的。从本质上讲，这种注意力模型中的查询与其他可训练参数一起学习。因此，查询可以被解释为一个一般性的问题：“哪些特征向量包含最重要的信息？”。这也被称为自注意力机制，因为注意力是仅基于特征向量本身计算的。自注意力机制在小节
    [3.3.1](#S3.SS3.SSS1 "3.3.1 查询类型 ‣ 3.3 查询相关注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的总体调查")
    中有更详细的解释。
- en: The scores are combined with an alignment function (see ([3](#S2.E3 "In 2.2
    Attention Output ‣ 2 General Attention Model ‣ A General Survey on Attention Mechanisms
    in Deep Learning"))), such as the softmax function, to create attention weights
    used to calculate the context vector $\bm{c}^{(0)}\in\mathbb{R}^{d_{v}^{(1)}}$
    (see ([4](#S2.E4 "In 2.2 Attention Output ‣ 2 General Attention Model ‣ A General
    Survey on Attention Mechanisms in Deep Learning"))). This context vector is not
    used as the output of the attention model, but rather as a query for calculating
    the context vector $\bm{c}^{(2)}\in\mathbb{R}^{d_{v}^{(2)}}$, based on the second
    feature matrix $\bm{F}^{(2)}$, where $d_{v}^{(2)}$ is the dimension of the value
    vectors obtained from $\bm{F}^{(2)}$ via a linear transformation (see ([1](#S2.E1
    "In 2.2 Attention Output ‣ 2 General Attention Model ‣ A General Survey on Attention
    Mechanisms in Deep Learning"))). For this module (Attention Module[2] in Fig.
    [4](#S3.F4 "Figure 4 ‣ 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning")), attention scores are calculated using another score function
    with $\bm{c}_{0}$ as query input, as presented in ([8](#S3.E8 "In 3.1.1 Multiplicity
    of Features ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention Taxonomy
    ‣ A General Survey on Attention Mechanisms in Deep Learning")). Any function can
    be used in this situation, but an additive function is used in [[32](#bib.bib32)].
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 分数与对齐函数结合（参见 ([3](#S2.E3 "在 2.2 注意力输出 ‣ 2 一般注意力模型 ‣ 深度学习中注意力机制的一般调查"))），例如 softmax
    函数，以创建用于计算上下文向量 $\bm{c}^{(0)}\in\mathbb{R}^{d_{v}^{(1)}}$ 的注意力权重（参见 ([4](#S2.E4
    "在 2.2 注意力输出 ‣ 2 一般注意力模型 ‣ 深度学习中注意力机制的一般调查"))）。这个上下文向量不是作为注意力模型的输出，而是作为计算上下文向量
    $\bm{c}^{(2)}\in\mathbb{R}^{d_{v}^{(2)}}$ 的查询，基于第二个特征矩阵 $\bm{F}^{(2)}$，其中 $d_{v}^{(2)}$
    是通过线性变换从 $\bm{F}^{(2)}$ 获得的值向量的维度（参见 ([1](#S2.E1 "在 2.2 注意力输出 ‣ 2 一般注意力模型 ‣ 深度学习中注意力机制的一般调查"))）。对于这个模块（图
    [4](#S3.F4 "图 4 ‣ 3.1.1 特征的多样性 ‣ 3.1 特征相关的注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的一般调查")
    中的注意力模块[2]），使用另一种分数函数来计算注意力分数，将 $\bm{c}_{0}$ 作为查询输入，如 ([8](#S3.E8 "在 3.1.1 特征的多样性
    ‣ 3.1 特征相关的注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的一般调查")) 中所示。在这种情况下可以使用任何函数，但在 [[32](#bib.bib32)]
    中使用了加法函数。
- en: '|  | $\setstackgap{L}{11pt}\stackunder{e_{l}^{(2)}}{\scriptscriptstyle 1\times
    1}=\text{score}(\stackunder{\bm{c}^{(0)}}{\scriptscriptstyle d_{v}^{(1)}\times
    1},\stackunder{\bm{k}_{l}^{(2)}}{\scriptscriptstyle d_{k}^{(2)}\times 1}).$ |  |
    (8) |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\stackunder{e_{l}^{(2)}}{\scriptscriptstyle 1\times
    1}=\text{score}(\stackunder{\bm{c}^{(0)}}{\scriptscriptstyle d_{v}^{(1)}\times
    1},\stackunder{\bm{k}_{l}^{(2)}}{\scriptscriptstyle d_{k}^{(2)}\times 1}).$ |  |
    (8) |'
- en: These attention scores are then used to calculate attention weights using, for
    example, a softmax function as alignment function, after which the context vector
    $\bm{c}^{(2)}$ can be derived as a weighted average of the second set of value
    vectors. Finally, the context vector $\bm{c}^{(2)}$ is used as a query for the
    first attention module, which will produce the context vector $\bm{c}^{(1)}$ for
    the first feature matrix $\bm{F}^{(1)}$. Attention scores are calculated according
    to ([9](#S3.E9 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning")). In [[32](#bib.bib32)], the same function and weight matrices
    as seen in ([7](#S3.E7 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning")) are used, but with an added query making it the same as the
    general additive score function (see ([6](#S3.E6 "In 3.1.1 Multiplicity of Features
    ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General
    Survey on Attention Mechanisms in Deep Learning"))). The rest of the attention
    calculation is similar as before.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用这些注意力分数来计算注意力权重，例如，使用 softmax 函数作为对齐函数，之后上下文向量 $\bm{c}^{(2)}$ 可以作为第二组值向量的加权平均得出。最后，上下文向量
    $\bm{c}^{(2)}$ 被用作第一个注意力模块的查询，这将产生第一个特征矩阵 $\bm{F}^{(1)}$ 的上下文向量 $\bm{c}^{(1)}$。注意力分数根据
    ([9](#S3.E9 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning")) 计算。在 [[32](#bib.bib32)] 中，使用了与 ([7](#S3.E7 "In 3.1.1 Multiplicity
    of Features ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention Taxonomy
    ‣ A General Survey on Attention Mechanisms in Deep Learning")) 中相同的函数和权重矩阵，但增加了一个查询，使其与一般的加法分数函数相同（参见
    ([6](#S3.E6 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning"))）。其余的注意力计算过程与之前类似。
- en: '|  | $\setstackgap{L}{11pt}\stackunder{e_{l}^{(1)}}{\scriptscriptstyle 1\times
    1}=\text{score}(\stackunder{\bm{c}^{(2)}}{\scriptscriptstyle d_{v}^{(2)}\times
    1},\stackunder{\bm{k}_{l}^{(1)}}{\scriptscriptstyle d_{k}^{(1)}\times 1}).$ |  |
    (9) |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\stackunder{e_{l}^{(1)}}{\scriptscriptstyle 1\times
    1}=\text{score}(\stackunder{\bm{c}^{(2)}}{\scriptscriptstyle d_{v}^{(2)}\times
    1},\stackunder{\bm{k}_{l}^{(1)}}{\scriptscriptstyle d_{k}^{(1)}\times 1}).$ |  |
    (9) |'
- en: The produced context vectors $\bm{c}^{(1)}$ and $\bm{c}^{(2)}$ are concatenated
    and used for prediction in the output model. Alternating co-attention inherently
    contains a form of sequentiality due to the fact that context vectors need to
    be calculated one after another. This may come with a computational disadvantage
    since it is not possible to parallelize. Instead of using a sequential mechanism
    like alternating co-attention, [[34](#bib.bib34)] proposes the interactive co-attention
    mechanism that can calculate attention on both feature matrices in parallel, as
    depicted in Fig. [5](#S3.F5 "Figure 5 ‣ 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning"). Instead of using the context vectors as queries, unweighted
    averages of the key vectors are used as queries. The calculation of the average
    keys are provided in ([10](#S3.E10 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning")), and the calculation of the attention scores are shown in
    ([11](#S3.E11 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning")). Any score function can be used in this case, but an additive
    score function is used in [[34](#bib.bib34)].
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的上下文向量 $\bm{c}^{(1)}$ 和 $\bm{c}^{(2)}$ 被串联在一起，用于输出模型的预测。交替共注意力固有地包含一种顺序性，因为上下文向量需要一个接一个地计算。这可能带来计算上的不利影响，因为无法并行化。与使用像交替共注意力这样的顺序机制不同，[[34](#bib.bib34)]
    提出了可以并行计算两个特征矩阵上的注意力的交互式共注意力机制，如图 [5](#S3.F5 "Figure 5 ‣ 3.1.1 Multiplicity of
    Features ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A
    General Survey on Attention Mechanisms in Deep Learning") 所示。与使用上下文向量作为查询不同，使用键向量的无权平均值作为查询。平均键的计算方法在
    ([10](#S3.E10 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning")) 中提供，注意力分数的计算方法在 ([11](#S3.E11 "In 3.1.1 Multiplicity of Features
    ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General
    Survey on Attention Mechanisms in Deep Learning")) 中展示。在这种情况下，可以使用任何分数函数，但 [[34](#bib.bib34)]
    使用了加法分数函数。
- en: '|  | $\setstackgap{L}{13pt}\stackunder{\bar{\bm{k}}^{(1)}}{\scriptscriptstyle
    d_{k}^{(1)}\times 1}=\frac{1}{n^{(1)}_{f}}\sum^{n^{(1)}_{f}}_{l=1}\stackunder{\bm{k}_{l}^{(1)}}{\scriptscriptstyle
    d_{k}^{(1)}\times 1},\hskip 20.0pt\stackunder{\bar{\bm{k}}^{(2)}}{\scriptscriptstyle
    d_{k}^{(2)}\times 1}=\frac{1}{n^{(2)}_{f}}\sum^{n^{(2)}_{f}}_{l=1}\stackunder{\bm{k}_{l}^{(2)}}{\scriptscriptstyle
    d_{k}^{(2)}\times 1};$ |  | (10) |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{13pt}\stackunder{\bar{\bm{k}}^{(1)}}{\scriptscriptstyle
    d_{k}^{(1)}\times 1}=\frac{1}{n^{(1)}_{f}}\sum^{n^{(1)}_{f}}_{l=1}\stackunder{\bm{k}_{l}^{(1)}}{\scriptscriptstyle
    d_{k}^{(1)}\times 1},\hskip 20.0pt\stackunder{\bar{\bm{k}}^{(2)}}{\scriptscriptstyle
    d_{k}^{(2)}\times 1}=\frac{1}{n^{(2)}_{f}}\sum^{n^{(2)}_{f}}_{l=1}\stackunder{\bm{k}_{l}^{(2)}}{\scriptscriptstyle
    d_{k}^{(2)}\times 1};$ |  | (10) |'
- en: '|  | $\setstackgap{L}{13pt}\stackunder{e^{(1)}_{l}}{\scriptscriptstyle 1\times
    1}=\text{score}(\stackunder{\bar{\bm{k}}^{(2)}}{\scriptscriptstyle d_{k}^{(2)}\times
    1},\stackunder{\bm{k}_{l}^{(1)}}{\scriptscriptstyle d_{k}^{(1)}\times 1}),\hskip
    5.0pt\stackunder{e^{(2)}_{l}}{\scriptscriptstyle 1\times 1}=\text{score}(\stackunder{\bar{\bm{k}}^{(1)}}{\scriptscriptstyle
    d_{k}^{(1)}\times 1},\stackunder{\bm{k}_{l}^{(2)}}{\scriptscriptstyle d_{k}^{(2)}\times
    1}).$ |  | (11) |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{13pt}\stackunder{e^{(1)}_{l}}{\scriptscriptstyle 1\times
    1}=\text{score}(\stackunder{\bar{\bm{k}}^{(2)}}{\scriptscriptstyle d_{k}^{(2)}\times
    1},\stackunder{\bm{k}_{l}^{(1)}}{\scriptscriptstyle d_{k}^{(1)}\times 1}),\hskip
    5.0pt\stackunder{e^{(2)}_{l}}{\scriptscriptstyle 1\times 1}=\text{score}(\stackunder{\bar{\bm{k}}^{(1)}}{\scriptscriptstyle
    d_{k}^{(1)}\times 1},\stackunder{\bm{k}_{l}^{(2)}}{\scriptscriptstyle d_{k}^{(2)}\times
    1}).$ |  | (11) |'
- en: From the attention scores, attention weights are created via an alignment function,
    and are used to produce the context vectors $\bm{c}^{(1)}$ and $\bm{c}^{(2)}$.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 从注意力分数中，通过对齐函数创建注意力权重，并用于生成上下文向量$\bm{c}^{(1)}$和$\bm{c}^{(2)}$。
- en: '![Refer to caption](img/0afbccc5347e1958a97dd4d28d41285d.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/0afbccc5347e1958a97dd4d28d41285d.png)'
- en: 'Figure 5: An illustration of interactive co-attention.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：交互式共同注意的示意图。
- en: While coarse-grained co-attention mechanisms use a compact representation of
    one input to use as a query when calculating attention for another input, fine-grained
    co-attention considers every element of each input individually when calculating
    attention scores. In this case, the query becomes a matrix. An example of fine-grained
    co-attention is parallel co-attention [[32](#bib.bib32)]. Similarly to interactive
    co-attention, parallel co-attention calculates attention on the two feature matrices
    at the same time, as shown in Fig. [6](#S3.F6 "Figure 6 ‣ 3.1.1 Multiplicity of
    Features ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A
    General Survey on Attention Mechanisms in Deep Learning"). We start by evaluating
    the keys matrices $\bm{K}^{(1)}\in\mathbb{R}^{d_{k}^{(1)}\times n_{f}^{(1)}}$
    and $\bm{K}^{(2)}\in\mathbb{R}^{d_{k}^{(2)}\times n_{f}^{(2)}}$ that are obtained
    by linearly transforming the feature matrices $\bm{F}^{(1)}$ and $\bm{F}^{(2)}$,
    where $d_{k}^{(1)}$ and $d_{k}^{(2)}$ are prespecified dimensions of the keys.
    The idea is to use the keys matrix from one input as the query for calculating
    attention on the other input. However, since $\bm{K}^{(1)}$ and $\bm{K}^{(2)}$
    have completely different dimensions, an affinity matrix $\bm{A}\in\mathbb{R}^{n_{f}^{(1)}\times
    n_{f}^{(2)}}$ is calculated that is used to essentially translate one keys matrix
    to the space of the other keys. In [[32](#bib.bib32)], $\bm{A}$ is calculated
    as shown in ([12](#S3.E12 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning")).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 粗粒度的共同注意机制使用一种紧凑的输入表示作为查询来计算另一个输入的注意力，而细粒度的共同注意则在计算注意力分数时逐个考虑每个输入的每个元素。在这种情况下，查询变成了一个矩阵。细粒度共同注意的一个例子是平行共同注意[[32](#bib.bib32)]。与交互式共同注意类似，平行共同注意同时计算两个特征矩阵上的注意力，如图[6](#S3.F6
    "Figure 6 ‣ 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention Mechanisms
    ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")所示。我们首先评估由线性变换特征矩阵$\bm{F}^{(1)}$和$\bm{F}^{(2)}$得到的键矩阵$\bm{K}^{(1)}\in\mathbb{R}^{d_{k}^{(1)}\times
    n_{f}^{(1)}}$和$\bm{K}^{(2)}\in\mathbb{R}^{d_{k}^{(2)}\times n_{f}^{(2)}}$，其中$d_{k}^{(1)}$和$d_{k}^{(2)}$是预设的键的维度。其思路是将一个输入的键矩阵作为计算另一个输入注意力的查询。然而，由于$\bm{K}^{(1)}$和$\bm{K}^{(2)}$具有完全不同的维度，因此计算一个亲和矩阵$\bm{A}\in\mathbb{R}^{n_{f}^{(1)}\times
    n_{f}^{(2)}}$，该矩阵用于将一个键矩阵本质上转换到另一个键矩阵的空间。在[[32](#bib.bib32)]中，$\bm{A}$的计算如([12](#S3.E12
    "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention Mechanisms
    ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning"))所示。
- en: '|  | $\setstackgap{L}{11pt}\stackunder{\bm{A}}{\scriptscriptstyle n_{f}^{(1)}\times
    n_{f}^{(2)}}=\text{act}(\stackunder{\bm{K}^{{(1)}^{T}}}{\scriptscriptstyle n_{f}^{(1)}\times
    d_{k}^{(1)}}\times\stackunder{\bm{W}_{A}}{\scriptscriptstyle d_{k}^{(1)}\times
    d_{k}^{(2)}}\times\stackunder{\bm{K}^{(2)}}{\scriptscriptstyle d_{k}^{(2)}\times
    n_{f}^{(2)}}),$ |  | (12) |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\stackunder{\bm{A}}{\scriptscriptstyle n_{f}^{(1)}\times
    n_{f}^{(2)}}=\text{act}(\stackunder{\bm{K}^{{(1)}^{T}}}{\scriptscriptstyle n_{f}^{(1)}\times
    d_{k}^{(1)}}\times\stackunder{\bm{W}_{A}}{\scriptscriptstyle d_{k}^{(1)}\times
    d_{k}^{(2)}}\times\stackunder{\bm{K}^{(2)}}{\scriptscriptstyle d_{k}^{(2)}\times
    n_{f}^{(2)}}),$ |  | (12) |'
- en: where $\bm{W}_{A}\in\mathbb{R}^{d_{k}^{(1)}\times d_{k}^{(2)}}$ is a trainable
    weights matrix and $\text{act}()$ is an activation function for which the $\text{tanh}()$
    function is used in [[32](#bib.bib32)]. [[35](#bib.bib35)] proposes a different
    way of calculating this matrix, i.e., one can use ([13](#S3.E13 "In 3.1.1 Multiplicity
    of Features ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention Taxonomy
    ‣ A General Survey on Attention Mechanisms in Deep Learning")) to calculate each
    individual element $A_{i,j}$ of the matrix $\bm{A}$.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\bm{W}_{A}\in\mathbb{R}^{d_{k}^{(1)}\times d_{k}^{(2)}}$ 是一个可训练的权重矩阵，$\text{act}()$
    是一个激活函数，在 [[32](#bib.bib32)] 中使用了 $\text{tanh}()$ 函数。[[35](#bib.bib35)] 提出了计算该矩阵的另一种方法，即可以使用
    ([13](#S3.E13 "在 3.1.1 特征的多样性 ‣ 3.1 与特征相关的注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的一般调查"))
    计算矩阵 $\bm{A}$ 的每个独立元素 $A_{i,j}$。
- en: '|  | $\setstackgap{L}{11pt}\stackunder{A_{i,j}}{\scriptscriptstyle 1\times
    1}=\stackunder{\bm{w}_{A}^{T}}{\scriptscriptstyle 1\times 3d_{k}}\times\text{concat}(\stackunder{\bm{k}_{i}^{(1)}}{\scriptscriptstyle
    d_{k}\times 1},\stackunder{\bm{k}_{j}^{(2)}}{\scriptscriptstyle d_{k}\times 1},\stackunder{\bm{k}_{i}^{(1)}}{\scriptscriptstyle
    d_{k}\times 1}\circ\stackunder{\bm{k}_{j}^{(2)}}{\scriptscriptstyle d_{k}\times
    1}),$ |  | (13) |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\stackunder{A_{i,j}}{\scriptscriptstyle 1\times
    1}=\stackunder{\bm{w}_{A}^{T}}{\scriptscriptstyle 1\times 3d_{k}}\times\text{concat}(\stackunder{\bm{k}_{i}^{(1)}}{\scriptscriptstyle
    d_{k}\times 1},\stackunder{\bm{k}_{j}^{(2)}}{\scriptscriptstyle d_{k}\times 1},\stackunder{\bm{k}_{i}^{(1)}}{\scriptscriptstyle
    d_{k}\times 1}\circ\stackunder{\bm{k}_{j}^{(2)}}{\scriptscriptstyle d_{k}\times
    1}),$ |  | (13) |'
- en: where $\bm{w}_{A}\in\mathbb{R}^{3d_{k}}$ denotes a trainable vector of weights,
    $\text{concat}()$ denotes vector concatenation, and $\circ$ denotes element-wise
    multiplication, also known as the Hadamard product. Note that the keys of each
    keys matrix in this case must have the same dimension $d_{k}$ for the element-wise
    multiplication to work. The affinity matrix can be interpreted as a similarity
    matrix for the columns of the two keys matrices, and helps translate, for example,
    image keys to the same space as the keys of the words in a sentence, and vice
    versa. The vectors of attention scores $\bm{e}^{(1)}$ and $\bm{e}^{(2)}$ can be
    calculated using an altered version of the additive score function as presented
    in ([14](#S3.E14 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning")) and ([15](#S3.E15 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning")). The previous attention score examples in this survey all
    used a score function to calculate each attention score for each value vector
    individually. However, ([14](#S3.E14 "In 3.1.1 Multiplicity of Features ‣ 3.1
    Feature-Related Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey
    on Attention Mechanisms in Deep Learning")) and ([15](#S3.E15 "In 3.1.1 Multiplicity
    of Features ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention Taxonomy
    ‣ A General Survey on Attention Mechanisms in Deep Learning")) are used to calculate
    the complete vector of all attention scores. Essentially, the attention scores
    are calculated in an aggregated form.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\bm{w}_{A}\in\mathbb{R}^{3d_{k}}$ 表示一个可训练的权重向量，$\text{concat}()$ 表示向量连接，$\circ$
    表示逐元素乘法，也称为哈达玛积。请注意，在这种情况下，每个键矩阵的键必须具有相同的维度 $d_{k}$，以使逐元素乘法有效。亲和力矩阵可以被解释为两个键矩阵列的相似性矩阵，并帮助将例如图像键转换到与句子中单词的键相同的空间，反之亦然。注意力得分向量
    $\bm{e}^{(1)}$ 和 $\bm{e}^{(2)}$ 可以使用修改版的加性得分函数计算，如 ([14](#S3.E14 "在 3.1.1 特征的多样性
    ‣ 3.1 特征相关的注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的一般调查")) 和 ([15](#S3.E15 "在 3.1.1 特征的多样性
    ‣ 3.1 特征相关的注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的一般调查")) 所示。本调查中的先前注意力得分示例都使用得分函数为每个值向量单独计算每个注意力得分。然而，([14](#S3.E14
    "在 3.1.1 特征的多样性 ‣ 3.1 特征相关的注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的一般调查")) 和 ([15](#S3.E15
    "在 3.1.1 特征的多样性 ‣ 3.1 特征相关的注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的一般调查")) 用于计算所有注意力得分的完整向量。实际上，注意力得分是以聚合的形式计算的。
- en: '|  | $\setstackgap{L}{11pt}\stackunder{\bm{e}^{(1)}}{\scriptscriptstyle 1\times
    n_{f}^{(1)}}=\stackunder{\bm{w}_{1}}{\scriptscriptstyle 1\times d_{w}}\times\text{act}(\stackunder{\bm{W}_{2}}{\scriptscriptstyle
    d_{w}\times d_{k}^{(2)}}\times\stackunder{\bm{K}^{(2)}}{\scriptscriptstyle d_{k}^{(2)}\times
    n_{f}^{(2)}}\times\stackunder{\bm{A}^{T}}{\scriptscriptstyle n_{f}^{(2)}\times
    n_{f}^{(1)}}+\stackunder{\bm{W}_{1}}{\scriptscriptstyle d_{w}\times d_{k}^{(1)}}\times\stackunder{\bm{K}^{(1)}}{\scriptscriptstyle
    d_{k}^{(1)}\times n_{f}^{(1)}});$ |  | (14) |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\stackunder{\bm{e}^{(1)}}{\scriptscriptstyle 1\times
    n_{f}^{(1)}}=\stackunder{\bm{w}_{1}}{\scriptscriptstyle 1\times d_{w}}\times\text{act}(\stackunder{\bm{W}_{2}}{\scriptscriptstyle
    d_{w}\times d_{k}^{(2)}}\times\stackunder{\bm{K}^{(2)}}{\scriptscriptstyle d_{k}^{(2)}\times
    n_{f}^{(2)}}\times\stackunder{\bm{A}^{T}}{\scriptscriptstyle n_{f}^{(2)}\times
    n_{f}^{(1)}}+\stackunder{\bm{W}_{1}}{\scriptscriptstyle d_{w}\times d_{k}^{(1)}}\times\stackunder{\bm{K}^{(1)}}{\scriptscriptstyle
    d_{k}^{(1)}\times n_{f}^{(1)}});$ |  | (14) |'
- en: '|  | $\setstackgap{L}{11pt}\stackunder{\bm{e}^{(2)}}{\scriptscriptstyle 1\times
    n_{f}^{(2)}}=\stackunder{\bm{w}_{2}}{\scriptscriptstyle 1\times d_{w}}\times\text{act}(\stackunder{\bm{W}_{1}}{\scriptscriptstyle
    d_{w}\times d_{k}^{(1)}}\times\stackunder{\bm{K}^{(1)}}{\scriptscriptstyle d_{k}^{(1)}\times
    n_{f}^{(1)}}\times\stackunder{\bm{A}}{\scriptscriptstyle n_{f}^{(1)}\times n_{f}^{(2)}}+\stackunder{\bm{W}_{2}}{\scriptscriptstyle
    d_{w}\times d_{k}^{(2)}}\times\stackunder{\bm{K}^{(2)}}{\scriptscriptstyle d_{k}^{(2)}\times
    n_{f}^{(2)}}),$ |  | (15) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\stackunder{\bm{e}^{(2)}}{\scriptscriptstyle 1\times
    n_{f}^{(2)}}=\stackunder{\bm{w}_{2}}{\scriptscriptstyle 1\times d_{w}}\times\text{act}(\stackunder{\bm{W}_{1}}{\scriptscriptstyle
    d_{w}\times d_{k}^{(1)}}\times\stackunder{\bm{K}^{(1)}}{\scriptscriptstyle d_{k}^{(1)}\times
    n_{f}^{(1)}}\times\stackunder{\bm{A}}{\scriptscriptstyle n_{f}^{(1)}\times n_{f}^{(2)}}+\stackunder{\bm{W}_{2}}{\scriptscriptstyle
    d_{w}\times d_{k}^{(2)}}\times\stackunder{\bm{K}^{(2)}}{\scriptscriptstyle d_{k}^{(2)}\times
    n_{f}^{(2)}}),$ |  | (15) |'
- en: where $\bm{w}_{1}\in\mathbb{R}^{d_{w}}$, $\bm{w}_{2}\in\mathbb{R}^{d_{w}}$,
    $\bm{W}_{1}\in\mathbb{R}^{d_{w}\times d_{k}^{(1)}}$, and $\bm{W}_{2}\in\mathbb{R}^{d_{w}\times
    d_{k}^{(2)}}$ are trainable weight matrices, for which $d_{w}$ is a prespecified
    dimension of the weight matrices. Note that $\text{tanh}()$ is used in [[32](#bib.bib32)]
    for the activation function, and the feature matrices are used as the key matrices.
    In that case, the affinity matrix $\bm{A}$ can be seen as a translator between
    feature spaces. As mentioned before, the affinity matrix is essentially a similarity
    matrix for the key vectors of the two inputs. In [[33](#bib.bib33)], this fact
    is used to propose a different way of determining attention scores. Namely, one
    could take the maximum similarity value in a row or column as the attention score,
    as shown in ([16](#S3.E16 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning")).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\bm{w}_{1}\in\mathbb{R}^{d_{w}}$，$\bm{w}_{2}\in\mathbb{R}^{d_{w}}$，$\bm{W}_{1}\in\mathbb{R}^{d_{w}\times
    d_{k}^{(1)}}$，以及 $\bm{W}_{2}\in\mathbb{R}^{d_{w}\times d_{k}^{(2)}}$ 是可训练的权重矩阵，其中
    $d_{w}$ 是权重矩阵的预设维度。注意 $\text{tanh}()$ 被用于[[32](#bib.bib32)]中的激活函数，特征矩阵作为键矩阵。在这种情况下，亲和力矩阵
    $\bm{A}$ 可以看作是特征空间之间的翻译器。如前所述，亲和力矩阵本质上是两个输入键向量的相似性矩阵。在[[33](#bib.bib33)]中，这一事实被用来提出确定注意力分数的不同方法。即，可以将一行或一列中的最大相似性值作为注意力分数，如（[16](#S3.E16
    "在 3.1.1 特征的多样性 ‣ 3.1 特征相关注意力机制 ‣ 3 注意力分类 ‣ 深度学习中的注意力机制概述")）中所示。
- en: '![Refer to caption](img/ece93d394ee5a2e8fb52bd54bbbc48c7.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ece93d394ee5a2e8fb52bd54bbbc48c7.png)'
- en: 'Figure 6: An illustration of parallel co-attention.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：平行共同注意力的示意图。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{e_{i}^{(1)}}{\scriptscriptstyle 1\times
    1}=\stackunder{\text{max}}{\scriptscriptstyle j=1,\dots,n_{f}^{(2)}}\stackunder{A_{i,j}}{\scriptscriptstyle
    1\times 1},\hskip 20.0pt\stackunder{e_{j}^{(2)}}{\scriptscriptstyle 1\times 1}=\stackunder{\text{max}}{\scriptscriptstyle
    i=1,\dots,n_{f}^{(1)}}\stackunder{A_{i,j}}{\scriptscriptstyle 1\times 1}.$ |  |
    (16) |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{e_{i}^{(1)}}{\scriptscriptstyle 1\times
    1}=\stackunder{\text{max}}{\scriptscriptstyle j=1,\dots,n_{f}^{(2)}}\stackunder{A_{i,j}}{\scriptscriptstyle
    1\times 1},\hskip 20.0pt\stackunder{e_{j}^{(2)}}{\scriptscriptstyle 1\times 1}=\stackunder{\text{max}}{\scriptscriptstyle
    i=1,\dots,n_{f}^{(1)}}\stackunder{A_{i,j}}{\scriptscriptstyle 1\times 1}.$ |  |
    (16) |'
- en: Next, the attention scores are used to calculate attention weights using an
    alignment function, so that two context vectors $\bm{c}^{(1)}$ and $\bm{c}^{(2)}$
    can be derived as weighted averages of the value vectors that are obtained from
    linearly transforming the features. For the alignment function, [[32](#bib.bib32)]
    proposes to use a softmax function, and the value vectors are simply set equal
    to the feature vectors. The resulting context vectors can be either concatenated
    or added together.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用注意力分数通过对齐函数计算注意力权重，以便可以将两个上下文向量 $\bm{c}^{(1)}$ 和 $\bm{c}^{(2)}$ 作为从线性变换特征得到的值向量的加权平均。对于对齐函数，[[32](#bib.bib32)]
    提议使用 softmax 函数，值向量被简单地设置为特征向量。结果上下文向量可以连接或相加。
- en: Finally, coarse-grained and fine-grained co-attention can be combined to create
    an even more complex co-attention mechanism. [[33](#bib.bib33)] proposes the multi-grained
    co-attention mechanism that calculates both coarse-grained and fine-grained co-attention
    for two inputs. Each mechanism produces one context vector per input. The four
    resulting context vectors are concatenated and used in the output model for prediction.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，粗粒度和细粒度的共同注意力可以结合起来，创建一个更复杂的共同注意力机制。[[33](#bib.bib33)] 提出了多粒度共同注意力机制，该机制计算两个输入的粗粒度和细粒度共同注意力。每个机制为每个输入生成一个上下文向量。这四个结果上下文向量被连接起来，并在输出模型中用于预测。
- en: 'A mechanism separate from co-attention that still uses multiple inputs is the
    rotatory attention mechanism [[36](#bib.bib36)]. This technique is typically used
    in a text sentiment analysis setting where there are three inputs involved: the
    phrase for which the sentiment needs to be determined (target phrase), the text
    before the target phrase (left context), and the text after the target phrase
    (right context). The words in these three inputs are all encoded by the feature
    model, producing the following feature matrices: $\bm{F}^{t}=[\bm{f}^{t}_{1},\dots,\bm{f}^{t}_{n^{t}_{f}}]\in\mathbb{R}^{d_{f}^{t}\times
    n_{f}^{t}}$, $\bm{F}^{l}=[\bm{f}^{l}_{1},\dots,\bm{f}^{l}_{n^{l}_{f}}]\in\mathbb{R}^{d_{f}^{l}\times
    n_{f}^{l}}$, and $\bm{F}^{r}=[\bm{f}^{r}_{1},\dots,\bm{f}^{r}_{n^{r}_{f}}]\in\mathbb{R}^{d_{f}^{r}\times
    n_{f}^{r}}$, for the target phrase words, left context words, and right context
    words, respectively, where $d_{f}^{t}$, $d_{f}^{l}$, and $d_{f}^{r}$ represent
    the dimensions of the feature vectors for the corresponding inputs, and $n_{f}^{t}$,
    $n_{f}^{l}$, and $n_{f}^{r}$ represent the number of feature vectors for the corresponding
    inputs. The feature model used in [[36](#bib.bib36)] consists of word embeddings
    and separate Bi-LSTM models for the target phrase, the left context, and the right
    context. This means that the feature vectors are in fact the hidden state vectors
    obtained from the Bi-LSTM models. Using these features, the idea is to extract
    a single vector $\bm{r}$ from the inputs such that a softmax layer can be used
    for classification. As such, we are now faced with two challenges: how to represent
    the inputs as a single vector, and how to incorporate the information from the
    left and right context into that vector. [[36](#bib.bib36)] proposes to use the
    rotatory attention mechanism for this purpose.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 与共同注意机制分开的一个机制是旋转注意机制[[36](#bib.bib36)]。该技术通常用于文本情感分析环境，其中涉及三个输入：需要确定情感的短语（目标短语）、目标短语之前的文本（左上下文）和目标短语之后的文本（右上下文）。这三个输入中的单词都由特征模型编码，生成以下特征矩阵：$\bm{F}^{t}=[\bm{f}^{t}_{1},\dots,\bm{f}^{t}_{n^{t}_{f}}]\in\mathbb{R}^{d_{f}^{t}\times
    n_{f}^{t}}$、$\bm{F}^{l}=[\bm{f}^{l}_{1},\dots,\bm{f}^{l}_{n^{l}_{f}}]\in\mathbb{R}^{d_{f}^{l}\times
    n_{f}^{l}}$和$\bm{F}^{r}=[\bm{f}^{r}_{1},\dots,\bm{f}^{r}_{n^{r}_{f}}]\in\mathbb{R}^{d_{f}^{r}\times
    n_{f}^{r}}$，分别对应目标短语词汇、左上下文词汇和右上下文词汇，其中$d_{f}^{t}$、$d_{f}^{l}$和$d_{f}^{r}$表示对应输入的特征向量维度，$n_{f}^{t}$、$n_{f}^{l}$和$n_{f}^{r}$表示对应输入的特征向量数量。[[36](#bib.bib36)]中使用的特征模型包括目标短语、左上下文和右上下文的词嵌入和分开的Bi-LSTM模型。这意味着特征向量实际上是从Bi-LSTM模型中获得的隐藏状态向量。使用这些特征的想法是从输入中提取一个单一向量$\bm{r}$，以便可以使用softmax层进行分类。因此，我们现在面临两个挑战：如何将输入表示为一个单一向量，以及如何将左上下文和右上下文的信息整合到该向量中。[[36](#bib.bib36)]提出使用旋转注意机制来解决这个问题。
- en: Firstly, a single target phrase representation is created by using a pooling
    layer that takes the average over the columns of $\bm{F}^{t}$, as shown in ([17](#S3.E17
    "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention Mechanisms
    ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，通过使用一个池化层对$\bm{F}^{t}$的列进行平均，创建一个单一的目标短语表示，如在([17](#S3.E17 "在3.1.1 特征的多样性
    ‣ 3.1 特征相关注意机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的综合调查"))中所示。
- en: '|  | $\setstackgap{L}{11pt}\stackunder{\bm{r}^{t}}{\scriptscriptstyle d_{f}^{t}\times
    1}=\frac{1}{n^{t}_{f}}\sum^{n^{t}_{f}}_{i=1}\stackunder{\bm{f}^{t}_{i}}{\scriptscriptstyle
    d_{f}^{t}\times 1}.$ |  | (17) |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\stackunder{\bm{r}^{t}}{\scriptscriptstyle d_{f}^{t}\times
    1}=\frac{1}{n^{t}_{f}}\sum^{n^{t}_{f}}_{i=1}\stackunder{\bm{f}^{t}_{i}}{\scriptscriptstyle
    d_{f}^{t}\times 1}.$ |  | (17) |'
- en: $\bm{r}^{t}$ is then used as a query to create a context vector out of the left
    and right contexts, separately. For example, for the left context, the key vectors
    $\bm{k}_{1}^{l},\dots,\bm{k}_{n_{f}^{l}}^{l}\in\mathbb{R}^{d_{k}^{l}}$ and value
    vectors $\bm{v}_{1}^{l},\dots,\bm{v}_{n_{f}^{l}}^{l}\in\mathbb{R}^{d_{v}^{l}}$
    are extracted from the left context feature vectors $\bm{f}_{1}^{l},\dots,\bm{f}_{n_{f}^{l}}^{l}\in\mathbb{R}^{d_{f}^{l}}$,
    similarly as before, where $d_{k}^{l}$ and $d_{v}^{l}$ are the dimensions of the
    key and value vectors, respectively. Note that [[36](#bib.bib36)] proposes to
    use the original feature vectors as keys and values, meaning that the linear transformation
    consists of a multiplication by an identity matrix. Next, the scores are calculated
    using ([18](#S3.E18 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning")).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: $\bm{r}^{t}$ 然后被用作查询，从左侧和右侧上下文分别创建上下文向量。例如，对于左侧上下文，关键向量 $\bm{k}_{1}^{l},\dots,\bm{k}_{n_{f}^{l}}^{l}\in\mathbb{R}^{d_{k}^{l}}$
    和值向量 $\bm{v}_{1}^{l},\dots,\bm{v}_{n_{f}^{l}}^{l}\in\mathbb{R}^{d_{v}^{l}}$ 从左侧上下文特征向量
    $\bm{f}_{1}^{l},\dots,\bm{f}_{n_{f}^{l}}^{l}\in\mathbb{R}^{d_{f}^{l}}$ 中提取，方法与之前类似，其中
    $d_{k}^{l}$ 和 $d_{v}^{l}$ 分别是关键向量和值向量的维度。注意[[36](#bib.bib36)] 提议使用原始特征向量作为键和值，意味着线性变换由单位矩阵的乘法组成。接下来，使用
    ([18](#S3.E18 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning")) 计算分数。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{e_{i}^{l}}{\scriptscriptstyle 1\times
    1}=\text{score}(\stackunder{\bm{r}^{t}}{\scriptscriptstyle d_{f}^{t}\times 1},\stackunder{\bm{k}_{i}^{l}}{\scriptscriptstyle
    d_{k}^{l}\times 1}).$ |  | (18) |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{e_{i}^{l}}{\scriptscriptstyle 1\times
    1}=\text{score}(\stackunder{\bm{r}^{t}}{\scriptscriptstyle d_{f}^{t}\times 1},\stackunder{\bm{k}_{i}^{l}}{\scriptscriptstyle
    d_{k}^{l}\times 1}).$ |  | (18) |'
- en: For the score function, [[36](#bib.bib36)] proposes to use an activated general
    score function [[34](#bib.bib34)] with a tanh activation function. The attention
    scores can be combined with an alignment function and the corresponding value
    vectors to produce the context vector $\bm{r}^{l}\in\mathbb{R}^{d_{v}^{l}}$. The
    alignment function used in [[36](#bib.bib36)] takes the form of a softmax function.
    An analogous procedure can be performed to obtain the representation of the right
    context, $\bm{r}^{r}$. These two context representations can then be used to create
    new representations of the target phrase, again, using attention. Firstly, the
    key vectors $\bm{k}_{1}^{t},\dots,\bm{k}_{n_{f}^{t}}^{t}\in\mathbb{R}^{d_{k}^{t}}$
    and value vectors $\bm{v}_{1}^{t},\dots,\bm{v}_{n_{f}^{t}}^{t}\in\mathbb{R}^{d_{v}^{t}}$
    are extracted from the target phrase feature vectors $\bm{f}_{1}^{t},\dots,\bm{f}_{n_{f}^{t}}^{t}\in\mathbb{R}^{d_{f}^{t}}$,
    similarly as before, using a linear transformation, where $d_{k}^{t}$ and $d_{v}^{t}$
    are the dimensions of the key and value vectors, respectively. Note, again, that
    the original feature vectors as keys and values in [[36](#bib.bib36)]. The attention
    scores for the left-aware target representation are then calculated using ([19](#S3.E19
    "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention Mechanisms
    ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分数函数，[[36](#bib.bib36)] 提议使用一个激活的一般分数函数 [[34](#bib.bib34)]，其中使用了 tanh 激活函数。注意力分数可以与对齐函数和相应的值向量结合，生成上下文向量
    $\bm{r}^{l}\in\mathbb{R}^{d_{v}^{l}}$。[[36](#bib.bib36)] 中使用的对齐函数呈现为 softmax 函数。可以采用类似的过程来获取右侧上下文的表示，$\bm{r}^{r}$。这两个上下文表示可以用来创建目标短语的新表示，再次使用注意力。首先，从目标短语特征向量
    $\bm{f}_{1}^{t},\dots,\bm{f}_{n_{f}^{t}}^{t}\in\mathbb{R}^{d_{f}^{t}}$ 中提取关键向量
    $\bm{k}_{1}^{t},\dots,\bm{k}_{n_{f}^{t}}^{t}\in\mathbb{R}^{d_{k}^{t}}$ 和值向量 $\bm{v}_{1}^{t},\dots,\bm{v}_{n_{f}^{t}}^{t}\in\mathbb{R}^{d_{v}^{t}}$，方法与之前类似，使用线性变换，其中
    $d_{k}^{t}$ 和 $d_{v}^{t}$ 分别是关键向量和值向量的维度。再次注意，[[36](#bib.bib36)] 中原始特征向量作为键和值。然后使用
    ([19](#S3.E19 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning")) 计算左侧感知目标表示的注意力分数。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{e_{i}^{l_{t}}}{\scriptscriptstyle 1\times
    1}=\text{score}(\stackunder{\bm{r}^{l}}{\scriptscriptstyle d_{v}^{l}\times 1},\stackunder{\bm{k}_{i}^{t}}{\scriptscriptstyle
    d_{k}^{t}\times 1}).$ |  | (19) |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{e_{i}^{l_{t}}}{\scriptscriptstyle 1\times
    1}=\text{score}(\stackunder{\bm{r}^{l}}{\scriptscriptstyle d_{v}^{l}\times 1},\stackunder{\bm{k}_{i}^{t}}{\scriptscriptstyle
    d_{k}^{t}\times 1}).$ |  | (19) |'
- en: The attention scores can be combined with an alignment function and the corresponding
    value vectors to produce the context vector $\bm{r}^{l_{t}}\in\mathbb{R}^{d_{v}^{t}}$.
    For this attention calculation, [[34](#bib.bib34)] proposes to use the same score
    and alignment functions as before. The right-aware target representation $\bm{r}^{r_{t}}$
    can be calculated in a similar manner. Finally, to obtain the full representation
    vector $\bm{r}$ that is used to determine the classification, the vectors $\bm{r}^{l}$,
    $\bm{r}^{r}$, $\bm{r}^{l_{t}}$, and $\bm{r}^{r_{t}}$ are concatenated together,
    as shown in ([20](#S3.E20 "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning")).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力得分可以与对齐函数及相应的值向量结合，以生成上下文向量$\bm{r}^{l_{t}}\in\mathbb{R}^{d_{v}^{t}}$。对于这个注意力计算，[[34](#bib.bib34)]建议使用之前相同的得分和对齐函数。右侧感知目标表示$\bm{r}^{r_{t}}$可以以类似的方式计算。最后，为了获得用于分类的完整表示向量$\bm{r}$，将向量$\bm{r}^{l}$、$\bm{r}^{r}$、$\bm{r}^{l_{t}}$和$\bm{r}^{r_{t}}$拼接在一起，如（[20](#S3.E20
    "In 3.1.1 Multiplicity of Features ‣ 3.1 Feature-Related Attention Mechanisms
    ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")）所示。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{r}}{\scriptscriptstyle(d_{v}^{l}+d_{v}^{r}+d_{v}^{t}+d_{v}^{t})\times
    1}=\text{concat}(\stackunder{\bm{r}^{l}}{\scriptscriptstyle d_{v}^{l}\times 1},\stackunder{\bm{r}^{r}}{\scriptscriptstyle
    d_{v}^{r}\times 1},\stackunder{\bm{r}^{l_{t}}}{\scriptscriptstyle d_{v}^{t}\times
    1},\stackunder{\bm{r}^{r_{t}}}{\scriptscriptstyle d_{v}^{t}\times 1}).$ |  | (20)
    |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{r}}{\scriptscriptstyle(d_{v}^{l}+d_{v}^{r}+d_{v}^{t}+d_{v}^{t})\times
    1}=\text{concat}(\stackunder{\bm{r}^{l}}{\scriptscriptstyle d_{v}^{l}\times 1},\stackunder{\bm{r}^{r}}{\scriptscriptstyle
    d_{v}^{r}\times 1},\stackunder{\bm{r}^{l_{t}}}{\scriptscriptstyle d_{v}^{t}\times
    1},\stackunder{\bm{r}^{r_{t}}}{\scriptscriptstyle d_{v}^{t}\times 1}).$ |  | (20)
    |'
- en: To summarize, rotatory attention uses the target phrase to compute new representations
    for the left and right context using attention, and then uses these left and right
    representations to calculate new representations for the target phrase. The first
    step is designed to capture the words in the left and right contexts that are
    most important to the target phrase. The second step is there to capture the most
    important information in the actual target phrase itself. Essentially, the mechanism
    rotates attention between the target and the contexts to improve the representations.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，旋转注意力机制使用目标短语来计算左侧和右侧上下文的新表示，然后利用这些左侧和右侧的表示来计算目标短语的新表示。第一步旨在捕捉对目标短语最重要的左侧和右侧上下文中的词汇。第二步则旨在捕捉实际目标短语本身最重要的信息。本质上，这一机制通过在目标和上下文之间旋转注意力来改善表示。
- en: There are many applications where combining information from different inputs
    into a single model can be highly beneficial. For example, in the field of medical
    data, there are often many different types of data available, such as various
    scans or documents, that can provide different types of information. In [[37](#bib.bib37)],
    a co-attention mechanism is used for automatic medical report generation to attend
    to both images and semantic tags simultaneously. Similarly, in [[38](#bib.bib38)],
    a co-attention model is proposed that combines general demographics features and
    patient medical history features to predict future health information. Additionally,
    an ablation study is used in [[38](#bib.bib38)] to show that the co-attention
    part of the model specifically improves performance. A field where multi-feature
    attention has been extensively explored is the domain of recommender systems.
    For example, in [[39](#bib.bib39)], a co-attention network is proposed that attends
    to both product reviews and the reviews a user has written. In [[40](#bib.bib40)],
    a model is proposed for video recommendation that attends to both user features
    and video features. Co-attention techniques have also been used in combination
    with graph networks for the purpose of, for example, reading comprehension across
    multiple documents [[41](#bib.bib41)] and fake news detection [[42](#bib.bib42)].
    In comparison to co-attention, rotatory attention has typically been explored
    only in the field of sentiment analysis, which is most likely due to the specific
    structure of the data that is necessary to use this technique. An implementation
    of rotatory attention is proposed in [[43](#bib.bib43)] for sentiment analysis,
    where the mechanism is extended by repeating the attention rotation to iteratively
    further improve the representations.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 结合来自不同输入的信息到一个模型中可以在许多应用中非常有益。例如，在医学数据领域，通常会有许多不同类型的数据，如各种扫描图像或文档，这些数据可以提供不同的信息。在[[37](#bib.bib37)]中，使用了一个共注意力机制来自动生成医学报告，以同时关注图像和语义标签。类似地，在[[38](#bib.bib38)]中，提出了一种共注意力模型，它将一般人口统计特征和患者医疗历史特征结合起来，以预测未来的健康信息。此外，在[[38](#bib.bib38)]中使用了消融研究来表明模型中的共注意力部分具体提高了性能。一个多特征注意力被广泛研究的领域是推荐系统。例如，在[[39](#bib.bib39)]中，提出了一种共注意力网络，关注产品评论和用户撰写的评论。在[[40](#bib.bib40)]中，提出了一种视频推荐模型，关注用户特征和视频特征。共注意力技术也与图网络结合使用，例如，用于多文档的阅读理解[[41](#bib.bib41)]和假新闻检测[[42](#bib.bib42)]。相比于共注意力，旋转注意力通常只在情感分析领域被探索，这可能是由于使用这种技术所需的数据特定结构。在[[43](#bib.bib43)]中提出了一种旋转注意力的实现，用于情感分析，其中该机制通过重复注意力旋转来迭代地进一步改进表示。
- en: 3.1.2 Feature Levels
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 特征层次
- en: The previously discussed attention mechanisms process data at a single level.
    We refer to these attention techniques as single-level attention mechanisms. However,
    some data types can be analyzed and represented on multiple levels. For example,
    when analyzing documents, one can analyze the document at the sentence level,
    word level, or even the character level. When representations or embeddings of
    all these levels are available, one can exploit the extra levels of information.
    For example, one could choose to perform translation based on either just the
    characters, or just the words of the sentence. However, in [[44](#bib.bib44)],
    a technique named attention-via-attention is introduced that allows one to incorporate
    information from both the character, and the word levels. The idea is to predict
    the sentence translation character-by-character, while also incorporating information
    from a word-level attention module.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 之前讨论的注意力机制在单一层次上处理数据。我们称这些注意力技术为单层次注意力机制。然而，一些数据类型可以在多个层次上进行分析和表示。例如，在分析文档时，可以在句子层次、词汇层次，甚至是字符层次进行分析。当所有这些层次的表示或嵌入可用时，可以利用额外的信息层次。例如，可以选择基于句子的字符或词汇进行翻译。然而，在[[44](#bib.bib44)]中，引入了一种名为注意力-通过-注意力的技术，允许结合字符层次和词汇层次的信息。其思想是逐字符预测句子翻译，同时结合词汇层次注意力模块的信息。
- en: '![Refer to caption](img/66241212d31a8569f864fd53d2061834.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/66241212d31a8569f864fd53d2061834.png)'
- en: 'Figure 7: An illustration of attention-via-attention.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7: 通过注意力实现的注意力示意图。'
- en: 'To begin with, a feature model (consisting of, for example, word embeddings
    and RNNs) is used to encode the input sentence into both a character-level feature
    matrix $\bm{F}^{(c)}\in\mathbb{R}^{d_{f}^{(c)}\times n_{f}^{(c)}}$, and a word-level
    feature matrix $\bm{F}^{(w)}\in\mathbb{R}^{d_{f}^{(w)}\times n_{f}^{(w)}}$, where
    $d_{f}^{(c)}$ and $n_{f}^{(c)}$ represent, respectively, the dimension of the
    embeddings of the characters, and the number of characters, while $d_{f}^{(w)}$
    and $n_{f}^{(w)}$ represent the same but at the word level. It is crucial for
    this method that each level in the data can be represented or embedded. When attempting
    to predict a character in the translated sentence, a query $\bm{q}^{(c)}\in\mathbb{R}^{d_{q}}$
    is created by the query model (like a character-level RNN), where $d_{q}$ is the
    dimension of the query vectors. As illustrated in Fig. [7](#S3.F7 "Figure 7 ‣
    3.1.2 Feature Levels ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention
    Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning"), the query
    is used to calculate attention on the word-level feature vectors $\bm{F}^{(w)}$.
    This generates the context vector $\bm{c}^{(w)}\in\mathbb{R}^{d_{v}^{(w)}}$, where
    $d_{v}^{(w)}$ represents the dimension of the value vectors for the word-level
    attention module. This context vector summarizes which words contain the most
    important information for predicting the next character. If we know which words
    are most important, then it becomes easier to identify which characters in the
    input sentence are most important. Thus, the next step is to attend to the character-level
    features in $\bm{F}^{(c)}$, with an additional query input: the word-level context
    vector $\bm{c}^{(w)}$. The actual query input for the attention model will therefore
    be the concatenation of the query $\bm{q}^{(c)}$ and the word context vector $\bm{c}^{(w)}$.
    The output of this character-level attention module is the context vector $\bm{c}^{(c)}$.
    The complete context output of the attention model is the concatenation of the
    word-level, and character-level context vectors.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，特征模型（例如，由词嵌入和RNNs组成）用于将输入句子编码为字符级特征矩阵$\bm{F}^{(c)}\in\mathbb{R}^{d_{f}^{(c)}\times
    n_{f}^{(c)}}$和词级特征矩阵$\bm{F}^{(w)}\in\mathbb{R}^{d_{f}^{(w)}\times n_{f}^{(w)}}$，其中$d_{f}^{(c)}$和$n_{f}^{(c)}$分别表示字符嵌入的维度和字符数量，而$d_{f}^{(w)}$和$n_{f}^{(w)}$则表示词级别的相应参数。对该方法至关重要的是数据中的每一层都可以被表示或嵌入。在尝试预测翻译句子中的一个字符时，通过查询模型（如字符级RNN）生成查询$\bm{q}^{(c)}\in\mathbb{R}^{d_{q}}$，其中$d_{q}$是查询向量的维度。如图[7](#S3.F7
    "Figure 7 ‣ 3.1.2 Feature Levels ‣ 3.1 Feature-Related Attention Mechanisms ‣
    3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")所示，查询用于计算词级特征向量$\bm{F}^{(w)}$的注意力。这生成了上下文向量$\bm{c}^{(w)}\in\mathbb{R}^{d_{v}^{(w)}}$，其中$d_{v}^{(w)}$表示词级注意力模块的值向量的维度。这个上下文向量总结了哪些词包含对预测下一个字符最重要的信息。如果我们知道哪些词最重要，那么识别输入句子中哪些字符最重要就变得容易。因此，下一步是关注$\bm{F}^{(c)}$中的字符级特征，添加一个额外的查询输入：词级上下文向量$\bm{c}^{(w)}$。因此，注意力模型的实际查询输入将是查询$\bm{q}^{(c)}$和词上下文向量$\bm{c}^{(w)}$的拼接。这个字符级注意力模块的输出是上下文向量$\bm{c}^{(c)}$。注意力模型的完整上下文输出是词级和字符级上下文向量的拼接。
- en: The attention-via-attention technique uses representations for each level. However,
    accurate representations may not always be available for each level of the data,
    or it may be desirable to let the model create the representations during the
    process by building them from lower level representations. A technique referred
    to as hierarchical attention [[5](#bib.bib5)] can be used in this situation. Hierarchical
    attention is another technique that allows one to apply attention on different
    levels of the data. Yet, the exact mechanisms work quite differently compared
    to attention-via-attention. The idea is to start at the lowest level, and then
    create representations, or summaries, of the next level using attention. This
    process is repeated till the highest level is reached. To make this a little clearer,
    suppose one attempts to create a model for document classification, similarly
    to the implementation from [[5](#bib.bib5)]. We analyze a document containing
    $n_{S}$ sentences, with the $s$th sentence containing $n_{s}$ words, for $s=1,\dots,n_{S}$.
    One could use attention based on just the collection of words to classify the
    document. However, a significant amount of important context is then left out
    of the analysis, since the model will consider all words as a single long sentence,
    and will therefore not consider the context within the separate sentences. Instead,
    one can use the hierarchical structure of a document (words form sentences, and
    sentences form the document).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制通过注意力技术使用每个层级的表示。然而，并非每个数据层级都有准确的表示，或者在过程中让模型从下层表示构建表示可能更为合适。这种情况下可以使用一种称为分层注意力的技术[[5](#bib.bib5)]。分层注意力是另一种技术，它允许在数据的不同层级上应用注意力。然而，与注意力通过注意力技术相比，具体机制运作有很大不同。其思路是从最低层级开始，然后使用注意力创建下一层级的表示或总结。这个过程会重复进行，直到达到最高层级。为了更清楚地说明这一点，假设我们尝试创建一个文档分类模型，类似于[[5](#bib.bib5)]中的实现。我们分析一个包含
    $n_{S}$ 个句子的文档，其中第 $s$ 个句子包含 $n_{s}$ 个单词，$s=1,\dots,n_{S}$。可以基于单词集合使用注意力来分类文档。然而，这样做会遗漏大量重要的上下文，因为模型会将所有单词视为一个长句子，从而忽略了各个句子内部的上下文。相反，可以利用文档的分层结构（单词构成句子，句子构成文档）。
- en: '![Refer to caption](img/9bd2045cd2974f304c4fe707f9c473d1.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/9bd2045cd2974f304c4fe707f9c473d1.png)'
- en: 'Figure 8: An illustration of hierarchical attention.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：分层注意力的示意图。
- en: Fig. [8](#S3.F8 "Figure 8 ‣ 3.1.2 Feature Levels ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning") illustrates the structure of hierarchical attention. For each
    sentence in the document, a sentence representation $\bm{c}^{(s)}\in\mathbb{R}^{d_{v}^{(S)}}$
    is produced, for $s=1,\dots,n_{S}$, where $d_{v}^{(S)}$ is the dimension of the
    value vectors used in the attention model for sentence representations (Attention
    Module[S] in Fig. [8](#S3.F8 "Figure 8 ‣ 3.1.2 Feature Levels ‣ 3.1 Feature-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning")). The representation is a context vector from an attention
    module that essentially summarizes the sentence. Each sentence is first put through
    a feature model to extract the feature matrix $\bm{F}^{(s)}\in\mathbb{R}^{d_{f}^{(S)}\times
    n_{s}}$, for $s=1,\dots,n_{S}$, where $d_{f}^{(S)}$ represents the dimension of
    the feature vector for each word, and $n_{s}$ represents the amount of words in
    sentence $s$. For extra clarification, the columns of $\bm{F}^{(s)}$ are feature
    vectors that correspond to the words in sentence $s$. As shown in Fig. [8](#S3.F8
    "Figure 8 ‣ 3.1.2 Feature Levels ‣ 3.1 Feature-Related Attention Mechanisms ‣
    3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning"),
    each feature matrix $\bm{F}^{(s)}$ is used as input for an attention model, which
    produces the context vector $\bm{c}^{(s)}$, for each $s=1,\dots,n_{S}$. No queries
    are used in this step, so it can be considered a self-attentive mechanism. The
    context vectors are essentially summaries of the words in the sentences. The matrix
    of context vectors $\bm{C}=[\bm{c}^{(1)},\dots,\bm{c}^{(n_{S})}]\in\mathbb{R}^{d_{v}^{(S)}\times
    n_{S}}$ is constructed by grouping all the obtained context vectors together as
    columns. Finally, attention is calculated using $\bm{C}$ as feature input, producing
    the representation of the entire document in the context vector $\bm{c}^{(D)}\in\mathbb{R}^{d_{v}^{(D)}}$,
    where $d_{v}^{(D)}$ is the dimension of the value vectors in the attention model
    for document representation (Attention Module[D] in Fig. [8](#S3.F8 "Figure 8
    ‣ 3.1.2 Feature Levels ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention
    Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")). This
    context vector can be used to classify the document, since it is essentially a
    summary of all the sentences (and therefore also the words) in the document.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [8](#S3.F8 "Figure 8 ‣ 3.1.2 Feature Levels ‣ 3.1 Feature-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning") 说明了层次注意力的结构。对于文档中的每一个句子，会生成一个句子表示 $\bm{c}^{(s)}\in\mathbb{R}^{d_{v}^{(S)}}$，其中
    $s=1,\dots,n_{S}$，$d_{v}^{(S)}$ 是用于句子表示的注意力模型中的值向量的维度（图 [8](#S3.F8 "Figure 8 ‣
    3.1.2 Feature Levels ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention
    Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning") 中的 Attention
    Module[S]）。这个表示是来自注意力模块的上下文向量，基本上总结了该句子。每个句子首先经过特征模型以提取特征矩阵 $\bm{F}^{(s)}\in\mathbb{R}^{d_{f}^{(S)}\times
    n_{s}}$，其中 $s=1,\dots,n_{S}$，$d_{f}^{(S)}$ 代表每个单词的特征向量的维度，$n_{s}$ 代表句子 $s$ 中单词的数量。为了进一步说明，$\bm{F}^{(s)}$
    的列是与句子 $s$ 中的单词对应的特征向量。如图 [8](#S3.F8 "Figure 8 ‣ 3.1.2 Feature Levels ‣ 3.1 Feature-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning") 所示，每个特征矩阵 $\bm{F}^{(s)}$ 被用作注意力模型的输入，生成上下文向量 $\bm{c}^{(s)}$，对于每个
    $s=1,\dots,n_{S}$。在这一步中没有使用查询，因此可以认为这是一个自注意力机制。这些上下文向量本质上是句子中单词的总结。上下文向量矩阵 $\bm{C}=[\bm{c}^{(1)},\dots,\bm{c}^{(n_{S})}]\in\mathbb{R}^{d_{v}^{(S)}\times
    n_{S}}$ 是通过将所有获得的上下文向量作为列组合在一起构造的。最后，使用 $\bm{C}$ 作为特征输入来计算注意力，生成整个文档的表示，即上下文向量
    $\bm{c}^{(D)}\in\mathbb{R}^{d_{v}^{(D)}}$，其中 $d_{v}^{(D)}$ 是文档表示的注意力模型中值向量的维度（图
    [8](#S3.F8 "Figure 8 ‣ 3.1.2 Feature Levels ‣ 3.1 Feature-Related Attention Mechanisms
    ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")
    中的 Attention Module[D]）。这个上下文向量可以用来对文档进行分类，因为它本质上是文档中所有句子（因此也包括所有单词）的总结。
- en: Multi-level models can be used in a variety of tasks. For example, in [[28](#bib.bib28)],
    hierarchical attention is used in a recommender system to model user preferences
    at the long-term level and the short-term level. Similarly, [[45](#bib.bib45)]
    proposes a hierarchical model for recommending social media images based on user
    preferences. Hierarchical attention has also been successfully applied in other
    domains. For example, [[46](#bib.bib46)] proposes to use hierarchical attention
    in a video action recognition model to capture motion information at the the long-term
    level and the short-term level. Furthermore, [[47](#bib.bib47)] proposes a hierarchical
    attention model for cross-domain sentiment classification. In [[48](#bib.bib48)],
    a hierarchical attention model for chatbot response generation is proposed. Lastly,
    using image data, [[49](#bib.bib49)] proposes a hierarchical attention model for
    crowd counting.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 多层次模型可以用于各种任务。例如，在[[28](#bib.bib28)]中，层次注意力被应用于推荐系统，以建模用户在长期和短期层次上的偏好。同样，[[45](#bib.bib45)]提出了一种层次模型，用于根据用户偏好推荐社交媒体图片。层次注意力也成功应用于其他领域。例如，[[46](#bib.bib46)]提出在视频动作识别模型中使用层次注意力，以捕捉长期和短期层次上的运动信息。此外，[[47](#bib.bib47)]提出了一种用于跨领域情感分类的层次注意力模型。在[[48](#bib.bib48)]中，提出了一种用于聊天机器人响应生成的层次注意力模型。最后，利用图像数据，[[49](#bib.bib49)]提出了一种用于人群计数的层次注意力模型。
- en: 3.1.3 Feature Representations
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.3 特征表示
- en: In a basic attention model, a single embedding or representation model is used
    to produce feature representations for the model to attend to. This is referred
    to as single-representational attention. Yet, one may also opt to incorporate
    multiple representations into the model. In [[50](#bib.bib50)], it is argued that
    allowing a model access to multiple embeddings can allow one to create even higher
    quality representations. Similarly, [[51](#bib.bib51)] incorporates multiple representations
    of the same book (textual, syntactic, semantic, visual etc.) into the feature
    model. Feature representations are an important part of the attention model, but
    attention can also be an important part of the feature model. The idea is to create
    a new representation by taking a weighted average of multiple representations,
    where the weights are determined via attention. This technique is referred to
    as multi-representational attention, and allows one to create so-called meta-embeddings.
    Suppose one wants to create a meta-embedding for a word $\bm{x}$ for which $E$
    embeddings $\bm{x}^{(e_{1})},\dots,\bm{x}^{(e_{E})}$ are available. Each embedding
    $\bm{x}^{(e_{i})}$ is of size $d_{e_{i}}$, for $i=1,\dots,E$. Since not all embeddings
    are of the same size, a transformation is performed to normalize the embedding
    dimensions. Using embedding-specific weight parameters, each embedding $\bm{x}^{(e_{i})}$
    is transformed into the size-normalized embedding $\bm{x}^{(t_{i})}\in\mathbb{R}^{d_{t}}$,
    where $d_{t}$ is the size of every transformed word embedding, as shown in ([21](#S3.E21
    "In 3.1.3 Feature Representations ‣ 3.1 Feature-Related Attention Mechanisms ‣
    3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在基本的注意力模型中，使用单一的嵌入或表示模型来生成模型需要关注的特征表示。这被称为单一表示注意力。然而，也可以选择将多个表示集成到模型中。在[[50](#bib.bib50)]中，认为允许模型访问多个嵌入可以生成更高质量的表示。同样，[[51](#bib.bib51)]将相同书籍的多个表示（文本、句法、语义、视觉等）整合到特征模型中。特征表示是注意力模型的重要组成部分，但注意力也可以是特征模型的重要部分。其思路是通过对多个表示进行加权平均来创建新的表示，其中权重通过注意力确定。这种技术被称为多表示注意力，并允许创建所谓的元嵌入。假设要为一个词$\bm{x}$创建元嵌入，并且有$E$个嵌入$\bm{x}^{(e_{1})},\dots,\bm{x}^{(e_{E})}$。每个嵌入$\bm{x}^{(e_{i})}$的大小为$d_{e_{i}}$，其中$i=1,\dots,E$。由于并非所有嵌入的大小相同，因此需要进行转换以规范化嵌入维度。使用嵌入特定的权重参数，每个嵌入$\bm{x}^{(e_{i})}$被转换为大小规范化的嵌入$\bm{x}^{(t_{i})}\in\mathbb{R}^{d_{t}}$，其中$d_{t}$是每个转换后的词嵌入的大小，如在([21](#S3.E21
    "在3.1.3特征表示 ‣ 3.1特征相关注意力机制 ‣ 3 注意力分类 ‣ 深度学习中的注意力机制通用调查"))中所示。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{x}^{(t_{i})}}{\scriptscriptstyle
    d_{t}\times 1}=\stackunder{\bm{W}_{e_{i}}}{\scriptscriptstyle d_{t}\times d_{e_{i}}}\times\stackunder{\bm{x}^{(e_{i})}}{\scriptscriptstyle
    d_{e_{i}}\times 1}+\stackunder{\bm{b}_{e_{i}}}{\scriptscriptstyle d_{t}\times
    1},$ |  | (21) |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{x}^{(t_{i})}}{\scriptscriptstyle
    d_{t}\times 1}=\stackunder{\bm{W}_{e_{i}}}{\scriptscriptstyle d_{t}\times d_{e_{i}}}\times\stackunder{\bm{x}^{(e_{i})}}{\scriptscriptstyle
    d_{e_{i}}\times 1}+\stackunder{\bm{b}_{e_{i}}}{\scriptscriptstyle d_{t}\times
    1},$ |  | (21) |'
- en: where $\bm{W}_{e_{i}}\in\mathbb{R}^{d_{t}\times d_{e_{i}}}$, and $\bm{b}_{e_{i}}\in\mathbb{R}^{d_{t}}$
    are trainable, embedding-specific weights matrices. The final embedding $\bm{x}^{(e)}\in\mathbb{R}^{d_{t}}$
    is a weighted average of the previously calculated transformed representations,
    as shown in ([22](#S3.E22 "In 3.1.3 Feature Representations ‣ 3.1 Feature-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning")).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\bm{W}_{e_{i}}\in\mathbb{R}^{d_{t}\times d_{e_{i}}}$ 和 $\bm{b}_{e_{i}}\in\mathbb{R}^{d_{t}}$
    是可训练的嵌入特定权重矩阵。最终的嵌入 $\bm{x}^{(e)}\in\mathbb{R}^{d_{t}}$ 是之前计算的变换表示的加权平均，如在 ([22](#S3.E22
    "在 3.1.3 特征表示 ‣ 3.1 特征相关注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的综述"))中所示。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{x}^{(e)}}{\scriptscriptstyle d_{t}\times
    1}=\sum_{i=1}^{E}\stackunder{a_{i}}{\scriptscriptstyle 1\times 1}\times\stackunder{\bm{x}^{(t_{i})}}{\scriptscriptstyle
    d_{t}\times 1}.$ |  | (22) |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{x}^{(e)}}{\scriptscriptstyle d_{t}\times
    1}=\sum_{i=1}^{E}\stackunder{a_{i}}{\scriptscriptstyle 1\times 1}\times\stackunder{\bm{x}^{(t_{i})}}{\scriptscriptstyle
    d_{t}\times 1}.$ |  | (22) |'
- en: The final representation $\bm{x}^{(e)}$ can be interpreted as the context vector
    from an attention model, meaning that the weights $a_{1},\dots,a_{E}\in\mathbb{R}^{1}$
    are attention weights. Attention can be calculated as normally, where the columns
    of the features matrix $\bm{F}$ are the transformed representations $\bm{x}^{(t_{1})},\dots,\bm{x}^{(t_{E})}$.
    The query in this case can be ignored since it is constant in all cases. Essentially,
    the query is “Which representations are the most important?” in every situation.
    As such, this is a self-attentive mechanism.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 最终表示 $\bm{x}^{(e)}$ 可以解释为来自注意力模型的上下文向量，这意味着权重 $a_{1},\dots,a_{E}\in\mathbb{R}^{1}$
    是注意力权重。注意力可以像往常一样计算，其中特征矩阵 $\bm{F}$ 的列是变换后的表示 $\bm{x}^{(t_{1})},\dots,\bm{x}^{(t_{E})}$。在这种情况下，查询可以忽略，因为它在所有情况下都是常量。本质上，查询是“在每种情况下哪些表示是最重要的？”。因此，这是一个自注意力机制。
- en: While an interesting idea, applications of multi-representational attention
    are limited. One example of the application of this technique is found in [[52](#bib.bib52)],
    where a multi-representational attention mechanism has been applied to generate
    multi-lingual meta-embeddings. Another example is [[53](#bib.bib53)], where a
    multi-representational text classification model is proposed that incorporates
    different representations of the same text. For example, the proposed model uses
    embeddings from part-of-speech tagging, named entity recognizers, and character-level
    and word-level embeddings.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是一个有趣的想法，但多表示注意力的应用还是有限的。这种技术的一个应用示例见于[[52](#bib.bib52)]，在该示例中，多表示注意力机制被应用于生成多语言的元嵌入。另一个示例是[[53](#bib.bib53)]，在该示例中，提出了一种多表示文本分类模型，该模型结合了相同文本的不同表示。例如，提出的模型使用了词性标注、命名实体识别器以及字符级和词级嵌入的嵌入。
- en: 3.2 General Attention Mechanisms
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 一般注意力机制
- en: 'This major category consists of attention mechanisms that can be applied in
    any type of attention model. The structure of this component can be broken down
    into the following sub-aspects: the attention score function, the attention alignment,
    and attention dimensionality.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这个主要类别包括可以应用于任何类型的注意力模型的注意力机制。该组件的结构可以分解为以下几个子方面：注意力评分函数、注意力对齐和注意力维度。
- en: 'TABLE II: Overview of score function ($\text{score}(\bm{q},\bm{k}_{l})$) forms.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：评分函数 ($\text{score}(\bm{q},\bm{k}_{l})$) 形式概述。
- en: '| Name | Function | Parameters |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 功能 | 参数 |'
- en: '| --- | --- | --- |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Additive (Concatenate) [[3](#bib.bib3)] | $\bm{w}^{T}\times\text{act}(\bm{W}_{1}\times\bm{q}+\bm{W}_{2}\times\bm{k}_{l})+\bm{b})$
    | <math   alttext="\bm{w}\in\mathbb{R}^{d_{w}}\newline \bm{W}_{1}\in\mathbb{R}^{d_{w}\times
    d_{q}}\newline'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '| 加法（连接） [[3](#bib.bib3)] | $\bm{w}^{T}\times\text{act}(\bm{W}_{1}\times\bm{q}+\bm{W}_{2}\times\bm{k}_{l})+\bm{b})$
    | <math   alttext="\bm{w}\in\mathbb{R}^{d_{w}}\newline \bm{W}_{1}\in\mathbb{R}^{d_{w}\times
    d_{q}}\newline'
- en: \bm{W}_{2}\in\mathbb{R}^{d_{w}\times d_{k}}\newline
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: \bm{W}_{2}\in\mathbb{R}^{d_{w}\times d_{k}}\newline
- en: \bm{b}\in\mathbb{R}^{d_{w}}" display="inline"><semantics ><mrow ><mi >𝒘</mi><mo
    >∈</mo><mrow ><msup ><mi >ℝ</mi><msub ><mi >d</mi><mi >w</mi></msub></msup><mo
    lspace="0em" rspace="0em"  >​</mo><msub ><mi >𝑾</mi><mn >1</mn></msub></mrow><mo
    >∈</mo><mrow ><msup ><mi >ℝ</mi><mrow ><msub ><mi >d</mi><mi >w</mi></msub><mo
    lspace="0.222em" rspace="0.222em"  >×</mo><msub ><mi >d</mi><mi >q</mi></msub></mrow></msup><mo
    lspace="0em" rspace="0em"  >​</mo><msub ><mi >𝑾</mi><mn >2</mn></msub></mrow><mo
    >∈</mo><mrow ><msup ><mi >ℝ</mi><mrow ><msub ><mi >d</mi><mi >w</mi></msub><mo
    lspace="0.222em" rspace="0.222em"  >×</mo><msub ><mi >d</mi><mi >k</mi></msub></mrow></msup><mo
    lspace="0em" rspace="0em"  >​</mo><mi >𝒃</mi></mrow><mo >∈</mo><msup ><mi >ℝ</mi><msub
    ><mi >d</mi><mi >w</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content"
    ><apply ><apply ><ci  >𝒘</ci><apply ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >ℝ</ci><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑑</ci><ci >𝑤</ci></apply></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑾</ci><cn type="integer"  >1</cn></apply></apply></apply><apply
    ><apply ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci >ℝ</ci><apply
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑑</ci><ci >𝑤</ci></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑑</ci><ci >𝑞</ci></apply></apply></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑾</ci><cn type="integer"  >2</cn></apply></apply></apply><apply
    ><apply ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci >ℝ</ci><apply
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑑</ci><ci >𝑤</ci></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑑</ci><ci >𝑘</ci></apply></apply></apply><ci
    >𝒃</ci></apply></apply><apply ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >ℝ</ci><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑑</ci><ci >𝑤</ci></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\bm{w}\in\mathbb{R}^{d_{w}}\newline \bm{W}_{1}\in\mathbb{R}^{d_{w}\times
    d_{q}}\newline \bm{W}_{2}\in\mathbb{R}^{d_{w}\times d_{k}}\newline \bm{b}\in\mathbb{R}^{d_{w}}</annotation></semantics></math>
    |
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: $\bm{b}\in\mathbb{R}^{d_{w}}$，$\bm{W}_{1}\in\mathbb{R}^{d_{w}\times d_{q}}$，$\bm{W}_{2}\in\mathbb{R}^{d_{w}\times
    d_{k}}$，$\bm{b}\in\mathbb{R}^{d_{w}}$ |
- en: '| Multiplicative (Dot-Product) [[4](#bib.bib4)] | $\bm{q}^{T}\times\bm{k}_{l}$
    | - |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 乘法（点积） [[4](#bib.bib4)] | $\bm{q}^{T}\times\bm{k}_{l}$ | - |'
- en: '| Scaled Multiplicative [[13](#bib.bib13)] | $\frac{\bm{q}^{T}\times\bm{k}_{l}}{\sqrt{d_{k}}}$
    | - |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 缩放的乘法 [[13](#bib.bib13)] | $\frac{\bm{q}^{T}\times\bm{k}_{l}}{\sqrt{d_{k}}}$
    | - |'
- en: '| General [[4](#bib.bib4)] | $\bm{k}_{l}^{T}\times\bm{W}\times\bm{q}$ | $\bm{W}\in\mathbb{R}^{d_{k}\times
    d_{q}}$ |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 通用形式 [[4](#bib.bib4)] | $\bm{k}_{l}^{T}\times\bm{W}\times\bm{q}$ | $\bm{W}\in\mathbb{R}^{d_{k}\times
    d_{q}}$ |'
- en: '| Biased General [[54](#bib.bib54)] | $\bm{k}_{l}^{T}\times(\bm{W}\times\bm{q}+\bm{b})$
    | $\bm{W}\in\mathbb{R}^{d_{k}\times d_{q}}\newline \bm{b}\in\mathbb{R}^{d_{k}}$
    |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 带偏差的通用形式 [[54](#bib.bib54)] | $\bm{k}_{l}^{T}\times(\bm{W}\times\bm{q}+\bm{b})$
    | $\bm{W}\in\mathbb{R}^{d_{k}\times d_{q}}\newline \bm{b}\in\mathbb{R}^{d_{k}}$
    |'
- en: '| Activated General [[34](#bib.bib34)] | $\text{act}(\bm{k}_{l}^{T}\times\bm{W}\times\bm{q}+b)$
    | $\bm{W}\in\mathbb{R}^{d_{k}\times d_{q}},\newline b\in\mathbb{R}^{1}$ |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 激活的通用形式 [[34](#bib.bib34)] | $\text{act}(\bm{k}_{l}^{T}\times\bm{W}\times\bm{q}+b)$
    | $\bm{W}\in\mathbb{R}^{d_{k}\times d_{q}},\newline b\in\mathbb{R}^{1}$ |'
- en: '| Similarity [[55](#bib.bib55)] | $\text{similarity}(\bm{q},\bm{k}_{l})$ |
    - |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 相似度 [[55](#bib.bib55)] | $\text{similarity}(\bm{q},\bm{k}_{l})$ | - |'
- en: 3.2.1 Attention Scoring
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 注意力评分
- en: The attention score function is a crucial component in how attention is calculated.
    Various approaches have been developed that each have their own advantages and
    disadvantages. An overview of these functions is provided in Table [II](#S3.T2
    "TABLE II ‣ 3.2 General Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General
    Survey on Attention Mechanisms in Deep Learning"). Each row of Table [II](#S3.T2
    "TABLE II ‣ 3.2 General Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General
    Survey on Attention Mechanisms in Deep Learning") presents a possible form for
    the function $\text{score}(\bm{q},\bm{k}_{l})$, as seen in ([23](#S3.E23 "In 3.2.1
    Attention Scoring ‣ 3.2 General Attention Mechanisms ‣ 3 Attention Taxonomy ‣
    A General Survey on Attention Mechanisms in Deep Learning")), where $\bm{q}$ is
    the query vector, and $\bm{k}_{l}$ is the $l$th column of $\bm{K}$. Note that
    the score functions presented in this section can be more efficiently calculated
    in matrix form using $\bm{K}$ instead of each column separately. Nevertheless,
    the score functions are presented using $\bm{k}_{l}$ to more clearly illustrate
    the relation between a key and query.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力得分函数是计算注意力的关键组成部分。已经开发了各种方法，每种方法都有其自身的优点和缺点。这些函数的概述见表[II](#S3.T2 "TABLE II
    ‣ 3.2 General Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on
    Attention Mechanisms in Deep Learning")。表[II](#S3.T2 "TABLE II ‣ 3.2 General Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning")的每一行展示了函数$\text{score}(\bm{q},\bm{k}_{l})$的一个可能形式，如([23](#S3.E23
    "In 3.2.1 Attention Scoring ‣ 3.2 General Attention Mechanisms ‣ 3 Attention Taxonomy
    ‣ A General Survey on Attention Mechanisms in Deep Learning"))中所示，其中$\bm{q}$是查询向量，$\bm{k}_{l}$是$\bm{K}$的第$l$列。请注意，本节中展示的得分函数可以使用矩阵形式的$\bm{K}$更高效地计算，而不是分别计算每一列。尽管如此，为了更清楚地说明键和查询之间的关系，得分函数仍以$\bm{k}_{l}$的形式展示。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{e_{l}}{\scriptscriptstyle 1\times 1}=\text{score}(\stackunder{\bm{q}}{\scriptscriptstyle
    d_{q}\times 1},\stackunder{\bm{k}_{l}}{\scriptscriptstyle d_{k}\times 1}).$ |  |
    (23) |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{e_{l}}{\scriptscriptstyle 1\times 1}=\text{score}(\stackunder{\bm{q}}{\scriptscriptstyle
    d_{q}\times 1},\stackunder{\bm{k}_{l}}{\scriptscriptstyle d_{k}\times 1}).$ |  |
    (23) |'
- en: Due to their simplicity, the most popular choices for the score function are
    the concatenate score function [[3](#bib.bib3)] and the multiplicative score function
    [[4](#bib.bib4)]. The multiplicative score function has the advantage of being
    computationally inexpensive due to highly optimized vector operations. However,
    the multiplicative function may produce non-optimal results when the dimension
    $d_{k}$ is too large [[56](#bib.bib56)]. When $d_{k}$ is large, the dot-product
    between $\bm{q}$ and $\bm{k}_{l}$ can grow large in magnitude. To illustrate this,
    in [[13](#bib.bib13)], an example is used where the elements of $\bm{q}$ and $\bm{k}_{l}$
    are all normally distributed with a mean equal to zero, and a variance equal to
    one. Then, the dot-product of the vectors has a variance of $d_{k}$. A higher
    variance means a higher chance of numbers that are large in magnitude. When the
    softmax function of the alignment step is then applied using these large numbers,
    the gradient will become very small, meaning the model will have trouble converging
    [[13](#bib.bib13)]. To adjust for this, [[13](#bib.bib13)] proposes to scale the
    multiplicative function by the factor $\frac{1}{\sqrt{d_{k}}}$, producing the
    scaled multiplicative score function.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其简单性，最受欢迎的得分函数选择是连接得分函数[[3](#bib.bib3)]和乘法得分函数[[4](#bib.bib4)]。乘法得分函数由于高度优化的向量运算，具有计算成本低的优点。然而，当维度$d_{k}$过大时，乘法函数可能会产生非最优结果[[56](#bib.bib56)]。当$d_{k}$很大时，$\bm{q}$和$\bm{k}_{l}$之间的点积可能会变得非常大。为了说明这一点，在[[13](#bib.bib13)]中，举了一个例子，其中$\bm{q}$和$\bm{k}_{l}$的元素都是正态分布的，均值为零，方差为一。然后，向量的点积具有$d_{k}$的方差。方差越大，数值越可能很大。当在对齐步骤中应用这些大数值的softmax函数时，梯度会变得非常小，这意味着模型在收敛时会遇到困难[[13](#bib.bib13)]。为此，[[13](#bib.bib13)]建议将乘法函数缩放因子调整为$\frac{1}{\sqrt{d_{k}}}$，以产生缩放后的乘法得分函数。
- en: In [[4](#bib.bib4)], the multiplicative score function is extended by introducing
    a weights matrix $\bm{W}$. This form, referred to as the general score function,
    allows for an extra transformation of $\bm{k}_{l}$. The biased general score function
    [[54](#bib.bib54)] is a further extension of the general function that introduces
    a bias weight vector $\bm{b}$. A final extension on this function named the activated
    general score function is introduced in [[34](#bib.bib34)], and includes the use
    of both a bias weight $b$, and an activation function $\text{act}()$.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[4](#bib.bib4)]中，通过引入权重矩阵$\bm{W}$扩展了乘法评分函数。这种形式被称为一般评分函数，它允许对$\bm{k}_{l}$进行额外的变换。偏置一般评分函数[[54](#bib.bib54)]是一般函数的进一步扩展，引入了偏置权重向量$\bm{b}$。最终扩展的函数被称为激活一般评分函数，在[[34](#bib.bib34)]中引入，它包括使用偏置权重$b$和激活函数$\text{act}()$。
- en: The previously presented score functions are all based on determining a type
    of similarity between the key vector and the query vector. As such, more typical
    similarity measures, such as the Euclidean (L[2]) distance and cosine similarity,
    can also be implemented [[55](#bib.bib55)]. These scoring methods are summarized
    under the similarity score function which is represented by the $\text{similarity}()$
    function.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 之前介绍的评分函数都基于确定键向量和查询向量之间的相似度。因此，更典型的相似度度量，如欧几里得（L[2]）距离和余弦相似度，也可以实现[[55](#bib.bib55)]。这些评分方法被总结为相似度评分函数，由$\text{similarity}()$函数表示。
- en: There typically is no common usage across domains regarding score functions.
    The choice of score function for a particular task is most often based on empirical
    experiments. However, there are exceptions when, for example, efficiency is vital.
    In models where this is the case, the multiplicative or scaled multiplicative
    score functions are typically the best choice. An example of this is the Transformer
    model, which is generally computationally expensive.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，不同领域的评分函数没有共同的使用标准。对特定任务选择评分函数通常基于经验实验。然而，当效率至关重要时，存在例外。在这种情况下，乘法或缩放乘法评分函数通常是最佳选择。例如，Transformer模型通常计算开销很大。
- en: 3.2.2 Attention Alignment
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 注意力对齐
- en: 'The attention alignment is the step after the attention scoring. This alignment
    process directly determines which parts of the input data the model will attend
    to. The alignment function is denoted as $\text{align}()$ and has various forms.
    The $\text{align}()$ function takes as input the previously calculated attention
    score vector $\bm{e}$ and calculates for each element $e_{l}$ of $\bm{e}$ the
    attention weight $a_{l}$. These attention weights can then be used to create the
    context vector $\bm{c}$ by taking a weighted average of the value vectors $\bm{v}_{1},\dots,\bm{v}_{n_{f}}$:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力对齐是注意力评分之后的步骤。这个对齐过程直接决定了模型将关注输入数据的哪些部分。对齐函数表示为$\text{align}()$，并有多种形式。$\text{align}()$函数以先前计算的注意力评分向量$\bm{e}$为输入，计算$\bm{e}$的每个元素$e_{l}$的注意力权重$a_{l}$。这些注意力权重随后可以用来通过对值向量$\bm{v}_{1},\dots,\bm{v}_{n_{f}}$进行加权平均来创建上下文向量$\bm{c}$：
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{c}}{\scriptscriptstyle d_{v}\times
    1}=\sum^{n_{f}}_{l=1}\stackunder{a_{l}}{\scriptscriptstyle 1\times 1}\times\stackunder{\bm{v}_{l}}{\scriptscriptstyle
    d_{v}\times 1}.$ |  | (24) |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{c}}{\scriptscriptstyle d_{v}\times
    1}=\sum^{n_{f}}_{l=1}\stackunder{a_{l}}{\scriptscriptstyle 1\times 1}\times\stackunder{\bm{v}_{l}}{\scriptscriptstyle
    d_{v}\times 1}.$ |  | (24) |'
- en: The most popular alignment method to calculate these weights is a simple softmax
    function, as depicted in ([25](#S3.E25 "In 3.2.2 Attention Alignment ‣ 3.2 General
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning")).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 计算这些权重的最流行方法是简单的softmax函数，如([25](#S3.E25 "在3.2.2注意力对齐 ‣ 3.2 一般注意力机制 ‣ 3 注意力分类
    ‣ 深度学习中的注意力机制概述"))所示。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{a_{l}}{\scriptscriptstyle 1\times 1}=\text{align}(\stackunder{e_{l}}{\scriptscriptstyle
    1\times 1};\stackunder{\bm{e}}{\scriptscriptstyle n_{f}\times 1})=\frac{\text{exp}(e_{l})}{\sum^{n_{f}}_{j=1}\text{exp}(e_{j})}.$
    |  | (25) |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{a_{l}}{\scriptscriptstyle 1\times 1}=\text{align}(\stackunder{e_{l}}{\scriptscriptstyle
    1\times 1};\stackunder{\bm{e}}{\scriptscriptstyle n_{f}\times 1})=\frac{\text{exp}(e_{l})}{\sum^{n_{f}}_{j=1}\text{exp}(e_{j})}.$
    |  | (25) |'
- en: This alignment method is often referred to as soft alignment in computer vision
    settings [[8](#bib.bib8)], or global alignment for sequence data [[4](#bib.bib4)].
    Nevertheless, both these terms represent the same function and can be interpreted
    similarly. Soft/global alignment can be interpreted as the model attending to
    all feature vectors. For example, the model attends to all regions in an image,
    or all words in a sentence. Even though the attention model generally does focus
    more on specific parts of the input, every part of the input will receive at least
    some amount of attention due to the nature of the softmax function. Furthermore,
    an advantage of the softmax function is that it introduces a probabilistic interpretation
    to the input vectors. This allows one to easily analyze which parts of the input
    are important to the output predictions.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这种对齐方法在计算机视觉环境中通常被称为**软对齐**[[8](#bib.bib8)]，或者对于序列数据被称为**全局对齐**[[4](#bib.bib4)]。然而，这两个术语都表示相同的功能，并且可以类似地进行解释。软/全局对齐可以被解释为模型关注所有特征向量。例如，模型关注图像中的所有区域，或者句子中的所有单词。尽管注意力模型通常确实更关注输入的特定部分，但由于softmax函数的特性，输入的每一部分至少会受到一些关注。此外，softmax函数的一个优点是它为输入向量引入了概率解释。这使得人们可以轻松分析输入的哪些部分对输出预测是重要的。
- en: 'In contrast to soft/global alignment, other methods aim to achieve a more focused
    form of alignment. For example, hard alignment [[8](#bib.bib8)], also known as
    hard attention or non-deterministic attention, is an alignment type that forces
    the attention model to focus on exactly one feature vector. Firstly, this method
    implements the softmax function in the exact same way as global alignment. However,
    the outputs $a_{1},\dots,a_{n_{f}}$ are not used as weights for the context vector
    calculation. Instead, these values are used as probabilities to draw the choice
    of the one value vector from. A value $m\in\mathbb{R}^{1}$ is drawn from a multinomial
    distribution with $a_{1},\dots,a_{n_{f}}$ as parameters for the probabilities.
    Then, the context vector is simply defined as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 相对于软/全局对齐，其他方法旨在实现更集中形式的对齐。例如，**硬对齐**[[8](#bib.bib8)]，也被称为**硬注意力**或**非确定性注意力**，是一种对齐类型，强制注意力模型专注于一个特定的特征向量。首先，这种方法以与全局对齐完全相同的方式实现softmax函数。然而，输出$a_{1},\dots,a_{n_{f}}$不会被用作上下文向量计算的权重。相反，这些值作为概率来从中选择一个值向量。一个值$m\in\mathbb{R}^{1}$是从一个多项分布中抽取的，其中$a_{1},\dots,a_{n_{f}}$作为概率的参数。然后，上下文向量简单地定义如下：
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{c}}{\scriptscriptstyle d_{v}\times
    1}=\stackunder{\bm{v}_{m}}{\scriptscriptstyle d_{v}\times 1}.$ |  | (26) |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{c}}{\scriptscriptstyle d_{v}\times
    1}=\stackunder{\bm{v}_{m}}{\scriptscriptstyle d_{v}\times 1}.$ |  | (26) |'
- en: 'Hard alignment is typically more efficient at inference compared to soft alignment.
    On the other hand, the main disadvantage of hard attention is that, due to the
    stochastic alignment of attention, the training of the model cannot be done via
    the regular backpropagation method. Instead, simulation and sampling, or reinforcement
    learning [[57](#bib.bib57)] are required to calculate the gradient at the hard
    attention layer. As such, soft/global attention is generally preferred. However,
    a compromise can be made in certain situations. Local alignment [[4](#bib.bib4)]
    is a method that implements a softmax distribution, similarly to soft/global alignment.
    But, the softmax distribution is calculated based only on a subset of the inputs.
    This method is generally used in combination with sequence data. One has to specify
    a variable $p\in\mathbb{R}^{1}$ that determines the position of the region. Feature
    vectors close to $p$ will be attended to by the model, and vectors too far from
    $p$ will be ignored. The size of the subset will be determined by the variable
    $D\in\mathbb{R}^{1}$. Summarizing, the attention model will apply a softmax function
    on the attention scores in the subset $[p-D,p+D]$. In other words, a window is
    placed on the input and soft/global attention is calculated within that window:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 与软对齐相比，硬对齐在推断过程中通常更高效。另一方面，硬注意力的主要缺点是，由于注意力的随机对齐，模型的训练不能通过常规的反向传播方法进行。相反，需要通过模拟和采样或强化学习
    [[57](#bib.bib57)] 来计算硬注意力层的梯度。因此，软/全局注意力通常是首选。然而，在某些情况下可以做出妥协。局部对齐 [[4](#bib.bib4)]
    是一种实现类似于软/全局对齐的 softmax 分布的方法。但是，softmax 分布仅基于输入的一个子集来计算。此方法通常与序列数据结合使用。需要指定一个变量
    $p\in\mathbb{R}^{1}$ 来确定区域的位置。接近 $p$ 的特征向量将被模型关注，而距离 $p$ 太远的向量将被忽略。子集的大小将由变量 $D\in\mathbb{R}^{1}$
    确定。总结来说，注意力模型将在子集 $[p-D,p+D]$ 内的注意力分数上应用 softmax 函数。换句话说，将窗口放在输入上，并在该窗口内计算软/全局注意力：
- en: '|  | $\setstackgap{L}{8pt}\stackunder{a_{l}}{\scriptscriptstyle 1\times 1}=\text{align}(\stackunder{e_{l}}{\scriptscriptstyle
    1\times 1};\stackunder{\bm{e}}{\scriptscriptstyle n_{f}\times 1})=\frac{\text{exp}(e_{l})}{\sum^{p+D}_{j=p-D}\text{exp}(e_{j})}.$
    |  | (27) |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{a_{l}}{\scriptscriptstyle 1\times 1}=\text{align}(\stackunder{e_{l}}{\scriptscriptstyle
    1\times 1};\stackunder{\bm{e}}{\scriptscriptstyle n_{f}\times 1})=\frac{\text{exp}(e_{l})}{\sum^{p+D}_{j=p-D}\text{exp}(e_{j})}.$
    |  | (27) |'
- en: 'The question that remains is how to determine the location parameter $p$. The
    first method is referred to as monotonic alignment. This straightforward method
    entails simply setting the location parameter equal to the location of the prediction
    in the output sequence. Another method of determining the position of the region
    is referred to as predictive alignment. As the name entails, the model attempts
    to actually predict the location of interest in the sequence:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的问题是如何确定位置参数 $p$。第一种方法称为单调对齐。这种简单的方法是将位置参数直接设置为输出序列中预测的位置。另一种确定区域位置的方法称为预测对齐。顾名思义，模型尝试实际预测序列中感兴趣的位置：
- en: '|  | $\setstackgap{L}{8pt}\stackunder{p}{\scriptscriptstyle 1\times 1}=\stackunder{S}{\scriptscriptstyle
    1\times 1}\times\text{sigmoid}(\stackunder{\bm{w}_{p}^{T}}{\scriptscriptstyle
    1\times d_{p}}\times\text{tanh}(\stackunder{\bm{W}_{p}}{\scriptscriptstyle d_{p}\times
    d_{q}}\times\stackunder{\bm{q}}{\scriptscriptstyle d_{q}\times 1})),$ |  | (28)
    |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{p}{\scriptscriptstyle 1\times 1}=\stackunder{S}{\scriptscriptstyle
    1\times 1}\times\text{sigmoid}(\stackunder{\bm{w}_{p}^{T}}{\scriptscriptstyle
    1\times d_{p}}\times\text{tanh}(\stackunder{\bm{W}_{p}}{\scriptscriptstyle d_{p}\times
    d_{q}}\times\stackunder{\bm{q}}{\scriptscriptstyle d_{q}\times 1})),$ |  | (28)
    |'
- en: 'where $S\in\mathbb{R}^{1}$ is the length of the input sequence, and $\bm{w}_{p}\in\mathbb{R}^{d_{p}}$
    and $\bm{W}_{p}\in\mathbb{R}^{d_{p}\times d_{q}}$ are both trainable weights parameters.
    The sigmoid function multiplied by $S$ makes sure that $p$ is in the range $[0,S]$.
    Additionally, in [[4](#bib.bib4)], it is recommended to add an additional term
    to the alignment function to favor alignment around $p$:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $S\in\mathbb{R}^{1}$ 是输入序列的长度，而 $\bm{w}_{p}\in\mathbb{R}^{d_{p}}$ 和 $\bm{W}_{p}\in\mathbb{R}^{d_{p}\times
    d_{q}}$ 都是可训练的权重参数。通过将 sigmoid 函数乘以 $S$ 可以确保 $p$ 的值在范围 $[0,S]$ 内。此外，在 [[4](#bib.bib4)]
    中，建议在对齐函数中添加一个额外的项，以偏向于 $p$ 附近的对齐：
- en: '|  | $\setstackgap{L}{8pt}\stackunder{a_{l}}{\scriptscriptstyle 1\times 1}=\text{align}(\stackunder{e_{l}}{\scriptscriptstyle
    1\times 1};\stackunder{\bm{e}}{\scriptscriptstyle n_{f}\times 1})\text{exp}(-\frac{(l-p)^{2})}{2\sigma^{2}}),$
    |  | (29) |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{a_{l}}{\scriptscriptstyle 1\times 1}=\text{align}(\stackunder{e_{l}}{\scriptscriptstyle
    1\times 1};\stackunder{\bm{e}}{\scriptscriptstyle n_{f}\times 1})\text{exp}(-\frac{(l-p)^{2})}{2\sigma^{2}}),$
    |  | (29) |'
- en: where $\sigma\in\mathbb{R}^{1}$ is empirically set equal to $\frac{D}{2}$ according
    to [[4](#bib.bib4)]. Another proposed method for compromising between soft and
    hard alignment is reinforced alignment [[58](#bib.bib58)]. Similarly to local
    alignment, a subset of the feature vectors is determined, for which soft alignment
    is calculated. However, instead of using a window to determine the subset, reinforced
    alignment uses a reinforcement learning agent [[57](#bib.bib57)], similarly to
    hard alignment, to choose the subset of feature vectors. The attention calculation
    based on these chosen feature vectors is the same as regular soft alignment.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\sigma\in\mathbb{R}^{1}$ 根据 [[4](#bib.bib4)] 实证设置为 $\frac{D}{2}$。另一种在软对齐和硬对齐之间妥协的方法是强化对齐
    [[58](#bib.bib58)]。类似于局部对齐，这种方法确定了特征向量的一个子集，并对其计算软对齐。然而，与使用窗口确定子集的方法不同，强化对齐使用强化学习代理
    [[57](#bib.bib57)]，类似于硬对齐，以选择特征向量的子集。基于这些选择的特征向量的注意力计算与常规软对齐相同。
- en: Soft alignment is often regarded as the standard alignment function for attention
    models in practically every domain. Yet, the other alignment methods have also
    seen interesting uses in various domains. For example, hard attention is used
    in [[59](#bib.bib59)] for the task of visual question answering. In [[60](#bib.bib60)],
    both soft and hard attention are used in a graph attention model for multi-agent
    game abstraction. Similarly, in [[61](#bib.bib61)], both global and local alignment
    are used for review rating predictions. Reinforced alignment has been employed
    in combination with a co-attention structure in [[62](#bib.bib62)] for the task
    of aspect sentiment classification. In [[63](#bib.bib63)], reinforced alignment
    is used for the task of person re-identification using surveillance images.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 软对齐通常被认为是几乎所有领域中注意力模型的标准对齐函数。然而，其他对齐方法在不同领域中也展现了有趣的应用。例如，硬注意力在 [[59](#bib.bib59)]
    中用于视觉问答任务。在 [[60](#bib.bib60)] 中，软注意力和硬注意力都用于多智能体游戏抽象的图注意力模型。同样，在 [[61](#bib.bib61)]
    中，全球对齐和局部对齐都用于评论评分预测。强化对齐已在 [[62](#bib.bib62)] 中与共注意力结构结合，用于方面情感分类任务。在 [[63](#bib.bib63)]
    中，强化对齐用于利用监控图像进行人员重新识别任务。
- en: 3.2.3 Attention Dimensionality
  id: totrans-164
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 注意力维度
- en: 'All previous model specifications of attention use a scalar weight $a_{l}$
    for each value vector $\bm{v}_{l}$. This technique is referred to as single-dimensional
    attention. However, instead of determining a single attention score and weight
    for the entire vector, [[64](#bib.bib64)] proposes to calculate weights for every
    single feature in those vectors separately. This technique is referred to as multi-dimensional
    attention, since the attention weights now become higher dimensional vectors.
    The idea is that the model no longer has to attend to entire vectors, but it can
    instead pick and choose specific elements from those vectors. More specifically,
    attention is calculated for each dimension. As such, the model must create a vector
    of attention weights $\bm{a}_{l}\in\mathbb{R}^{d_{v}}$ for each value vector $\bm{v}_{l}\in\mathbb{R}^{d_{v}}$.
    The context vector can then be calculated by summing the element-wise multiplications
    ($\circ$) of the value vectors $\bm{v}_{1},\dots,\bm{v}_{n_{f}}\in\mathbb{R}^{d_{v}}$
    and the corresponding attention weight vectors $\bm{a}_{1},\dots,\bm{a}_{n_{f}}\in\mathbb{R}^{d_{v}}$,
    as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 所有之前的注意力模型规范都使用标量权重 $a_{l}$ 为每个值向量 $\bm{v}_{l}$ 赋值。这种技术被称为单维注意力。然而，[[64](#bib.bib64)]
    提出了计算这些向量中每个特征的权重的方法。这种技术被称为多维注意力，因为注意力权重现在变成了更高维的向量。其核心思想是模型不再需要关注整个向量，而是可以从这些向量中挑选特定的元素。更具体地说，注意力是为每个维度计算的。因此，模型必须为每个值向量
    $\bm{v}_{l}\in\mathbb{R}^{d_{v}}$ 创建一个注意力权重向量 $\bm{a}_{l}\in\mathbb{R}^{d_{v}}$。然后，可以通过对值向量
    $\bm{v}_{1},\dots,\bm{v}_{n_{f}}\in\mathbb{R}^{d_{v}}$ 和相应的注意力权重向量 $\bm{a}_{1},\dots,\bm{a}_{n_{f}}\in\mathbb{R}^{d_{v}}$
    进行逐元素乘法 ($\circ$) 并求和来计算上下文向量，如下所示：
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{c}}{\scriptscriptstyle d_{v}\times
    1}=\sum^{n_{f}}_{l=1}\stackunder{\bm{a}_{l}}{\scriptscriptstyle d_{v}\times 1}\circ\stackunder{\bm{v}_{l}}{\scriptscriptstyle
    d_{v}\times 1}.$ |  | (30) |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{c}}{\scriptscriptstyle d_{v}\times
    1}=\sum^{n_{f}}_{l=1}\stackunder{\bm{a}_{l}}{\scriptscriptstyle d_{v}\times 1}\circ\stackunder{\bm{v}_{l}}{\scriptscriptstyle
    d_{v}\times 1}.$ |  | (30) |'
- en: 'However, since one needs to create attention weight vectors, this technique
    requires adjusted attention score and weight calculations. For example, the concatenate
    score function found in Table [II](#S3.T2 "TABLE II ‣ 3.2 General Attention Mechanisms
    ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")
    can be adjusted by changing the $\bm{w}\in\mathbb{R}^{d_{w}}$ weights vector to
    the weight matrix $\bm{W}_{d}\in\mathbb{R}^{d_{w}\times d_{v}}$:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于需要创建注意力权重向量，这项技术要求调整注意力评分和权重计算。例如，表 [II](#S3.T2 "TABLE II ‣ 3.2 General
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning") 中的拼接评分函数可以通过将 $\bm{w}\in\mathbb{R}^{d_{w}}$ 权重向量调整为权重矩阵 $\bm{W}_{d}\in\mathbb{R}^{d_{w}\times
    d_{v}}$ 来进行调整：
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{e}_{l}}{\scriptscriptstyle d_{v}\times
    1}=\stackunder{\bm{W}_{d}^{T}}{\scriptscriptstyle d_{v}\times d_{w}}\times\text{act}(\stackunder{\bm{W}_{1}}{\scriptscriptstyle
    d_{w}\times d_{q}}\times\stackunder{\bm{q}}{\scriptscriptstyle d_{q}\times 1}+\stackunder{\bm{W}_{2}}{\scriptscriptstyle
    d_{w}\times d_{k}}\times\stackunder{\bm{k}_{l}}{\scriptscriptstyle d_{k}\times
    1}+\stackunder{\bm{b}}{\scriptscriptstyle d_{w}\times 1}).$ |  | (31) |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{e}_{l}}{\scriptscriptstyle d_{v}\times
    1}=\stackunder{\bm{W}_{d}^{T}}{\scriptscriptstyle d_{v}\times d_{w}}\times\text{act}(\stackunder{\bm{W}_{1}}{\scriptscriptstyle
    d_{w}\times d_{q}}\times\stackunder{\bm{q}}{\scriptscriptstyle d_{q}\times 1}+\stackunder{\bm{W}_{2}}{\scriptscriptstyle
    d_{w}\times d_{k}}\times\stackunder{\bm{k}_{l}}{\scriptscriptstyle d_{k}\times
    1}+\stackunder{\bm{b}}{\scriptscriptstyle d_{w}\times 1}).$ |  | (31) |'
- en: 'This new score function produces the attention score vectors $\bm{e}_{1},\dots,\bm{e}_{n_{f}}\in\mathbb{R}^{d_{v}}$.
    These score vectors can be combined into a matrix of scores $\bm{e}=[\bm{e}_{1},\dots,\bm{e}_{n_{f}}]\in\mathbb{R}^{d_{v}\times
    n_{f}}$. To produce multi-dimensional attention weights, the alignment function
    stays the same, but it is applied for each feature across the attention score
    columns. To illustrate, when implementing soft attention, the attention weight
    produced from the $i$th element of score vector $\bm{e}_{l}$ is defined as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新的评分函数产生了注意力评分向量 $\bm{e}_{1},\dots,\bm{e}_{n_{f}}\in\mathbb{R}^{d_{v}}$。这些评分向量可以组合成一个评分矩阵
    $\bm{e}=[\bm{e}_{1},\dots,\bm{e}_{n_{f}}]\in\mathbb{R}^{d_{v}\times n_{f}}$。为了产生多维注意力权重，虽然对齐函数保持不变，但它会应用于每个特征的注意力评分列。为了说明，当实现软注意力时，来自评分向量
    $\bm{e}_{l}$ 的第 $i$ 个元素产生的注意力权重定义如下：
- en: '|  | $\setstackgap{L}{8pt}\stackunder{a_{l,i}}{\scriptscriptstyle 1\times 1}=\text{align}(\stackunder{e_{l,i}}{\scriptscriptstyle
    1\times 1};\stackunder{\bm{e}}{\scriptscriptstyle d_{v}\times n_{f}})=\frac{\text{exp}(e_{l,i})}{\sum^{n_{f}}_{j=1}\text{exp}(e_{j,i})},$
    |  | (32) |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{a_{l,i}}{\scriptscriptstyle 1\times 1}=\text{align}(\stackunder{e_{l,i}}{\scriptscriptstyle
    1\times 1};\stackunder{\bm{e}}{\scriptscriptstyle d_{v}\times n_{f}})=\frac{\text{exp}(e_{l,i})}{\sum^{n_{f}}_{j=1}\text{exp}(e_{j,i})},$
    |  | (32) |'
- en: where $e_{l,i}$ represents the $i$th element of score vector $\bm{e}_{l}$, and
    $a_{l,i}$ is the $i$th element of the attention weights vector $\bm{a}_{l}$. Finally,
    these attention weight vectors can be used to compute the context vector as presented
    in ([30](#S3.E30 "In 3.2.3 Attention Dimensionality ‣ 3.2 General Attention Mechanisms
    ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $e_{l,i}$ 代表评分向量 $\bm{e}_{l}$ 的第 $i$ 个元素，而 $a_{l,i}$ 是注意力权重向量 $\bm{a}_{l}$
    的第 $i$ 个元素。最后，这些注意力权重向量可以用于计算上下文向量，如 ([30](#S3.E30 "In 3.2.3 Attention Dimensionality
    ‣ 3.2 General Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on
    Attention Mechanisms in Deep Learning")) 中所示。
- en: Multi-dimensional attention is a very general mechanism that can be applied
    in practically every attention model, but actual applications of the technique
    have been relatively sparse. One application example is [[65](#bib.bib65)], where
    multi-dimensional attention is used in a model for named entity recognition based
    on text and visual context from multimedia posts. In [[66](#bib.bib66)], multi-dimensional
    attention is used in a model for answer selection in community question answering.
    In [[67](#bib.bib67)], the U-net model for medical image segmentation is extended
    with a multi-dimensional attention mechanism. Similarly, in [[68](#bib.bib68)],
    the Transformer model is extended with the multi-dimensional attention mechanism
    for the task of dialogue response generation. In [[69](#bib.bib69)], multi-dimensional
    attention is used to extend graph attention networks for dialogue state tracking.
    Lastly, for the task of next-item recommendation, [[70](#bib.bib70)] proposes
    a model that incorporates multi-dimensional attention.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 多维注意力是一种非常通用的机制，可以应用于几乎所有的注意力模型，但该技术的实际应用相对较少。一个应用示例是[[65](#bib.bib65)]，其中多维注意力用于基于文本和多媒体帖子中的视觉上下文的命名实体识别模型。在[[66](#bib.bib66)]中，多维注意力用于社区问答中的答案选择模型。在[[67](#bib.bib67)]中，医学图像分割的U-net模型扩展了多维注意力机制。类似地，在[[68](#bib.bib68)]中，Transformer模型扩展了多维注意力机制以生成对话回应。在[[69](#bib.bib69)]中，多维注意力用于扩展图注意力网络以进行对话状态跟踪。最后，对于下一项推荐任务，[[70](#bib.bib70)]提出了一种包含多维注意力的模型。
- en: 3.3 Query-Related Attention Mechanisms
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 查询相关的注意力机制
- en: 'Queries are an important part of any attention model, since they directly determine
    which information is extracted from the feature vectors. These queries are based
    on the desired output of the task model, and can be interpreted as literal questions.
    Some queries have specific characteristics that require specific types of mechanisms
    to process them. As such, this category encapsulates the attention mechanisms
    that deal with specific types of query characteristics. The mechanisms in this
    category deal with one of the two following query characteristics: the type of
    queries or the multiplicity of queries.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 查询是任何注意力模型的重要组成部分，因为它们直接决定从特征向量中提取哪些信息。这些查询基于任务模型的期望输出，可以被解释为字面上的问题。一些查询具有特定的特性，需要特定类型的机制来处理。因此，这一类别包括处理特定查询特性类型的注意力机制。这一类别的机制处理以下两种查询特性之一：查询的类型或查询的多样性。
- en: 3.3.1 Type of Queries
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1 查询的类型
- en: Different attention models employ attention for different purposes, meaning
    that distinct query types are necessary. There are basic queries, which are queries
    that are typically straightforward to define based on the data and model. For
    example, the hidden state for one prediction in an RNN is often used as the query
    for the next prediction. One could also use a vector of auxiliary variables as
    query. For example, when doing medical image classification, general patient characteristics
    can be incorporated into a query.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的注意力模型用于不同的目的，这意味着需要不同的查询类型。基本查询是那些通常根据数据和模型定义起来比较简单的查询。例如，RNN中的一个预测的隐藏状态通常用作下一个预测的查询。也可以使用辅助变量的向量作为查询。例如，在进行医学图像分类时，可以将一般的患者特征纳入查询中。
- en: 'Some attention mechanisms, such as co-attention, rotatory attention, and attention-over-attention,
    use specialized queries. For example, rotatory attention uses the context vector
    from another attention module as query, while interactive co-attention uses an
    averaged keys vector based on another input. Another case one can consider is
    when attention is calculated based purely on the feature vectors. This concept
    has been mentioned before and is referred to as self-attention or intra-attention
    [[71](#bib.bib71)]. We say that the models use self-attentive queries. There are
    two ways of interpreting such queries. Firstly, one can say that the query is
    constant. For example, document classification requires only a single classification
    as the output of the model. As such, the query is always the same, namely: “What
    is the class of the document?”. The query can be ignored and attention can be
    calculated based only on the features themselves. Score functions can be adjusted
    for this by making the query vector a vector of constants or removing it entirely:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一些注意力机制，例如共同注意力、旋转注意力和注意力上的注意力，使用特定的查询。例如，旋转注意力使用来自另一个注意力模块的上下文向量作为查询，而交互式共同注意力使用基于另一个输入的平均键向量。另一种情况是，当注意力完全基于特征向量计算时。这一概念之前提到过，称为自注意力或内部注意力
    [[71](#bib.bib71)]。我们说这些模型使用自注意力查询。有两种解释这种查询的方法。首先，可以说查询是常量。例如，文档分类只需要模型输出一个单一的分类。因此，查询始终是相同的，即：“文档的类别是什么？”。查询可以被忽略，注意力可以仅基于特征本身进行计算。通过将查询向量调整为常量向量或完全去除查询，可以调整评分函数：
- en: '|  | $\setstackgap{L}{11pt}\text{score}(\stackunder{\bm{k}_{l}}{\scriptscriptstyle
    d_{k}\times 1})=\stackunder{\bm{w}^{T}}{\scriptscriptstyle 1\times d_{w}}\times\text{act}(\stackunder{\bm{W}}{\scriptscriptstyle
    d_{w}\times d_{k}}\times\stackunder{\bm{k}_{l}}{\scriptscriptstyle d_{k}\times
    1}+\stackunder{\bm{b}}{\scriptscriptstyle d_{w}\times 1}).$ |  | (33) |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\text{score}(\stackunder{\bm{k}_{l}}{\scriptscriptstyle
    d_{k}\times 1})=\stackunder{\bm{w}^{T}}{\scriptscriptstyle 1\times d_{w}}\times\text{act}(\stackunder{\bm{W}}{\scriptscriptstyle
    d_{w}\times d_{k}}\times\stackunder{\bm{k}_{l}}{\scriptscriptstyle d_{k}\times
    1}+\stackunder{\bm{b}}{\scriptscriptstyle d_{w}\times 1}).$ |  | (33) |'
- en: 'Additionally, one can also interpret self-attention as learning the query along
    the way, meaning that the query can be defined as a trainable vector of weights.
    For example, the dot-product score function may take the following form:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，也可以将自注意力解释为在过程中学习查询，即查询可以定义为一个可训练的权重向量。例如，点积评分函数可能采取以下形式：
- en: '|  | $\setstackgap{L}{11pt}\text{score}(\stackunder{\bm{k}_{l}}{\scriptscriptstyle
    d_{k}\times 1})=\stackunder{\bm{q}^{T}}{\scriptscriptstyle 1\times d_{k}}\times\stackunder{\bm{k}_{l}}{\scriptscriptstyle
    d_{k}\times 1},$ |  | (34) |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\text{score}(\stackunder{\bm{k}_{l}}{\scriptscriptstyle
    d_{k}\times 1})=\stackunder{\bm{q}^{T}}{\scriptscriptstyle 1\times d_{k}}\times\stackunder{\bm{k}_{l}}{\scriptscriptstyle
    d_{k}\times 1},$ |  | (34) |'
- en: 'where $\bm{q}\in\mathbb{R}^{d_{k}}$ is a trainable vector of weights. One could
    also interpret vector $\bm{b}\in\mathbb{R}^{d_{w}}$ as the query in ([33](#S3.E33
    "In 3.3.1 Type of Queries ‣ 3.3 Query-Related Attention Mechanisms ‣ 3 Attention
    Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")). Another
    use of self-attention is to uncover the relations between the feature vectors
    $\bm{f}_{1},\dots,\bm{f}_{n_{f}}$. These relations can then be used as additional
    information to incorporate into new representations of the feature vectors. With
    basic attention mechanisms, the keys matrix $\bm{K}$, and the values matrix $\bm{V}$
    are extracted from the features matrix $\bm{F}$, while the query $\bm{q}$ is produced
    separately. For this type of self-attention, the query vectors are extracted in
    a similar process as the keys and values, via a transformation matrix of trainable
    weights $\bm{W}_{Q}\in\mathbb{R}^{d_{q}\times d_{f}}$. We define the matrix $\bm{Q}=[\bm{q}_{1},\dots,\bm{q}_{n_{f}}]\in\mathbb{R}^{d_{q}\times
    n_{f}}$, which can be obtained as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\bm{q}\in\mathbb{R}^{d_{k}}$ 是一个可训练的权重向量。也可以将向量 $\bm{b}\in\mathbb{R}^{d_{w}}$
    解释为查询，在 ([33](#S3.E33 "在 3.3.1 查询类型 ‣ 3.3 查询相关注意机制 ‣ 3 注意机制分类 ‣ 深度学习中的注意机制总体调查"))
    中。自注意力的另一个用途是揭示特征向量 $\bm{f}_{1},\dots,\bm{f}_{n_{f}}$ 之间的关系。这些关系可以作为额外的信息融入到特征向量的新表示中。对于基本的注意力机制，键矩阵
    $\bm{K}$ 和值矩阵 $\bm{V}$ 从特征矩阵 $\bm{F}$ 中提取，而查询 $\bm{q}$ 单独生成。对于这种类型的自注意力，查询向量的提取过程类似于键和值，通过一个可训练权重的转换矩阵
    $\bm{W}_{Q}\in\mathbb{R}^{d_{q}\times d_{f}}$。我们定义矩阵 $\bm{Q}=[\bm{q}_{1},\dots,\bm{q}_{n_{f}}]\in\mathbb{R}^{d_{q}\times
    n_{f}}$，可以通过以下方式获得：
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{Q}}{\scriptscriptstyle d_{q}\times
    n_{f}}=\stackunder{\bm{W}_{Q}}{\scriptscriptstyle d_{q}\times d_{f}}\times\stackunder{\bm{F}}{\scriptscriptstyle
    d_{f}\times n_{f}}.$ |  | (35) |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{Q}}{\scriptscriptstyle d_{q}\times
    n_{f}}=\stackunder{\bm{W}_{Q}}{\scriptscriptstyle d_{q}\times d_{f}}\times\stackunder{\bm{F}}{\scriptscriptstyle
    d_{f}\times n_{f}}.$ |  | (35) |'
- en: 'Each column of $\bm{Q}$ can be used as the query for the attention model. When
    attention is calculated using a query $\bm{q}$, the resulting context vector $\bm{c}$
    will summarize the information in the feature vectors that is important to the
    query. Since the query, or a column of $\bm{Q}$, is now also a feature vector
    representation, the context vector contains the information of all feature vectors
    that are important to that specific feature vector. In other words, the context
    vectors capture the relations between the feature vectors. For example, self-attention
    allows one to extract the relations between words: which verbs refer to which
    nouns, which pronouns refer to which nouns, etc. For images, self-attention can
    be used to determine which image regions relate to each other.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: $\bm{Q}$ 的每一列都可以用作注意力模型的查询。当使用查询$\bm{q}$计算注意力时，得到的上下文向量$\bm{c}$将总结特征向量中与查询相关的重要信息。由于查询，或$\bm{Q}$
    的一列，现在也是特征向量表示，因此上下文向量包含所有对该特定特征向量重要的特征向量的信息。换句话说，上下文向量捕捉特征向量之间的关系。例如，自注意力可以提取单词之间的关系：哪些动词指代哪些名词，哪些代词指代哪些名词，等等。对于图像，自注意力可以用来确定哪些图像区域彼此相关。
- en: While self-attention is placed in the query-related category, it is also very
    much related to the feature model. Namely, self-attention is a technique that
    is often used in the feature model to create improved representations of the feature
    vectors. For example, the Transformer model for language processing [[13](#bib.bib13)],
    and the Transformer model for image processing [[15](#bib.bib15)], both use multiple
    rounds of (multi-head) self-attention to improve the representation of the feature
    vectors. The relations captured by the self-attention mechanism are incorporated
    into new representations. A simple method of determining such a new representation
    is to simply set the feature vectors equal to the acquired self-attention context
    vectors [[71](#bib.bib71)], as presented in ([36](#S3.E36 "In 3.3.1 Type of Queries
    ‣ 3.3 Query-Related Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey
    on Attention Mechanisms in Deep Learning")).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然自注意力被归类于查询相关类别，但它与特征模型也有很大关系。即，自注意力是一种常用于特征模型中的技术，用以创建改进的特征向量表示。例如，语言处理的Transformer模型[[13](#bib.bib13)]和图像处理的Transformer模型[[15](#bib.bib15)]，都使用了多轮的（多头）自注意力来提升特征向量的表示。这些自注意力机制捕捉到的关系被纳入到新的表示中。一种简单的确定这种新表示的方法是将特征向量直接设置为获得的自注意力上下文向量[[71](#bib.bib71)]，如在([36](#S3.E36
    "In 3.3.1 Type of Queries ‣ 3.3 Query-Related Attention Mechanisms ‣ 3 Attention
    Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning"))中所示。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{f}^{(\text{new})}}{\scriptscriptstyle
    d_{f}\times 1}=\stackunder{\bm{c}}{\scriptscriptstyle d_{f}\times 1},$ |  | (36)
    |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{f}^{(\text{new})}}{\scriptscriptstyle
    d_{f}\times 1}=\stackunder{\bm{c}}{\scriptscriptstyle d_{f}\times 1},$ |  | (36)
    |'
- en: 'where $\bm{f}^{(\text{new})}$ is the updated feature vector. Another possibility
    is to add the context vectors to the previous feature vectors with an additional
    normalization layer [[13](#bib.bib13)]:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\bm{f}^{(\text{new})}$ 是更新后的特征向量。另一种可能性是将上下文向量与之前的特征向量相加，再通过一个额外的归一化层[[13](#bib.bib13)]：
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{f}^{(\text{new})}}{\scriptscriptstyle
    d_{f}\times 1}=\text{Normalize}(\stackunder{\bm{f}^{(\text{old})}}{\scriptscriptstyle
    d_{f}\times 1}+\stackunder{\bm{c}}{\scriptscriptstyle d_{f}\times 1}),$ |  | (37)
    |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{f}^{(\text{new})}}{\scriptscriptstyle
    d_{f}\times 1}=\text{Normalize}(\stackunder{\bm{f}^{(\text{old})}}{\scriptscriptstyle
    d_{f}\times 1}+\stackunder{\bm{c}}{\scriptscriptstyle d_{f}\times 1}),$ |  | (37)
    |'
- en: where $\bm{f}^{(\text{old})}$ is the previous feature vector, and $\text{Normalize}()$
    is a normalization layer [[72](#bib.bib72)]. Using such techniques, self-attention
    has been used to create improved word or sentence embeddings that enhance model
    accuracy [[71](#bib.bib71)].
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\bm{f}^{(\text{old})}$ 是之前的特征向量，$\text{Normalize}()$ 是一个归一化层[[72](#bib.bib72)]。使用这些技术，自注意力已被用来创建改进的词嵌入或句子嵌入，从而提高模型的准确性[[71](#bib.bib71)]。
- en: Self-attention is arguably one of the more important types of attention, partly
    due to its vital role in the highly popular Transformer model. Self-attention
    is a very general mechanism and can be applied to practically any problem. As
    such, self-attention has been extensively explored in many different fields in
    both Transformer-based architectures and other types of models. For example, in
    [[73](#bib.bib73)], self-attention is explored for image recognition tasks, and
    results indicate that the technique may have substantial advantages with regards
    to robustness and generalization. In [[74](#bib.bib74)], self-attention is used
    in a generative adversarial network (GAN) [[75](#bib.bib75)] to determine which
    regions of the input image to focus on when generating the regions of a new image.
    In [[76](#bib.bib76)], self-attention is used to design a state-of-the-art medical
    image segmentation model. Naturally, self-attention can also be used for video
    processing. In [[77](#bib.bib77)], a self-attention model is proposed for the
    purpose of video summarization that reaches state-of-the-art results. In other
    fields, like audio processing, self-attention has been explored as well. In [[78](#bib.bib78)],
    self-attention is used to create a speech recognition model. Self-attention has
    also been explored in overlapping domains. For example, in [[79](#bib.bib79)],
    the self-attention Transformer architecture is used to create a model that can
    recognize phrases from audio and by lip-reading from a video. For the problem
    of next item recommendation, [[80](#bib.bib80)] proposes a Transformer model that
    explicitly captures item-item relations using self-attention. Self-attention also
    has applications in any natural language processing fields. For example, in [[81](#bib.bib81)],
    self-attention is used for sentiment analysis. Self-attention is also highly popular
    for graph models. For example, self-attention is explored in [[82](#bib.bib82)]
    for the purpose of representation learning in communication networks and rating
    networks. Additionally, the first attention model for graph networks was based
    on self-attention [[83](#bib.bib83)].
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 自注意力可以说是更重要的注意力类型之一，部分原因是它在高度流行的Transformer模型中的重要作用。自注意力是一种非常通用的机制，可以应用于几乎任何问题。因此，自注意力在许多不同领域的Transformer基础架构和其他类型的模型中都得到了广泛的探索。例如，在[[73](#bib.bib73)]中，自注意力被探索用于图像识别任务，结果表明这种技术在鲁棒性和泛化能力方面可能具有显著优势。在[[74](#bib.bib74)]中，自注意力被用于生成对抗网络（GAN）[[75](#bib.bib75)]中，以确定在生成新图像的区域时应关注输入图像的哪些区域。在[[76](#bib.bib76)]中，自注意力被用于设计最先进的医学图像分割模型。自然，自注意力也可以用于视频处理。在[[77](#bib.bib77)]中，提出了一种自注意力模型用于视频摘要，达到了最先进的结果。在其他领域，如音频处理，自注意力也被探索过。在[[78](#bib.bib78)]中，自注意力被用于创建语音识别模型。自注意力也在重叠领域中得到了探索。例如，在[[79](#bib.bib79)]中，自注意力Transformer架构被用于创建一个可以从音频识别短语和从视频中进行唇读的模型。对于下一个项目推荐问题，[[80](#bib.bib80)]提出了一种Transformer模型，明确捕捉了使用自注意力的项目-项目关系。自注意力也在任何自然语言处理领域中具有应用。例如，在[[81](#bib.bib81)]中，自注意力被用于情感分析。自注意力在图模型中也非常受欢迎。例如，自注意力在[[82](#bib.bib82)]中被探索用于通信网络和评分网络中的表示学习。此外，第一个图网络的注意力模型基于自注意力[[83](#bib.bib83)]。
- en: 3.3.2 Multiplicity of Queries
  id: totrans-190
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2 查询的多样性
- en: In previous examples, the attention model generally used a single query for
    a prediction. We say that such models use singular query attention. However, there
    are attention architectures that allow the model to compute attention using multiple
    queries. Note that this is different from, for example, an RNN that may involve
    multiple queries to produce a sequence of predictions. Namely, such a model still
    requires only a single query per prediction.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的示例中，注意力模型通常使用单一查询进行预测。我们称这种模型为使用单一查询注意力的模型。然而，也有一些注意力架构允许模型使用多个查询来计算注意力。请注意，这与例如一个可能涉及多个查询来生成预测序列的RNN不同。也就是说，这种模型每次预测仍然只需要一个查询。
- en: 'One example of a technique that incorporates multiple queries is multi-head
    attention [[13](#bib.bib13)], as presented in Fig. [9](#S3.F9 "Figure 9 ‣ 3.3.2
    Multiplicity of Queries ‣ 3.3 Query-Related Attention Mechanisms ‣ 3 Attention
    Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning"). Multi-head
    attention works by implementing multiple attention modules in parallel by utilizing
    multiple different versions of the same query. The idea is to linearly transform
    the query $\bm{q}$ using different weight matrices. Each newly formed query essentially
    asks for a different type of relevant information, allowing the attention model
    to introduce more information into the context vector calculation. An attention
    model implements $d\geq 1$ heads with each attention head having its own query
    vector, keys matrix, and values matrix: $\bm{q}^{(j)}$, $\bm{K}^{(j)}$ and $\bm{V}^{(j)}$,
    for $j=1,\dots,d$. The query $\bm{q}^{(j)}$ is obtained by linearly transforming
    the original query $\bm{q}$, while the matrices $\bm{K}^{(j)}$ and $\bm{V}^{(j)}$
    are obtained through linear transformations of $\bm{F}$. As such, each attention
    head has its own learnable weights matrices $\bm{W}_{q}^{(j)}$, $\bm{W}_{K}^{(j)}$
    and $\bm{W}_{V}^{(j)}$ for these transformations. The calculation of the query,
    keys, and values for the $j$th head are defined as follows:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包含多个查询的技术示例是多头注意力[[13](#bib.bib13)]，如图 [9](#S3.F9 "Figure 9 ‣ 3.3.2 Multiplicity
    of Queries ‣ 3.3 Query-Related Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A
    General Survey on Attention Mechanisms in Deep Learning")所示。多头注意力通过并行实现多个注意力模块，利用同一查询的多个不同版本来工作。其思路是使用不同的权重矩阵对查询$\bm{q}$进行线性变换。每个新形成的查询本质上要求不同类型的相关信息，使注意力模型能够将更多信息引入上下文向量的计算中。一个注意力模型实现了$d\geq
    1$个头，每个注意力头都有其自己的查询向量、键矩阵和值矩阵：$\bm{q}^{(j)}$、$\bm{K}^{(j)}$和$\bm{V}^{(j)}$，其中$j=1,\dots,d$。查询$\bm{q}^{(j)}$是通过对原始查询$\bm{q}$进行线性变换获得的，而矩阵$\bm{K}^{(j)}$和$\bm{V}^{(j)}$则通过对$\bm{F}$进行线性变换获得。因此，每个注意力头都有其自己的可学习的权重矩阵$\bm{W}_{q}^{(j)}$、$\bm{W}_{K}^{(j)}$和$\bm{W}_{V}^{(j)}$用于这些变换。第$j$个头的查询、键和值的计算定义如下：
- en: '|  | $\setstackgap{L}{8pt}\begin{split}\stackunder{\bm{q}^{(j)}}{\scriptscriptstyle
    d_{q}\times 1}=\stackunder{\bm{W}_{q}^{(j)}}{\scriptscriptstyle d_{q}\times d_{q}}\times\stackunder{\bm{q}}{\scriptscriptstyle
    d_{q}\times 1},\hskip 30.0pt\stackunder{\bm{K}^{(j)}}{\scriptscriptstyle d_{k}\times
    n_{f}}=\stackunder{\bm{W}_{K}^{(j)}}{\scriptscriptstyle d_{k}\times d_{f}}\times\stackunder{\bm{F}}{\scriptscriptstyle
    d_{f}\times n_{f}},\\ \stackunder{\bm{V}^{(j)}}{\scriptscriptstyle d_{v}\times
    n_{f}}=\stackunder{\bm{W}_{V}^{(j)}}{\scriptscriptstyle d_{v}\times d_{f}}\times\stackunder{\bm{F}}{\scriptscriptstyle
    d_{f}\times n_{f}}.\hskip 60.0pt\end{split}$ |  | (38) |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\begin{split}\stackunder{\bm{q}^{(j)}}{\scriptscriptstyle
    d_{q}\times 1}=\stackunder{\bm{W}_{q}^{(j)}}{\scriptscriptstyle d_{q}\times d_{q}}\times\stackunder{\bm{q}}{\scriptscriptstyle
    d_{q}\times 1},\hskip 30.0pt\stackunder{\bm{K}^{(j)}}{\scriptscriptstyle d_{k}\times
    n_{f}}=\stackunder{\bm{W}_{K}^{(j)}}{\scriptscriptstyle d_{k}\times d_{f}}\times\stackunder{\bm{F}}{\scriptscriptstyle
    d_{f}\times n_{f}},\\ \stackunder{\bm{V}^{(j)}}{\scriptscriptstyle d_{v}\times
    n_{f}}=\stackunder{\bm{W}_{V}^{(j)}}{\scriptscriptstyle d_{v}\times d_{f}}\times\stackunder{\bm{F}}{\scriptscriptstyle
    d_{f}\times n_{f}}.\hskip 60.0pt\end{split}$ |  | (38) |'
- en: 'Thus, each head creates its own representations of the query $\bm{q}$, and
    the input matrix $\bm{F}$. Each head can therefore learn to focus on different
    parts of the inputs, allowing the model to attend to more information. For example,
    when training a machine translation model, one attention head can learn to focus
    on which nouns (e.g., student, car, apple) do certain verbs (e.g., walking, driving,
    buying) refer to, while another attention head learns to focus on which nouns
    refer to certain pronouns (e.g., he, she, it) [[13](#bib.bib13)]. Each head will
    also create its own vector of attention scores $\bm{e}^{(j)}=[e_{1}^{(j)},\dots,e_{n_{f}}^{(j)}]\in\mathbb{R}^{n_{f}}$,
    and a corresponding vector of attention weights $\bm{a}^{(j)}=[a_{1}^{(j)},\dots,a_{n_{f}}^{(j)}]\in\mathbb{R}^{n_{f}}$.
    As can be expected, each attention model produces its own context vector $\bm{c}^{(j)}\in\mathbb{R}^{d_{v}}$,
    as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，每个头都创建了自己对查询$\bm{q}$和输入矩阵$\bm{F}$的表示。每个头可以学习关注输入的不同部分，使得模型能够关注更多的信息。例如，在训练机器翻译模型时，一个注意力头可以学习关注哪些名词（例如，学生、汽车、苹果）是某些动词（例如，走路、驾驶、购买）所指的，而另一个注意力头则学习关注哪些名词是某些代词（例如，他、她、它）所指的[[13](#bib.bib13)]。每个头还将创建其自己的注意力得分向量$\bm{e}^{(j)}=[e_{1}^{(j)},\dots,e_{n_{f}}^{(j)}]\in\mathbb{R}^{n_{f}}$和相应的注意力权重向量$\bm{a}^{(j)}=[a_{1}^{(j)},\dots,a_{n_{f}}^{(j)}]\in\mathbb{R}^{n_{f}}$。可以预期，每个注意力模型都会生成其自己的上下文向量$\bm{c}^{(j)}\in\mathbb{R}^{d_{v}}$，如下所示：
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{c}^{(j)}}{\scriptscriptstyle d_{v}\times
    1}=\sum^{n_{f}}_{l=1}\stackunder{a_{l}^{(j)}}{\scriptscriptstyle 1\times 1}\times\stackunder{\bm{v}_{l}^{(j)}}{\scriptscriptstyle
    d_{v}\times 1}.$ |  | (39) |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{c}^{(j)}}{\scriptscriptstyle d_{v}\times
    1}=\sum^{n_{f}}_{l=1}\stackunder{a_{l}^{(j)}}{\scriptscriptstyle 1\times 1}\times\stackunder{\bm{v}_{l}^{(j)}}{\scriptscriptstyle
    d_{v}\times 1}.$ |  | (39) |'
- en: '![Refer to caption](img/4b7b27e41e472c54960ecc46d302e087.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4b7b27e41e472c54960ecc46d302e087.png)'
- en: 'Figure 9: An illustration of multi-head attention.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '图 9: 多头注意力的示意图。'
- en: The goal is still to create a single context vector as output of the attention
    model. As such, the context vectors produced by the individual attention heads
    are concatenated into a single vector. Afterwards, a linear transformation is
    applied using the weight matrix $\bm{W}_{O}\in\mathbb{R}^{d_{c}\times d_{v}d}$
    to make sure the resulting context vector $\bm{c}\in\mathbb{R}^{d_{c}}$ has the
    desired dimension. This calculation is presented in ([40](#S3.E40 "In 3.3.2 Multiplicity
    of Queries ‣ 3.3 Query-Related Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A
    General Survey on Attention Mechanisms in Deep Learning")). The dimension $d_{c}$
    can be pre-specified by, for example, setting it equal to $d_{v}$, so that the
    context vector dimension is unchanged.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 目标仍然是创建一个单一的上下文向量作为注意力模型的输出。因此，单个注意力头生成的上下文向量被串联成一个单一的向量。之后，使用权重矩阵$\bm{W}_{O}\in\mathbb{R}^{d_{c}\times
    d_{v}d}$进行线性变换，以确保得到的上下文向量$\bm{c}\in\mathbb{R}^{d_{c}}$具有期望的维度。这个计算在([40](#S3.E40
    "在 3.3.2 查询的多样性 ‣ 3.3 查询相关的注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的通用调查"))中进行了展示。维度$d_{c}$可以通过将其设为$d_{v}$等方式预先指定，以使上下文向量维度保持不变。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{c}}{\scriptscriptstyle d_{c}\times
    1}=\stackunder{\bm{W}_{O}}{\scriptscriptstyle d_{c}\times d_{v}d}\times\text{concat}(\stackunder{\bm{c}^{(1)}}{\scriptscriptstyle
    d_{v}\times 1},...,\stackunder{\bm{c}^{(d)}}{\scriptscriptstyle d_{v}\times 1}).$
    |  | (40) |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{c}}{\scriptscriptstyle d_{c}\times
    1}=\stackunder{\bm{W}_{O}}{\scriptscriptstyle d_{c}\times d_{v}d}\times\text{concat}(\stackunder{\bm{c}^{(1)}}{\scriptscriptstyle
    d_{v}\times 1},...,\stackunder{\bm{c}^{(d)}}{\scriptscriptstyle d_{v}\times 1}).$
    |  | (40) |'
- en: Multi-head attention processes multiple attention modules in parallel, but attention
    modules can also be implemented sequentially to iteratively adjust the context
    vectors. Each of these attention modules are referred to as “repetitions” or “rounds”
    of attention. Such attention architectures are referred to as multi-hop attention
    models, also known as multi-step attention models. An important note to consider
    is the fact that multi-hop attention is a mechanism that has been proposed in
    various forms throughout various works. While the mechanism always involves multiple
    rounds of attention, the multi-hop implementation proposed in [[84](#bib.bib84)]
    differs from the mechanism proposed in [[85](#bib.bib85)] or [[86](#bib.bib86)].
    Another interesting example is [[87](#bib.bib87)], where a “multi-hop” attention
    model is proposed that would actually be considered alternating co-attention in
    this survey, as explained in Subsection [3.1.1](#S3.SS1.SSS1 "3.1.1 Multiplicity
    of Features ‣ 3.1 Feature-Related Attention Mechanisms ‣ 3 Attention Taxonomy
    ‣ A General Survey on Attention Mechanisms in Deep Learning").
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 多头注意力并行处理多个注意力模块，但注意力模块也可以按顺序实现，以迭代地调整上下文向量。这些注意力模块中的每一个被称为“重复”或“轮次”注意力。这种注意力架构被称为多跳注意力模型，也被称为多步注意力模型。需要注意的是，多跳注意力是一种在各种工作中以不同形式提出的机制。虽然该机制总是涉及多个轮次的注意力，但[[84](#bib.bib84)]中提出的多跳实现与[[85](#bib.bib85)]或[[86](#bib.bib86)]中提出的机制不同。另一个有趣的例子是[[87](#bib.bib87)]，其中提出了一种“多跳”注意力模型，在本调查中实际上被视为交替共同注意力，如在小节[3.1.1](#S3.SS1.SSS1
    "3.1.1 特征的多样性 ‣ 3.1 特征相关的注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的通用调查")中解释。
- en: We present a general form of multi-hop attention that is largely a generalization
    of the techniques introduced in [[85](#bib.bib85)] and [[88](#bib.bib88)]. Fig.
    [10](#S3.F10 "Figure 10 ‣ 3.3.2 Multiplicity of Queries ‣ 3.3 Query-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning") provides an example implementation of a multi-hop attention mechanism.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了一种通用的多跳注意力形式，它在很大程度上是对[[85](#bib.bib85)]和[[88](#bib.bib88)]中介绍的技术的概括。图[10](#S3.F10
    "图 10 ‣ 3.3.2 查询的多样性 ‣ 3.3 查询相关的注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的通用调查")提供了多跳注意力机制的一个示例实现。
- en: '![Refer to caption](img/cc9bc7ee6d749ed94b327380a8b2bca8.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/cc9bc7ee6d749ed94b327380a8b2bca8.png)'
- en: 'Figure 10: An example illustration of multi-hop attention. Solid arrows represent
    the base multi-hop model structure, while dotted arrows represent optional connections.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：多跳注意力的示例插图。实线箭头表示基本的多跳模型结构，而虚线箭头表示可选的连接。
- en: 'The general idea is to iteratively transform the query, and use the query to
    transform the context vector, such that the model can extract different information
    in each step. Remember that a query is similar to a literal question. As such,
    one can interpret the transformed queries as asking the same question in a different
    manner or from a different perspective, similarly to the queries in multi-head
    attention. The query that was previously denoted by $\bm{q}$ is now referred to
    as the initial query, and is denoted by $\bm{q}^{(0)}$. At hop $s$, the current
    query $\bm{q}^{(s)}$ is transformed into a new query representation $\bm{q}^{(s+1)}$,
    possibly using the current context vector $\bm{c}^{(s)}$ as another input, and
    some transformation function $\text{transform}()$:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 一般的想法是迭代地转换查询，并使用该查询来转换上下文向量，使得模型可以在每一步提取不同的信息。记住，查询类似于一个具体的问题。因此，可以将转换后的查询解释为以不同的方式或从不同的角度提出相同的问题，类似于多头注意力中的查询。之前表示为$\bm{q}$的查询现在被称为初始查询，记作$\bm{q}^{(0)}$。在第$s$步时，当前查询$\bm{q}^{(s)}$被转换为新的查询表示$\bm{q}^{(s+1)}$，可能使用当前上下文向量$\bm{c}^{(s)}$作为另一个输入，以及某些转换函数$\text{transform}()$：
- en: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{q}^{(s+1)}}{\scriptscriptstyle d_{q}\times
    1}=\text{transform}(\stackunder{\bm{q}^{(s)}}{\scriptscriptstyle d_{q}\times 1},\;\stackunder{\bm{c}^{(s)}}{\scriptscriptstyle
    d_{v}\times 1}).$ |  | (41) |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{\bm{q}^{(s+1)}}{\scriptscriptstyle d_{q}\times
    1}=\text{transform}(\stackunder{\bm{q}^{(s)}}{\scriptscriptstyle d_{q}\times 1},\;\stackunder{\bm{c}^{(s)}}{\scriptscriptstyle
    d_{v}\times 1}).$ |  | (41) |'
- en: For the specific form of the transformation function $\text{transform}()$, [[85](#bib.bib85)]
    proposes to use a mechanism similar to self-attention. Essentially, the queries
    used by the question answer matching model proposed in [[85](#bib.bib85)] were
    originally based on a set of feature vectors extracted from a question. [[85](#bib.bib85)]
    also defines the original query $\bm{q}^{(0)}$ as the unweighted average of these
    feature vectors. At each hop $s$, attention can be calculated on these feature
    vectors using the previous query $\bm{q}^{(s)}$ as the query in this process.
    The resulting context vector of this calculation is the next query vector. Using
    the context vector $\bm{c}^{(s)}$ instead of $\bm{q}^{(s)}$ as the query for this
    process is also a possibility, which is similar to the LCR-Rot-hop model proposed
    in [[43](#bib.bib43)] and the multi-step model proposed in [[88](#bib.bib88)].
    Such a connection is represented by the dotted arrows in Fig. [10](#S3.F10 "Figure
    10 ‣ 3.3.2 Multiplicity of Queries ‣ 3.3 Query-Related Attention Mechanisms ‣
    3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning").
    The transformation mechanism uses either the $\bm{q}^{(s)}$ or the context vector
    $\bm{c}^{(s)}$ as query, but a combination via concatenation is also possible.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 对于转换函数$\text{transform}()$的具体形式，[[85](#bib.bib85)]建议使用类似于自注意力的机制。从本质上讲，[[85](#bib.bib85)]中提出的问题回答匹配模型所使用的查询最初是基于从问题中提取的一组特征向量。[[85](#bib.bib85)]还将原始查询$\bm{q}^{(0)}$定义为这些特征向量的无权平均值。在每一步$s$中，可以使用之前的查询$\bm{q}^{(s)}$作为该过程中的查询，对这些特征向量进行注意力计算。这一计算的结果上下文向量即为下一个查询向量。使用上下文向量$\bm{c}^{(s)}$而不是$\bm{q}^{(s)}$作为该过程的查询也是一种可能性，这类似于[[43](#bib.bib43)]中提出的LCR-Rot-hop模型和[[88](#bib.bib88)]中提出的多步骤模型。这样的连接由图中的虚线箭头表示[10](#S3.F10
    "Figure 10 ‣ 3.3.2 Multiplicity of Queries ‣ 3.3 Query-Related Attention Mechanisms
    ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")。转换机制使用$\bm{q}^{(s)}$或上下文向量$\bm{c}^{(s)}$作为查询，但也可以通过串联的组合。
- en: Each query representation is used as input for the attention module to compute
    attention on the columns of the feature matrix $\bm{F}$, as seen previously. One
    main difference, however, is that the context vector $\bm{c}^{(s)}$ is also used
    as input, so that the actual query input for the attention model is the concatenation
    of $\bm{c}^{(s)}$ and $\bm{q}^{(s+1)}$. The adjusted attention score function
    is presented in ([42](#S3.E42 "In 3.3.2 Multiplicity of Queries ‣ 3.3 Query-Related
    Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms
    in Deep Learning")). Note that the initial context vector $\bm{c}^{(0)}$ is predefined.
    One way of doing this is by setting it equal to the unweighted average of the
    value vectors $\bm{v}_{1},\dots,\bm{v}_{n_{f}}\in\mathbb{R}^{d_{v}}$ extracted
    from $\bm{F}$.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 每个查询表示作为输入传递给注意力模块，以计算对特征矩阵 $\bm{F}$ 列的注意力，正如之前所见。然而，一个主要的区别是，上下文向量 $\bm{c}^{(s)}$
    也作为输入使用，因此，注意力模型的实际查询输入是 $\bm{c}^{(s)}$ 和 $\bm{q}^{(s+1)}$ 的连接。调整后的注意力得分函数在 ([42](#S3.E42
    "In 3.3.2 Multiplicity of Queries ‣ 3.3 Query-Related Attention Mechanisms ‣ 3
    Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning"))
    中展示。请注意，初始上下文向量 $\bm{c}^{(0)}$ 是预定义的。一种方法是将其设置为从 $\bm{F}$ 中提取的值向量 $\bm{v}_{1},\dots,\bm{v}_{n_{f}}\in\mathbb{R}^{d_{v}}$
    的无权平均值。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{e_{l}^{(s)}}{\scriptscriptstyle 1\times
    1}=\text{score}(\text{concat}(\stackunder{\bm{q}^{(s+1)}}{\scriptscriptstyle d_{q}\times
    1},\stackunder{\bm{c}^{(s)}}{\scriptscriptstyle d_{v}\times 1}),\stackunder{\bm{k}_{l}}{\scriptscriptstyle
    d_{k}\times 1}).$ |  | (42) |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{e_{l}^{(s)}}{\scriptscriptstyle 1\times
    1}=\text{score}(\text{concat}(\stackunder{\bm{q}^{(s+1)}}{\scriptscriptstyle d_{q}\times
    1},\stackunder{\bm{c}^{(s)}}{\scriptscriptstyle d_{v}\times 1}),\stackunder{\bm{k}_{l}}{\scriptscriptstyle
    d_{k}\times 1}).$ |  | (42) |'
- en: An alignment function and the value vectors are then used to produce the next
    context vector $\bm{c}^{(s+1)}$. One must note that in [[85](#bib.bib85)], the
    weights used in each iteration are the same weights, meaning that the number of
    parameters do not scale with the number of repetitions. Yet, using multiple hops
    with different weight matrices can also be viable, as shown by the Transformer
    model [[13](#bib.bib13)] and in [[88](#bib.bib88)]. It may be difficult to grasp
    why $\bm{c}^{(s)}$ is part of the query input for the attention model. Essentially,
    this technique is closely related to self-attention in the sense that, in each
    iteration, a new context representation is created from the feature vectors and
    the context vector. The essence of this mechanism is that one wants to iteratively
    alter the query and the context vector, while attending to the feature vectors.
    In the process, the new representations of the context vector absorb more different
    kinds of information. This is also the main difference between this type of attention
    and multi-head attention. Multi-head attention creates multiple context vectors
    from multiple queries and combines them to create a final context vector as output.
    Multi-hop attention iteratively refines the context vector by incorporating information
    from the different queries. This does have the disadvantage of having to calculate
    attention sequentially.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用对齐函数和值向量生成下一个上下文向量 $\bm{c}^{(s+1)}$。需要注意的是，在 [[85](#bib.bib85)] 中，每次迭代中使用的权重是相同的权重，这意味着参数的数量不会随着重复次数的增加而增加。然而，如
    Transformer 模型 [[13](#bib.bib13)] 和 [[88](#bib.bib88)] 所示，使用具有不同权重矩阵的多个跳跃也是可行的。理解为什么
    $\bm{c}^{(s)}$ 是注意力模型查询输入的一部分可能很困难。从本质上讲，这种技术与自注意力密切相关，因为在每次迭代中，从特征向量和上下文向量中创建新的上下文表示。这个机制的精髓在于希望迭代地改变查询和上下文向量，同时关注特征向量。在这个过程中，上下文向量的新表示吸收了更多不同种类的信息。这也是这种注意力与多头注意力的主要区别。多头注意力从多个查询中创建多个上下文向量，并将它们组合成最终的上下文向量作为输出。多跳注意力通过结合来自不同查询的信息来迭代地细化上下文向量。这确实有需要顺序计算注意力的缺点。
- en: Interestingly, due to the variations in which multi-hop attention has been proposed,
    some consider the Transformer model’s encoder and decoder to consist of several
    single-hop attention mechanisms [[84](#bib.bib84)] instead of being a multi-hop
    model. However, in the context of this survey, we consider the Transformer model
    to be an alternative form of the multi-hop mechanism, as the features matrix $\bm{F}$
    is not directly reused in each step. Instead, $\bm{F}$ is only used as an input
    for the first hop, and is transformed via self-attention into a new representation.
    The self-attention mechanism uses each feature vector in $\bm{F}$ as a query,
    resulting in a matrix of context vectors as output of each attention hop. The
    intermediate context vectors are turned into matrices and represent iterative
    transformations of the matrix $\bm{F}$, which are used in the consecutive steps.
    Thus, the Transformer model iteratively refines the features matrix $\bm{F}$ by
    extracting and incorporating new information.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，由于提出的多跳注意力机制存在不同变体，一些人认为 Transformer 模型的编码器和解码器由几个单跳注意力机制组成[[84](#bib.bib84)]，而不是一个多跳模型。然而，在本次调查的背景下，我们认为
    Transformer 模型是一种多跳机制的替代形式，因为特征矩阵$\bm{F}$在每一步中并未直接重复使用。相反，$\bm{F}$仅用作第一次跳跃的输入，并通过自注意力机制转化为新的表示。自注意力机制将$\bm{F}$中的每个特征向量作为查询，从而生成每次注意力跳跃的上下文向量矩阵。这些中间上下文向量被转换为矩阵，表示矩阵$\bm{F}$的迭代变换，并在连续步骤中使用。因此，Transformer
    模型通过提取和整合新信息迭代地优化特征矩阵$\bm{F}$。
- en: 'When dealing with a classification task, another idea is to use a different
    query for each class. This is the basic principle behind capsule-based attention
    [[89](#bib.bib89)], as inspired by the capsule networks [[90](#bib.bib90)]. Suppose
    we have the feature vectors $\bm{f}_{1},\dots,\bm{f}_{n_{f}}\in\mathbb{R}^{d_{f}}$,
    and suppose there are are $d_{y}$ classes that the model can predict. Then, a
    capsule-based attention model defines a capsule for each of the $d_{y}$ classes
    that each take as input the feature vectors. Each capsule consists of, in order,
    an attention module, a probability module, and a reconstruction module, which
    are depicted in Fig. [11](#S3.F11 "Figure 11 ‣ 3.3.2 Multiplicity of Queries ‣
    3.3 Query-Related Attention Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey
    on Attention Mechanisms in Deep Learning"). The attention modules all use self-attentive
    queries, so each module learns its own query: ”Which feature vectors are important
    to identify this class?”. In [[89](#bib.bib89)], a self-attentive multiplicative
    score function is used for this purpose:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理分类任务时，另一种思路是为每个类别使用不同的查询。这是基于胶囊网络[[90](#bib.bib90)]的胶囊注意力[[89](#bib.bib89)]的基本原理。假设我们有特征向量$\bm{f}_{1},\dots,\bm{f}_{n_{f}}\in\mathbb{R}^{d_{f}}$，并且模型可以预测$d_{y}$个类别。那么，胶囊注意力模型为每个$d_{y}$个类别定义一个胶囊，每个胶囊将特征向量作为输入。每个胶囊由以下三个模块组成：注意力模块、概率模块和重建模块，如图[11](#S3.F11
    "Figure 11 ‣ 3.3.2 Multiplicity of Queries ‣ 3.3 Query-Related Attention Mechanisms
    ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in Deep Learning")所示。注意力模块都使用自注意力查询，因此每个模块学习自己的查询：“哪些特征向量对识别此类别很重要？”。在[[89](#bib.bib89)]中，使用了自注意力乘性评分函数来实现这一目的：
- en: '|  | $\setstackgap{L}{11pt}\stackunder{e_{c,l}}{\scriptscriptstyle 1\times
    1}=\stackunder{\bm{q}_{c}^{T}}{\scriptscriptstyle 1\times d_{k}}\times\stackunder{\bm{k}_{l}}{\scriptscriptstyle
    d_{k}\times 1},$ |  | (43) |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\stackunder{e_{c,l}}{\scriptscriptstyle 1\times
    1}=\stackunder{\bm{q}_{c}^{T}}{\scriptscriptstyle 1\times d_{k}}\times\stackunder{\bm{k}_{l}}{\scriptscriptstyle
    d_{k}\times 1},$ |  | (43) |'
- en: 'where $e_{c,l}\in\mathbb{R}^{1}$ is the attention score for vector $l$ in capsule
    $c$, and $\bm{q}_{c}\in\mathbb{R}^{d_{k}}$ is a trainable query for capsule $c$,
    for $c=1,\dots,d_{y}$. Each attention module then uses an alignment function,
    and uses the produced attention weights to determine a context vector $\bm{c}_{c}\in\mathbb{R}^{d_{v}}$.
    Next, the context vector $\bm{c}_{c}$ is fed through a probability layer consisting
    of a linear transformation with a sigmoid activation function:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$e_{c,l}\in\mathbb{R}^{1}$是胶囊$c$中向量$l$的注意力分数，$\bm{q}_{c}\in\mathbb{R}^{d_{k}}$是胶囊$c$的可训练查询，对于$c=1,\dots,d_{y}$。每个注意力模块然后使用一个对齐函数，并利用生成的注意力权重确定上下文向量$\bm{c}_{c}\in\mathbb{R}^{d_{v}}$。接下来，上下文向量$\bm{c}_{c}$通过一个由线性变换和
    sigmoid 激活函数组成的概率层：
- en: '|  | $\setstackgap{L}{11pt}\stackunder{p_{c}}{\scriptscriptstyle 1\times 1}=\text{sigmoid}(\stackunder{\bm{w}_{c}^{T}}{\scriptscriptstyle
    1\times d_{v}}\times\stackunder{\bm{c}_{c}}{\scriptscriptstyle d_{v}\times 1}+\stackunder{b_{c}}{\scriptscriptstyle
    1\times 1}),$ |  | (44) |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\stackunder{p_{c}}{\scriptscriptstyle 1\times 1}=\text{sigmoid}(\stackunder{\bm{w}_{c}^{T}}{\scriptscriptstyle
    1\times d_{v}}\times\stackunder{\bm{c}_{c}}{\scriptscriptstyle d_{v}\times 1}+\stackunder{b_{c}}{\scriptscriptstyle
    1\times 1}),$ |  | (44) |'
- en: 'where $\bm{w}_{c}\in\mathbb{R}^{d_{v}}$ and $b_{c}\in\mathbb{R}^{1}$ are trainable
    capsule-specific weights parameters, and $p_{c}\in\mathbb{R}^{1}$ is the predicted
    probability that the correct class is class $c$. The final layer is the reconstruction
    module that creates a class vector representation. This representation $\bm{r}_{c}\in\mathbb{R}^{d_{v}}$
    is determined by simply multiplying the context vector $\bm{c}_{c}$ by the probability
    $p_{c}$:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\bm{w}_{c}\in\mathbb{R}^{d_{v}}$ 和 $b_{c}\in\mathbb{R}^{1}$ 是可训练的胶囊特定权重参数，而
    $p_{c}\in\mathbb{R}^{1}$ 是预测正确类别为类别 $c$ 的概率。最终层是重建模块，它创建一个类别向量表示。这个表示 $\bm{r}_{c}\in\mathbb{R}^{d_{v}}$
    通过简单地将上下文向量 $\bm{c}_{c}$ 乘以概率 $p_{c}$ 来确定：
- en: '|  | $\setstackgap{L}{11pt}\stackunder{\bm{r}_{c}}{\scriptscriptstyle d_{v}\times
    1}=\stackunder{p_{c}}{\scriptscriptstyle 1\times 1}\times\stackunder{\bm{c}_{c}}{\scriptscriptstyle
    d_{v}\times 1}.$ |  | (45) |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{11pt}\stackunder{\bm{r}_{c}}{\scriptscriptstyle d_{v}\times
    1}=\stackunder{p_{c}}{\scriptscriptstyle 1\times 1}\times\stackunder{\bm{c}_{c}}{\scriptscriptstyle
    d_{v}\times 1}.$ |  | (45) |'
- en: The capsule representation is used when training the model. First of all, the
    model is trained to predict the probabilities $p_{1},\dots,p_{d_{y}}$ as accurately
    as possible compared to the true values. Secondly, via a joint loss function,
    the model is also trained to accurately construct the capsule representations
    $\bm{r}_{1},\dots,\bm{r}_{d_{y}}$. A features representation $\bm{f}\in\mathbb{R}^{d_{f}}$
    is defined which is simply the unweighted average of the original feature vectors.
    The idea is to train the model such that vector representations from capsules
    that are not the correct class differ significantly from $\bm{f}$ while the representation
    from the correct capsule is very similar to $\bm{f}$. A dot-product between the
    capsule representations and the features representation is used in [[89](#bib.bib89)]
    as a measure of the distance between the vectors. Note that $d_{v}$ must equal
    $d_{f}$ in this case, otherwise the vectors would have incompatible dimensions.
    Interestingly, since attention is calculated for each class individually, one
    can track which specific feature vectors are important for which specific class.
    In [[89](#bib.bib89)], this idea is used to discover which words correspond to
    which sentiment class.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练模型时，会使用胶囊表示。首先，模型被训练以尽可能准确地预测概率 $p_{1},\dots,p_{d_{y}}$ 与真实值相比。其次，通过一个联合损失函数，模型还被训练以准确构建胶囊表示
    $\bm{r}_{1},\dots,\bm{r}_{d_{y}}$。定义了一个特征表示 $\bm{f}\in\mathbb{R}^{d_{f}}$，它只是原始特征向量的未加权平均。其思想是训练模型，使得来自不是正确类别的胶囊的向量表示与
    $\bm{f}$ 显著不同，而来自正确胶囊的表示与 $\bm{f}$ 非常相似。在 [[89](#bib.bib89)] 中，使用胶囊表示与特征表示之间的点积作为向量之间距离的度量。请注意，在这种情况下
    $d_{v}$ 必须等于 $d_{f}$，否则向量将具有不兼容的维度。有趣的是，由于注意力是为每个类别单独计算的，因此可以追踪哪些特定的特征向量对哪些特定类别很重要。在
    [[89](#bib.bib89)] 中，利用这个思想发现哪些词汇对应于哪个情感类别。
- en: '![Refer to caption](img/9255a464b0559f8b90cf7bb3e146dc2c.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/9255a464b0559f8b90cf7bb3e146dc2c.png)'
- en: 'Figure 11: An illustration of capsule-based attention.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '图 11: 基于胶囊的注意力的示意图。'
- en: The number of tasks that can make use of multiple queries is substantial, due
    to how general the mechanisms are. As such, the techniques described in this section
    have been extensively explored in various domains. For example, multi-head attention
    has been used for speaker recognition based on audio spectrograms [[91](#bib.bib91)].
    In [[92](#bib.bib92)], multi-head attention is used for recommendation of news
    articles. Additionally, multi-head attention can be beneficial for graph attention
    models as well [[83](#bib.bib83)]. As for multi-hop attention, quite a few papers
    have been mentioned before, but there are still many other interesting examples.
    For example, in [[93](#bib.bib93)], a multi-hop attention model is proposed for
    medication recommendation. Furthermore, practically every Transformer model makes
    use of both multi-head and multi-hop attention. The Transformer model has been
    extensively explored in various domains. For example, in [[94](#bib.bib94)], a
    Transformer model is implemented for image captioning. In [[95](#bib.bib95)],
    Transformers are explored for medical image segmentation. In [[96](#bib.bib96)],
    a Transformer model is used for emotion recognition in text messages. A last example
    of an application of Transformers is [[17](#bib.bib17)], which proposes a Transformer
    model for recommender systems. In comparison with multi-head and multi-hop attention,
    capsule-based attention is arguably the least popular of the mechanisms discussed
    for the multiplicity of queries. One example is [[97](#bib.bib97)], where an attention-based
    capsule network is proposed that also includes a multi-hop attention mechanism
    for the purpose of visual question answering. Another example is [[98](#bib.bib98)],
    where capsule-based attention is used for aspect-level sentiment analysis of restaurant
    reviews.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 可以利用多个查询的任务数量是相当可观的，这得益于机制的通用性。因此，本节描述的技术在各种领域得到了广泛的探索。例如，基于音频频谱图的说话人识别中使用了**多头注意力**[[91](#bib.bib91)]。在[[92](#bib.bib92)]中，多头注意力用于新闻文章推荐。此外，多头注意力对图注意力模型也有益处[[83](#bib.bib83)]。至于**多跳注意力**，之前提到过不少论文，但仍有许多有趣的例子。例如，在[[93](#bib.bib93)]中，提出了一种用于药物推荐的多跳注意力模型。此外，几乎每个Transformer模型都使用了**多头**和**多跳**注意力。Transformer模型在各种领域得到了广泛的探索。例如，在[[94](#bib.bib94)]中，实施了一种用于图像描述的Transformer模型。在[[95](#bib.bib95)]中，探索了用于医学图像分割的Transformers。在[[96](#bib.bib96)]中，使用了Transformer模型来进行文本消息中的情感识别。Transformer应用的最后一个例子是[[17](#bib.bib17)]，提出了一种用于推荐系统的Transformer模型。与**多头**和**多跳**注意力相比，基于胶囊的注意力在处理多个查询方面可以说是最不受欢迎的机制之一。一个例子是[[97](#bib.bib97)]，其中提出了一种基于注意力的胶囊网络，该网络还包括了多跳注意力机制，用于视觉问答。另一个例子是[[98](#bib.bib98)]，其中使用基于胶囊的注意力进行餐馆评论的方面级情感分析。
- en: The multiplicity of queries is a particularly interesting category due to the
    Transformer model [[13](#bib.bib13)], which combines a form of multi-hop and multi-head
    attention. Due to the initial success of the Transformer model, many improvements
    and iterations of the model have been produced that typically aim to improve the
    predictive performance, the computational efficiency, or both. For example, the
    Transformer-XL [[99](#bib.bib99)] is an extension of the original Transformer
    that uses a recurrence mechanism to not be limited by a context window when processing
    the outputs. This allows the model to learn significantly longer dependencies
    while also being computationally more efficient during the evaluation phase. Another
    extension of the Transformer is known as the Reformer model [[100](#bib.bib100)].
    This model is significantly more efficient computationally, by means of locality-sensitive
    hashing, and memory-wise, by means of reversible residual layers. Such computational
    improvements are vital, since one of the main disadvantages of the Transformer
    model is the sheer computational cost due to the complexity of the model scaling
    quadratically with the amount of input feature vectors. The Linformer model [[101](#bib.bib101)]
    manages to reduce the complexity of the model to scale linearly, while achieving
    similar performance as the Transformer model. This is achieved by approximating
    the attention weights using a low-rank matrix. The Lite-Transformer model proposed
    in [[102](#bib.bib102)] achieves similar results by implementing two branches
    within the Transformer block that specialize in capturing global and local information.
    Another interesting Transformer architecture is the Synthesizer [[103](#bib.bib103)].
    This model replaces the pairwise self-attention mechanism with “synthetic” attention
    weights. Interestingly, the performance of this model is relatively close to the
    original Transformer, meaning that the necessity of the pairwise self-attention
    mechanism of the Transformer model may be questionable. For a more comprehensive
    overview of Transformer architectures, we refer to [[104](#bib.bib104)].
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE III: Attention models analyzed based on the proposed taxonomy. A plus
    sign (+) between two mechanisms indicates that both techniques were combined in
    the same model, while a comma (,) indicates that both mechanisms were tested in
    the same paper, but not necessarily as a combination in the same model.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Feature-Related | General | Query-Related |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
- en: '|  | Multiplicity | Levels | Representations | Scoring | Alignment | Dimensionality
    | Type | Multiplicity |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
- en: '| Bahdanau et al. [[3](#bib.bib3)] | Singular | Single-Level | Single-Representational
    | Additive | Global | Single-Dimensional | Basic | Singular |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
- en: '| Luong et al. [[4](#bib.bib4)] | Singular | Single-Level | Single-Representational
    | Multiplicative, Location | Global, Local | Single-Dimensional | Basic | Singular
    |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
- en: '| Xu et al. [[8](#bib.bib8)] | Singular | Single-Level | Single-Representational
    | Additive | Soft, Hard | Single-Dimensional | Basic | Singular |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| Xu et al. [[8](#bib.bib8)] | 单一 | 单层次 | 单一表示 | 加性 | 软、硬 | 单维度 | 基本 | 单一 |'
- en: '| Lu et al. [[32](#bib.bib32)] | Parallel Co-attention | Hierarchical | Single-Representational
    | Additive | Global | Single-Dimensional | Specialized | Singular |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| Lu et al. [[32](#bib.bib32)] | 并行共同注意 | 分层 | 单一表示 | 加性 | 全局 | 单维度 | 专门化 |
    单一 |'
- en: '| Yang et al. [[5](#bib.bib5)] | Singular | Hierarchical | Single-Representational
    | Additive | Global | Single-Dimensional | Self-Attentive | Singular |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| Yang et al. [[5](#bib.bib5)] | 单一 | 分层 | 单一表示 | 加性 | 全局 | 单维度 | 自注意力 | 单一
    |'
- en: '| Li et al. [[47](#bib.bib47)] | Singular | Hierarchical | Single-Representational
    | Additive | Global | Single-Dimensional | Self-Attentive | Singular |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| Li et al. [[47](#bib.bib47)] | 单一 | 分层 | 单一表示 | 加性 | 全局 | 单维度 | 自注意力 | 单一
    |'
- en: '| Vaswani et al. [[13](#bib.bib13)] | Singular | Single-Level | Single-Representational
    | Scaled-Multiplicative | Global | Single-Dimensional | Self-Attentive + Basic
    | Multi-Head + Multi-Hop |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| Vaswani et al. [[13](#bib.bib13)] | 单一 | 单层次 | 单一表示 | 缩放乘法 | 全局 | 单维度 | 自注意力
    + 基本 | 多头 + 多跳 |'
- en: '| Wallaart and Frasincar [[43](#bib.bib43)] | Rotatory | Single-Level | Single-Representational
    | Activated General | Global | Single-Dimensional | Specialized | Multi-Hop |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| Wallaart and Frasincar [[43](#bib.bib43)] | 旋转 | 单层次 | 单一表示 | 激活的通用 | 全局
    | 单维度 | 专门化 | 多跳 |'
- en: '| Kiela et al. [[50](#bib.bib50)] | Singular | Single-Level | Multi-Representational
    | Additive | Global | Single-Dimensional | Self-Attentive | Singular |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| Kiela et al. [[50](#bib.bib50)] | 单一 | 单层次 | 多重表示 | 加性 | 全局 | 单维度 | 自注意力
    | 单一 |'
- en: '| Shen et al. [[64](#bib.bib64)] | Singular | Single-Level | Single-Representational
    | Additive | Global | Multi-Dimensional | Self-Attentive | Singular |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| Shen et al. [[64](#bib.bib64)] | 单一 | 单层次 | 单一表示 | 加性 | 全局 | 多维度 | 自注意力 |
    单一 |'
- en: '| Zhang et al. [[74](#bib.bib74)] | Singular | Single-Level | Single-Representational
    | Multiplicative | Global | Single-Dimensional | Self-Attentive | Singular |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| Zhang et al. [[74](#bib.bib74)] | 单一 | 单层次 | 单一表示 | 乘法 | 全局 | 单维度 | 自注意力
    | 单一 |'
- en: '| Li et al. [[105](#bib.bib105)] | Parallel Co-attention | Single-Level | Single-Representational
    | Scaled-Multiplicative | Global | Single-Dimensional | Self-Attentive + Specialized
    | Singular |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| Li et al. [[105](#bib.bib105)] | 并行共同注意 | 单层次 | 单一表示 | 缩放乘法 | 全局 | 单维度 |
    自注意力 + 专门化 | 单一 |'
- en: '| Yu et al. [[106](#bib.bib106)] | Parallel Co-attention | Single-Level | Single-Representational
    | Multiplicative | Global | Single-Dimensional | Self-Attentive + Specialized
    | Multi-Head |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| Yu et al. [[106](#bib.bib106)] | 并行共同注意 | 单层次 | 单一表示 | 乘法 | 全局 | 单维度 | 自注意力
    + 专门化 | 多头 |'
- en: '| Wang et al. [[62](#bib.bib62)] | Parallel Co-attention | Single-Level | Single-Representational
    | Additive | Reinforced | Single-Dimensional | Specialized | Singular |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| Wang et al. [[62](#bib.bib62)] | 并行共同注意 | 单层次 | 单一表示 | 加性 | 强化 | 单维度 | 专门化
    | 单一 |'
- en: '| Oktay et al. [[67](#bib.bib67)] | Singular | Single-Level | Single-Representational
    | Additive | Global | Multi-Dimensional | Self-Attentive + Specialized | Singular
    |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| Oktay et al. [[67](#bib.bib67)] | 单一 | 单层次 | 单一表示 | 加性 | 全局 | 多维度 | 自注意力
    + 专门化 | 单一 |'
- en: '| Winata et al. [[52](#bib.bib52)] | Singular | Single-Level | Multi-Representational
    | Additive | Global | Single-Dimensional | Self-Attentive | Multi-Head |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| Winata et al. [[52](#bib.bib52)] | 单一 | 单层次 | 多重表示 | 加性 | 全局 | 单维度 | 自注意力
    | 多头 |'
- en: '| Wang et al. [[89](#bib.bib89)] | Singular | Single-Level | Single-Representational
    | Multiplicative | Global | Single-Dimensional | Self-Attentive | Capsule-Based
    |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| Wang et al. [[89](#bib.bib89)] | 单一 | 单层次 | 单一表示 | 乘法 | 全局 | 单维度 | 自注意力 |
    基于胶囊 |'
- en: 4 Evaluation of Attention Models
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 注意力模型的评估
- en: In this section, we present various types of evaluation for attention models.
    Firstly, one can evaluate the structure of attention models using the taxonomy
    presented in Section [3](#S3 "3 Attention Taxonomy ‣ A General Survey on Attention
    Mechanisms in Deep Learning"). For such an analysis, we consider the attention
    mechanism categories (see Fig. [3](#S2.F3 "Figure 3 ‣ 2.3 Attention Applications
    ‣ 2 General Attention Model ‣ A General Survey on Attention Mechanisms in Deep
    Learning")) as orthogonal dimensions of a model. The structure of a model can
    be analyzed by determining which mechanism a model uses for each category. Table
    [III](#S3.T3 "TABLE III ‣ 3.3.2 Multiplicity of Queries ‣ 3.3 Query-Related Attention
    Mechanisms ‣ 3 Attention Taxonomy ‣ A General Survey on Attention Mechanisms in
    Deep Learning") provides an overview of attention models found in the literature
    with a corresponding analysis based on the attention mechanisms the models implement.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了对注意力模型进行各种类型评估的方法。首先，可以使用第 [3](#S3 "3 注意力分类 ‣ 深度学习中注意力机制的一般调查") 节中提出的分类法评估注意力模型的结构。对于这样的分析，我们将注意力机制类别（见图
    [3](#S2.F3 "图 3 ‣ 2.3 注意力应用 ‣ 2 一般注意力模型 ‣ 深度学习中注意力机制的一般调查")）视为模型的正交维度。通过确定模型在每个类别中使用的机制，可以分析模型的结构。表
    [III](#S3.T3 "表 III ‣ 3.3.2 查询的多样性 ‣ 3.3 查询相关的注意力机制 ‣ 3 注意力分类 ‣ 深度学习中注意力机制的一般调查")
    提供了文献中注意力模型的概述，并根据模型实现的注意力机制进行相应的分析。
- en: Secondly, we discuss various techniques for evaluating the performance of attention
    models. The performance of attention models can be evaluated using extrinsic or
    intrinsic performance measures, which are discussed in Subsections [4.1](#S4.SS1
    "4.1 Extrinsic Evaluation ‣ 4 Evaluation of Attention Models ‣ A General Survey
    on Attention Mechanisms in Deep Learning") and [4.2](#S4.SS2 "4.2 Intrinsic Evaluation
    ‣ 4 Evaluation of Attention Models ‣ A General Survey on Attention Mechanisms
    in Deep Learning"), respectively.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们讨论了评估注意力模型性能的各种技术。注意力模型的性能可以使用外在或内在性能度量进行评估，这在小节 [4.1](#S4.SS1 "4.1 外在评估
    ‣ 4 注意力模型评估 ‣ 深度学习中注意力机制的一般调查") 和 [4.2](#S4.SS2 "4.2 内在评估 ‣ 4 注意力模型评估 ‣ 深度学习中注意力机制的一般调查")
    中分别讨论了。
- en: 4.1 Extrinsic Evaluation
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 外在评估
- en: In general, the performance of an attention model is measured using extrinsic
    performance measures. For example, performance measures typically used in the
    field of natural language processing are the BLEU [[107](#bib.bib107)], METEOR
    [[108](#bib.bib108)], and Perplexity [[109](#bib.bib109)] metrics. In the field
    of audio processing, the Word Error Rate [[110](#bib.bib110)] and Phoneme Error
    Rate [[111](#bib.bib111)] are generally employed. For general classification tasks,
    error rates, precision, and recall are generally used. For computer vision tasks,
    the PSNR [[112](#bib.bib112)], SSIM [[113](#bib.bib113)], or IoU [[114](#bib.bib114)]
    metrics are used. Using these performance measures, an attention model can either
    be compared to other state-of-the-art models, or an ablation study can be performed.
    If possible, the importance of the attention mechanism can be tested by replacing
    it with another mechanism and observing whether the overall performance of the
    model decreases [[105](#bib.bib105), [115](#bib.bib115)]. An example of this is
    replacing the weighted average used to produce the context vector with a simple
    unweighted average and observing whether there is a decrease in overall model
    performance [[35](#bib.bib35)]. This ablation method can be used to evaluate whether
    the attention weights can actually distinguish important from irrelevant information.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，注意力模型的性能通过外在性能度量来衡量。例如，自然语言处理领域通常使用的性能度量包括BLEU [[107](#bib.bib107)]、METEOR
    [[108](#bib.bib108)]和Perplexity [[109](#bib.bib109)]指标。在音频处理领域，通常使用Word Error
    Rate [[110](#bib.bib110)]和Phoneme Error Rate [[111](#bib.bib111)]。对于一般分类任务，通常使用错误率、精确度和召回率。对于计算机视觉任务，使用的指标有PSNR
    [[112](#bib.bib112)]、SSIM [[113](#bib.bib113)]或IoU [[114](#bib.bib114)]。通过这些性能度量，可以将注意力模型与其他先进的模型进行比较，或进行消融研究。如果可能，可以通过将注意力机制替换为其他机制并观察模型的整体性能是否下降，来测试注意力机制的重要性
    [[105](#bib.bib105), [115](#bib.bib115)]。一个例子是将用于生成上下文向量的加权平均替换为简单的无加权平均，并观察是否存在整体模型性能的下降
    [[35](#bib.bib35)]。这种消融方法可以用来评估注意力权重是否能够实际区分重要信息与无关信息。
- en: 4.2 Intrinsic Evaluation
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 内在评估
- en: Attention models can also be evaluated using attention-specific intrinsic performance
    measures. In [[4](#bib.bib4)], the attention weights are formally evaluated via
    the Alignment Error Rate (AER) to measure the accuracy of the attention weights
    with respect to annotated attention vectors. [[116](#bib.bib116)] incorporates
    this idea into an attention model by supervising the attention mechanism using
    gold attention vectors. A joint loss function consisting of the regular task-specific
    loss and the attention weights loss function is constructed for this purpose.
    The gold attention vectors are based on annotated text data sets where keywords
    are hand-labelled. However, since attention is inspired by human attention, one
    could evaluate attention models by comparing them to the attention behaviour of
    humans.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力模型还可以通过特定于注意力的内在性能指标来进行评估。在 [[4](#bib.bib4)] 中，通过对齐误差率（AER）正式评估注意力权重，以测量注意力权重与注释的注意力向量之间的准确性。[[116](#bib.bib116)]
    将这一思想融入到注意力模型中，通过使用黄金注意力向量来监督注意力机制。为此构建了一个联合损失函数，该函数包括常规任务特定损失和注意力权重损失函数。黄金注意力向量基于标注的文本数据集，其中关键词是手工标记的。然而，由于注意力受到人类注意力的启发，可以通过将注意力模型与人类的注意力行为进行比较来评估注意力模型。
- en: 4.2.1 Evaluation via Human Attention
  id: totrans-250
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1 人类注意力评估
- en: In [[117](#bib.bib117)], the concept of attention correctness is proposed, which
    is a quantitative intrinsic performance metric that evaluates the quality of the
    attention mechanism based on actual human attention behaviour. Firstly, the calculation
    of this metric requires data that includes the attention behaviour of a human.
    For example, a data set containing images with the corresponding regions that
    a human focuses on when performing a certain task, such as image captioning. The
    collection of regions focused on by the human is referred to as the ground truth
    region. Suppose an attention model attends to the $n_{f}$ feature vectors $\bm{f}_{1},\dots,\bm{f}_{n_{f}}\in\mathbb{R}^{d_{f}}$.
    Feature vector $\bm{f}_{i}$ corresponds to region $R_{i}$ of the given image,
    for $i=1,\dots,n_{f}$. We define the set $G$ as the set of regions that belong
    to the ground truth region, such that $R_{i}\in G$ if $R_{i}$ is part of the ground
    truth region. The attention model calculates the attention weights $a_{1},\dots,a_{n_{f}}\in\mathbb{R}^{1}$
    via the usual attention process. The Attention Correctness ($AC$) metric can then
    be calculated using ([46](#S4.E46 "In 4.2.1 Evaluation via Human Attention ‣ 4.2
    Intrinsic Evaluation ‣ 4 Evaluation of Attention Models ‣ A General Survey on
    Attention Mechanisms in Deep Learning")).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [[117](#bib.bib117)] 中，提出了注意力正确性的概念，这是一种定量内在性能指标，用于根据实际的人类注意力行为评估注意力机制的质量。首先，这一指标的计算需要包含人类注意力行为的数据。例如，一个包含图像的数据集，其中标出了人类在执行某些任务时关注的区域，如图像标题生成。人类关注的区域被称为真实区域。假设一个注意力模型关注于
    $n_{f}$ 个特征向量 $\bm{f}_{1},\dots,\bm{f}_{n_{f}}\in\mathbb{R}^{d_{f}}$。特征向量 $\bm{f}_{i}$
    对应于给定图像的区域 $R_{i}$，对于 $i=1,\dots,n_{f}$。我们将集合 $G$ 定义为属于真实区域的区域集合，使得 $R_{i}\in
    G$ 如果 $R_{i}$ 是真实区域的一部分。注意力模型通过常规的注意力过程计算注意力权重 $a_{1},\dots,a_{n_{f}}\in\mathbb{R}^{1}$。然后可以使用
    ([46](#S4.E46 "在 4.2.1 人类注意力评估 ‣ 4.2 内在评估 ‣ 4 注意力模型的评估 ‣ 深度学习中注意力机制的总体调查")) 计算注意力正确性（$AC$）指标。
- en: '|  | $\setstackgap{L}{8pt}\stackunder{AC}{\scriptscriptstyle 1\times 1}=\sum_{i:R_{i}\in
    G}\stackunder{a_{i}}{\scriptscriptstyle 1\times 1}.$ |  | (46) |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '|  | $\setstackgap{L}{8pt}\stackunder{AC}{\scriptscriptstyle 1\times 1}=\sum_{i:R_{i}\in
    G}\stackunder{a_{i}}{\scriptscriptstyle 1\times 1}.$ |  | (46) |'
- en: Thus, this metric is equal to the sum of the attention weights for the ground
    truth regions. Since the attention weights sum up to 1 due to, for example, a
    softmax alignment function, the $AC$ value will be a value between 0 and 1\. If
    the model attends to only the ground truth regions, then $AC$ is equal to 1, and
    if the attention model does not attend to any of the ground truth regions, $AC$
    will be equal to 0.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这一指标等于真实区域的注意力权重之和。由于例如软最大对齐函数使得注意力权重之和等于1，$AC$ 值将是介于 0 和 1 之间的值。如果模型仅关注真实区域，则
    $AC$ 等于 1，如果注意力模型没有关注任何真实区域，$AC$ 将等于 0。
- en: In [[118](#bib.bib118)], a rank correlation metric is used to compare the generated
    attention weights to the attention behaviour of humans. The conclusion of this
    work is that attention maps generated by standard attention models generally do
    not correspond to human attention. Attention models often focus on much larger
    regions or multiple small non-adjacent regions. As such, a technique to improve
    attention models is to allow the model to learn from human attention patterns
    via a joint loss of the regular loss function and an attention weight loss function
    based on the human gaze behaviour, similarly to how annotated attention vectors
    are used in [[116](#bib.bib116)] to supervise the attention mechanism. [[117](#bib.bib117)]
    proposes to use human attention data to supervise the attention mechanism in such
    a manner. Similarly, a state-of-the-art video captioning model is proposed in
    [[119](#bib.bib119)] that learns from human gaze data to improve the attention
    mechanism.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[118](#bib.bib118)]中，使用排名相关度指标来比较生成的注意力权重与人类的注意力行为。该工作的结论是，标准注意力模型生成的注意力图通常与人类注意力不符。注意力模型通常集中在更大的区域或多个小的非相邻区域。因此，一种改进注意力模型的技术是允许模型通过结合常规损失函数和基于人类注视行为的注意力权重损失函数来学习人类注意力模式，类似于[[116](#bib.bib116)]中用于监督注意力机制的注释注意力向量。[[117](#bib.bib117)]提议以这种方式使用人类注意力数据来监督注意力机制。类似地，在[[119](#bib.bib119)]中提出了一种最先进的视频字幕生成模型，该模型通过学习人类注视数据来改进注意力机制。
- en: 4.2.2 Manual Evaluation
  id: totrans-255
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2 手动评估
- en: A method that is often used to evaluate attention models is the manual inspection
    of attention weights. As previously mentioned, the attention weights are a direct
    indication of which parts of the data the attention model finds most important.
    Therefore, observing which parts of the inputs the model focuses on can be helpful
    in determining if the model is behaving correctly. This allows for some interpretation
    of the behaviour of models that are typically known to be black boxes. However,
    rather than checking if the model focuses on the most important parts of the data,
    some use the attention weights to determine which parts of the data are most important.
    This would imply that attention models provide a type of explanation, which is
    a subject of contention among researchers. Particularly, in [[120](#bib.bib120)],
    extensive experiments are conducted for various natural language processing tasks
    to investigate the relation between attention weights and important information
    to determine whether attention can actually provide meaningful explanations. In
    this paper titled “Attention is not Explanation”, it is found that attention weights
    do not tend to correlate with important features. Additionally, the authors are
    able to replace the produced attention weights with completely different values
    while keeping the model output the same. These so-called “adversarial” attention
    distributions show that an attention model may focus on completely different information
    and still come to the same conclusions, which makes interpretation difficult.
    Yet, in another paper titled “Attention is not not Explanation” [[121](#bib.bib121)],
    the claim that attention is not explanation is questioned by challenging the assumptions
    of the previous work. It is found that the adversarial attention distributions
    do not perform as reliably well as the learned attention weights, indicating that
    it was not proved that attention is not viable for explanation.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 评估注意力模型的方法之一是手动检查注意力权重。如前所述，注意力权重直接指示了注意力模型认为数据的哪些部分最为重要。因此，观察模型集中于输入的哪些部分对于确定模型是否正常工作非常有帮助。这为通常被认为是黑箱的模型行为提供了一些解释。然而，与其检查模型是否集中于数据中最重要的部分，一些人使用注意力权重来确定数据中哪些部分最重要。这意味着注意力模型提供了一种解释，这在研究人员中存在争议。特别是在[[120](#bib.bib120)]中，进行了广泛的实验来调查注意力权重与重要信息之间的关系，以确定注意力是否真的能提供有意义的解释。在题为“注意力不是解释”的论文中发现，注意力权重通常与重要特征不相关。此外，作者能够用完全不同的值替换生成的注意力权重，同时保持模型输出不变。这些所谓的“对抗性”注意力分布表明，注意力模型可能关注完全不同的信息而仍得出相同的结论，这使得解释变得困难。然而，在另一篇题为“注意力不是不解释”的论文[[121](#bib.bib121)]中，通过挑战先前工作的假设质疑了注意力不是解释的观点。发现对抗性注意力分布的表现不如学习到的注意力权重可靠，表明尚未证明注意力不能用于解释。
- en: In general, the conclusion regarding the interpretability of attention models
    is that researchers must be extremely careful when drawing conclusions based on
    attention patterns. For example, problems with an attention model can be diagnosed
    via the attention weights if the model is found to focus on the incorrect parts
    of the data, if such information is available. Yet, conversely, attention weights
    may only be used to obtain plausible explanations for why certain parts of the
    data are focused on, rather than concluding that those parts are significant to
    the problem [[121](#bib.bib121)]. However, one should still be cautious as the
    viability of such approaches can depend on the model architecture [[122](#bib.bib122)].
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: 5 Conclusion
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this survey, we have provided an overview of recent research on attention
    models in deep learning. Attention mechanisms have been a prominent development
    for deep learning models as they have shown to improve model performance significantly,
    producing state-of-the-art results for various tasks in several fields of research.
    We have presented a comprehensive taxonomy that can be used to categorize and
    explain the diverse number of attention mechanisms proposed in the literature.
    The organization of the taxonomy was motivated based on the structure of a task
    model that consists of a feature model, an attention model, a query model, and
    an output model. Furthermore, the attention mechanisms have been discussed using
    a framework based on queries, keys, and values. Last, we have shown how one can
    use extrinsic and intrinsic measures to evaluate the performance of attention
    models, and how one can use the taxonomy to analyze the structure of attention
    models.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: The attention mechanism is typically relatively simple to understand and implement
    and can lead to significant improvements in performance. As such, it is no surprise
    that this is a highly active field of research with new attention mechanisms and
    models being developed constantly. Not only are new mechanisms consistently being
    developed, but there is also still ample opportunity for the exploration of existing
    mechanisms for new tasks. For example, multi-dimensional attention [[64](#bib.bib64)]
    is a technique that shows promising results and is general enough to be implemented
    in almost any attention model. However, it has not seen much application in current
    works. Similarly, multi-head attention [[13](#bib.bib13)] is a technique that
    can be efficiently parallelized and implemented in practically any attention model.
    Yet, it is mostly seen only in Transformer-based architectures. Lastly, similarly
    to how [[43](#bib.bib43)] combines rotatory attention with multi-hop attention,
    combining multi-dimensional attention, multi-head attention, capsule-based attention,
    or any of the other mechanisms presented in this survey may produce new state-of-the-art
    results for the various fields of research mentioned in this survey.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: This survey has mainly focused on attention mechanisms for supervised models,
    since these comprise the largest proportion of the attention models in the literature.
    In comparison to the total amount of research that has been done on attention
    models, research on attention models for semi-supervised learning [[123](#bib.bib123),
    [124](#bib.bib124)] or unsupervised learning [[125](#bib.bib125), [126](#bib.bib126)]
    has received limited attention and has only become active recently. Attention
    may play a more significant role for such tasks in the future as obtaining large
    amounts of labeled data is a difficult task. Yet, as larger and more detailed
    data sets become available, the research on attention models can advance even
    further. For example, we mentioned the fact that attention weights can be trained
    directly based on hand-annotated data [[116](#bib.bib116)] or actual human attention
    behaviour [[117](#bib.bib117), [119](#bib.bib119)]. As new data sets are released,
    future research may focus on developing attention models that can incorporate
    those types of data.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查主要集中在监督模型的注意力机制上，因为这些模型占据了文献中注意力模型的最大比例。与对注意力模型进行的总体研究相比，针对半监督学习[[123](#bib.bib123)、[124](#bib.bib124)]或无监督学习[[125](#bib.bib125)、[126](#bib.bib126)]的注意力模型研究受到了有限关注，并且只是在最近才开始活跃。由于获得大量标注数据是一项艰巨的任务，注意力机制在这些任务中可能在未来扮演更重要的角色。然而，随着更大、更详细的数据集的可用，注意力模型的研究可以更进一步。例如，我们提到注意力权重可以基于手工标注的数据[[116](#bib.bib116)]或实际的人类注意行为[[117](#bib.bib117)、[119](#bib.bib119)]直接进行训练。随着新数据集的发布，未来的研究可能会集中在开发能够融入这些数据类型的注意力模型上。
- en: While attention is intuitively easy to understand, there still is a substantial
    lack of theoretical support for attention. As such, we expect more theoretical
    studies to additionally contribute to the understanding of the attention mechanisms
    in complex deep learning systems. Nevertheless, the practical advantages of attention
    models are clear. Since attention models provide significant performance improvements
    in a variety of fields, and as there are ample opportunities for more advancements,
    we foresee that these models will still receive significant attention in the time
    to come.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然注意力机制直观上容易理解，但仍然缺乏理论支持。因此，我们期望更多的理论研究能进一步加深对复杂深度学习系统中注意力机制的理解。尽管如此，注意力模型的实际优势是显而易见的。由于注意力模型在多个领域提供了显著的性能提升，并且还有许多进一步发展的机会，我们预见这些模型在未来仍将受到广泛关注。
- en: References
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] H. Larochelle and G. E. Hinton, “Learning to combine foveal glimpses with
    a third-order Boltzmann machine,” in *24th Annual Conference in Neural Information
    Processing Systems (NIPS 2010)*.   Curran Associates, Inc., 2010, pp. 1243–1251.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] H. Larochelle 和 G. E. Hinton, “学习将视网膜窥视与三阶玻尔兹曼机结合起来，” *第24届神经信息处理系统年会 (NIPS
    2010)*。Curran Associates, Inc., 2010, 页 1243–1251。'
- en: '[2] V. Mnih, N. Heess, A. Graves, and k. kavukcuoglu, “Recurrent models of
    visual attention,” in *27th Annual Conference on Neural Information Processing
    Systems (NIPS 2014)*.   Curran Associates, Inc., 2014, pp. 2204–2212.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] V. Mnih, N. Heess, A. Graves, 和 k. kavukcuoglu, “视觉注意力的递归模型，” *第27届神经信息处理系统年会
    (NIPS 2014)*。Curran Associates, Inc., 2014, 页 2204–2212。'
- en: '[3] D. Bahdanau, K. Cho, and Y. Bengio, “Neural machine translation by jointly
    learning to align and translate,” in *3rd International Conference on Learning
    Representation (ICLR 2015)*, 2015.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] D. Bahdanau, K. Cho, 和 Y. Bengio, “通过联合学习对齐和翻译的神经机器翻译，” *第三届国际学习表征会议 (ICLR
    2015)*, 2015。'
- en: '[4] T. Luong, H. Pham, and C. D. Manning, “Effective approaches to attention-based
    neural machine translation,” in *2015 Conference on Empirical Methods in Natural
    Language Processing (EMNLP 2015)*.   ACL, 2015, pp. 1412–1421.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] T. Luong, H. Pham, 和 C. D. Manning, “基于注意力的神经机器翻译的有效方法，” *2015年自然语言处理实证方法会议
    (EMNLP 2015)*。ACL, 2015, 页 1412–1421。'
- en: '[5] Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and E. Hovy, “Hierarchical
    attention networks for document classification,” in *2016 Conference of the North
    American Chapter of the Association for Computational Linguistics: Human Language
    Technologies (NAACL-HLT 2016)*.   ACL, 2016, pp. 1480–1489.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, 和 E. Hovy, “用于文档分类的层次注意力网络，”
    *2016年北美计算语言学协会会议：人类语言技术 (NAACL-HLT 2016)*。ACL, 2016, 页 1480–1489。'
- en: '[6] Y. Wang, M. Huang, X. Zhu, and L. Zhao, “Attention-based LSTM for aspect-level
    sentiment classification,” in *2016 Conference on Empirical Methods in Natural
    Language Processing (EMNLP 2016)*.   ACL, 2016, pp. 606–615.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] P. Anderson, X. He, C. Buehler, D. Teney, M. Johnson, S. Gould, and L. Zhang,
    “Bottom-up and top-down attention for image captioning and visual question answering,”
    in *2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR
    2018)*, 2018, pp. 6077–6086.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel,
    and Y. Bengio, “Show, attend and tell: Neural image caption generation with visual
    attention,” in *32nd International Conference on Machine Learning (ICML 2015)*,
    vol. 37.   PMLR, 2015, pp. 2048–2057.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Y. Ma, H. Peng, and E. Cambria, “Targeted aspect-based sentiment analysis
    via embedding commonsense knowledge into an attentive LSTM,” in *32nd AAAI Conference
    on Artificial Intelligence (AAAI 2018)*.   AAAI Press, 2018, pp. 5876–5883.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] J. K. Chorowski, D. Bahdanau, D. Serdyuk, K. Cho, and Y. Bengio, “Attention-based
    models for speech recognition,” in *28th Annual Conference on Neural Information
    Processing Systems (NIPS 2015)*.   Curran Associates, Inc., 2015, pp. 577–585.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] D. Bahdanau, J. Chorowski, D. Serdyuk, P. Brakel, and Y. Bengio, “End-to-end
    attention-based large vocabulary speech recognition,” in *2016 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP 2016)*.   IEEE Signal
    Processing Society, 2016, pp. 4945–4949.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] S. Kim, T. Hori, and S. Watanabe, “Joint CTC-attention based end-to-end
    speech recognition using multi-task learning,” in *2017 IEEE International Conference
    on Acoustics, Speech and Signal Processing (ICASSP 2017)*.   IEEE Signal Processing
    Society, 2017, pp. 4835–4839.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    L. u. Kaiser, and I. Polosukhin, “Attention is all you need,” in *31st Annual
    Conference on Neural Information Processing Systems (NIPS 2017)*.   Curran Associates,
    Inc., 2017, pp. 5998–6008.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] K. Cho, B. van Merriënboer, D. Bahdanau, and Y. Bengio, “On the properties
    of neural machine translation: Encoder–decoder approaches,” in *8th Workshop on
    Syntax, Semantics and Structure in Statistical Translation (SSST 2014)*.   ACL,
    2014, pp. 103–111.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] N. Parmar, A. Vaswani, J. Uszkoreit, L. Kaiser, N. Shazeer, A. Ku, and
    D. Tran, “Image Transformer,” in *35th International Conference on Machine Learning
    (ICML 2018)*, vol. 80.   PMLR, 2018, pp. 4055–4064.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] L. Zhou, Y. Zhou, J. J. Corso, R. Socher, and C. Xiong, “End-to-end dense
    video captioning with masked transformer,” in *2018 IEEE/CVF Conference on Computer
    Vision and Pattern Recognition (CVPR 2018)*.   IEEE Computer Society, 2018, pp.
    8739–8748.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] F. Sun, J. Liu, J. Wu, C. Pei, X. Lin, W. Ou, and P. Jiang, “BERT4Rec:
    Sequential recommendation with bidirectional encoder representations from transformer,”
    in *28th ACM International Conference on Information and Knowledge Management
    (CIKM 2019)*.   ACM, 2019, p. 1441–1450.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] F. Wang and D. M. J. Tax, “Survey on the attention based RNN model and
    its applications in computer vision,” *arXiv:1601.06823*, 2016.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] J. B. Lee, R. A. Rossi, S. Kim, N. K. Ahmed, and E. Koh, “Attention models
    in graphs: A survey,” *ACM Transitions on Knowledge Discovery from Data*, vol. 13,
    pp. 62:1–62:25, 2019.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] S. Chaudhari, V. Mithal, G. Polatkan, and R. Ramanath, “An attentive survey
    of attention models,” *ACM Transactions on Intelligent Systems and Technology*,
    vol. 12, no. 5, pp. 1–32, 2021.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] D. Hu, “An introductory survey on attention mechanisms in NLP problems,”
    in *Proceedings of the 2019 Intelligent Systems Conference (IntelliSys 2019)*,
    ser. AISC, vol. 1038.   Springer, 2020, pp. 432–448.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] A. Galassi, M. Lippi, and P. Torroni, “Attention, please! a critical review
    of neural attention models in natural language processing,” *arXiv:1902.02181*,
    2019.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] M. Daniluk, T. Rocktäschel, J. Welbl, and S. Riedel, “Frustratingly short
    attention spans in neural language modeling,” in *5th International Conference
    on Learning Representations (ICLR 2017)*, 2017.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Y. Xu, Q. Kong, Q. Huang, W. Wang, and M. D. Plumbley, “Attention and
    localization based on a deep convolutional recurrent model for weakly supervised
    audio tagging,” in *Proceedings of the 18th Annual Conference of the International
    Speech Communication Association (Interspeech 2017)*.   ISCA, 2017, pp. 3083–3087.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] C. Yu, K. S. Barsim, Q. Kong, and B. Yang, “Multi-level attention model
    for weakly supervised audio classification,” in *Proceedings of the Detection
    and Classification of Acoustic Scenes and Events 2018 Workshop (DCASE 2018)*,
    2018, pp. 188–192.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] S. Sharma, R. Kiros, and R. Salakhutdinov, “Action recognition using visual
    attention,” in *Proceedings of the 4th International Conference on Learning Representations
    Workshop (ICLR 2016)*, 2016.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] L. Gao, Z. Guo, H. Zhang, X. Xu, and H. T. Shen, “Video captioning with
    attention-based LSTM and semantic consistency,” *IEEE Transactions on Multimedia*,
    vol. 19, no. 9, pp. 2045–2055, 2017.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] H. Ying, F. Zhuang, F. Zhang, Y. Liu, G. Xu, X. Xie, H. Xiong, and J. Wu,
    “Sequential recommender system based on hierarchical attention networks,” in *27th
    International Joint Conference on Artificial Intelligence (IJCAI 2018)*.   IJCAI,
    2018, pp. 3926–3932.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] H. Song, D. Rajan, J. Thiagarajan, and A. Spanias, “Attend and diagnose:
    Clinical time series analysis using attention models,” in *32nd AAAI Conference
    on Artificial Intelligence (AAAI 2018)*.   AAAI Press, 2018, pp. 4091–4098.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] D. T. Tran, A. Iosifidis, J. Kanniainen, and M. Gabbouj, “Temporal attention-augmented
    bilinear network for financial time-series data analysis,” *IEEE Transactions
    on Neural Networks and Learning Systems*, vol. 30, no. 5, pp. 1407–1418, 2019.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio,
    “Graph attention networks,” in *6th International Conference on Learning Representations
    (ICLR 2018)*, 2018.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] J. Lu, J. Yang, D. Batra, and D. Parikh, “Hierarchical question-image
    co-attention for visual question answering,” in *30th Annual Conference on Neural
    Information Processing Systems (NIPS 2016)*.   Curran Associates, Inc., 2016,
    pp. 289–297.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] F. Fan, Y. Feng, and D. Zhao, “Multi-grained attention network for aspect-level
    sentiment classification,” in *2018 Conference on Empirical Methods in Natural
    Language Processing (EMNLP 2018)*.   ACL, 2018, pp. 3433–3442.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] D. Ma, S. Li, X. Zhang, and H. Wang, “Interactive attention networks for
    aspect-level sentiment classification,” in *26th International Joint Conference
    on Artificial Intelligence (IJCAI 2017)*.   IJCAI, 2017, pp. 4068–4074.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] M. Seo, A. Kembhavi, A. Farhadi, and H. Hajishirzi, “Bidirectional attention
    flow for machine comprehension,” in *4th International Conference on Learning
    Representations (ICLR 2016)*, 2016.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] S. Zheng and R. Xia, “Left-center-right separated neural network for aspect-based
    sentiment analysis with rotatory attention,” *arXiv:1802.00892*, 2018.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] B. Jing, P. Xie, and E. Xing, “On the automatic generation of medical
    imaging reports,” in *56th Annual Meeting of the Association for Computational
    Linguistics (ACL 2018)*.   ACL, 2018, pp. 2577–2586.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] J. Gao, X. Wang, Y. Wang, Z. Yang, J. Gao, J. Wang, W. Tang, and X. Xie,
    “CAMP: Co-attention memory networks for diagnosis prediction in healthcare,” in
    *2019 IEEE International Conference on Data Mining (ICDM 2019)*.   IEEE, 2019,
    pp. 1036–1041.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] Y. Tay, A. T. Luu, and S. C. Hui, “Multi-pointer co-attention networks
    for recommendation,” in *24th ACM SIGKDD International Conference on Knowledge
    Discovery & Data Mining (KDD 2018)*.   ACM, 2018, pp. 2309–2318.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] S. Liu, Z. Chen, H. Liu, and X. Hu, “User-video co-attention network for
    personalized micro-video recommendation,” in *2019 World Wide Web Conference (WWW
    2019)*.   ACM, 2019, pp. 3020–3026.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] M. Tu, G. Wang, J. Huang, Y. Tang, X. He, and B. Zhou, “Multi-hop reading
    comprehension across multiple documents by reasoning over heterogeneous graphs,”
    in *57th Annual Meeting of the Association for Computational Linguistics (ACL
    2019)*.   Association for Computational Linguistics, 2019, pp. 2704–2713.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] Y.-J. Lu and C.-T. Li, “GCAN: Graph-aware co-attention networks for explainable
    fake news detection on social media,” in *58th Annual Meeting of the Association
    for Computational Linguistics (ACL 2020)*.   ACL, 2020, pp. 505–514.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] O. Wallaart and F. Frasincar, “A hybrid approach for aspect-based sentiment
    analysis using a lexicalized domain ontology and attentional neural models,” in
    *16th Extended Semantic Web Conference (ESWC 2019)*, ser. LNCS, vol. 11503.   Springer,
    2019, pp. 363–378.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] S. Zhao and Z. Zhang, “Attention-via-attention neural machine translation,”
    in *32nd AAAI Conference on Artificial Intelligence (AAAI 2018)*.   AAAI Press,
    2018, pp. 563–570.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] L. Wu, L. Chen, R. Hong, Y. Fu, X. Xie, and M. Wang, “A hierarchical attention
    model for social contextual image recommendation,” *IEEE Transactions on Knowledge
    and Data Engineering*, 2019.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] Y. Wang, S. Wang, J. Tang, N. O’Hare, Y. Chang, and B. Li, “Hierarchical
    attention network for action recognition in videos,” *arXiv:1607.06416*, 2016.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] Z. Li, Y. Wei, Y. Zhang, and Q. Yang, “Hierarchical attention transfer
    network for cross-domain sentiment classification,” in *32nd AAAI Conference on
    Artificial Intelligence (AAAI 2018)*.   AAAI Press, 2018, pp. 5852–5859.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] C. Xing, Y. Wu, W. Wu, Y. Huang, and M. Zhou, “Hierarchical recurrent
    attention network for response generation,” in *32nd AAAI Conference on Artificial
    Intelligence (AAAI 2018)*.   AAAI Press, 2018, pp. 5610–5617.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] V. A. Sindagi and V. M. Patel, “HA-CCN: Hierarchical attention-based crowd
    counting network,” *IEEE Transactions on Image Processing*, vol. 29, pp. 323–335,
    2019.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] D. Kiela, C. Wang, and K. Cho, “Dynamic meta-embeddings for improved sentence
    representations,” in *2018 Conference on Empirical Methods in Natural Language
    Processing (EMNLP 2018)*.   ACL, 2018, pp. 1466–1477.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] S. Maharjan, M. Montes, F. A. González, and T. Solorio, “A genre-aware
    attention model to improve the likability prediction of books,” in *2018 Conference
    on Empirical Methods in Natural Language Processing (EMNLP 2018)*.   ACL, 2018,
    pp. 3381–3391.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] G. I. Winata, Z. Lin, and P. Fung, “Learning multilingual meta-embeddings
    for code-switching named entity recognition,” in *4th Workshop on Representation
    Learning for NLP (RepL4NLP 2019)*.   ACL, 2019, pp. 181–186.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] R. Jin, L. Lu, J. Lee, and A. Usman, “Multi-representational convolutional
    neural networks for text classification,” *Computational Intelligence*, vol. 35,
    no. 3, pp. 599–609, 2019.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] A. Sordoni, P. Bachman, A. Trischler, and Y. Bengio, “Iterative alternating
    neural attention for machine reading,” *arXiv:1606.02245*, 2016.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] A. Graves, G. Wayne, and I. Danihelka, “Neural Turing machines,” *arXiv:1410.5401*,
    2014.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] D. Britz, A. Goldie, M.-T. Luong, and Q. Le, “Massive exploration of neural
    machine translation architectures,” in *2017 Conference on Empirical Methods in
    Natural Language Processing (EMNLP 2017)*.   ACL, 2017, pp. 1442–1451.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] R. J. Williams, “Simple statistical gradient-following algorithms for
    connectionist reinforcement learning,” *Machine Learning*, vol. 8, no. 3, pp.
    229–256, 1992.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] T. Shen, T. Zhou, G. Long, J. Jiang, S. Wang, and C. Zhang, “Reinforced
    self-attention network: a hybrid of hard and soft attention for sequence modeling,”
    in *27th International Joint Conference on Artificial Intelligence (IJCAI 2018)*.   IJCAI,
    2018, pp. 4345–4352.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] M. Malinowski, C. Doersch, A. Santoro, and P. Battaglia, “Learning visual
    question answering by bootstrapping hard attention,” in *2018 European Conference
    on Computer Vision (ECCV 2018)*, 2018.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] Y. Liu, W. Wang, Y. Hu, J. Hao, X. Chen, and Y. Gao, “Multi-agent game
    abstraction via graph attention neural network,” in *34th AAAI Conference on Artificial
    Intelligence (AAAI 2020)*, vol. 34, no. 05.   AAAI Press, 2020, pp. 7211–7218.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] S. Seo, J. Huang, H. Yang, and Y. Liu, “Interpretable convolutional neural
    networks with dual local and global attention for review rating prediction,” in
    *11th ACM Conference on Recommender Systems (RecSys 2017)*.   ACM, 2017, pp. 297–305.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] J. Wang, C. Sun, S. Li, X. Liu, L. Si, M. Zhang, and G. Zhou, “Aspect
    sentiment classification towards question-answering with reinforced bidirectional
    attention network,” in *57th Annual Meeting of the Association for Computational
    Linguistics (ACL 2019)*.   ACL, 2019, pp. 3548–3557.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] M. Jiang, C. Li, J. Kong, Z. Teng, and D. Zhuang, “Cross-level reinforced
    attention network for person re-identification,” *Journal of Visual Communication
    and Image Representation*, vol. 69, p. 102775, 2020.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] T. Shen, T. Zhou, G. Long, J. Jiang, S. Pan, and C. Zhang, “DiSAN: Directional
    self-attention network for RNN/CNN-free language understanding,” in *32nd AAAI
    Conference on Artificial Intelligence (AAAI 2018)*.   AAAI Press, 2018, pp. 5446–5455.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] O. Arshad, I. Gallo, S. Nawaz, and A. Calefati, “Aiding intra-text representations
    with visual context for multimodal named entity recognition,” in *2019 International
    Conference on Document Analysis and Recognition (ICDAR 2019)*.   IEEE, 2019, pp.
    337–342.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] W. Wu, X. Sun, and H. Wang, “Question condensing networks for answer selection
    in community question answering,” in *Proceedings of the 56th Annual Meeting of
    the Association for Computational Linguistics (ACL 2018)*.   ACL, 2018, pp. 1746–1755.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] O. Oktay, J. Schlemper, L. L. Folgoc, M. Lee, M. Heinrich, K. Misawa,
    K. Mori, S. McDonagh, N. Y. Hammerla, B. Kainz, B. Glocker, and D. Rueckert, “Attention
    U-Net: Learning where to look for the pancreas,” in *1st Medical Imaging with
    Deep Learning Conference (MIDL 2018)*, 2018.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] R. Tan, J. Sun, B. Su, and G. Liu, “Extending the transformer with context
    and multi-dimensional mechanism for dialogue response generation,” in *8th International
    Conference on Natural Language Processing and Chinese Computing (NLPCC 2019)*,
    ser. LNCS, J. Tang, M.-Y. Kan, D. Zhao, S. Li, and H. Zan, Eds., vol. 11839.   Springer,
    2019, pp. 189–199.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] L. Chen, B. Lv, C. Wang, S. Zhu, B. Tan, and K. Yu, “Schema-guided multi-domain
    dialogue state tracking with graph attention neural networks,” in *34th AAAI Conference
    on Artificial Intelligence (AAAI 2020)*, vol. 34, no. 05.   AAAI Press, 2020,
    pp. 7521–7528.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] H. Wang, G. Liu, A. Liu, Z. Li, and K. Zheng, “Dmran: A hierarchical fine-grained
    attention-based network for recommendation,” in *28th International Joint Conference
    on Artificial Intelligence (IJCAI 2019)*.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] Z. Lin, M. Feng, C. N. d. Santos, M. Yu, B. Xiang, B. Zhou, and Y. Bengio,
    “A structured self-attentive sentence embedding,” in *5th International Conference
    on Learning Representations (ICLR 2017)*, 2017.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] J. L. Ba, J. R. Kiros, and G. E. Hinton, “Layer normalization,” *arXiv:1607.06450*,
    2016.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] H. Zhao, J. Jia, and V. Koltun, “Exploring self-attention for image recognition,”
    in *2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR
    2020)*, 2020, pp. 10 076–10 085.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] H. Zhang, I. Goodfellow, D. Metaxas, and A. Odena, “Self-attention generative
    adversarial networks,” in *36th International Conference on Machine Learning (ICML
    2019)*, ser. Proceedings of Machine Learning Research, K. Chaudhuri and R. Salakhutdinov,
    Eds., vol. 97.   PMLR, 2019, pp. 7354–7363.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, and Y. Bengio, “Generative adversarial nets,” in *27th Annual Conference
    on Neural Information Processing Systems (NIPS 2014)*.   Curran Associates, Inc.,
    2014, pp. 2672–2680.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] A. Sinha and J. Dolz, “Multi-scale self-guided attention for medical image
    segmentation,” *IEEE Journal of Biomedical and Health Informatics*, vol. 25, no. 1,
    pp. 121–130, 2021.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] J. Fajtl, H. S. Sokeh, V. Argyriou, D. Monekosso, and P. Remagnino, “Summarizing
    videos with attention,” in *2018 Asian Conference on Computer Vision (ACCV 2018)*,
    ser. LNCS, vol. 11367.   Springer, 2018, pp. 39–54.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] J. Salazar, K. Kirchhoff, and Z. Huang, “Self-attention networks for connectionist
    temporal classification in speech recognition,” in *2019 IEEE International Conference
    on Acoustics, Speech and Signal Processing (ICASSP 2019)*.   IEEE, 2019, pp. 7115–7119.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] T. Afouras, J. S. Chung, A. Senior, O. Vinyals, and A. Zisserman, “Deep
    audio-visual speech recognition,” *IEEE Transactions on Pattern Analysis and Machine
    Intelligence*, pp. 1–1, 2018.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] S. Zhang, Y. Tay, L. Yao, and A. Sun, “Next item recommendation with self-attention,”
    *arXiv preprint arXiv:1808.06414*, 2018.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] G. Letarte, F. Paradis, P. Giguère, and F. Laviolette, “Importance of
    self-attention for sentiment analysis,” in *2018 Workshop BlackboxNLP: Analyzing
    and Interpreting Neural Networks for NLP (BlackboxNLP 2018)*.   ACL, 2018, pp.
    267–275.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] A. Sankar, Y. Wu, L. Gou, W. Zhang, and H. Yang, “Dysat: Deep neural representation
    learning on dynamic graphs via self-attention networks,” in *13th International
    Conference on Web Search and Data Mining (WSDM 2020)*, 2020, pp. 519–527.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Liò, and Y. Bengio,
    “Graph attention networks,” in *5th International Conference on Learning Representations
    (ICLR 2017)*, 2017.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] S. Iida, R. Kimura, H. Cui, P.-H. Hung, T. Utsuro, and M. Nagata, “Attention
    over heads: A multi-hop attention for neural machine translation,” in *57th Annual
    Meeting of the Association for Computational Linguistics: Student Research Workshop
    (ACL-SRW 2019)*.   ACL, 2019, pp. 217–222.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] N. K. Tran and C. Niedereée, “Multihop attention networks for question
    answer matching,” in *41st ACM SIGIR International Conference on Research & Development
    in Information Retrieval (SIGIR 2018)*.   ACM, 2018, pp. 325–334.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] Y. Gong and S. R. Bowman, “Ruminating reader: Reasoning with gated multi-hop
    attention,” in *5th International Conference on Learning Representation (ICLR
    2017)*, 2017.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] S. Yoon, S. Byun, S. Dey, and K. Jung, “Speech emotion recognition using
    multi-hop attention mechanism,” in *2019 IEEE International Conference on Acoustics,
    Speech and Signal Processing (ICASSP 2019)*.   IEEE, 2019, pp. 2822–2826.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] Z. Yang, X. He, J. Gao, L. Deng, and A. Smola, “Stacked attention networks
    for image question answering,” in *2016 IEEE/CVF Conference on Computer Vision
    and Pattern Recognition (CVPR 2016)*, 2016, pp. 21–29.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] Y. Wang, A. Sun, J. Han, Y. Liu, and X. Zhu, “Sentiment analysis by capsules,”
    in *2018 World Wide Web Conference (WWW 2018)*.   ACM, 2018, p. 1165–1174.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] S. Sabour, N. Frosst, and G. E. Hinton, “Dynamic routing between capsules,”
    in *31st Annual Conference on Neural Information Processing Systems (NIPS 2017)*.   Curran
    Associates, Inc., 2017, p. 3859–3869.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] M. India, P. Safari, and J. Hernando, “Self multi-head attention for speaker
    recognition,” in *Proceedings of the 20th Annual Conference of the International
    Speech Communication Association (Interspeech 2019)*.   ISCA, 2019, pp. 2822–2826.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] C. Wu, F. Wu, S. Ge, T. Qi, Y. Huang, and X. Xie, “Neural news recommendation
    with multi-head self-attention,” in *2019 Conference on Empirical Methods in Natural
    Language Processing and the 9th International Joint Conference on Natural Language
    Processing (EMNLP-IJCNLP 2019)*.   ACL, 2019, pp. 6389–6394.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] Y. Wang, W. Chen, D. Pi, and L. Yue, “Adversarially regularized medication
    recommendation model with multi-hop memory network,” *Knowledge and Information
    Systems*, vol. 63, no. 1, pp. 125–142, 2021.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] M. Cornia, M. Stefanini, L. Baraldi, and R. Cucchiara, “Meshed-memory
    transformer for image captioning,” in *2020 IEEE/CVF Conference on Computer Vision
    and Pattern Recognition (CVPR 2020)*, 2020, pp. 10 578–10 587.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] J. Chen, Y. Lu, Q. Yu, X. Luo, E. Adeli, Y. Wang, L. Lu, A. L. Yuille,
    and Y. Zhou, “TransUnet: Transformers make strong encoders for medical image segmentation,”
    *arXiv preprint arXiv:2102.04306*, 2021.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] P. Zhong, D. Wang, and C. Miao, “Knowledge-enriched transformer for emotion
    detection in textual conversations,” in *2019 Conference on Empirical Methods
    in Natural Language Processing and the 9th International Joint Conference on Natural
    Language Processing (EMNLP-IJCNLP 2019)*.   ACL, 2019, pp. 165–176.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] Y. Zhou, R. Ji, J. Su, X. Sun, and W. Chen, “Dynamic capsule attention
    for visual question answering,” in *33rd AAAI Conference on Artificial Intelligence
    (AAAI 2019)*, vol. 33, no. 01.   AAAI Press, 2019, pp. 9324–9331.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] Y. Wang, A. Sun, M. Huang, and X. Zhu, “Aspect-level sentiment analysis
    using AS-capsules,” in *The World Wide Web Conference*, 2019, pp. 2033–2044.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] Z. Dai, Z. Yang, Y. Yang, J. Carbonell, Q. Le, and R. Salakhutdinov, “Transformer-XL:
    Attentive language models beyond a fixed-length context,” in *57th Annual Meeting
    of the Association for Computational Linguistics (ACL 2019)*.   ACL, 2019, pp.
    2978–2988.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] N. Kitaev, Ł. Kaiser, and A. Levskaya, “Reformer: The efficient Transformer,”
    in *8th International Conference on Learning Representations (ICLR 2020)*, 2020.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] S. Wang, B. Li, M. Khabsa, H. Fang, and H. Ma, “Linformer: Self-attention
    with linear complexity,” *arXiv:2006.04768*, 2020.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] Z. Wu, Z. Liu, J. Lin, Y. Lin, and S. Han, “Lite transformer with long-short
    range attention,” in *8th International Conference on Learning Representations
    (ICLR 2020)*, 2020.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] Y. Tay, D. Bahri, D. Metzler, D.-C. Juan, Z. Zhao, and C. Zheng, “Synthesizer:
    Rethinking self-attention for transformer models,” in *Proceedings of the 38th
    International Conference on Machine Learning (ICML 2021)*, vol. 139.   PMLR, 2021,
    pp. 10 183–10 192.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] Y. Tay, M. Dehghani, D. Bahri, and D. Metzler, “Efficient transformers:
    A survey,” *arXiv:2009.06732*, 2020.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] X. Li, J. Song, L. Gao, X. Liu, W. Huang, X. He, and C. Gan, “Beyond
    RNNs: Positional self-attention with co-attention for video question answering,”
    in *33rd AAAI Conference on Artificial Intelligence (AAAI 2019)*, vol. 33.   AAAI
    Press, 2019, pp. 8658–8665.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] A. W. Yu, D. Dohan, M.-T. Luong, R. Zhao, K. Chen, M. Norouzi, and Q. V.
    Le, “QANet: Combining local convolution with global self-attention for reading
    comprehension,” in *6th International Conference on Learning Representations (ICLR
    2018)*, 2018.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, “BLEU: a method for automatic
    evaluation of machine translation,” in *40th Annual Meeting of the Association
    for Computational Linguistics (ACL 2002)*.   ACL, 2002, pp. 311–318.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] S. Banerjee and A. Lavie, “METEOR: An automatic metric for MT evaluation
    with improved correlation with human judgments,” in *2005 Workshop on Intrinsic
    and Extrinsic Evaluation Measures for Machine Translation and/or Summarization*.   ACL,
    2005, pp. 65–72.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] R. Sennrich, “Perplexity minimization for translation model domain adaptation
    in statistical machine translation,” in *13th Conference of the European Chapter
    of the Association for Computational Linguistics (EACL 2012)*.   ACL, 2012, pp.
    539–549.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] M. Popović and H. Ney, “Word error rates: Decomposition over POS classes
    and applications for error analysis,” in *2nd Workshop on Statistical Machine
    Translation (WMT 2007)*.   ACL, 2007, pp. 48–55.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] P. Schwarz, P. Matějka, and J. Černockỳ, “Towards lower error rates in
    phoneme recognition,” in *7th International Conference on Text, Speech and Dialogue
    (TSD 2004)*, ser. LNCS, vol. 3206.   Springer, 2004, pp. 465–472.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] D. S. Turaga, Y. Chen, and J. Caviedes, “No reference PSNR estimation
    for compressed pictures,” *Signal Processing: Image Communication*, vol. 19, no. 2,
    pp. 173–184, 2004.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] P. Ndajah, H. Kikuchi, M. Yukawa, H. Watanabe, and S. Muramatsu, “SSIM
    image quality metric for denoised images,” in *3rd WSEAS International Conference
    on Visualization, Imaging and Simulation (VIS 2010)*.   WSEAS, 2010, pp. 53–58.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] M. A. Rahman and Y. Wang, “Optimizing intersection-over-union in deep
    neural networks for image segmentation,” in *12th International Symposium on Visual
    Computing (ISVC 2016)*, ser. LNCS, vol. 10072.   Springer, 2016, pp. 234–244.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] X. Chen, L. Yao, and Y. Zhang, “Residual attention U-net for automated
    multi-class segmentation of COVID-19 chest CT images,” *arXiv:2004.05645*, 2020.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[116] S. Liu, Y. Chen, K. Liu, and J. Zhao, “Exploiting argument information
    to improve event detection via supervised attention mechanisms,” in *55th Annual
    Meeting of the Association for Computational Linguistics (ACL 2017)*.   ACL, 2017,
    pp. 1789–1798.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[117] C. Liu, J. Mao, F. Sha, and A. Yuille, “Attention correctness in neural
    image captioning,” in *31st AAAI Conference on Artificial Intelligence (AAAI 2017)*.   AAAI
    Press, 2017, pp. 4176–4182.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[118] A. Das, H. Agrawal, L. Zitnick, D. Parikh, and D. Batra, “Human attention
    in visual question answering: Do humans and deep networks look at the same regions?”
    *Computer Vision and Image Understanding*, vol. 163, pp. 90 – 100, 2017.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[119] Y. Yu, J. Choi, Y. Kim, K. Yoo, S.-H. Lee, and G. Kim, “Supervising neural
    attention models for video captioning by human gaze data,” in *2017 IEEE Conference
    on Computer Vision and Pattern Recognition (CVPR 2017)*.   IEEE Computer Society,
    2017.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[120] S. Jain and B. C. Wallace, “Attention is not explanation,” in *2019 Conference
    of the North American Chapter of the Association for Computational Linguistics:
    Human Language Technologies (NAACL-HLT 2019)*.   ACL, 2019, pp. 3543–3556.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[121] S. Wiegreffe and Y. Pinter, “Attention is not not explanation,” in *2019
    Conference on Empirical Methods in Natural Language Processing and the 9th International
    Joint Conference on Natural Language Processing (EMNLP-IJCNLP 2019)*.   ACL, 2019,
    pp. 11–20.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[122] A. K. Mohankumar, P. Nema, S. Narasimhan, M. M. Khapra, B. V. Srinivasan,
    and B. Ravindran, “Towards transparent and explainable attention models,” in *58th
    Annual Meeting of the Association for Computational Linguistics (ACL 2020)*.   ACL,
    2020, pp. 4206–4216.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[123] K. K. Thekumparampil, C. Wang, S. Oh, and L.-J. Li, “Attention-based
    graph neural network for semi-supervised learning,” *arXiv:1803.03735*, 2018.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[124] D. Nie, Y. Gao, L. Wang, and D. Shen, “ASDNet: Attention based semi-supervised
    deep networks for medical image segmentation,” in *21st International Conference
    on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2018)*,
    ser. LNCS, vol. 11073.   Springer, 2018, pp. 370–378.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[125] Y. Alami Mejjati, C. Richardt, J. Tompkin, D. Cosker, and K. I. Kim,
    “Unsupervised attention-guided image-to-image translation,” in *32nd Annual Conference
    on Neural Information Processing Systems (NIPS 2018)*.   Curran Associates, Inc.,
    2018, pp. 3693–3703.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[126] R. He, W. S. Lee, H. T. Ng, and D. Dahlmeier, “An unsupervised neural
    attention model for aspect extraction,” in *55th Annual Meeting of the Association
    for Computational Linguistics (ACL 2017)*.   ACL, 2017, pp. 388–397.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| ![[Uncaptioned image]](img/b82c9e2e5d3c92985b9ac16c33097aa3.png) | Gianni
    Brauwers was born in Spijkenisse, the Netherlands, in 1998\. He received the B.S.
    degree in econometrics and operations research from Erasmus University Rotterdam,
    Rotterdam, the Netherlands, in 2019, and is currently pursuing the M.S. degree
    in econometrics and management science at Erasmus University Rotterdam. He is
    a Research Assistant at Erasmus University Rotterdam, focusing his research on
    neural attention models and sentiment analysis. |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/318ebb088d471a90f84e394d8e0670e9.png) | Flavius
    Frasincar was born in Bucharest, Romania, in 1971\. He received the M.S. degree
    in computer science, in 1996, and the M.Phil. degree in computer science, in 1997,
    from Politehnica University of Bucharest, Bucharest, Romania, and the P.D.Eng.
    degree in computer science, in 2000, and the Ph.D. degree in computer science,
    in 2005, from Eindhoven University of Technology, Eindhoven, the Netherlands.
    Since 2005, he has been an Assistant Professor in computer science at Erasmus
    University Rotterdam, Rotterdam, the Netherlands. He has published in numerous
    conferences and journals in the areas of databases, Web information systems, personalization,
    machine learning, and the Semantic Web. He is a member of the editorial boards
    of Decision Support Systems, International Journal of Web Engineering and Technology,
    and Computational Linguistics in the Netherlands Journal, and co-editor-in-chief
    of the Journal of Web Engineering. Dr. Frasincar is a member of the Association
    for Computing Machinery. |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
