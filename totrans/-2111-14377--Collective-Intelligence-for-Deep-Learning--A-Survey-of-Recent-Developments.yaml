- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '分类: 未分类'
- en: 'date: 2024-09-06 19:49:35'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 19:49:35'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2111.14377] Collective Intelligence for Deep Learning: A Survey of Recent
    Developments'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2111.14377] 集体智能与深度学习：近期发展综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2111.14377](https://ar5iv.labs.arxiv.org/html/2111.14377)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2111.14377](https://ar5iv.labs.arxiv.org/html/2111.14377)
- en: 'Collective Intelligence for Deep Learning: A Survey of Recent Developments'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集体智能与深度学习：近期发展综述
- en: 'David Ha¹¹affiliationmark: and Yujin Tang¹¹affiliationmark: ¹¹affiliationmark:
    Google Brain, Tokyo, Japan.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 'David Ha¹¹affiliationmark: 和 Yujin Tang¹¹affiliationmark: ¹¹affiliationmark:
    Google Brain, 东京, 日本。'
- en: Both authors contributed equally to this work.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 两位作者对本工作贡献相同。
- en: 'Email: hadavid@google.com, yujintang@google.com'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 邮箱：hadavid@google.com, yujintang@google.com
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: In the past decade, we have witnessed the rise of deep learning to dominate
    the field of artificial intelligence. Advances in artificial neural networks alongside
    corresponding advances in hardware accelerators with large memory capacity, together
    with the availability of large datasets enabled practitioners to train and deploy
    sophisticated neural network models that achieve state-of-the-art performance
    on tasks across several fields spanning computer vision, natural language processing,
    and reinforcement learning. However, as these neural networks become bigger, more
    complex, and more widely used, fundamental problems with current deep learning
    models become more apparent. State-of-the-art deep learning models are known to
    suffer from issues that range from poor robustness, inability to adapt to novel
    task settings, to requiring rigid and inflexible configuration assumptions. Collective
    behavior, commonly observed in nature, tends to produce systems that are robust,
    adaptable, and have less rigid assumptions about the environment configuration.
    Collective intelligence, as a field, studies the group intelligence that emerges
    from the interactions of many individuals. Within this field, ideas such as self-organization,
    emergent behavior, swarm optimization, and cellular automata were developed to
    model and explain complex systems. It is therefore natural to see these ideas
    incorporated into newer deep learning methods. In this review, we will provide
    a historical context of neural network research’s involvement with complex systems,
    and highlight several active areas in modern deep learning research that incorporate
    the principles of collective intelligence to advance its current capabilities.
    We hope this review can serve as a bridge between the complex systems and deep
    learning communities.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年里，我们见证了深度学习在人工智能领域的崛起。人工神经网络的进步，加上具有大内存容量的硬件加速器的相应进步，以及大数据集的可用性，使得实践者能够训练和部署复杂的神经网络模型，从而在计算机视觉、自然语言处理和强化学习等多个领域的任务上实现最先进的性能。然而，随着这些神经网络变得越来越大、越来越复杂并被广泛使用，当前深度学习模型的基本问题变得越来越明显。最先进的深度学习模型被认为存在从鲁棒性差、无法适应新任务设置到需要僵化和不灵活的配置假设等问题。自然界中常见的集体行为往往产生鲁棒、适应性强且对环境配置假设较少的系统。集体智能作为一个领域，研究从多个个体的互动中产生的集体智能。在这一领域中，像自组织、涌现行为、群体优化和元胞自动机等思想被发展出来以建模和解释复杂系统。因此，看到这些思想被融入到更新的深度学习方法中是很自然的。在这篇综述中，我们将提供神经网络研究与复杂系统相关的历史背景，并重点介绍现代深度学习研究中几个活跃的领域，这些领域结合了集体智能的原则，以推进当前的能力。我们希望这篇综述能作为复杂系统和深度学习社区之间的桥梁。
- en: 'keywords:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Deep Learning, Reinforcement Learning, Cellular Automata, Self-Organization,
    Complex Systems
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习，强化学习，元胞自动机，自组织，复杂系统
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Deep learning (DL) is a class of machine learning methods that uses multi-layer
    (“deep”) neural networks for representation learning. While artificial neural
    networks, trained with the backpropagation algorithm, first appeared in the 1980s Schmidhuber
    ([2014](#bib.bib69)), deep neural networks did not receive widespread attention
    until 2012 when a deep artificial neural network solution trained on GPUs Krizhevsky
    et al. ([2012](#bib.bib39)) won an annual image recognition competition Deng et al.
    ([2009](#bib.bib16)) by a significant margin over the non-DL runner up methods.
    This success demonstrated that DL, when combined with fast hardware-accelerated
    implementations and the availability of large datasets, is capable of achieving
    exceptionally better results in non-trivial tasks than conventional methods. Practitioners
    soon quickly incorporated DL to address the long-standing problems in several
    other fields. In computer vision (CV), deep learning models are used in image
    recognition Simonyan and Zisserman ([2014](#bib.bib75)); He et al. ([2016](#bib.bib27));
    Radford et al. ([2021](#bib.bib57)) and image generation Wang et al. ([2021](#bib.bib92));
    Jabbar et al. ([2021](#bib.bib33)). In natural language processing (NLP), deep
    language models can generate text Radford et al. ([2018](#bib.bib58), [2019](#bib.bib59));
    Brown et al. ([2020](#bib.bib7)) and perform machine translation Stahlberg ([2020](#bib.bib76)).
    Deep learning has also been incorporated into reinforcement learning (RL) to tackle
    vision-based computer games such as Doom Ha and Schmidhuber ([2018](#bib.bib25))
    and Atari Mnih et al. ([2015](#bib.bib46)), and play games with large search spaces
    such as Go Silver et al. ([2016](#bib.bib74)) and Starcraft Vinyals et al. ([2019](#bib.bib90)).
    Deep learning models are also deployed for mobile applications like speech recognition Alam
    et al. ([2020](#bib.bib1)) and speech synthesis Tan et al. ([2021](#bib.bib83)),
    demonstrating their wide applicability.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）是一类使用多层（“深度”）神经网络进行表示学习的机器学习方法。尽管人工神经网络在1980年代由Schmidhuber（[2014](#bib.bib69)）首次出现，并使用反向传播算法进行训练，但深度神经网络直到2012年才引起广泛关注，那时基于GPU训练的深度人工神经网络解决方案Krizhevsky等人（[2012](#bib.bib39)）在年度图像识别竞赛中显著超越了非DL的竞争方法。这一成功表明，DL结合快速硬件加速实现和大量数据集，能够在复杂任务中比传统方法取得更好的结果。实践者很快将DL应用于解决多个领域长期存在的问题。在计算机视觉（CV）中，深度学习模型用于图像识别Simonyan和Zisserman（[2014](#bib.bib75)）；He等人（[2016](#bib.bib27)）；Radford等人（[2021](#bib.bib57)）和图像生成Wang等人（[2021](#bib.bib92)）；Jabbar等人（[2021](#bib.bib33)）。在自然语言处理（NLP）中，深度语言模型可以生成文本Radford等人（[2018](#bib.bib58)，[2019](#bib.bib59)）；Brown等人（[2020](#bib.bib7)）并执行机器翻译Stahlberg（[2020](#bib.bib76)）。深度学习还被纳入强化学习（RL）中，以应对基于视觉的计算机游戏，如Doom
    Ha和Schmidhuber（[2018](#bib.bib25)）和Atari Mnih等人（[2015](#bib.bib46)），以及大搜索空间的游戏，如围棋
    Silver等人（[2016](#bib.bib74)）和星际争霸 Vinyals等人（[2019](#bib.bib90)）。深度学习模型还被部署用于移动应用，如语音识别
    Alam等人（[2020](#bib.bib1)）和语音合成 Tan等人（[2021](#bib.bib83)），展示了其广泛的适用性。
- en: '![Refer to caption](img/925092d99566b371b4c55a2a35e71fa3.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/925092d99566b371b4c55a2a35e71fa3.png)'
- en: 'Figure 1: Recent advances in GPU hardware enables realistic 3D simulation of
    thousands of robot models Heiden et al. ([2021](#bib.bib28)), such as the one
    shown in this figure from Rudin et al. Rudin et al. ([2021](#bib.bib63)). Such
    advances opens the door for large scale 3D simulation of artificial agents that
    can interact with each other and collectively develop intelligent behavior.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：GPU硬件的最新进展使得对数千个机器人模型进行逼真的3D模拟成为可能，如图中所示的Rudin等人（[2021](#bib.bib63)）的模型。这样的进展为大规模3D模拟人工代理提供了可能，这些代理可以相互互动并共同发展智能行为。
- en: However, DL is not an elixir without side effects. While we are witnessing many
    successes and a growing adoption of deep neural networks, fundamental problems
    with DL are also revealing themselves more and more clearly as our models and
    training algorithms become bigger and more complex. DL models are not robust in
    some cases. For example, it is now known that by simply modifying several pixels
    on the screen of a video game (the modification is not even noticeable to humans),
    the agent trained with unmodified screens that originally surpassed human performance
    could fail Qu et al. ([2020](#bib.bib56)). Also, CV models trained without special
    treatment may fail to recognize rotated or similarly transformed examples, in
    other words, our current model and training methods do not lend themselves to
    generalization to novel task settings. Last but not least, most DL models do not
    adapt to changes. They make assumptions about input and expect rigid configurations
    and stationarity of the environment, what statisticians think of as the data generating
    process. For instance, they may expect a fixed number of inputs, in a determined
    ordered. We cannot expect agents to capably act beyond their skills learned during
    training, but once these rigid configurations are violated, the models do not
    perform well unless we retrain them or manually process the inputs to be consistent
    with the expectations of their initial training configurations.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，深度学习并非没有副作用的灵丹妙药。尽管我们见证了许多成功和深度神经网络的日益普及，但随着我们的模型和训练算法变得越来越大和复杂，深度学习的基本问题也越来越清晰地显现出来。在某些情况下，深度学习模型并不稳健。例如，现在已知通过简单地修改视频游戏屏幕上的几个像素（这些修改对人类几乎不可见），原本在未经修改的屏幕上表现超越人类的训练代理可能会失败 Qu
    等人（[2020](#bib.bib56)）。此外，未经特殊处理的计算机视觉模型可能无法识别旋转或类似变换的示例，换句话说，我们当前的模型和训练方法无法很好地推广到新任务设置。最后但并非最不重要的是，大多数深度学习模型无法适应变化。它们对输入做出假设，并期望环境的配置和稳定性是固定的，统计学家称之为数据生成过程。例如，它们可能期望输入数量固定，且顺序确定。我们不能指望代理在超出其训练期间学习到的技能之外表现出色，但一旦这些固定配置被打破，除非我们重新训练模型或手动处理输入以与其初始训练配置的期望一致，否则模型表现会不佳。
- en: '![Refer to caption](img/d9e13eb2f28cbc59e0f95830a196e590.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/d9e13eb2f28cbc59e0f95830a196e590.png)'
- en: 'Figure 2: Neural network architecture of AlexNet Krizhevsky et al. ([2012](#bib.bib39)),
    the winner of the ImageNet competition in 2012.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: AlexNet Krizhevsky 等人（[2012](#bib.bib39)）的神经网络架构，2012年ImageNet竞赛的获胜者。'
- en: 'Furthermore, with all these advances, the impressive feats in deep learning
    involve sophisticated engineering efforts. For instance, the famous AlexNet Krizhevsky
    et al. ([2012](#bib.bib39)) (See Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction
    ‣ Collective Intelligence for Deep Learning: A Survey of Recent Developments")),
    which put deep learning into the spotlight in the computer vision community after
    winning ImageNet in 2012, presented a carefully designed network architecture
    with a well-calibrated training procedure. Modern neural networks are often even
    more sophisticated, and require a pipeline that spans network architecture to
    delicate training schemes. Like many engineering projects, much labor and fine-tuning
    went into producing each result.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，尽管所有这些进展都很令人印象深刻，但深度学习中的卓越成就涉及复杂的工程工作。例如，著名的 AlexNet Krizhevsky 等人（[2012](#bib.bib39)）（参见图 [2](#S1.F2
    "图 2 ‣ 1 引言 ‣ 深度学习的集体智能：最近发展的调查")），它在2012年赢得了ImageNet，使深度学习在计算机视觉界成为焦点，呈现了一个精心设计的网络架构和经过良好校准的训练程序。现代神经网络通常更加复杂，且需要涵盖从网络架构到精细训练方案的整个流程。像许多工程项目一样，产生每一个结果都投入了大量的劳动和精细调整。
- en: 'We believe that many of the limitations and side effects of deep learning stems
    from the fact that the current practice of deep learning is similar to the practice
    of engineering. The way we are building modern neural network systems is similar
    to the way we are building bridges and buildings, which are designs that are not
    adaptive. To quote Pickering, author of The Cybernetic Brain Pickering ([2010](#bib.bib54)):
    “Most of the examples of engineering that come to mind are not adaptive. Bridges
    and buildings, lathes and power presses, cars, televisions, computers, are all
    designed to be indifferent to their environment, to withstand fluctuations, not
    to adapt to them. The best bridge is one that just stands there, whatever the
    weather.”'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信，深度学习的许多限制和副作用源于当前深度学习实践与工程实践的相似性。我们构建现代神经网络系统的方式类似于我们建造桥梁和建筑物的方式，这些设计是不具备适应性的。正如《控制论大脑》的作者Pickering（[2010](#bib.bib54)）所引用的：“大多数想到的工程实例都是不具备适应性的。桥梁和建筑物、车床和动力压机、汽车、电视机、计算机，都是被设计成对其环境漠不关心、能够承受波动而不是适应它们。最好的桥梁是那种无论天气如何都能稳固存在的桥梁。”
- en: '![Refer to caption](img/2a6de7dade0cd2fbf07e3959e12eb2b7.png)![Refer to caption](img/435044726fcec6e51410c31c0844bdcd.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2a6de7dade0cd2fbf07e3959e12eb2b7.png)![参见说明](img/435044726fcec6e51410c31c0844bdcd.png)'
- en: 'Figure 3: Left: Trajan’s Bridge at Alcantara, built in 106 AD by Romans Authors
    ([2022](#bib.bib2)). Right: Army ants forming a bridge Jenal ([2011](#bib.bib35)).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：左：由罗马人于公元 106 年建造的阿尔坎塔拉的特拉扬桥 作者（[2022](#bib.bib2)）。右：军蚁形成的桥梁 Jenal（[2011](#bib.bib35)）。
- en: 'In natural systems, where collective intelligence plays a big role, we see
    adaptive designs that emerge due to self-organization, and such designs are very
    sensitive and responsive to changes in the world around them. Natural systems
    adapt, and become part of their environment (See Figure [3](#S1.F3 "Figure 3 ‣
    1 Introduction ‣ Collective Intelligence for Deep Learning: A Survey of Recent
    Developments") for an analogy).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然系统中，集体智能发挥着重要作用，我们可以看到由于自组织而产生的适应性设计，这些设计对周围环境的变化非常敏感和响应。自然系统会适应环境，并成为其一部分（参见图 [3](#S1.F3
    "图 3 ‣ 1 介绍 ‣ 深度学习的集体智能：近期发展的调查")以获取类比）。
- en: As exemplified by the example of army ants collectively forming a bridge that
    adapts to its environment, collective behavior, commonly seen in nature, tends
    to produce systems that are adaptable, robust, and have less rigid assumptions
    about the environment configuration. Collective intelligence, as a field, studies
    the shared intelligence that emerges from the interactions (such as collaboration,
    collective efforts, and competition) of many individuals. Within this field, ideas
    such as self-organization, emergent behavior, swarm optimization, and cellular
    automata were developed to model and explain complex systems. It is therefore
    natural to see these ideas incorporated into newer deep learning methods.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以军蚁集体形成适应环境的桥梁为例，自然界中常见的集体行为往往会产生适应性强、稳健且对环境配置假设较少的系统。集体智能作为一个领域，研究从许多个体的互动（如协作、集体努力和竞争）中涌现出的共享智能。在这个领域中，诸如自组织、涌现行为、群体优化和细胞自动机等概念被开发出来以建模和解释复杂系统。因此，将这些概念融入到更新的深度学习方法中是很自然的。
- en: 'We do not believe that deep learning models have to be built in the same vein
    as bridges. As we will discuss later on, it didn’t have to be this way. The reason
    why the deep learning field took this course could just be an accidental outcome
    in history. In fact, recently, several works have been addressing the limitations
    of deep learning by combining it with ideas from collective intelligence, from
    applying cellular automata to neural network-based image processing models Mordvintsev
    et al. ([2020](#bib.bib47)); Randazzo et al. ([2020](#bib.bib60)) to re-defining
    how problems in reinforcement learning can be approached using self-organizing
    agents Pathak et al. ([2019](#bib.bib52)); Huang et al. ([2020](#bib.bib32));
    Tang and Ha ([2021](#bib.bib84)). As we witness the continuous technological advances
    in parallel-computation hardware (which is naturally suited to simulate collective
    behavior, see Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Collective Intelligence
    for Deep Learning: A Survey of Recent Developments") for an example), we can expect
    more works that incorporate collective intelligence into problems that have been
    traditionally approached with deep learning.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '我们不认为深度学习模型必须像桥梁一样构建。正如我们稍后讨论的，这不一定是这样。深度学习领域采取这种路径的原因可能只是历史上的一个偶然结果。事实上，最近有几项工作通过将深度学习与集体智能的理念相结合来解决深度学习的局限性，从将细胞自动机应用于基于神经网络的图像处理模型 Mordvintsev
    et al. ([2020](#bib.bib47)); Randazzo et al. ([2020](#bib.bib60))，到重新定义如何使用自组织代理处理强化学习中的问题 Pathak
    et al. ([2019](#bib.bib52)); Huang et al. ([2020](#bib.bib32)); Tang and Ha ([2021](#bib.bib84))。随着我们目睹平行计算硬件的持续技术进步（这自然适合模拟集体行为，见图 [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Collective Intelligence for Deep Learning: A Survey
    of Recent Developments)"), 我们可以期待更多将集体智能融入传统深度学习方法中的工作。'
- en: The goal of this review is to provide a high level survey of how ideas, tools,
    and insights central to the field of collective intelligence, most notably self-organization,
    emergence, and swarm models have impacted different areas of deep learning, ranging
    from image processing, reinforcement learning to meta-learning. We hope this review
    will provide some insights on future deep learning collective intelligence synergies,
    which we believe will lead to meaningful breakthroughs in both fields.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本次综述的目标是对集体智能领域中的核心理念、工具和见解进行高水平的概述，特别是自组织、涌现和群体模型如何影响深度学习的不同领域，从图像处理、强化学习到元学习。我们希望这次综述能为未来深度学习集体智能的协同提供一些见解，我们相信这将导致两个领域的有意义突破。
- en: '2 Background: Collective Intelligence'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景：集体智能
- en: 'Collective intelligence (CI) is a term widely used in areas like sociology,
    business, communication and computer science. The definition of CI can be summarized
    as a form of distributed intelligence that is constantly enhancing and coordinating,
    with the goal of achieving better results than any individual of the group, through
    mutual recognition and enrichment of the individual Lévy ([1997](#bib.bib42));
    Leimeister ([2010](#bib.bib41)). The better results from CI are attributed to
    three factors: diversity, independence and decentralization Surowiecki ([2005](#bib.bib82));
    Tapscott and Williams ([2008](#bib.bib87)).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 集体智能（CI）是一个广泛用于社会学、商业、通信和计算机科学等领域的术语。CI的定义可以总结为一种分布式智能，它通过互相识别和丰富个体的方式，持续提升和协调，旨在取得比任何个体更好的结果 Lévy
    ([1997](#bib.bib42)); Leimeister ([2010](#bib.bib41))。CI的更好结果归因于三个因素：多样性、独立性和分散性 Surowiecki
    ([2005](#bib.bib82)); Tapscott and Williams ([2008](#bib.bib87))。
- en: For our purposes, we view collective intelligence, as a field, to be the study
    of the group intelligence that emerges from interactions (can be collaborative
    or competitive) between many individuals. This group intelligence is a product
    of emergence, which occurs when the group is observed to have properties that
    the individuals that compose of the group do not have on their own, and emerge
    only when the individuals of the group interact in a wider whole.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 就我们而言，我们认为集体智能作为一个领域，是研究从多个人之间的互动（可以是合作或竞争）中涌现出的群体智能。这种群体智能是涌现的产物，当观察到群体具有个体自身所不具备的属性时出现，而只有当群体中的个体在更大的整体中互动时才会出现。
- en: Examples of such systems are abounded in nature where complex global behaviors
    toward mutual goals emerge from simple local interactions/collaborations between
    individuals Deneubourg and Goss ([1989](#bib.bib15)); Toner et al. ([2005](#bib.bib89));
    Sumpter ([2010](#bib.bib81)); Lajad et al. ([2021](#bib.bib40)). In this review,
    we confine ourselves to be concerned with the simulation of collective intelligence,
    rather than the analysis of CI observed in nature and society. Decades of earlier
    work have also explored the simulation of collective behavior and to gather insights
    from such simulations. Mataric ([1993](#bib.bib45)) investigated the use of physical
    mobile robots for studying social interactions leading to group behavior. They
    proposed a set of basic interactions (e.g., collision avoidance, following, flocking,
    etc) with the hope that these primitives would enable a group of autonomous agents
    to accomplish a common goal or to learn from each other. Inspired by group behaviors
    observed in real ant colonies, Dorigo et al. ([2000](#bib.bib17)) posed stigmergy
    (a particular form of indirect communication used by social insects) as a distributed
    communication paradigm and showed how it inspired novel algorithms for solutions
    of distributed optimization and control problems. Moreover, Schweitzer and Farmer
    ([2003](#bib.bib72)) applied Brownian agent models in many different contexts.
    Combined with multi-agent systems and statistical approaches, the authors laid
    out a vision for a coherent framework for understanding complex systems.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这类系统的例子在自然界中比比皆是，其中复杂的全球行为从个体之间简单的局部互动/合作中涌现出来，参见Deneubourg和Goss ([1989](#bib.bib15))；Toner等人
    ([2005](#bib.bib89))；Sumpter ([2010](#bib.bib81))；Lajad等人 ([2021](#bib.bib40))。在这篇综述中，我们将重点关注集体智能的模拟，而不是自然和社会中观察到的集体智能的分析。几十年的早期工作也探讨了集体行为的模拟，并从这些模拟中获得了洞见。Mataric
    ([1993](#bib.bib45)) 研究了使用物理移动机器人来研究导致群体行为的社会互动。他们提出了一组基本的互动（例如，避免碰撞、跟随、成群等），希望这些原语能够使一组自主代理完成共同目标或互相学习。受到真实蚂蚁群体行为的启发，Dorigo等人
    ([2000](#bib.bib17)) 提出了stigmergy（社会昆虫使用的一种间接通信形式）作为一种分布式通信范式，并展示了它如何启发分布式优化和控制问题的创新算法。此外，Schweitzer和Farmer
    ([2003](#bib.bib72)) 在许多不同的背景下应用了布朗运动代理模型。结合多代理系统和统计方法，作者们为理解复杂系统提供了一个连贯的框架愿景。
- en: While some of these earlier works led to the discovery of algorithms that are
    applicable to optimization problems (such as ant colony optimization for tackling
    the traveling salesman problem), many of these works aim to use these simulation
    models to understand the emergent phenomenon of collective intelligence. This
    points to a fundamental difference between the goals of collective intelligence
    and artificial intelligence fields. In collective intelligence, the goal is to
    build models of complex systems that can help us explain and understand emergent
    phenomena, which may have applications to understand real systems in nature and
    society. Artificial intelligence (in particular, the field of machine learning),
    on the other hand, is concerned with optimization, classification, prediction,
    and solving a problem.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些早期工作中的一些导致了可用于优化问题的算法（例如，解决旅行推销员问题的蚂蚁群体优化），但许多工作旨在利用这些模拟模型来理解集体智能的涌现现象。这指向了集体智能和人工智能领域目标之间的根本差异。在集体智能中，目标是建立复杂系统的模型，以帮助我们解释和理解涌现现象，这些现象可能有助于理解自然和社会中的真实系统。另一方面，人工智能（尤其是机器学习领域）关注于优化、分类、预测和解决问题。
- en: The early works we mentioned did not fully leverage the modeling power of DL
    or the advancement of hardware development, but nonetheless are consistently demonstrating
    the incredible effects of CI. Namely, the systems are self-organizing, capable
    of optimization via swarm intelligence, present emergent behavior, etc. They suggest
    that concepts from CI are promising ideas that can be applied to DL to produce
    solutions that are robust, adaptable, and have less rigid assumptions about the
    environment configuration, which is the focus of this review.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到的早期工作没有充分利用深度学习（DL）的建模能力或硬件发展的进步，但仍然持续展示了集体智能（CI）的令人难以置信的效果。即，这些系统是自组织的，能够通过群体智能进行优化，呈现出涌现行为等。它们表明，集体智能中的概念是可以应用于深度学习以产生健壮、适应性强且对环境配置假设较少的解决方案的有前途的想法，这是这篇综述的重点。
- en: '3 Historical Background: Cellular Neural Networks'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 历史背景：细胞神经网络
- en: Ideas from complex systems such self-organization that were used to model and
    understand emergent and collective behavior have a long and interesting historical
    relationship with the development of artificial neural networks. While connectionism
    and artificial neural networks came about in the 1950s with the birth of artificial
    intelligence as a research field, our story begins in the 1970s, when a group
    of electrical engineers led by pioneer Leon Chua, started developing nonlinear
    circuits theory and applied it to computation. He is known for conceptualizing
    the Memristor in the 1970s (a device that has been implemented only recently),
    and devising the Chua circuit, one of the first circuits to exhibit chaotic behavior.
    In the 1980s, his group developed Cellular Neural Networks, which are computational
    systems that resemble cellular automata (CA), but use neural networks in place
    of the algorithmic cells typically seen in CA systems such as Conway’s Game of
    Life Conway et al. ([1970](#bib.bib13)) or elementary cellular automata rules Wolfram
    ([2002](#bib.bib93)).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8fea747693013c74095cdb6a29a0f867.png)![Refer to caption](img/c1a2ee587ae44b40b0888f5bd0cac66c.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Left: Typical configuration of a 2D Cellular Neural Network Liu et al.
    ([2020](#bib.bib43)). Right: [Google trends](https://bit.ly/3sZlpyh) for the terms
    Deep Learning and Cellular Neural Network over time.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 'Cellular Neural Networks (CeNNs) Chua and Yang ([1988b](#bib.bib12), [a](#bib.bib11))
    are artificial neural networks where each neuron, or cell, can only interact with
    their immediate neighbors. In the most basic setting, the state of each cell is
    continuously updated using a nonlinear function of the states of its neighbors
    and itself. Unlike modern deep learning approaches which rely on digital, discrete-time
    computation, CeNNs are continuous-time systems that are usually implemented with
    non-linear analog electronic components (See Figure [4](#S3.F4 "Figure 4 ‣ 3 Historical
    Background: Cellular Neural Networks ‣ Collective Intelligence for Deep Learning:
    A Survey of Recent Developments"), left), making them very fast. The dynamics
    of CeNNs rely on independent local processing of information and interaction between
    processing units, and like CAs, they also exhibit emergent behavior, and can be
    made to be Universal Turing Machines. However, they are vastly more general than
    discrete CAs and digital computers. Due to the continuous state space, CeNNs exhibit
    emergent behavior never seen before. GoraS et al. ([1995](#bib.bib21))'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: From the 1990s to mid 2000s, CeNNs became an entire subfield of AI research.
    Due to its powerful and efficient distributed computation, it found applications
    in image processing, texture analysis, and its inherent analog computation applied
    to solving PDEs and even modeling biological systems and organs. Chua and Roska
    ([2002](#bib.bib10)) There were thousands of peer-reviewed papers, textbooks,
    and an IEEE conference devoted to CeNNs, with many proposals to scale them up,
    stack them, combining them with digital circuits, and investigating different
    methods of training them (just like what we are currently seeing in deep learning).
    At least two hardware startups were formed to produce CeNN hardware and devices.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从1990年代到2000年代中期，CeNNs成为人工智能研究的一个完整子领域。由于其强大而高效的分布式计算，它在图像处理、纹理分析以及其固有的模拟计算应用于求解PDEs（偏微分方程）甚至生物系统和器官建模中找到了应用。 Chua和Roska
    ([2002](#bib.bib10)) 有成千上万的同行评审论文、教科书，还有一个IEEE会议专门讨论CeNNs，并有许多提案来扩大它们的规模、堆叠它们、将它们与数字电路结合，并研究不同的训练方法（就像我们目前在深度学习中看到的那样）。至少有两个硬件初创公司成立以生产CeNN硬件和设备。
- en: 'But in the latter half of the decade in the 2000s, they suddenly disappeared
    from the scene! There is hardly any mention of Cellular Neural Networks in the
    AI community after 2006\. And from the 2010s, GPUs took over as the predominant
    platform for neural network research, which led to the rebranding of artificial
    neural networks to deep learning. See Figure [4](#S3.F4 "Figure 4 ‣ 3 Historical
    Background: Cellular Neural Networks ‣ Collective Intelligence for Deep Learning:
    A Survey of Recent Developments") (right) for a comparison of the trends over
    time.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '但是在2000年代后半期，它们突然从舞台上消失了！在2006年后，人工智能社区几乎没有提及细胞神经网络。而从2010年代开始，GPU成为神经网络研究的主要平台，导致人工神经网络被重新命名为深度学习。请参见图 [4](#S3.F4
    "Figure 4 ‣ 3 Historical Background: Cellular Neural Networks ‣ Collective Intelligence
    for Deep Learning: A Survey of Recent Developments")（右侧）以查看趋势的对比。'
- en: No one can really pinpoint the exact reason for the demise of Cellular Neural
    Networks in AI research. Like the Memristor, perhaps CeNNs were ahead of its time.
    Or perhaps the eventual rise of consumer GPUs made it a compelling platform for
    deep learning. One can only imagine in a parallel universe where CeNN’s analog
    computer chips had won the Hardware Lottery Hooker ([2020](#bib.bib30)), the state
    of AI might be very different where the world and all of our devices are embedded
    with powerful distributed analog cellular automata.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 没有人能准确指出**细胞神经网络**在人工智能研究中衰退的原因。像**忆阻器**一样，也许CeNNs（细胞神经网络）超前于时代。或者，最终消费者GPU的兴起使其成为深度学习的一个有吸引力的平台。我们只能想象，在一个平行宇宙中，如果CeNN的模拟计算芯片赢得了硬件彩票 Hooker
    ([2020](#bib.bib30))，AI的现状可能会非常不同，世界和我们所有的设备都嵌入了强大的分布式模拟细胞自动机。
- en: However, one key difference between CeNNs and deep learning is accessibility,
    and in our opinion, this is the main reason it did not catch on. In the current
    deep learning paradigm, there is an entire ecosystem of tools designed to make
    it easy to train and deploy neural network models. It is also relatively straightforward
    to train the parameters of a neural network with deep learning frameworks by providing
    it with a dataset Chollet et al. ([2015](#bib.bib9)), or a simulated task environment Hill
    et al. ([2018](#bib.bib29)). Deep learning tools are designed to be used by anyone
    with a basic programming background. CeNNs, on the other hand, were designed for
    electrical engineers at a time when most EE students knew more about analog circuits
    than programming languages.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，CeNNs与深度学习之间的一个关键区别是可访问性，在我们看来，这也是它未能流行的主要原因。在当前的深度学习范式中，存在一个完整的工具生态系统，旨在简化神经网络模型的训练和部署。通过提供数据集 Chollet
    et al. ([2015](#bib.bib9))，或模拟任务环境 Hill et al. ([2018](#bib.bib29))，训练神经网络的参数也相对简单。深度学习工具旨在供任何具有基本编程背景的人使用。而CeNNs则设计用于电气工程师，当时大多数EE学生对模拟电路的了解超过编程语言。
- en: To illustrate this difficulty, “training” a CeNN requires solving a system of
    at least nine ODEs to determine the coefficients that govern the analog circuits
    to define the behavior of the system! In practice, many practitioners needed to
    rely on a cookbook Chua and Roska ([2002](#bib.bib10)) of known solutions to problems
    and then manually adjust the solutions for new problems. Eventually, genetic algorithms
    (and early versions of backpropagation) have been proposed to train CeNNs Kozek
    et al. ([1993](#bib.bib38)), but they require simulation software to train and
    test the circuits, before deploying on an actual (and highly customized) CeNN
    hardware.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一难点，“训练”一个 CeNN 需要解决至少九个常微分方程系统，以确定控制模拟电路的系数，从而定义系统的行为！实际上，许多从业者需要依赖于 Chua
    和 Roska ([2002](#bib.bib10)) 的已知问题解决方案手册，然后手动调整这些解决方案以应对新问题。最终，遗传算法（以及早期版本的反向传播）被提出用于训练
    CeNNs (Kozek et al. ([1993](#bib.bib38)))，但它们需要模拟软件来训练和测试电路，然后才能部署到实际的（且高度定制的）CeNN
    硬件上。
- en: There are likely more lessons to be learned from Cellular Neural Networks. They
    were an immensely powerful hybrid of analog and digital computation that truly
    synthesized cellular automata with neural networks. Unfortunately, we probably
    only witnessed the very beginning of its full potential, before its demise. Ultimately,
    commodity GPUs and software tools that abstracted neural networks into simple
    Python code enabled deep learning to take over. Although CeNNs have faded away,
    concepts and ideas from complex systems, like CAs, self-organization and emergent
    behavior have not. Despite being limited to digital hardware, we are witnessing
    a resurgence of Collective Intelligence concepts in many areas of deep learning,
    from image generation, deep reinforcement learning, to collective and distributed
    learning algorithms. As we will see, these concepts are advancing the state of
    deep learning research by providing solutions to some limitations and restrictions
    of traditional artificial neural networks.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 从细胞神经网络中可能还有更多的教训可以汲取。它们是模拟与数字计算的强大混合体，真正将细胞自动机与神经网络合成。不幸的是，我们可能只见证了它完全潜力的开始，然后它就消亡了。**最终**，商品化的
    GPU 和将神经网络抽象成简单 Python 代码的软件工具使深度学习成为主流。尽管 CeNNs 已经淡出，但复杂系统中的概念和想法，如 CAs、自组织和涌现行为并没有消失。尽管限于数字硬件，我们在深度学习的许多领域中见证了集体智能概念的复兴，从图像生成、深度强化学习到集体和分布式学习算法。正如我们将看到的，这些概念正在通过提供对传统人工神经网络的一些限制和约束的解决方案来推动深度学习研究的进步。
- en: '![Refer to caption](img/f6c7f9fed64a98ba709be3f6d510c9f6.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f6c7f9fed64a98ba709be3f6d510c9f6.png)'
- en: 'Figure 5: A Neural Cellular Automata trained to recognize MNIST digits created
    by Randazzo et al. Randazzo et al. ([2020](#bib.bib60)) is also available as an
    interactive web demo. Each cell is only allowed to see the contents of a single
    pixel and communicate with its neighbors. Over time, a consensus will be formed
    as to which digit is the most likely pixel, but interestingly, disagreements may
    result depending on the location of the pixel where the prediction is made.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：一个神经元细胞自动机被训练以识别 MNIST 数字，由 Randazzo 等人创建。Randazzo 等人 ([2020](#bib.bib60))
    还提供了一个互动的网页演示。每个单元只能查看单个像素的内容，并与其邻居通信。随着时间的推移，会形成对哪个数字最可能的像素的共识，但有趣的是，根据预测所做像素的位置，可能会出现不同的意见。
- en: 4 Collective Intelligence for Deep Learning
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 集体智能与深度学习
- en: Collective intelligence naturally arises from the interaction of multiple individuals
    in a network, and it is no surprise to also see self-organizing behaviors naturally
    emerge from artificial neural networks. This is especially true when we employ
    repeated computation of identical modules with identical weight parameters across
    the network. For example, Gilpin Gilpin ([2019](#bib.bib20)) observed the close
    connection between cellular automata and convolutional neural networks (CNNs),
    a type of neural network often used in image processing that applies the same
    weights (or filters) to all of its inputs. In fact, they show that any CA can
    be represented with a certain kind of CNN, and with an elegant demonstration of
    Conway’s Game of Life Conway et al. ([1970](#bib.bib13)) in a CNN, illustrating
    that in certain settings, CNNs can exhibit interesting self-organizing behaviors.
    Recently, several works such as Mordintsev et al. Mordvintsev et al. ([2020](#bib.bib47))
    that we will discuss later have exploited the self-organizing properties of CNN,
    and have developed neural network-based cellular automata for applications such
    as image regeneration.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 集体智能自然地来源于网络中多个个体的互动，看到自组织行为自然从人工神经网络中出现也不足为奇。这尤其适用于我们在网络中使用重复计算相同模块并具有相同权重参数的情况。例如，Gilpin
    Gilpin ([2019](#bib.bib20)) 观察到细胞自动机与卷积神经网络（CNNs）之间的紧密联系，这是一种在图像处理中常用的神经网络类型，它将相同的权重（或滤波器）应用于所有输入。事实上，他们表明任何细胞自动机都可以用某种类型的CNN表示，通过对康威的《生命游戏》
    Conway et al. ([1970](#bib.bib13)) 的优雅演示，展示了在某些设置下，CNN可以表现出有趣的自组织行为。最近，一些研究如Mordintsev
    et al. Mordvintsev et al. ([2020](#bib.bib47))利用了CNN的自组织特性，开发了基于神经网络的细胞自动机，用于图像再生等应用。
- en: Other types of neural network architectures, such as Graph Neural Networks Wu
    et al. ([2020](#bib.bib94)); Sanchez-Lengeling et al. ([2021](#bib.bib64)); Daigavane
    et al. ([2021](#bib.bib14)) explicitly target self-organizing as a central feature,
    modeling the behavior of each node of a graph as identical neural network modules
    that pass messages to their neighbors defined by the edges of a graph. GNNs have
    been traditionally used to analyze graph domains such as social networks and molecular
    structures. Recent work Grattarola et al. ([2021](#bib.bib22)) has also demonstrated
    the ability of GNNs to learn rules for established CA systems such as Voronoi
    diagrams, or the flocking behavior of swarms Schoenholz and Cubuk ([2020](#bib.bib71)).
    As we will discuss later, the self-organizing properties of GNNs have recently
    been applied to the deep reinforcement learning domain, creating agents with far
    superior generalization capabilities.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 其他类型的神经网络架构，如图神经网络 Wu et al. ([2020](#bib.bib94))；Sanchez-Lengeling et al. ([2021](#bib.bib64))；Daigavane
    et al. ([2021](#bib.bib14))，明确将自组织作为核心特征，建模图中每个节点的行为为相同的神经网络模块，这些模块通过图的边缘定义的邻居之间传递信息。图神经网络传统上用于分析图域，如社交网络和分子结构。最近的研究
    Grattarola et al. ([2021](#bib.bib22)) 还展示了图神经网络学习已建立的细胞自动机系统规则的能力，如Voronoi图或群体的集群行为
    Schoenholz 和 Cubuk ([2020](#bib.bib71))。如我们后续讨论的那样，图神经网络的自组织特性最近已被应用于深度强化学习领域，创造了具有远超一般化能力的智能体。
- en: 'We have identified four areas of deep learning that have started to incorporate
    ideas related to collective intelligence: (1) Image Processing, (2) Deep Reinforcement
    Learning, (3) Multi-agent Learning, and (4) Meta-Learning. We will discuss each
    area in detail and provide examples in this section.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经识别出四个开始融入集体智能相关理念的深度学习领域：（1）图像处理，（2）深度强化学习，（3）多智能体学习，和（4）元学习。我们将在本节中详细讨论每个领域，并提供示例。
- en: 4.1 Image Processing
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 图像处理
- en: 'Implicit relationships and recurring patterns in nature (such as texture and
    scenery) can benefit from employing approaches from cellular automata in learning
    alternative representations of natural images. Like CeNNs, the Neural Cellular
    Automata (neural CA) model proposed by Mordvintsev et al. Mordvintsev et al. ([2020](#bib.bib47))
    treated each individual pixel of an image as a single neural network cell. The
    networks are trained to predict its color based on the states of its immediate
    neighbors, thereby developing a model of morphogenesis for image generation. They
    demonstrated that it was possible to train neural networks to reconstruct entire
    images this way, even when each cell lacks information about its location and
    rely only on local information from its neighbors. This approach enabled the generation
    algorithm to be resistant to noise, and moreover, allowed images to regenerate
    when damaged. An extension of neural CA Randazzo et al. ([2020](#bib.bib60)) enabled
    individual cell to perform image classification tasks, such as handwritten digit
    classification (MNIST) by only examining the contents of a single pixel, and passing
    a message on to the cell’s immediate neighbors (See Figure [5](#S3.F5 "Figure
    5 ‣ 3 Historical Background: Cellular Neural Networks ‣ Collective Intelligence
    for Deep Learning: A Survey of Recent Developments")). Over time, a consensus
    will be formed as to which digit is the most likely pixel, but interestingly,
    disagreements may result depending on the location of the pixel, especially if
    the image is intentionally drawn to represent different digits.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '自然界中的隐含关系和重复模式（如纹理和风景）可以通过采用细胞自动机的方法来学习自然图像的替代表示。像CeNNs一样，Mordvintsev等人提出的神经细胞自动机（neural
    CA）模型将图像的每一个像素视为一个独立的神经网络单元。网络被训练以预测其颜色，基于其邻近像素的状态，从而发展出一种用于图像生成的形态发生模型。他们展示了即使每个单元缺乏关于其位置的信息，仅依靠来自邻居的局部信息，也可以训练神经网络来重建整个图像。这种方法使生成算法对噪声具有抵抗力，并且在图像损坏时能够重新生成。神经CA的扩展Randazzo等人使得单个单元可以执行图像分类任务，如仅通过检查一个像素的内容来进行手写数字分类（MNIST），并将信息传递给单元的直接邻居（见图[5](#S3.F5
    "Figure 5 ‣ 3 Historical Background: Cellular Neural Networks ‣ Collective Intelligence
    for Deep Learning: A Survey of Recent Developments")）。随着时间的推移，将形成关于哪个数字最可能的像素的共识，但有趣的是，争议可能会根据像素的位置而产生，特别是如果图像故意绘制以表示不同的数字时。'
- en: '![Refer to caption](img/d1b505238812060e7f3481c392f430c2.png)![Refer to caption](img/a0ed0228d8524ceae652c00ad4ba9774.png)![Refer
    to caption](img/b05f3644bbc0b50a7b8d406db93d0c0a.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d1b505238812060e7f3481c392f430c2.png)![参见说明](img/a0ed0228d8524ceae652c00ad4ba9774.png)![参见说明](img/b05f3644bbc0b50a7b8d406db93d0c0a.png)'
- en: 'Figure 6: Neural CAs have also been applied to the regeneration of Minecraft
    entities. Sudhakaran et al. Sudhakaran et al. ([2021](#bib.bib80))’s formulation
    enabled the regeneration of not only Minecraft buildings, trees, but also simple
    functional machines in the game such as worm-like creatures that can even regenerate
    into two distinct creatures when cut in half.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：神经CA还被应用于Minecraft实体的再生。Sudhakaran等人（Sudhakaran et al. ([2021](#bib.bib80))）的公式不仅实现了Minecraft建筑、树木的再生，还能够再生游戏中的简单功能性机器，如可以在被切成两半时再生为两个不同生物的蠕虫状生物。
- en: 'The regeneration with neural CA has been explored beyond 2D images. In a later
    work, Zhang et al. Zhang et al. ([2021](#bib.bib95)) employed a similar approach
    to 3D voxel generation. This is particularly useful for high-resolution 3D scanning,
    where 3D shape data is often described with sparse and incomplete points. Using
    generative cellular automata they can recover full 3D shapes from only a partial
    set of points. This approach is also applicable outside of pure generative domains,
    and can also be applied to the construction of artificial agents in active environments
    such as Minecraft. Sudhakaran et al. Sudhakaran et al. ([2021](#bib.bib80)) trained
    neural CAs to grow complex entities from Minecraft such as castles, apartment
    blocks, and trees, some of which are composed of thousands of blocks. Aside from
    regeneration, their system is able to regrow parts of simple functional machines
    (such as a virtual creature in the game), and they demonstrate a morphogenetic
    creature grow into two distinct creatures when cut in half in the virtual world
    (See Figure [6](#S4.F6 "Figure 6 ‣ 4.1 Image Processing ‣ 4 Collective Intelligence
    for Deep Learning ‣ Collective Intelligence for Deep Learning: A Survey of Recent
    Developments")).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '使用神经细胞自动机的再生研究已经超越了 2D 图像。在一项后续工作中，Zhang 等人（[2021](#bib.bib95)）采用了类似的方法进行 3D
    体素生成。这对于高分辨率的 3D 扫描特别有用，因为 3D 形状数据通常用稀疏和不完整的点来描述。通过使用生成性细胞自动机，他们能够从仅部分点中恢复完整的
    3D 形状。这种方法不仅适用于纯生成领域，还可以应用于在动态环境中构建人工代理，如 Minecraft。Sudhakaran 等人（[2021](#bib.bib80)）训练了神经细胞自动机来生成复杂的
    Minecraft 实体，如城堡、公寓楼和树木，其中一些由数千个方块组成。除了再生之外，他们的系统还能够再生简单功能机器的部分（如游戏中的虚拟生物），并展示了一个形态发生生物在虚拟世界中被切成两半时，变成两个不同的生物（见图
    [6](#S4.F6 "Figure 6 ‣ 4.1 Image Processing ‣ 4 Collective Intelligence for Deep
    Learning ‣ Collective Intelligence for Deep Learning: A Survey of Recent Developments")）。'
- en: Cellular Automata is also naturally applicable to provide visual interpretation
    for images. Qin at al. Qin et al. ([2018](#bib.bib55)) examined the use of a Hierarchical
    CA model for visual saliency, to identify items in an image that stand out. By
    getting a CA to operate on visual features extracted from a deep neural network,
    they were able to iteratively construct multi-scale saliency maps of the image,
    with the final image being close to the target items. Sandler et al. Sandler et al.
    ([2020](#bib.bib66)) later investigated the use of CA for the task of image segmentation,
    an area where deep learning enjoys tremendous success. They demonstrated the viability
    of performing complex segmentation tasks using CAs with relatively simple rules
    (with as little as 10K neural network parameters), with the advantage of the approach
    being able to scale up to incredibly large image sizes, a challenge for traditional
    deep learning models with millions or even billions of model parameters, which
    are bounded by GPU memory.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 细胞自动机自然适用于为图像提供视觉解释。Qin 等人（[2018](#bib.bib55)）研究了使用分层细胞自动机模型进行视觉显著性，以识别图像中突出的项目。通过使细胞自动机对从深度神经网络中提取的视觉特征进行操作，他们能够迭代地构建图像的多尺度显著性图，最终图像接近目标项目。Sandler
    等人（[2020](#bib.bib66)）随后研究了细胞自动机在图像分割任务中的应用，这是一个深度学习取得巨大成功的领域。他们展示了使用具有相对简单规则的细胞自动机（神经网络参数少至
    10K）来执行复杂分割任务的可行性，这种方法的优点在于能够扩展到非常大的图像尺寸，这是传统深度学习模型（具有数百万甚至数十亿模型参数）所面临的挑战，而这些模型受到
    GPU 内存的限制。
- en: 4.2 Deep Reinforcement Learning
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 深度强化学习
- en: The rise in deep learning gave birth to the use of deep neural networks for
    reinforcement learning, or deep reinforcement learning (Deep RL), equipping reinforcement
    learning agents with modern neural networks architectures that can address more
    complex problems, such as high dimensional continuous control or vision-based
    tasks from pixel observations. While Deep RL shares successful characteristics
    with deep learning, in that employing sufficient computation resources will generally
    lead to the solution of a target training task to be found. But like deep learning,
    Deep RL has its share of limitations. Agents trained to perform a particular task
    often fail when the task is slightly altered. Furthermore, neural network solutions
    generally only work for a specific morphology with well-defined input and output
    mappings. For instance, a locomotion policy trained for a 4-legged ant might not
    work for a 6-legged one, and a controller that expects to receive 10 inputs won’t
    work if you give it 5, or 20 inputs.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的兴起催生了深度神经网络在强化学习中的应用，即深度强化学习（Deep RL），为强化学习代理配备了现代神经网络架构，这些架构能够解决更复杂的问题，如高维连续控制或基于像素观测的视觉任务。虽然深度强化学习与深度学习具有成功的相似特征，即足够的计算资源通常会导致目标训练任务的解决，但与深度学习一样，深度强化学习也有其局限性。经过训练的代理在任务稍有变化时往往会失败。此外，神经网络解决方案通常只适用于具有明确输入和输出映射的特定形态。例如，为四足蚂蚁训练的运动策略可能不适用于六足蚂蚁，而期望接收10个输入的控制器如果给它5个或20个输入就无法正常工作。
- en: '![Refer to caption](img/ddabf687cb5ea2808b164f8f0f37a499.png)![Refer to caption](img/b18226a8a0a676a7ff4006634df7ccb4.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/ddabf687cb5ea2808b164f8f0f37a499.png)![参见标题](img/b18226a8a0a676a7ff4006634df7ccb4.png)'
- en: 'Figure 7: Examples of soft-bodied robot simulation in 2D and 3D. Each cell
    represents an individual neural network with local sensory functions that produce
    local actions, including communicating to neighboring cells. Training these systems
    to perform various locomotion tasks involve not only training the neural networks,
    but also the design and placement of the soft cells that form the agent’s morphology.
    Figure from Horibe et al. Horibe et al. ([2021](#bib.bib31))'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：二维和三维软体机器人仿真的示例。每个单元格代表一个具有局部感知功能的独立神经网络，这些网络产生局部动作，包括与邻近单元格的通信。训练这些系统以执行各种运动任务不仅涉及神经网络的训练，还包括设计和放置形成代理形态的软体单元。图来源于
    Horibe 等人 Horibe et al. ([2021](#bib.bib31))
- en: 'The evolutionary computation community started approaching some of these challenges
    earlier on, by incorporating modularity Schilling ([2000](#bib.bib67)); Schilling
    and Steensma ([2001](#bib.bib68)) in the evolutionary process that govern the
    design of artificial agents. Having agents that are composed of identical but
    independent modules foster self-organization via local interactions between the
    modules, enabling systems that are robust to changes in the agent’s morphology,
    an essential requirement in evolutionary systems. These ideas have been presented
    in the literature of work on soft-bodied robotics Cheney et al. ([2014](#bib.bib8)),
    where robots consist of a grid of voxel cells–each controlled by an independent
    neural network with local sensory function that can produce a localized action.
    Through message passing, the group of cells that make up the robot are able to
    self-organize and perform a range of locomotion tasks (See Figure [7](#S4.F7 "Figure
    7 ‣ 4.2 Deep Reinforcement Learning ‣ 4 Collective Intelligence for Deep Learning
    ‣ Collective Intelligence for Deep Learning: A Survey of Recent Developments")).
    Later work Joachimczak et al. ([2016](#bib.bib36)) even proposes incorporating
    metamorphosis in the evolution of the placement of the cells to produce configurations
    robust to a range of environments.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '进化计算社区较早地开始解决这些挑战，通过在控制人工代理设计的进化过程中融入模块化 Schilling ([2000](#bib.bib67))；Schilling
    和 Steensma ([2001](#bib.bib68))。由相同但独立模块组成的代理促进了模块之间的局部互动，从而实现自组织，这使得系统对代理形态的变化具有鲁棒性，这是进化系统中的一个重要要求。这些想法在软体机器人文献中有所展示 Cheney
    et al. ([2014](#bib.bib8))，其中机器人由一个体素单元网格组成，每个单元由一个具有局部感知功能的独立神经网络控制，可以产生局部动作。通过消息传递，构成机器人的单元组能够自组织并执行一系列运动任务（见图[7](#S4.F7
    "Figure 7 ‣ 4.2 Deep Reinforcement Learning ‣ 4 Collective Intelligence for Deep
    Learning ‣ Collective Intelligence for Deep Learning: A Survey of Recent Developments")）。后续工作
    Joachimczak et al. ([2016](#bib.bib36)) 甚至提出在细胞放置的进化中加入变形，以产生对各种环境具有鲁棒性的配置。'
- en: '![Refer to caption](img/e133a0dfd92610ba3db600350c9ea6cf.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e133a0dfd92610ba3db600350c9ea6cf.png)'
- en: 'Figure 8: Traditional RL methods train a specific policy for a particular robot
    with a fixed morphology. But recent work, like the one shown here by Huang et
    al. Huang et al. ([2020](#bib.bib32)) attempts to train a single modular neural
    network responsible for controlling a single part of a robot. The global policy
    of each robot is thus the result of coordination of these identical modular neural
    networks. They show that such a system can generalize across a variety of different
    skeletal structures, from hoppers to quadrupeds, and even to some unseen morphologies.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：传统的强化学习方法为具有固定形态的特定机器人训练特定的策略。但最近的工作，例如Huang等人（[2020](#bib.bib32)）展示了尝试训练一个负责控制机器人单一部件的单一模块神经网络。每个机器人的全局策略因此是这些相同模块神经网络的协调结果。他们展示了这样的系统能够在各种不同的骨架结构中进行泛化，从跳跃者到四足动物，甚至包括一些未见过的形态。
- en: Recently, soft-bodied robots have even been combined with the neural CA approach
    discussed earlier to enable these robots to regenerate themselves. Horibe et al.
    ([2021](#bib.bib31)) To bridge the gap between policy optimization (where the
    goal is to find the best parameters of the policy neural network) usually done
    in the Deep RL community and the type of morphology-policy co-evolution (where
    both the morphology and the policy neural network is optimized together) work
    done in the soft-bodied literature, Bhatia et al. Bhatia et al. ([2021](#bib.bib5))
    has recently developed an OpenAI Gym-like Brockman et al. ([2016](#bib.bib6))
    environment called Evolution Gym, a benchmark for developing and comparing algorithms
    for co-optimizing design and control, which provided an efficient soft-bodied
    robot simulator written in C++ with a Python interface.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，软体机器人甚至与之前讨论的神经CA方法结合，以使这些机器人能够自我再生。Horibe等人（[2021](#bib.bib31)）为弥合政策优化（其目标是找到策略神经网络的最佳参数）通常在深度强化学习社区中完成，以及软体文献中形态-策略共同进化（形态和策略神经网络一起优化）工作的差距，Bhatia等人（[2021](#bib.bib5)）最近开发了一个类似OpenAI
    Gym的环境，称为Evolution Gym，这是一个用于共同优化设计和控制的算法开发和比较的基准，为开发了一个用C++编写的高效软体机器人模拟器，并提供了Python接口。
- en: 'Modular, decentralized self-organizing controllers have also started to be
    explored in the Deep RL community. Wang et al. Wang et al. ([2018](#bib.bib91))
    and Huang et al. Huang et al. ([2020](#bib.bib32)) explored the use of modular
    neural networks to control each individual actuator of a simulated robot for continuous
    control. They expressed a global locomotion policy as a collection of modular
    neural networks (in the case of Huang et al. Huang et al. ([2020](#bib.bib32)),
    identical networks) that correspond to each of the agent’s actuators, and trained
    the system using RL. Like soft-bodied robots, every module is only responsible
    for controlling its corresponding actuator and receives information from only
    its local sensors (See Figure [8](#S4.F8 "Figure 8 ‣ 4.2 Deep Reinforcement Learning
    ‣ 4 Collective Intelligence for Deep Learning ‣ Collective Intelligence for Deep
    Learning: A Survey of Recent Developments")). Messages are passed between neighboring
    modules, propagating information between distant modules. They show that a single
    modular policy can generate locomotion behaviors for several distinct robot morphologies,
    and show that the policies generalize to variations of the morphologies not seen
    during training, such as creatures with extra legs. As in the case of soft-bodied
    robots, these results also demonstrate the emergence of centralized coordination
    via message passing between decentralized modules that are collectively optimizing
    for a shared reward.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '模块化、去中心化自组织控制器也开始在深度强化学习社区中得到探索。Wang等人（[2018](#bib.bib91)）和Huang等人（[2020](#bib.bib32)）探索了使用模块化神经网络来控制模拟机器人每个单独执行器以实现连续控制。他们将全局运动策略表示为一组模块化神经网络（在Huang等人（[2020](#bib.bib32)）的情况下，为相同的网络），这些网络对应于每个代理的执行器，并使用强化学习训练系统。与软体机器人一样，每个模块仅负责控制其对应的执行器，并仅接收来自其局部传感器的信息（参见图[8](#S4.F8
    "Figure 8 ‣ 4.2 Deep Reinforcement Learning ‣ 4 Collective Intelligence for Deep
    Learning ‣ Collective Intelligence for Deep Learning: A Survey of Recent Developments")）。消息在相邻模块之间传递，信息在远离的模块之间传播。他们展示了单一模块策略能够为几种不同的机器人形态生成运动行为，并展示了这些策略可以泛化到训练过程中未见过的形态变化，例如具有额外腿部的生物体。与软体机器人情况类似，这些结果也展示了通过去中心化模块之间的消息传递来实现集中协调，这些模块共同优化以获取共享奖励。'
- en: '![Refer to caption](img/fa40eca908d9140b153975801ab39c89.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/fa40eca908d9140b153975801ab39c89.png)'
- en: 'Figure 9: Self-organization also enables systems in RL environments to self-configure
    its own design for a given task. Pathak et al. Pathak et al. ([2019](#bib.bib52))
    explored such dynamic and modular agents and showed that they can generalize to
    not only unseen environments, but also to unseen morphologies composed of additional
    modules.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：自组织还使RL环境中的系统能够自我配置以完成给定任务。Pathak等 Pathak等 ([2019](#bib.bib52)) 探索了这种动态和模块化的代理，并展示了它们不仅能泛化到未见过的环境，还能泛化到由额外模块组成的未见过的形态。
- en: The aforementioned work hints at the power of embodied cognition, which emphasizes
    the role of the agent’s body in generating behavior. Although the focus of much
    of the work in Deep RL is in learning neural network policies for an agent with
    a fixed design (e.g., a bipedal robot, humanoid, or robot arm), embodied intelligence
    is an area that is gathering interest in the sub-field Ha ([2018](#bib.bib23));
    Pathak et al. ([2019](#bib.bib52)). Inspired by previous work on self-configuring
    modular robots Stoy et al. ([2010](#bib.bib77)); Rubenstein et al. ([2014](#bib.bib62));
    Hamann ([2018](#bib.bib26)), Pathak et al. Pathak et al. ([2019](#bib.bib52))
    investigates a collection of primitive agents that learn to self-assemble into
    a complex body while also learning a local policy to control the body without
    an explicit centralized control unit. Each primitive agent (which consists of
    a limb and a motor) can link up with nearby agents, allowing for complex morphologies
    to emerge. Their results show that these dynamic and modular agents are robust
    to changes in conditions and the policies can generalize to not only unseen environments,
    but also to unseen morphologies consisting of a greater number of modules. We
    note that these ideas can be used to allow general DL systems (not confined to
    RL) to have more flexible architectures that can even learn machine learning algorithms,
    and we will discuss this later on in the Meta-Learning section.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 前述工作暗示了具身认知的力量，这强调了代理体在生成行为中的作用。尽管深度RL中的大部分工作集中于为具有固定设计的代理（如双足机器人、人形机器人或机器人手臂）学习神经网络策略，但具身智能是一个在子领域中受到关注的领域
    Ha ([2018](#bib.bib23)); Pathak等 ([2019](#bib.bib52))。受之前关于自配置模块化机器人的工作启发 Stoy等
    ([2010](#bib.bib77)); Rubenstein等 ([2014](#bib.bib62)); Hamann ([2018](#bib.bib26))，Pathak等
    Pathak等 ([2019](#bib.bib52)) 研究了一组原始代理，这些代理学习自我组装成复杂的身体，同时学习控制身体的局部策略，而不依赖于明确的集中控制单元。每个原始代理（由一个肢体和一个电机组成）可以与附近的代理连接，允许复杂的形态出现。他们的结果表明，这些动态和模块化的代理对条件变化具有鲁棒性，并且策略不仅能泛化到未见过的环境，还能泛化到由更多模块组成的未见过的形态。我们注意到，这些思想可以用于使通用DL系统（不限于RL）具有更灵活的架构，甚至可以学习机器学习算法，我们将在稍后的Meta-Learning部分讨论这一点。
- en: '![Refer to caption](img/9c888e3a00bf484f11b9a9a5da27f03e.png)![Refer to caption](img/12ecc025043e316d39c4b999be31761b.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/9c888e3a00bf484f11b9a9a5da27f03e.png)![参见标题](img/12ecc025043e316d39c4b999be31761b.png)'
- en: 'Figure 10: Using the properties of self-organization and attention, Tang and
    Ha Tang and Ha ([2021](#bib.bib84)) investigated RL agents that treat their observations
    as an arbitrarily ordered, variable-length list of sensory inputs. They partition
    the input in visual tasks such as CarRacing and Atari Pong Brockman et al. ([2016](#bib.bib6));
    Tang et al. ([2020](#bib.bib85)) into a 2D grid of small patches, and shuffled
    their ordering (Left). They also added many additional redundant noisy input channels
    in continuous control tasks Freeman et al. ([2019](#bib.bib19)) in a shuffled
    order (Right), where the agent has to learn to identify which inputs are useful.
    Each sensory neuron in the system receives a stream of a particular input, and
    through coordination, must complete the task at hand.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：利用自组织和注意力的特性，Tang和Ha Tang和Ha ([2021](#bib.bib84)) 研究了将观察视为任意排序的、可变长度的感官输入列表的RL代理。他们将输入在视觉任务中，如CarRacing和Atari
    Pong Brockman等 ([2016](#bib.bib6)); Tang等 ([2020](#bib.bib85))，划分为小块的2D网格，并打乱其顺序（左）。他们还在连续控制任务中添加了许多额外的冗余噪声输入通道
    Freeman等 ([2019](#bib.bib19))，以打乱的顺序（右），代理必须学会识别哪些输入是有用的。系统中的每个感官神经元接收特定输入的流，通过协调，必须完成手头的任务。
- en: Aside from adapting to changing morphologies and environments, self-organizing
    systems can also adapt to changes in their sensory inputs. Sensory substitution
    refers to the brain’s ability to use one sensory modality (e.g., touch) to supply
    environmental information normally gathered by another sense (e.g., vision). However,
    most neural networks are not able to adapt to sensory substitutions. For instance,
    most RL agents require their inputs to be in an exact, pre-specified rigid format,
    otherwise they will fail. In a recent work, Tang and Ha Tang and Ha ([2021](#bib.bib84))
    explored permutation invariant neural network agents that require each of their
    sensory neurons (receptors that receive sensory inputs from the environment) to
    deduce the meaning and context of its input signal, rather than explicitly assume
    a fixed meaning. They demonstrate that these sensory networks can be trained to
    integrate information received locally, and through communication between them
    using an attention mechanism, can collectively produce a globally coherent policy.
    Moreover, the system can still perform its task even if the ordering of its sensory
    inputs (represented as real-valued numbers) is randomly permuted several times
    during an episode. Their experiments show that such agents are robust to observations
    that contain many additional redundant or noisy information, or observations that
    are corrupt and incomplete.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 除了适应不断变化的形态和环境，自组织系统还可以适应其感官输入的变化。感官替代是指大脑利用一种感官模态（例如触觉）来提供通常由另一种感官（例如视觉）获取的环境信息。然而，大多数神经网络无法适应感官替代。例如，大多数RL代理需要其输入以确切的、预先指定的固定格式出现，否则它们将失败。在最近的研究中，Tang和Ha
    ([2021](#bib.bib84)) 探索了排列不变的神经网络代理，这些代理要求每个感官神经元（接收来自环境的感官输入的感受器）推断其输入信号的意义和上下文，而不是明确地假设固定的意义。他们展示了这些感官网络可以被训练来整合局部接收到的信息，并通过使用注意机制的相互通信，集体产生一个全球一致的策略。此外，即使在一个过程中的感官输入（表示为实数）被随机排列多次，系统仍然可以执行其任务。他们的实验表明，这些代理对包含许多额外冗余或噪声信息，或者受到损坏和不完整的观察结果具有鲁棒性。
- en: 4.3 Multi-agent Learning
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 多代理学习
- en: Collective intelligence can be viewed at several different scales. The brain
    can be viewed as a network of individual neurons functioning collectively. Each
    organ can be viewed as a collection of cells performing a collective function.
    Individual animals can be viewed as a collection of organs working together. As
    we zoom out further, we can also look at human intelligence beyond biology and
    see human civilization as a collective intelligence solving (and producing) problems
    that are beyond the capabilities of a single person. As such, while in the previous
    section, we discussed several works that leverage the power of collective intelligence
    to essentially decompose a single RL agent into a collection of smaller RL agents
    working together towards a collective goal, resembling a model of collective intelligence
    at the biological level, we can also view multi-agent problems as a model of collective
    intelligence at the societal level.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 集体智能可以在不同的尺度上进行观察。大脑可以被视为一个由个体神经元共同工作的网络。每个器官可以被视为一个执行集体功能的细胞集合。个体动物可以被视为一个器官共同运作的集合。随着我们进一步放大，我们还可以超越生物学来看待人类智能，将人类文明视为一个解决（并产生）超越单个人能力的问题的集体智能。因此，虽然在前一节中，我们讨论了几项利用集体智能的力量将单个RL代理分解为多个协作的RL代理，类似于生物学层面的集体智能模型，我们也可以将多代理问题视为社会层面的集体智能模型。
- en: A major focus of the collective intelligence field is to study the group intelligence
    and behaviors emerged from a large collection of individuals, whether in humans citetapscott2008wikinomics,
    animals Sumpter ([2010](#bib.bib81)) insects Dorigo et al. ([2000](#bib.bib17));
    Seeley ([2010](#bib.bib73)), or artificial swarm robots Hamann ([2018](#bib.bib26));
    Rubenstein et al. ([2014](#bib.bib62)). This focus has clearly been missing in
    the Deep RL field. While multi-agent reinforcement learning (MARL) is a well-established
    branch of Deep RL, most learning algorithms and environments proposed have targeted
    a relatively small number of agents Foerster et al. ([2016](#bib.bib18)); OroojlooyJadid
    and Hajinezhad ([2019](#bib.bib49)), and thus not sufficient to study the emergent
    properties from large populations. In the most common MARL environments Resnick
    et al. ([2018](#bib.bib61)); Baker et al. ([2019](#bib.bib3)); Jaderberg et al.
    ([2019](#bib.bib34)); Terry et al. ([2020](#bib.bib88)), “multi-agent” simply
    means 2 or 4 agent trained to perform a task by means of self-play  Bansal et al.
    ([2017](#bib.bib4)); Liu et al. ([2019](#bib.bib44)); Ha ([2020](#bib.bib24)).
    Collective intelligence observed in nature or in society, however, relies on a
    much larger number of individuals than typically studied in MARL, involving population
    sizes from thousands to million. In this section, we will discuss recent works
    from the MARL sub-field of Deep RL that had been inspired by collective intelligence
    (as their authors have even noted in their publications). Unlike most MARL works,
    these work started to employ large population of agents (each enabled by a neural
    network), from thousands to millions, in order to truly study their emergent properties
    at the macro level (1000+ agents), rather than at the micro-level (2-4 agents).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/06cec791200fe5634ee37cc86586af46.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: MAgent Zheng et al. ([2018](#bib.bib96)) is a set of environments
    where large numbers of pixel agents in a gridworld interact in battles or other
    competitive scenarios. Unlike most platforms that focus on RL research with a
    single agent or only few agents, their aim is to support RL research that scales
    up to millions of agents. The environments in this platform are now maintained
    as part of the PettingZoo Terry et al. ([2020](#bib.bib88)) open-source library
    for multi-agent RL research.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Recent advances in Deep RL have demonstrated the capabilities of simulating
    thousands of agents in complex 3D simulation environments using only a single
    GPU Heiden et al. ([2021](#bib.bib28)); Rudin et al. ([2021](#bib.bib63)). A key
    challenge is in approaching the problem of multi-agent learning at a much larger
    scale, leveraging such advances in parallel computing hardware and distributed
    computation, with the goal of training millions of agents. In this section, we
    will example recent attempts at training a massive number of agents that interact
    in a collective setting.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Rather than focusing on realistic physics or environment realism, Zheng. et
    al. Zheng et al. ([2018](#bib.bib96)) developed a platform called MAgent, a simple
    grid-world environment that can allows millions of neural network agents. Their
    focus is on scalability, and they demonstrate that MAgent can host up to a million
    agents on a single GPU (in 2017). Their platform supports interactions among the
    population of agents, and facilitates not only the study of learning algorithms
    for policy optimization, but more critically, enables the study of social phenomena
    emerging from the millions of agents in an AI society, including the emergence
    of languages and societal hierarchy structures that may have emerged. Environments
    can be built using scripting, and they have provided examples such as predator-prey
    simulations, battlefields, adversarial pursuit, supporting different species of
    distinct agents that may exhibit different behaviors.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Zheng 等人 ([2018](#bib.bib96)) 开发了一个名为 MAgent 的平台，这个平台是一个简单的网格世界环境，允许数百万个神经网络代理人。他们的重点是可扩展性，并且展示了
    MAgent 可以在单个 GPU 上容纳多达一百万个代理人（2017 年）。他们的平台支持代理人群体之间的互动，不仅促进了针对策略优化的学习算法研究，更关键的是，使得研究
    AI 社会中数百万个代理人涌现的社会现象成为可能，包括可能出现的语言和社会等级结构。环境可以通过脚本构建，并且他们提供了诸如捕食者-猎物模拟、战场、对抗追逐等示例，支持可能表现出不同行为的不同物种的代理人。
- en: MAgent inspired many recent applications, including multi-agent driving Peng
    et al. ([2021](#bib.bib53)), which looks at emergent behavior of entire populations
    of driving agents to optimize the driving policies which not only affect a single
    car, but aim to improve the safety of the population as a whole. These directions
    are good examples that demonstrate the difference between problems framed for
    deep learning (finding a driving policy for a single car) versus problems in collective
    intelligence (finding a driving policy for the entire population).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: MAgent 激发了许多近期应用，包括多智能体驾驶 Peng 等人 ([2021](#bib.bib53))，该研究关注于整个驾驶代理人群体的涌现行为，以优化驾驶策略，这些策略不仅影响单个汽车，还旨在提高整个群体的安全性。这些方向是很好的例子，展示了深度学习问题（为单个汽车寻找驾驶策略）与集体智能问题（为整个群体寻找驾驶策略）之间的区别。
- en: '![Refer to caption](img/d0f20c6c4e22ea1b4525b8bc964ebddf.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d0f20c6c4e22ea1b4525b8bc964ebddf.png)'
- en: 'Figure 12: Neural MMO Suarez et al. ([2021](#bib.bib79)) is a platform that
    simulates populations of agents in procedurally generated virtual worlds to support
    multi-agent research while keeping its requirements computationally accessible.
    Users select from a set of provided game systems to create environments for their
    specific research problems–-with support for up to a thousand agents and one square
    kilometer maps over several thousand time steps. The project is under active development,
    with extensive documentation and tools that provide logging, and visualization
    tools for researchers. As of writing, this platform is to be demoed at the NeurIPS
    2021 conference.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：Neural MMO Suarez 等人 ([2021](#bib.bib79)) 是一个平台，用于模拟程序生成虚拟世界中的代理人群体，以支持多智能体研究，同时保持其计算需求在可接受范围内。用户可以从提供的游戏系统中选择，以创建适合其特定研究问题的环境——支持多达一千个代理人和一平方公里的地图，跨越数千个时间步骤。该项目正在积极开发中，提供了广泛的文档和工具，包括日志记录和可视化工具。撰写本文时，该平台将在
    NeurIPS 2021 会议上展示。
- en: Inspired by the game genre of MMORPGs (Massively Multiplayer Online Role-Playing
    Games, aka MMOs), Neural MMO Suarez et al. ([2021](#bib.bib79)) is an AI research
    environment that supports a large number of artificial agents that have to compete
    for finite resources in order to survive. As such, their environment enables large-scale
    simulation of multi-agent interactions that requires agents to learn combat and
    navigation policies alongside other agents in a large population all attempting
    to do the same. Unlike most MARL environments, each agent is allowed to have their
    own distinct set of neural network weights, which has been a technical challenge
    in terms of memory consumption. Preliminary experimental results in early versions
    of the platform Suarez et al. ([2019](#bib.bib78)) demonstrated agents with distinct
    neural network weight parameters developed skills to fill different niches in
    order to avoid competition within a large population of agents.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: As of writing, this project is in active development in the NeurIPS machine
    learning community Suarez et al. ([2021](#bib.bib79)) to work towards studies
    of large agent populations, long time horizons, open-ended tasks, and modular
    game systems. The developers provide active support and documentation, and also
    develop additional training, logging, and visualization tools to enable this line
    of large-scale multi-agent research. This work is still in its early stages, and
    only time will tell if platforms that enable the study of large populations such
    as Neural MMO or MAgent gain further traction within the Deep RL communities.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Meta-Learning
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous sections, we described works that express the solution to problems
    in terms of a collection of independent neural network agents acting together
    to achieve a common goal. These parameters of these neural network models are
    optimized for the collective performance of the population. While these systems
    have been shown to be robust and adapt to changes in its environment, they are
    ultimately hardwired to perform a certain task, and cannot perform another task
    unless retrained from scratch.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Meta-learning is an active area of research within deep learning where the goal
    is to train the system to learn. It is a large sub-field of ML, including areas
    such as simple transfer learning from one training set to another. For our purposes,
    we follow the line of work from Schmidhuber Schmidhuber ([2020](#bib.bib70)),
    where he views meta learning as the problem of ML algorithms that can learn better
    ML algorithms, which he believes is required to build truly self-improving AI
    systems.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: So unlike traditionally training a neural network to perform one task, where
    the weight parameters of neural networks are traditionally optimized with a gradient
    descent algorithm, or with evolution strategies Tang et al. ([2022](#bib.bib86)),
    the goal of meta-learning is to train a meta-learner (which can be another neural
    network-based system) to learn a learning algorithm. This is a particularly challenging
    task, with a long history see Schmidhuber Schmidhuber ([2020](#bib.bib70)) for
    a review). In this section, we will highlight recent promising works that make
    use of collective agents that can learn to learn, rather than learn to perform
    only a particular task (which we have covered in the previous section).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Concepts from self-organization can be naturally applied to train neural networks
    to meta-learn by extending the basic building blocks that compose artificial neural
    networks. As we know, artificial neural networks consist of identical neurons
    which are modeled as non-linear activation functions. These neurons are connected
    in a network by synaposes which are weight parameters which are normally trained
    with a learning algorithm such as gradient descent. But one can imagine extending
    the abstraction of neurons and synapses beyond static activation functions and
    floating point parameters. Indeed, recent work Ohsawa et al. ([2018](#bib.bib48));
    Ott ([2020](#bib.bib50)) have explored modeling each neuron of a neural network
    as an individual reinforcement learning agent. Using the terminology of RL, each
    neuron’s observations are its current state which change as information is transmitted
    through the network, and each neuron’s actions enable each neuron to modify its
    connections with other neurons in the system, hence the problem of learning to
    learn is treated as a multi-agent RL problem where each agent is part of the collection
    of neurons in a neural network. While this approach is elegant, the aforementioned
    works are only capable of learning to solve toy problems and are not yet competitive
    with existing learning algorithms.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Recent methods have gone beyond using simple scalar weights to transmit scalar
    signals between neurons. Sandler et al. Sandler et al. ([2021](#bib.bib65)) introduce
    a new type of generalized artificial neural network where both neurons and synapses
    have multiple states. Traditional artificial neural networks can be viewed as
    a special case of their framework with two-states where one is used for activations,
    the other is used for gradients produced using the backpropagation learning rule.
    In the general framework, they do not require the backpropagation procedure to
    compute any gradients, and instead rely on a shared local learning rule for updating
    the states of the synapses and neurons. This Hebbian-style bi-directional local
    update rule would only require that each synapse and neuron only requires state
    information from their neighboring synapse and neurons, similar to cellular automata.
    The rule is parameterized as a low-dimensional genome vector, and is consistent
    across the system. They employed both evolution strategies, or conventional optimization
    techniques to meta-learn this genome vector, and their main result is that the
    update rules meta-learned on the training tasks generalize to unseen novel test
    tasks. Furthermore, the update rules perform faster than gradient-descent based
    learning algorithms for several standard classification tasks.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的方法已经超越了使用简单标量权重在神经元之间传递标量信号的方式。Sandler等人（[2021](#bib.bib65)）介绍了一种新型的广义人工神经网络，其中神经元和突触都具有多个状态。传统的人工神经网络可以被视为其框架中两状态的特例，其中一种用于激活，另一种用于使用反向传播学习规则产生的梯度。在一般框架中，它们不需要反向传播过程来计算任何梯度，而是依靠一个共享的局部学习规则来更新突触和神经元的状态。这种Hebbian风格的双向局部更新规则只要求每个突触和神经元从其邻近的突触和神经元那里获取状态信息，类似于细胞自动机。该规则被参数化为低维基因组向量，并在整个系统中保持一致。他们采用了进化策略或传统优化技术来元学习这个基因组向量，他们的主要结果是，训练任务上元学习的更新规则能够推广到未见过的新测试任务。此外，这些更新规则在多个标准分类任务上比基于梯度下降的学习算法运行得更快。
- en: '![Refer to caption](img/7f515b143e77166046661e3d4d806747.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7f515b143e77166046661e3d4d806747.png)'
- en: 'Figure 13: Recent work by Sandler et al. Sandler et al. ([2021](#bib.bib65))
    and Kirsch et al. Kirsch and Schmidhuber ([2020](#bib.bib37)) attempt to generalize
    the accepted notion of artificial neural networks, where each neuron can hold
    multiple states rather than a scalar value, and each synapse function bi-directionally
    to facilitate both learning and inference. In this figure, Kirsch et al. Kirsch
    and Schmidhuber ([2020](#bib.bib37)) use an identical recurrent neural network
    (RNN) (with different internal hidden states) to model each synapse, and show
    that the network can be trained by simply running the RNNs forward, without using
    backpropagation.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图13：Sandler等人（[2021](#bib.bib65)）和Kirsch等人（[2020](#bib.bib37)）的最新工作尝试将人工神经网络的公认概念推广到更一般的情况，其中每个神经元可以持有多个状态而不是标量值，每个突触功能是双向的，以便于学习和推理。在这个图中，Kirsch等人（[2020](#bib.bib37)）使用相同的递归神经网络（RNN）（具有不同的内部隐藏状态）来建模每个突触，并展示了该网络可以通过简单地运行RNN前向传播来进行训练，而无需使用反向传播。
- en: 'A similar direction has been taken by Kirsch et al. Kirsch and Schmidhuber
    ([2020](#bib.bib37)), where the neurons and synapses of a neural network are also
    generalized to higher dimension message-passing systems, but in their case each
    synapse is replaced by an recurrent neural network (RNN) with the same shared
    parameters. These RNN synapses are bi-directional and govern the flow of information
    across the network. Like Sandler et al. Sandler et al. ([2021](#bib.bib65)), the
    bi-directional property allows for the network to be used for both inference and
    learning at the same time by running the system in forward-pass mode. The weights
    of this system are essentially stored in the hidden states of the RNNs so by simply
    running the system, they can train themselves using the error signals as feedback.
    Since RNNs are general-purpose computers, they were able to demonstrate that the
    system can encode the gradient-based backpropagation algorithm by training the
    system to simply emulate backpropagation, rather than explicitly calculating gradients
    via hand-engineering. Of course, their system is much more general than backpropagation,
    and thus capable of learning new learning algorithms that are much more efficient
    than backpropagation (See Figure [13](#S4.F13 "Figure 13 ‣ 4.4 Meta-Learning ‣
    4 Collective Intelligence for Deep Learning ‣ Collective Intelligence for Deep
    Learning: A Survey of Recent Developments")).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: The previous two works mentioned in this section are only recently published
    at the time of writing, and we believe that these decentralized local meta-learning
    approaches have the potential to revolutionize the way neural networks are used
    in the future in a way that challenges the current paradigm that separates model
    training and model deployment. There is still much work to be done in demonstrating
    that these approaches can scale to larger datasets, due to inherently much larger
    memory requirements (due to much larger internal states of the system). Furthermore,
    while the algorithms are able to produce learning algorithms that are vastly more
    sample efficient compared to gradient descent, this efficiency is only apparent
    in the early stages of learning, and performance tends to peak very early on.
    Gradient descent, while less efficient, is less biased towards few-shot learning,
    and can continue to run for many more cycles to refine the weight parameters that
    will ultimately produce networks that achieve higher performance.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: 5 Discussion
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this survey, we first gave a brief historical background to describe the
    intertwined development of deep learning and collective intelligence research.
    The two research areas were born at roughly the same time, and we can also spot
    some positive correlations of the rises and falls between the two areas throughout
    their history. This is no coincidence, since advances and breakthroughs in one
    of the two areas can usually innovate new ideas or complement the solutions to
    the problems in the other. For example, introducing deep neural networks and related
    training algorithms to cellular automata allowed us to develop image generation
    algorithms that are resistant to noise and have “self-healing” properties. This
    survey explored several works in deep learning that were also inspired by concepts
    in collective intelligence. At a macro-level collective intelligence in multi-agent
    deep RL led to interesting works that can exceed human performance through collective
    self-play, and to decentralized self-organizing robot controllers; At a micro-level,
    collective intelligence is also embedded inside advanced methods of simulating
    each neuron, synapse or other object at a finer granularity within a system with
    deep models.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Despite the progress made in the works described in this survey, many challenges
    lie ahead. While neural CA techniques have been applied to image-processing, their
    application has so far been limited to relatively small and simple datasets, and
    their image generation quality is still far below the state-of-the-art on more
    sophisticated datasets such as ImageNet or Celebrity Faces Palm et al. ([2022](#bib.bib51)).
    For Deep RL, while the surveyed works have demonstrated that a global policy can
    be replaced by a collection of smaller individual policies, we have yet to transfer
    these experiments to real physical robots. Finally, we have witnessed self-organization
    guide meta-learning algorithms. While this line of work is extremely promising,
    they are currently confined to small-scale experiments due to the large computational
    requirements that come with replacing every single neural connection with an entire
    artificial neural network. We believe many challenges will be solved in due time
    as their trajectories are already in motion.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Looking at their respective development trajectories, DL has accomplished notable
    achievements in developing novel architectures and training algorithms that led
    to efficient learning and better performance. The research and development cycle
    of DL is more engineering-focused, as such the advances seen are more benchmark-based
    (such as classification accuracy for image recognition problems, or related quantitative
    metrics for language modeling and machine translation problems). DL advances are
    generally more incremental and predictable in nature, while CI focuses more on
    problem formulations and environmental mechanisms that motivate novel emergent
    group behavior. As we have shown in this survey, CI-based techniques enable new
    capabilities that were simply not possible before. For instance, it is impossible
    to incrementally-improve a fixed-robot to become a robot capable of self-assembly,
    and gain all the benefits from such modularity. Naturally, the two areas can complement
    each other. We are confident that the hand-in-hand style of co-development will
    continue.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 6 Glossary of Terms and Definitions
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Deep Learning Related |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
- en: '| Term | Definition |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
- en: '| Deep Learning (field) |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
- en: '&#124; The study of machine learning methods based on artificial neural &#124;'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; networks. Much of the field is devoted to research on the numerous &#124;'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; architectures, their training methods, theoretical properties, and &#124;'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; applications of artificial neural networks. &#124;'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '| Supervised Learning |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
- en: '&#124; An approach of learning when both the data and the expected &#124;'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; outputs (training signal) are given. &#124;'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Unsupervised &#124;'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Representation &#124;'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Learning &#124;'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; An approach of learning to represent data in a latent space (the &#124;'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; dimension of which is usually, but not necessarily, lower than that
    &#124;'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; of the input data) without additional training signals. &#124;'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '| Transfer Learning |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
- en: '&#124; A research problem in ML that focuses on applying knowledge gained &#124;'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; from one problem to solve another different but related problem. &#124;'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '| Meta-Learning |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
- en: '&#124; A large sub-field of ML, and in this paper (and including areas such
    &#124;'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; as simple transfer learning from one training set to another). For our
    &#124;'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; purposes, we view meta-learning as the problem of machine learning &#124;'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; algorithms that can learn better machine learning algorithms, which
    &#124;'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; many believe is required to build truly self-improving artificial &#124;'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; intelligent systems. &#124;'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Reinforcement &#124;'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Learning &#124;'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; RL is an area of ML. It consists of methods that train an agent to &#124;'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; improve its policy from interactions with the environment or &#124;'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; experiences in order to achieve goals. &#124;'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '| Agent / Controller |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
- en: '&#124; An (artificial) agent or a controller is a system that takes actions
    &#124;'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; corresponding to a series of inputs in order to achieve goals. &#124;'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '| Policy |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
- en: '&#124; A (control) policy is the “guide book” by which an agent makes &#124;'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; decisions for its actions. In deep RL, a policy usually takes the &#124;'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; form of an artificial neural network which accepts the inputs from &#124;'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; the task/environment and outputs the corresponding actions. &#124;'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '| Self-Play |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
- en: '&#124; A training scheme in RL where an agent is trained by playing &#124;'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; against/with snapshots of itself. &#124;'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Convolutional &#124;'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Neural Networks &#124;'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A class of artificial neural networks that are commonly applied to &#124;'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; imagery data. Their connectivity pattern resembles the organization
    &#124;'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; of the animal visual cortex. &#124;'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Recurrent &#124;'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Neural Networks &#124;'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A class of artificial neural networks most commonly applied to analyze
    &#124;'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; sequential/temporal data. RNNs can use their internal states to process
    &#124;'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; inputs of variable lengths. &#124;'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Graph &#124;'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Neural Networks &#124;'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A class of artificial neural networks for processing data best represented
    &#124;'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; by graph data structures. Such data examples include social networks,
    &#124;'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; molecule structures, robot morphologies, etc. &#124;'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Graph &#124;'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Processing &#124;'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Unit &#124;'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A GPU is a specialized electronic circuit designed to rapidly accelerate
    &#124;'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; the creation of images. Their highly parallel structure makes them &#124;'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; efficient for algorithms that process large blocks of data parallelly
    and &#124;'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; are therefore widely adopted in DL research. &#124;'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '| MNIST |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
- en: '&#124; MNIST is a dataset of handwritten digits that is commonly used for &#124;'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; training image processing systems. &#124;'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '| Collective Intelligence Related Concepts |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
- en: '| Term | Definition |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
- en: '|'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Collective &#124;'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Intelligence (field) &#124;'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; The study of the shared, or group intelligence that emerges from the
    &#124;'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; interaction (collaboration, collective efforts, and/or competition)
    of &#124;'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; a large group of individuals. &#124;'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '| Self-Organization |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
- en: '&#124; A process where some form of overall order arises from (local) &#124;'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; interactions between parts within a system. &#124;'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '| Other Concepts |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
- en: '| Term | Definition |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
- en: '| Complex Systems |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
- en: '&#124; Systems whose behavior is intrinsically difficult to model due to the
    &#124;'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; dependencies and interactions between the parts within the system &#124;'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; and/or across time. &#124;'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '| Cellular Automaton |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
- en: '&#124; A CA is a collection of cells on a grid that evolves their states over
    a &#124;'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; set of discrete values according to predefined rules based on the states
    &#124;'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; of the neighboring cells. &#124;'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '| Embodied Cognition |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
- en: '&#124; It is a theory stating that cognition is shaped by aspects of the entire
    &#124;'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; body of the organism. It emphasizes the role of the body (e.g., motor,
    &#124;'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; perception) in forming cognition features (e.g., form concepts, make
    &#124;'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; judgements). &#124;'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Alam et al. (2020) Alam M, Samad MD, Vidyaratne L, Glandon A and Iftekharuddin
    KM (2020) Survey on deep neural networks in speech and vision systems. *Neurocomputing*
    417: 302–321.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authors (2022) Authors W (2022) Trajan’s bridge at alcantara. *Wikipedia* .
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baker et al. (2019) Baker B, Kanitscheider I, Markov T, Wu Y, Powell G, McGrew
    B and Mordatch I (2019) Emergent tool use from multi-agent autocurricula. *arXiv
    preprint arXiv:1909.07528* .
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bansal et al. (2017) Bansal T, Pachocki J, Sidor S, Sutskever I and Mordatch
    I (2017) Emergent complexity via multi-agent competition. *arXiv preprint arXiv:1710.03748*
    .
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bhatia et al. (2021) Bhatia J, Jackson H, Tian Y, Xu J and Matusik W (2021)
    Evolution gym: A large-scale benchmark for evolving soft robots. In: *Advances
    in Neural Information Processing Systems*. Curran Associates, Inc. URL [https://sites.google.com/corp/view/evolution-gym-benchmark/](https://sites.google.com/corp/view/evolution-gym-benchmark/).'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brockman et al. (2016) Brockman G, Cheung V, Pettersson L, Schneider J, Schulman
    J, Tang J and Zaremba W (2016) Openai gym. *arXiv preprint arXiv:1606.01540* .
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020) Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal
    P, Neelakantan A, Shyam P, Sastry G, Askell A et al. (2020) Language models are
    few-shot learners. *arXiv preprint arXiv:2005.14165* .
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cheney et al. (2014) Cheney N, MacCurdy R, Clune J and Lipson H (2014) Unshackling
    evolution: evolving soft robots with multiple materials and a powerful generative
    encoding. *ACM SIGEVOlution* 7(1): 11–23.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chollet et al. (2015) Chollet F et al. (2015) keras.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chua and Roska (2002) Chua LO and Roska T (2002) *Cellular neural networks
    and visual computing: foundations and applications*. Cambridge university press.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chua and Yang (1988a) Chua LO and Yang L (1988a) Cellular neural networks:
    Applications. *IEEE Transactions on circuits and systems* 35(10): 1273–1290.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chua and Yang (1988b) Chua LO and Yang L (1988b) Cellular neural networks:
    Theory. *IEEE Transactions on circuits and systems* 35(10): 1257–1272.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Conway et al. (1970) Conway J et al. (1970) The game of life. *Scientific American*
    223(4): 4.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Daigavane et al. (2021) Daigavane A, Ravindran B and Aggarwal G (2021) Understanding
    convolutions on graphs. *Distill* [10.23915/distill.00032](https:/doi.org/10.23915/distill.00032).
    Https://distill.pub/2021/understanding-gnns.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deneubourg and Goss (1989) Deneubourg JL and Goss S (1989) Collective patterns
    and decision-making. *Ethology Ecology & Evolution* 1(4): 295–311.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deng et al. (2009) Deng J, Dong W, Socher R, Li LJ, Li K and Fei-Fei L (2009)
    Imagenet: A large-scale hierarchical image database. In: *2009 IEEE conference
    on computer vision and pattern recognition*. Ieee, pp. 248–255.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dorigo et al. (2000) Dorigo M, Bonabeau E and Theraulaz G (2000) Ant algorithms
    and stigmergy. *Future Generation Computer Systems* 16(8): 851–871.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Foerster et al. (2016) Foerster JN, Assael YM, De Freitas N and Whiteson S (2016)
    Learning to communicate with deep multi-agent reinforcement learning. *arXiv preprint
    arXiv:1605.06676* .
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Freeman et al. (2019) Freeman CD, Metz L and Ha D (2019) Learning to predict
    without looking ahead: World models without forward prediction URL [https://learningtopredict.github.io](https://learningtopredict.github.io).'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gilpin (2019) Gilpin W (2019) Cellular automata as convolutional neural networks.
    *Physical Review E* 100(3): 032402.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GoraS et al. (1995) GoraS L, Chua LO and Leenaerts D (1995) Turing patterns
    in cnns. i. once over lightly. *IEEE Transactions on Circuits and Systems I: Fundamental
    Theory and Applications* 42(10): 602–611.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grattarola et al. (2021) Grattarola D, Livi L and Alippi C (2021) Learning graph
    cellular automata.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ha (2018) Ha D (2018) Reinforcement learning for improving agent design URL
    [https://designrl.github.io](https://designrl.github.io).
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ha (2020) Ha D (2020) Slime volleyball gym environment. [https://github.com/hardmaru/slimevolleygym](https://github.com/hardmaru/slimevolleygym).
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ha and Schmidhuber (2018) Ha D and Schmidhuber J (2018) Recurrent world models
    facilitate policy evolution. In: *Advances in Neural Information Processing Systems
    31*. Curran Associates, Inc., pp. 2451–2463. URL [https://papers.nips.cc/paper/7512-recurrent-world-models-facilitate-policy-evolution](https://papers.nips.cc/paper/7512-recurrent-world-models-facilitate-policy-evolution).
    [https://worldmodels.github.io](https://worldmodels.github.io).'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hamann (2018) Hamann H (2018) *Swarm robotics: A formal approach*. Springer.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'He et al. (2016) He K, Zhang X, Ren S and Sun J (2016) Deep residual learning
    for image recognition. In: *Proceedings of the IEEE conference on computer vision
    and pattern recognition*. pp. 770–778.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Heiden et al. (2021) Heiden E, Millard D, Coumans E, Sheng Y and Sukhatme GS
    (2021) NeuralSim: Augmenting differentiable simulators with neural networks. In:
    *Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)*.
    URL [https://github.com/google-research/tiny-differentiable-simulator](https://github.com/google-research/tiny-differentiable-simulator).'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hill et al. (2018) Hill A, Raffin A, Ernestus M, Gleave A, Kanervisto A, Traore
    R, Dhariwal P, Hesse C, Klimov O, Nichol A et al. (2018) Stable baselines.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hooker (2020) Hooker S (2020) The hardware lottery. *arXiv preprint arXiv:2009.06489*
    URL [https://hardwarelottery.github.io/](https://hardwarelottery.github.io/).
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Horibe et al. (2021) Horibe K, Walker K and Risi S (2021) Regenerating soft
    robots through neural cellular automata. In: *EuroGP*. pp. 36–50.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. (2020) Huang W, Mordatch I and Pathak D (2020) One policy to control
    them all: Shared modular policies for agent-agnostic control. In: *International
    Conference on Machine Learning*. PMLR, pp. 4455–4464.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jabbar et al. (2021) Jabbar A, Li X and Omar B (2021) A survey on generative
    adversarial networks: Variants, applications, and training. *ACM Computing Surveys
    (CSUR)* 54(8): 1–49.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jaderberg et al. (2019) Jaderberg M, Czarnecki WM, Dunning I, Marris L, Lever
    G, Castaneda AG, Beattie C, Rabinowitz NC, Morcos AS, Ruderman A et al. (2019)
    Human-level performance in 3d multiplayer games with population-based reinforcement
    learning. *Science* 364(6443): 859–865.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jenal (2011) Jenal M (2011) What ants can teach us about the market. URL [https://www.jenal.org/what-ants-can-teach-us-about-the-market/](https://www.jenal.org/what-ants-can-teach-us-about-the-market/).
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Joachimczak et al. (2016) Joachimczak M, Suzuki R and Arita T (2016) Artificial
    metamorphosis: Evolutionary design of transforming, soft-bodied robots. *Artificial
    life* 22(3): 271–298.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kirsch and Schmidhuber (2020) Kirsch L and Schmidhuber J (2020) Meta learning
    backpropagation and improving it. *arXiv preprint arXiv:2012.14905* .
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kozek et al. (1993) Kozek T, Roska T and Chua LO (1993) Genetic algorithm for
    cnn template learning. *IEEE Transactions on Circuits and Systems I: Fundamental
    Theory and Applications* 40(6): 392–402.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Krizhevsky et al. (2012) Krizhevsky A, Sutskever I and Hinton GE (2012) Imagenet
    classification with deep convolutional neural networks. *Advances in neural information
    processing systems* 25: 1097–1105.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lajad et al. (2021) Lajad R, Moreno E and Arenas A (2021) Young honeybees show
    learned preferences after experiencing adulterated pollen. *Scientific reports*
    11(1): 1–11.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Leimeister (2010) Leimeister JM (2010) Collective intelligence. *Business &
    Information Systems Engineering* 2(4): 245–248.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lévy (1997) Lévy P (1997) Collective intelligence.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2020) Liu JB, Raza Z and Javaid M (2020) Zagreb connection numbers
    for cellular neural networks. *Discrete Dynamics in Nature and Society* 2020.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2019) Liu S, Lever G, Merel J, Tunyasuvunakool S, Heess N and Graepel
    T (2019) Emergent coordination through competition. *arXiv preprint arXiv:1902.07151*
    .
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mataric (1993) Mataric MJ (1993) Designing emergent behaviors: From local interactions
    to collective intelligence. In: *Proceedings of the Second International Conference
    on Simulation of Adaptive Behavior*. pp. 432–441.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mnih et al. (2015) Mnih V, Kavukcuoglu K, Silver D, Rusu AA, Veness J, Bellemare
    MG, Graves A, Riedmiller M, Fidjeland AK, Ostrovski G et al. (2015) Human-level
    control through deep reinforcement learning. *nature* 518(7540): 529–533.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mordvintsev et al. (2020) Mordvintsev A, Randazzo E, Niklasson E and Levin M
    (2020) Growing neural cellular automata. *Distill* [10.23915/distill.00023](https:/doi.org/10.23915/distill.00023).
    URL [https://distill.pub/2020/growing-ca](https://distill.pub/2020/growing-ca).
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ohsawa et al. (2018) Ohsawa S, Akuzawa K, Matsushima T, Bezerra G, Iwasawa Y,
    Kajino H, Takenaka S and Matsuo Y (2018) Neuron as an agent. URL [https://openreview.net/forum?id=BkfEzz-0-](https://openreview.net/forum?id=BkfEzz-0-).
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OroojlooyJadid and Hajinezhad (2019) OroojlooyJadid A and Hajinezhad D (2019)
    A review of cooperative multi-agent deep reinforcement learning. *arXiv preprint
    arXiv:1908.03963* .
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ott (2020) Ott J (2020) Giving up control: Neurons as reinforcement learning
    agents. *arXiv preprint arXiv:2003.11642* .'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Palm et al. (2022) Palm RB, Duque MG, Sudhakaran S and Risi S (2022) Variational
    neural cellular automata. In: *International Conference on Learning Representations*.
    URL [https://openreview.net/forum?id=7fFO4cMBx_9](https://openreview.net/forum?id=7fFO4cMBx_9).'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pathak et al. (2019) Pathak D, Lu C, Darrell T, Isola P and Efros AA (2019)
    Learning to control self-assembling morphologies: a study of generalization via
    modularity. *arXiv preprint arXiv:1902.05546* .'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peng et al. (2021) Peng Z, Hui KM, Liu C, Zhou B et al. (2021) Learning to simulate
    self-driven particles system with coordinated policy optimization. *Advances in
    Neural Information Processing Systems* 34.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pickering (2010) Pickering A (2010) *The cybernetic brain*. University of Chicago
    Press.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qin et al. (2018) Qin Y, Feng M, Lu H and Cottrell GW (2018) Hierarchical cellular
    automata for visual saliency. *International Journal of Computer Vision* 126(7):
    751–770.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qu et al. (2020) Qu X, Sun Z, Ong YS, Gupta A and Wei P (2020) Minimalistic
    attacks: How little it takes to fool deep reinforcement learning policies. *IEEE
    Transactions on Cognitive and Developmental Systems* .'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2021) Radford A, Kim JW, Hallacy C, Ramesh A, Goh G, Agarwal
    S, Sastry G, Askell A, Mishkin P, Clark J et al. (2021) Learning transferable
    visual models from natural language supervision. *arXiv preprint arXiv:2103.00020*
    .
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2018) Radford A, Narasimhan K, Salimans T and Sutskever I (2018)
    Improving language understanding by generative pre-training .
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Radford et al. (2019) Radford A, Wu J, Child R, Luan D, Amodei D, Sutskever
    I et al. (2019) Language models are unsupervised multitask learners. *OpenAI blog*
    1(8): 9.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Randazzo et al. (2020) Randazzo E, Mordvintsev A, Niklasson E, Levin M and Greydanus
    S (2020) Self-classifying mnist digits. *Distill* [10.23915/distill.00027.002](https:/doi.org/10.23915/distill.00027.002).
    URL [https://distill.pub/2020/selforg/mnist](https://distill.pub/2020/selforg/mnist).
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Resnick et al. (2018) Resnick C, Eldridge W, Ha D, Britz D, Foerster J, Togelius
    J, Cho K and Bruna J (2018) Pommerman: A multi-agent playground. *arXiv preprint
    arXiv:1809.07124* .'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rubenstein et al. (2014) Rubenstein M, Cornejo A and Nagpal R (2014) Programmable
    self-assembly in a thousand-robot swarm. *Science* 345(6198): 795–799.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rudin et al. (2021) Rudin N, Hoeller D, Reist P and Hutter M (2021) Learning
    to walk in minutes using massively parallel deep reinforcement learning. *arXiv
    preprint arXiv:2109.11978* .
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sanchez-Lengeling et al. (2021) Sanchez-Lengeling B, Reif E, Pearce A and Wiltschko
    AB (2021) A gentle introduction to graph neural networks. *Distill* 6(9): e33.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sandler et al. (2021) Sandler M, Vladymyrov M, Zhmoginov A, Miller N, Madams
    T, Jackson A and Arcas BAY (2021) Meta-learning bidirectional update rules. In:
    *International Conference on Machine Learning*. PMLR, pp. 9288–9300.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sandler et al. (2020) Sandler M, Zhmoginov A, Luo L, Mordvintsev A, Randazzo
    E et al. (2020) Image segmentation via cellular automata. *arXiv preprint arXiv:2008.04965*
    .
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schilling (2000) Schilling MA (2000) Toward a general modular systems theory
    and its application to interfirm product modularity. *Academy of management review*
    25(2): 312–334.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schilling and Steensma (2001) Schilling MA and Steensma HK (2001) The use of
    modular organizational forms: An industry-level analysis. *Academy of management
    journal* 44(6): 1149–1168.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schmidhuber (2014) Schmidhuber J (2014) Who invented backpropagation? *More[DL2]*
    .
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schmidhuber (2020) Schmidhuber J (2020) Metalearning machines learn to learn
    (1987-). URL [https://people.idsia.ch/~juergen/metalearning.html](https://people.idsia.ch/~juergen/metalearning.html).
    [https://people.idsia.ch/~juergen/metalearning.html](https://people.idsia.ch/~juergen/metalearning.html).
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schoenholz and Cubuk (2020) Schoenholz S and Cubuk ED (2020) Jax md: a framework
    for differentiable physics. *Advances in Neural Information Processing Systems*
    33.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schweitzer and Farmer (2003) Schweitzer F and Farmer JD (2003) *Brownian agents
    and active particles: collective dynamics in the natural and social sciences*,
    volume 1. Springer.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seeley (2010) Seeley TD (2010) *Honeybee democracy*. Princeton University Press.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Silver et al. (2016) Silver D, Huang A, Maddison CJ, Guez A, Sifre L, Van Den Driessche
    G, Schrittwieser J, Antonoglou I, Panneershelvam V, Lanctot M et al. (2016) Mastering
    the game of go with deep neural networks and tree search. *nature* 529(7587):
    484–489.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonyan and Zisserman (2014) Simonyan K and Zisserman A (2014) Very deep convolutional
    networks for large-scale image recognition. *arXiv preprint arXiv:1409.1556* .
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stahlberg (2020) Stahlberg F (2020) Neural machine translation: A review. *Journal
    of Artificial Intelligence Research* 69: 343–418.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stoy et al. (2010) Stoy K, Brandt D, Christensen DJ and Brandt D (2010) Self-reconfigurable
    robots: an introduction .'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Suarez et al. (2019) Suarez J, Du Y, Isola P and Mordatch I (2019) Neural mmo:
    A massively multiagent game environment for training and evaluating intelligent
    agents. *arXiv preprint arXiv:1903.00784* .'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Suarez et al. (2021) Suarez J, Du Y, Zhu C, Mordatch I and Isola P (2021) The
    neural mmo platform for massively multiagent research. In: *Thirty-fifth Conference
    on Neural Information Processing Systems Datasets and Benchmarks Track*. URL [https://openreview.net/forum?id=J0d-I8yFtP](https://openreview.net/forum?id=J0d-I8yFtP).'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sudhakaran et al. (2021) Sudhakaran S, Grbic D, Li S, Katona A, Najarro E, Glanois
    C and Risi S (2021) Growing 3d artefacts and functional machines with neural cellular
    automata. *arXiv preprint arXiv:2103.08737* .
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sumpter (2010) Sumpter DJ (2010) *Collective animal behavior*. Princeton University
    Press.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Surowiecki (2005) Surowiecki J (2005) *The wisdom of crowds*. Anchor.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tan et al. (2021) Tan X, Qin T, Soong F and Liu TY (2021) A survey on neural
    speech synthesis. *arXiv preprint arXiv:2106.15561* .
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tang and Ha (2021) Tang Y and Ha D (2021) The sensory neuron as a transformer:
    Permutation-invariant neural networks for reinforcement learning. In: *Thirty-Fifth
    Conference on Neural Information Processing Systems*. URL [https://openreview.net/forum?id=wtLW-Amuds](https://openreview.net/forum?id=wtLW-Amuds).
    [https://attentionneuron.github.io](https://attentionneuron.github.io).'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tang et al. (2020) Tang Y, Nguyen D and Ha D (2020) Neuroevolution of self-interpretable
    agents. In: *Proceedings of the Genetic and Evolutionary Computation Conference*.
    URL [https://attentionagent.github.io](https://attentionagent.github.io).'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tang et al. (2022) Tang Y, Tian Y and Ha D (2022) Evojax: Hardware-accelerated
    neuroevolution. *arXiv preprint arXiv:2202.05008* .'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tapscott and Williams (2008) Tapscott D and Williams AD (2008) *Wikinomics:
    How mass collaboration changes everything*. Penguin.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Terry et al. (2020) Terry JK, Black B, Jayakumar M, Hari A, Sullivan R, Santos
    L, Dieffendahl C, Williams NL, Lokesh Y, Horsch C et al. (2020) Pettingzoo: Gym
    for multi-agent reinforcement learning. *arXiv preprint arXiv:2009.14471* .'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Toner et al. (2005) Toner J, Tu Y and Ramaswamy S (2005) Hydrodynamics and
    phases of flocks. *Annals of Physics* 318(1): 170–244.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vinyals et al. (2019) Vinyals O, Babuschkin I, Czarnecki WM, Mathieu M, Dudzik
    A, Chung J, Choi DH, Powell R, Ewalds T, Georgiev P et al. (2019) Grandmaster
    level in starcraft ii using multi-agent reinforcement learning. *Nature* 575(7782):
    350–354.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2018) Wang T, Liao R, Ba J and Fidler S (2018) Nervenet: Learning
    structured policy with graph neural networks. In: *International Conference on
    Learning Representations*.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2021) Wang Z, She Q and Ward TE (2021) Generative adversarial
    networks in computer vision: A survey and taxonomy. *ACM Computing Surveys (CSUR)*
    54(2): 1–38.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wolfram (2002) Wolfram S (2002) *A new kind of science*, volume 5. Wolfram media
    Champaign, IL.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2020) Wu Z, Pan S, Chen F, Long G, Zhang C and Philip SY (2020)
    A comprehensive survey on graph neural networks. *IEEE transactions on neural
    networks and learning systems* 32(1): 4–24.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2021) Zhang D, Choi C, Kim J and Kim YM (2021) Learning to generate
    3d shapes with generative cellular automata. In: *International Conference on
    Learning Representations*. URL [https://openreview.net/forum?id=rABUmU3ulQh](https://openreview.net/forum?id=rABUmU3ulQh).'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zheng et al. (2018) Zheng L, Yang J, Cai H, Zhou M, Zhang W, Wang J and Yu
    Y (2018) Magent: A many-agent reinforcement learning platform for artificial collective
    intelligence. In: *Proceedings of the AAAI Conference on Artificial Intelligence*,
    volume 32.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
