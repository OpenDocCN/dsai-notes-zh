- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:38:29'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2307.00014] Inertial Navigation Meets Deep Learning: A Survey of Current Trends
    and Future Directions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2307.00014](https://ar5iv.labs.arxiv.org/html/2307.00014)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Inertial Navigation Meets Deep Learning: A Survey of Current Trends and Future
    Directions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nadav Cohen0 and Itzik Klein0 0The Hatter Department of Marine Technologies,
    Charney School of Marine Sciences,
  prefs: []
  type: TYPE_NORMAL
- en: University of Haifa, Haifa, Israel
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Inertial sensing is used in many applications and platforms, ranging from day-to-day
    devices such as smartphones to very complex ones such as autonomous vehicles.
    In recent years, the development of machine learning and deep learning techniques
    has increased significantly in the field of inertial sensing. This is due to the
    development of efficient computing hardware and the accessibility of publicly
    available sensor data. These data-driven approaches are used to empower model-based
    navigation and sensor fusion algorithms. This paper provides an in-depth review
    of those deep learning methods. We examine separately, each vehicle operation
    domain including land, air, and sea. Each domain is divided into pure inertial
    advances and improvements based on filter parameters learning. In addition, we
    review deep learning approaches for calibrating and denoising inertial sensors.
    Throughout the paper, we discuss these trends and future directions. We also provide
    statistics on the commonly used approaches to illustrate their efficiency and
    stimulate further research in deep learning embedded in inertial navigation and
    fusion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Inertial sensing, Navigation, Deep learning, Data-driven, Sensor fusion, Autonomous
    platforms, Robotics.
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Research on the concepts of inertial sensing has been conducted for several
    decades and has been used in the navigation process for a variety of platforms
    during the last century [[1](#bib.bib1)]. As of today, most inertial sensing relies
    on accelerometers, which provide specific force measurements, as well as gyroscopes,
    which provide angular velocity measurements [[2](#bib.bib2)]. An inertial measurement
    unit (IMU) is a unit composed of three orthonormal accelerometers and three orthonormal
    gyroscopes that differ in performance and cost [[3](#bib.bib3), [4](#bib.bib4)].
  prefs: []
  type: TYPE_NORMAL
- en: 'The IMU readings are processed in real-time to provide a navigation solution.
    Such a system, which executes the strapdown inertial navigation algorithm, is
    known as an inertial navigation system (INS) [[5](#bib.bib5)]. The INS provides
    the navigation solution consisting of position, velocity, and orientation as illustrated
    in Fig.[1(a)](#S1.F1.sf1 "In Figure 1 ‣ I Introduction ‣ Inertial Navigation Meets
    Deep Learning: A Survey of Current Trends and Future Directions").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a1712a58ec757c3b8c9ef7c85d4b8876.png)'
  prefs: []
  type: TYPE_IMG
- en: (a)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/482ed68a30b9ff44d43cda2fd9e91501.png)'
  prefs: []
  type: TYPE_IMG
- en: (b)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1: (a) Strapdown inertial navigation algorithm. For a given initial
    condition, the gyroscope’s angular velocity and the accelerometer’s specific force
    measurements are integrated over time to receive the navigation solution in the
    desired reference frame (local, geographic, and so on). (b) The process by which
    the navigation solution can be corrected using a nonlinear filter and an aiding
    sensor. By looking at the output, the black diverging curve shows how the navigation
    solution accumulates error and the red curve illustrates how the aiding sensor
    corrects this error, resulting in a chainsaw-like signal.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to note that the navigation solution accuracy and efficiency
    is affected by the duration of the mission, the platform dynamics, as well as
    the quality of the IMU. Using high-end sensors results in a more accurate navigation
    solution for extended periods of time, while using low-cost INS results in a much
    faster accumulation of errors. There is, however, a common approach for dealing
    with error accumulation in both cases, which is to use an accurate aiding sensor
    to ensure that the solution is bounded or the error is mitigated [[6](#bib.bib6)].
    Sensors such as the global navigation satellite system (GNSS) that accurately
    measures position, or the Doppler velocity log (DVL) that gives accurate velocity
    measurements, are examples of aiding sensors. Further, it is possible to use additional
    information instead of or in addition to a physical sensor, such as zero velocity
    updates (ZUPT), zero angular rates (ZAR), and more in specific applications and
    scenarios, all to prevent the inertial navigation solution from accumulating errors
    [[7](#bib.bib7)]. The INS and aiding sensors are commonly fused in nonlinear filters
    such as the extended Kalman filter (EKF) and the uncentered Kalman filter (UKF).
    It is possible for filters of this type to propagate the uncertainty of a model
    while taking into account the process noise covariance, thereby providing additional
    useful information along with preventing the accumulation of errors within an
    inertial navigation algorithm [[8](#bib.bib8)]. A diagram of the sensor fusion
    is shown in Fig. [1(b)](#S1.F1.sf2 "In Figure 1 ‣ I Introduction ‣ Inertial Navigation
    Meets Deep Learning: A Survey of Current Trends and Future Directions").'
  prefs: []
  type: TYPE_NORMAL
- en: During the past decade, deep learning has made remarkable progress due to advances
    in neural network architectures, large datasets, and innovative training methods.
    In the field of computer vision, convolutional neural networks (CNNs) have revolutionized
    tasks such as image classification, object detection, and semantic segmentation
    [[9](#bib.bib9)]. It has been demonstrated that recurrent neural networks (RNNs),
    including long short-term memory (LSTM) networks, are particularly effective at
    modeling sequences and undertaking language-related tasks, such as translation
    and sentiment analysis when used for natural language processing [[10](#bib.bib10)].
    Moreover, techniques such as generative adversarial networks (GANs) and transfer
    learning have extended the capabilities of deep learning models to enable tasks
    such as image synthesis and the use of pre-trained models [[11](#bib.bib11), [12](#bib.bib12)].
    In light of these advancements, deep learning has been significantly enhanced,
    propelling it to new frontiers in the field of artificial intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: The recent advances in hardware and computational efficiency have proven deep
    learning (DL) methods to be useful for dealing with real-time applications ranging
    from image processing and signal processing to natural language processing by
    utilizing its capabilities to address nonlinear problems [[13](#bib.bib13), [14](#bib.bib14),
    [15](#bib.bib15), [16](#bib.bib16)]. As a result, DL methods began to be integrated
    into inertial navigation algorithms. One of the first papers to use neural networks
    (NNs) in inertial navigation was written by Chiang *et al.* [[17](#bib.bib17)]
    in 2003\. A multi-sensor integration was proposed using multi-layer, feed-forward
    neural networks and a back-propagation learning algorithm to regress the accurate
    land vehicle position. It demonstrated the effectiveness of the NN in addressing
    navigation problems.
  prefs: []
  type: TYPE_NORMAL
- en: Inspired by success and impact, papers were published suggesting the use of
    deeper neural networks. Noureldin *et al.* [[18](#bib.bib18)] designed a multi-layer
    perceptron (MLP) network to predict the INS position error during GNSS outages
    using the INS position component and instantaneous time $t$. This work was continued
    and modified in [[19](#bib.bib19)], where the authors replaced the MLP network
    with a radial basis function (RBF) neural network to address the same scenario
    and were successful in reducing the position error. In [[20](#bib.bib20)], further
    improvements were described, utilizing a multi-layer feed-forward neural networks
    to regress not only the vehicle’s position but also its velocity, in an INS/DGNSS
    integration by employing a low-cost IMU. Further research concerning GNSS outage
    and INS/GNSS fusion is available in [[21](#bib.bib21)] using input-delayed neural
    networks that regress velocity and position utilizing fully connected layers.
    Additionally, in [[22](#bib.bib22)], the development of fully connected neural
    networks with hidden layers constructed of wavelet base functions was proposed
    to develop INS/GNSS integration to eliminate the complexities associated with
    KF by providing a reliable positioning solution when GNSS signals are not available.
    In addition to position regression, Chiang *et al.* in [[23](#bib.bib23), [24](#bib.bib24),
    [25](#bib.bib25)] introduced NNs based on fully connected layers for the enhancement
    of orientation measurements provided by INS/GNSS fusions when using low-cost MEMS
    IMUs or when GNSS signals are not available. Another concept is to improve a specific
    block within the KF, and a suggestion in [[26](#bib.bib26)] was to provide the
    innovation process in an adaptive KF for an integrated INS/GNSS system using a
    three-layer, fully connected network.
  prefs: []
  type: TYPE_NORMAL
- en: These researchers were among the pioneers in using inertial data in DNNs to
    improve navigation. Performance analysis for the networks above was conducted
    in [[27](#bib.bib27)] for INS/GNSS fusion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Aside from this paper, there are several other papers that conducted surveys
    on the general topic of data-driven navigation. Most of them looked at specific
    platforms or DL methods. In [[28](#bib.bib28), [29](#bib.bib29)], a review of
    the navigation of spacecraft was made in addition to other concepts such as dynamics
    and control. Furthermore, approaches of only deep-reinforcement learning were
    reviewed for different platforms in [[30](#bib.bib30), [31](#bib.bib31), [32](#bib.bib32)].
    In light of DL’s significant advances in the fields of image processing and computer
    vision, vision-based navigation surveys were conducted for different platforms
    and in general [[33](#bib.bib33), [34](#bib.bib34), [35](#bib.bib35), [36](#bib.bib36),
    [37](#bib.bib37)]. Some papers focused only on machine-learning-based navigation,
    which is based primarily on determining the features through preprocessing data
    analysis [[38](#bib.bib38), [39](#bib.bib39), [40](#bib.bib40)]. In [[41](#bib.bib41)]
    there is a discussion of end-to-end DL methods employed in autonomous navigation,
    including subjects other than navigation such as obstacle detection, scene perception,
    path planning, and control. A survey was conducted in [[42](#bib.bib42)] to examine
    inertial positioning using recent DL methods. It targeted tasks such as pedestrian
    dead-reckoning and human activity recognition. An overview of all the survey papers
    is in Table [I](#S1.T1 "TABLE I ‣ I Introduction ‣ Inertial Navigation Meets Deep
    Learning: A Survey of Current Trends and Future Directions").'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE I: An overview of survey papers reviewing DL methods used in different
    aspects of navigation. A total of fifteen papers.'
  prefs: []
  type: TYPE_NORMAL
- en: Paper Topic [28](#bib.bib28) DL methods for spacecraft dynamics, navigation
    and control [29](#bib.bib29) DL methods of relative navigation of a spacecraft
    [30](#bib.bib30), [31](#bib.bib31) DRL for mobile robot navigation [32](#bib.bib32)
    UAV autonomous navigation using RL [33](#bib.bib33) DL methods for visual indoor
    navigation [34](#bib.bib34), [36](#bib.bib36) Visual navigation using RL [35](#bib.bib35)
    DL methods of perception and navigation in unstructured environments [37](#bib.bib37)
    DL for perception and navigation in autonomous systems [38](#bib.bib38) Machine
    learning for maritime vehicle navigation [39](#bib.bib39) Survey of inertial sensing
    and machine learning [40](#bib.bib40) Machine learning for indoor navigation [41](#bib.bib41)
    DL applications and methods for autonomous vehicles [42](#bib.bib42) DL methods
    for positioning including pedestrian dead-reckoning and human activity recognition
  prefs: []
  type: TYPE_NORMAL
- en: 'Contrary to all of the above, this paper examines DL methods utilized exclusively
    in inertial navigation algorithms, as defined in the literature, and focuses entirely
    on vehicles regardless of their operating environment. The contributions of this
    paper are:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide an in-depth review of DL methods applied to inertial navigation tasks
    for land, aerial, and maritime vehicles.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Examine DL methods for calibrating and denoising inertial sensor data suitable
    for any vehicle and any inertial sensor.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide insights into current trends on the subject and describe the common
    DL architectures for inertial navigation tasks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Discussion of potential future directions for the use of DL approaches for improving
    inertial navigation algorithms.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The rest of the paper is organized as follows: Sections [II](#S2 "II Land Vehicle
    Inertial Sensing ‣ Inertial Navigation Meets Deep Learning: A Survey of Current
    Trends and Future Directions"), [III](#S3 "III Aerial Vehicle Inertial Sensing
    ‣ Inertial Navigation Meets Deep Learning: A Survey of Current Trends and Future
    Directions") and [IV](#S4 "IV Maritime Vehicle Inertial Sensing ‣ Inertial Navigation
    Meets Deep Learning: A Survey of Current Trends and Future Directions") address
    DL approaches for improving land, aerial, and maritime inertial sensing, respectively,
    and are further divided into subsections on pure inertial navigation and aided
    inertial navigation. Section [V](#S5 "V Calibration and Denoising ‣ Inertial Navigation
    Meets Deep Learning: A Survey of Current Trends and Future Directions") discusses
    methods of improving the calibration and denoising of inertial data using DL methods.
    Section [VI](#S6 "VI Discussion ‣ Inertial Navigation Meets Deep Learning: A Survey
    of Current Trends and Future Directions") discusses the survey, and Section [VII](#S7
    "VII Conclusions ‣ Inertial Navigation Meets Deep Learning: A Survey of Current
    Trends and Future Directions") draws conclusions.'
  prefs: []
  type: TYPE_NORMAL
- en: II Land Vehicle Inertial Sensing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: II-A Pure Inertial Navigation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Several studies have investigated the inertial deep learning compensations when
    GNSS signals are not available. Shen *et al.* in [[43](#bib.bib43)] presented
    an approach for improving MEMS-INS/GNSS navigation during GNSS outages. This article
    proposed two neural networks for a dual optimization process, wherein the first
    NN compensates for the INS error, while the second NN compensates for the error
    generated by a filter using the RBF network for accurate position data.
  prefs: []
  type: TYPE_NORMAL
- en: Considering the great interest in scenarios of GNSS outages, many papers have
    been published suggesting more complex DNNs. For cases of GNSS outages, Lu *et
    al.* introduced a multi-task learning method in [[44](#bib.bib44)]. In the first
    phase, the inertial data is denoised using a convolutional auto-encoder, followed
    by a temporal convolutional network (TCN) to bridge any GNSS gaps and a one dimensional-CNN
    (1DCNN) to detect zero velocity scenarios. An accurate navigation solution is
    derived from this aiding data later on in the KF. An additional paper proposed
    a CNN model for accurate speed estimation using the inertial data when there are
    no aiding sensors such as GNSS or internal wheel speed [[45](#bib.bib45)].
  prefs: []
  type: TYPE_NORMAL
- en: GNSS signals are not viable in all scenarios, such as indoor navigation or tunnel
    navigation, requiring not only compensation for gaps, but also accounting for
    the entire process. For example, in [[46](#bib.bib46), [47](#bib.bib47)], Tong
    *et al.* regressed the change in velocity and heading of a vehicle in GNSS-blocked
    environments such as tunnels using a TCN architecture with residual blocks used
    from low-cost IMU data given by smartphones. Additionally, ”DeepVIP”, an LSTM-based
    architecture, was introduced for indoor vehicle positioning and trained on low-cost
    inertial data from smartphones. ”DeepVIP” is available in two variations. The
    first achieves a higher level of positioning accuracy and is appropriate for scenarios
    requiring the highest degree of positioning accuracy, and the other is more appropriate
    for situations requiring computational efficiency, therefore its accuracy is slightly
    lower [[48](#bib.bib48)]. The use of data-driven methods in inertial vehicle navigation
    also provides the benefit of improving the output of the inertial sensors independent
    of the other aiding sensors. Zhao *et al.* examined high-end sensors in [[49](#bib.bib49)]
    and proposed ”GyroNet” and ”FoGNet”, which are based on bi-LSTMs. The first estimates
    the bias and noise of a gyroscope to improve angular velocity measurements, while
    the second corrects the drift of the fiber optic gyroscope (FOG) to improve vehicle
    localization. A similar approach was done in [[50](#bib.bib50)] where the authors
    introduced a novel approach to produce IMU-like data from GNSS data to train a
    fully connected-based network to regress angular velocity and acceleration for
    better positioning based on MEMS IMU data. Gao *et al.* [[51](#bib.bib51)] proposed
    the ”VeTorch”, an inertial tracking system that tracks the location of a vehicle
    in real-time using inertial data obtained from a smartphone. For acceleration
    and orientation sequence learning as well as pose estimation, the authors used
    a TCN. As a means of measuring the speed of the vehicle, Freydin & Or employed
    a model based on LSTM, which takes as input low-cost IMU readings provided by
    the smartphone [[52](#bib.bib52)]. Apart from enhancing the inertial reading ability
    to provide a more accurate navigation solution, DL approaches are useful for improving
    sensor fusion. Li *et al.* [[53](#bib.bib53)] introduced a novel, recurrent, convolutional
    neural network (RCNN)-based architecture to scan-to-scan laser/inertial data fusion
    for pose estimation. After studying the extreme dynamics of an autonomous race
    car, [[54](#bib.bib54)] proposed an end-to-end RNN-based approach that utilizes
    IMU data along with the wheel odometry sensor and motor current data to estimate
    velocity. In the ”GALNet” framework, the authors utilized inertial, kinematic,
    and wheel velocity data to train an LSTM-based network that regressed the relative
    pose of a car [[55](#bib.bib55)]. In [[56](#bib.bib56)], a smartphone accelerometer,
    gyroscope, magnetometer, and gravity sensor were integrated to train ”XDRNet”
    architecture. Using 1DCNN, the network regresses vehicle speed and heading changes
    and, as a consequence, reduces inertial positioning error drift. Moreover, Liu
    *et al.* presented a hybrid CNN-LSTM-based network that integrates a dual-antenna
    satellite receiver and MEMS IMU to forecast the residual of the position, velocity,
    and orientation at each time step [[57](#bib.bib57)].
  prefs: []
  type: TYPE_NORMAL
- en: II-B Aided Inertial Navigation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It has been demonstrated that using a filter such as the KF is a common approach
    to achieving a high level of accuracy and reliability in sensor fusion. Aside
    from providing a navigation solution, the filter also provides us with information
    regarding the propagation of navigation uncertainty over time. As a result, DL
    methods were suggested as a way to account for different blocks in the filter
    that tend to have a greater impact on the solution. A deep KF was suggested by
    Hosseinyalamdary [[58](#bib.bib58)]. In addition to the prediction and update
    steps of the EKF, a modeling step was added to the deep KF to correct IMU positioning
    and to model IMU errors. GNSS measurements were used to learn IMU error models
    with RNN and LSTM methods, and in the absence of GNSS observations, the trained
    model predicted the IMU errors. Further, SL-SRCKF (self-learning square-root-cubature
    KF) enables continuous observation vectors during GNSS outages by employing an
    LSTM-based network to learn the relationship between observation vectors and internal
    filter parameters, enhancing the accuracy of integrated MEMS-INS/GNSS navigation
    systems [[59](#bib.bib59)]. Additionally, DL methods identified specific scenarios
    in the inertial data that may prevent the navigation solution from accumulating
    errors. Using RNN, a zero velocity situation or no lateral slip could be identified
    and incorporated later on into a KF for localization processes [[60](#bib.bib60)].
  prefs: []
  type: TYPE_NORMAL
- en: The literature indicates that the covariance noise matrix plays an important
    role in the KF, and therefore DL methods were employed to adapt it consistently.
    According to Brossard, Barrau, & Bonnabel, a CNN-based method was used to dynamically
    adapt the covariance noise matrix for an invariant-EKF using moderate-cost IMU
    measurements [[61](#bib.bib61)]. Previously, the authors developed in [[62](#bib.bib62)]
    a procedure for Gaussian processes combined with RBF neural networks and stochastic
    variational inference in an attempt to improve a state-space dynamical model’s
    propagation and measurement functions by learning residual error between physical
    prediction and ground truth. It was also shown that these corrections may be used
    to design EKFs. An alternative method of estimating the process noise covariance
    relies on reinforcement learning, as explained in [[63](#bib.bib63)], which uses
    an adaptive KF to determine position, velocity, and orientation. In [[64](#bib.bib64)],
    not only the parameters of measurement noise covariances but also the parameters
    of process noise covariances were regressed. These parameters can be more accurately
    estimated using a multitask TCN, resulting in higher position accuracy than traditional
    GNSS/INS-integrated navigation systems. The authors in [[65](#bib.bib65)] introduced
    a residual network incorporating an attention mechanism to predict individual
    velocity elements of the noise covariance matrix. As a result of the empirical
    study, it has been demonstrated that adjusting the non-holonomic constraint uncertainty
    during large dynamic vehicle motions rather than strictly setting the lateral
    and vertical velocities to zero could improve positioning accuracy under large
    dynamic motions.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE II: Papers discussing DL and inertial sensing of land vehicles, categorized
    by their improvement goal. A total of thirty-three papers.'
  prefs: []
  type: TYPE_NORMAL
- en: Improvement Goals Papers Position [17](#bib.bib17), [18](#bib.bib18), [19](#bib.bib19),
    [20](#bib.bib20), [23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25) [21](#bib.bib21),
    [22](#bib.bib22), [27](#bib.bib27), [43](#bib.bib43), [50](#bib.bib50), [51](#bib.bib51),
    [48](#bib.bib48) [57](#bib.bib57) Velocity [20](#bib.bib20), [21](#bib.bib21),
    [49](#bib.bib49), [54](#bib.bib54), [46](#bib.bib46), [47](#bib.bib47), [45](#bib.bib45)
    [56](#bib.bib56), [57](#bib.bib57), [52](#bib.bib52) Orientation [23](#bib.bib23),
    [24](#bib.bib24), [25](#bib.bib25), [49](#bib.bib49), [55](#bib.bib55), [46](#bib.bib46),
    [47](#bib.bib47) [50](#bib.bib50), [51](#bib.bib51), [53](#bib.bib53), [56](#bib.bib56),
    [57](#bib.bib57) Filter Parameters [26](#bib.bib26), [58](#bib.bib58), [43](#bib.bib43),
    [60](#bib.bib60), [62](#bib.bib62), [63](#bib.bib63), [44](#bib.bib44) [64](#bib.bib64),
    [65](#bib.bib65), [59](#bib.bib59)
  prefs: []
  type: TYPE_NORMAL
- en: III Aerial Vehicle Inertial Sensing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: III-A Pure Inertial Navigation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A number of the papers examined visual-inertial odometry as a tool for aerial
    inertial navigation. Clark *et al.* [[66](#bib.bib66)] developed the ”VINet” architecture.
    It comprises LSTM blocks that process camera output at the camera-rate and IMU
    LSTM blocks that process data at the IMU rate. For the first time, this study
    used deep learning to determine a micro air vehicle’s (MAV’s) orientation. In
    [[67](#bib.bib67)], a similar approach was employed; however, the platform was
    not a MAV, but rather an unmanned aerial vehicle (UAV). Another vision-inertial
    fusion study was conducted in [[68](#bib.bib68)] in which a camera and IMU sensor
    fusion method were used to estimate the position of an unmanned aircraft system
    (UAS) using a CNN-LSTM-based network known as ”HVIOnet”, which stands for hybrid
    visual-inertial odometry network. A more complex method was introduced by Yusefi
    *et al.* where an end-to-end, multi-model, DL-based, monocular, visual-inertial
    localization system was utilized to resolve the global pose regression problem
    for UAVs in indoor environments. Using the proposed deep RCNN, experimental findings
    demonstrate an impressive degree of time efficiency, as well as a high degree
    of accuracy in UAV indoor localization [[69](#bib.bib69)].
  prefs: []
  type: TYPE_NORMAL
- en: For assessing a vehicle’s attitude with only inertial sensing, Liu *et al.*
    employed an LSTM-based network based on IMU data from a UAV [[70](#bib.bib70)].
    While in [[71](#bib.bib71)] the authors utilized a hybrid, more complex network
    that incorporates CNN and LSTM blocks to estimate MAV pose utilizing the current
    position and unit quaternion. An inertial odometry network known as ”AbolDeepIO”
    was developed by Esfahani *et al.* [[72](#bib.bib72)]. A deep, inertial, odometry,
    LSTM network architecture based on an IMU reading was proposed and tested on MAV
    data, yielding better results than ”VINet” [[66](#bib.bib66)]. Seven sub-architectures
    (AbolDeepIO1-AbolDeepIO7) were also tested and evaluated. As a follow-up to ”AbolDeepIO”,
    the authors brought forward ”OriNet”, which is also based on LSTM and capable
    of estimating the full 3D orientation of a flying robot with a single particular
    IMU in the quaternion coordinate [[73](#bib.bib73)]. A robust inertial attitude
    estimator called ”RIANN” was also proposed, a network whose name stands for Robust
    IMU-based Attitude Neural Network. Several motions, including MAV motion, were
    regressed using a gated recurrent units (GRUs) network. As well as proposing three
    domain-specific advances in neural networks for inertial attitude estimation,
    they also propose two methods that enable neural networks to handle a wide variety
    of sampling rates [[74](#bib.bib74)]. It has been suggested by Chumuang *et al.*
    [[75](#bib.bib75)] that CNNs and LSTMs are both effective for predicting the orientation
    of a MAV, the former using the quaternions predicted from data from the IMU using
    Madgwick’s adaptive algorithm [[76](#bib.bib76)], and the latter using raw gyroscope
    measurements. For improving MAV navigation, rather than using two separate networks,
    the authors in [[77](#bib.bib77)] suggested three models including CNN, RNN, and
    a CNN and LSTM hybrid model, and performed a comparison amongst them.
  prefs: []
  type: TYPE_NORMAL
- en: In aerial navigation, as in other areas, GNSS signals can be useful when integrating
    with the INS, and in the absence of these signals, difficulties arise. To achieve
    better performance than traditional GNSS/INS fusion, an LSTM-based network was
    proposed in [[78](#bib.bib78)] to estimate the 3D position of an aerial vehicle.
    When the aerial vehicle encounters GNSS-denied environments, DL approaches are
    used to compensate. Continuing their research in [[70](#bib.bib70)], as discussed
    above, Liu *et al.* proposed a 1DCNN/GRU hybrid deep learning model that predicts
    the GNSS position increments for integrated INS/GNSS navigation in the event of
    GNSS outages[[79](#bib.bib79), [80](#bib.bib80), [81](#bib.bib81)]. A similar
    approach to deal with scenarios of denied GNSS environments was implemented by
    [[82](#bib.bib82)], in which a GRU-based network was used to estimate position
    and velocity. A novel method known as ”QuadNet” was proposed by Shurin & Klein
    in [[83](#bib.bib83)] in which they utilized a periodic quadrotor drone motion
    along with its inertial readings to develop a 1DCNN and LSTM method for regression
    of the distance and altitude changes of the quadrotor.
  prefs: []
  type: TYPE_NORMAL
- en: III-B Aided Inertial Navigation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To improve the quality of Kalman attitude estimates, Al-Sharman *et al.* proposed
    a simple, fully connected network in [[84](#bib.bib84)]. The network uses the
    Kalman states estimates, provided by the inertial readings and control vector
    as inputs, and the UAV attitude is regressed. A recurring aspect is predicting
    the noise covariance information using DL. In [[85](#bib.bib85)], the authors
    proposed a CNN-based, adaptive Kalman filter for enhancing high-speed navigation
    with low-cost IMUs. The paper presents a 1DCNN approach to predict noise covariance
    information of 3D acceleration and angular velocity by utilizing windowed inertial
    measurements in an attempt to outperform classical KFs and Sage-Husa adaptive
    filters in high dynamic conditions. In a subsequent paper, Or & Klein [[86](#bib.bib86)]
    developed a data-driven, adaptive noise covariance approach for an error state
    EKF in INS/GNSS fusion. Using a 1DCNN, they were able to estimate the noise covariance
    matrix, also known as the $Q$ matrix, and use the information to provide a better
    navigation solution for a quadrotor drone.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE III: Papers discussing DL and inertial sensing of aerial vehicles, categorized
    by their improvement goal. A total of twenty papers.'
  prefs: []
  type: TYPE_NORMAL
- en: Improvement Goals Papers Position [68](#bib.bib68), [77](#bib.bib77), [78](#bib.bib78),
    [79](#bib.bib79), [80](#bib.bib80), [81](#bib.bib81), [82](#bib.bib82), [83](#bib.bib83)
    Velocity [77](#bib.bib77), [82](#bib.bib82) Orientation [66](#bib.bib66), [67](#bib.bib67),
    [69](#bib.bib69), [70](#bib.bib70), [71](#bib.bib71), [72](#bib.bib72), [73](#bib.bib73)
    [74](#bib.bib74), [75](#bib.bib75), [77](#bib.bib77), [83](#bib.bib83) Filter
    Parameters [84](#bib.bib84), [85](#bib.bib85), [86](#bib.bib86)
  prefs: []
  type: TYPE_NORMAL
- en: IV Maritime Vehicle Inertial Sensing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: IV-A Pure Inertial Navigation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Zhang *et al.* [[87](#bib.bib87), [88](#bib.bib88)] were the first to apply
    deep learning techniques to autonomous underwater vehicle (AUV) navigation. To
    regress the position displacements of an AUV, the authors used an LSTM-based network
    trained over GNSS data that was utilized as the position displacement training
    targets. The output of this network is incorporated into EKF for the purpose of
    making the position directly observable. Later, the authors developed a system
    called ”Navnet”, which utilizes data from the IMU and Doppler velocity log (DVL)
    sensors through a deep learning framework using LSTM and attention mechanisms
    to regress the position displacement of an AUV and compares it to the EKF and
    UKF [[89](#bib.bib89)]. Further improvements and revisions were made in [[90](#bib.bib90)],
    which used TCN blocks instead of LSTM blocks. As a way of rectifying the error
    accumulation in the navigation system, Ma *et al.* proposed a similar procedure,
    as previously mentioned, and developed an adaptive navigation algorithm for AUV
    navigation that uses deep learning to generate low-frequency position information
    as a method of generating low-frequency positioning information. Based on LSTM
    blocks, the network receives velocity measurements from the DVL and Euler angles
    from the attitude and heading reference system (AHRS) [[91](#bib.bib91)].
  prefs: []
  type: TYPE_NORMAL
- en: A task such as navigation on or under water may encounter difficulties due to
    the dynamics of the environment or the inaccessibility of aid signals, such as
    GNSS signals. In [[92](#bib.bib92)] the authors used a hybrid TCN-LSTM network
    to predict the pitch and heave movement of a ship in different challenging scenarios.
    A fully connected network is suggested in [[93](#bib.bib93)] to improve AUV navigation
    in rapidly changing environments, such as in waves near or on the surface. This
    network is based on data from an accelerometer and is used to predict the pitch
    angle. The Kalman filter, neural network, and velocity compensation are then combined
    in the ”NN-DR” method to provide a more accurate navigation solution.
  prefs: []
  type: TYPE_NORMAL
- en: The DVL is used in underwater applications as a sensor to assist in navigation,
    similar to GNSS data used by above-water applications. Several papers have been
    published examining scenarios of DVL failure. There was, for example, a proposal
    in [[94](#bib.bib94)] to aid dead-reckoning navigation for AUVs with limited sensor
    capabilities. Using RNN architecture, the algorithm predicts relative velocities
    based on the data obtained from the IMU, pressure sensors, and control actions
    of the actuators on the AUV. In [[95](#bib.bib95)] the Nonlinear AutoRegressive
    with Exogenous Input (NARX) approach is used in cases where DVL malfunctions occur
    to determine the velocity measurements using INS data. For receiving the navigation
    solution, the output of the network is integrated into a robust Kalman filter
    (RKF). Cohen & Klein proposed ”BeamsNet”, which replaces the model-based approach
    to derive the AUV velocity measurements out of the DVL raw beam measurements using
    1DCNN that uses inertial readings [[96](#bib.bib96)]. The authors continued the
    work by looking at cases of partial DVL measurements and succeeded in recovering
    the velocity with a similar architecture called ”LiBeamsNet” [[97](#bib.bib97)].
    In the case of a complete DVL outage, in [[98](#bib.bib98)] the authors introduced
    ”ST-BeamsNet”, which is a Set-Transformer based network that uses inertial reading
    and past DVL measurements to regress the current velocity.
  prefs: []
  type: TYPE_NORMAL
- en: Lately, Topini *et al.* [[99](#bib.bib99)] conducted an experimental comparison
    of data-driven strategies for AUV navigation in DVL-denied environments where
    they compared MLP, CNN, LSTM, and hybrid CNN-LSTM networks to predict the velocity
    of the AUV.
  prefs: []
  type: TYPE_NORMAL
- en: IV-B Aided Inertial Navigation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: According to the authors of [[100](#bib.bib100)], the RBF network can be augmented
    with error state KF to improve the state estimation of an underwater vehicle.
    Through the application of the RBF neural network, the proposed algorithm compensates
    for the lack of error state KF performance by enhancing innovation error terms.
    Or & Klein [[86](#bib.bib86), [101](#bib.bib101), [102](#bib.bib102)] developed
    an adaptive EKF for velocity updates in INS/DVL fusions. Initially, they demonstrated
    that by correcting the noise covariance matrix using 1DCNN to predict the variance
    in each sample time using a classification problem, they could significantly improve
    navigation results. In recent work, the authors introduced ”ProNet”, which uses
    regression instead of classification to accomplish the same task.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE IV: Papers describing DL and inertial sensing of maritime vehicles, categorized
    by their improvement goal. A total of sixteen papers.'
  prefs: []
  type: TYPE_NORMAL
- en: Improvement Goals Papers Position [87](#bib.bib87), [88](#bib.bib88), [89](#bib.bib89),
    [90](#bib.bib90), [91](#bib.bib91), [92](#bib.bib92), [93](#bib.bib93) Velocity
    [93](#bib.bib93), [94](#bib.bib94), [96](#bib.bib96), [97](#bib.bib97), [98](#bib.bib98),
    [99](#bib.bib99) Orientation [92](#bib.bib92), [93](#bib.bib93) Filter Parameters
    [100](#bib.bib100), [86](#bib.bib86), [101](#bib.bib101), [102](#bib.bib102)
  prefs: []
  type: TYPE_NORMAL
- en: V Calibration and Denoising
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since the INS is based on the integration of inertial data over time, it accumulates
    errors due to structured errors in the sensors. Calibration and denoising are
    crucial to minimizing these errors. In Chen *et al.* [[103](#bib.bib103)], deep
    learning was used for the first time to reduce IMU errors. IMU data, containing
    deterministic and random errors, is fed as input to CNN, which filters the data.
    According to Engelsman & Klein [[104](#bib.bib104), [105](#bib.bib105)], an LSTM-based
    network can be used for de-noising accelerometer signals and a CNN-based network
    can be used to eliminate bias in low-cost gyroscopes.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the papers mentioned above, the majority of research focuses on the
    denoising and calibration of gyroscopes. A series of papers [[106](#bib.bib106),
    [107](#bib.bib107), [108](#bib.bib108)] examined the denoising of gyroscope data
    by utilizing various variations of RNNs. One paper demonstrated the performance
    of a simple RNN structure, while the others utilized LSTMs. A comparison was made
    between LSTM, GRU, and hybrid LSTM-GRU approaches for gyroscope denoising in [[109](#bib.bib109)].
    Additional comparisons between GRU, LSTM, and hybrid GRU-LSTM were conducted.
    However, the performance was tested not only in static conditions but dynamic
    ones too [[110](#bib.bib110)]. In Brossard *et al.* [[111](#bib.bib111)], a deep
    learning method is presented for reducing the gyroscope noise of an IMU gyroscope
    in order to achieve accurate attitude estimations utilizing a low-cost IMU. For
    feature extraction, a dilated convolutional network was used and for training
    on orientation increments, an appropriate loss function was utilized. More different
    kinds of CNN-based architectures addressed the gyroscope corrections. One research
    demonstrated a denoising autoencoder architecture that is built on a deep convolutional
    model and designed to recover clean, undistorted output from corrupted data. It
    was found that the LKF angle prediction was boosted in this scenario [[112](#bib.bib112)].
    Furthermore, a TCN and 1DCNN were integrated for MEMS gyroscope calibration in
    [[113](#bib.bib113)] and Liu *et al.* introduced ”LGC-Net” as a method for extracting
    local and global characteristics from IMU measurements to regress the gyroscope
    compensation components in a dynamic manner. To create the ”LGC-Net”, special
    convolution layers are employed along with attention mechanisms [[114](#bib.bib114)].
    Finally, Yuan et al. introduced ”IMUDB”, which stands for IMU denoising BERT.
    This model was inspired by the natural language processing field. A self-supervised
    IMU denoising method, besides obtaining good results, also addressed the difficulty
    of obtaining sufficient and accurate annotations for supervised learning [[115](#bib.bib115)].
  prefs: []
  type: TYPE_NORMAL
- en: VI Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By analyzing the course of the studies depicted above, this section presents
    an in-depth analysis of current trends in using DL methods for inertial navigation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Taking a closer look at the most common courses of action, it appears there
    are four repeating baseline approaches, as illustrated in Fig. [2](#S6.F2 "Figure
    2 ‣ VI Discussion ‣ Inertial Navigation Meets Deep Learning: A Survey of Current
    Trends and Future Directions"). The first approach involves inserting the inertial
    data into a DL architecture and regressing one or more aspects of the full navigation
    solution as shown in Fig. [2(a)](#S6.F2.sf1 "In Figure 2 ‣ VI Discussion ‣ Inertial
    Navigation Meets Deep Learning: A Survey of Current Trends and Future Directions").
    Other papers, however, examined the desired residual/delta that needs to be added
    to the current measurements to update the data rather than regress the full state
    of navigation components. Looking at the residual was demonstrated to result in
    a normally distributed output, which would make it easier for the network to handle
    the problem. An illustration is shown in Fig. [2(b)](#S6.F2.sf2 "In Figure 2 ‣
    VI Discussion ‣ Inertial Navigation Meets Deep Learning: A Survey of Current Trends
    and Future Directions").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rather than relying solely on inertial data, and as discussed before, most
    navigation solutions integrate inertial data with other sensors to provide a more
    accurate result. Fig. [2(c)](#S6.F2.sf3 "In Figure 2 ‣ VI Discussion ‣ Inertial
    Navigation Meets Deep Learning: A Survey of Current Trends and Future Directions")
    and Fig. [2(d)](#S6.F2.sf4 "In Figure 2 ‣ VI Discussion ‣ Inertial Navigation
    Meets Deep Learning: A Survey of Current Trends and Future Directions") show how
    DL is incorporated in the sensor fusion operation. The former uses both the inertial
    data and the aiding measurements as input to the network to give the navigation
    solution. The latter target parameters of the nonlinear filter, which is responsible
    for the sensor fusion, such as the noise covariance matrix estimation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The methods listed above are applicable to all three domains: land, aerial,
    and maritime.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3b61e5dce4d26144024fb76bf4f2314e.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Using DL to regress the full state of the vehicle.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/55e1e438382dda1217560d8fd05ab5b1.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Using DL to regress the residual between the current
  prefs: []
  type: TYPE_NORMAL
- en: state and the previous one of the vehicle.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/926bd7000e990432d22a160946ebbda1.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Implementing sensor fusing with a DL block to regress
  prefs: []
  type: TYPE_NORMAL
- en: the full state or the required increment.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4bde9ae1518b0bc17335888f690ad806.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) In sensor fusion scenarios, DL methods are applied
  prefs: []
  type: TYPE_NORMAL
- en: to obtain one or more filter parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2: Different techniques for improving inertial navigation using DL'
  prefs: []
  type: TYPE_NORMAL
- en: 'By examining the details of the survey, we determined what are the most common
    goals that current research focuses on improving, and presented them in a pie
    chart, see Fig. [3](#S6.F3 "Figure 3 ‣ VI Discussion ‣ Inertial Navigation Meets
    Deep Learning: A Survey of Current Trends and Future Directions"). According to
    the chart, 81% of the papers focus on improving position, velocity, and orientation,
    while 19% addressed filter parameter improvement. Most of the latter papers were
    published within the past three years.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/68f695aa3282ef2ee25c273d0f45ab8a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: DL goals in improving the navigation performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the initial analysis, we carried out a study of the general
    DL architectures that have been employed. We identified four distinct architectural
    streams: MLP, CNN, RNN, and others. MLP includes all fully connected networks,
    CNN includes networks such as 1DCNN and TCN, RNN includes LSTM and GRU, and ”others”
    consists of transformers, reinforcement learning, and so on. As shown in Fig.
    [4](#S6.F4 "Figure 4 ‣ VI Discussion ‣ Inertial Navigation Meets Deep Learning:
    A Survey of Current Trends and Future Directions"), the networks are also divided
    into single and combined networks, where combined refers to architectures that
    comprise more than one method, such as CNN-RNN. The bar plot indicates that the
    main architecture is RNN with its derivatives, which makes sense since this architecture
    was specifically designed for time-series problems. However, CNN methods also
    have a significant impact on inertial navigation, and in some cases are more accurate
    than RNNs. MLP is more basic architecture and was among the first to be incorporated
    into inertial navigation. As a result of improvements in the field of natural
    language processing, other architectures such as transformers and BERT have started
    to appear in recent papers, demonstrating a great deal of promise.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e849a740fca595a017511a813949be45.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Common DL architectures for improving navigation tasks, divided into
    single architectures and combined architectures.'
  prefs: []
  type: TYPE_NORMAL
- en: VII Conclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since inertial sensors can operate on any platform regardless of the environment,
    inertial navigation has been a major topic of study in the past decade. As data-driven
    methods became increasingly popular, DL methods were integrated into this field,
    which relied on model-based algorithms. This paper presents a survey of DL methods
    applied to inertial navigation. The paper reviews research conducted in three
    different domains — land, air, and sea— as well as calibration and denoising methods.
    It also provides an insight into the course of the study based on statistical
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the research was conducted on land vehicles rather than aerial or maritime
    vehicles or even calibration and denoising techniques. However, some papers mention
    that despite the different mechanics, maneuvers, etc., the techniques can be adaptable
    to different platforms. Most of the reviewed papers dealt with improving one or
    more aspects of the inertial navigation algorithm for a better solution. However,
    in recent years, a focus has been placed on improving filter parameters for an
    enhanced sensor fusion process. Although the leading DL architectures are based
    on RNNs and CNNs, it appears that recent research is inspired by natural language
    processing approaches as it imports and adapts its leading architectures.
  prefs: []
  type: TYPE_NORMAL
- en: To conclude, since 2018 there has been a significant increase in using DL methods
    with applications of inertial navigation. It has been found that these approaches
    outperformed the known model-based techniques and have shown great promise for
    future research in the area of inertial sensing. The initial research focused
    on improving the navigation aspects defined in the literature; namely, position,
    velocity, and orientation. In recent years, more attention has been paid to improving
    filter parameters utilizing more advanced networks.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: N.C. is supported by the Maurice Hatter Foundation and University of Haifa presidential
    scholarship for students on a direct Ph.D. track.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] D. MacKenzie, *Inventing accuracy: A historical sociology of nuclear missile
    guidance*.   MIT press, 1993.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] D. Titterton, J. L. Weston, and J. Weston, *Strapdown inertial navigation
    technology*.   IET, 2004, vol. 17.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] A. Noureldin, T. B. Karamat, and J. Georgy, *Fundamentals of inertial navigation,
    satellite-based positioning and their integration*.   Springer Science & Business
    Media, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] N. El-Sheimy and A. Youssef, “Inertial sensors technologies for navigation
    applications: State of the art and future trends,” *Satellite Navigation*, vol. 1,
    no. 1, pp. 1–21, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] K. R. Britting, *Inertial navigation systems analysis*.   Artech House,
    2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] J. Farrell, *Aided navigation: GPS with high rate sensors*.   McGraw-Hill,
    Inc., 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] D. Engelsman and I. Klein, “Information aided navigation: A review,” *arXiv
    preprint arXiv:2301.01114*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] P. Groves, *Principles of GNSS, inertial, and multisensor integrated navigation
    systems, second edition*.   Artech house, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] S. S. A. Zaidi, M. S. Ansari, A. Aslam, N. Kanwal, M. Asghar, and B. Lee,
    “A survey of modern deep learning based object detection models,” *Digital Signal
    Processing*, p. 103514, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] D. W. Otter, J. R. Medina, and J. K. Kalita, “A survey of the usages of
    deep learning for natural language processing,” *IEEE transactions on neural networks
    and learning systems*, vol. 32, no. 2, pp. 604–624, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] M. Durgadevi *et al.*, “Generative adversarial network (GAN): a general
    review on different variants of GAN and applications,” in *2021 6th International
    Conference on Communication and Electronics Systems (ICCES)*.   IEEE, 2021, pp.
    1–8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] F. Zhuang, Z. Qi, K. Duan, D. Xi, Y. Zhu, H. Zhu, H. Xiong, and Q. He,
    “A comprehensive survey on transfer learning,” *Proceedings of the IEEE*, vol.
    109, no. 1, pp. 43–76, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” *nature*, vol. 521,
    no. 7553, pp. 436–444, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] I. Goodfellow, Y. Bengio, and A. Courville, *Deep learning*.   MIT press,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] P. P. Shinde and S. Shah, “A review of machine learning and deep learning
    applications,” in *2018 Fourth international conference on computing communication
    control and automation (ICCUBEA)*.   IEEE, 2018, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] M. Mahrishi, K. K. Hiran, G. Meena, and P. Sharma, *Machine learning and
    deep learning in real-time applications*.   IGI global, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] K.-W. Chiang, A. Noureldin, and N. El-Sheimy, “Multisensor integration
    using neuron computing for land-vehicle navigation,” *GPS solutions*, vol. 6,
    no. 4, pp. 209–218, 2003.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] A. Noureldin, A. Osman, and N. El-Sheimy, “A neuro-wavelet method for
    multi-sensor system integration for vehicular navigation,” *Measurement science
    and technology*, vol. 15, no. 2, p. 404, 2003.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] R. Sharaf, A. Noureldin, A. Osman, and N. El-Sheimy, “Online INS/GPS integration
    with a radial basis function neural network,” *IEEE Aerospace and Electronic Systems
    Magazine*, vol. 20, no. 3, pp. 8–14, 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] N. El-Sheimy, K.-W. Chiang, and A. Noureldin, “The utilization of artificial
    neural networks for multisensor system integration in navigation and positioning
    instruments,” *IEEE Transactions on instrumentation and measurement*, vol. 55,
    no. 5, pp. 1606–1615, 2006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] A. Noureldin, A. El-Shafie, and M. Bayoumi, “GPS/INS integration utilizing
    dynamic neural networks for vehicular navigation,” *Information fusion*, vol. 12,
    no. 1, pp. 48–57, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] X. Chen, C. Shen, W.-b. Zhang, M. Tomizuka, Y. Xu, and K. Chiu, “Novel
    hybrid of strong tracking Kalman filter and wavelet neural network for GPS/INS
    during GPS outages,” *Measurement*, vol. 46, no. 10, pp. 3847–3854, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] K.-W. Chiang, A. Noureldin, and N. El-Sheimy, “Constructive neural-networks-based
    MEMS/GPS integration scheme,” *IEEE transactions on aerospace and electronic systems*,
    vol. 44, no. 2, pp. 582–594, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] K.-W. Chiang, H.-W. Chang, C.-Y. Li, and Y.-W. Huang, “An artificial neural
    network embedded position and orientation determination algorithm for low cost
    MEMS INS/GPS integrated sensors,” *Sensors*, vol. 9, no. 4, pp. 2586–2610, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] K.-W. Chiang and H.-W. Chang, “Intelligent sensor positioning and orientation
    through constructive neural network-embedded INS/GPS integration algorithms,”
    *Sensors*, vol. 10, no. 10, pp. 9252–9285, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] J. J. Wang, W. Ding, and J. Wang, “Improving adaptive Kalman Filter in
    GPS/SDINS integration with neural network,” in *Proceedings of the 20th International
    Technical Meeting of the Satellite Division of The Institute of Navigation (ION
    GNSS 2007)*, 2007, pp. 571–578.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] M. Malleswaran, V. Vaidehi, A. Saravanaselvan, and M. Mohankumar, “Performance
    analysis of various artificial intelligent neural networks for GPS/INS integration,”
    *Applied Artificial Intelligence*, vol. 27, no. 5, pp. 367–407, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] S. Silvestrini and M. Lavagna, “Deep learning and artificial neural networks
    for spacecraft dynamics, navigation and control,” *Drones*, vol. 6, no. 10, p.
    270, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] J. Song, D. Rondao, and N. Aouf, “Deep learning-based spacecraft relative
    navigation methods: A survey,” *Acta Astronautica*, vol. 191, pp. 22–40, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] H. Jiang, H. Wang, W.-Y. Yau, and K.-W. Wan, “A brief survey: Deep reinforcement
    learning in mobile robot navigation,” in *2020 15th IEEE Conference on Industrial
    Electronics and Applications (ICIEA)*.   IEEE, 2020, pp. 592–597.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] K. Zhu and T. Zhang, “Deep reinforcement learning based mobile robot navigation:
    A review,” *Tsinghua Science and Technology*, vol. 26, no. 5, pp. 674–691, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] F. AlMahamid and K. Grolinger, “Autonomous unmanned aerial vehicle navigation
    using reinforcement learning: A systematic review,” *Engineering Applications
    of Artificial Intelligence*, vol. 115, p. 105321, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] X. Ye and Y. Yang, “From seeing to moving: A survey on learning for visual
    indoor navigation (VIN),” *arXiv preprint arXiv:2002.11310*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] F. Zeng, C. Wang, and S. S. Ge, “A survey on visual navigation for artificial
    agents with deep reinforcement learning,” *IEEE Access*, vol. 8, pp. 135 426–135 442,
    2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] D. C. Guastella and G. Muscato, “Learning-based methods of perception
    and navigation for ground vehicles in unstructured environments: A review,” *Sensors*,
    vol. 21, no. 1, p. 73, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] F. Zhu, Y. Zhu, V. Lee, X. Liang, and X. Chang, “Deep learning for embodied
    vision navigation: A survey,” *arXiv preprint arXiv:2108.04097*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] Y. Tang, C. Zhao, J. Wang, C. Zhang, Q. Sun, W. X. Zheng, W. Du, F. Qian,
    and J. Kurths, “Perception and navigation in autonomous systems in the era of
    learning: A survey,” *IEEE Transactions on Neural Networks and Learning Systems*,
    2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] S. Azimi, J. Salokannel, S. Lafond, J. Lilius, M. Salokorpi, and I. Porres,
    “A survey of machine learning approaches for surface maritime navigation,” in
    *Maritime Transport VIII: proceedings of the 8th International Conference on Maritime
    Transport: Technology, Innovation and Research: Maritime Transport’20*.   Barcelona,
    2020, pp. 103–117.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] Y. Li, R. Chen, X. Niu, Y. Zhuang, Z. Gao, X. Hu, and N. El-Sheimy, “Inertial
    sensing meets machine learning: opportunity or challenge?” *IEEE Transactions
    on Intelligent Transportation Systems*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] P. Roy and C. Chowdhury, “A survey of machine learning techniques for
    indoor localization and navigation systems,” *Journal of Intelligent & Robotic
    Systems*, vol. 101, no. 3, p. 63, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] A. A. Golroudbari and M. H. Sabour, “Recent advancements in deep learning
    applications and methods for autonomous navigation–A comprehensive review,” *arXiv
    preprint arXiv:2302.11089*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] C. Chen, “Deep learning for inertial positioning: A survey,” *arXiv preprint
    arXiv:2303.03757*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] C. Shen, Y. Zhang, J. Tang, H. Cao, and J. Liu, “Dual-optimization for
    a MEMS-INS/GPS system during GPS outages based on the cubature Kalman filter and
    neural networks,” *Mechanical Systems and Signal Processing*, vol. 133, p. 106222,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] S. Lu, Y. Gong, H. Luo, F. Zhao, Z. Li, and J. Jiang, “Heterogeneous multi-task
    learning for multiple pseudo-measurement estimation to bridge GPS outages,” *IEEE
    Transactions on Instrumentation and Measurement*, vol. 70, pp. 1–16, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] R. Karlsson and G. Hendeby, “Speed estimation from vibrations using a
    deep learning CNN approach,” *IEEE Sensors Letters*, vol. 5, no. 3, pp. 1–4, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] Y. Tong, S. Zhu, Q. Zhong, R. Gao, C. Li, and L. Liu, “Smartphone-based
    vehicle tracking without GPS: Experience and improvements,” in *2021 IEEE 27th
    International Conference on Parallel and Distributed Systems (ICPADS)*.   IEEE,
    2021, pp. 209–216.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] Y. Tong, S. Zhu, X. Ren, Q. Zhong, D. Tao, C. Li, L. Liu, and R. Gao,
    “Vehicle inertial tracking via mobile crowdsensing: Experience and enhancement,”
    *IEEE Transactions on Instrumentation and Measurement*, vol. 71, pp. 1–13, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] B. Zhou, Z. Gu, F. Gu, P. Wu, C. Yang, X. Liu, L. Li, Y. Li, and Q. Li,
    “DeepVIP: Deep learning-based vehicle indoor positioning using smartphones,” *IEEE
    Transactions on Vehicular Technology*, vol. 71, no. 12, pp. 13 299–13 309, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] X. Zhao, C. Deng, X. Kong, J. Xu, and Y. Liu, “Learning to compensate
    for the drift and error of gyroscope in vehicle localization,” in *2020 IEEE Intelligent
    Vehicles Symposium (IV)*.   IEEE, 2020, pp. 852–857.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] Z. Fei, S. Jia, and Q. Li, “Research on GNSS/DR method based on B-spline
    and optimized BP neural network,” in *2021 IEEE 33rd International Conference
    on Tools with Artificial Intelligence (ICTAI)*.   IEEE, 2021, pp. 161–168.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] R. Gao, X. Xiao, S. Zhu, W. Xing, C. Li, L. Liu, L. Ma, and H. Chai, “Glow
    in the dark: Smartphone inertial odometry for vehicle tracking in GPS blocked
    environments,” *IEEE Internet of Things Journal*, vol. 8, no. 16, pp. 12 955–12 967,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] M. Freydin and B. Or, “Learning car speed using inertial sensors for dead
    reckoning navigation,” *IEEE Sensors Letters*, vol. 6, no. 9, pp. 1–4, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] C. Li, S. Wang, Y. Zhuang, and F. Yan, “Deep sensor fusion between 2D
    laser scanner and IMU for mobile robot localization,” *IEEE Sensors Journal*,
    vol. 21, no. 6, pp. 8501–8509, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] S. Srinivasan, I. Sa, A. Zyner, V. Reijgwart, M. I. Valls, and R. Siegwart,
    “End-to-end velocity estimation for autonomous racing,” *IEEE Robotics and Automation
    Letters*, vol. 5, no. 4, pp. 6869–6875, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] R. C. Mendoza, B. Cao, D. Goehring, and R. Rojas, “GALNet: An end-to-end
    deep neural network for ground localization of autonomous cars.” in *ROBOVIS*,
    2020, pp. 39–50.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] B. Zhou, P. Wu, Z. Gu, Z. Wu, and C. Yang, “XDRNet: Deep learning-based
    pedestrian and vehicle dead reckoning using smartphones,” in *2022 IEEE 12th International
    Conference on Indoor Positioning and Indoor Navigation (IPIN)*.   IEEE, 2022,
    pp. 1–8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] N. Liu, Z. Hui, Z. Su, L. Qiao, and Y. Dong, “Integrated navigation on
    vehicle based on low-cost SINS/GNSS using deep learning,” *Wireless Personal Communications*,
    vol. 126, no. 3, pp. 2043–2064, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] S. Hosseinyalamdary, “Deep Kalman filter: Simultaneous multi-sensor integration
    and modelling; A GNSS/IMU case study,” *Sensors*, vol. 18, no. 5, p. 1316, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] C. Shen, Y. Zhang, X. Guo, X. Chen, H. Cao, J. Tang, J. Li, and J. Liu,
    “Seamless GPS/inertial navigation system based on self-learning square-root cubature
    Kalman filter,” *IEEE Transactions on Industrial Electronics*, vol. 68, no. 1,
    pp. 499–508, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] M. Brossard, A. Barrau, and S. Bonnabel, “RINS-W: Robust inertial navigation
    system on wheels,” in *2019 IEEE/RSJ International Conference on Intelligent Robots
    and Systems (IROS)*.   IEEE, 2019, pp. 2068–2075.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] ——, “AI-IMU dead-reckoning,” *IEEE Transactions on Intelligent Vehicles*,
    vol. 5, no. 4, pp. 585–595, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] M. Brossard and S. Bonnabel, “Learning wheel odometry and IMU errors for
    localization,” in *2019 International Conference on Robotics and Automation (ICRA)*.   IEEE,
    2019, pp. 291–297.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] X. Gao, H. Luo, B. Ning, F. Zhao, L. Bao, Y. Gong, Y. Xiao, and J. Jiang,
    “RL-AKF: An adaptive Kalman filter navigation algorithm based on reinforcement
    learning for ground vehicles,” *Remote Sensing*, vol. 12, no. 11, p. 1704, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] F. Wu, H. Luo, H. Jia, F. Zhao, Y. Xiao, and X. Gao, “Predicting the noise
    covariance with a multitask learning model for Kalman filter-based GNSS/INS integrated
    navigation,” *IEEE Transactions on Instrumentation and Measurement*, vol. 70,
    pp. 1–13, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] Y. Xiao, H. Luo, F. Zhao, F. Wu, X. Gao, Q. Wang, and L. Cui, “Residual
    attention network-based confidence estimation algorithm for non-holonomic constraint
    in GNSS/INS integrated navigation system,” *IEEE Transactions on Vehicular Technology*,
    vol. 70, no. 11, pp. 11 404–11 418, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] R. Clark, S. Wang, H. Wen, A. Markham, and N. Trigoni, “Vinet: Visual-inertial
    odometry as a sequence-to-sequence learning problem,” in *Proceedings of the AAAI
    Conference on Artificial Intelligence*, vol. 31, no. 1, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] F. Baldini, A. Anandkumar, and R. M. Murray, “Learning pose estimation
    for UAV autonomous navigation and landing using visual-inertial sensor data,”
    in *2020 American Control Conference (ACC)*.   IEEE, 2020, pp. 2961–2966.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] M. F. Aslan, A. Durdu, A. Yusefi, and A. Yilmaz, “HVIOnet: A deep learning
    based hybrid visual–inertial odometry approach for unmanned aerial system position
    estimation,” *Neural Networks*, vol. 155, pp. 461–474, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] A. Yusefi, A. Durdu, M. F. Aslan, and C. Sungur, “LSTM and filter based
    comparison analysis for indoor global localization in UAVs,” *IEEE Access*, vol. 9,
    pp. 10 054–10 069, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] Y. Liu, Y. Zhou, and X. Li, “Attitude estimation of unmanned aerial vehicle
    based on LSTM neural network,” in *2018 international joint conference on neural
    networks (IJCNN)*.   IEEE, 2018, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] J. P. Silva do Monte Lima, H. Uchiyama, and R.-i. Taniguchi, “End-to-end
    learning framework for IMU-based 6-DOF odometry,” *Sensors*, vol. 19, no. 17,
    p. 3777, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] M. A. Esfahani, H. Wang, K. Wu, and S. Yuan, “AbolDeepIO: A novel deep
    inertial odometry network for autonomous vehicles,” *IEEE Transactions on Intelligent
    Transportation Systems*, vol. 21, no. 5, pp. 1941–1950, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] ——, “OriNet: Robust 3-D orientation estimation with a single particular
    IMU,” *IEEE Robotics and Automation Letters*, vol. 5, no. 2, pp. 399–406, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] D. Weber, C. Gühmann, and T. Seel, “RIANN—A robust neural network outperforms
    attitude estimation filters,” *Ai*, vol. 2, no. 3, pp. 444–463, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] N. Chumuang, A. Farooq, M. Irfan, S. Aziz, and M. Qureshi, “Feature matching
    and deep learning models for attitude estimation on a micro-aerial vehicle,” in
    *2022 International Conference on Cybernetics and Innovations (ICCI)*.   IEEE,
    2022, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] S. O. Madgwick, A. J. Harrison, and R. Vaidyanathan, “Estimation of IMU
    and MARG orientation using a gradient descent algorithm,” in *2011 IEEE international
    conference on rehabilitation robotics*.   IEEE, 2011, pp. 1–7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] A. A. Golroudbari and M. H. Sabour, “End-to-end deep learning framework
    for real-time inertial attitude estimation using 6DOF IMU,” *arXiv preprint arXiv:2302.06037*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] P. Narkhede, A. Mishra, K. Hamshita, A. K. Shubham, and A. Chauhan, “Inertial
    sensors and GPS fusion using LSTM for position estimation of aerial vehicle,”
    in *2022 4th International Conference on Smart Systems and Inventive Technology
    (ICSSIT)*.   IEEE, 2022, pp. 671–675.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] Y. Liu, Q. Luo, W. Liang, and Y. Zhou, “GPS/INS integrated navigation
    with LSTM neural network,” in *2021 4th International Conference on Intelligent
    Autonomous Systems (ICoIAS)*.   IEEE, 2021, pp. 345–350.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] Y. Liu, Y. Zhou, and Y. Zhang, “A novel hybrid attitude fusion method
    based on LSTM neural network for unmanned aerial vehicle,” in *2021 IEEE International
    Conference on Robotics and Biomimetics (ROBIO)*.   IEEE, 2021, pp. 1630–1635.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] Y. Liu, Q. Luo, and Y. Zhou, “Deep learning-enabled fusion to bridge GPS
    outages for INS/GPS integrated navigation,” *IEEE Sensors Journal*, vol. 22, no. 9,
    pp. 8974–8985, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] P. Geragersian, I. Petrunin, W. Guo, and R. Grech, “An INS/GNSS fusion
    architecture in GNSS denied environment using gated recurrent unit,” in *AIAA
    SCITECH 2022 Forum*, 2022, p. 1759.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] A. Shurin and I. Klein, “QuadNet: A hybrid framework for quadrotor dead
    reckoning,” *Sensors*, vol. 22, no. 4, p. 1426, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] M. K. Al-Sharman, Y. Zweiri, M. A. K. Jaradat, R. Al-Husari, D. Gan, and
    L. D. Seneviratne, “Deep-learning-based neural network training for state estimation
    enhancement: Application to attitude estimation,” *IEEE Transactions on Instrumentation
    and Measurement*, vol. 69, no. 1, pp. 24–34, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] Z. Zou, T. Huang, L. Ye, and K. Song, “CNN based adaptive Kalman filter
    in high-dynamic condition for low-cost navigation system on highspeed UAV,” in
    *2020 5th Asia-Pacific Conference on Intelligent Robot Systems (ACIRS)*.   IEEE,
    2020, pp. 103–108.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] B. Or and I. Klein, “A hybrid model and learning-based adaptive navigation
    filter,” *IEEE Transactions on Instrumentation and Measurement*, vol. 71, pp.
    1–11, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] X. Zhang, X. Mu, H. Liu, B. He, and T. Yan, “Application of modified EKF
    based on intelligent data fusion in AUV navigation,” in *2019 IEEE Underwater
    Technology (UT)*.   IEEE, 2019, pp. 1–4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] X. Mu, B. He, X. Zhang, Y. Song, Y. Shen, and C. Feng, “End-to-end navigation
    for autonomous underwater vehicle with hybrid recurrent neural networks,” *Ocean
    Engineering*, vol. 194, p. 106602, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] X. Zhang, B. He, G. Li, X. Mu, Y. Zhou, and T. Mang, “NavNet: AUV navigation
    through deep sequential learning,” *IEEE Access*, vol. 8, pp. 59 845–59 861, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] X. Zhang, B. He, S. Gao, L. Zhou, and R. Huang, “Sequential learning navigation
    method and general correction model for Autonomous Underwater Vehicle,” *Ocean
    Engineering*, vol. 278, p. 114347, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] H. Ma, X. Mu, and B. He, “Adaptive navigation algorithm with deep learning
    for autonomous underwater vehicle,” *Sensors*, vol. 21, no. 19, p. 6406, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] G. He, Y. Chaobang, D. Guohua, and S. Xiaoshuai, “The TCN-LSTM deep learning
    model for real-time prediction of ship motions,” *Available at SSRN 4405121*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] S. Song, J. Liu, J. Guo, J. Wang, Y. Xie, and J.-H. Cui, “Neural-network-based
    AUV navigation for fast-changing environments,” *IEEE Internet of Things Journal*,
    vol. 7, no. 10, pp. 9773–9783, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] I. B. Saksvik, A. Alcocer, and V. Hassani, “A deep learning approach to
    dead-reckoning navigation for autonomous underwater vehicles with limited sensor
    payloads,” in *OCEANS 2021: San Diego–Porto*.   IEEE, 2021, pp. 1–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] D. Li, J. Xu, H. He, and M. Wu, “An underwater integrated navigation algorithm
    to deal with DVL malfunctions based on deep learning,” *IEEE Access*, vol. 9,
    pp. 82 010–82 020, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] N. Cohen and I. Klein, “BeamsNet: A data-driven approach enhancing Doppler
    velocity log measurements for autonomous underwater vehicle navigation,” *Engineering
    Applications of Artificial Intelligence*, vol. 114, p. 105216, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] ——, “Libeamsnet: AUV velocity vector estimation in situations of limited
    DVL beam measurements,” in *OCEANS 2022, Hampton Roads*.   IEEE, 2022, pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] N. Cohen, Z. Yampolsky, and I. Klein, “Set-transformer BeamsNet for AUV
    velocity forecasting in complete DVL outage scenarios,” in *2023 IEEE Underwater
    Technology (UT)*, 2023, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] E. Topini, F. Fanelli, A. Topini, M. Pebody, A. Ridolfi, A. B. Phillips,
    and B. Allotta, “An experimental comparison of deep learning strategies for AUV
    navigation in DVL-denied environments,” *Ocean Engineering*, vol. 274, p. 114034,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] N. Shaukat, A. Ali, M. Javed Iqbal, M. Moinuddin, and P. Otero, “Multi-sensor
    fusion for underwater vehicle localization by augmentation of RBF neural network
    and error-state Kalman filter,” *Sensors*, vol. 21, no. 4, p. 1149, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] B. Or and I. Klein, “Adaptive step size learning with applications to
    velocity aided inertial navigation system,” *IEEE Access*, vol. 10, pp. 85 818–85 830,
    2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] ——, “ProNet: Adaptive process noise estimation for INS/DVL fusion,” in
    *2023 IEEE Underwater Technology (UT)*, 2023, pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] H. Chen, P. Aggarwal, T. M. Taha, and V. P. Chodavarapu, “Improving inertial
    sensor by reducing errors using deep learning methodology,” in *NAECON 2018-IEEE
    National Aerospace and Electronics Conference*.   IEEE, 2018, pp. 197–202.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] D. Engelsman, “Data-driven denoising of accelerometer signals,” Ph.D.
    dissertation, University of Haifa (Israel), 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] D. Engelsman and I. Klein, “A learning-based approach for bias elimination
    in low-cost gyroscopes,” in *2022 IEEE International Symposium on Robotic and
    Sensors Environments (ROSE)*.   IEEE, 2022, pp. 01–05.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] C. Jiang, S. Chen, Y. Chen, Y. Bo, L. Han, J. Guo, Z. Feng, and H. Zhou,
    “Performance analysis of a deep simple recurrent unit recurrent neural network
    (SRU-RNN) in MEMS gyroscope de-noising,” *Sensors*, vol. 18, no. 12, p. 4471,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] C. Jiang, S. Chen, Y. Chen, B. Zhang, Z. Feng, H. Zhou, and Y. Bo, “A
    MEMS IMU de-noising method using long short term memory recurrent neural networks
    (LSTM-RNN),” *Sensors*, vol. 18, no. 10, p. 3470, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] Z. Zhu, Y. Bo, and C. Jiang, “A MEMS gyroscope noise suppressing method
    using neural architecture search neural network,” *Mathematical Problems in Engineering*,
    vol. 2019, pp. 1–9, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] C. Jiang, Y. Chen, S. Chen, Y. Bo, W. Li, W. Tian, and J. Guo, “A mixed
    deep recurrent neural network for MEMS gyroscope noise suppressing,” *Electronics*,
    vol. 8, no. 2, p. 181, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] S. Han, Z. Meng, X. Zhang, and Y. Yan, “Hybrid deep recurrent neural
    networks for noise reduction of MEMS-IMU with static and dynamic conditions,”
    *Micromachines*, vol. 12, no. 2, p. 214, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] M. Brossard, S. Bonnabel, and A. Barrau, “Denoising IMU gyroscopes with
    deep learning for open-loop attitude estimation,” *IEEE Robotics and Automation
    Letters*, vol. 5, no. 3, pp. 4796–4803, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] P. Russo, F. Di Ciaccio, and S. Troisi, “DANAE: A denoising autoencoder
    for underwater attitude estimation,” *arXiv preprint arXiv:2011.06853*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] F. Huang, Z. Wang, L. Xing, and C. Gao, “A MEMS IMU gyroscope calibration
    method based on deep learning,” *IEEE Transactions on Instrumentation and Measurement*,
    vol. 71, pp. 1–9, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] Y. Liu, W. Liang, and J. Cui, “LGC-Net: A lightweight gyroscope calibration
    network for efficient attitude estimation,” *arXiv preprint arXiv:2209.08816*,
    2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] K. Yuan and Z. J. Wang, “A simple self-supervised IMU denoising method
    for inertial aided navigation,” *IEEE Robotics and Automation Letters*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| ![[Uncaptioned image]](img/ab71791a010bf5fa3213cf2731c4faf6.png) | Nadav
    Cohen received his B.Sc degree in Electrical and Computer Engineering from Ben-Gurion
    University of the Negev, Be’er Sheva, Israel in 2021\. He is currently pursuing
    a Ph.D. (direct track) degree at the Hatter Department of Marine Technologies,
    Charney School of Marine Sciences, University of Haifa, Israel. His research interests
    are inertial sensing, data-driven navigation, sensor fusion, signal processing,
    and estimation theory. |'
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/c58c55bf7513e6747d8add2b3af5c2f8.png) | Itzik
    Klein received B.Sc. and M.Sc. degrees in Aerospace Engineering from the Technion
    – Israel Institute of Technology, Haifa, Israel, in 2004 and 2007, respectively,
    and a Ph.D. degree in Geo-information Engineering from the Technion – Israel Institute
    of Technology, in 2011\. He is currently an Assistant Professor, heading the Autonomous
    Navigation and Sensor Fusion Lab, at the Hatter Department of Marine Technologies,
    Leon H. Charney School of Marine Sciences, University of Haifa. He is an IEEE
    Senior Member and a member of the IEEE journal of Indoor and Seamless Positioning
    and Navigation (J-ISPIN) Editorial Board. His research interests lie in the intersection
    of artificial intelligence, inertial sensing, and sensor fusion. |'
  prefs: []
  type: TYPE_TB
