- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:58:02'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:58:02
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2012.02364] Deep Learning for Medical Anomaly Detection - A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2012.02364] 深度学习在医学异常检测中的应用 - 调研'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2012.02364](https://ar5iv.labs.arxiv.org/html/2012.02364)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2012.02364](https://ar5iv.labs.arxiv.org/html/2012.02364)
- en: Deep Learning for Medical Anomaly Detection - A Survey
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在医学异常检测中的应用 - 调研
- en: 'Tharindu Fernando, Harshala Gammulle, Simon Denman, Sridha Sridharan, and Clinton
    Fookes T. Fernando, H. Gammulle, S. Denman, S. Sridharan and C. Fookes are with
    SAIVT, Queensland University of Technology, Australia (e-mail: t.warnakulasuriya@qut.edu.au.)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Tharindu Fernando、Harshala Gammulle、Simon Denman、Sridha Sridharan 和 Clinton
    Fookes T. Fernando、H. Gammulle、S. Denman、S. Sridharan 和 C. Fookes 均在澳大利亚昆士兰科技大学
    SAIVT 工作（电子邮件：t.warnakulasuriya@qut.edu.au.）
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Machine learning-based medical anomaly detection is an important problem that
    has been extensively studied. Numerous approaches have been proposed across various
    medical application domains and we observe several similarities across these distinct
    applications. Despite this comparability, we observe a lack of structured organisation
    of these diverse research applications such that their advantages and limitations
    can be studied. The principal aim of this survey is to provide a thorough theoretical
    analysis of popular deep learning techniques in medical anomaly detection. In
    particular, we contribute a coherent and systematic review of state-of-the-art
    techniques, comparing and contrasting their architectural differences as well
    as training algorithms. Furthermore, we provide a comprehensive overview of deep
    model interpretation strategies that can be used to interpret model decisions.
    In addition, we outline the key limitations of existing deep medical anomaly detection
    techniques and propose key research directions for further investigation.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基于机器学习的医学异常检测是一个重要问题，已被广泛研究。许多方法在不同的医学应用领域提出，我们观察到这些不同应用之间存在若干相似之处。尽管存在这些可比性，我们仍发现缺乏对这些不同研究应用的结构化组织，以便研究它们的优缺点。本调研的主要目的是对流行的深度学习技术在医学异常检测中的应用进行全面的理论分析。特别地，我们提供了对最先进技术的连贯和系统的综述，比较和对比它们的架构差异以及训练算法。此外，我们提供了对深度模型解释策略的全面概述，以帮助解释模型决策。我们还概述了现有深度医学异常检测技术的主要局限性，并提出了进一步研究的关键方向。
- en: 'Index Terms:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Deep Learning, Anomaly detection, Machine Learning, Temporal analysis
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习，异常检测，机器学习，时间分析
- en: I Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Identifying data samples that do not fit the overall data distribution is the
    principle task in anomaly detection. Anomalies can arise due to various reasons
    such as noise in the data capture process, changes in underlying phenomenon, or
    due to new or previously unseen conditions in the captured environment. Therefore,
    anomaly detection is a crucial task in medical signal analysis.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 识别不符合整体数据分布的数据样本是异常检测的主要任务。异常可能由于数据捕获过程中的噪声、潜在现象的变化，或由于捕获环境中新出现的或以前未见过的条件而发生。因此，异常检测在医学信号分析中是一个至关重要的任务。
- en: The dawn of deep learning has revolutionised the machine learning field and
    it’s success has seeped into the domain of medical anomaly detection, which has
    resulted in a myriad of research articles leveraging deep machine learning architectures
    for medical anomaly detection.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的曙光彻底改变了机器学习领域，它的成功已渗透到医学异常检测领域，催生了大量利用深度机器学习架构进行医学异常检测的研究文章。
- en: The principal aim of this survey is to present a structured and comprehensive
    review of this existing literature, systematically comparing and contrasting methodologies.
    Furthermore, we provide an extensive investigation in to deep model interpretation
    strategies, which is critical when applying ‘black-box’ deep models for medical
    diagnosis and to understand why a decision is reached. In addition, we summarise
    the challenges and limitations of existing research, and identify key future research
    directions, paving the way for the prevalent and effective application of deep
    learning in medical anomaly detection.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本调研的主要目的是对现有文献进行结构化和全面的综述，系统地比较和对比方法。此外，我们提供了对深度模型解释策略的深入研究，这在应用‘黑箱’深度模型进行医学诊断时至关重要，以理解决策的原因。此外，我们总结了现有研究的挑战和局限性，并确定了未来的关键研究方向，为深度学习在医学异常检测中的广泛有效应用铺平道路。
- en: I-A What are Anomalies?
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-A 异常是什么？
- en: Anomaly detection is the task of identifying out of distribution examples. Simply
    put, it seeks to detect examples that do not follow the general pattern present
    in the dataset. This is a crucial task as anomalous observations correlate with
    types of problem or fault, such as structural defects, system or malware intrusions,
    production errors, financial frauds or health problems. Despite the straightforward
    definition, identifying anomalies is a challenging task in machine learning. One
    of the main challenges arises from the inconsistent behaviour of different anomalies,
    and the lack of constant definition of what constitutes an anomaly [[1](#bib.bib1),
    [2](#bib.bib2), [3](#bib.bib3)]. For example, in a particular context a certain
    heart rate can be normal, while in a different context it could indicate a health
    concern. Furthermore, noisy data capture settings and/or dynamic changes in monitoring
    environments can lead normal examples to appear as out of distribution samples
    (i.e. abnormal), yielding higher false positive rates [[4](#bib.bib4)]. Hence,
    intelligent learning strategies with high modelling capacity are required to better
    segregate the anomalous samples from normal data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测是识别分布外示例的任务。简单来说，它旨在检测不符合数据集中普遍模式的示例。这是一项关键任务，因为异常观察与问题或故障类型相关，如结构缺陷、系统或恶意软件入侵、生产错误、金融欺诈或健康问题。尽管定义简单，但在机器学习中识别异常是一项具有挑战性的任务。主要挑战之一是不同异常的不一致行为，以及对异常的定义缺乏一致性
    [[1](#bib.bib1), [2](#bib.bib2), [3](#bib.bib3)]。例如，在特定上下文中，某个心率可能是正常的，而在不同的上下文中，它可能表明健康问题。此外，噪声数据捕获设置和/或监控环境的动态变化可能导致正常示例看起来像分布外样本（即异常），从而导致较高的假阳性率
    [[4](#bib.bib4)]。因此，需要具有高建模能力的智能学习策略，以更好地将异常样本与正常数据区分开来。
- en: I-B Why are Medical Anomalies Different?
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-B 为什么医学异常不同？
- en: The diagram in Fig. [1](#S1.F1 "Figure 1 ‣ I-B Why are Medical Anomalies Different?
    ‣ I Introduction ‣ Deep Learning for Medical Anomaly Detection - A Survey") illustrates
    the main stages with respect to medical data processing with machine learning,
    and how each stage relates to anomaly detection. Collected physiological data
    is analysed and typically utilised for i) prediction and/or ii) diagnosis. Prediction
    tasks include predicting future states of physiological signals such as blood
    pressure, or other characteristics such as recovery rates. For diagnosis tasks
    a portion of the data is analysed to recognise pathological signs of specific
    medical conditions. Anomaly detection relates to both prediction and diagnosis
    tasks, as it captures unique characteristics of the physiological data that could
    offer information about the data or patient.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [1](#S1.F1 "Figure 1 ‣ I-B Why are Medical Anomalies Different? ‣ I Introduction
    ‣ Deep Learning for Medical Anomaly Detection - A Survey") 展示了机器学习在医学数据处理中的主要阶段，以及每个阶段如何与异常检测相关。收集到的生理数据被分析，通常用于
    i) 预测和/或 ii) 诊断。预测任务包括预测生理信号的未来状态，如血压，或其他特征如恢复率。对于诊断任务，分析数据的一部分以识别特定医学条件的病理征兆。异常检测与预测和诊断任务相关，因为它捕捉生理数据的独特特征，这些特征可能提供有关数据或患者的信息。
- en: '![Refer to caption](img/a412c70190be078cdd7fd81c9caadc45.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a412c70190be078cdd7fd81c9caadc45.png)'
- en: 'Figure 1: Illustration of the main stages in medical data processing and how
    anomaly detection relates to other stages.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：医学数据处理的主要阶段及异常检测如何与其他阶段相关的插图。
- en: Similar to other application domains, medical anomaly detection also inherits
    the challenges described in Sec. [I-A](#S1.SS1 "I-A What are Anomalies? ‣ I Introduction
    ‣ Deep Learning for Medical Anomaly Detection - A Survey"). For instance, Fig.
    [2](#S1.F2 "Figure 2 ‣ I-B Why are Medical Anomalies Different? ‣ I Introduction
    ‣ Deep Learning for Medical Anomaly Detection - A Survey") (a) illustrates two
    examples from the Kvasir endoscopy image dataset [[5](#bib.bib5)]. Despite the
    strong visual similarities, the left figure is an example from the normal-cecum
    class while the right figure is an example from the ulcerative-colitis disease
    category. Another example is given in Fig. [2](#S1.F2 "Figure 2 ‣ I-B Why are
    Medical Anomalies Different? ‣ I Introduction ‣ Deep Learning for Medical Anomaly
    Detection - A Survey") (b) which illustrates the diverse nature of the normal
    data in a typical medical dataset. These examples are heart sound recordings from
    the PhysioNet Computing in Cardiology Challenge 2016 [[6](#bib.bib6)]. The top
    figure shows a clean normal heart sound recording. While the figure in the 2nd
    row represents a recording of the normal category that has been corrupted by noise
    during data capture. Therefore, when modelling normal examples, the model should
    have the capacity to represent the diverse nature of the normal data distribution.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于其他应用领域，医学异常检测也继承了在第[I-A节](#S1.SS1 "I-A What are Anomalies? ‣ I Introduction
    ‣ Deep Learning for Medical Anomaly Detection - A Survey")中描述的挑战。例如，图[2](#S1.F2
    "Figure 2 ‣ I-B Why are Medical Anomalies Different? ‣ I Introduction ‣ Deep Learning
    for Medical Anomaly Detection - A Survey") (a) 展示了来自Kvasir内窥镜图像数据集[[5](#bib.bib5)]的两个示例。尽管它们在视觉上非常相似，但左侧的图像来自正常盲肠类别，而右侧的图像来自溃疡性结肠炎病类别。另一个示例见图[2](#S1.F2
    "Figure 2 ‣ I-B Why are Medical Anomalies Different? ‣ I Introduction ‣ Deep Learning
    for Medical Anomaly Detection - A Survey") (b)，该图展示了典型医学数据集中正常数据的多样性。这些示例是来自PhysioNet心脏病学挑战赛2016的心音录音[[6](#bib.bib6)]。顶部的图像显示了一个干净的正常心音录音。第二行的图像代表了一个在数据捕获过程中被噪声污染的正常类别录音。因此，在建模正常示例时，模型应具有表示正常数据分布多样性的能力。
- en: '![Refer to caption](img/26595635b460017131340289216bfef3.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/26595635b460017131340289216bfef3.png)'
- en: (a)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/c10838d937f1c9220a1958e1df8fda49.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c10838d937f1c9220a1958e1df8fda49.png)'
- en: (b)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 2: Challenges associated with medical anomaly detection. (a) Two examples
    (normal and abnormal) from the Kvasir endoscopy image dataset [[5](#bib.bib5)]
    with strong visual similarities. (b) Two normal examples from the PhysioNet CinC
    2016 heart sound dataset [[6](#bib.bib6)], where the signal in the bottom row
    is corrupted by noise.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：与医学异常检测相关的挑战。(a) 来自Kvasir内窥镜图像数据集[[5](#bib.bib5)]的两个示例（正常和异常），具有强烈的视觉相似性。(b)
    来自PhysioNet CinC 2016心音数据集[[6](#bib.bib6)]的两个正常示例，其中底部行的信号被噪声污染。
- en: Apart from these inherent challenges, medical anomaly detection has additional
    hindrances which are application specific. Firstly as the end application is primarily
    medical diagnosis, the test sensitivity (the ability to correctly identify the
    anomalous samples) is a decisive and crucial factor, and the abnormality detection
    model is required to be highly accurate. Secondly, there are numerous patient
    specific characteristics that contribute to dissimilarities among different data
    samples. For instance, in [[7](#bib.bib7)] the authors have identified substantial
    differences among children from different demographics with respect to their resting
    state in EEG data. There are also substantial differences between different age
    groups, genders, etc. Therefore, when designing an accurate medical anomaly detection
    framework measures should be taken to mitigate such hindrances. Considering these
    challenges, medical anomaly detection is often posed as a supervised learning
    task [[8](#bib.bib8), [1](#bib.bib1)], where a supervision signal is presented
    for the model to learn to discriminate normal from abnormal examples. This is
    in contrast to other domains such as production defect detection or financial
    frauds detection, where anomalies are detected in an unsupervised manner.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些固有的挑战，医疗异常检测还有一些特定于应用的额外障碍。首先，由于最终应用主要是医疗诊断，测试灵敏度（正确识别异常样本的能力）是一个决定性且至关重要的因素，因此异常检测模型需要高度准确。其次，不同数据样本之间存在许多患者特有的特征，这些特征会导致差异。例如，在[[7](#bib.bib7)]中，作者发现不同人群中的儿童在EEG数据的静息状态下存在显著差异。不同年龄组、性别等之间也存在显著差异。因此，在设计准确的医疗异常检测框架时，需要采取措施以减轻这些障碍。考虑到这些挑战，医疗异常检测通常被视为一个监督学习任务[[8](#bib.bib8),
    [1](#bib.bib1)]，其中为模型提供监督信号，以便模型学习区分正常样本和异常样本。这与其他领域如生产缺陷检测或金融欺诈检测有所不同，在这些领域中，异常是以无监督的方式检测的。
- en: I-C Why use Deep Learning for Medical Anomaly Detection?
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-C 为什么使用深度学习进行医疗异常检测？
- en: Deep learning is becoming increasingly popular among researchers in biomedical
    engineering as it offers a way to address the above stated challenges. One prominent
    characteristics of deep learning is it’s ability to model non-linearity. Increasing
    non-linearity in the model can better segregate normal and anomalous samples,
    and better model the inconsistencies in the data. An additional merit that deep
    learning brings is its automatic feature learning capability. The availability
    of big-data [[9](#bib.bib9)] and increased computational resources has empowered
    deep learning’s hierarchical feature learning process, avoiding the need to explicitly
    hand-craft and define what constitutes an anomaly. Another interesting trait of
    deep learning is its ability to uncover long-term relationships within the data
    seamlessly through the neural network architecture [[1](#bib.bib1)], without explicitly
    defining them during feature design. For instance, recurrent architectures such
    as Long Short-Term Memory (LSTM) [[10](#bib.bib10)] and Gated Recurrent Units
    (GRU) [[11](#bib.bib11)] can efficiently model temporal relationships in time
    series data using what is termed ‘memory’.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在生物医学工程领域的研究人员中越来越受欢迎，因为它提供了一种解决上述挑战的方法。深度学习的一个突出特点是它建模非线性的能力。增加模型的非线性可以更好地区分正常样本和异常样本，并更好地建模数据中的不一致性。深度学习的另一个优点是其自动特征学习能力。大数据[[9](#bib.bib9)]和计算资源的增加使深度学习的层级特征学习过程得以实现，避免了显式手工设计和定义什么构成异常的需要。深度学习的另一个有趣特点是其通过神经网络架构[[1](#bib.bib1)]无缝发现数据中的长期关系的能力，而无需在特征设计过程中显式定义这些关系。例如，像长短期记忆（LSTM）[[10](#bib.bib10)]和门控递归单元（GRU）[[11](#bib.bib11)]这样的递归架构可以使用所谓的“记忆”高效地建模时间序列数据中的时间关系。
- en: I-D Our Contributions
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-D 我们的贡献
- en: Although several recent survey articles [[3](#bib.bib3), [2](#bib.bib2)] on
    anomaly detection have briefly touched upon the medical anomaly detection domain,
    and despite numerous survey papers published on specific medical application domains
    [[12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16)],
    there is no systematic review of deep learning based medical anomaly detection
    techniques which would allow readers to compare and contrast the strengths and
    weakness of different deep learning techniques, and leverage those findings for
    different medical application domains. Tab. [I](#S1.T1 "TABLE I ‣ I-D Our Contributions
    ‣ I Introduction ‣ Deep Learning for Medical Anomaly Detection - A Survey") summarises
    these limitations. This paper directly addresses this need and contributes a thorough
    theoretical analysis of popular deep learning model architectures, including convolutional
    neural networks, recurrent neural networks, generative adversarial networks, auto
    encoders, and neural memory networks; and their application to medial anomaly
    detection. Furthermore, we extensively analyse different model training strategies,
    including unsupervised learning, supervised learning and multi-task learning.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管几篇近期的综述文章 [[3](#bib.bib3), [2](#bib.bib2)] 简要涉及了医学异常检测领域，尽管有许多专门针对特定医学应用领域的综述论文
    [[12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16)]，但仍缺乏关于深度学习医学异常检测技术的系统性综述，这种综述可以使读者比较不同深度学习技术的优缺点，并将这些发现应用于不同的医学应用领域。表
    [I](#S1.T1 "TABLE I ‣ I-D Our Contributions ‣ I Introduction ‣ Deep Learning for
    Medical Anomaly Detection - A Survey") 总结了这些局限性。本文直接解决了这一需求，提供了对流行深度学习模型架构的详细理论分析，包括卷积神经网络、递归神经网络、生成对抗网络、自编码器和神经记忆网络；以及它们在医学异常检测中的应用。此外，我们还广泛分析了不同的模型训练策略，包括无监督学习、有监督学习和多任务学习。
- en: 'TABLE I: Comparison of Our Survey to Other Related Studies'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：我们综述与其他相关研究的比较
- en: '|  |  | Reference |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 参考文献 |'
- en: '| --- | --- | --- |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|  |  | [[3](#bib.bib3)] | [[2](#bib.bib2)] | [[14](#bib.bib14)] | [[13](#bib.bib13)]
    | [[15](#bib.bib15)] | [[12](#bib.bib12)] | [[16](#bib.bib16)] | Proposed |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '|  |  | [[3](#bib.bib3)] | [[2](#bib.bib2)] | [[14](#bib.bib14)] | [[13](#bib.bib13)]
    | [[15](#bib.bib15)] | [[12](#bib.bib12)] | [[16](#bib.bib16)] | 提出的 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Algorithmic Approach | Unsupervised | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |  | ✓ |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 算法方法 | 无监督 | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |  | ✓ |'
- en: '| Supervised | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 有监督 | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: '| Recurrent | ✓ |  | ✓ | ✓ | ✓ | ✓ |  | ✓ |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 循环神经网络 | ✓ |  | ✓ | ✓ | ✓ | ✓ |  | ✓ |'
- en: '| Multi-Task |  |  |  |  |  |  |  | ✓ |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 多任务 |  |  |  |  |  |  |  | ✓ |'
- en: '| Network Architecture | Auto-Encoders | ✓ |  | ✓ |  |  |  |  | ✓ |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 网络架构 | 自编码器 | ✓ |  | ✓ |  |  |  |  | ✓ |'
- en: '| Generative Adversarial Networks | ✓ |  | ✓ |  | ✓ | ✓ |  | ✓ |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 生成对抗网络 | ✓ |  | ✓ |  | ✓ | ✓ |  | ✓ |'
- en: '| Neural Memory Networks |  |  |  |  |  |  |  | ✓ |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 神经记忆网络 |  |  |  |  |  |  |  | ✓ |'
- en: '| Long Short-Term Memory Networks | ✓ |  | ✓ | ✓ | ✓ |  |  | ✓ |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 长短期记忆网络 | ✓ |  | ✓ | ✓ | ✓ |  |  | ✓ |'
- en: '| Gated Recurrent Units | ✓ |  | ✓ | ✓ | ✓ |  |  | ✓ |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 门控循环单元 | ✓ |  | ✓ | ✓ | ✓ |  |  | ✓ |'
- en: '| Applications | MRI-based Anomaly Detection | ✓ |  |  |  | ✓ |  |  | ✓ |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 应用 | 基于 MRI 的异常检测 | ✓ |  |  |  | ✓ |  |  | ✓ |'
- en: '| Anomalies in Endoscopy Images |  |  | ✓ |  |  |  | ✓ | ✓ |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 内窥镜图像中的异常 |  |  | ✓ |  |  |  | ✓ | ✓ |'
- en: '| Heart Sound Anomalies |  |  |  | ✓ |  |  |  | ✓ |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 心音异常 |  |  |  | ✓ |  |  |  | ✓ |'
- en: '| Epileptic Seizures | ✓ |  |  |  |  | ✓ |  | ✓ |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 癫痫发作 | ✓ |  |  |  |  | ✓ |  | ✓ |'
- en: '| Model Interpretation Methods |  |  |  |  |  |  |  |  | ✓ |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 模型解释方法 |  |  |  |  |  |  |  |  | ✓ |'
- en: '| Medical Data Capturing Processes |  |  |  |  |  |  |  |  | ✓ |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 医学数据捕捉过程 |  |  |  |  |  |  |  |  | ✓ |'
- en: Moreover, this paper provides a comprehensive overview of deep model interpretation
    strategies that can be used to interpret model decisions. This analysis systematically
    illustrates how these methods generates model agnostic interpretations, and the
    limitations of these methods when applied to medical data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，本文还提供了深度模型解释策略的全面概述，这些策略可以用来解释模型决策。该分析系统地阐述了这些方法如何生成与模型无关的解释，以及这些方法在应用于医学数据时的局限性。
- en: Finally, this review details the limitations of existing deep medical anomaly
    detection approaches and lists key research directions, inspiring readers to direct
    their future investigations towards generalisable and interpretable deep medical
    anomaly detection frameworks, as well as probabilistic and causal approaches which
    may reveal cause and effect relationships within the data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，本综述详细描述了现有深度医疗异常检测方法的局限性，并列出了关键的研究方向，激励读者将未来的研究方向转向可泛化和可解释的深度医疗异常检测框架，以及可能揭示数据中因果关系的概率性和因果性方法。
- en: I-E Organisation
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-E 组织结构
- en: In Sec. [II](#S2 "II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning
    for Medical Anomaly Detection - A Survey") we illustrate different aspects of
    deep anomaly detection algorithms, illustrating the motivation for these architectures,
    and highlighting the complexities associated with medical anomaly detection. Specifically,
    Sec. [II-A](#S2.SS1 "II-A Types of Data ‣ II Detecting Medical Anomalies with
    Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey") illustrates
    the types of data available in the medical anomaly detection domain, and how different
    deep learning architectures are designed to capture information from different
    modalities. Sec. [II-B](#S2.SS2 "II-B Algorithmic Approaches for Medical Anomaly
    Detection ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning
    for Medical Anomaly Detection - A Survey") categorises deep anomaly detection
    architectures based on their training objectives, discussing the theories behind
    these algorithms and the merits and deficiencies of them. Sec. [II-C](#S2.SS3
    "II-C Background and Related Applications ‣ II Detecting Medical Anomalies with
    Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey") provides
    an overview of key application domains to which deep medical anomaly detection
    has been applied. In Sec. [III](#S3 "III Model Interpretation ‣ Deep Learning
    for Medical Anomaly Detection - A Survey") we theoretically outline deep model
    interpretation strategies which are a key consideration when deploying deep models
    in medical applications. Sec. [IV](#S4 "IV Challenges and Open Research Questions
    ‣ Deep Learning for Medical Anomaly Detection - A Survey") illustrates some of
    the challenges and limitations of existing deep anomaly detection frameworks,
    and provides future directions to pursue. Sec. [V](#S5 "V Conclusion ‣ Deep Learning
    for Medical Anomaly Detection - A Survey") contains concluding remarks.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在节 [II](#S2 "II 使用深度学习检测医疗异常 ‣ 深度学习在医疗异常检测中的应用 - 调查") 中，我们展示了深度异常检测算法的不同方面，阐明了这些架构的动机，并强调了与医疗异常检测相关的复杂性。具体而言，节
    [II-A](#S2.SS1 "II-A 数据类型 ‣ II 使用深度学习检测医疗异常 ‣ 深度学习在医疗异常检测中的应用 - 调查") 展示了医疗异常检测领域中的数据类型，以及不同的深度学习架构如何设计以捕获来自不同模态的信息。节
    [II-B](#S2.SS2 "II-B 医疗异常检测的算法方法 ‣ II 使用深度学习检测医疗异常 ‣ 深度学习在医疗异常检测中的应用 - 调查") 根据训练目标对深度异常检测架构进行分类，讨论了这些算法背后的理论及其优缺点。节
    [II-C](#S2.SS3 "II-C 背景和相关应用 ‣ II 使用深度学习检测医疗异常 ‣ 深度学习在医疗异常检测中的应用 - 调查") 概述了深度医疗异常检测应用的关键领域。在节
    [III](#S3 "III 模型解释 ‣ 深度学习在医疗异常检测中的应用 - 调查") 中，我们理论性地概述了深度模型解释策略，这是在医疗应用中部署深度模型时的一个关键考虑因素。节
    [IV](#S4 "IV 挑战和开放的研究问题 ‣ 深度学习在医疗异常检测中的应用 - 调查") 说明了现有深度异常检测框架的一些挑战和限制，并提供了未来的研究方向。节
    [V](#S5 "V 结论 ‣ 深度学习在医疗异常检测中的应用 - 调查") 包含了结论性评论。
- en: II Detecting Medical Anomalies with Deep Learning
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 使用深度学习检测医疗异常
- en: In this section we identify different aspects of deep medical anomaly detection
    algorithms, including the types of data used, different algorithmic architectures,
    and different application domains that are considered. The following subsections
    discuss existing deep medical anomaly detection algorithms within each of these
    categories.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将识别深度医疗异常检测算法的不同方面，包括使用的数据类型、不同的算法架构以及考虑的不同应用领域。以下小节讨论了这些类别中现有的深度医疗异常检测算法。
- en: II-A Types of Data
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 数据类型
- en: Biomedical signals can be broadly categorised into biomedical images, electrical
    biomedical signals, and other biomedical data such as data from laboratory results,
    audio recordings and wearable medical devices. The following subsections provide
    a brief discussion of popular applications scenarios. We also refer the readers
    to supplementary material where we provide a more comprehensive discussion regarding
    each of these categories.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 生物医学信号可以大致分为生物医学图像、电生物医学信号和其他生物医学数据，如实验室结果数据、音频记录和可穿戴医疗设备的数据。以下小节将简要讨论流行的应用场景。我们还将读者引导到补充材料中，在那里我们提供了有关这些类别的更全面讨论。
- en: II-A1 Biomedical Imagining
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A1 生物医学成像
- en: 'X-ray radiography: X-rays have shorter wave lengths than visible light and
    can pass through most tissue types in the human body. However, the calcium contained
    in bones is denser and scatters the x-rays. The film that sits on the opposite
    side of the x-ray source is a negative image such that areas that are exposed
    to more light appear darker. Therefore, as more x-rays penetrate tissues such
    as lungs and mussels, these areas are darkened on the film and the bones appear
    as brighter regions. X-ray imaging is typically used for various diagnostic purposes,
    including detecting bone fractures, dental problems, pneumonia, and certain types
    of tumor.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: X射线摄影：X射线的波长比可见光短，可以穿透人体大多数组织。然而，骨骼中的钙含量更高，能够散射X射线。位于X射线源对面的胶卷呈负片形式，使得暴露在更多光线下的区域显得更暗。因此，当更多X射线穿透如肺和肌肉等组织时，这些区域在胶卷上显得更暗，而骨骼则显得更亮。X射线成像通常用于各种诊断目的，包括检测骨折、牙科问题、肺炎和某些类型的肿瘤。
- en: 'Computed Tomography scan (CT): In CT imaging, cross sectional images of the
    body are generated using a narrow beam of x-rays that are emitted while the patient
    is quickly rotated. CT imaging collects a number of cross sectional slices which
    are stacked together to generate a 3 dimensional representation, which is more
    informative than a conventional X-ray image. CT scans are a popular diagnostic
    tool when identifying disease or injury within various regions of the body. Applications
    include detecting tumors or lesions in the abdomen, and localising head injuries,
    tumors, and clots. They are also used for diagnosing complex bone fractures and
    bone tumors.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机断层扫描（CT）：在CT成像中，使用窄束X射线生成身体的横截面图像，这些射线在患者快速旋转时发射。CT成像收集多个横截面切片，并将其叠加生成三维图像，这比传统的X射线图像更具信息性。CT扫描是识别身体各个区域疾病或损伤的常用诊断工具。应用包括检测腹部肿瘤或病变，以及定位头部损伤、肿瘤和血块。它们也用于诊断复杂的骨折和骨肿瘤。
- en: 'Magnetic Resonance Imaging (MRI): As the name implies MRI employs a magnetic
    field for imagining by forcing protons in the body to align with the applied field.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 磁共振成像（MRI）：顾名思义，MRI通过施加磁场来进行成像，迫使体内的质子与施加的磁场对齐。
- en: Specifically, the protons in the human body spin and create a small magnetic
    field. When a strong magnetic field such as from the MRI machine is introduced,
    the protons align with that field. Then a radio frequency pulse is introduced
    which disrupts the alignment. When the radio frequency pulse is turned off the
    protons discharge energy and try to re-align with the magnetic field. The energy
    released varies for different tissue types, allowing the MRI scan to segregate
    different regions. Therefore, MRIs are typically used to image non-bony or soft
    tissue regions of the human body. Comparison studies have shown that the brain,
    spinal cord, nerves and muscles are better captured by MRIs than CT scans. Therefore,
    MRI is the modality of choice for tasks such as brain tumor detection and identifying
    tissue damage.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，人体内的质子旋转并产生一个小的磁场。当引入如MRI机产生的强磁场时，质子会与该磁场对齐。然后引入一个射频脉冲，扰乱质子的对齐。当射频脉冲关闭时，质子释放能量并试图重新对齐磁场。不同组织类型释放的能量不同，使得MRI扫描能够区分不同区域。因此，MRI通常用于成像非骨骼或软组织区域。对比研究表明，脑部、脊髓、神经和肌肉在MRI下的成像效果优于CT扫描。因此，MRI是脑肿瘤检测和识别组织损伤等任务的首选技术。
- en: In addition to these popular biomedical imaging sensor categories there exists
    other common data sources such as Positron Emission Tomography (PET), Ultrasound
    and Medical Optical Imaging. An illustration of different medical imaging signal
    types is provided in Fig. [3](#S2.F3 "Figure 3 ‣ II-A1 Biomedical Imagining ‣
    II-A Types of Data ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep
    Learning for Medical Anomaly Detection - A Survey"). In the Sec. 1.1 of supplementary
    material we provide a comprehensive discussion of these different data sources,
    including a discussion regarding their recent applications in deep learning as
    well as a list of publicly available datasets.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些流行的生物医学成像传感器类别外，还存在其他常见的数据源，如正电子发射断层扫描 (PET)、超声和医学光学成像。不同医学成像信号类型的示意图见图
    [3](#S2.F3 "图 3 ‣ II-A1 生物医学成像 ‣ II-A 数据类型 ‣ II 使用深度学习检测医学异常 ‣ 医学异常检测的深度学习 - 综述")。在附录材料的第
    1.1 节中，我们提供了对这些不同数据源的全面讨论，包括对其在深度学习中的最新应用的讨论，以及公开可用数据集的列表。
- en: '![Refer to caption](img/18b16eeb599c34dda62b49248f9da4fc.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/18b16eeb599c34dda62b49248f9da4fc.png)'
- en: (a)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/0cfc2714952831d820e0ae2e3b0931b4.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/0cfc2714952831d820e0ae2e3b0931b4.png)'
- en: (b)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: '![Refer to caption](img/5e9bea84e47e466a2932d5462b9c3838.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/5e9bea84e47e466a2932d5462b9c3838.png)'
- en: (c)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: (c)
- en: '![Refer to caption](img/b9ca1b82b1f379c97c0f2cde10769d1a.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/b9ca1b82b1f379c97c0f2cde10769d1a.png)'
- en: (d)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: (d)
- en: '![Refer to caption](img/b8f3004d4ef918fb5f137b2219e70368.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/b8f3004d4ef918fb5f137b2219e70368.png)'
- en: (e)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: (e)
- en: '![Refer to caption](img/29352b1074912a9602490f364b161a22.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/29352b1074912a9602490f364b161a22.png)'
- en: (f)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: (f)
- en: 'Figure 3: Illustration of different medical imaging signals. (a) X-ray image
    ([Image Source](https://commons.wikimedia.org/)), (b) Lung CT scans of healthy
    and diseased subjects taken from the [SARS-CoV-2 CT scan dataset](https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset),
    (c) An MRI image with a brain tumor taken from [Kaggle Brain MRI Images for Brain
    Tumor Detection dataset](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection),
    (d) An example PET scan. Image taken from [PET radiomics challenges](https://www.kaggle.com/c/pet-radiomics-challenges),
    (e) An ultrasound image of the neck which is taken from [Kaggle Ultrasound Nerve
    Segmentation dataset](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection),
    (f) An endoscopy image of the gastrointestinal tract which is taken from [The
    Nerthus endoscopy dataset.](https://datasets.simula.no/nerthus/)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 不同医学成像信号的示意图。 (a) X射线图像 ([图像来源](https://commons.wikimedia.org/))， (b)
    健康和病态受试者的肺部 CT 扫描，取自 [SARS-CoV-2 CT 扫描数据集](https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset)，
    (c) 带有脑肿瘤的 MRI 图像，取自 [Kaggle 脑部 MRI 图像用于脑肿瘤检测数据集](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection)，
    (d) 一个 PET 扫描示例。图像取自 [PET 放射组学挑战](https://www.kaggle.com/c/pet-radiomics-challenges)，
    (e) 颈部超声图像，取自 [Kaggle 超声神经分割数据集](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection)，
    (f) 胃肠道内窥镜图像，取自 [Nerthus 内窥镜数据集](https://datasets.simula.no/nerthus/)'
- en: II-A2 Electrical Biomedical Signals
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A2 电生物医学信号
- en: 'Electrocardiogram (ECG): ECG is a tool to visualise electricity flowing through
    the heart which creates the heart beat, and starts at the top of the heart and
    travels to the bottom. At rest, heart cells are negatively charged compared to
    the outside environment and when they become depolarized they become positively
    charged. The difference in polarization is captured by the ECG. There are two
    types of information which can be extracted by analysing the ECG [[17](#bib.bib17)].
    First, by measuring time intervals on an ECG one can screen for irregular electrical
    activities. Second, the strength of the electrical activity provides an indication
    of the regions of the heart that are over worked or stressed.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '心电图 (ECG): ECG 是一种可视化心脏电流的工具，它产生心跳，从心脏顶部开始，向底部传播。在静息状态下，心脏细胞相对于外部环境带负电，当它们去极化时，变为正电。心电图捕捉到这种极化差异。通过分析心电图，可以提取两种信息
    [[17](#bib.bib17)]。首先，通过测量心电图上的时间间隔，可以筛查不规则的电活动。其次，电活动的强度可以指示心脏的哪些区域过度工作或受到压力。'
- en: 'Electroencephalogram (EEG): The EEG detects electrical activity in the brain,
    which uses electrical impulses to communicate. To capture the electrical activity,
    small metal discs (electrodes) are placed on the scalp. The electrical signals
    captured by these electrodes are amplified to better visualise brain activity.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 脑电图（EEG）：EEG 检测大脑中的电活动，大脑使用电信号进行通讯。为了捕捉电活动，在头皮上放置小金属圆片（电极）。这些电极捕捉到的电信号会被放大，以便更好地可视化大脑活动。
- en: EEGs are a prominent tool for observing the cognitive process of a subject.
    They are often used to study sleep patterns, psychological disorders, brain damage
    from head injury, and epilepsy.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 脑电图（EEG）是观察被试认知过程的一个重要工具。它们通常用于研究睡眠模式、心理障碍、头部损伤造成的脑损伤以及癫痫。
- en: 'Magnetoencephalography (MEG): As described above, an EEG captures the electrical
    fields generated by extracellular currents of the human brain while MEG primarily
    detects the magnetic fields induced by these extracellular currents [[18](#bib.bib18)].
    We acknowledge that MEG is not an electrical biomedical signal, however, we list
    MEG alongside with other electrical signals since it’s capturing a by-product
    of the brain’s electrical activity. Several studies [[19](#bib.bib19), [20](#bib.bib20),
    [21](#bib.bib21), [22](#bib.bib22), [23](#bib.bib23), [24](#bib.bib24)] have investigated
    the utility of MEG signals for the detection of anomalous brain activities and
    conditions.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 磁脑图（MEG）：如上所述，EEG 捕捉由大脑外部电流生成的电场，而 MEG 主要检测这些外部电流引起的磁场 [[18](#bib.bib18)]。我们承认
    MEG 不是一种电生物医学信号，但由于它捕捉的是大脑电活动的副产品，因此我们将 MEG 与其他电信号一起列出。多项研究 [[19](#bib.bib19),
    [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22), [23](#bib.bib23), [24](#bib.bib24)]
    探讨了 MEG 信号在检测异常脑活动和状态中的实用性。
- en: In addition to ECGs, EEGs and MEGs which are the most commonly utilsed electrical
    biomedical signals we would like to acknowledge Electromyography (EMG) sensors
    where electric potential generated by muscle cells is monitored to diagnose the
    health of muscles and motor neurons. We refer the readers to Sec. 1.2 of supplementary
    material for a more comprehensive discussion related to ECGs, EEGs, MEGs, EMGs,
    and discussion regarding their recent applications in deep learning research and
    a list of publicly available datasets.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 ECG、EEG 和 MEG 这几种最常用的电生物医学信号外，我们还希望承认肌电图（EMG）传感器，通过监测肌肉细胞产生的电位来诊断肌肉和运动神经元的健康状况。我们建议读者参阅补充材料第
    1.2 节，以获取有关 ECG、EEG、MEG、EMG 的更全面讨论，以及关于它们在深度学习研究中的最新应用和公开数据集的列表。
- en: II-A3 Miscellaneous data types
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A3 其他数据类型
- en: In addition to the primary data types discussed above we would like to acknowledge
    other miscellaneous data sources such as Phonocardiography (PCG) and wearable
    medical devices which also provide useful information to medical diagnosis. We
    refer the reader to Sec. 1.3 of the supplementary material where we discuss these
    data sources in detail, providing discussion related to their recent applications
    in deep learning research.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述主要数据类型外，我们还希望承认其他杂项数据来源，例如心音图（PCG）和可穿戴医疗设备，这些设备也提供了对医学诊断有用的信息。我们建议读者参阅补充材料第
    1.3 节，其中详细讨论了这些数据来源，并讨论了它们在深度学习研究中的最新应用。
- en: II-B Algorithmic Approaches for Medical Anomaly Detection
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 医疗异常检测的算法方法
- en: In this subsection, we summarise existing deep learning algorithms based on
    their training objectives, and whether labels for normal/abnormal are provided
    during training. In addition, Sec. [II-B3](#S2.SS2.SSS3 "II-B3 Recurrent Neural
    Networks (RNNs) ‣ II-B Algorithmic Approaches for Medical Anomaly Detection ‣
    II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning for Medical
    Anomaly Detection - A Survey") summarises popular recurrent deep neural network
    architectures used in the medical domain. Finally, a discussion of dimensionality
    differences between different data types, and how this is managed by existing
    deep learning research is presented.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们总结了现有的深度学习算法，基于其训练目标以及训练过程中是否提供正常/异常的标签。此外，第 [II-B3](#S2.SS2.SSS3 "II-B3
    循环神经网络（RNNs） ‣ II-B 医疗异常检测的算法方法 ‣ II 使用深度学习检测医疗异常 ‣ 医疗异常检测的深度学习 - 综述") 节总结了在医疗领域中常用的循环深度神经网络架构。最后，我们讨论了不同数据类型之间的维度差异，以及现有深度学习研究如何管理这些差异。
- en: II-B1 Unsupervised Anomaly Detection
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B1 无监督异常检测
- en: In unsupervised anomaly detection, no supervision signal (indicating if a sample
    is normal or abnormal) is provided during training. Therefore, unsupervised algorithms
    do not require labelled datasets, making them appealing to the machine learning
    community. Auto Encoders (AEs) and Generative Adversarial Networks (GANs) are
    two common unsupervised deep learning architectures, and are presented in the
    following subsections.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督异常检测中，训练过程中不提供监督信号（指示样本是否正常或异常）。因此，无监督算法不需要标记数据集，这使它们对机器学习社区具有吸引力。自编码器（AEs）和生成对抗网络（GANs）是两种常见的无监督深度学习架构，并在以下子章节中介绍。
- en: Auto Encoders (AEs) Since their introduction in [[25](#bib.bib25)] as a method
    for pre-training deep neural networks, AEs have been widely used for automatic
    feature learning [[26](#bib.bib26)]. Fig. [4](#S2.F4 "Figure 4 ‣ II-B1 Unsupervised
    Anomaly Detection ‣ II-B Algorithmic Approaches for Medical Anomaly Detection
    ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning for Medical
    Anomaly Detection - A Survey") illustrates the structure of an AE. They are symmetric
    and the model is trained to re-construct the input from a learned compressed representation,
    captured at the center of the architecture.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器（AEs）自从[[25](#bib.bib25)]被提出作为深度神经网络的预训练方法以来，已被广泛用于自动特征学习[[26](#bib.bib26)]。图[4](#S2.F4
    "Figure 4 ‣ II-B1 Unsupervised Anomaly Detection ‣ II-B Algorithmic Approaches
    for Medical Anomaly Detection ‣ II Detecting Medical Anomalies with Deep Learning
    ‣ Deep Learning for Medical Anomaly Detection - A Survey")展示了AE的结构。它们是对称的，模型被训练以从学习到的压缩表示（捕获在架构中心）重建输入。
- en: '![Refer to caption](img/1dba69ec212e9368c356e57631608761.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/1dba69ec212e9368c356e57631608761.png)'
- en: 'Figure 4: Illustration of the main components of an Auto Encoder.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：自编码器的主要组件示意图。
- en: Formally, let there be $N$ samples in the dataset, the current input be $x$,
    and $f$ and $g$ denote the encoder and decoder networks respectively. Then, the
    compressed representation, $z$, is given by,
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 正式地，设数据集中有$N$个样本，当前输入为$x$，$f$和$g$分别表示编码器和解码器网络。则压缩表示$z$由下式给出，
- en: '|  | $z=f(x),$ |  | (1) |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  | $z=f(x),$ |  | (1) |'
- en: and reconstructed using,
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 并通过以下公式重建，
- en: '|  | $y=g(z).$ |  | (2) |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '|  | $y=g(z).$ |  | (2) |'
- en: This model is trained to minimise the reconstruction loss,
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的训练目的是最小化重建损失，
- en: '|  | $\sum_{x\in N}{L(x,g(f(x)))},$ |  | (3) |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '|  | $\sum_{x\in N}{L(x,g(f(x)))},$ |  | (3) |'
- en: where $L$ is a distance function, which is commonly the Mean Squared Error (MSE).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$L$是一个距离函数，通常是均方误差（MSE）。
- en: There exist several variants of AEs. One of which is the sparse Auto Encoder
    (S-AE). An added sparsity constraint limits the number of non-zeros elements in
    the encoded representation, $z$. This is enforced by a penalty term added to the
    loss (i.e. Eq. [3](#S2.E3 "In II-B1 Unsupervised Anomaly Detection ‣ II-B Algorithmic
    Approaches for Medical Anomaly Detection ‣ II Detecting Medical Anomalies with
    Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey")),
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 存在几种不同的自编码器（AEs）变体。其中之一是稀疏自编码器（S-AE）。额外的稀疏性约束限制了编码表示$z$中非零元素的数量。这是通过添加一个惩罚项到损失中来强制执行的（即方程[3](#S2.E3
    "In II-B1 Unsupervised Anomaly Detection ‣ II-B Algorithmic Approaches for Medical
    Anomaly Detection ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning
    for Medical Anomaly Detection - A Survey")）。
- en: '|  | $L_{S-AE}=\sum_{x\in N}{L(x,g(f(x)))}+\lambda\frac{1}{&#124;N&#124;}\sum_{x\in
    N}&#124;f(x)&#124;,$ |  | (4) |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '|  | $L_{S-AE}=\sum_{x\in N}{L(x,g(f(x)))}+\lambda\frac{1}{|N|}\sum_{x\in N}|f(x)|,$
    |  | (4) |'
- en: where $\lambda$ is a hyper-parameter which controls the strength of the sparsity
    constraint.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\lambda$是一个超参数，用于控制稀疏性约束的强度。
- en: De-Noising AEs [[27](#bib.bib27)] learn to reconstruct a clean signal from a
    noisy (corrupted) input; with the aim being to leverage the de-noising capability
    to learn a robust and general feature encoding. Contractive AEs try to mitigate
    the sensitivity of AEs to perturbations of the input samples. A regularisation
    term is added to the loss defined (see Eq. [3](#S2.E3 "In II-B1 Unsupervised Anomaly
    Detection ‣ II-B Algorithmic Approaches for Medical Anomaly Detection ‣ II Detecting
    Medical Anomalies with Deep Learning ‣ Deep Learning for Medical Anomaly Detection
    - A Survey")) which measures the sensitivity of the learned embedding to small
    changes in the input. This sensitivity is measured using Frobenius Norm of the
    Jacobian matrix of the encoder [[26](#bib.bib26)].
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 去噪自编码器（De-Noising AEs）[[27](#bib.bib27)] 学会从嘈杂（损坏）的输入中重建干净的信号；其目的是利用去噪能力来学习稳健且通用的特征编码。收缩自编码器（Contractive
    AEs）试图减轻自编码器对输入样本扰动的敏感性。在定义的损失中添加了正则化项（参见 Eq. [3](#S2.E3 "In II-B1 Unsupervised
    Anomaly Detection ‣ II-B Algorithmic Approaches for Medical Anomaly Detection
    ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning for Medical
    Anomaly Detection - A Survey")），该项测量了所学习的嵌入对输入小变化的敏感性。使用编码器的雅可比矩阵的 Frobenius 范数来测量这种敏感性[[26](#bib.bib26)]。
- en: Finally, the Variational AE (VAE) assumes that the observations, $x$, are sampled
    from a probability distribution and seeks to estimate the parameters of this distribution.
    Formally, given observations, $x$, the VAE tries to approximate the latent distribution,
    $P_{\phi}$. Let ${\phi}$ represent the parameters of the distribution approximating
    the true latent distribution and ${\theta}$ represent the parameters of the sampled
    distribution, then the objective of the VAE is,
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，变分自编码器（VAE）假设观察值$x$是从概率分布中采样的，并试图估计该分布的参数。正式地，给定观察值$x$，VAE 试图近似潜在分布$P_{\phi}$。令${\phi}$表示近似真实潜在分布的分布参数，而${\theta}$表示采样分布的参数，则
    VAE 的目标是，
- en: '|  | $L_{VAE}(\theta,\phi;x)=\mathrm{KL}(P_{\phi}(z&#124;x)&#124;&#124;P_{\theta}(z))-\mathbb{E}_{P_{\phi}(z&#124;x)}(log(P_{\theta}(x&#124;z))),$
    |  | (5) |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|  | $L_{VAE}(\theta,\phi;x)=\mathrm{KL}(P_{\phi}(z&#124;x)&#124;&#124;P_{\theta}(z))-\mathbb{E}_{P_{\phi}(z&#124;x)}(log(P_{\theta}(x&#124;z))),$
    |  | (5) |'
- en: where $\mathrm{KL}$ is the Kullback-Leibler divergence.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathrm{KL}$是 Kullback-Leibler 散度。
- en: There have been a number of applications of auto-encoders for medical anomaly
    detection. In [[28](#bib.bib28)] the authors proposed an AE based method for early
    detection of respiratory diseases in pigs. The AE is composed of GRUs to learn
    from the recordings temporally. An EEG based anomaly detection method is proposed
    in [[29](#bib.bib29)] where the authors employ a Convolutional Neural Network
    (CNN) based AE. In [[30](#bib.bib30)], a 3D-CNN based AE is used to learn from
    volumetric CT scans.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器在医学异常检测中的应用已有多种。在[[28](#bib.bib28)]中，作者提出了一种基于 AE 的方法，用于早期检测猪的呼吸疾病。AE 由
    GRU 组成，用于从时间序列记录中学习。在[[29](#bib.bib29)]中，提出了一种基于 EEG 的异常检测方法，其中作者使用了基于卷积神经网络（CNN）的
    AE。在[[30](#bib.bib30)]中，使用了基于 3D-CNN 的 AE 从体积 CT 扫描中学习。
- en: In [[31](#bib.bib31)] a VAE based framework is proposed to detect anomalies
    in skin images. In [[32](#bib.bib32)] the authors introduce perturbations to evaluate
    the effect of input representation variations on the modeled representation; and
    propose a two branch structure where ‘context-dependent’ variations are also added
    to a VAE branch of the model. This method is validated on an MRI anomaly detection
    task. Another conditional model is proposed in [[33](#bib.bib33)] where the authors
    condition the VAE output on prior knowledge. The method has been validated on
    both 2D and 3D anomaly detection tasks.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[31](#bib.bib31)]中，提出了一种基于 VAE 的框架，用于检测皮肤图像中的异常。在[[32](#bib.bib32)]中，作者引入了扰动以评估输入表示变化对建模表示的影响；并提出了一种双分支结构，其中“上下文相关”的变化也被添加到
    VAE 模型的一个分支中。该方法在 MRI 异常检测任务上进行了验证。在[[33](#bib.bib33)]中，提出了另一种条件模型，其中作者将 VAE 输出条件化于先验知识。该方法已在
    2D 和 3D 异常检测任务中进行了验证。
- en: Despite their interesting characteristics, AEs have limited capabilities when
    modelling high-dimensional data distributions, often leading to erroneous re-constructions
    and inaccurate approximations of the modelled data distribution [[34](#bib.bib34)].
    Hence, another class of generative models, Generative Adversarial Networks, have
    received increasing attention.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管具有有趣的特性，自编码器在建模高维数据分布时能力有限，通常会导致错误的重建和对建模数据分布的不准确近似[[34](#bib.bib34)]。因此，另一类生成模型，即生成对抗网络，受到了越来越多的关注。
- en: 'Generative Adversarial Networks (GANs): Another class of AEs are adversarial
    AEs, more widely known as GANs [[35](#bib.bib35)]. They train two networks, a
    ‘Generator’ (G) and a ‘Discriminator’ (D), which play a min-max game. G tries
    to fool D, while D tries avoid being fooled.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络（GANs）：另一类自编码器（AE）是对抗性自编码器，更广为人知的是 GAN [[35](#bib.bib35)]。它们训练两个网络，一个是‘生成器’（G），另一个是‘判别器’（D），它们进行一个最小-最大游戏。G
    尝试欺骗 D，而 D 则试图避免被欺骗。
- en: '![Refer to caption](img/3af41ea736c959818b8fbbe71c02886a.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3af41ea736c959818b8fbbe71c02886a.png)'
- en: 'Figure 5: Main components in Generative Adversarial Networks'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：生成对抗网络的主要组件
- en: Fig. [5](#S2.F5 "Figure 5 ‣ II-B1 Unsupervised Anomaly Detection ‣ II-B Algorithmic
    Approaches for Medical Anomaly Detection ‣ II Detecting Medical Anomalies with
    Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey") illustrates
    the basic structure of GAN training. The generator receives noise sampled from
    $P_{z}(z)$ and seeks to learn a distribution of the true data, $P_{data}(x)$,
    modelling the mapping from noise space to the data space. The discriminator, $D$,
    outputs a scalar variable when given a synthesised (fake) or true (real) example.
    The discriminator is trained to output the correct label for the real/fake classification,
    and this objective can be written as,
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [5](#S2.F5 "图 5 ‣ II-B1 无监督异常检测 ‣ II-B 医学异常检测的算法方法 ‣ II 使用深度学习检测医学异常 ‣ 深度学习在医学异常检测中的应用
    - 综述") 说明了 GAN 训练的基本结构。生成器接收来自 $P_{z}(z)$ 的噪声，并尝试学习真实数据 $P_{data}(x)$ 的分布，建模从噪声空间到数据空间的映射。判别器
    $D$ 在给定合成（虚假）或真实（真实）示例时输出一个标量变量。判别器被训练为输出真实/虚假分类的正确标签，这一目标可以写成，
- en: '|  | $\min_{G}\max_{D}V(D,G)=\mathbb{E}_{x\sim P_{data}(x)}[logD(x)]+\mathbb{E}_{z\sim
    P_{z}(z)}[log1-D(G(z))].$ |  | (6) |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{G}\max_{D}V(D,G)=\mathbb{E}_{x\sim P_{data}(x)}[logD(x)]+\mathbb{E}_{z\sim
    P_{z}(z)}[log1-D(G(z))].$ |  | (6) |'
- en: While a supervised signal is provided to the discriminator for training the
    real/fake classification task, the real/fake classification is not the primary
    task and the model is not shown any anomalous examples. Hence, no supervision
    is given to the GAN framework regarding how to identify abnormalities, making
    it unsupervised.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然为判别器提供了监督信号以训练真实/虚假分类任务，但真实/虚假分类不是主要任务，并且模型没有看到任何异常示例。因此，GAN 框架没有得到关于如何识别异常的监督，使其成为无监督的。
- en: A popular sub-class of GANs are conditional-GANs (cGANs), in which both generator
    and discriminator outputs are conditioned on additional data, $c$. The cGAN objective
    is given by,
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 的一个流行子类是条件GAN（cGAN），在这种方法中，生成器和判别器的输出都依赖于额外的数据 $c$。cGAN 的目标是，
- en: '|  | $\min_{G}\max_{D}V(D,G)=\mathbb{E}_{x\sim P_{data}(x)}[logD(x&#124;c)]+\mathbb{E}_{z\sim
    P_{z}(z)}[log1-D(G(z&#124;c)&#124;c)].$ |  | (7) |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{G}\max_{D}V(D,G)=\mathbb{E}_{x\sim P_{data}(x)}[logD(x&#124;c)]+\mathbb{E}_{z\sim
    P_{z}(z)}[log1-D(G(z&#124;c)&#124;c)].$ |  | (7) |'
- en: cGANs are popular for tasks where the synthesised output should relate to a
    stimulus [[36](#bib.bib36), [37](#bib.bib37)].
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: cGAN 在合成输出应该与刺激相关的任务中非常受欢迎 [[36](#bib.bib36), [37](#bib.bib37)]。
- en: 'Cycle Consistency GANs (Cycle-GANs) are popular for image-to-image translation
    tasks. Cycle-GANs provide an additional constraint to the framework: that the
    original input can be synthesised from the generated output.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 循环一致性 GAN（Cycle-GAN）在图像到图像转换任务中非常受欢迎。Cycle-GAN 为框架提供了额外的约束：即原始输入可以从生成的输出中合成出来。
- en: An example application of GANs for medical anomaly detection is in Schlegl et.
    al [[38](#bib.bib38)], where the authors used a GAN framework for anomaly detection
    in Optical Coherence Tomography (OCT). They trained a GAN to generate normal OCT
    scans using the latent distribution $z$. Then an encoder is used to map normal
    OCT scans to $z$. Hence, it should be possible to recover an identical image when
    mapping from the image to $z$ using the encoder, and from $z$ to image using the
    generator. When there are anomalies the authors show that there exist discrepancies
    in this translation, and identify anomalies using this process.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 在医学异常检测中的一个应用示例是 Schlegl 等人 [[38](#bib.bib38)]，作者使用 GAN 框架进行光学相干断层扫描（OCT）中的异常检测。他们训练了一个
    GAN 以使用潜在分布 $z$ 生成正常的 OCT 扫描。然后，使用编码器将正常的 OCT 扫描映射到 $z$。因此，当从图像映射到 $z$ 使用编码器时，并从
    $z$ 到图像使用生成器时，应该能够恢复出相同的图像。当存在异常时，作者表明这种转换中存在差异，并利用此过程识别异常。
- en: II-B2 Supervised Anomaly Detection
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B2 监督异常检测
- en: Considering the requirement for a high degree of sensitivity and robustness,
    particularly due to the diagnostic applications, supervised learning has been
    widely applied for medical anomaly detection and has demonstrated superior performance
    to unsupervised methods. In contrast to unsupervised learning methods (see Sec.
    [II-B1](#S2.SS2.SSS1 "II-B1 Unsupervised Anomaly Detection ‣ II-B Algorithmic
    Approaches for Medical Anomaly Detection ‣ II Detecting Medical Anomalies with
    Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey")), in
    supervised anomaly detection a supervised signal is provided indicating which
    examples are from the normal category and which are anomalous. Hence, this is
    actually a binary classification task and models are typically trained using binary
    cross entropy loss [[39](#bib.bib39)],
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到对高敏感性和鲁棒性的要求，特别是由于诊断应用，监督学习已广泛应用于医学异常检测，并且表现出优于无监督方法的性能。与无监督学习方法（参见第 [II-B1](#S2.SS2.SSS1
    "II-B1 无监督异常检测 ‣ II-B 医学异常检测的算法方法 ‣ II 使用深度学习检测医学异常 ‣ 深度学习在医学异常检测中的应用 - 综述")），在监督异常检测中，提供了一个监督信号，指示哪些示例来自正常类别，哪些是异常的。因此，这实际上是一个二分类任务，模型通常使用二分类交叉熵损失进行训练
    [[39](#bib.bib39)]，
- en: '|  | $L=-ylog(f(x))-(1-y)log(1-f(x)),$ |  | (8) |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|  | $L=-y\log(f(x))-(1-y)\log(1-f(x)),$ |  | (8) |'
- en: where $y$ is the ground truth label, $f$ is the classifier and $x$ is the input
    to the model. Example architectures include the CNN structures in [[40](#bib.bib40)]
    and [[41](#bib.bib41)] where they employ supervised learning to identify anomalies
    in retina images and for automated classification of skin lesions, respectively.
    In [[42](#bib.bib42)] a deep belief network is trained to detect seizures in EEG
    data.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $y$ 是真实标签，$f$ 是分类器，$x$ 是模型的输入。示例架构包括 [[40](#bib.bib40)] 和 [[41](#bib.bib41)]
    中的 CNN 结构，它们分别用于通过监督学习识别视网膜图像中的异常和自动分类皮肤病变。在 [[42](#bib.bib42)] 中，训练了一个深度信念网络以检测脑电图数据中的癫痫发作。
- en: Multi-task Learning (MtL) is a sub category of supervised learning, and seeks
    to share relevant information among several related tasks rather than learning
    them individually [[43](#bib.bib43)]. For instance, to overcome challenges which
    arise due to subject specific variations, a secondary subject identification task
    can be coupled with the primary abnormality detection task. Hence, the model learns
    to identify similarities and differences among subjects while learning to classify
    abnormalities. Several studies have leveraged MtL in the medical domain. In [[43](#bib.bib43)]
    an efficient kernel learning structure for multiple tasks is proposed and applied
    to regress Parkinson’s disease symptom scores. In [[44](#bib.bib44)] a multi-task
    learning strategy is formulated through detection and localisation of lesions
    in medical images, which jointly learns to detect suspicious images and segment
    regions of interest in those images.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务学习（MtL）是监督学习的一个子类别，旨在在多个相关任务之间共享相关信息，而不是单独学习这些任务 [[43](#bib.bib43)]。例如，为了克服由于个体特异性变异带来的挑战，可以将一个次要的个体识别任务与主要的异常检测任务结合起来。因此，模型在学习分类异常的同时，学会识别个体之间的相似性和差异性。多个研究在医学领域利用了
    MtL。在 [[43](#bib.bib43)] 中，提出了一种高效的多任务内核学习结构，并应用于回归帕金森病症状评分。在 [[44](#bib.bib44)]
    中，通过检测和定位医学图像中的病变，制定了多任务学习策略，该策略共同学习检测可疑图像并分割这些图像中的感兴趣区域。
- en: The deep learning architectures discussed so far are feed-forward architectures,
    i.e. the data travels in one direction, from input to output. This limits their
    ability to model temporal signals. To address this limitation, Recurrent Neural
    Networks are introduced.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止讨论的深度学习架构是前馈架构，即数据沿着一个方向流动，从输入到输出。这限制了它们建模时间信号的能力。为了解决这个限制，引入了递归神经网络（RNN）。
- en: II-B3 Recurrent Neural Networks (RNNs)
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B3 递归神经网络（RNNs）
- en: Recurrence is a critical characteristic for tasks such as time-series modelling,
    and means the output of the current time step is also fed as an input to the next
    time step.In medical data processing, this is important for modelling sequential
    data such as EEG and Phonocardiographic data, where we are concerned with the
    temporal evolution of the signal.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 递归是时间序列建模等任务的一个关键特征，意味着当前时间步的输出也会作为输入传递到下一个时间步。在医学数据处理方面，这对于建模诸如脑电图（EEG）和心音图数据这样的序列数据非常重要，因为我们关心的是信号的时间演变。
- en: '![Refer to caption](img/f1921735d200f1234199f86dec17abb0.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f1921735d200f1234199f86dec17abb0.png)'
- en: 'Figure 6: Illustration of Recurrent Neural Network structure and how it temporally
    unrolls.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '图 6: 递归神经网络结构的示意图及其时间展开。'
- en: Fig. [6](#S2.F6 "Figure 6 ‣ II-B3 Recurrent Neural Networks (RNNs) ‣ II-B Algorithmic
    Approaches for Medical Anomaly Detection ‣ II Detecting Medical Anomalies with
    Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey") illustrates
    the basic structure of an RNN, where we show how it temporally unrolls. This structure
    requires the use of Backpropagation Through Time (BPTT) [[45](#bib.bib45)], as
    the gradient of the error at a given time step depends upon the prediction at
    the previous time step, and errors accumulate over time. Despite their interesting
    characteristics, vanishing gradients [[46](#bib.bib46), [47](#bib.bib47)] are
    a major drawback of simple RNN structures due to BPTT, and this makes them ineffective
    for modelling long-term dependencies (relationships between distant time-steps).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [6](#S2.F6 "Figure 6 ‣ II-B3 Recurrent Neural Networks (RNNs) ‣ II-B Algorithmic
    Approaches for Medical Anomaly Detection ‣ II Detecting Medical Anomalies with
    Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey") 展示了 RNN
    的基本结构，包括时间展开。这种结构要求使用时间反向传播（BPTT）[[45](#bib.bib45)]，因为给定时间步的误差梯度依赖于前一个时间步的预测，并且随着时间的推移误差会积累。尽管具有很有趣的特性，简单的
    RNN 结构由于 BPTT 导致梯度消失[[46](#bib.bib46), [47](#bib.bib47)]，这使得它们对建模长期依赖性（远距离时间步之间的关系）不起作用。
- en: 'Several RNN variants have been introduced to address this limitations. In the
    following sections we illustrate three of such popular variants: Long Short-Term
    Memory (LSTM) Networks, Gated Recurrent Units (GRUs) and Neural Memory Networks
    (NMNs).'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 已经提出了几种 RNN 变体来解决这些限制。在下面的章节中，我们介绍了三种流行的变体：长短期记忆（LSTM）网络、门控循环单元（GRU）和神经记忆网络（NMN）。
- en: Long Short-Term Memory (LSTM) [[10](#bib.bib10)] networks are specifically designed
    to model long-term dependencies which are ill represented by RNNs due to vanishing
    gradients. They introduce a ‘memory cell’ (or cell state) to capture long-term
    dependencies, and a series of gated operations to manipulate the information stored
    in the memory and update it over time. The core idea behind LSTMs is that long-term
    dependencies can be stored in the cell state [[10](#bib.bib10)].
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 长短期记忆（LSTM）[[10](#bib.bib10)] 网络专门设计来模拟 RNN 不能很好表示的长期依赖性。它们引入了一个 “记忆单元”（或称为状态单元）来捕捉长期依赖性，并使用一系列门操作来操作存储在记忆中的信息并随时间更新。LSTM
    的核心思想是长期依赖性可以存储在状态单元中[[10](#bib.bib10)]。
- en: '![Refer to caption](img/2ab415acd07423c8e95b804acfa715fd.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/2ab415acd07423c8e95b804acfa715fd.png)'
- en: 'Figure 7: Visual illustration of Long Short-Term Memory cell.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7: 长短期记忆单元的可视化示意图。'
- en: There are three gates which control what is retrieved from and written to the
    cell state. The ‘forget gate’ determines what portion of information from the
    previous time step is kept at the current time step. It is controlled by the output
    at the previous time step and the current input, and has a value between 0 and
    1 to control information flow (See Fig. [7](#S2.F7 "Figure 7 ‣ II-B3 Recurrent
    Neural Networks (RNNs) ‣ II-B Algorithmic Approaches for Medical Anomaly Detection
    ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning for Medical
    Anomaly Detection - A Survey")). This can be written as,
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个门控制从和写入到状态单元的信息。 “遗忘门” 决定保留在当前时间步上一个时间步的信息的部分。它由上一个时间步的输出和当前输入控制，其值在 0 和
    1 之间以控制信息流动（参见图 [7](#S2.F7 "Figure 7 ‣ II-B3 Recurrent Neural Networks (RNNs)
    ‣ II-B Algorithmic Approaches for Medical Anomaly Detection ‣ II Detecting Medical
    Anomalies with Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A
    Survey")）。可以表示为，
- en: '|  | $f_{t}=\sigma(w^{f}[h_{t-1},x_{t}]+b^{f}),$ |  | (9) |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '|  | $f_{t}=\sigma(w^{f}[h_{t-1},x_{t}]+b^{f}),$ |  | (9) |'
- en: where $w^{f}$ and $b^{f}$ are the gate’s weights and bias, $h_{t-1}$ is the
    previous time step’s output, $x_{t}$ is the current input and $\sigma$ is a sigmoid
    function.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $w^{f}$ 和 $b^{f}$ 是门的权重和偏置，$h_{t-1}$ 是上一时间步的输出，$x_{t}$ 是当前输入，$\sigma$ 是一个
    sigmoid 函数。
- en: The ‘input gate’ decides what information is written to the cell. Similar to
    the previous gate we have a function deciding what portion of information to write,
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: “输入门”决定写入单元中的信息。与前一个门类似，我们有一个函数来确定要写入的信息的部分，
- en: '|  | $g_{t}=\sigma(w^{i}[h_{t-1},x_{t}]+b^{i}),$ |  | (10) |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|  | $g_{t}=\sigma(w^{i}[h_{t-1},x_{t}]+b^{i}),$ |  | (10) |'
- en: and we use a $\mathrm{tanh}$ function to generate the information to write,
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 $\mathrm{tanh}$ 函数来生成写入的信息，
- en: '|  | $\tilde{c}_{t}=\mathrm{tanh}(w^{c}[h_{t-1},x_{t}]+b^{c}).$ |  | (11) |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '|  | $\tilde{c}_{t}=\mathrm{tanh}(w^{c}[h_{t-1},x_{t}]+b^{c}).$ |  | (11) |'
- en: Then the cell state can be updated using,
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以使用以下公式更新单元状态，
- en: '|  | $c_{t}=f_{t}\times c_{t-1}+i_{t}\times\tilde{c}_{t}.$ |  | (12) |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|  | $c_{t}=f_{t}\times c_{t-1}+i_{t}\times\tilde{c}_{t}.$ |  | (12) |'
- en: The information from the previous cell state and the current time step are controlled
    via the forget and input gate values. The final step is to decide what information
    to output from the cell at the current time step. This is done through the output
    gate,
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 来自先前单元状态的信息和当前时间步的信息通过遗忘门和输入门值进行控制。最后一步是决定在当前时间步从单元中输出什么信息。这是通过输出门完成的，
- en: '|  | $o_{t}=\sigma(w^{o}[h_{t-1},x_{t}]+b^{o}),$ |  | (13) |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '|  | $o_{t}=\sigma(w^{o}[h_{t-1},x_{t}]+b^{o}),$ |  | (13) |'
- en: and, $h_{t}$, the current time step’s output is given by,
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 并且，$h_{t}$，当前时间步的输出由以下公式给出，
- en: '|  | $h_{t}=o_{t}\times\mathrm{tanh}(c_{t}).$ |  | (14) |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|  | $h_{t}=o_{t}\times\mathrm{tanh}(c_{t}).$ |  | (14) |'
- en: Gated Recurrent Units (GRUs) are a popular variant of the LSTM which were introduced
    by Cho et. al in 2014 [[48](#bib.bib48)]. They combine the forget gate and input
    gate into a single ‘update gate’. Specifically, Eq. [12](#S2.E12 "In II-B3 Recurrent
    Neural Networks (RNNs) ‣ II-B Algorithmic Approaches for Medical Anomaly Detection
    ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning for Medical
    Anomaly Detection - A Survey") becomes,
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 门控递归单元（GRUs）是LSTM的一种流行变体，由Cho等人于2014年引入[[48](#bib.bib48)]。它们将遗忘门和输入门合并为一个“更新门”。具体地，方程[12](#S2.E12
    "In II-B3 Recurrent Neural Networks (RNNs) ‣ II-B Algorithmic Approaches for Medical
    Anomaly Detection ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning
    for Medical Anomaly Detection - A Survey")变为，
- en: '|  | $c_{t}=f_{t}\times c_{t-1}+(1-f_{t})\times\tilde{c}_{t}.$ |  | (15) |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '|  | $c_{t}=f_{t}\times c_{t-1}+(1-f_{t})\times\tilde{c}_{t}.$ |  | (15) |'
- en: Neural Memory Networks (NMNs) are another variant of RNNs, where an external
    memory stack is used to store information. A limitation of LSTMs and GRUs is that
    content is erased when a new sequence is presented [[49](#bib.bib49), [50](#bib.bib50)],
    as these architectures are designed to map temporal relationships within a sequence,
    not between sequences [[49](#bib.bib49), [50](#bib.bib50), [51](#bib.bib51), [52](#bib.bib52)].
    Hence, the limited capacity of the internal cell state is insufficient to model
    relationships across a large corpus [[53](#bib.bib53), [49](#bib.bib49)].
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 神经记忆网络（NMNs）是RNN的另一种变体，其中使用外部记忆堆栈来存储信息。LSTMs和GRUs的一个限制是，当呈现新序列时，内容会被擦除[[49](#bib.bib49),
    [50](#bib.bib50)]，因为这些架构设计用于映射序列内的时间关系，而不是序列之间的关系[[49](#bib.bib49), [50](#bib.bib50),
    [51](#bib.bib51), [52](#bib.bib52)]。因此，内部单元状态的有限容量不足以建模跨大语料库的关系[[53](#bib.bib53),
    [49](#bib.bib49)]。
- en: '![Refer to caption](img/afd713f047acfdf84680579d275df3e8.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/afd713f047acfdf84680579d275df3e8.png)'
- en: 'Figure 8: Illustration of the main components of a Neural Memory Network.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：神经记忆网络的主要组成部分示意图。
- en: Fig. [8](#S2.F8 "Figure 8 ‣ II-B3 Recurrent Neural Networks (RNNs) ‣ II-B Algorithmic
    Approaches for Medical Anomaly Detection ‣ II Detecting Medical Anomalies with
    Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey") illustrates
    a typical NMN architecture, which is composed of a memory stack to store information,
    and a set of controllers (read, output and write) to manipulate the memory. There
    are similarities between the LSTM gated operations and these controllers which
    manipulate the external memory. Specifically, let the state of the external memory,
    $M\in\mathbb{R}^{k\times l}$, at time instance $t-1$ be given by $M_{t-1}$, where
    $l$ is the number of memory slots and $k$ is the size of each slot. The current
    input is denoted $x_{t}$. Then the read controller, $f^{r}$, generates a vector,
    $q_{t}$, to query the memory,
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图[8](#S2.F8 "Figure 8 ‣ II-B3 Recurrent Neural Networks (RNNs) ‣ II-B Algorithmic
    Approaches for Medical Anomaly Detection ‣ II Detecting Medical Anomalies with
    Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey")展示了一个典型的神经记忆网络（NMN）架构，该架构由一个用于存储信息的记忆堆栈和一组控制器（读取、输出和写入）组成，以操作记忆。LSTM门控操作与这些操作外部记忆的控制器之间有相似之处。具体地，设外部记忆的状态为$M\in\mathbb{R}^{k\times
    l}$，在时间点$t-1$时为$M_{t-1}$，其中$l$是记忆槽的数量，$k$是每个槽的大小。当前输入记作$x_{t}$。然后读取控制器$f^{r}$生成一个向量$q_{t}$来查询记忆，
- en: '|  | $q_{t}=f^{r}(x_{t}).$ |  | (16) |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '|  | $q_{t}=f^{r}(x_{t}).$ |  | (16) |'
- en: Using a softmax function we measure the similarity between the content of each
    memory slot and the query vector such that,
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 使用softmax函数，我们测量每个记忆槽的内容与查询向量之间的相似度，如下所示，
- en: '|  | $z_{t}=\textrm{softmax}({q_{t}}^{\top}M_{t-1}).$ |  | (17) |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '|  | $z_{t}=\textrm{softmax}({q_{t}}^{\top}M_{t-1}).$ |  | (17) |'
- en: The score vector, $z_{t}$, capture the relevance of the memory content to the
    current input. This parallels the input gate functionality of an LSTM, which determines
    what information to extract from the history. However, in contrast to the LSTM
    where there is only one vector storing historical information, the NMN has multiple
    memory blocks to consider. Hence, attention is employed to extract the most relevant
    information.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 得分向量$z_{t}$捕获内存内容与当前输入的相关性。这与LSTM的输入门功能相类似，LSTM决定从历史中提取哪些信息。然而，与LSTM中只有一个向量存储历史信息不同，NMN需要考虑多个内存块。因此，采用了注意力机制来提取最相关的信息。
- en: The output controller, $f_{o}$, generates the output such that,
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 输出控制器$f_{o}$生成输出，使得，
- en: '|  | $\bar{m}_{t}=z_{t}[M_{t-1}]^{\top},$ |  | (18) |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '|  | $\bar{m}_{t}=z_{t}[M_{t-1}]^{\top},$ |  | (18) |'
- en: and,
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 并且，
- en: '|  | $m_{t}=f^{o}(\bar{m}_{t}).$ |  | (19) |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|  | $m_{t}=f^{o}(\bar{m}_{t}).$ |  | (19) |'
- en: This aligns with the output gate functionality of the LSTM, using the input
    at the current time-step and information retrieved from the memory to compose
    the output. Finally, the write controller, $f^{w}$, generates a vector to update
    the memory,
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这与LSTM的输出门功能相一致，使用当前时间步的输入和从内存中检索的信息来组成输出。最后，写控制器$f^{w}$生成一个向量以更新内存，
- en: '|  | $m^{\prime}_{t}=f^{w}(m_{t}),$ |  | (20) |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '|  | $m^{\prime}_{t}=f^{w}(m_{t}),$ |  | (20) |'
- en: and updates the memory using,
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 并使用下列公式更新内存，
- en: '|  | $M_{t}=M_{t-1}(I-z_{t}\otimes e_{k})^{\top}+(m^{\prime}_{t}\otimes e_{l})(z_{t}\otimes
    e_{k})^{\top},$ |  | (21) |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '|  | $M_{t}=M_{t-1}(I-z_{t}\otimes e_{k})^{\top}+(m^{\prime}_{t}\otimes e_{l})(z_{t}\otimes
    e_{k})^{\top},$ |  | (21) |'
- en: where $I$ is a matrix of ones, $e_{l}\in\mathbb{R}^{l}$ and $e_{k}\in\mathbb{R}^{k}$
    are vectors of ones and $\otimes$ denotes the outer product which duplicates its
    left vector $l$ or $k$ times to form a matrix [[54](#bib.bib54), [1](#bib.bib1)].
    As NMNs are a relatively new concept we refer interested readers to [[53](#bib.bib53)]
    for further details.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$I$是一个全1矩阵，$e_{l}\in\mathbb{R}^{l}$和$e_{k}\in\mathbb{R}^{k}$是全1向量，而$\otimes$表示外积，它将其左向量重复$l$次或$k$次以形成一个矩阵[[54](#bib.bib54),
    [1](#bib.bib1)]。由于NMN是一个相对较新的概念，我们建议感兴趣的读者参考[[53](#bib.bib53)]以获取更多细节。
- en: While the exact memory update mechanisms for LSTMs and NMNs are dissimilar,
    we would like to highlight the parallels between the LSTM forget gate and the
    write controller. The LSTM forget gate considers the current time-step’s input
    and the previous cell state (i.e memory) and determines what to pass through from
    the history. Similarly, the write controller, utilising the NMN output and the
    retrieved historical information, determines what memory slots to update.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然LSTM和NMN的内存更新机制不完全相同，但我们想强调LSTM的遗忘门和写控制器之间的相似性。LSTM的遗忘门考虑当前时间步的输入和之前的单元状态（即内存），并决定从历史中传递什么信息。同样，写控制器利用NMN的输出和检索的历史信息，决定更新哪些内存槽。
- en: There are numerous works that have utilised RNNs for medical anomaly detection.
    For instance, RNNs have been used in [[55](#bib.bib55)] and [[56](#bib.bib56)]
    for text based abnormality detection in electronic health records; and in [[57](#bib.bib57)]
    to detect abnormal heart beats in Phonocardiographic recordings.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多研究利用了RNN进行医学异常检测。例如，RNN已在[[55](#bib.bib55)]和[[56](#bib.bib56)]中用于电子健康记录中的基于文本的异常检测；以及在[[57](#bib.bib57)]中用于在心音图记录中检测异常心跳。
- en: More recently, NMNs have been applied in medical anomaly detection, where works
    have illustrated the value of external memory storage to memorise similarities
    and differences between normal and anomalous examples. Specifically, in [[1](#bib.bib1)]
    the authors couple an NMN with a neural plasticity framework to identify tumors
    in MRI scans and abnormalities in EEGs. Furthermore, in [[58](#bib.bib58)] the
    same architecture is used to identify different seizure types in EEGs.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，NMN已被应用于医学异常检测，其中的研究展示了外部内存存储在记忆正常和异常样本之间的相似性和差异性的价值。具体而言，在[[1](#bib.bib1)]中，作者将NMN与神经可塑性框架结合，以识别MRI扫描中的肿瘤和EEG中的异常。此外，在[[58](#bib.bib58)]中，使用相同的架构来识别EEG中的不同癫痫类型。
- en: II-C Background and Related Applications
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 背景和相关应用
- en: This subsection provides a detailed discussion of popular application domains
    within deep medical anomaly detection, illustrating how previously discussed architectural
    variants are leveraged in these domains.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 本小节详细讨论了深度医学异常检测中的热门应用领域，说明了之前讨论的架构变体如何在这些领域中得到应用。
- en: II-C1 MRI based Anomaly Detection
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-C1 基于MRI的异常检测
- en: In this section we summarize some of key recent literature in deep learning
    based anomaly detection with MRI data. Fusion of modalities has been a popular
    research direction which has recently emerged for MRI analysis. In [[59](#bib.bib59)]
    the authors investigate the fusion of T1-weighted (T1w) MRIs and myelin water
    imaging of MRIs (which is a quantitative MRI technique that specifically measures
    myelin content) for diagnosis of Multiple sclerosis (MS). In their proposed architecture,
    they utilise two modality specific Deep Belief Networks (DBN) [[60](#bib.bib60)]
    to extract features from the individual T1w and myelin maps. This is followed
    by a multi-modal DBN which jointly learns complementary information from both
    modes. They retrieve a multi-modal feature vector by concatenating the top-level
    hidden unit activations of the multimodal DBN. As the final step a Random Forest
    [[61](#bib.bib61)] is trained to detect abnormalities. The proposed algorithm
    is validated using an in-house dataset, which consists of 55 relapse-remitting
    MS patients and 44 healthy controls. The classification accuracy was $70.1\pm
    13.6$% and $83.8\pm 11.0$ % for T1w and myelin map modalities, respectively, while
    the fused representation achieved $87.9\pm 8.4$ %.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们总结了最近关于基于深度学习的 MRI 数据异常检测的关键文献。融合多模态成为最近 MRI 分析中出现的研究方向。在 [[59](#bib.bib59)]
    中，作者们研究了T1加权（T1w）MRI和MRI的髓鞘水成像（这是一种特别测量髓鞘含量的定量MRI技术）在多发性硬化（MS）诊断中的融合。在他们提出的结构中，他们利用两种模态特定的深信念网络（DBN）[[60](#bib.bib60)]
    从个体 T1w 和髓鞘图中提取特征。然后使用多模态DBN共同学习两种模式的互补信息。他们通过连接多模态DBN的顶层隐藏单元激活来检索多模态特征向量。最后，使用随机森林[[61](#bib.bib61)]
    对异常进行训练。提出的算法使用内部数据集进行验证，该数据集包括 55 名复发缓解型 MS 患者和 44 名健康对照者。 T1w 和髓鞘图模态的分类准确率分别为
    $70.1\pm 13.6$% 和 $83.8\pm 11.0$%，而融合表现达到了 $87.9\pm 8.4$%。
- en: A strategy to fuse MRI images with fluorodeoxyglucose positron emission tomography
    (FDG-PET) samples has been proposed in [[62](#bib.bib62)]. In their approach,
    the authors first segment the MRI images into gray and white matter regions, followed
    by subdivision of the gray matter into 87 anatomical Regions Of Interest (ROI).
    Then they extract patches of sizes 1488, 705 and 343 from these regions. Similar
    size patches are also extracted from FDG-PET images. Then 6 independent Deep Neural
    Networks (DNNs) with dense layers are used to embed patch information and another
    DNN is used to fuse the encoded embedding. A softmax layer is used generate the
    final abnormality classification. The authors utilise this architecture to detect
    pathologies related to Alzheimer’s Disease and the framework is evaluated using
    publicly available Alzheimer’s Disease Neuroimaging Initiative (ADNI) database
    [[63](#bib.bib63)], which contains 1242 subjects. The proposed method achieves
    82.93 % accuracy and an approximately 1.5% improvement over utilising FDG-PET
    alone.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [[62](#bib.bib62)] 中提出了一种融合 MRI 图像与氟脱氧葡萄糖正电子发射断层扫描（FDG-PET）样本的策略。在他们的方法中，作者首先将
    MRI 图像分割为灰白质区域，然后将灰质分成 87 个解剖感兴趣区（ROI）。然后从这些区域提取尺寸为 1488、705 和 343 的补丁。同样大小的补丁也从
    FDG-PET 图像中提取。然后使用 6 个独立的具有密集层的深度神经网络（DNN）来嵌入补丁信息，并使用另一个 DNN 来融合编码嵌入。使用 softmax
    层生成最终的异常分类。作者们利用这种架构来检测与阿尔茨海默病相关的病理，并使用公开可用的阿尔茨海默病神经影像学倡议（ADNI）数据库[[63](#bib.bib63)]
    进行评估，该数据库包含 1242 名受试者。提出的方法实现了 82.93% 的准确率，比仅使用 FDG-PET 提高了约 1.5%。
- en: A method to fuse Apparent Diffusion Coefficients (ADCs) of MRIs together with
    T2-weighted MRI images (T2w) is proposed in [[64](#bib.bib64)]. In contrast to
    predicting a single score level classification, they proposed a method which outputs
    a segmentation map for each modality, indicating the likelihood of each pixel
    belonging to the class of interest. They propose to utilise a novel similarity
    loss function such that the ADC and T2WI streams produce consistent predictions,
    allowing complementary information to be shared between the streams. The initial
    segmentation maps are combined with hand-crafted features and passed through an
    SVM to generate the final predictions. Evaluations were carried out using a dataset
    with 364 subjects, with a total of 463 prostate cancer lesions and 450 identified
    noncancerous image patches in which the framework achieves a sensitivity of 89.85%
    and a specificity of 95.83% for distinguishing cancerous from non-cancerous tissues.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[64](#bib.bib64)]中提出了一种将MRI的表观扩散系数（ADC）与T2加权MRI图像（T2w）融合的方法。与预测单一评分级别分类相反，他们提出了一种方法，该方法输出每种模态的分割图，指示每个像素属于感兴趣类别的可能性。他们提出利用一种新颖的相似性损失函数，使得ADC和T2WI流产生一致的预测，从而允许流之间共享互补信息。初步分割图与手工特征结合，并通过SVM生成最终预测。评估使用了一个包含364个受试者的数据集，共有463个前列腺癌病灶和450个识别出的非癌性图像块，在这个框架下，实现了89.85%的灵敏度和95.83%的特异性，以区分癌性与非癌性组织。
- en: 'In contrast to the above approach which employs feature level fusion, an architecture
    using decision level fusion in proposed in [[65](#bib.bib65)]. The proposed approach
    has an ensemble of classifiers composed of 3 convolutional neural networks which
    are trained separately. Each network provides a softmax classification denoting
    the likelihood of four Alzheimer’s disease classes: non-demented, very mild, mild
    and moderate. The fusion of the individual classifications is performed using
    majority voting. The evaluation is conducted on the public OASIS dataset [[66](#bib.bib66)]
    which consists of 416 subjects, and the proposed ensemble method achieves 94 %
    precision and 93 % recall.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述采用特征级融合的方法不同，[[65](#bib.bib65)]中提出了一种使用决策级融合的架构。该方法有一个由3个卷积神经网络组成的分类器集合，这些网络分别训练。每个网络提供一个softmax分类，表示四种阿尔茨海默病类别的可能性：非痴呆、非常轻度、轻度和中度。个别分类的融合通过多数投票完成。评估是在公共的OASIS数据集[[66](#bib.bib66)]上进行的，该数据集包含416个受试者，提出的集合方法实现了94%的精准率和93%的召回率。
- en: Despite the architectural differences, the above discussed methods are all supervised
    Deep CNN (DCNN) models and these dominate the MRI based anomaly detection literature.
    This is clearly motivated by the fact that supervised CNN models are highly effective
    when extracting task specific spatial information from two dimensional inputs.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管架构有所不同，上述讨论的方法都是监督式深度卷积神经网络（DCNN）模型，这些模型主导了基于MRI的异常检测文献。这显然是因为监督式CNN模型在从二维输入中提取任务特定空间信息时非常有效。
- en: Despite the prevalence of supervised DCNN models, a number of approaches have
    also used Auto-Encoders (AE) [[67](#bib.bib67), [68](#bib.bib68)]. In [[68](#bib.bib68)]
    an AE network with a sparsity constraint has been proposed for the diagnosis of
    individuals with schizophrenia. First the AE is trained in an unsupervised manner
    for feature extraction and in the second stage the authors use validation set
    of the dataset to fine tune the network after adding a softmax layer to the AE.
    As the final stage a linear support vector machine is used to classify samples.
    The system is validated using a large scale MRI dataset which is collected from
    7 image sources and consists of 474 patients with schizophrenia and 607 healthy
    controls. This model achieves approximately 85 % accuracy in a k-fold cross validation
    setting. Similarly, in [[67](#bib.bib67)] an AE is trained for early detection
    of acute renal transplant rejection. As the first stage the AE is trained in an
    unsupervised manner. To classify inputs, the decoder of the AE is removed and
    a softmax layer is trained using supervised learning. This method achieves 97%
    classification accuracy in a leave-one-subject-out experimental setting on 100
    subjects.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管监督的深度卷积神经网络（DCNN）模型很常见，但也有许多方法使用了自编码器（AE）[[67](#bib.bib67), [68](#bib.bib68)]。在[[68](#bib.bib68)]中，提出了一种具有稀疏性约束的AE网络，用于诊断精神分裂症患者。首先，AE以无监督方式进行特征提取训练；在第二阶段，作者使用数据集的验证集来微调网络，在AE中添加一个softmax层。作为最终阶段，使用线性支持向量机对样本进行分类。该系统使用了从7个图像来源收集的大规模MRI数据集进行验证，数据集中包括474名精神分裂症患者和607名健康对照组。该模型在k折交叉验证设置中实现了约85%的准确率。类似地，在[[67](#bib.bib67)]中，AE被训练用于急性肾移植排斥的早期检测。在第一阶段，AE以无监督方式进行训练。为了分类输入，移除了AE的解码器，并使用监督学习训练了一个softmax层。这种方法在100名受试者的留一法实验设置中实现了97%的分类准确率。
- en: Critically, unlike the unsupervised AE models discussed in Sec. [II-B1](#S2.SS2.SSS1
    "II-B1 Unsupervised Anomaly Detection ‣ II-B Algorithmic Approaches for Medical
    Anomaly Detection ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning
    for Medical Anomaly Detection - A Survey") these models are not purely unsupervised
    architectures. Rather after the preliminary training of the AE, a classification
    layer is added and trained using a supervised signal to detect anomalies.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 批判性地，与第[II-B1](#S2.SS2.SSS1 "II-B1 无监督异常检测 ‣ II-B 医疗异常检测的算法方法 ‣ II 利用深度学习检测医疗异常
    ‣ 医疗异常检测的深度学习综述")节中讨论的无监督自编码器（AE）模型不同，这些模型并非完全无监督架构。相反，在AE的初步训练之后，会添加一个分类层，并使用监督信号进行训练以检测异常。
- en: In a different line of work, a multi-scale multi-task learning framework is
    proposed in [[69](#bib.bib69)] for diagnosis of Lumbar Neural Foraminal Stenosis
    (LNFS). Fig. [9](#S2.F9 "Figure 9 ‣ II-C1 MRI based Anomaly Detection ‣ II-C Background
    and Related Applications ‣ II Detecting Medical Anomalies with Deep Learning ‣
    Deep Learning for Medical Anomaly Detection - A Survey") illustrates the architecture
    used. The authors show that each lumbar spine image can have multiple organs captured
    at various scales. Furthermore, they illustrate that multi-task learning can be
    used such that learning from multiple related tasks can boost learning, as discussed
    in Sec. [II-B2](#S2.SS2.SSS2 "II-B2 Supervised Anomaly Detection ‣ II-B Algorithmic
    Approaches for Medical Anomaly Detection ‣ II Detecting Medical Anomalies with
    Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey"), and
    we note that this strategy is seen across multiple applications domains. Feature
    maps are extracted at multiple scales and at each level the model tries to perform
    two tasks, regression of bounding boxes to locate the organs and prediction of
    abnormalities in the located organs. This system is validated using 200 clinical
    patients and it is capable of diagnosing abnormal neural foramina with 0.83 precision
    and 0.8 recall.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同的研究领域中，[[69](#bib.bib69)] 提出了一个多尺度多任务学习框架，用于腰椎神经孔狭窄症（LNFS）的诊断。图 [9](#S2.F9
    "图 9 ‣ II-C1 基于 MRI 的异常检测 ‣ II-C 背景及相关应用 ‣ II 使用深度学习检测医学异常 ‣ 深度学习在医学异常检测中的综述")
    展示了所使用的架构。作者展示了每个腰椎图像可以捕捉到多个器官，并且这些器官在不同的尺度下进行捕捉。此外，他们说明了多任务学习可以通过从多个相关任务中学习来提升学习效果，如在
    Sec. [II-B2](#S2.SS2.SSS2 "II-B2 监督异常检测 ‣ II-B 医学异常检测的算法方法 ‣ II 使用深度学习检测医学异常 ‣
    深度学习在医学异常检测中的综述") 中讨论的那样，我们注意到这种策略在多个应用领域中都有体现。特征图在多个尺度下提取，并且在每个级别上，模型尝试执行两项任务，即回归边界框以定位器官，以及预测已定位器官中的异常。该系统通过
    200 名临床患者进行验证，能够以 0.83 的精确度和 0.8 的召回率诊断异常神经孔。
- en: '![Refer to caption](img/7b9b8237fc00e67775a0a94e64d28167.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7b9b8237fc00e67775a0a94e64d28167.png)'
- en: 'Figure 9: The architecture proposed in [[69](#bib.bib69)] for diagnosis of
    Lumbar Neural Foraminal Stenosis. Recreated from [[69](#bib.bib69)]'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '图 9: [[69](#bib.bib69)] 提出的用于腰椎神经孔狭窄症诊断的架构。重新制作自 [[69](#bib.bib69)]'
- en: 'In addition to those approaches, a Neural Memory Network (NMN) based approach
    is proposed in [[1](#bib.bib1)]. This method utilises the recurrent structure
    of NMN to compare and contrast characteristics of the samples in the entire dataset
    using supervised learning. The memory stack stores important characteristics that
    separates normal and anomalous samples. Therefore, this architecture significantly
    deviates from rest of the approaches already described. Specifically, a ResNet-50
    CNN is used to extract a $14\times 14\times 256$ feature from the input MRI image.
    This feature becomes the input to the read controller of the NMN. Utilising this
    as a query vector, the read controller attends to the content that is stored in
    the memory, comparing them to find the best possible match to the input. The output
    of the memory read function and the input vector are passed though an output controller
    which generates the memory output (i.e. a feature vector which is subsequently
    used to generate the final classification). As the final step, the write controller
    decides how to update the content in the memory slots, reflecting the information
    retrieved from the current input. In addition to this typical functionality of
    the NMN, plasticity is utilised in the NMN controllers such that they can adapt
    the connectivity dynamically, changing the overall behaviour of the NMN. This
    framework was evaluated using the dataset of [[70](#bib.bib70)] which contains
    MRI images captured from 233 patients with different types of brain tumours: meningioma
    (708 samples), glioma (1426 samples), and pituitary (930 samples). In the 5-fold
    cross validation setting the model achieves 97.52% classification accuracy. Here
    we would like to point out that instead of binary normal/abnormal classification,
    a multi-class classification was conducted where the model discriminates between
    different abnormal classes using the categorical cross-entropy loss.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些方法，[[1](#bib.bib1)] 中提出了一种基于神经记忆网络（NMN）的方法。这种方法利用NMN的递归结构，通过监督学习比较和对比整个数据集中的样本特征。记忆堆栈存储了区分正常样本和异常样本的重要特征。因此，这种架构与之前描述的其他方法有显著不同。具体而言，使用ResNet-50
    CNN从输入的MRI图像中提取一个 $14\times 14\times 256$ 的特征。该特征作为NMN的读取控制器的输入。利用这个特征作为查询向量，读取控制器会关注存储在记忆中的内容，并与输入进行比较，以找到最佳匹配。记忆读取函数的输出和输入向量通过输出控制器，生成记忆输出（即，随后用于生成最终分类的特征向量）。最后，写入控制器决定如何更新记忆槽中的内容，以反映从当前输入中检索到的信息。除了NMN的典型功能外，NMN控制器还利用了可塑性，以便它们可以动态调整连接性，改变NMN的整体行为。该框架使用包含来自233名不同类型脑肿瘤患者的MRI图像的数据集[[70](#bib.bib70)]进行了评估：脑膜瘤（708个样本）、胶质瘤（1426个样本）和垂体瘤（930个样本）。在5折交叉验证设置下，该模型达到了97.52%的分类准确率。这里我们要指出的是，与二分类正常/异常分类不同，这里进行了多类分类，模型通过使用分类交叉熵损失在不同异常类别之间进行区分。
- en: II-C2 Detecting abnormalities in Endoscopy Data
  id: totrans-187
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-C2 内镜数据中的异常检测
- en: In this section we summarise some popular deep learning architectures introduced
    for abnormality detection from endoscopy’s.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们总结了一些用于内镜异常检测的流行深度学习架构。
- en: Considering the fact that endoscopy devices capture RGB data, CNNs pre-trained
    on large scale object detection benchmarks such as Image-Net [[71](#bib.bib71)]
    have been extensively applied. For instance, in [[72](#bib.bib72)] the authors
    apply the Xception [[73](#bib.bib73)] CNN architecture pre-trained on [[71](#bib.bib71)]
    for the detection of ulcers in endoscopy images. The proposed system is evaluated
    using a dataset that consists of 49 subjects and the authors have performed both
    5-fold cross validation and a leave-one-subject out evaluation. The system achieves
    an average of 96.05 % accuracy in the 5-fold cross validation setting, while the
    performance varies between 73.7% to 98.2% in the leave-one-subject out evaluation.
    Similarly in [[74](#bib.bib74)] both GoogLeNet [[75](#bib.bib75)] and AlexNet
    [[76](#bib.bib76)] pre-trained networks have been investigated for the classification
    of ulcers. The models were tested on a public dataset [[74](#bib.bib74)] which
    consists of 1875 images. Both models achieve 100% accuracy in this dataset. Furthermore,
    in [[77](#bib.bib77)] AlexNet [[76](#bib.bib76)] has been applied for both ulcer
    and erosion detection. The resultant model is capable of achieving 95.16% and
    95.34% accuracy levels for ulcer and erosion detection when tested on 500 ulcer
    and 690 erosion images.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到内窥镜设备捕捉RGB数据，预先在大规模物体检测基准（如Image-Net）上训练的**卷积神经网络**（CNNs）被广泛应用。例如，在[[72](#bib.bib72)]中，作者应用了在[[71](#bib.bib71)]上预训练的Xception
    [[73](#bib.bib73)] CNN架构来检测内窥镜图像中的溃疡。该系统使用包含49名受试者的数据集进行评估，作者进行了5折交叉验证和留一法评估。该系统在5折交叉验证设置中实现了96.05%的平均准确率，而在留一法评估中，性能在73.7%到98.2%之间变化。同样，在[[74](#bib.bib74)]中，已经研究了预训练的GoogLeNet
    [[75](#bib.bib75)]和AlexNet [[76](#bib.bib76)]网络用于溃疡分类。这些模型在包含1875张图像的公共数据集[[74](#bib.bib74)]上进行了测试，两种模型在该数据集上均达到了100%的准确率。此外，在[[77](#bib.bib77)]中，AlexNet
    [[76](#bib.bib76)]被应用于溃疡和侵蚀检测。结果模型在测试500张溃疡图像和690张侵蚀图像时，能够达到95.16%和95.34%的准确率。
- en: In contrast to these architectures, a two stage approach is proposed in [[78](#bib.bib78)].
    RetinaNet [[79](#bib.bib79)] has been adapted for the initial detection stage
    where it receives an endoscopy image and predicts the classification scores and
    bounding boxes for the input image. Then they extract multiple fixed size patches
    of size $160\times 160$ from this image and pass those through a ResNet-18 [[80](#bib.bib80)]
    network where the final fully connected layer produces a binary classification
    for the detection of ulcers. This system has been tested with 4917 ulcer frames
    and 5007 normal frames and the model reaches 0.9469 ROC-AUC value.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 与这些架构相比，在[[78](#bib.bib78)]中提出了一种两阶段的方法。RetinaNet [[79](#bib.bib79)]被用于初始检测阶段，它接收内窥镜图像并预测输入图像的分类得分和边界框。然后，他们从该图像中提取多个固定大小为$160\times
    160$的图像块，并将其通过ResNet-18 [[80](#bib.bib80)]网络，最终的全连接层对溃疡的检测进行二分类。该系统在4917张溃疡帧和5007张正常帧上进行了测试，模型达到了0.9469的ROC-AUC值。
- en: Most recently, a two stream framework has been proposed in [[81](#bib.bib81)]
    where the authors extract features from two levels of the ResNet-50 [[80](#bib.bib80)]
    architecture, and they are combined using a relational network [[82](#bib.bib82)].
    Fig. [10](#S2.F10 "Figure 10 ‣ II-C2 Detecting abnormalities in Endoscopy Data
    ‣ II-C Background and Related Applications ‣ II Detecting Medical Anomalies with
    Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey") illustrates
    this method. Specifically, the relational network allows this approach to map
    all possible relationships among the features extracted at the two levels. The
    resultant augmented feature vector is passed through an LSTM network and classification
    is performed using a fully connected layer. This framework has been evaluated
    on two public benchmarks, Kvasir [[5](#bib.bib5)] (with 8000 endoscopy images)
    and Nerthus [[83](#bib.bib83)] (with 2,552 colonoscopy images). In the Kvasir
    dataset this system was able to detect 8 abnormality classes with 98.4 % accuracy,
    and reaches 100 % accuracy for classifying the cleanliness of the bowel on the
    Nerthus dataset. We note that this study exploits the hierarchical nature of the
    CNN to address the requirements in endoscopy image analysis. Top level kernels
    of a CNN capture local spatial features such as textures and contours in the input
    while the bottom level layers capture more semantic features, such as the overall
    representation of the image. This is because the local features are pooled together,
    hierarchically, when they flow through the CNN. Therefore, when extracting features
    from a CNN, top level layers carry spatially variant characteristics of the input
    while the bottom layers have spatially invariant features. The authors in [[81](#bib.bib81)]
    leverage this characteristic of CNNs for endoscopy image analysis in which, both
    existence of a particular distinctive pattern as well as its location is vital
    for diagnosis.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，在[[81](#bib.bib81)]中提出了一种双流框架，其中作者从ResNet-50 [[80](#bib.bib80)]架构的两个层级提取特征，并通过关系网络[[82](#bib.bib82)]将其结合。图
    [10](#S2.F10 "Figure 10 ‣ II-C2 Detecting abnormalities in Endoscopy Data ‣ II-C
    Background and Related Applications ‣ II Detecting Medical Anomalies with Deep
    Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey") 说明了这种方法。具体来说，关系网络使得这种方法能够映射两个层级提取特征之间的所有可能关系。最终的增强特征向量通过LSTM网络，并使用全连接层进行分类。该框架已在两个公共基准测试上进行评估，Kvasir
    [[5](#bib.bib5)]（包含8000张内窥镜图像）和Nerthus [[83](#bib.bib83)]（包含2552张结肠镜图像）。在Kvasir数据集中，该系统能够以98.4%的准确率检测8种异常类，并在Nerthus数据集中对肠道清洁度的分类达到100%的准确率。我们注意到，这项研究利用了CNN的层次结构特性来满足内窥镜图像分析的需求。CNN的顶层卷积核捕捉输入的局部空间特征，如纹理和轮廓，而底层则捕捉更语义化的特征，如图像的整体表示。这是因为局部特征在通过CNN时会按层次聚合。因此，从CNN中提取特征时，顶层层具有空间变化的特征，而底层层具有空间不变的特征。[[81](#bib.bib81)]中的作者利用了CNN的这一特性用于内窥镜图像分析，其中，特定独特模式的存在以及其位置对诊断至关重要。
- en: '![Refer to caption](img/c0a5a989f7bd7539f4f20f5fea9140d6.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c0a5a989f7bd7539f4f20f5fea9140d6.png)'
- en: 'Figure 10: The architecture proposed in [[81](#bib.bib81)] for abnormality
    detection in endoscopy data. Recreated from [[81](#bib.bib81)]'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：在[[81](#bib.bib81)]中提出的用于内窥镜数据异常检测的架构。重建自[[81](#bib.bib81)]
- en: Similar to MRI image analysis, DCNNs have dominated endoscopy image abnormality
    detection. Furthermore, most methods utilise pre-trained feature extractors trained
    on large scale datasets with natural images leveraging the fact that endoscopy
    images are also captured with visible light. In contrast to binary supervised
    classification, methods such as [[81](#bib.bib81)] and [[5](#bib.bib5)] use multi-class
    classification (often trained using categorical cross-entropy loss) such that
    the model can detect normal and abnormal examples while recognising individual
    anomalies.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于MRI图像分析，DCNNs在内窥镜图像异常检测中已占据主导地位。此外，大多数方法利用在大规模自然图像数据集上训练的预训练特征提取器，利用内窥镜图像也使用可见光的事实。与二分类监督学习相比，如[[81](#bib.bib81)]和[[5](#bib.bib5)]等方法采用多类分类（通常使用类别交叉熵损失训练），使得模型不仅能检测正常和异常示例，还能识别个体异常。
- en: II-C3 Heart Sound Anomaly Detection
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-C3 心音异常检测
- en: In contrast to the MRI and endoscopy applications which use images, heart sound
    anomaly detection operates on a one-dimensional audio signal, and methods primarily
    use 1D CNNs and RNN architectures, however some pre-processing methods can be
    used to transform the audio signal to an image representation, allowing 2D CNNs
    to be used. An ensemble of VGG [[84](#bib.bib84)] networks is proposed in [[85](#bib.bib85)],
    where the authors first apply a Savitzky–Golay filter [[86](#bib.bib86)] to remove
    noise from the input signals. Then a series of 2D features, a spectrogram feature,
    a Mel Spectrogram and Mel Frequency Cepstral Coefficients (MFCCs), are extracted
    from the audio signal. These separate feature streams are passed through separate
    VGG networks and the final decision is made via majority voting. This method has
    also been evalauted on the PhysioNet/CinC 2016 dataset in a 10 fold cross validation
    setting and it reaches an accuracy of 89.81 %.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 相较于使用图像的MRI和内窥镜应用，心音异常检测则处理一维音频信号，主要使用1D CNNs和RNN架构，然而一些预处理方法可以将音频信号转换为图像表示，从而允许使用2D
    CNNs。在[[85](#bib.bib85)]中，提出了一种VGG网络的集成方法[[84](#bib.bib84)]，作者首先应用Savitzky–Golay滤波器[[86](#bib.bib86)]来去除输入信号中的噪声。然后从音频信号中提取一系列2D特征，包括频谱图特征、Mel频谱图和Mel频率倒谱系数（MFCCs）。这些独立的特征流通过不同的VGG网络处理，最终通过多数投票来做出决策。这种方法也在PhysioNet/CinC
    2016数据集上进行了10折交叉验证评估，达到了89.81%的准确率。
- en: In [[87](#bib.bib87)] the authors leverage 497 feature values which are hand-crafted
    from 8 domains, including time domain features, higher-order statistics, signal
    energy, and frequency domain features. The extracted features are concatenated
    and passed through a 1D CNN with 3 convolutional layers followed by a global average
    pooling layer and a dense layer with a sigmoid activation to perform the normal/abnormal
    classification. This system is evaluated on PhysioNet/CinC 2016 dataset and achieves
    an accuracy value of 86.8 %.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[87](#bib.bib87)]中，作者利用从8个领域手工制作的497个特征值，包括时域特征、高阶统计量、信号能量和频域特征。这些提取的特征被连接并通过一个包含3个卷积层的1D
    CNN进行处理，接着是一个全局平均池化层和一个带有sigmoid激活函数的全连接层，用于进行正常/异常分类。该系统在PhysioNet/CinC 2016数据集上进行了评估，并取得了86.8%的准确率。
- en: In contrast to the above stated approaches, frameworks that operate on raw audio
    signals are proposed in [[88](#bib.bib88), [89](#bib.bib89)]. Specifically, in
    [[88](#bib.bib88)] the authors augment the raw audio signal from the PhysioNet/CinC
    2016 dataset by performing a Discrete Fourier Transform (DFT) and adding the variance
    and standard deviation of each data sample to the original audio. Then the recordings
    are segmented into S1 and S2 heart states using the algorithm of [[90](#bib.bib90)].
    The segmented recordings are passed through an RNN to validate its normality.
    This framework achieves 80 % accuracy on the PhysioNet/CinC 2016 challenge. A
    similar approach utilising GRUs has been proposed in [[89](#bib.bib89)]. Similar
    to [[88](#bib.bib88)] the raw audio recordings were segmented to heart states
    using the algorithm of [[90](#bib.bib90)]. However, the authors in [[89](#bib.bib89)]
    skip the DFT based heart sound augmentation step utilised in [[88](#bib.bib88)].
    The segmented audio is passed through a GRU network to generate the classification.
    The proposed framework has been validated for heart failure detection. The authors
    have acquired the heart failure data from patients in University-Town Hospital
    of Chongqing Medical University and the normal recordings were obtained from PhysioNet/CinC
    2016 dataset (1286 randomly sampled normal recordings). In a 10-fold cross-validation
    setting the proposed model achieves an average accuracy of 98.82%. In this paper
    the authors have also tested the utilisation of an LSTM and Fully Convolutional
    Network (FCN) instead of a GRU network, however, these models have only been able
    to achieve 96.29 % and 94.65 %, respectively.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述方法相比，提出了一些在原始音频信号上操作的框架，参见[[88](#bib.bib88)、[89](#bib.bib89)]。具体来说，在[[88](#bib.bib88)]中，作者通过执行离散傅里叶变换（DFT）并将每个数据样本的方差和标准差添加到原始音频中，从PhysioNet/CinC
    2016数据集中增强了原始音频信号。然后，使用[[90](#bib.bib90)]的算法将录音分割为S1和S2心脏状态。这些分割的录音通过RNN进行正常性验证。该框架在PhysioNet/CinC
    2016挑战中实现了80%的准确率。在[[89](#bib.bib89)]中提出了类似的方法，利用GRUs。与[[88](#bib.bib88)]类似，原始音频录音通过[[90](#bib.bib90)]的算法被分割为心脏状态。然而，[[89](#bib.bib89)]中的作者省略了[[88](#bib.bib88)]中使用的基于DFT的心音增强步骤。分割的音频通过GRU网络生成分类。该框架已被验证用于心力衰竭检测。作者从重庆医科大学附属大学城医院获得了心力衰竭数据，正常录音则来自PhysioNet/CinC
    2016数据集（1286个随机抽样的正常录音）。在10折交叉验证设置下，该模型的平均准确率为98.82%。本文中，作者还测试了使用LSTM和全卷积网络（FCN）替代GRU网络，但这些模型分别只能达到96.29%和94.65%的准确率。
- en: There has been a mixed response from researches regarding the need for heart
    sound segmentation prior to the abnormal heart sound detection. Heart sound segmentation
    has primarily been used due to the belief that features surrounding the S1 and
    S2 heart sound locations carry important information for detecting abnormalities.
    However, some argue that in the errors associated with this pre-processing step
    can be propagated to the abnormality detection module, and the model should be
    given the freedom to choose it’s own informative features [[91](#bib.bib91)].
    In [[91](#bib.bib91)] the authors have conducted a comparative study investigating
    the importance of prior segmentation of heart sounds into heart states for abnormality
    detection. The authors have utilised the features extracted from the state-of-the-art
    the sound segmentation model [[92](#bib.bib92)] and trained a classifier to detect
    abnormalities using these features. For comparison, they also trained a separate
    2D CNN model without segmentation which uses MFCC features as the inputs. The
    comparisons were conducted using the PhysioNet/CinC 2016 dataset and their evaluation
    indicates that a 2D CNN model without segmentation is capable of achieving superior
    results to a model that receives segmented inputs. In the 10-fold cross validation
    setting the unsegmeted model achieves $98.94\pm 0.27$ % accuracy compared to $98.49\pm
    0.13$ % for the segmented model. Utilising the SHAP model interpretations [[93](#bib.bib93)]
    the authors conclude that the unsegmented model has also focused on the regions
    of the audio wave that correspond to S1 and S2 locations, however, this model
    has the capacity to learn what the informative features for the abnormality detection
    task are, compared to the restricted model inputs that are received by the segmented
    model.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在检测异常心音之前是否需要心音分割，研究者们的反馈意见不一。心音分割主要用于认为 S1 和 S2 心音位置周围的特征包含重要的异常检测信息。然而，有些人认为这一预处理步骤中的错误可能会传递到异常检测模块，并且模型应该有自由选择其自身的有用特征
    [[91](#bib.bib91)]。在 [[91](#bib.bib91)] 中，作者进行了一项比较研究，探讨了心音先前分割成心脏状态对异常检测的重要性。作者利用从最先进的声音分割模型
    [[92](#bib.bib92)] 中提取的特征，训练了一个分类器来检测这些异常。为了比较，他们还训练了一个没有分割的 2D CNN 模型，该模型使用 MFCC
    特征作为输入。比较使用 PhysioNet/CinC 2016 数据集进行，他们的评估表明，没有分割的 2D CNN 模型能够获得比接受分割输入的模型更优的结果。在
    10 倍交叉验证设置中，无分割模型的准确率为 $98.94\pm 0.27$ %，而分割模型的准确率为 $98.49\pm 0.13$ %。利用 SHAP
    模型解释 [[93](#bib.bib93)]，作者得出结论，无分割模型也关注了与 S1 和 S2 位置对应的音频波段，但相比之下，该模型能够学习异常检测任务中的有用特征，而不是像分割模型那样受限的输入。
- en: 'Finally, Oh et. al [[94](#bib.bib94)] proposed a deep learned model called
    WaveNet to classify heart sounds into five categories, namely: normal, aortic
    stenosis, mitral valve prolapse, mitral stenosis, and mitral regurgitation. The
    architecture utilised in this study is illustrated in Fig. [11](#S2.F11 "Figure
    11 ‣ II-C3 Heart Sound Anomaly Detection ‣ II-C Background and Related Applications
    ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning for Medical
    Anomaly Detection - A Survey"). Specifically, inspired by [[80](#bib.bib80)] the
    authors proposed a residual block which is composed of 1D dilated convolutions
    to extract features from the raw audio signal. The architecture is composed of
    6 such residual blocks and the features captured from those 6 blocks are aggregated
    into a single feature vector, which is subsequently passed through two 1D convolution
    layers and a two fully connected layers, prior to classification. This model is
    evaluated using an in house dataset which consists of 1000 PCG recording (200
    per each category) and the model achieves an average accuracy of 97 % in a 10-fold
    cross validation setting.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Oh 等人 [[94](#bib.bib94)] 提出了一个深度学习模型 WaveNet，用于将心音分类为五种类型，即：正常、主动脉狭窄、二尖瓣脱垂、二尖瓣狭窄和二尖瓣返流。本研究中使用的架构如图
    [11](#S2.F11 "Figure 11 ‣ II-C3 Heart Sound Anomaly Detection ‣ II-C Background
    and Related Applications ‣ II Detecting Medical Anomalies with Deep Learning ‣
    Deep Learning for Medical Anomaly Detection - A Survey") 所示。具体来说，受到 [[80](#bib.bib80)]
    启发，作者提出了一个由 1D 膨胀卷积组成的残差块，用于从原始音频信号中提取特征。该架构由 6 个这样的残差块组成，这 6 个块捕获的特征被聚合成一个单一的特征向量，然后通过两个
    1D 卷积层和两个全连接层进行分类。该模型使用包含 1000 个 PCG 记录（每种类别 200 个）的内部数据集进行评估，在 10 倍交叉验证设置中，模型达到了
    97% 的平均准确率。
- en: '![Refer to caption](img/a2cd652e0da58ee970892c8c1cf9d927.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a2cd652e0da58ee970892c8c1cf9d927.png)'
- en: 'Figure 11: The architecture proposed in [[94](#bib.bib94)] for abnormal heart
    sound detection. Recreated from [[94](#bib.bib94)]'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：[[94](#bib.bib94)] 提出的异常心音检测架构。重新创建自[[94](#bib.bib94)]
- en: As noted earlier, 1D-CNN networks and RNNs have been extensively applied for
    the abnormal heart sound detection. This is primarily due to the temporal nature
    of the signal where 1D-CNN networks can perform convolutions over the time axis
    and extract temporal features while the recurrent architectures can model the
    temporal evolution of the signal and generate better features for detecting the
    abnormalities. As discussed, there are only minor variations among the models
    and they have often utilised supervised learning to train the models. Furthermore,
    hand-crafted frequency domain features such as MFCCs are extensively applied within
    the heart sound anomaly detection domain as opposed to automatic feature learning.
    Finally, as observed in other application domains, supervised approaches are the
    most common methods for anomaly detection.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，1D-CNN网络和RNNs已广泛应用于异常心音检测。这主要是由于信号的时间特性，1D-CNN网络可以在时间轴上执行卷积并提取时间特征，而递归结构可以建模信号的时间演变，并生成更好的特征来检测异常。如前所讨论，这些模型之间只有轻微的差异，并且它们通常利用监督学习来训练模型。此外，与自动特征学习相对，手工制作的频域特征如MFCCs在心音异常检测领域被广泛应用。最后，与其他应用领域观察到的情况一样，监督方法是异常检测中最常见的方法。
- en: II-C4 Epileptic Seizure Prediction
  id: totrans-204
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-C4 癫痫发作预测
- en: '![Refer to caption](img/936aade847de4b6b7ad5962aaa305e69.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/936aade847de4b6b7ad5962aaa305e69.png)'
- en: 'Figure 12: Variations of the EEG recording before and after a seizure.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：癫痫发作前后脑电图记录的变化。
- en: 'Fig. [26](#A1.F26 "Figure 26 ‣ A-B Electrical Biomedical Signals ‣ Appendix
    A Types of Data ‣ Deep Learning for Medical Anomaly Detection - A Survey") illustrates
    how the four brain states: interictal, pre-ictal , ictal and post-ictal; are located
    in an EEG. The interictal state is the normal brain state of a subject, while
    the brain state before a seizure event is refereed to as the pre-ictal state.
    The state in which the seizure occurs is denoted as ictal state, and after the
    seizure event, the brain shifts to the post-ictal state.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图[26](#A1.F26 "Figure 26 ‣ A-B Electrical Biomedical Signals ‣ Appendix A Types
    of Data ‣ Deep Learning for Medical Anomaly Detection - A Survey")展示了四种脑状态：间歇期、发作前期、发作期和发作后期；这些状态在脑电图中的位置。间歇期状态是受试者的正常脑状态，而发作事件前的脑状态称为发作前期状态。发生癫痫发作的状态被标记为发作期状态，而在发作事件后，大脑会转变为发作后期状态。
- en: The seizure prediction problem can be viewed as an abnormality detection problem
    where machine learning models are trained to distinguish between the pre-ictal
    and interictal brain states, identifying when a particular subjects brain activity
    shifts from the normal interictal state to pre-ictal (abnormal state). As the
    pre-ictal state is the brain state before a seizure, this problem is termed seizure
    prediction.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 癫痫发作预测问题可以视为一个异常检测问题，在该问题中，机器学习模型被训练以区分发作前期和间歇期脑状态，从而识别特定受试者的大脑活动何时从正常的间歇期状态转变为发作前期（异常状态）。由于发作前期是癫痫发作前的大脑状态，因此这个问题被称为癫痫发作预测。
- en: We acknowledge that epileptic seizure prediction has several distinct characteristics
    compared to rest of the abnormality detection application domains that we discussed
    above, however, numerous studies have posed this task as an abnormality detection
    task [[95](#bib.bib95), [96](#bib.bib96), [97](#bib.bib97)], and hence we consider
    it here.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们承认癫痫发作预测相比于上述讨论的其他异常检测应用领域具有几个显著特点，但许多研究将这一任务视为异常检测任务[[95](#bib.bib95), [96](#bib.bib96),
    [97](#bib.bib97)]，因此我们在此讨论。
- en: A key challenge in designing a generalised seizure prediction framework is the
    vast differences in the pre-ictal duration among subjects. This can vary from
    minutes to hours depending on the subject [[98](#bib.bib98)]. One of the notable
    attempts to perform patient independent seizure prediction is the framework of
    [[99](#bib.bib99)], where the authors propose a 2D CNN architecture trained on
    Short-term Fourier transform (STFT) features extracted from raw EEG signals. This
    framework has been validated on both the Freiburg intracranial EEG (iEEG) [[100](#bib.bib100)]
    and CHB-MIT scalp EEG (sEEG) datasets [[101](#bib.bib101)], and achieves approximately
    81 % sensitivity in a leave-one-subject-out cross validation setting.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 设计一个通用的癫痫预测框架的一个关键挑战是受试者之间前癫痫发作时间的巨大差异。这种差异可能从几分钟到几小时不等，具体取决于受试者[[98](#bib.bib98)]。一种显著的尝试是[[99](#bib.bib99)]
    的框架，其中作者提出了一种基于短期傅里叶变换（STFT）特征的2D CNN架构，该特征从原始EEG信号中提取。该框架在弗赖堡脑内EEG（iEEG）[[100](#bib.bib100)]
    和CHB-MIT头皮EEG（sEEG）数据集[[101](#bib.bib101)] 上进行了验证，在留一受试者交叉验证设置中实现了约81%的灵敏度。
- en: Despite this promising level of performance, the authors in [[102](#bib.bib102),
    [103](#bib.bib103)] identified significant performance variations in [[99](#bib.bib99)].
    For example, the sensitivity drops to 33.3 % for some subjects. A multi-scale
    CNN architecture is proposed in [[102](#bib.bib102)] to address this limitation.
    The authors re-sample the original 400Hz iEEG dataset at 100Hz and STFT features
    are extracted from this down sampled signal. They extract STFT as 2D images for
    each EEG channel, resulting in 16 STFT images per data sample. The proposed multi-scale
    CNN is composed of 3 convolutional streams, each with different filter sizes ($1\times
    1$, $3\times 3$ and $5\times 5$). The authors propose to capture features at different
    scales using these individual streams. These features are concatenated and passed
    through a fully connected layer to generate the relevant predictions. Their system
    is evaluated on 2016 Kaggle seizure prediction competition dataset [[104](#bib.bib104)]
    and the proposed system achieves a 87.85 % sensitivity where the lowest value
    per subject is only 79.65 %.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管表现出色，[[102](#bib.bib102), [103](#bib.bib103)] 的作者指出了[[99](#bib.bib99)] 中显著的性能差异。例如，对于一些受试者，灵敏度下降到33.3%。[[102](#bib.bib102)]
    提出了一个多尺度CNN架构以解决这个限制。作者将原始400Hz的iEEG数据集重新采样到100Hz，并从这一降采样信号中提取STFT特征。他们将STFT作为每个EEG通道的2D图像提取，导致每个数据样本生成16个STFT图像。提出的多尺度CNN由3个卷积流组成，每个流具有不同的滤波器大小（$1\times
    1$, $3\times 3$ 和 $5\times 5$）。作者建议使用这些单独的流捕捉不同尺度的特征。这些特征被连接并通过一个全连接层生成相关预测。他们的系统在2016年Kaggle癫痫预测竞赛数据集[[104](#bib.bib104)]
    上进行了评估，提出的系统实现了87.85%的灵敏度，其中每个受试者的最低值仅为79.65%。
- en: In contrast to this approach, a fine-tuning based method is proposed in [[103](#bib.bib103)].
    The authors first train the model using a balanced dataset which consists of an
    equal amount of pre-ictal and interictal data. When the system is deployed, the
    authors propose to add a tunable processing layer which can be optimised depending
    on the patient requirements. This two stage framework is evaluated using the dataset
    proposed in [[105](#bib.bib105)] and the system achieve a mean sensitivity of
    69%.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，[[103](#bib.bib103)] 中提出了一种基于微调的方法。作者首先使用一个平衡的数据集训练模型，该数据集由等量的前癫痫发作数据和间歇期数据组成。当系统部署时，作者建议添加一个可调节的处理层，该层可以根据患者需求进行优化。这个两阶段的框架使用[[105](#bib.bib105)]
    中提出的数据集进行了评估，系统达到了69%的平均灵敏度。
- en: In contrast to these CNN based approaches, recurrent neural networks are leveraged
    in [[96](#bib.bib96), [97](#bib.bib97)]. Specifically, the authors in [[96](#bib.bib96)]
    utilised a 2 layer LSTM network trained on hand-crafted time domain, frequency
    domain, graph theory based (i.e clustering coefficients, diameter, radius, local
    efficiency, centrality, etc.), and correlation features. The system is evaluated
    using the CHB-MIT sEEG dataset and reaches 99.28% sensitivity for a 15 min pre-ictal
    period. Motivated by this approach, a bi-directional LSTM based architecture is
    given in [[97](#bib.bib97)]. Similar to [[96](#bib.bib96)], a 2-layer LSTM is
    used with a bi-directional structure, however, in contrast to [[96](#bib.bib96)]
    it operates on the raw EEG signal. This framework has been validated using the
    Bonn University EEG database [[106](#bib.bib106)] and achieves an overall 89.2
    % sensitivity score.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 与这些基于 CNN 的方法相比，[[96](#bib.bib96)、[97](#bib.bib97)] 中利用了递归神经网络。具体来说，[[96](#bib.bib96)]
    的作者使用了一个 2 层 LSTM 网络，该网络在手工设计的时域、频域、图论（即聚类系数、直径、半径、局部效率、中心性等）和相关特征上进行训练。该系统使用
    CHB-MIT sEEG 数据集进行评估，在 15 分钟前兆期的灵敏度达到 99.28%。受到这种方法的启发，[[97](#bib.bib97)] 提出了一个基于双向
    LSTM 的架构。与 [[96](#bib.bib96)] 类似，使用了 2 层 LSTM 和双向结构，但与 [[96](#bib.bib96)] 相比，它处理的是原始
    EEG 信号。该框架已通过 Bonn University EEG 数据库 [[106](#bib.bib106)] 进行验证，整体灵敏度得分为 89.2%。
- en: Compared to heart sound anomaly detection, most existing works in seizure prediction
    have utilised DCNN architectures. This is mainly due to the use of hand-crafted
    2D image like features which are extracted jointly by considering all EEG electrodes.
    Once again, supervised learning methods are most prevalent and the architectures
    comprise standard deep learning methods.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 与心音异常检测相比，大多数现有的癫痫预测工作使用了 DCNN 架构。这主要是由于使用了手工设计的类似 2D 图像的特征，这些特征通过考虑所有 EEG 电极共同提取。再一次，监督学习方法最为普遍，架构包括标准的深度学习方法。
- en: A different approach is proposed by [[107](#bib.bib107)], who propose a GAN
    based method which is illustrated in Fig. [13](#S2.F13 "Figure 13 ‣ II-C4 Epileptic
    Seizure Prediction ‣ II-C Background and Related Applications ‣ II Detecting Medical
    Anomalies with Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A
    Survey"). The generator of the GAN model is capable of synthesising realistic
    looking STFT images using a noise vector. The generated STFTs are passed through
    the discriminator which performs the real fake validation. Once the generator
    is trained for the seizure prediction task, the authors adapt the discriminator
    network by adding two fully-connected layers such that it is trained to perform
    the normal/abnormal classification instead of real/fake classification. Therefore,
    the proposed system leverages the information in not only labeled EEG signals,
    but also the unlabeled synthesised samples in the training process. This system
    is validated using CHB-MIT sEEG, Freiburg iEEG, and EPILEPSIAE [[108](#bib.bib108)]
    datasets, and achieves AUC values of 77.68%, 75.47% and 65.05%, respectively.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[[107](#bib.bib107)] 提出了另一种方法，提出了一种基于 GAN 的方法，详见图 [13](#S2.F13 "Figure 13 ‣
    II-C4 Epileptic Seizure Prediction ‣ II-C Background and Related Applications
    ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning for Medical
    Anomaly Detection - A Survey")。GAN 模型的生成器能够利用噪声向量合成逼真的 STFT 图像。生成的 STFT 图像通过鉴别器进行真假验证。一旦生成器在癫痫预测任务上经过训练，作者通过添加两个全连接层来调整鉴别器网络，使其训练以进行正常/异常分类，而不是真假分类。因此，所提系统不仅利用标记的
    EEG 信号信息，还利用训练过程中的未标记合成样本。该系统已使用 CHB-MIT sEEG、Freiburg iEEG 和 EPILEPSIAE [[108](#bib.bib108)]
    数据集进行验证，分别获得 77.68%、75.47% 和 65.05% 的 AUC 值。'
- en: We highlight that this approach deviates from the standard GAN model illustrated
    in Sec. [II-B1](#S2.SS2.SSS1 "II-B1 Unsupervised Anomaly Detection ‣ II-B Algorithmic
    Approaches for Medical Anomaly Detection ‣ II Detecting Medical Anomalies with
    Deep Learning ‣ Deep Learning for Medical Anomaly Detection - A Survey"), as in
    this model a secondary training process is used where the discriminator is fine-tuned
    to do normal/abnormal classification using supervised learning. Hence, like the
    autoencoder methods discussed for MRI anomaly detection in Section [II-C1](#S2.SS3.SSS1
    "II-C1 MRI based Anomaly Detection ‣ II-C Background and Related Applications
    ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning for Medical
    Anomaly Detection - A Survey"), this is not a completely unsupervised model. Rather
    this architecture is semi-supervised, where both labelled and unlabelled examples
    are used for model training [[109](#bib.bib109)]. In Tab. [II](#S2.T2 "TABLE II
    ‣ II-C4 Epileptic Seizure Prediction ‣ II-C Background and Related Applications
    ‣ II Detecting Medical Anomalies with Deep Learning ‣ Deep Learning for Medical
    Anomaly Detection - A Survey") we provide a comprehensive summary regarding key
    research in these different application type, their evaluation details, results
    and limitations.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强调，这种方法偏离了在 Sec. [II-B1](#S2.SS2.SSS1 "II-B1 无监督异常检测 ‣ II-B 医疗异常检测的算法方法 ‣
    II 深度学习检测医疗异常 ‣ 医疗异常检测的深度学习综述") 中所示的标准 GAN 模型，因为在此模型中使用了次级训练过程，其中鉴别器被微调以进行正常/异常分类，采用的是监督学习。因此，像在
    [II-C1](#S2.SS3.SSS1 "II-C1 基于 MRI 的异常检测 ‣ II-C 背景及相关应用 ‣ II 深度学习检测医疗异常 ‣ 医疗异常检测的深度学习综述")
    中讨论的自编码器方法一样，这并不是一个完全的无监督模型。相反，这种架构是半监督的，其中使用了标记和未标记的示例进行模型训练 [[109](#bib.bib109)]。在表
    [II](#S2.T2 "表 II ‣ II-C4 癫痫发作预测 ‣ II-C 背景及相关应用 ‣ II 深度学习检测医疗异常 ‣ 医疗异常检测的深度学习综述")
    中，我们提供了关于这些不同应用类型的关键研究的综合总结，包括评估细节、结果和局限性。
- en: '![Refer to caption](img/355f82889c87ed3456deaeed02440c39.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/355f82889c87ed3456deaeed02440c39.png)'
- en: 'Figure 13: The architecture proposed in [[107](#bib.bib107)] for epileptic
    seizure prediction. Recreated from [[107](#bib.bib107)]'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '图 13: [[107](#bib.bib107)] 提出的癫痫发作预测架构。重建自 [[107](#bib.bib107)]。'
- en: 'TABLE II: Summary of key research in different applications, their evaluation
    results, and limitations'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '表 II: 不同应用中的关键研究总结，包括其评估结果和局限性。'
- en: '| Application Type | Reference | Method | Task | Dataset | Results | Limitations
    and Research Gaps |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 应用类型 | 参考文献 | 方法 | 任务 | 数据集 | 结果 | 局限性和研究空白 |'
- en: '| MRI based Anomaly Detection | [[59](#bib.bib59)] | Fusion of T1-weighted
    MRIs and myelin water imaging of MRIs | Diagnosis of Multiple sclerosis | in-house
    (55 relapse-remitting MS patients and 44 healthy controls) | $87.9\pm 8.4$ % accuracy
    | Simple feature concatenation is used for fusion, Not an end-to-end learning
    framework, Causality or Uncertainty were not investigated. |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 基于 MRI 的异常检测 | [[59](#bib.bib59)] | 融合 T1 加权 MRI 和髓鞘水成像的 MRI | 多发性硬化症的诊断
    | 内部数据（55 名复发缓解型 MS 患者和 44 名健康对照） | $87.9\pm 8.4$ % 准确率 | 使用简单的特征拼接进行融合，非端到端学习框架，因果关系或不确定性未被调查。
    |'
- en: '| [[62](#bib.bib62)] | Fusion of MRI and FDG-PET | Detection of Alzheimer’s
    Disease | Alzheimer’s Disease Neuroimaging Initiative (ADNI) database [[63](#bib.bib63)]
    | 82.93 % accuracy | Simple feature concatenation is used for fusion, Lack of
    Interpretability, Two stages of training is required, Causality or Uncertainty
    were not investigated. |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| [[62](#bib.bib62)] | 融合 MRI 和 FDG-PET | 阿尔茨海默病检测 | 阿尔茨海默病神经影像学倡议 (ADNI) 数据库
    [[63](#bib.bib63)] | 82.93 % 准确率 | 使用简单的特征拼接进行融合，缺乏可解释性，需要两阶段训练，因果关系或不确定性未被调查。
    |'
- en: '| [[64](#bib.bib64)] | Fusion of Apparent Diffusion Coefficients of MRIs and
    T2-weighted MRI images | Detection of prostate cancer lesions | in-house (463
    cancer lesions and 450 noncancerous images) | Sensitivity 89.85% and Specificity
    95.83% | Heavily reliant on pre-processing, Lack of Interpretability, Causality
    or Uncertainty were not investigated. |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| [[64](#bib.bib64)] | 融合 MRI 的表观扩散系数和 T2 加权 MRI 图像 | 前列腺癌病灶检测 | 内部数据（463 个癌症病灶和
    450 张非癌症图像） | 敏感性 89.85% 和特异性 95.83% | 依赖于预处理，缺乏可解释性，因果关系或不确定性未被调查。 |'
- en: '|  | [[65](#bib.bib65)] | Decision level fusion using ensemble of classifiers
    | Classification between four Alzheimer’s disease classes (non-demented, very
    mild, mild and moderate) | OASIS dataset [[66](#bib.bib66)] | 94 % precision and
    93 % recall | Higher computation cost due to the use of ensemble of classifiers,
    Lack of Interpretability, Causality or Uncertainty were not investigated. |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '|  | [[65](#bib.bib65)] | 使用分类器集成的决策级融合 | 四种阿尔茨海默病类别的分类（无痴呆、非常轻度、轻度和中度） | OASIS
    数据集 [[66](#bib.bib66)] | 94 % 精度和 93 % 召回率 | 由于使用了分类器集成，计算成本较高，缺乏可解释性，因果关系或不确定性未被调查。
    |'
- en: '|  | [[68](#bib.bib68)] | Multi-stage training of Auto-Encoders | Schizophrenia
    Diagnosis | In-house (474 schizophrenia and 607 healthy controls) | 85 % accuracy
    | High development time due to multiple stages of training, Heavily reliant on
    pre-processing, Lack of Interpretability, Causality or Uncertainty were not investigated.
    |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '|  | [[68](#bib.bib68)] | 自动编码器的多阶段训练 | 精神分裂症诊断 | 内部数据（474 名精神分裂症患者和 607 名健康对照）
    | 85 % 准确率 | 由于多阶段训练，开发时间较长，严重依赖预处理，缺乏可解释性，因果关系或不确定性未被调查。 |'
- en: '|  | [[67](#bib.bib67)] | Multi-stage training of Auto-Encoders | Early detection
    of acute renal transplant rejection | In-house (100 subjects) | 97% accuracy |
    3D segmentation maps are required as inputs, Lack of Interpretability, Causality
    or Uncertainty were not investigated. |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '|  | [[67](#bib.bib67)] | 自动编码器的多阶段训练 | 急性肾移植排斥的早期检测 | 内部数据（100 名受试者） | 97%
    准确率 | 需要 3D 分割图作为输入，缺乏可解释性，因果关系或不确定性未被调查。'
- en: '|  | [[69](#bib.bib69)] | Multi-scale Multi-task learning algorithm | Diagnosis
    of Lumbar Neural Foraminal Stenosis | In-house (200 subjects) | 83 % precision
    and 80 % recall | Evaluation can be slower due to the multi-stage pipeline, Causality
    or Uncertainty were not investigated. |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '|  | [[69](#bib.bib69)] | 多尺度多任务学习算法 | 腰椎神经孔狭窄的诊断 | 内部数据（200 名受试者） | 83 % 精度和
    80 % 召回率 | 由于多阶段流程，评估可能较慢，因果关系或不确定性未被调查。 |'
- en: '|  | [[1](#bib.bib1)] | Neural Memory Network | Classification of brain tumours
    | The dataset of [[70](#bib.bib70)]. Meningioma (708), glioma (1426), pituitary
    (930) | 97.52% accuracy | Computationally expensive and data intensive due to
    the usage of memory network, Lack of Interpretability, Causality or Uncertainty
    were not investigated. |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '|  | [[1](#bib.bib1)] | 神经记忆网络 | 脑肿瘤分类 | 数据集 [[70](#bib.bib70)]。脑膜瘤（708），胶质瘤（1426），垂体瘤（930）
    | 97.52% 准确率 | 由于使用了记忆网络，计算成本高且数据密集，缺乏可解释性，因果关系或不确定性未被调查。 |'
- en: '| Detecting abnormalities in Endoscopy Data | [[72](#bib.bib72)] | Fine-tuning
    Xception | Detection of ulcers | in-house (49 subjects) | 96.05 % accuracy | Cannot
    identify different types of ulcers, Lack of Interpretability, Causality or Uncertainty
    were not investigated. |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 检测内窥镜数据中的异常 | [[72](#bib.bib72)] | 微调 Xception | 溃疡检测 | 内部数据（49 名受试者） | 96.05
    % 准确率 | 无法识别不同类型的溃疡，缺乏可解释性，因果关系或不确定性未被调查。 |'
- en: '| [[74](#bib.bib74)] | Fine-tuning GoogLeNet and AlexNet | Detection of ulcers
    | The dataset of [[74](#bib.bib74)] | 100% accuracy | Cannot identify different
    types of ulcers, Lack of Interpretability, Causality or Uncertainty were not investigated.
    |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| [[74](#bib.bib74)] | 微调 GoogLeNet 和 AlexNet | 溃疡检测 | 数据集 [[74](#bib.bib74)]
    | 100% 准确率 | 无法识别不同类型的溃疡，缺乏可解释性，因果关系或不确定性未被调查。 |'
- en: '| [[77](#bib.bib77)] | Fine-tuning AlexNet | ulcer and erosion detection |
    in-house (500 ulcer and 690 erosion images) | 95.16% and 95.34% accuracy levels
    for ulcer and erosion detection | Lack of Interpretability, Causality or Uncertainty
    were not investigated. |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| [[77](#bib.bib77)] | 微调 AlexNet | 溃疡和侵蚀检测 | 内部数据（500 张溃疡图像和 690 张侵蚀图像） |
    溃疡和侵蚀检测的准确率分别为 95.16% 和 95.34% | 缺乏可解释性，因果关系或不确定性未被调查。 |'
- en: '|  | [[78](#bib.bib78)] | Two-stage approach using RetinaNet | detection of
    ulcers | in-house ( 4917 ulcer frames and 5007 normal frames) | 0.9469 ROC-AUC
    | Cannot identify different types of ulcers, Computationally expensive due to
    the two-stage approach, Lack of Interpretability. |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '|  | [[78](#bib.bib78)] | 使用 RetinaNet 的两阶段方法 | 溃疡检测 | 内部数据（4917 溃疡帧和 5007
    正常帧） | 0.9469 ROC-AUC | 无法识别不同类型的溃疡，由于两阶段方法计算成本高，缺乏可解释性。 |'
- en: '|  | [[81](#bib.bib81)] | Two stream framework using ResNet-50 | Classifying
    abnormalities, Classifying the cleanliness of the bowel | Kvasir [[5](#bib.bib5)]
    (with 8000 endoscopy images) and Nerthus [[83](#bib.bib83)] (with 2,552 colonoscopy
    images) | 98.4 % accuracy when detecting 8 abnormality classes, and 100 % accuracy
    for classifying the cleanliness of the bowel on the Nerthus dataset | Computationally
    expensive due to the relational network architecture, Lack of Interpretability,
    Causality or Uncertainty were not investigated. |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '|  | [[81](#bib.bib81)] | 使用ResNet-50的双流框架 | 异常分类，肠道清洁度分类 | Kvasir [[5](#bib.bib5)]（含8000张内镜图像）和
    Nerthus [[83](#bib.bib83)]（含2552张结肠镜图像） | 检测8类异常时准确率98.4%，在Nerthus数据集上对肠道清洁度分类准确率100%
    | 由于关系网络架构计算开销大，缺乏可解释性，因果关系或不确定性未被探讨。 |'
- en: '| Heart Sound Anomaly Detection | [[85](#bib.bib85)] | Ensemble of VGG networks
    | Abnormal heart sound detection | PhysioNet/CinC 2016 | 89.81 % accuracy | Heavily
    reliant on pre-processing, Computationally expensive due to ensemble of models,
    Lack of Interpretability, Causality or Uncertainty were not investigated. |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 心音异常检测 | [[85](#bib.bib85)] | VGG网络的集成 | 异常心音检测 | PhysioNet/CinC 2016 | 89.81
    % 准确率 | 严重依赖预处理，由于模型集成计算开销大，缺乏可解释性，因果关系或不确定性未被探讨。 |'
- en: '| [[87](#bib.bib87)] | 1D CNN using a combination of time, statistical, energy,
    and frequency domain features | Abnormal heart sound detection | PhysioNet/CinC
    2016 | 86.8 % accuracy | Hand-engineered features, Lack of Interpretability, Causality
    or Uncertainty were not investigated. |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| [[87](#bib.bib87)] | 1D CNN 使用时间、统计、能量和频率域特征的组合 | 异常心音检测 | PhysioNet/CinC
    2016 | 86.8 % 准确率 | 手工设计特征，缺乏可解释性，因果关系或不确定性未被探讨。 |'
- en: '| [[88](#bib.bib88)] | RNN $+$ DFT based heart sound augmentation $+$ segmentation
    | Abnormal heart sound detection | PhysioNet/CinC 2016 | 80 % accuracy | Heavily
    reliant on pre-processing, Lack of Interpretability, Causality or Uncertainty
    were not investigated. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| [[88](#bib.bib88)] | RNN $+$ DFT 基于心音增强 $+$ 分割 | 异常心音检测 | PhysioNet/CinC
    2016 | 80 % 准确率 | 严重依赖预处理，缺乏可解释性，因果关系或不确定性未被探讨。 |'
- en: '|  | [[89](#bib.bib89)] | GRU $+$ segmentation | Heart failure detection |
    University-Town Hospital of Chongqing Medical University | 98.82% accuracy | Heavily
    reliant on pre-processing, Lack of Interpretability, Causality or Uncertainty
    were not investigated. |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '|  | [[89](#bib.bib89)] | GRU $+$ 分割 | 心衰检测 | 重庆医科大学附属大学城医院 | 98.82% 准确率 |
    严重依赖预处理，缺乏可解释性，因果关系或不确定性未被探讨。 |'
- en: '|  | [[91](#bib.bib91)] | 2D CNN using MFCC features and without segmentation
    | Abnormal heart sound detection | PhysioNet/CinC 2016 | $98.94\pm 0.27$ % accuracy
    | Causality or Uncertainty were not investigated. |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '|  | [[91](#bib.bib91)] | 使用MFCC特征的2D CNN且不进行分割 | 异常心音检测 | PhysioNet/CinC 2016
    | $98.94\pm 0.27$ % 准确率 | 因果关系或不确定性未被探讨。 |'
- en: '|  | [[94](#bib.bib94)] | Residual block with raw audio | classification of
    heart sounds (normal, aortic stenosis, mitral valve prolapse, mitral stenosis,
    and mitral regurgitation) | in-house dataset which consists of 1000 recordings.
    | 97 % accuracy | Causality or Uncertainty were not investigated. |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '|  | [[94](#bib.bib94)] | 原始音频的残差块 | 心音分类（正常、主动脉狭窄、二尖瓣脱垂、二尖瓣狭窄和二尖瓣返流） | 内部数据集包含1000个录音。
    | 97 % 准确率 | 因果关系或不确定性未被探讨。 |'
- en: '| Epileptic Seizure Prediction | [[99](#bib.bib99)] | 2D CNN architecture trained
    on Short-term Fourier transform (STFT) features | Seizure prediction | Freiburg
    intracranial EEG (iEEG) [[100](#bib.bib100)] and CHB-MIT scalp EEG (sEEG) datasets
    [[101](#bib.bib101)] | 81 % sensitivity | Heavily reliant on pre-processing, Lack
    of Interpretability, Causality or Uncertainty were not investigated. |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 癫痫发作预测 | [[99](#bib.bib99)] | 训练于短时傅里叶变换（STFT）特征的2D CNN架构 | 癫痫预测 | Freiburg颅内EEG
    (iEEG) [[100](#bib.bib100)] 和 CHB-MIT头皮EEG (sEEG) 数据集 [[101](#bib.bib101)] | 81
    % 灵敏度 | 严重依赖预处理，缺乏可解释性，因果关系或不确定性未被探讨。 |'
- en: '| [[102](#bib.bib102)] | Multi-scale CNN | Seizure prediction | 2016 Kaggle
    seizure prediction competition dataset [[104](#bib.bib104)] | 87.85 % sensitivity
    | Heavily reliant on pre-processing, Computationally expensive due to multi-scale
    architecture, Lack of Interpretability, Causality or Uncertainty were not investigated.
    |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| [[102](#bib.bib102)] | 多尺度CNN | 癫痫预测 | 2016 Kaggle癫痫预测竞赛数据集 [[104](#bib.bib104)]
    | 87.85 % 灵敏度 | 严重依赖预处理，由于多尺度架构计算开销大，缺乏可解释性，因果关系或不确定性未被探讨。 |'
- en: '| [[103](#bib.bib103)] | Tunable layer for patient based fine-tuning | Seizure
    prediction | dataset of [[105](#bib.bib105)] | 69% sensitivity | Requires patient-specific
    data for deployment, Lack of Interpretability, Causality or Uncertainty were not
    investigated. |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| [[103](#bib.bib103)] | 可调层用于基于患者的微调 | 癫痫预测 | [[105](#bib.bib105)] 数据集 | 69%的灵敏度
    | 部署时需要特定于患者的数据，缺乏可解释性，因果关系或不确定性未被调查。 |'
- en: '|  | [[96](#bib.bib96)] | 2 layer LSTM trained on time, frequency, graph theory,
    and correlation features | Seizure prediction | CHB-MIT sEEG dataset | 99.28%
    sensitivity | Hand-engineered features, Lack of Interpretability, Causality or
    Uncertainty were not investigated. |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '|  | [[96](#bib.bib96)] | 在时间、频率、图论和相关特征上训练的2层LSTM | 癫痫预测 | CHB-MIT sEEG数据集
    | 99.28%的灵敏度 | 手工工程特征，缺乏可解释性，因果关系或不确定性未被调查。 |'
- en: '|  | [[97](#bib.bib97)] | bi-directional LSTM using raw signal | Seizure prediction
    | Bonn University EEG database [[106](#bib.bib106)] | 89.2 % sensitivity | Lack
    of Interpretability, Causality or Uncertainty were not investigated. |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '|  | [[97](#bib.bib97)] | 使用原始信号的双向LSTM | 癫痫预测 | 波恩大学EEG数据库 [[106](#bib.bib106)]
    | 89.2%的灵敏度 | 缺乏可解释性，因果关系或不确定性未被调查。'
- en: '|  | [[107](#bib.bib107)] | Synthesising STFT images using a GAN | Seizure
    prediction | CHB-MIT sEEG, Freiburg iEEG, and EPILEPSIAE [[108](#bib.bib108)]
    datasets | AUC values of 77.68%, 75.47% and 65.05%, respectively. | High development
    time due to multiple stages of training, Lack of Interpretability, Causality or
    Uncertainty were not investigated. |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '|  | [[107](#bib.bib107)] | 使用GAN合成STFT图像 | 癫痫预测 | CHB-MIT sEEG、Freiburg iEEG
    和 EPILEPSIAE [[108](#bib.bib108)] 数据集 | AUC值分别为77.68%、75.47%和65.05%。 | 开发时间长，因训练阶段多，缺乏可解释性，因果关系或不确定性未被调查。
    |'
- en: III Model Interpretation
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 模型解释
- en: Interpretability is one of the key challenges that modern deep learning methods
    face. Despite their tremendous success and often astonishingly precise predictions,
    the application of methods to real world diagnostic tasks is hindered as we are
    unsure how models reached their predictions. The complexity of the deep learned
    models further contributes to this, as decisions are based upon hundreds of thousands
    of parameters, which are not human interpretable. Hence, interpretable machine
    learning has become an active area of research where black-box deep models are
    converted white-box models.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性是现代深度学习方法面临的关键挑战之一。尽管这些方法取得了巨大的成功，并且预测结果往往令人惊讶地准确，但由于我们无法了解模型是如何得出这些预测的，这限制了这些方法在现实世界诊断任务中的应用。深度学习模型的复杂性进一步加剧了这一问题，因为决策是基于数十万个参数，这些参数对人类来说不可解释。因此，可解释的机器学习已成为一个活跃的研究领域，研究者们致力于将黑箱深度模型转化为白箱模型。
- en: Fig. [14](#S3.F14 "Figure 14 ‣ III Model Interpretation ‣ Deep Learning for
    Medical Anomaly Detection - A Survey") illustrates a taxonomy of model interpretation
    methods, which is adopted in [[110](#bib.bib110)]. Model-agnostic interpretation
    methods are interpretation methods that are not limited to a specific architecture.
    In contrast, a model-specific interpretation method seeks to explain a single
    model.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [14](#S3.F14 "Figure 14 ‣ III Model Interpretation ‣ Deep Learning for Medical
    Anomaly Detection - A Survey") 说明了一种模型解释方法的分类，这在 [[110](#bib.bib110)] 中有所采用。模型无关的解释方法是不限制于特定架构的解释方法。相反，模型特定的解释方法旨在解释单个模型。
- en: Model interpretation methods can be further classified into local and global
    methods. Local methods try to reason regarding a particular prediction while global
    methods explore overall model behaviour by exploiting knowledge regarding the
    architecture, the training process and the data associated with training. The
    third class we consider is surrogate vs. visualization methods. In surrogate methods,
    a model with a simpler architecture (a surrogate model) is trained to mimic the
    behaviour of the original black box model. This is done with the intent that understanding
    the surrogate model’s decision is simpler than the complex model. In contrast,
    visualisation methods use visual representations such as activation maps obtained
    from the black-box model to explain behaviour. Finally, as per [[110](#bib.bib110)]
    model interpretation techniques in the medical domain can be broadly categorised
    into attribution based and non-attribution based methods. Attribution-based methods
    seek to determine the contribution of an input feature to the generated classification.
    Non-attribution based methods investigate generating new methods to validate model
    behaviour for a given problem [[110](#bib.bib110)].
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 模型解释方法可以进一步分为局部方法和全局方法。局部方法尝试对特定预测进行推理，而全局方法则通过利用有关架构、训练过程和训练数据的知识来探索整体模型行为。我们考虑的第三类是代理方法与可视化方法。在代理方法中，训练一个具有更简单架构的模型（代理模型）以模拟原始黑箱模型的行为。这样做的目的是理解代理模型的决策比理解复杂模型更简单。相反，可视化方法使用如从黑箱模型获得的激活图等视觉表示来解释行为。最后，根据[[110](#bib.bib110)]，医学领域的模型解释技术可以大致分为基于归因和非基于归因的方法。基于归因的方法旨在确定输入特征对生成分类的贡献。非基于归因的方法则探讨生成新方法来验证模型在特定问题上的行为[[110](#bib.bib110)]。
- en: '![Refer to caption](img/f640994350cfc9e5d79463caba83b474.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f640994350cfc9e5d79463caba83b474.png)'
- en: 'Figure 14: Taxonomy of Model Interpretation methods.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：模型解释方法的分类。
- en: The majority of existing literature on explainability of deep learned models
    in the medical domain considers attribution based methods. They leverage the model-agnostic
    plug and play nature of attribution based methods in their studies. The following
    paragraphs illustrate the most common model-agnostic interpretability methods
    that are used.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 现有文献中关于医学领域深度学习模型可解释性的研究主要集中于基于归因的方法。它们在研究中利用了基于归因的方法的模型无关即插即用特性。以下段落说明了最常用的模型无关可解释性方法。
- en: 'Visualising Activation Maps: This offers one of the simplest ways to understand
    what features lead to a certain model decision. As deep learning methods hierarchically
    encode features, the top layers of the model capture local features while later
    layers aggregate local features together to arrive at a decision. This concept
    is the foundation of Class Activation Maps (CAM) [[111](#bib.bib111)].'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉化激活图：这提供了理解哪些特征导致模型特定决策的最简单方法之一。由于深度学习方法层次性地编码特征，模型的顶部层捕捉局部特征，而后续层则将局部特征聚合在一起以得出决策。这个概念是类别激活图（CAM）的基础[[111](#bib.bib111)]。
- en: We can consider kernels in a convolution layer to be a set of filters which
    control information flow to subsequent layers, and at the final classification
    layer the positive features (emphasised features from the filters) are multiplied
    by learned values to obtain a classification decision. Fig. [15](#S3.F15 "Figure
    15 ‣ III Model Interpretation ‣ Deep Learning for Medical Anomaly Detection -
    A Survey") illustrates this concept. Hence the activation maps, or feature maps
    extracted at the final convolution layer, are multiplied by the associated weights
    and they are aggregated to generate the final activation map of the predicted
    class. The resultant map is up-sampled such that it can be superimposed on the
    input image. This can reveal what regions/characteristics of the input are highly
    activated and pass information to the classifier. Such a technique can be applied
    for tasks such as CNN based MRI tumor detection to identify whether the features
    from the tumor region are actually contributing to the classification, or if the
    model is acting upon noisy features from elsewhere in the sample.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将卷积层中的卷积核视为一组控制信息流向后续层的滤波器，在最终的分类层中，正特征（来自滤波器的强化特征）会乘以学习到的值以获得分类决策。图 [15](#S3.F15
    "Figure 15 ‣ III Model Interpretation ‣ Deep Learning for Medical Anomaly Detection
    - A Survey") 说明了这一概念。因此，激活图或在最终卷积层提取的特征图会与相关权重相乘，并聚合以生成预测类别的最终激活图。结果图会进行上采样，以便可以与输入图像叠加。这可以揭示输入的哪些区域/特征被高度激活并传递信息给分类器。这种技术可以应用于基于
    CNN 的 MRI 肿瘤检测等任务，以确定肿瘤区域的特征是否实际贡献于分类，或者模型是否在处理样本中的其他噪声特征。
- en: '![Refer to caption](img/685d8dfbcb4c7fb8fc43a834aa62fbc5.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/685d8dfbcb4c7fb8fc43a834aa62fbc5.png)'
- en: 'Figure 15: Illustration of the process of creating class activation maps. Recreated
    from [[111](#bib.bib111)]'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '图 15: 创建类别激活图的过程说明。重建自 [[111](#bib.bib111)]'
- en: One of the drawbacks of the CAM generation process is that the technique is
    constrained to architectures where global average pooling is performed over convolutional
    maps immediately before prediction. This is a requirement for utilising the weighted
    liner sum of the activations to generate the final convolution map.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: CAM 生成过程的一个缺点是该技术受限于在预测之前对卷积图进行全局平均池化的架构。这是利用激活值的加权线性和生成最终卷积图的要求。
- en: The Grad-Cam [[112](#bib.bib112)] method addresses this shortcoming, and uses
    the gradient information flowing into the last convolutional layer of the network
    to understand how each pixel contributes to the decision. Let the $k^{t}h$ feature
    map of the final convolution layer of size $u\times v$ be denoted by $A^{k}$.
    Then the gradients of the score for class $c$, $y^{c}$, are computed with respect
    to feature maps $A^{k}$, and averaged across $u\times v$ such that,
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: Grad-Cam [[112](#bib.bib112)] 方法解决了这一缺点，并使用流入网络最后一个卷积层的梯度信息来了解每个像素如何对决策做出贡献。设最终卷积层的
    $k^{t}$ 特征图的大小为 $u\times v$，记为 $A^{k}$。然后计算类别 $c$ 的分数 $y^{c}$ 对特征图 $A^{k}$ 的梯度，并在
    $u\times v$ 上进行平均，如下所示，
- en: '|  | $\alpha^{c,k}=\frac{1}{uv}\sum_{i\in u}\sum_{j\in v}{\frac{\partial y^{c}}{\partial
    A^{k}_{i,j}}}$ |  | (22) |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '|  | $\alpha^{c,k}=\frac{1}{uv}\sum_{i\in u}\sum_{j\in v}{\frac{\partial y^{c}}{\partial
    A^{k}_{i,j}}}$ |  | (22) |'
- en: Then to generate the final activation map across all $k$ feature maps a weighted
    combination of activation maps is computed. The resultant feature map is passed
    through the ReLU activation to set negetive values to zero.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为生成所有 $k$ 特征图的最终激活图，计算激活图的加权组合。结果特征图通过 ReLU 激活函数以将负值设为零。
- en: '|  | $L_{Grad-Cam}=\mathrm{ReLU}(\sum_{k}{\alpha^{c,k}A^{k}})$ |  | (23) |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '|  | $L_{Grad-Cam}=\mathrm{ReLU}(\sum_{k}{\alpha^{c,k}A^{k}})$ |  | (23) |'
- en: Grad-Cam however does not handle instances where multiple occurrences of the
    same object are in the input image, and in such instances it fails to properly
    localise the multiple instances [[113](#bib.bib113)].
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Grad-Cam 不能处理输入图像中存在多个相同对象的情况，在这种情况下，它无法正确定位多个实例 [[113](#bib.bib113)]。
- en: 'Local Interpretable Model-agnostic Explanations (LIME): As the name implies,
    LIME is a local interpretation method. It tries to interpret a model’s behaviour
    when presented with different inputs by understanding how predictions change with
    perturbations of the input data. Fig. [16](#S3.F16 "Figure 16 ‣ III Model Interpretation
    ‣ Deep Learning for Medical Anomaly Detection - A Survey") illustrates the concept
    behind LIME. First, the input is divided to a series of interpretable components
    where some portion of the input is masked out. Then each perturbed sample is passed
    through the model to get the probability of a particular class and the components
    of the image with the highest weights are returned as the explanation.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 局部可解释模型无关解释（LIME）：顾名思义，LIME 是一种局部解释方法。它通过理解输入数据扰动下预测的变化来尝试解释模型在不同输入下的行为。图 [16](#S3.F16
    "Figure 16 ‣ III Model Interpretation ‣ Deep Learning for Medical Anomaly Detection
    - A Survey") 说明了 LIME 背后的概念。首先，输入被分为一系列可解释的组件，其中一部分输入被屏蔽。然后，每个扰动样本都通过模型以获取特定类别的概率，图像中权重最高的组件被返回作为解释。
- en: '![Refer to caption](img/a2b6cc9206e83d63dd3f2e597bf77bca.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/a2b6cc9206e83d63dd3f2e597bf77bca.png)'
- en: 'Figure 16: Illustration of Local Interpretable Model-agnostic Explanations
    method. Recreated from [[114](#bib.bib114)]'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16：局部可解释模型无关解释方法的说明。重新制作自 [[114](#bib.bib114)]
- en: One of the key limitations of LIME is that when sampling the data points for
    interpretable components, it can sample unrealistic data points. Furthermore,
    as the interpretations are biased towards these data points the generated explanations
    can be unstable such that two components in close proximity can lead to very different
    explanations.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: LIME 的一个主要限制是，在采样可解释组件的数据点时，可能会采样到不现实的数据点。此外，由于解释偏向这些数据点，生成的解释可能不稳定，例如，两个相近的组件可能导致非常不同的解释。
- en: 'SHapley Additive exPlanations (SHAP): The inspiration for SHAP [[115](#bib.bib115)]
    comes from game theory. Specifically, we define individual feature values (or
    groups of feature values) as a ‘player’ in the game and the contribution of each
    player to the game is measured by adding and removing the players. Let the input
    $x$ be composed of $N$ features, $\omega_{i}$s, where $x=[\omega_{1},\omega_{2},\ldots,\omega_{N}]$,
    and $M$ is the maximum number of coalitions (or feature combinations) that can
    be generated using $N$ features. Then the model is queried with different feature
    coalitions where some feature values are present and some are absent. (eg. $x_{1}=[\omega_{1}],x_{2}=[\omega_{2}],x_{1,2}=[\omega_{1},\omega_{2}],x_{1,3}=[\omega_{1},\omega_{3}],\ldots$).
    This allows the identification of which features contribute to a certain prediction
    and which do not.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: SHapley Additive exPlanations（SHAP）：SHAP 的灵感来自博弈论[[115](#bib.bib115)]。具体来说，我们将单个特征值（或特征值组）定义为游戏中的‘玩家’，并通过增加和移除玩家来衡量每个玩家对游戏的贡献。设输入
    $x$ 由 $N$ 个特征 $\omega_{i}$ 组成，其中 $x=[\omega_{1},\omega_{2},\ldots,\omega_{N}]$，$M$
    是使用 $N$ 个特征生成的最大联盟（或特征组合）数。然后，模型使用不同的特征联盟进行查询，其中一些特征值存在，而一些特征值缺失。（例如，$x_{1}=[\omega_{1}],x_{2}=[\omega_{2}],x_{1,2}=[\omega_{1},\omega_{2}],x_{1,3}=[\omega_{1},\omega_{3}],\ldots$）。这允许识别哪些特征对某个预测有贡献，哪些没有。
- en: '![Refer to caption](img/4892d928777b9fdb5738c11de922fd6a.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/4892d928777b9fdb5738c11de922fd6a.png)'
- en: 'Figure 17: Illustration of SHapley Additive exPlanations which explore how
    different features contribute to the risk of hypoxaemia. Image taken from [[116](#bib.bib116)]'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17：SHapley Additive exPlanations 的说明，探讨不同特征如何影响低氧血症的风险。图片来源于 [[116](#bib.bib116)]
- en: Fig. [17](#S3.F17 "Figure 17 ‣ III Model Interpretation ‣ Deep Learning for
    Medical Anomaly Detection - A Survey") illustrates how different features such
    as height/weight, respiration rate and pulse affect the risk of hypoxaemia in
    the next five minutes. Features shown in purple increase the risk while green
    features reduce the risk.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [17](#S3.F17 "Figure 17 ‣ III Model Interpretation ‣ Deep Learning for Medical
    Anomaly Detection - A Survey") 说明了不同特征如身高/体重、呼吸频率和脉搏如何影响接下来五分钟内低氧血症的风险。紫色特征增加风险，而绿色特征降低风险。
- en: In [[93](#bib.bib93)] the author suggests that SHAP is one of the few explanation
    method with a strong theoretical basis and the only method that currently exists
    to deliver a full interpretation. However, it is computationally expensive to
    calculate SAHPly values as we have to consider all possible combinations of the
    features.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[93](#bib.bib93)]中，作者建议SHAP是少数几个具有强理论基础的解释方法之一，并且是目前存在的唯一能够提供完整解释的方法。然而，计算SAHPly值是计算密集型的，因为我们必须考虑所有可能的特征组合。
- en: 'Interpretation of Medical Anomaly Detection Methods: In addition to the above
    stated commonly used interpretation methods we acknowledge the methods DeepLIFT
    (Deep Learning Important FeaTures) [[117](#bib.bib117)], DeepTaylor [[118](#bib.bib118)],
    Guided backpropagation (GBP) [[119](#bib.bib119)] and Integrated Gradients [[120](#bib.bib120)],
    that are also proposed to explain the black-box deep learning model.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 医学异常检测方法的解释：除了上述常用的解释方法，我们还承认DeepLIFT（Deep Learning Important FeaTures）[[117](#bib.bib117)]、DeepTaylor
    [[118](#bib.bib118)]、Guided backpropagation（GBP）[[119](#bib.bib119)]和Integrated
    Gradients [[120](#bib.bib120)]等方法，这些方法也被提出用以解释黑箱深度学习模型。
- en: In [[121](#bib.bib121)] the authors attempt to explain the features learned
    by a CNN which they proposed for automated grading of brain tumors from MRI images
    using GradCAM and GBP techniques. In [[122](#bib.bib122)] 30 CNN models were trained
    for melanoma detection using skin images and the authors interpret the model features
    using SHAP and GradCAM. They illustrate that models occasionally focus on features
    that were irrelevant for diagnosis.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[121](#bib.bib121)]中，作者尝试解释他们为从MRI图像中自动评估脑肿瘤而提出的CNN所学到的特征，使用了GradCAM和GBP技术。在[[122](#bib.bib122)]中，30个CNN模型被训练用于黑色素瘤检测，使用皮肤图像，作者使用SHAP和GradCAM解释模型特征。他们展示了模型有时会关注与诊断无关的特征。
- en: In recent studies [[123](#bib.bib123), [124](#bib.bib124)] GradCAM, GBP, CAM,
    DeepLIFT and IG have been utilised to explain chest X-ray based COVID-19 detection
    of a deep learned model. Most recently, SHAP interpretations are used to illustrate
    that a heart sound anomaly detection methods can automatically learn to focus
    on S1 and S2 sounds without the need to provide segmented inputs [[91](#bib.bib91)].
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在近期研究[[123](#bib.bib123), [124](#bib.bib124)]中，GradCAM、GBP、CAM、DeepLIFT和IG被用于解释基于胸部X光的COVID-19检测深度学习模型。最近，SHAP解释被用于说明心音异常检测方法可以自动学会关注S1和S2声音，而无需提供分段输入[[91](#bib.bib91)]。
- en: In contrast to the attribution based approaches illustrated earlier, non-attribution
    based methods use concepts like attention maps, and expert knowledge to interpret
    model decisions. However, these methods are specific to a particular problem.
    For instance, in [[125](#bib.bib125)] attention is used to map the relationships
    between medical images and corresponding diagnostic reports. This mechanism uncovers
    the mapping between images and the diagnostic reports. A textual justification
    for a breast mass classification task is proposed in [[126](#bib.bib126)]. The
    proposed justification model receives visual features and embeddings from the
    classifier and generates a diagnostic sentence explaining the model classification.
    In [[127](#bib.bib127)] a method for generating understandable explanations utilising
    a set of explainable rules is presented. In this approach, a set of anatomical
    features are defined based on segmentation and anatomical regularities (i.e set
    of pre-defined rules), and the feature importance is evaluated based on perturbation.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前展示的基于归因的方法不同，非归因方法使用诸如注意力图和专家知识等概念来解释模型决策。然而，这些方法特定于某个特定问题。例如，在[[125](#bib.bib125)]中，注意力机制用于映射医学图像与相应诊断报告之间的关系。这一机制揭示了图像与诊断报告之间的映射。在[[126](#bib.bib126)]中，提出了一种用于乳腺肿块分类任务的文本化理由。该理由模型接收分类器的视觉特征和嵌入，并生成解释模型分类的诊断句子。在[[127](#bib.bib127)]中，提出了一种利用一组可解释规则生成易于理解的解释的方法。在这种方法中，基于分割和解剖学规律（即预定义规则集）定义了一组解剖特征，并基于扰动评估特征重要性。
- en: 'Considering the above discussion it is clear that the selection of the interpretation
    method depends on several factors:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到上述讨论，很明显解释方法的选择依赖于几个因素：
- en: '1.'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: whether a global level model interpretation method is required, or whether it
    is sufficient to generate local (example level) interpretations;
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 是否需要全局级别的模型解释方法，或仅生成局部（示例级别）解释是否足够；
- en: '2.'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: the end users expertise level with regards to understanding the resultant explanations;
    and
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 终端用户在理解结果解释方面的专业水平；以及
- en: '3.'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: whether the application domain has time constraints, i.e. do the interpretations
    need to be generated in real-time?
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 应用领域是否有时间限制，即解释是否需要实时生成？
- en: Interpretable machine learning is an active area of research and the medical
    domain is a good test bed to evaluate the proposed methods. Better understanding
    regarding the black-box model decisions would not only build trust among the medical
    practitioners regarding machine learning algorithms, but also would help the machine
    learning researchers to understand the limitations of model architectures and
    help to design better models. However, as illustrated earlier, different interpretation
    approaches have different strengths and limitations, and designing optimal interpretation
    strategies is an open research problem for future exploration.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释的机器学习是一个活跃的研究领域，而医疗领域是评估提出的方法的良好试验场。对黑箱模型决策的更好理解不仅会增强医疗从业者对机器学习算法的信任，还会帮助机器学习研究者理解模型架构的局限性，并有助于设计更好的模型。然而，如前所述，不同的解释方法具有不同的优缺点，设计最佳解释策略是未来探索的一个开放研究问题。
- en: IV Challenges and Open Research Questions
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 挑战和开放研究问题
- en: In this section, we outline limitations of existing deep medical anomaly detection
    techniques as well as various open research questions, and highlight future research
    directions.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们概述了现有深度医疗异常检测技术的局限性以及各种未解的研究问题，并强调了未来的研究方向。
- en: IV-A Lack of Interpretability
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 缺乏可解释性
- en: As illustrated in Sec. [III](#S3 "III Model Interpretation ‣ Deep Learning for
    Medical Anomaly Detection - A Survey"), attribution based methods have been popular
    among researchers in the medical domain for deep model interpretation due to their
    model agnostic plug-and-play nature. However, the end-user of the given particular
    medical application (i.e. the clinician) should be considered when selecting one
    interpretation method over another. Although popular, methodologies such as GradCAM,
    LIME, and GBP are not specifically developed to address explainability in the
    medical domain, and while they are informative for machine learning practitioners,
    they may be of much less use for a clinicians. Therefore, more studies such as
    [[128](#bib.bib128), [129](#bib.bib129)] should be conducted using expert clinicians
    to rate the explanations across different application domains. Such illustrations
    would evaluate the applicability and the limitations of model-agnostic interpretation
    methods. Hybrid techniques such as Human-in-the-Loop learning techniques could
    be utilised to design interpretable diagnostic models where clinical experts could
    refine deep model decisions to mimic their own decision making process.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 如[III](#S3 "III Model Interpretation ‣ Deep Learning for Medical Anomaly Detection
    - A Survey")节所示，基于归因的方法由于其模型无关的即插即用特性，在医疗领域的深度模型解释中广受研究者欢迎。然而，在选择解释方法时，应考虑到特定医疗应用的最终用户（即临床医生）。尽管这些方法如GradCAM、LIME和GBP很受欢迎，但它们并不是专门为医疗领域的可解释性开发的，虽然对机器学习从业者有帮助，但对临床医生的实用性可能较低。因此，需要更多像[[128](#bib.bib128)、[129](#bib.bib129)]这样的研究，利用专家临床医生对不同应用领域的解释进行评分。这些示例将评估模型无关解释方法的适用性和局限性。可以利用人机协作学习技术等混合技术来设计可解释的诊断模型，使临床专家能够优化深度模型决策以模拟自己的决策过程。
- en: Furthermore, we observe a lack of model-agnostic methods to interpret multi-modal
    deep methodologies. Such methods have increased complexity in that the decision
    depends on multiple input feature streams, requiring more sophisticated strategies
    to interpret behaviour.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们观察到缺乏通用的方法来解释多模态深度方法。这些方法因决策依赖于多个输入特征流而增加了复杂性，需要更复杂的策略来解释行为。
- en: Finally, we present Reinforcement Learning (RL) as a possible future direction
    to generate explainable decisions [[130](#bib.bib130), [131](#bib.bib131)]. In
    RL the autonomous agent’s behaviour is governed by a ‘reward function’, and the
    agent tries to maximise this reward. As such the agent utilises exploration to
    detect anomalies and improve its detection process across many iterations. The
    exploration process that the agent utilised to detect the anomalies could illustrate
    the intuition behind it’s behaviour.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们提出了强化学习（RL）作为生成可解释决策的一个可能未来方向[[130](#bib.bib130), [131](#bib.bib131)]。在强化学习中，自动化代理的行为由“奖励函数”控制，代理试图最大化这一奖励。因此，代理利用探索来检测异常，并在多个迭代中改善其检测过程。代理用于检测异常的探索过程可以揭示其行为背后的直觉。
- en: IV-B Causality and Uncertainty
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 因果关系与不确定性
- en: Causal identification is crucial characteristic that most existing deep medical
    anomaly detection methods lack. Causality is often confused with association [[132](#bib.bib132),
    [133](#bib.bib133), [134](#bib.bib134)]. For instance, if $X$ and $Y$ are associated
    (dependent) it only implies that there is a dependency between the two factors.
    The association does not imply that $X$ is causing $Y$. Association can arise
    between variables in the presence and absence of a causal relationship. If both
    $X$ and $Y$ have a common cause they both can show associative relationships without
    causality [[134](#bib.bib134)].
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 因果识别是现有大多数深度医学异常检测方法所缺乏的关键特性。因果关系常常与关联混淆[[132](#bib.bib132), [133](#bib.bib133),
    [134](#bib.bib134)]。例如，如果$X$和$Y$存在关联（依赖），这仅意味着这两个因素之间存在依赖关系。关联并不意味着$X$是导致$Y$的原因。关联可以在存在或不存在因果关系的情况下出现。如果$X$和$Y$有一个共同的原因，它们可以在没有因果关系的情况下表现出关联关系[[134](#bib.bib134)]。
- en: In medical diagnosis the doctor tries to explain the cause of the patient’s
    symptoms, which is causal identification. However, in most existing deep learned
    approaches the diagnosis is purely associative. Methods try to associate the patient’s
    symptoms with a particular disease category without trying to uncover what is
    actually causing these symptoms (and whether this disease is the only cause of
    these symptoms) [[132](#bib.bib132)]. As such, causality estimation is a crucial
    area that requires additional focus from the research community. For instance,
    in epilepsy prediction if the the brain regions that are actually causing the
    seizures can be identified then epileptologists can surgically treat that specific
    region to address the root cause of the patient’s seizures. Existing approaches
    for causality estimation in deep learning studies include causal graph structures
    [[135](#bib.bib135)], algorithmic information theory based approaches [[136](#bib.bib136),
    [137](#bib.bib137)], and Causal Bayesian Networks [[138](#bib.bib138), [139](#bib.bib139)];
    however, these methods are seldom applied in medical abnormality detection.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在医学诊断中，医生试图解释患者症状的原因，这就是因果识别。然而，在大多数现有的深度学习方法中，诊断纯粹是关联性的。这些方法试图将患者的症状与特定的疾病类别关联起来，而不试图揭示实际导致这些症状的原因（以及这种疾病是否是这些症状唯一的原因）[[132](#bib.bib132)]。因此，因果估计是一个需要研究界额外关注的关键领域。例如，在癫痫预测中，如果能够识别出实际导致癫痫发作的大脑区域，那么癫痫专家可以对该特定区域进行外科治疗，以解决患者癫痫发作的根本原因。现有的深度学习研究中的因果估计方法包括因果图结构[[135](#bib.bib135)]、基于算法信息理论的方法[[136](#bib.bib136),
    [137](#bib.bib137)]以及因果贝叶斯网络[[138](#bib.bib138), [139](#bib.bib139)]；然而，这些方法在医学异常检测中的应用仍然很少。
- en: Uncertainty estimation is another characteristic that most current state-of-the-art
    anomaly detection algorithms lack. Such methods quantitatively estimate how a
    small change in input parameters affects model predictions. This can be indicative
    of model confidence. For instance, Bayesian Deep Learning [[140](#bib.bib140)]
    could be used to generate probabilistic scores, where the model parameters are
    approximated through a variational method, generating uncertainty information
    regarding the model weights, such that one can observe the uncertainty of the
    model outputs. We would like to acknowledge the work of Leibig et. al [[141](#bib.bib141)]
    where they illustrate how the computed measure of uncertainty can be utilised
    to refer a subset of difficult cases for further inspection. Furthermore, Bayesian
    uncertainty estimation has been applied for estimating the quality of medical
    image segmentation [[142](#bib.bib142), [143](#bib.bib143), [144](#bib.bib144)],
    and sclerosis lesion detection [[145](#bib.bib145)]. We believe further extensive
    investigation will allow rapid application of uncertainty estimation measure in
    the medical anomaly detection algorithms.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定性估计是目前大多数最先进的异常检测算法缺乏的另一个特征。这些方法定量估计输入参数的微小变化如何影响模型预测。这可以指示模型的信心。例如，贝叶斯深度学习
    [[140](#bib.bib140)] 可以用来生成概率评分，其中模型参数通过变分方法进行近似，从而生成关于模型权重的不确定性信息，使得可以观察到模型输出的不确定性。我们想要感谢
    Leibig 等人 [[141](#bib.bib141)] 的工作，他们展示了如何利用计算出的不确定性度量来将一部分困难案例转交进一步检查。此外，贝叶斯不确定性估计已被应用于医学图像分割质量
    [[142](#bib.bib142), [143](#bib.bib143), [144](#bib.bib144)] 和硬化性病变检测 [[145](#bib.bib145)]。我们相信，进一步的广泛研究将允许在医学异常检测算法中快速应用不确定性估计度量。
- en: IV-C Lack of Generalisation
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 缺乏泛化能力
- en: Another limitation that we observe in present research is the lack of generalisation
    to different operating conditions. For instance, [[146](#bib.bib146)] observed
    an abnormal heart sound detection model that achieves more than 99 % accuracy
    drop to 52.27 % when presented with an unseen dataset. Such performance instability
    significantly hinders the applicability of the deep learned models in real world
    life-or-death medical applications. One of the major reasons for such specificity
    of the models is data scarcity in the medical domain. Even though the number of
    datasets that are publicly available continues to increase, there are still a
    limited number of data samples available (compared to large scale datasets such
    are ImageNet). Most datasets are also highly curated, collected in controlled
    environments and restricted settings that do not capture the real data distribution.
    For instance, in Fig. [18](#S4.F18 "Figure 18 ‣ IV-C Lack of Generalisation ‣
    IV Challenges and Open Research Questions ‣ Deep Learning for Medical Anomaly
    Detection - A Survey") we visualise the t-SNE plot generated for the model in
    [[146](#bib.bib146)] using 2,000 randomly chosen samples (which contain both normal
    and abnormal samples) from PhysioNet/CinC 2016 dataset. This dataset is composed
    of 6 sub datasets (denoted a-f in the figure), collected from different devices
    (Welch Allyn Meditron, 3M Littmann, and ABES Electronic stethoscope), different
    capture environments (Lab setting and hospitals), varying age groups, etc.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在当前研究中观察到的另一个限制是对不同操作条件的缺乏泛化能力。例如，[[146](#bib.bib146)] 观察到一个异常心音检测模型在处理未见数据集时，其准确率从超过
    99% 降低到 52.27%。这种性能不稳定显著阻碍了深度学习模型在实际生死医疗应用中的适用性。模型特异性的一个主要原因是医疗领域的数据稀缺。尽管公开数据集的数量不断增加，但可用的数据样本仍然有限（与如
    ImageNet 这样的大规模数据集相比）。大多数数据集也都是高度筛选的，收集于受控环境和限制设置中，这些环境无法捕捉到真实的数据分布。例如，在图 [18](#S4.F18
    "图 18 ‣ IV-C 缺乏泛化 ‣ IV 挑战与开放研究问题 ‣ 医学异常检测的深度学习 - 综述") 中，我们可视化了为 [[146](#bib.bib146)]
    中的模型生成的 t-SNE 图，该图使用了来自 PhysioNet/CinC 2016 数据集的 2,000 个随机选择的样本（包括正常样本和异常样本）。该数据集由
    6 个子数据集（图中标记为 a-f）组成，收集自不同设备（Welch Allyn Meditron、3M Littmann 和 ABES 电子听诊器）、不同采集环境（实验室设置和医院）、不同年龄组等。
- en: '![Refer to caption](img/d5d5b1fd130b95112e12748f60a118f2.png)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/d5d5b1fd130b95112e12748f60a118f2.png)'
- en: 'Figure 18: Visualisation of t-SNE plots for different domains in PhysioNet/CinC
    2016 dataset abnormal heart sound detection challenge. Image taken from [[146](#bib.bib146)]'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 图18：PhysioNet/CinC 2016 数据集异常心音检测挑战中，不同领域 t-SNE 图的可视化。图片摘自 [[146](#bib.bib146)]
- en: As illustrated in Figure [18](#S4.F18 "Figure 18 ‣ IV-C Lack of Generalisation
    ‣ IV Challenges and Open Research Questions ‣ Deep Learning for Medical Anomaly
    Detection - A Survey"), the samples of each subset are somewhat grouped together
    while the samples from different subsets are distributed across the embedding
    space. This example clearly illustrates the challenges associated with medical
    anomaly detection as the acquired samples may not optimally capture the population
    characteristics. If a diagnostic model is trained only on a particular sub-set
    of this dataset it would generate erroneous detections on another. Therefore,
    large scale datasets which capture the diverse nature of the full population are
    required.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[18](#S4.F18 "Figure 18 ‣ IV-C Lack of Generalisation ‣ IV Challenges and
    Open Research Questions ‣ Deep Learning for Medical Anomaly Detection - A Survey")所示，每个子集的样本在嵌入空间中有所分组，而不同子集的样本则分布在不同区域。这个例子清楚地展示了医学异常检测中的挑战，因为获得的样本可能无法最优地捕捉总体特征。如果诊断模型仅在这个数据集的特定子集上进行训练，它在其他子集上可能会产生错误的检测。因此，需要捕捉整个总体多样性的的大规模数据集。
- en: While large scale datasets akin to ImageNet are ideal, it is very expensive
    and sometimes not practically feasible to collect large scale annotated datasets
    in medical diagnostic research [[147](#bib.bib147), [148](#bib.bib148)]. Therefore,
    meta-learning and domain adaptation approaches could be of use when annotated
    examples are scarce. In particular, meta-learning, which is a sub-field of transfer
    learning, focuses on how a model trained for a particular task can be quickly
    adapted to a novel task. Hence, the learned knowledge is shared between the two
    tasks. Meta-learning is an emerging technique in the medical domain [[149](#bib.bib149),
    [148](#bib.bib148), [147](#bib.bib147)], and could be extensively utilised to
    train large scale models using limited data samples. In contrast to meta-learning,
    domain adaptation focuses on how a generalised model trained for the same task
    can be adapted to a particular sub-domain (such as subsets a-f in Fig. [18](#S4.F18
    "Figure 18 ‣ IV-C Lack of Generalisation ‣ IV Challenges and Open Research Questions
    ‣ Deep Learning for Medical Anomaly Detection - A Survey")) [[146](#bib.bib146)].
    Such approaches can also utilised to attain generalisation in medical anomaly
    detection such that a model trained on a specific domain can be adapted to other
    domains using few labeled examples.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管类似于ImageNet的大规模数据集是理想的，但在医学诊断研究中收集大规模注释数据集非常昂贵，有时也不切实际[[147](#bib.bib147),
    [148](#bib.bib148)]。因此，当注释样本稀缺时，元学习和领域适应方法可能会有用。特别是，元学习作为迁移学习的一个子领域，专注于如何将为特定任务训练的模型快速适应新任务。因此，学习到的知识在两个任务之间共享。元学习是医学领域的新兴技术[[149](#bib.bib149),
    [148](#bib.bib148), [147](#bib.bib147)]，可以广泛用于使用有限的数据样本训练大规模模型。与元学习相比，领域适应专注于如何将为相同任务训练的通用模型适应到特定的子领域（如图[18](#S4.F18
    "Figure 18 ‣ IV-C Lack of Generalisation ‣ IV Challenges and Open Research Questions
    ‣ Deep Learning for Medical Anomaly Detection - A Survey")中的a-f子集）[[146](#bib.bib146)]。这些方法也可以用于在医学异常检测中实现泛化，使得在特定领域训练的模型可以使用少量标记样本适应其他领域。
- en: IV-D Handling Data Imbalance and Unlabelled Data
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-D 处理数据不平衡和未标记数据
- en: The majority of existing public medical abnormality detection benchmarks are
    highly imbalanced in terms of normal and abnormal sample counts. In most scenarios
    it is comparatively easy to obtain normal samples compared to anomalous samples,
    yielding imbalanced datasets. This typically becomes an issue in supervised training
    as the model becomes more sensitive to the loss arising from the majority class,
    compared to classes with fewer examples. The most common approaches to address
    class imbalance in medical anomaly detection has been data re-sampling (under
    or over sampling) and cost sensitive training where more weight in the loss is
    assigned to the minority class [[150](#bib.bib150)].
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的大多数公共医学异常检测基准在正常样本和异常样本的数量上高度不平衡。在大多数情况下，相比于异常样本，获取正常样本相对容易，从而导致数据集的不平衡。这在监督训练中通常会成为一个问题，因为模型对多数类产生的损失变得更加敏感，而对少数类的损失则相对较小。解决医学异常检测中类别不平衡的最常见方法是数据重新采样（过采样或欠采样）和成本敏感训练，其中对少数类的损失赋予更多的权重[[150](#bib.bib150)]。
- en: However, data augmentation strategies such using GANs have recently emerged
    which are capable of generating synthetic data for training, and they are favoured
    over traditional methods for handling data imbalance [[151](#bib.bib151), [152](#bib.bib152)].
    For instance, in [[153](#bib.bib153), [151](#bib.bib151), [152](#bib.bib152)]
    the generator is used to synthesise realistic-looking minority class samples,
    thereby balancing the class distribution and avoiding overfitting. Despite their
    superior results compared to traditional methods, generating realistic looking
    data samples is an open research problem [[152](#bib.bib152)]. Further research
    is required to improve the quality of the synthesised samples and to determine
    effective GAN learning strategies that can better adapt to novelties in the abnormal
    (which is typically the minority) class.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，数据增强策略，如使用 GANs 的方法，最近出现了能够生成用于训练的合成数据，并且它们比传统方法更受青睐以处理数据不平衡 [[151](#bib.bib151),
    [152](#bib.bib152)]。例如，在 [[153](#bib.bib153), [151](#bib.bib151), [152](#bib.bib152)]
    中，生成器被用来合成具有现实感的少数类样本，从而平衡类别分布并避免过拟合。尽管与传统方法相比，它们的结果更优越，但生成现实感数据样本仍然是一个未解决的研究问题
    [[152](#bib.bib152)]。需要进一步研究以提高合成样本的质量，并确定能够更好适应异常（通常是少数类）新情况的有效 GAN 学习策略。
- en: Another interesting research direction for investigation is methods to handle
    unlabelled data. In most scenarios it is cheaper to obtain unlabelled data compared
    to labelled samples. Hence, if the training mechanism can leverage information
    in unlabelled samples, it could be highly beneficial. The sub-field of semi-supervised
    learning addresses this situation and GANs have also demonstrated tremendous success
    in a semi-supervised setting [[109](#bib.bib109)] where the trained discriminator
    is adapted to perform the normal abnormal classification task, instead of real/fake
    validation [[107](#bib.bib107)]. However, we observe that deep medical anomaly
    detection methods rarely utilise semi-supervised learning strategies. Hence, further
    investigation should be carried out to introduce such strategies into the medical
    domain.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的研究方向是处理未标记数据的方法。在大多数情况下，获取未标记数据的成本低于获取标记样本的成本。因此，如果训练机制能够利用未标记样本中的信息，这可能会带来极大的好处。半监督学习的子领域处理这种情况，GANs
    在半监督环境中也展示了巨大的成功 [[109](#bib.bib109)]，在这种情况下，训练的鉴别器被调整为执行正常与异常分类任务，而不是实际/虚假验证
    [[107](#bib.bib107)]。然而，我们观察到深度医学异常检测方法很少利用半监督学习策略。因此，应该进一步研究将这些策略引入医学领域。
- en: In addition to semi-supervised learning, self-supervised learning is another
    new research direction with significant potential. In contrast to semi-supervised
    learning, self-supervised learning considers learning from internal cues. In particular,
    it uses preliminary tasks such as context prediction [[154](#bib.bib154)], colorization
    [[155](#bib.bib155)], and design a jigsaw puzzle game [[156](#bib.bib156)] to
    pre-train the model such that it learns about the data distribution. Most importantly,
    these pretext tasks do not require labelled data and the objectives are designed
    to generate labels automatically. Then, the learned knowledge is transferred to
    different downstream tasks such as image classification, object detection, and
    action recognition.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 除了半监督学习，自监督学习是另一个具有显著潜力的新研究方向。与半监督学习不同，自监督学习考虑从内部线索中学习。特别是，它使用诸如上下文预测 [[154](#bib.bib154)]、着色
    [[155](#bib.bib155)] 和设计拼图游戏 [[156](#bib.bib156)] 等预备任务来预训练模型，从而让其了解数据分布。最重要的是，这些预任务不需要标记数据，目标是自动生成标签。然后，学到的知识被转移到不同的下游任务中，如图像分类、目标检测和动作识别。
- en: Recent works have investigated self-supervised learning for anomaly detection.
    For instance, in [[157](#bib.bib157)] the authors investigate the objective of
    predicting the indices of randomly permuted video frames as the self-supervised
    objective. The authors show that implicitly reasoning about the relative positions
    of the objects and their motions, which is beneficial to detect abnormal behaviour.
    However, we observe that self-supervised learning has not yet emerged into the
    medical anomaly detection domain. We observe the potential of utilising pretext
    tasks such as medical image segmentation, artificially synthesising rotated images
    as self-supervised objectives in this filed. Therefore, further investigations
    can be carried out to assess the viability of such techniques.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究探讨了自监督学习在异常检测中的应用。例如，在[[157](#bib.bib157)]中，作者研究了将随机排列的视频帧的索引作为自监督目标。作者表明，通过隐式推理对象的相对位置及其运动，有助于检测异常行为。然而，我们观察到自监督学习尚未在医学异常检测领域出现。我们发现，利用诸如医学图像分割、人工合成旋转图像等预文本任务作为自监督目标在此领域具有潜力。因此，进一步的研究可以评估这些技术的可行性。
- en: V Conclusion
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this survey paper, we have discussed various approaches across deep learning-based
    medical anomaly detection. In particular, we have outlined different data capture
    settings across different medical applications, numerous deep learning architectures
    that have been motivated due to these different data types and problem specifications,
    and various learning strategies that have been applied. This structured analysis
    of deep medical anomaly detection research methodologies enabled comparing and
    contrasting existing state-of-the-art techniques despite their application differences.
    Moreover, we provided a comprehensive overview of deep model interpretation strategies,
    outlining the strengths and weaknesses of those interpretation mechanisms. As
    concluding remarks, we outlined key limitations of existing deep medical anomaly
    detection techniques and proposed possible future research directions for further
    investigation.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇综述论文中，我们讨论了基于深度学习的医学异常检测的各种方法。特别是，我们概述了不同医学应用中的数据捕捉设置，介绍了由于这些不同数据类型和问题规格而激发的多种深度学习架构，以及应用的各种学习策略。这种对深度医学异常检测研究方法的结构化分析使得尽管存在应用差异，但仍能够比较和对比现有的最先进技术。此外，我们提供了深度模型解释策略的全面概述，概述了这些解释机制的优缺点。作为结论，我们概述了现有深度医学异常检测技术的主要局限性，并提出了未来进一步研究的可能方向。
- en: References
  id: totrans-308
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] T. Fernando, S. Denman, D. Ahmedt-Aristizabal, S. Sridharan, K. R. Laurens,
    P. Johnston, and C. Fookes, “Neural memory plasticity for medical anomaly detection,”
    *Neural Networks*, 2020.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] T. Fernando, S. Denman, D. Ahmedt-Aristizabal, S. Sridharan, K. R. Laurens,
    P. Johnston和C. Fookes，“医学异常检测的神经记忆可塑性”，*神经网络*，2020年。'
- en: '[2] S. Thudumu, P. Branch, J. Jin, and J. J. Singh, “A comprehensive survey
    of anomaly detection techniques for high dimensional big data,” *Journal of Big
    Data*, vol. 7, no. 1, pp. 1–30, 2020.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] S. Thudumu, P. Branch, J. Jin和J. J. Singh，“高维大数据异常检测技术的全面综述”，*大数据期刊*，第7卷，第1期，页码1–30，2020年。'
- en: '[3] R. Chalapathy and S. Chawla, “Deep learning for anomaly detection: A survey,”
    *arXiv preprint arXiv:1901.03407*, 2019.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] R. Chalapathy和S. Chawla，“异常检测的深度学习：综述”，*arXiv预印本arXiv:1901.03407*，2019年。'
- en: '[4] Z. Zhao, S. Cerf, R. Birke, B. Robu, S. Bouchenak, S. B. Mokhtar, and L. Y.
    Chen, “Robust anomaly detection on unreliable data,” in *2019 49th Annual IEEE/IFIP
    International Conference on Dependable Systems and Networks (DSN)*.   IEEE, 2019,
    pp. 630–637.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Z. Zhao, S. Cerf, R. Birke, B. Robu, S. Bouchenak, S. B. Mokhtar和L. Y.
    Chen，“在不可靠数据上进行稳健的异常检测”，收录于*2019年第49届IEEE/IFIP国际依赖系统与网络会议（DSN）*。IEEE，2019年，页码630–637。'
- en: '[5] K. Pogorelov, K. R. Randel, C. Griwodz, S. L. Eskeland, T. de Lange, D. Johansen,
    C. Spampinato, D.-T. Dang-Nguyen, M. Lux, P. T. Schmidt *et al.*, “Kvasir: A multi-class
    image dataset for computer aided gastrointestinal disease detection,” in *Proceedings
    of the 8th ACM on Multimedia Systems Conference*, 2017, pp. 164–169.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] K. Pogorelov, K. R. Randel, C. Griwodz, S. L. Eskeland, T. de Lange, D.
    Johansen, C. Spampinato, D.-T. Dang-Nguyen, M. Lux, P. T. Schmidt *等人*，“Kvasir:
    一种用于计算机辅助胃肠疾病检测的多类别图像数据集”，收录于*第8届ACM多媒体系统会议论文集*，2017年，页码164–169。'
- en: '[6] G. D. Clifford, C. Liu, B. Moody, D. Springer, I. Silva, Q. Li, and R. G.
    Mark, “Classification of normal/abnormal heart sound recordings: The physionet/computing
    in cardiology challenge 2016,” in *2016 Computing in Cardiology Conference (CinC)*.   IEEE,
    2016, pp. 609–612.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] G. D. Clifford, C. Liu, B. Moody, D. Springer, I. Silva, Q. Li 和 R. G.
    Mark，“正常/异常心音记录的分类：PhysioNet/计算心脏病学挑战 2016，” 在 *2016 计算心脏病学会议 (CinC)*。 IEEE，2016
    年，第 609–612 页。'
- en: '[7] N. Alahmadi, S. A. Evdokimov, Y. J. Kropotov, A. M. Müller, and L. Jäncke,
    “Different resting state eeg features in children from switzerland and saudi arabia,”
    *Frontiers in human neuroscience*, vol. 10, p. 559, 2016.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] N. Alahmadi, S. A. Evdokimov, Y. J. Kropotov, A. M. Müller 和 L. Jäncke，“瑞士和沙特阿拉伯儿童的不同静息状态
    EEG 特征，” *人类神经科学前沿*，第 10 卷，第 559 页，2016 年。'
- en: '[8] N. Görnitz, M. Kloft, K. Rieck, and U. Brefeld, “Toward supervised anomaly
    detection,” *Journal of Artificial Intelligence Research*, vol. 46, pp. 235–262,
    2013.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] N. Görnitz, M. Kloft, K. Rieck 和 U. Brefeld，“朝着监督异常检测的方向，” *人工智能研究期刊*，第
    46 卷，第 235–262 页，2013 年。'
- en: '[9] A. L. Beam and I. S. Kohane, “Big data and machine learning in health care,”
    *Jama*, vol. 319, no. 13, pp. 1317–1318, 2018.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] A. L. Beam 和 I. S. Kohane，“医疗保健中的大数据和机器学习，” *Jama*，第 319 卷，第 13 期，第 1317–1318
    页，2018 年。'
- en: '[10] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” *Neural computation*,
    vol. 9, no. 8, pp. 1735–1780, 1997.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] S. Hochreiter 和 J. Schmidhuber，“长短期记忆，” *神经计算*，第 9 卷，第 8 期，第 1735–1780
    页，1997 年。'
- en: '[11] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, “Empirical evaluation of
    gated recurrent neural networks on sequence modeling,” *arXiv preprint arXiv:1412.3555*,
    2014.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] J. Chung, C. Gulcehre, K. Cho 和 Y. Bengio，“门控递归神经网络在序列建模中的实证评估，” *arXiv
    预印本 arXiv:1412.3555*，2014 年。'
- en: '[12] K. Rasheed, A. Qayyum, J. Qadir, S. Sivathamboo, P. Kwan, L. Kuhlmann,
    T. O’Brien, and A. Razi, “Machine learning for predicting epileptic seizures using
    eeg signals: A review,” *arXiv preprint arXiv:2002.01925*, 2020.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] K. Rasheed, A. Qayyum, J. Qadir, S. Sivathamboo, P. Kwan, L. Kuhlmann,
    T. O’Brien 和 A. Razi，“利用 EEG 信号预测癫痫发作的机器学习：综述，” *arXiv 预印本 arXiv:2002.01925*，2020
    年。'
- en: '[13] S. Li, F. Li, S. Tang, and W. Xiong, “A review of computer-aided heart
    sound detection techniques,” *BioMed Research International*, vol. 2020, 2020.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] S. Li, F. Li, S. Tang 和 W. Xiong，“计算机辅助心音检测技术综述，” *生物医学研究国际*，第 2020 卷，2020
    年。'
- en: '[14] W. Du, N. Rao, D. Liu, H. Jiang, C. Luo, Z. Li, T. Gan, and B. Zeng, “Review
    on the applications of deep learning in the analysis of gastrointestinal endoscopy
    images,” *IEEE Access*, vol. 7, pp. 142 053–142 069, 2019.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] W. Du, N. Rao, D. Liu, H. Jiang, C. Luo, Z. Li, T. Gan 和 B. Zeng，“关于深度学习在胃肠内窥镜图像分析中的应用综述，”
    *IEEE Access*，第 7 卷，第 142 053–142 069 页，2019 年。'
- en: '[15] A. S. Lundervold and A. Lundervold, “An overview of deep learning in medical
    imaging focusing on mri,” *Zeitschrift für Medizinische Physik*, vol. 29, no. 2,
    pp. 102–127, 2019.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] A. S. Lundervold 和 A. Lundervold，“聚焦于 MRI 的医学成像中深度学习的概述，” *医学物理学杂志*，第
    29 卷，第 2 期，第 102–127 页，2019 年。'
- en: '[16] S. Soffer, E. Klang, O. Shimon, N. Nachmias, R. Eliakim, S. Ben-Horin,
    U. Kopylov, and Y. Barash, “Deep learning for wireless capsule endoscopy: a systematic
    review and meta-analysis,” *Gastrointestinal Endoscopy*, 2020.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] S. Soffer, E. Klang, O. Shimon, N. Nachmias, R. Eliakim, S. Ben-Horin,
    U. Kopylov 和 Y. Barash，“无线胶囊内窥镜的深度学习：系统评价与荟萃分析，” *胃肠内窥镜*，2020 年。'
- en: '[17] Z. Ebrahimi, M. Loni, M. Daneshtalab, and A. Gharehbaghi, “A review on
    deep learning methods for ecg arrhythmia classification,” *Expert Systems with
    Applications: X*, p. 100033, 2020.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Z. Ebrahimi, M. Loni, M. Daneshtalab 和 A. Gharehbaghi，“深度学习方法在 ECG 心律失常分类中的综述，”
    *应用专家系统：X*，第 100033 页，2020 年。'
- en: '[18] S. P. Singh, “Magnetoencephalography: basic principles,” *Annals of Indian
    Academy of Neurology*, vol. 17, no. Suppl 1, p. S107, 2014.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] S. P. Singh，“磁脑电图：基本原理，” *印度神经学会年鉴*，第 17 卷，第补充 1 期，第 S107 页，2014 年。'
- en: '[19] A. Lardone, M. Liparoti, P. Sorrentino, R. Rucco, F. Jacini, A. Polverino,
    R. Minino, M. Pesoli, F. Baselice, A. Sorriso *et al.*, “Mindfulness meditation
    is related to long-lasting changes in hippocampal functional topology during resting
    state: a magnetoencephalography study,” *Neural plasticity*, vol. 2018, 2018.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] A. Lardone, M. Liparoti, P. Sorrentino, R. Rucco, F. Jacini, A. Polverino,
    R. Minino, M. Pesoli, F. Baselice 和 A. Sorriso *等*，“正念冥想与静息状态下海马功能拓扑的持久变化相关：一项磁脑电图研究，”
    *神经可塑性*，第 2018 卷，2018 年。'
- en: '[20] F. Jacini, P. Sorrentino, A. Lardone, R. Rucco, F. Baselice, C. Cavaliere,
    M. Aiello, M. Orsini, A. Iavarone, V. Manzo *et al.*, “Amnestic mild cognitive
    impairment is associated with frequency-specific brain network alterations in
    temporal poles,” *Frontiers in aging neuroscience*, vol. 10, p. 400, 2018.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] F. Jacini, P. Sorrentino, A. Lardone, R. Rucco, F. Baselice, C. Cavaliere,
    M. Aiello, M. Orsini, A. Iavarone, V. Manzo *等*，"健忘型轻度认知障碍与颞极特定频率脑网络改变相关"，*衰老神经科学前沿*，第10卷，第400页，2018年。'
- en: '[21] R. Rucco, M. Liparoti, F. Jacini, F. Baselice, A. Antenora, G. De Michele,
    C. Criscuolo, A. Vettoliere, L. Mandolesi, G. Sorrentino *et al.*, “Mutations
    in the spast gene causing hereditary spastic paraplegia are related to global
    topological alterations in brain functional networks,” *Neurological Sciences*,
    vol. 40, no. 5, pp. 979–984, 2019.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] R. Rucco, M. Liparoti, F. Jacini, F. Baselice, A. Antenora, G. De Michele,
    C. Criscuolo, A. Vettoliere, L. Mandolesi, G. Sorrentino *等*，"导致遗传性痉挛性截瘫的 spast
    基因突变与脑功能网络的全球拓扑变化相关"，*神经科学*，第40卷，第5期，第979–984页，2019年。'
- en: '[22] A. Hasasneh, N. Kampel, P. Sripad, N. J. Shah, and J. Dammers, “Deep learning
    approach for automatic classification of ocular and cardiac artifacts in meg data,”
    *Journal of Engineering*, vol. 2018, 2018.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] A. Hasasneh, N. Kampel, P. Sripad, N. J. Shah, 和 J. Dammers，"基于深度学习的 MEG
    数据中眼部和心脏伪影的自动分类方法"，*工程学杂志*，第2018卷，2018年。'
- en: '[23] M. Lopez-Martin, A. Nevado, and B. Carro, “Detection of early stages of
    alzheimer’s disease based on meg activity with a randomized convolutional neural
    network,” *Artificial Intelligence in Medicine*, vol. 107, p. 101924, 2020.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] M. Lopez-Martin, A. Nevado, 和 B. Carro，"基于 MEG 活动和随机卷积神经网络的早期阿尔茨海默病检测"，*医学中的人工智能*，第107卷，第101924页，2020年。'
- en: '[24] J. Aoe, R. Fukuma, T. Yanagisawa, T. Harada, M. Tanaka, M. Kobayashi,
    Y. Inoue, S. Yamamoto, Y. Ohnishi, and H. Kishima, “Automatic diagnosis of neurological
    diseases using meg signals with a deep neural network,” *Scientific reports*,
    vol. 9, no. 1, pp. 1–9, 2019.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] J. Aoe, R. Fukuma, T. Yanagisawa, T. Harada, M. Tanaka, M. Kobayashi,
    Y. Inoue, S. Yamamoto, Y. Ohnishi, 和 H. Kishima，"使用 MEG 信号和深度神经网络自动诊断神经系统疾病"，*科学报告*，第9卷，第1期，第1–9页，2019年。'
- en: '[25] D. H. Ballard, “Modular learning in neural networks.” in *AAAI*, 1987,
    pp. 279–284.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] D. H. Ballard，"神经网络中的模块化学习"，在 *AAAI*，1987年，第279–284页。'
- en: '[26] D. Charte, F. Charte, S. García, M. J. del Jesus, and F. Herrera, “A practical
    tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software
    and guidelines,” *Information Fusion*, vol. 44, pp. 78–96, 2018.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] D. Charte, F. Charte, S. García, M. J. del Jesus, 和 F. Herrera，"关于自编码器在非线性特征融合中的实用教程：分类、模型、软件和指南"，*信息融合*，第44卷，第78–96页，2018年。'
- en: '[27] P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol, “Extracting
    and composing robust features with denoising autoencoders,” in *Proceedings of
    the 25th international conference on Machine learning*, 2008, pp. 1096–1103.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] P. Vincent, H. Larochelle, Y. Bengio, 和 P.-A. Manzagol，"通过去噪自编码器提取和组合鲁棒特征"，在
    *第25届国际机器学习会议论文集*，2008年，第1096–1103页。'
- en: '[28] J. Cowton, I. Kyriazakis, T. Plötz, and J. Bacardit, “A combined deep
    learning gru-autoencoder for the early detection of respiratory disease in pigs
    using multiple environmental sensors,” *Sensors*, vol. 18, no. 8, p. 2521, 2018.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] J. Cowton, I. Kyriazakis, T. Plötz, 和 J. Bacardit，"一种结合深度学习的 GRU-自编码器用于利用多种环境传感器早期检测猪的呼吸道疾病"，*传感器*，第18卷，第8期，第2521页，2018年。'
- en: '[29] K. Wang, Y. Zhao, Q. Xiong, M. Fan, G. Sun, L. Ma, and T. Liu, “Research
    on healthy anomaly detection model based on deep learning from multiple time-series
    physiological signals,” *Scientific Programming*, vol. 2016, 2016.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] K. Wang, Y. Zhao, Q. Xiong, M. Fan, G. Sun, L. Ma, 和 T. Liu，"基于深度学习的多时间序列生理信号健康异常检测模型研究"，*科学编程*，第2016卷，2016年。'
- en: '[30] D. Sato, S. Hanaoka, Y. Nomura, T. Takenaga, S. Miki, T. Yoshikawa, N. Hayashi,
    and O. Abe, “A primitive study on unsupervised anomaly detection with an autoencoder
    in emergency head ct volumes,” in *Medical Imaging 2018: Computer-Aided Diagnosis*,
    vol. 10575.   International Society for Optics and Photonics, 2018, p. 105751P.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] D. Sato, S. Hanaoka, Y. Nomura, T. Takenaga, S. Miki, T. Yoshikawa, N. Hayashi,
    和 O. Abe，"一种关于紧急头部 CT 体积中无监督异常检测的初步研究"，在 *医学成像 2018: 计算机辅助诊断*，第10575卷。国际光学与光子学学会，2018年，第105751P页。'
- en: '[31] Y. Lu and P. Xu, “Anomaly detection for skin disease images using variational
    autoencoder,” *arXiv preprint arXiv:1807.01349*, 2018.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Y. Lu 和 P. Xu，"使用变分自编码器进行皮肤病图像异常检测"，*arXiv 预印本 arXiv:1807.01349*，2018年。'
- en: '[32] D. Zimmerer, S. A. Kohl, J. Petersen, F. Isensee, and K. H. Maier-Hein,
    “Context-encoding variational autoencoder for unsupervised anomaly detection,”
    *arXiv preprint arXiv:1812.05941*, 2018.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] D. Zimmerer, S. A. Kohl, J. Petersen, F. Isensee, 和 K. H. Maier-Hein,
    “用于无监督异常检测的上下文编码变分自编码器，” *arXiv预印本 arXiv:1812.05941*，2018。'
- en: '[33] H. Uzunova, S. Schultz, H. Handels, and J. Ehrhardt, “Unsupervised pathology
    detection in medical images using conditional variational autoencoders,” *International
    journal of computer assisted radiology and surgery*, vol. 14, no. 3, pp. 451–461,
    2019.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] H. Uzunova, S. Schultz, H. Handels, 和 J. Ehrhardt, “使用条件变分自编码器在医学图像中进行无监督病理检测，”
    *国际计算机辅助放射学与外科杂志*，第14卷，第3期，第451–461页，2019。'
- en: '[34] D. Saxena and J. Cao, “Generative adversarial networks (gans): Challenges,
    solutions, and future directions,” *arXiv preprint arXiv:2005.00065*, 2020.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] D. Saxena 和 J. Cao, “生成对抗网络（GANs）：挑战、解决方案和未来方向，” *arXiv预印本 arXiv:2005.00065*，2020。'
- en: '[35] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, and Y. Bengio, “Generative adversarial nets,” in *Advances in neural
    information processing systems*, 2014, pp. 2672–2680.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S.
    Ozair, A. Courville, 和 Y. Bengio, “生成对抗网络，” 收录于 *神经信息处理系统进展*，2014，第2672–2680页。'
- en: '[36] T. Fernando, S. Denman, S. Sridharan, and C. Fookes, “Task specific visual
    saliency prediction with memory augmented conditional generative adversarial networks,”
    in *2018 IEEE Winter Conference on Applications of Computer Vision (WACV)*.   IEEE,
    2018, pp. 1539–1548.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] T. Fernando, S. Denman, S. Sridharan, 和 C. Fookes, “基于记忆增强的条件生成对抗网络的任务特定视觉显著性预测，”
    收录于 *2018 IEEE冬季计算机视觉应用会议（WACV）*。 IEEE，2018，第1539–1548页。'
- en: '[37] ——, “Gd-gan: Generative adversarial networks for trajectory prediction
    and group detection in crowds,” in *Asian Conference on Computer Vision*.   Springer,
    2018, pp. 314–330.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] ——, “Gd-gan：用于人群中的轨迹预测和群体检测的生成对抗网络，” 收录于 *亚洲计算机视觉会议*。 Springer，2018，第314–330页。'
- en: '[38] T. Schlegl, P. Seeböck, S. M. Waldstein, G. Langs, and U. Schmidt-Erfurth,
    “f-anogan: Fast unsupervised anomaly detection with generative adversarial networks,”
    *Medical image analysis*, vol. 54, pp. 30–44, 2019.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] T. Schlegl, P. Seeböck, S. M. Waldstein, G. Langs, 和 U. Schmidt-Erfurth,
    “f-anogan：使用生成对抗网络进行快速无监督异常检测，” *医学图像分析*，第54卷，第30–44页，2019。'
- en: '[39] Z. Zhang and M. Sabuncu, “Generalized cross entropy loss for training
    deep neural networks with noisy labels,” in *Advances in neural information processing
    systems*, 2018, pp. 8778–8788.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Z. Zhang 和 M. Sabuncu, “针对噪声标签训练深度神经网络的广义交叉熵损失，” 收录于 *神经信息处理系统进展*，2018，第8778–8788页。'
- en: '[40] U. Schmidt-Erfurth, A. Sadeghipour, B. S. Gerendas, S. M. Waldstein, and
    H. Bogunović, “Artificial intelligence in retina,” *Progress in retinal and eye
    research*, vol. 67, pp. 1–29, 2018.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] U. Schmidt-Erfurth, A. Sadeghipour, B. S. Gerendas, S. M. Waldstein, 和
    H. Bogunović, “视网膜中的人工智能，” *视网膜与眼部研究进展*，第67卷，第1–29页，2018。'
- en: '[41] A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. Blau, and
    S. Thrun, “Dermatologist-level classification of skin cancer with deep neural
    networks,” *nature*, vol. 542, no. 7639, pp. 115–118, 2017.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. Blau, 和
    S. Thrun, “利用深度神经网络进行皮肤癌的皮肤科医生级别分类，” *自然*，第542卷，第7639期，第115–118页，2017。'
- en: '[42] J. Turner, A. Page, T. Mohsenin, and T. Oates, “Deep belief networks used
    on high resolution multichannel electroencephalography data for seizure detection,”
    *arXiv preprint arXiv:1708.08430*, 2017.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] J. Turner, A. Page, T. Mohsenin, 和 T. Oates, “深度信念网络在高分辨率多通道脑电图数据上的癫痫检测应用，”
    *arXiv预印本 arXiv:1708.08430*，2017。'
- en: '[43] P. K. Jawanpuria, M. Lapin, M. Hein, and B. Schiele, “Efficient output
    kernel learning for multiple tasks,” in *Advances in neural information processing
    systems*, 2015, pp. 1189–1197.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] P. K. Jawanpuria, M. Lapin, M. Hein, 和 B. Schiele, “多任务高效输出核学习，” 收录于 *神经信息处理系统进展*，2015，第1189–1197页。'
- en: '[44] P. Kisilev, E. Sason, E. Barkan, and S. Hashoul, “Medical image description
    using multi-task-loss cnn,” in *Deep Learning and Data Labeling for Medical Applications*.   Springer,
    2016, pp. 121–129.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] P. Kisilev, E. Sason, E. Barkan, 和 S. Hashoul, “使用多任务损失CNN进行医学图像描述，” 收录于
    *深度学习与医学应用的数据标注*。 Springer，2016，第121–129页。'
- en: '[45] R. Williams, “Gradient-based learning algorithm for recurrent networks,”
    *Back-propagation: theory, architectures and applications*, 1995.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] R. Williams, “基于梯度的递归网络学习算法，” *反向传播：理论、架构和应用*，1995。'
- en: '[46] S. Hochreiter, “The vanishing gradient problem during learning recurrent
    neural nets and problem solutions,” *International Journal of Uncertainty, Fuzziness
    and Knowledge-Based Systems*, vol. 6, no. 02, pp. 107–116, 1998.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] S. Hochreiter，“学习递归神经网络时的梯度消失问题及其解决方案，” *国际不确定性、模糊性和知识基础系统期刊*，第6卷，第02期，页码107–116，1998年。'
- en: '[47] Y. Bengio, P. Simard, and P. Frasconi, “Learning long-term dependencies
    with gradient descent is difficult,” *IEEE transactions on neural networks*, vol. 5,
    no. 2, pp. 157–166, 1994.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Y. Bengio, P. Simard, 和 P. Frasconi，“使用梯度下降学习长期依赖性是困难的，” *IEEE Transactions
    on Neural Networks*，第5卷，第2期，页码157–166，1994年。'
- en: '[48] K. Cho, B. Van Merriënboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk,
    and Y. Bengio, “Learning phrase representations using rnn encoder-decoder for
    statistical machine translation,” *arXiv preprint arXiv:1406.1078*, 2014.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] K. Cho, B. Van Merriënboer, C. Gulcehre, D. Bahdanau, F. Bougares, H.
    Schwenk, 和 Y. Bengio，“使用rnn编码器-解码器学习短语表示用于统计机器翻译，” *arXiv预印本arXiv:1406.1078*，2014年。'
- en: '[49] T. Fernando, S. Denman, A. McFadyen, S. Sridharan, and C. Fookes, “Tree
    memory networks for modelling long-term temporal dependencies,” *Neurocomputing*,
    vol. 304, pp. 64–81, 2018.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] T. Fernando, S. Denman, A. McFadyen, S. Sridharan, 和 C. Fookes，“用于建模长期时间依赖性的树记忆网络，”
    *Neurocomputing*，第304卷，页码64–81，2018年。'
- en: '[50] T. Fernando, S. Denman, S. Sridharan, and C. Fookes, “Learning temporal
    strategic relationships using generative adversarial imitation learning,” in *Proceedings
    of the 17th International Conference on Autonomous Agents and MultiAgent Systems*.   International
    Foundation for Autonomous Agents and Multiagent Systems, 2018, pp. 113–121.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] T. Fernando, S. Denman, S. Sridharan, 和 C. Fookes，“使用生成对抗模仿学习学习时间战略关系，”
    收录于 *第17届国际自主代理与多代理系统会议论文集*。 国际自主代理与多代理系统基金会，2018年，页码113–121。'
- en: '[51] ——, “Memory augmented deep generative models for forecasting the next
    shot location in tennis,” *IEEE Transactions on Knowledge and Data Engineering*,
    2019.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] ——，“用于预测网球下一个击球位置的记忆增强深度生成模型，” *IEEE Transactions on Knowledge and Data
    Engineering*，2019年。'
- en: '[52] H. Gammulle, S. Denman, S. Sridharan, and C. Fookes, “Forecasting future
    action sequences with neural memory networks,” *British Machine Vision Conference
    (BMVC)*, 2019.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] H. Gammulle, S. Denman, S. Sridharan, 和 C. Fookes，“使用神经记忆网络预测未来动作序列，”
    *英国机器视觉会议（BMVC）*，2019年。'
- en: '[53] Y. Ma and J. C. Principe, “A taxonomy for neural memory networks,” *IEEE
    transactions on neural networks and learning systems*, 2019.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] Y. Ma 和 J. C. Principe，“神经记忆网络的分类法，” *IEEE Transactions on Neural Networks
    and Learning Systems*，2019年。'
- en: '[54] T. Munkhdalai and H. Yu, “Neural semantic encoders,” in *Proceedings of
    the conference. Association for Computational Linguistics. Meeting*, vol. 1.   NIH
    Public Access, 2017, p. 397.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] T. Munkhdalai 和 H. Yu，“神经语义编码器，” 收录于 *计算语言学协会会议论文集*，第1卷。 NIH公共访问，2017年，页码397。'
- en: '[55] A. N. Jagannatha and H. Yu, “Bidirectional rnn for medical event detection
    in electronic health records,” in *Proceedings of the conference. Association
    for Computational Linguistics. North American Chapter. Meeting*, vol. 2016.   NIH
    Public Access, 2016, p. 473.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] A. N. Jagannatha 和 H. Yu，“用于电子健康记录中医疗事件检测的双向rnn，” 收录于 *计算语言学协会北美章节会议论文集*，第2016卷。
    NIH公共访问，2016年，页码473。'
- en: '[56] H. Yang and H. Gao, “Toward sustainable virtualized healthcare: extracting
    medical entities from chinese online health consultations using deep neural networks,”
    *Sustainability*, vol. 10, no. 9, p. 3292, 2018.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] H. Yang 和 H. Gao，“迈向可持续虚拟医疗：使用深度神经网络从中文在线健康咨询中提取医疗实体，” *Sustainability*，第10卷，第9期，页码3292，2018年。'
- en: '[57] S. Latif, M. Usman, R. Rana, and J. Qadir, “Phonocardiographic sensing
    using deep learning for abnormal heartbeat detection,” *IEEE Sensors Journal*,
    vol. 18, no. 22, pp. 9393–9400, 2018.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] S. Latif, M. Usman, R. Rana, 和 J. Qadir，“使用深度学习进行异常心跳检测的心音图传感，” *IEEE
    Sensors Journal*，第18卷，第22期，页码9393–9400，2018年。'
- en: '[58] D. Ahmedt-Aristizabal, T. Fernando, S. Denman, L. Petersson, M. J. Aburn,
    and C. Fookes, “Neural memory networks for robust classification of seizure type,”
    *International Conferences of the IEEE Engineering in Medicine and Biology Society*,
    2020.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] D. Ahmedt-Aristizabal, T. Fernando, S. Denman, L. Petersson, M. J. Aburn,
    和 C. Fookes，“用于稳健分类癫痫类型的神经记忆网络，” *国际工程医学与生物学学会会议*，2020年。'
- en: '[59] Y. Yoo, L. Y. Tang, T. Brosch, D. K. Li, S. Kolind, I. Vavasour, A. Rauscher,
    A. L. MacKay, A. Traboulsee, and R. C. Tam, “Deep learning of joint myelin and
    t1w mri features in normal-appearing brain tissue to distinguish between multiple
    sclerosis patients and healthy controls,” *NeuroImage: Clinical*, vol. 17, pp.
    169–178, 2018.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Y. Yoo, L. Y. Tang, T. Brosch, D. K. Li, S. Kolind, I. Vavasour, A. Rauscher,
    A. L. MacKay, A. Traboulsee, 和 R. C. Tam，“深度学习正常外观脑组织中的髓鞘和 t1w mri 特征，以区分多发性硬化症患者和健康对照组，”
    *NeuroImage: Clinical*，第 17 卷，页码 169–178，2018年。'
- en: '[60] G. E. Hinton, “Deep belief networks,” *Scholarpedia*, vol. 4, no. 5, p.
    5947, 2009.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] G. E. Hinton，“深度信念网络，” *Scholarpedia*，第 4 卷，第 5 期，页码 5947，2009年。'
- en: '[61] L. Breiman, “Random forests,” *Machine learning*, vol. 45, no. 1, pp.
    5–32, 2001.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] L. Breiman，“随机森林，” *Machine learning*，第 45 卷，第 1 期，页码 5–32，2001年。'
- en: '[62] D. Lu, K. Popuri, G. W. Ding, R. Balachandar, and M. F. Beg, “Multimodal
    and multiscale deep neural networks for the early diagnosis of alzheimer’s disease
    using structural mr and fdg-pet images,” *Scientific reports*, vol. 8, no. 1,
    pp. 1–13, 2018.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] D. Lu, K. Popuri, G. W. Ding, R. Balachandar, 和 M. F. Beg，“用于阿尔茨海默病早期诊断的多模态和多尺度深度神经网络，基于结构
    mri 和 fdg-pet 图像，” *Scientific reports*，第 8 卷，第 1 期，页码 1–13，2018年。'
- en: '[63] C. R. Jack Jr, M. A. Bernstein, N. C. Fox, P. Thompson, G. Alexander,
    D. Harvey, B. Borowski, P. J. Britson, J. L. Whitwell, C. Ward *et al.*, “The
    alzheimer’s disease neuroimaging initiative (adni): Mri methods,” *Journal of
    Magnetic Resonance Imaging: An Official Journal of the International Society for
    Magnetic Resonance in Medicine*, vol. 27, no. 4, pp. 685–691, 2008.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] C. R. Jack Jr, M. A. Bernstein, N. C. Fox, P. Thompson, G. Alexander,
    D. Harvey, B. Borowski, P. J. Britson, J. L. Whitwell, C. Ward *等*，“阿尔茨海默病神经影像学倡议
    (adni)：mri 方法，” *Journal of Magnetic Resonance Imaging: An Official Journal of
    the International Society for Magnetic Resonance in Medicine*，第 27 卷，第 4 期，页码
    685–691，2008年。'
- en: '[64] M. H. Le, J. Chen, L. Wang, Z. Wang, W. Liu, K.-T. T. Cheng, and X. Yang,
    “Automated diagnosis of prostate cancer in multi-parametric mri based on multimodal
    convolutional neural networks,” *Physics in Medicine & Biology*, vol. 62, no. 16,
    p. 6497, 2017.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] M. H. Le, J. Chen, L. Wang, Z. Wang, W. Liu, K.-T. T. Cheng, 和 X. Yang，“基于多模态卷积神经网络的多参数
    mri 前列腺癌自动化诊断，” *Physics in Medicine & Biology*，第 62 卷，第 16 期，页码 6497，2017年。'
- en: '[65] J. Islam and Y. Zhang, “Brain mri analysis for alzheimer’s disease diagnosis
    using an ensemble system of deep convolutional neural networks,” *Brain informatics*,
    vol. 5, no. 2, p. 2, 2018.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] J. Islam 和 Y. Zhang，“用于阿尔茨海默病诊断的脑 mri 分析，采用深度卷积神经网络的集成系统，” *Brain informatics*，第
    5 卷，第 2 期，页码 2，2018年。'
- en: '[66] D. Marcus, T. Wang *et al.*, “Oasis: Cross-sectional mri data in young,
    middle aged, nondemented, and demented older adults,” *Journal of Cognitive Neuroscience*.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] D. Marcus, T. Wang *等*，“Oasis: 年轻、中年、非痴呆和痴呆老年人的横断面 mri 数据，” *Journal of
    Cognitive Neuroscience*。'
- en: '[67] M. Shehata, F. Khalifa, A. Soliman, M. Ghazal, F. Taher, M. Abou El-Ghar,
    A. C. Dwyer, G. Gimel’farb, R. S. Keynton, and A. El-Baz, “Computer-aided diagnostic
    system for early detection of acute renal transplant rejection using diffusion-weighted
    mri,” *IEEE Transactions on Biomedical Engineering*, vol. 66, no. 2, pp. 539–552,
    2018.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] M. Shehata, F. Khalifa, A. Soliman, M. Ghazal, F. Taher, M. Abou El-Ghar,
    A. C. Dwyer, G. Gimel’farb, R. S. Keynton, 和 A. El-Baz，“基于扩散加权 mri 的急性肾移植排斥反应早期检测计算机辅助诊断系统，”
    *IEEE Transactions on Biomedical Engineering*，第 66 卷，第 2 期，页码 539–552，2018年。'
- en: '[68] L.-L. Zeng, H. Wang, P. Hu, B. Yang, W. Pu, H. Shen, X. Chen, Z. Liu,
    H. Yin, Q. Tan *et al.*, “Multi-site diagnostic classification of schizophrenia
    using discriminant deep learning with functional connectivity mri,” *EBioMedicine*,
    vol. 30, pp. 74–85, 2018.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] L.-L. Zeng, H. Wang, P. Hu, B. Yang, W. Pu, H. Shen, X. Chen, Z. Liu,
    H. Yin, Q. Tan *等*，“使用功能连接 mri 进行多站点精神分裂症诊断分类的判别深度学习，” *EBioMedicine*，第 30 卷，页码
    74–85，2018年。'
- en: '[69] Z. Han, B. Wei, S. Leung, I. B. Nachum, D. Laidley, and S. Li, “Automated
    pathogenesis-based diagnosis of lumbar neural foraminal stenosis via deep multiscale
    multitask learning,” *Neuroinformatics*, vol. 16, no. 3-4, pp. 325–337, 2018.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] Z. Han, B. Wei, S. Leung, I. B. Nachum, D. Laidley, 和 S. Li，“通过深度多尺度多任务学习自动化诊断腰椎神经孔狭窄，”
    *Neuroinformatics*，第 16 卷，第 3-4 期，页码 325–337，2018年。'
- en: '[70] J. Cheng, W. Huang, S. Cao, R. Yang, W. Yang, Z. Yun, Z. Wang, and Q. Feng,
    “Enhanced performance of brain tumor classification via tumor region augmentation
    and partition,” *PloS one*, vol. 10, no. 10, p. e0140381, 2015.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] J. Cheng, W. Huang, S. Cao, R. Yang, W. Yang, Z. Yun, Z. Wang, 和 Q. Feng，“通过肿瘤区域增强和分割提升脑肿瘤分类性能，”
    *PloS one*，第 10 卷，第 10 期，页码 e0140381，2015年。'
- en: '[71] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “Imagenet:
    A very deep convolutional networks for large-scale image recognition hierarchical
    image database,” in *2009 IEEE conference on computer vision and pattern recognition*.   Ieee,
    2009, pp. 248–255.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, 和 L. Fei-Fei，"Imagenet：用于大规模图像识别的深度卷积网络分层图像数据库"，在*2009
    IEEE计算机视觉与模式识别会议*，2009年，第248–255页。'
- en: '[72] E. Klang, Y. Barash, R. Y. Margalit, S. Soffer, O. Shimon, A. Albshesh,
    S. Ben-Horin, M. M. Amitai, R. Eliakim, and U. Kopylov, “Deep learning algorithms
    for automated detection of crohn’s disease ulcers by video capsule endoscopy,”
    *Gastrointestinal Endoscopy*, vol. 91, no. 3, pp. 606–613, 2020.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] E. Klang, Y. Barash, R. Y. Margalit, S. Soffer, O. Shimon, A. Albshesh,
    S. Ben-Horin, M. M. Amitai, R. Eliakim, 和 U. Kopylov，"基于深度学习算法的克罗恩病溃疡视频胶囊内镜自动检测"，*胃肠内镜*，第91卷，第3期，第606–613页，2020年。'
- en: '[73] F. Chollet, “Xception: Deep learning with depthwise separable convolutions,”
    in *Proceedings of the IEEE conference on computer vision and pattern recognition*,
    2017, pp. 1251–1258.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] F. Chollet，"Xception：深度学习与深度可分卷积"，在*IEEE计算机视觉与模式识别会议论文集*，2017年，第1251–1258页。'
- en: '[74] H. Alaskar, A. Hussain, N. Al-Aseem, P. Liatsis, and D. Al-Jumeily, “Application
    of convolutional neural networks for automated ulcer detection in wireless capsule
    endoscopy images,” *Sensors*, vol. 19, no. 6, p. 1265, 2019.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] H. Alaskar, A. Hussain, N. Al-Aseem, P. Liatsis, 和 D. Al-Jumeily，"卷积神经网络在无线胶囊内镜图像中自动检测溃疡的应用"，*传感器*，第19卷，第6期，第1265页，2019年。'
- en: '[75] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan,
    V. Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,” in *Proceedings
    of the IEEE conference on computer vision and pattern recognition*, 2015, pp.
    1–9.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan,
    V. Vanhoucke, 和 A. Rabinovich，"卷积更深"，在*IEEE计算机视觉与模式识别会议论文集*，2015年，第1–9页。'
- en: '[76] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
    with deep convolutional neural networks,” in *Advances in neural information processing
    systems*, 2012, pp. 1097–1105.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] A. Krizhevsky, I. Sutskever, 和 G. E. Hinton，"使用深度卷积神经网络的Imagenet分类"，在*神经信息处理系统进展*，2012年，第1097–1105页。'
- en: '[77] S. Fan, L. Xu, Y. Fan, K. Wei, and L. Li, “Computer-aided detection of
    small intestinal ulcer and erosion in wireless capsule endoscopy images,” *Physics
    in Medicine & Biology*, vol. 63, no. 16, p. 165001, 2018.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] S. Fan, L. Xu, Y. Fan, K. Wei, 和 L. Li，"计算机辅助检测无线胶囊内镜图像中的小肠溃疡和侵蚀"，*医学物理与生物学*，第63卷，第16期，第165001页，2018年。'
- en: '[78] S. Wang, Y. Xing, L. Zhang, H. Gao, and H. Zhang, “A systematic evaluation
    and optimization of automatic detection of ulcers in wireless capsule endoscopy
    on a large dataset using deep convolutional neural networks,” *Physics in Medicine
    & Biology*, vol. 64, no. 23, p. 235014, 2019.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] S. Wang, Y. Xing, L. Zhang, H. Gao, 和 H. Zhang，"基于深度卷积神经网络的大数据集无线胶囊内镜中溃疡自动检测的系统评估和优化"，*医学物理与生物学*，第64卷，第23期，第235014页，2019年。'
- en: '[79] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár, “Focal loss for
    dense object detection,” in *Proceedings of the IEEE international conference
    on computer vision*, 2017, pp. 2980–2988.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] T.-Y. Lin, P. Goyal, R. Girshick, K. He, 和 P. Dollár，"密集目标检测的焦点损失"，在*IEEE国际计算机视觉会议论文集*，2017年，第2980–2988页。'
- en: '[80] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
    recognition,” in *Proceedings of the IEEE conference on computer vision and pattern
    recognition*, 2016, pp. 770–778.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] K. He, X. Zhang, S. Ren, 和 J. Sun，"用于图像识别的深度残差学习"，在*IEEE计算机视觉与模式识别会议论文集*，2016年，第770–778页。'
- en: '[81] H. Gammulle, S. Denman, S. Sridharan, and C. Fookes, “Two-stream deep
    feature modelling for automated video endoscopy data analysis,” *International
    Conference on Medical Image Computing and Computer Assisted Intervention*, 2020.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] H. Gammulle, S. Denman, S. Sridharan, 和 C. Fookes，"用于自动视频内镜数据分析的双流深度特征建模"，*医学图像计算与计算机辅助手术国际会议*，2020年。'
- en: '[82] A. Santoro, D. Raposo, D. G. Barrett, M. Malinowski, R. Pascanu, P. Battaglia,
    and T. Lillicrap, “A simple neural network module for relational reasoning,” in
    *Advances in neural information processing systems*, 2017, pp. 4967–4976.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] A. Santoro, D. Raposo, D. G. Barrett, M. Malinowski, R. Pascanu, P. Battaglia,
    和 T. Lillicrap，"用于关系推理的简单神经网络模块"，在*神经信息处理系统进展*，2017年，第4967–4976页。'
- en: '[83] K. Pogorelov, K. R. Randel, T. de Lange, S. L. Eskeland, C. Griwodz, D. Johansen,
    C. Spampinato, M. Taschwer, M. Lux, P. T. Schmidt *et al.*, “Nerthus: A bowel
    preparation quality video dataset,” in *Proceedings of the 8th ACM on Multimedia
    Systems Conference*, 2017, pp. 170–174.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] K. Pogorelov, K. R. Randel, T. de Lange, S. L. Eskeland, C. Griwodz, D.
    Johansen, C. Spampinato, M. Taschwer, M. Lux, P. T. Schmidt *等*，“Nerthus: 一种肠道准备质量视频数据集，”
    在 *第 8 届 ACM 多媒体系统会议论文集*，2017 年，页码 170–174。'
- en: '[84] K. Simonyan and A. Zisserman, “Very deep convolutional networks for large-scale
    image recognition,” *arXiv preprint arXiv:1409.1556*, 2014.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] K. Simonyan 和 A. Zisserman, “用于大规模图像识别的非常深的卷积网络，” *arXiv 预印本 arXiv:1409.1556*，2014
    年。'
- en: '[85] J. M.-T. Wu, M.-H. Tsai, Y. Z. Huang, S. H. Islam, M. M. Hassan, A. Alelaiwi,
    and G. Fortino, “Applying an ensemble convolutional neural network with savitzky–golay
    filter to construct a phonocardiogram prediction model,” *Applied Soft Computing*,
    vol. 78, pp. 29–40, 2019.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] J. M.-T. Wu, M.-H. Tsai, Y. Z. Huang, S. H. Islam, M. M. Hassan, A. Alelaiwi,
    和 G. Fortino, “应用 Savitzky–Golay 滤波器的集成卷积神经网络构建心音图预测模型，” *应用软计算*，第 78 卷，页码 29–40，2019
    年。'
- en: '[86] A. Savitzky and M. J. Golay, “Smoothing and differentiation of data by
    simplified least squares procedures.” *Analytical chemistry*, vol. 36, no. 8,
    pp. 1627–1639, 1964.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] A. Savitzky 和 M. J. Golay, “通过简化的最小二乘法程序对数据进行平滑和微分。” *分析化学*，第 36 卷，第 8
    期，页码 1627–1639，1964 年。'
- en: '[87] F. Li, H. Tang, S. Shang, K. Mathiak, and F. Cong, “Classification of
    heart sounds using convolutional neural network,” *Applied Sciences*, vol. 10,
    no. 11, p. 3956, 2020.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] F. Li, H. Tang, S. Shang, K. Mathiak, 和 F. Cong, “使用卷积神经网络分类心音，” *应用科学*，第
    10 卷，第 11 期，页码 3956，2020 年。'
- en: '[88] T.-c. I. Yang and H. Hsieh, “Classification of acoustic physiological
    signals based on deep learning neural networks with augmented features,” in *2016
    Computing in Cardiology Conference (CinC)*.   IEEE, 2016, pp. 569–572.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] T.-c. I. Yang 和 H. Hsieh, “基于深度学习神经网络和增强特征的声学生理信号分类，” 在 *2016 年计算机心脏病学会议
    (CinC)*。IEEE，2016 年，页码 569–572。'
- en: '[89] S. Gao, Y. Zheng, and X. Guo, “Gated recurrent unit-based heart sound
    analysis for heart failure screening,” *BioMedical Engineering OnLine*, vol. 19,
    no. 1, p. 3, 2020.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] S. Gao, Y. Zheng, 和 X. Guo, “基于门控递归单元的心音分析用于心力衰竭筛查，” *生物医学工程在线*，第 19 卷，第
    1 期，页码 3，2020 年。'
- en: '[90] D. B. Springer, L. Tarassenko, and G. D. Clifford, “Logistic regression-hsmm-based
    heart sound segmentation,” *IEEE Transactions on Biomedical Engineering*, vol. 63,
    no. 4, pp. 822–832, 2015.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] D. B. Springer, L. Tarassenko, 和 G. D. Clifford, “基于逻辑回归-HSMM 的心音分割，”
    *IEEE 生物医学工程学报*，第 63 卷，第 4 期，页码 822–832，2015 年。'
- en: '[91] T. Dissanayake, T. Fernando, S. Denman, S. Sridharan, H. Ghaemmaghami,
    and C. Fookes, “A robust interpretable deep learning classifier for heart anomaly
    detection without segmentation,” *IEEE Journal of Biomedical and Health Informatics*,
    2020.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] T. Dissanayake, T. Fernando, S. Denman, S. Sridharan, H. Ghaemmaghami,
    和 C. Fookes, “一种稳健且可解释的深度学习分类器，用于无需分割的心脏异常检测，” *IEEE 生物医学与健康信息学期刊*，2020 年。'
- en: '[92] T. Fernando, H. Ghaemmaghami, S. Denman, S. Sridharan, N. Hussain, and
    C. Fookes, “Heart sound segmentation using bidirectional lstms with attention,”
    *IEEE Journal of Biomedical and Health Informatics*, vol. 24, no. 6, pp. 1601–1609,
    2019.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] T. Fernando, H. Ghaemmaghami, S. Denman, S. Sridharan, N. Hussain, 和 C.
    Fookes, “使用双向 LSTM 和注意力机制进行心音分割，” *IEEE 生物医学与健康信息学期刊*，第 24 卷，第 6 期，页码 1601–1609，2019
    年。'
- en: '[93] C. Molnar, *Interpretable Machine Learning*.   Lulu. com, 2020.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] C. Molnar, *可解释的机器学习*。Lulu.com，2020 年。'
- en: '[94] S. L. Oh, V. Jahmunah, C. P. Ooi, R.-S. Tan, E. J. Ciaccio, T. Yamakawa,
    M. Tanabe, M. Kobayashi, and U. R. Acharya, “Classification of heart sound signals
    using a novel deep wavenet model,” *Computer Methods and Programs in Biomedicine*,
    p. 105604, 2020.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] S. L. Oh, V. Jahmunah, C. P. Ooi, R.-S. Tan, E. J. Ciaccio, T. Yamakawa,
    M. Tanabe, M. Kobayashi, 和 U. R. Acharya, “使用新型深度 WaveNet 模型分类心音信号，” *生物医学计算方法与程序*，页码
    105604，2020 年。'
- en: '[95] K. Gadhoumi, J.-M. Lina, and J. Gotman, “Discriminating preictal and interictal
    states in patients with temporal lobe epilepsy using wavelet analysis of intracerebral
    eeg,” *Clinical neurophysiology*, vol. 123, no. 10, pp. 1906–1916, 2012.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] K. Gadhoumi, J.-M. Lina, 和 J. Gotman, “利用小波分析区分颞叶癫痫患者的先兆状态和间歇状态，” *临床神经生理学*，第
    123 卷，第 10 期，页码 1906–1916，2012 年。'
- en: '[96] K. M. Tsiouris, V. C. Pezoulas, M. Zervakis, S. Konitsiotis, D. D. Koutsouris,
    and D. I. Fotiadis, “A long short-term memory deep learning network for the prediction
    of epileptic seizures using eeg signals,” *Computers in biology and medicine*,
    vol. 99, pp. 24–37, 2018.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] K. M. Tsiouris, V. C. Pezoulas, M. Zervakis, S. Konitsiotis, D. D. Koutsouris
    和 D. I. Fotiadis，“用于癫痫发作预测的长短期记忆深度学习网络，基于 EEG 信号，” *计算生物学与医学*，第 99 卷，页码 24–37，2018
    年。'
- en: '[97] D. Thara, B. PremaSudha, and F. Xiong, “Epileptic seizure detection and
    prediction using stacked bidirectional long short term memory,” *Pattern Recognition
    Letters*, vol. 128, pp. 529–535, 2019.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] D. Thara, B. PremaSudha 和 F. Xiong，“使用堆叠双向长短期记忆网络进行癫痫发作检测和预测，” *模式识别快报*，第
    128 卷，页码 529–535，2019 年。'
- en: '[98] H. Khan, L. Marcuse, M. Fields, K. Swann, and B. Yener, “Focal onset seizure
    prediction using convolutional networks,” *IEEE Transactions on Biomedical Engineering*,
    vol. 65, no. 9, pp. 2109–2118, 9 2018.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] H. Khan, L. Marcuse, M. Fields, K. Swann 和 B. Yener，“使用卷积网络进行局部发作预测，”
    *IEEE 生物医学工程学报*，第 65 卷，第 9 期，页码 2109–2118，2018 年 9 月。'
- en: '[99] N. D. Truong, A. D. Nguyen, L. Kuhlmann, M. R. Bonyadi, J. Yang, and O. Kavehei,
    “A generalised seizure prediction with convolutional neural networks for intracranial
    and scalp electroencephalogram data analysis,” *arXiv preprint arXiv:1707.01976*,
    2017.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] N. D. Truong, A. D. Nguyen, L. Kuhlmann, M. R. Bonyadi, J. Yang 和 O. Kavehei，“基于卷积神经网络的通用发作预测，用于脑内和头皮
    EEG 数据分析，” *arXiv 预印本 arXiv:1707.01976*，2017 年。'
- en: '[100] M. Winterhalder, T. Maiwald, H. Voss, R. Aschenbrenner-Scheibe, J. Timmer,
    and A. Schulze-Bonhage, “The seizure prediction characteristic: a general framework
    to assess and compare seizure prediction methods,” *Epilepsy & Behavior*, vol. 4,
    no. 3, pp. 318–325, 2003.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] M. Winterhalder, T. Maiwald, H. Voss, R. Aschenbrenner-Scheibe, J. Timmer
    和 A. Schulze-Bonhage，“发作预测特征：评估和比较发作预测方法的一般框架，” *癫痫与行为*，第 4 卷，第 3 期，页码 318–325，2003
    年。'
- en: '[101] A. H. Shoeb, “Application of machine learning to epileptic seizure onset
    detection and treatment,” Ph.D. dissertation, Massachusetts Institute of Technology,
    2009.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] A. H. Shoeb，“机器学习在癫痫发作起始检测和治疗中的应用，” 博士学位论文，麻省理工学院，2009 年。'
- en: '[102] R. Hussein, M. O. Ahmed, R. Ward, Z. J. Wang, L. Kuhlmann, and Y. Guo,
    “Human intracranial eeg quantitative analysis and automatic feature learning for
    epileptic seizure prediction,” *arXiv preprint arXiv:1904.03603*, 2019.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] R. Hussein, M. O. Ahmed, R. Ward, Z. J. Wang, L. Kuhlmann 和 Y. Guo，“人脑皮层
    EEG 定量分析及癫痫发作预测的自动特征学习，” *arXiv 预印本 arXiv:1904.03603*，2019 年。'
- en: '[103] I. Kiral-Kornek, S. Roy, E. Nurse, B. Mashford, P. Karoly, T. Carroll,
    D. Payne, S. Saha, S. Baldassano, T. O’Brien *et al.*, “Epileptic seizure prediction
    using big data and deep learning: toward a mobile system,” *EBioMedicine*, vol. 27,
    pp. 103–111, 2018.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] I. Kiral-Kornek, S. Roy, E. Nurse, B. Mashford, P. Karoly, T. Carroll,
    D. Payne, S. Saha, S. Baldassano, T. O’Brien *等*，“使用大数据和深度学习进行癫痫发作预测：迈向移动系统，”
    *EBioMedicine*，第 27 卷，页码 103–111，2018 年。'
- en: '[104] L. Kuhlmann, P. Karoly, D. R. Freestone, B. H. Brinkmann, A. Temko, A. Barachant,
    F. Li, G. Titericz Jr, B. W. Lang, D. Lavery *et al.*, “Epilepsyecosystem. org:
    crowd-sourcing reproducible seizure prediction with long-term human intracranial
    eeg,” *Brain*, vol. 141, no. 9, pp. 2619–2630, 2018.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] L. Kuhlmann, P. Karoly, D. R. Freestone, B. H. Brinkmann, A. Temko, A.
    Barachant, F. Li, G. Titericz Jr, B. W. Lang, D. Lavery *等*，“Epilepsyecosystem.org：通过长期人脑皮层
    EEG 的众包重复发作预测，” *Brain*，第 141 卷，第 9 期，页码 2619–2630，2018 年。'
- en: '[105] M. J. Cook, T. J. O’Brien, S. F. Berkovic, M. Murphy, A. Morokoff, G. Fabinyi,
    W. D’Souza, R. Yerra, J. Archer, L. Litewka *et al.*, “Prediction of seizure likelihood
    with a long-term, implanted seizure advisory system in patients with drug-resistant
    epilepsy: a first-in-man study,” *The Lancet Neurology*, vol. 12, no. 6, pp. 563–571,
    2013.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] M. J. Cook, T. J. O’Brien, S. F. Berkovic, M. Murphy, A. Morokoff, G.
    Fabinyi, W. D’Souza, R. Yerra, J. Archer, L. Litewka *等*，“在药物耐受性癫痫患者中使用长期植入发作建议系统预测发作可能性：首次人体研究，”
    *柳叶刀神经学*，第 12 卷，第 6 期，页码 563–571，2013 年。'
- en: '[106] R. G. Andrzejak, K. Lehnertz, F. Mormann, C. Rieke, P. David, and C. E.
    Elger, “Indications of nonlinear deterministic and finite-dimensional structures
    in time series of brain electrical activity: Dependence on recording region and
    brain state,” *Physical Review E*, vol. 64, no. 6, p. 061907, 2001.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] R. G. Andrzejak, K. Lehnertz, F. Mormann, C. Rieke, P. David 和 C. E.
    Elger，“脑电活动时间序列中非线性确定性和有限维结构的迹象：依赖于记录区域和脑状态，” *物理评论 E*，第 64 卷，第 6 期，页码 061907，2001
    年。'
- en: '[107] N. D. Truong, L. Kuhlmann, M. R. Bonyadi, D. Querlioz, L. Zhou, and O. Kavehei,
    “Epileptic seizure forecasting with generative adversarial networks,” *IEEE Access*,
    vol. 7, pp. 143 999–144 009, 2019.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] N. D. Truong, L. Kuhlmann, M. R. Bonyadi, D. Querlioz, L. Zhou, 和 O.
    Kavehei，“使用生成对抗网络预测癫痫发作，” *IEEE Access*，第 7 卷，页 143 999–144 009，2019 年。'
- en: '[108] M. Ihle, H. Feldwisch-Drentrup, C. A. Teixeira, A. Witon, B. Schelter,
    J. Timmer, and A. Schulze-Bonhage, “Epilepsiae–a european epilepsy database,”
    *Computer methods and programs in biomedicine*, vol. 106, no. 3, pp. 127–138,
    2012.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] M. Ihle, H. Feldwisch-Drentrup, C. A. Teixeira, A. Witon, B. Schelter,
    J. Timmer, 和 A. Schulze-Bonhage，“Epilepsiae——一个欧洲癫痫数据库，” *计算机方法与生物医学程序*，第 106
    卷，第 3 期，页 127–138，2012 年。'
- en: '[109] H. Gammulle, S. Denman, S. Sridharan, and C. Fookes, “Fine-grained action
    segmentation using the semi-supervised action gan,” *Pattern Recognition*, vol. 98,
    p. 107039, 2020.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] H. Gammulle, S. Denman, S. Sridharan, 和 C. Fookes，“使用半监督动作 GAN 进行细粒度动作分割，”
    *模式识别*，第 98 卷，页 107039，2020 年。'
- en: '[110] A. Singh, S. Sengupta, and V. Lakshminarayanan, “Explainable deep learning
    models in medical image analysis,” *arXiv preprint arXiv:2005.13799*, 2020.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] A. Singh, S. Sengupta, 和 V. Lakshminarayanan，“医疗图像分析中的可解释深度学习模型，” *arXiv
    预印本 arXiv:2005.13799*，2020 年。'
- en: '[111] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba, “Learning
    deep features for discriminative localization,” in *Proceedings of the IEEE conference
    on computer vision and pattern recognition*, 2016, pp. 2921–2929.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, 和 A. Torralba，“用于辨别定位的深度特征学习，”
    见 *IEEE 计算机视觉与模式识别会议论文集*，2016 年，页 2921–2929。'
- en: '[112] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra,
    “Grad-cam: Visual explanations from deep networks via gradient-based localization,”
    in *Proceedings of the IEEE international conference on computer vision*, 2017,
    pp. 618–626.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, 和 D. Batra，“Grad-cam：通过基于梯度的定位从深度网络获得可视化解释，”
    见 *IEEE 国际计算机视觉会议论文集*，2017 年，页 618–626。'
- en: '[113] A. Chattopadhay, A. Sarkar, P. Howlader, and V. N. Balasubramanian, “Grad-cam++:
    Generalized gradient-based visual explanations for deep convolutional networks,”
    in *2018 IEEE Winter Conference on Applications of Computer Vision (WACV)*.   IEEE,
    2018, pp. 839–847.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] A. Chattopadhay, A. Sarkar, P. Howlader, 和 V. N. Balasubramanian，“Grad-cam++：基于梯度的深度卷积网络可视化解释的推广，”
    见 *2018 IEEE 冬季计算机视觉应用大会 (WACV)*。 IEEE，2018 年，页 839–847。'
- en: '[114] M. T. Ribeiro, S. Singh, and C. Guestrin, “” why should i trust you?”
    explaining the predictions of any classifier,” in *Proceedings of the 22nd ACM
    SIGKDD international conference on knowledge discovery and data mining*, 2016,
    pp. 1135–1144.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] M. T. Ribeiro, S. Singh, 和 C. Guestrin，“‘为什么我应该相信你？’解释任何分类器的预测，” 见 *第
    22 届 ACM SIGKDD 国际知识发现与数据挖掘大会论文集*，2016 年，页 1135–1144。'
- en: '[115] S. M. Lundberg and S.-I. Lee, “A unified approach to interpreting model
    predictions,” in *Advances in neural information processing systems*, 2017, pp.
    4765–4774.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] S. M. Lundberg 和 S.-I. Lee，“解释模型预测的统一方法，” 见 *神经信息处理系统进展*，2017 年，页 4765–4774。'
- en: '[116] S. M. Lundberg, B. Nair, M. S. Vavilala, M. Horibe, M. J. Eisses, T. Adams,
    D. E. Liston, D. K.-W. Low, S.-F. Newman, J. Kim *et al.*, “Explainable machine-learning
    predictions for the prevention of hypoxaemia during surgery,” *Nature biomedical
    engineering*, vol. 2, no. 10, pp. 749–760, 2018.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] S. M. Lundberg, B. Nair, M. S. Vavilala, M. Horibe, M. J. Eisses, T.
    Adams, D. E. Liston, D. K.-W. Low, S.-F. Newman, J. Kim *等*，“用于手术期间预防低氧血症的可解释机器学习预测，”
    *自然生物医学工程*，第 2 卷，第 10 期，页 749–760，2018 年。'
- en: '[117] A. Shrikumar, P. Greenside, and A. Kundaje, “Learning important features
    through propagating activation differences,” *arXiv preprint arXiv:1704.02685*,
    2017.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] A. Shrikumar, P. Greenside, 和 A. Kundaje，“通过传播激活差异学习重要特征，” *arXiv 预印本
    arXiv:1704.02685*，2017 年。'
- en: '[118] G. Montavon, S. Lapuschkin, A. Binder, W. Samek, and K.-R. Müller, “Explaining
    nonlinear classification decisions with deep taylor decomposition,” *Pattern Recognition*,
    vol. 65, pp. 211–222, 2017.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] G. Montavon, S. Lapuschkin, A. Binder, W. Samek, 和 K.-R. Müller，“使用深度泰勒分解解释非线性分类决策，”
    *模式识别*，第 65 卷，页 211–222，2017 年。'
- en: '[119] J. T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller, “Striving
    for simplicity: The all convolutional net,” *arXiv preprint arXiv:1412.6806*,
    2014.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] J. T. Springenberg, A. Dosovitskiy, T. Brox, 和 M. Riedmiller，“追求简单性：全卷积网络，”
    *arXiv 预印本 arXiv:1412.6806*，2014 年。'
- en: '[120] M. Sundararajan, A. Taly, and Q. Yan, “Axiomatic attribution for deep
    networks,” *arXiv preprint arXiv:1703.01365*, 2017.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] M. Sundararajan, A. Taly, 和 Q. Yan，“深度网络的公理归因，” *arXiv 预印本 arXiv:1703.01365*，2017
    年。'
- en: '[121] S. Pereira, R. Meier, V. Alves, M. Reyes, and C. A. Silva, “Automatic
    brain tumor grading from mri data using convolutional neural networks and quality
    assessment,” in *Understanding and interpreting machine learning in medical image
    computing applications*.   Springer, 2018, pp. 106–114.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] S. Pereira, R. Meier, V. Alves, M. Reyes, 和 C. A. Silva，“基于卷积神经网络和质量评估的自动脑肿瘤分级，”在
    *医学图像计算应用中的机器学习理解与解释*。Springer，2018年，第106–114页。'
- en: '[122] K. Young, G. Booth, B. Simpson, R. Dutton, and S. Shrapnel, “Deep neural
    network or dermatologist?” in *Interpretability of Machine Intelligence in Medical
    Image Computing and Multimodal Learning for Clinical Decision Support*.   Springer,
    2019, pp. 48–55.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] K. Young, G. Booth, B. Simpson, R. Dutton, 和 S. Shrapnel，“深度神经网络还是皮肤科医生？”在
    *医学图像计算和临床决策支持的机器智能解释性*。Springer，2019年，第48–55页。'
- en: '[123] N. Tsiknakis, E. Trivizakis, E. E. Vassalou, G. Z. Papadakis, D. A. Spandidos,
    A. Tsatsakis, J. Sánchez-García, R. López-González, N. Papanikolaou, A. H. Karantanas
    *et al.*, “Interpretable artificial intelligence framework for covid-19 screening
    on chest x-rays,” *Experimental and Therapeutic Medicine*, vol. 20, no. 2, pp.
    727–735, 2020.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] N. Tsiknakis, E. Trivizakis, E. E. Vassalou, G. Z. Papadakis, D. A. Spandidos,
    A. Tsatsakis, J. Sánchez-García, R. López-González, N. Papanikolaou, A. H. Karantanas
    *等*，“用于COVID-19筛查的可解释人工智能框架在胸部X光片上的应用，” *实验与治疗医学*，第20卷，第2期，第727–735页，2020年。'
- en: '[124] S. Chatterjee, F. Saad, C. Sarasaen, S. Ghosh, R. Khatun, P. Radeva,
    G. Rose, S. Stober, O. Speck, and A. Nürnberger, “Exploration of interpretability
    techniques for deep covid-19 classification using chest x-ray images,” *arXiv
    preprint arXiv:2006.02570*, 2020.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] S. Chatterjee, F. Saad, C. Sarasaen, S. Ghosh, R. Khatun, P. Radeva,
    G. Rose, S. Stober, O. Speck, 和 A. Nürnberg，“使用胸部X光图像进行深度COVID-19分类的可解释性技术探索，”
    *arXiv预印本arXiv:2006.02570*，2020年。'
- en: '[125] Z. Zhang, Y. Xie, F. Xing, M. McGough, and L. Yang, “Mdnet: A semantically
    and visually interpretable medical image diagnosis network,” in *Proceedings of
    the IEEE conference on computer vision and pattern recognition*, 2017, pp. 6428–6436.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] Z. Zhang, Y. Xie, F. Xing, M. McGough, 和 L. Yang，“Mdnet：一种语义和视觉可解释的医学图像诊断网络，”在
    *IEEE计算机视觉与模式识别会议论文集*，2017年，第6428–6436页。'
- en: '[126] H. Lee, S. T. Kim, and Y. M. Ro, “Generation of multimodal justification
    using visual word constraint model for explainable computer-aided diagnosis,”
    in *Interpretability of Machine Intelligence in Medical Image Computing and Multimodal
    Learning for Clinical Decision Support*.   Springer, 2019, pp. 21–29.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] H. Lee, S. T. Kim, 和 Y. M. Ro，“利用视觉词约束模型生成多模态解释，用于可解释的计算机辅助诊断，”在 *医学图像计算和临床决策支持的机器智能解释性*。Springer，2019年，第21–29页。'
- en: '[127] P. Zhu and M. Ogino, “Guideline-based additive explanation for computer-aided
    diagnosis of lung nodules,” in *Interpretability of Machine Intelligence in Medical
    Image Computing and Multimodal Learning for Clinical Decision Support*.   Springer,
    2019, pp. 39–47.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] P. Zhu 和 M. Ogino，“基于指南的附加解释用于计算机辅助诊断肺结节，”在 *医学图像计算和临床决策支持的机器智能解释性*。Springer，2019年，第39–47页。'
- en: '[128] M. R. Arbabshirani, B. K. Fornwalt, G. J. Mongelluzzo, J. D. Suever,
    B. D. Geise, A. A. Patel, and G. J. Moore, “Advanced machine learning in action:
    identification of intracranial hemorrhage on computed tomography scans of the
    head with clinical workflow integration,” *NPJ digital medicine*, vol. 1, no. 1,
    pp. 1–7, 2018.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] M. R. Arbabshirani, B. K. Fornwalt, G. J. Mongelluzzo, J. D. Suever,
    B. D. Geise, A. A. Patel, 和 G. J. Moore，“先进的机器学习应用：头部CT扫描中的颅内出血识别及其与临床工作流程的集成，”
    *NPJ数字医学*，第1卷，第1期，第1–7页，2018年。'
- en: '[129] A. Almazroa, S. Alodhayb, E. Osman, E. Ramadan, M. Hummadi, M. Dlaim,
    M. Alkatee, K. Raahemifar, and V. Lakshminarayanan, “Agreement among ophthalmologists
    in marking the optic disc and optic cup in fundus images,” *International ophthalmology*,
    vol. 37, no. 3, pp. 701–717, 2017.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] A. Almazroa, S. Alodhayb, E. Osman, E. Ramadan, M. Hummadi, M. Dlaim,
    M. Alkatee, K. Raahemifar, 和 V. Lakshminarayanan，“眼科医生在视网膜图像中标记视盘和视杯的协议，” *国际眼科学*，第37卷，第3期，第701–717页，2017年。'
- en: '[130] C. Huang, Y. Wu, Y. Zuo, K. Pei, and G. Min, “Towards experienced anomaly
    detector through reinforcement learning,” in *AAAI*, 2018.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] C. Huang, Y. Wu, Y. Zuo, K. Pei, 和 G. Min，“通过强化学习实现经验异常检测器，”在 *AAAI*，2018年。'
- en: '[131] M.-h. Oh and G. Iyengar, “Sequential anomaly detection using inverse
    reinforcement learning,” in *Proceedings of the 25th ACM SIGKDD International
    Conference on Knowledge Discovery & Data Mining*, 2019, pp. 1480–1490.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] M.-h. Oh 和 G. Iyengar，“使用逆强化学习进行序列异常检测，”在 *第25届ACM SIGKDD国际知识发现与数据挖掘会议论文集*，2019年，第1480–1490页。'
- en: '[132] J. G. Richens, C. M. Lee, and S. Johri, “Improving the accuracy of medical
    diagnosis with causal machine learning,” *Nature communications*, vol. 11, no. 1,
    pp. 1–9, 2020.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] J. G. Richens, C. M. Lee, 和 S. Johri，“利用因果机器学习提高医学诊断的准确性，” *自然通讯*，第11卷，第1期，页码1–9，2020年。'
- en: '[133] D. C. Castro, I. Walker, and B. Glocker, “Causality matters in medical
    imaging,” *Nature Communications*, vol. 11, no. 1, pp. 1–10, 2020.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] D. C. Castro, I. Walker, 和 B. Glocker，“因果性在医学成像中的重要性，” *自然通讯*，第11卷，第1期，页码1–10，2020年。'
- en: '[134] N. Altman and M. Krzywinski, “Association, correlation and causation,”
    *Nature Methods*, 2015.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] N. Altman 和 M. Krzywinski，“关联、相关性和因果关系，” *自然方法*，2015年。'
- en: '[135] M. Nauta, D. Bucur, and C. Seifert, “Causal discovery with attention-based
    convolutional neural networks,” *Machine Learning and Knowledge Extraction*, vol. 1,
    no. 1, pp. 312–340, 2019.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] M. Nauta, D. Bucur, 和 C. Seifert，“基于注意力的卷积神经网络中的因果发现，” *机器学习与知识提取*，第1卷，第1期，页码312–340，2019年。'
- en: '[136] H. Zenil, N. A. Kiani, F. Marabita, Y. Deng, S. Elias, A. Schmidt, G. Ball,
    and J. Tegnér, “An algorithmic information calculus for causal discovery and reprogramming
    systems,” *iScience*, vol. 19, pp. 1160–1172, 2019.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] H. Zenil, N. A. Kiani, F. Marabita, Y. Deng, S. Elias, A. Schmidt, G. Ball,
    和 J. Tegnér，“用于因果发现和重编程系统的算法信息微积分，” *iScience*，第19卷，页码1160–1172，2019年。'
- en: '[137] H. Zenil, N. A. Kiani, A. A. Zea, and J. Tegnér, “Causal deconvolution
    by algorithmic generative models,” *Nature Machine Intelligence*, vol. 1, no. 1,
    pp. 58–66, 2019.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] H. Zenil, N. A. Kiani, A. A. Zea, 和 J. Tegnér，“通过算法生成模型进行因果解卷积，” *自然机器智能*，第1卷，第1期，页码58–66，2019年。'
- en: '[138] Y. Zhang, S. Pal, M. Coates, and D. Ustebay, “Bayesian graph convolutional
    neural networks for semi-supervised classification,” in *Proceedings of the AAAI
    Conference on Artificial Intelligence*, vol. 33, 2019, pp. 5829–5836.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] Y. Zhang, S. Pal, M. Coates, 和 D. Ustebay，“用于半监督分类的贝叶斯图卷积神经网络，” 见 *AAAI人工智能会议论文集*，第33卷，2019年，页码5829–5836。'
- en: '[139] S. Pal, F. Regol, and M. Coates, “Bayesian graph convolutional neural
    networks using node copying,” *arXiv preprint arXiv:1911.04965*, 2019.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] S. Pal, F. Regol, 和 M. Coates，“使用节点复制的贝叶斯图卷积神经网络，” *arXiv 预印本 arXiv:1911.04965*，2019年。'
- en: '[140] A. Kendall and Y. Gal, “What uncertainties do we need in bayesian deep
    learning for computer vision?” in *Advances in neural information processing systems*,
    2017, pp. 5574–5584.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] A. Kendall 和 Y. Gal，“在计算机视觉的贝叶斯深度学习中，我们需要哪些不确定性？” 见 *神经信息处理系统进展*，2017年，页码5574–5584。'
- en: '[141] C. Leibig, V. Allken, M. S. Ayhan, P. Berens, and S. Wahl, “Leveraging
    uncertainty information from deep neural networks for disease detection,” *Scientific
    reports*, vol. 7, no. 1, pp. 1–14, 2017.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] C. Leibig, V. Allken, M. S. Ayhan, P. Berens, 和 S. Wahl，“利用深度神经网络中的不确定性信息进行疾病检测，”
    *科学报告*，第7卷，第1期，页码1–14，2017年。'
- en: '[142] Y. Kwon, J.-H. Won, B. J. Kim, and M. C. Paik, “Uncertainty quantification
    using bayesian neural networks in classification: Application to biomedical image
    segmentation,” *Computational Statistics & Data Analysis*, vol. 142, p. 106816,
    2020.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] Y. Kwon, J.-H. Won, B. J. Kim, 和 M. C. Paik，“分类中的贝叶斯神经网络的不确定性量化：应用于生物医学图像分割，”
    *计算统计与数据分析*，第142卷，页码106816，2020年。'
- en: '[143] T. DeVries and G. W. Taylor, “Leveraging uncertainty estimates for predicting
    segmentation quality,” *arXiv preprint arXiv:1807.00502*, 2018.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] T. DeVries 和 G. W. Taylor，“利用不确定性估计预测分割质量，” *arXiv 预印本 arXiv:1807.00502*，2018年。'
- en: '[144] P. Seeböck, J. I. Orlando, T. Schlegl, S. M. Waldstein, H. Bogunović,
    S. Klimscha, G. Langs, and U. Schmidt-Erfurth, “Exploiting epistemic uncertainty
    of anatomy segmentation for anomaly detection in retinal oct,” *IEEE transactions
    on medical imaging*, vol. 39, no. 1, pp. 87–98, 2019.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] P. Seeböck, J. I. Orlando, T. Schlegl, S. M. Waldstein, H. Bogunović,
    S. Klimscha, G. Langs, 和 U. Schmidt-Erfurth，“利用解剖分割的认知不确定性检测视网膜OCT中的异常，” *IEEE医学成像事务*，第39卷，第1期，页码87–98，2019年。'
- en: '[145] T. Nair, D. Precup, D. L. Arnold, and T. Arbel, “Exploring uncertainty
    measures in deep networks for multiple sclerosis lesion detection and segmentation,”
    *Medical image analysis*, vol. 59, p. 101557, 2020.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] T. Nair, D. Precup, D. L. Arnold, 和 T. Arbel，“探索深度网络中的不确定性度量用于多发性硬化症病变检测和分割，”
    *医学图像分析*，第59卷，页码101557，2020年。'
- en: '[146] T. Dissanayake, T. Fernando, S. Denman, H. Ghaemmaghami, S. Sridharan,
    and C. Fookes, “Domain generalization in biosignal classification,” *arXiv preprint
    arXiv:2011.06207*, 2020.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] T. Dissanayake, T. Fernando, S. Denman, H. Ghaemmaghami, S. Sridharan,
    和 C. Fookes，“生物信号分类中的领域泛化，” *arXiv 预印本 arXiv:2011.06207*，2020年。'
- en: '[147] S. Hu, J. Tomczak, and M. Welling, “Meta-learning for medical image classification,”
    *Conference on Medical Imaging with Deep Learning (MIDL 2018)*, 2018.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] S. Hu, J. Tomczak, 和 M. Welling，“医疗图像分类的元学习，” *医疗影像深度学习会议（MIDL 2018）*，2018年。'
- en: '[148] K. Mahajan, M. Sharma, and L. Vig, “Meta-dermdiagnosis: Few-shot skin
    disease identification using meta-learning,” in *Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition Workshops*, 2020, pp. 730–731.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] K. Mahajan, M. Sharma, 和 L. Vig，“Meta-dermdiagnosis：使用元学习的少样本皮肤病识别，”
    *IEEE/CVF计算机视觉与模式识别会议研讨会论文集*，2020年，第730–731页。'
- en: '[149] X. S. Zhang, F. Tang, H. H. Dodge, J. Zhou, and F. Wang, “Metapred: Meta-learning
    for clinical risk prediction with limited patient electronic health records,”
    in *Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery
    & Data Mining*, 2019, pp. 2487–2495.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] X. S. Zhang, F. Tang, H. H. Dodge, J. Zhou, 和 F. Wang，“Metapred：用于有限患者电子健康记录的临床风险预测的元学习，”
    *第25届ACM SIGKDD国际知识发现与数据挖掘会议论文集*，2019年，第2487–2495页。'
- en: '[150] J. M. Johnson and T. M. Khoshgoftaar, “Survey on deep learning with class
    imbalance,” *Journal of Big Data*, vol. 6, no. 1, p. 27, 2019.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] J. M. Johnson 和 T. M. Khoshgoftaar，“关于类不平衡的深度学习综述，” *大数据杂志*，第6卷，第1期，第27页，2019年。'
- en: '[151] L. Zhang, H. Yang, and Z. Jiang, “Imbalanced biomedical data classification
    using self-adaptive multilayer elm combined with dynamic gan,” *Biomedical engineering
    online*, vol. 17, no. 1, p. 181, 2018.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] L. Zhang, H. Yang, 和 Z. Jiang，“使用自适应多层ELM结合动态GAN进行不平衡生物医学数据分类，” *生物医学工程在线*，第17卷，第1期，第181页，2018年。'
- en: '[152] S. S. Mullick, S. Datta, and S. Das, “Generative adversarial minority
    oversampling,” in *Proceedings of the IEEE International Conference on Computer
    Vision*, 2019, pp. 1695–1704.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] S. S. Mullick, S. Datta, 和 S. Das，“生成对抗少数类过采样，” *IEEE国际计算机视觉会议论文集*，2019年，第1695–1704页。'
- en: '[153] T. Zhou, W. Liu, C. Zhou, and L. Chen, “Gan-based semi-supervised for
    imbalanced data classification,” in *2018 4th International Conference on Information
    Management (ICIM)*.   IEEE, 2018, pp. 17–21.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] T. Zhou, W. Liu, C. Zhou, 和 L. Chen，“基于GAN的半监督不平衡数据分类，” *2018年第四届国际信息管理会议（ICIM）*。IEEE，2018年，第17–21页。'
- en: '[154] C. Doersch, A. Gupta, and A. A. Efros, “Unsupervised visual representation
    learning by context prediction,” in *Proceedings of the IEEE international conference
    on computer vision*, 2015, pp. 1422–1430.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] C. Doersch, A. Gupta, 和 A. A. Efros，“通过上下文预测进行无监督视觉表示学习，” *IEEE国际计算机视觉会议论文集*，2015年，第1422–1430页。'
- en: '[155] R. Zhang, P. Isola, and A. A. Efros, “Colorful image colorization,” in
    *European conference on computer vision*.   Springer, 2016, pp. 649–666.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] R. Zhang, P. Isola, 和 A. A. Efros，“色彩丰富的图像上色，” *欧洲计算机视觉会议*。Springer，2016年，第649–666页。'
- en: '[156] M. Noroozi and P. Favaro, “Unsupervised learning of visual representations
    by solving jigsaw puzzles,” in *European Conference on Computer Vision*.   Springer,
    2016, pp. 69–84.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] M. Noroozi 和 P. Favaro，“通过解决拼图难题进行无监督学习的视觉表示，” *欧洲计算机视觉会议*。Springer，2016年，第69–84页。'
- en: '[157] R. Ali, M. U. K. Khan, and C. M. Kyung, “Self-supervised representation
    learning for visual anomaly detection,” *arXiv preprint arXiv:2006.09654*, 2020.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] R. Ali, M. U. K. Khan, 和 C. M. Kyung，“用于视觉异常检测的自监督表示学习，” *arXiv预印本arXiv:2006.09654*，2020年。'
- en: '[158] E. D. Bhandari and M. S. Badmera, “Chest abnormality detection from x-ray
    using deep learning,” *Chest*, vol. 6, no. 11, 2019.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] E. D. Bhandari 和 M. S. Badmera，“使用深度学习从X光中检测胸部异常，” *Chest*，第6卷，第11期，2019年。'
- en: '[159] C. Tataru, D. Yi, A. Shenoyas, and A. Ma, “Deep learning for abnormality
    detection in chest x-ray images,” in *IEEE Conference on Deep Learning*, 2017.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[159] C. Tataru, D. Yi, A. Shenoyas, 和 A. Ma，“用于胸部X光图像异常检测的深度学习，” *IEEE深度学习会议*，2017年。'
- en: '[160] Y.-X. Tang, Y.-B. Tang, Y. Peng, K. Yan, M. Bagheri, B. A. Redd, C. J.
    Brandon, Z. Lu, M. Han, J. Xiao *et al.*, “Automated abnormality classification
    of chest radiographs using deep convolutional neural networks,” *NPJ Digital Medicine*,
    vol. 3, no. 1, pp. 1–8, 2020.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[160] Y.-X. Tang, Y.-B. Tang, Y. Peng, K. Yan, M. Bagheri, B. A. Redd, C. J.
    Brandon, Z. Lu, M. Han, J. Xiao *等人*, “使用深度卷积神经网络对胸部X光片进行自动异常分类，” *NPJ Digital
    Medicine*，第3卷，第1期，第1–8页，2020年。'
- en: '[161] H. Wang and Y. Xia, “Chestnet: A deep neural network for classification
    of thoracic diseases on chest radiography,” *arXiv preprint arXiv:1807.03058*,
    2018.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[161] H. Wang 和 Y. Xia，“Chestnet：用于胸部X光影像中胸部疾病分类的深度神经网络，” *arXiv预印本arXiv:1807.03058*，2018年。'
- en: '[162] H. H. Pham, T. T. Le, D. T. Ngo, D. Q. Tran, and H. Q. Nguyen, “Interpreting
    chest x-rays via cnns that exploit hierarchical disease dependencies and uncertainty
    labels,” *arXiv preprint arXiv:2005.12734*, 2020.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[162] H. H. Pham, T. T. Le, D. T. Ngo, D. Q. Tran 和 H. Q. Nguyen, “通过利用分层疾病依赖性和不确定性标签的CNN解读胸部X射线，”
    *arXiv预印本 arXiv:2005.12734*，2020年。'
- en: '[163] J. Zhang, Y. Xie, Z. Liao, G. Pang, J. Verjans, W. Li, Z. Sun, J. He,
    Y. Li, C. Shen *et al.*, “Viral pneumonia screening on chest x-ray images using
    confidence-aware anomaly detection,” *arXiv: 2003.12338*, 2020.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[163] J. Zhang, Y. Xie, Z. Liao, G. Pang, J. Verjans, W. Li, Z. Sun, J. He,
    Y. Li, C. Shen *等*，“使用基于信心的异常检测在胸部X射线图像上筛查病毒性肺炎，” *arXiv: 2003.12338*，2020年。'
- en: '[164] S. Basu and S. Mitra, “Deep learning for screening covid-19 using chest
    x-ray images,” *arXiv preprint arXiv:2004.10507*, 2020.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[164] S. Basu 和 S. Mitra, “使用胸部X射线图像筛查COVID-19的深度学习，” *arXiv预印本 arXiv:2004.10507*，2020年。'
- en: '[165] V. Shah, R. Keniya, A. Shridharani, M. Punjabi, J. Shah, and N. Mehendale,
    “Diagnosis of covid-19 using ct scan images and deep learning techniques,” *medRxiv*,
    2020.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[165] V. Shah, R. Keniya, A. Shridharani, M. Punjabi, J. Shah 和 N. Mehendale,
    “使用CT扫描图像和深度学习技术诊断COVID-19，” *medRxiv*，2020年。'
- en: '[166] A. K. Mishra, S. K. Das, P. Roy, and S. Bandyopadhyay, “Identifying covid19
    from chest ct images: A deep convolutional neural networks based approach,” *Journal
    of Healthcare Engineering*, vol. 2020, 2020.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[166] A. K. Mishra, S. K. Das, P. Roy 和 S. Bandyopadhyay, “从胸部CT图像中识别COVID-19：基于深度卷积神经网络的方法，”
    *医疗保健工程杂志*，2020年。'
- en: '[167] V. Perumal, V. Narayanan, and S. J. S. Rajasekar, “Detection of covid-19
    using cxr and ct images using transfer learning and haralick features,” *Applied
    Intelligence*, pp. 1–18, 2020.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[167] V. Perumal, V. Narayanan 和 S. J. S. Rajasekar, “使用迁移学习和Haralick特征检测COVID-19的胸部X射线和CT图像，”
    *应用智能*，第1-18页，2020年。'
- en: '[168] S. Sharma, “Drawing insights from covid-19-infected patients using ct
    scan images and machine learning techniques: a study on 200 patients,” *Environmental
    Science and Pollution Research*, pp. 1–9, 2020.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[168] S. Sharma, “从COVID-19感染患者的CT扫描图像和机器学习技术中获取见解：对200名患者的研究，” *环境科学与污染研究*，第1-9页，2020年。'
- en: '[169] S. A. Harmon, T. H. Sanford, S. Xu, E. B. Turkbey, H. Roth, Z. Xu, D. Yang,
    A. Myronenko, V. Anderson, A. Amalou *et al.*, “Artificial intelligence for the
    detection of covid-19 pneumonia on chest ct using multinational datasets,” *Nature
    communications*, vol. 11, no. 1, pp. 1–7, 2020.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[169] S. A. Harmon, T. H. Sanford, S. Xu, E. B. Turkbey, H. Roth, Z. Xu, D.
    Yang, A. Myronenko, V. Anderson 和 A. Amalou *等*，“利用多国数据集在胸部CT中检测COVID-19肺炎的人工智能，”
    *自然通讯*，第11卷，第1期，第1-7页，2020年。'
- en: '[170] V. Makde, J. Bhavsar, S. Jain, and P. Sharma, “Deep neural network based
    classification of tumourous and non-tumorous medical images,” in *International
    Conference on Information and Communication Technology for Intelligent Systems*.   Springer,
    2017, pp. 199–206.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[170] V. Makde, J. Bhavsar, S. Jain 和 P. Sharma, “基于深度神经网络的肿瘤性和非肿瘤性医学图像分类，”
    在 *智能系统的信息与通信技术国际会议*。 施普林格，2017年，第199-206页。'
- en: '[171] X. Huang, J. Shan, and V. Vaidya, “Lung nodule detection in ct using
    3d convolutional neural networks,” in *2017 IEEE 14th International Symposium
    on Biomedical Imaging (ISBI 2017)*.   IEEE, 2017, pp. 379–383.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[171] X. Huang, J. Shan 和 V. Vaidya, “使用3D卷积神经网络在CT中检测肺结节，” 在 *2017年第14届IEEE生物医学成像国际研讨会（ISBI
    2017）*。 IEEE，2017年，第379-383页。'
- en: '[172] G. Jakimovski and D. Davcev, “Using double convolution neural network
    for lung cancer stage detection,” *Applied Sciences*, vol. 9, no. 3, p. 427, 2019.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[172] G. Jakimovski 和 D. Davcev, “使用双卷积神经网络进行肺癌分期检测，” *应用科学*，第9卷，第3期，第427页，2019年。'
- en: '[173] P. Afshar, A. Mohammadi, and K. N. Plataniotis, “Brain tumor type classification
    via capsule networks,” in *2018 25th IEEE International Conference on Image Processing
    (ICIP)*.   IEEE, 2018, pp. 3129–3133.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[173] P. Afshar, A. Mohammadi 和 K. N. Plataniotis, “通过胶囊网络进行脑肿瘤类型分类，” 在 *2018年第25届IEEE国际图像处理会议（ICIP）*。
    IEEE，2018年，第3129-3133页。'
- en: '[174] N. Abiwinanda, M. Hanif, S. T. Hesaputra, A. Handayani, and T. R. Mengko,
    “Brain tumor classification using convolutional neural network,” in *World Congress
    on Medical Physics and Biomedical Engineering 2018*.   Springer, 2019, pp. 183–189.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[174] N. Abiwinanda, M. Hanif, S. T. Hesaputra, A. Handayani 和 T. R. Mengko,
    “使用卷积神经网络进行脑肿瘤分类，” 在 *2018年世界医学物理与生物医学工程大会*。 施普林格，2019年，第183-189页。'
- en: '[175] A. Ari and D. Hanbay, “Deep learning based brain tumor classification
    and detection system,” *Turkish Journal of Electrical Engineering & Computer Sciences*,
    vol. 26, no. 5, pp. 2275–2286, 2018.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[175] A. Ari 和 D. Hanbay, “基于深度学习的脑肿瘤分类和检测系统，” *土耳其电气工程与计算机科学杂志*，第26卷，第5期，第2275-2286页，2018年。'
- en: '[176] Y. Zhou, Z. Li, H. Zhu, C. Chen, M. Gao, K. Xu, and J. Xu, “Holistic
    brain tumor screening and classification based on densenet and recurrent neural
    network,” in *International MICCAI Brainlesion Workshop*.   Springer, 2018, pp.
    208–217.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[176] Y. Zhou, Z. Li, H. Zhu, C. Chen, M. Gao, K. Xu, 和 J. Xu，"基于 Densenet
    和递归神经网络的整体脑肿瘤筛查与分类"，在 *国际MICCAI脑病变研讨会*。 Springer，2018年，第208–217页。'
- en: '[177] Y. Xu, Z. Jia, Y. Ai, F. Zhang, M. Lai, I. Eric, and C. Chang, “Deep
    convolutional activation features for large scale brain tumor histopathology image
    classification and segmentation,” in *2015 IEEE international conference on acoustics,
    speech and signal processing (ICASSP)*.   IEEE, 2015, pp. 947–951.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[177] Y. Xu, Z. Jia, Y. Ai, F. Zhang, M. Lai, I. Eric, 和 C. Chang，"用于大规模脑肿瘤组织病理图像分类和分割的深度卷积激活特征"，在
    *2015年IEEE国际声学、语音和信号处理会议（ICASSP）*。 IEEE，2015年，第947–951页。'
- en: '[178] C.-L. DENG, H.-Y. JIANG, and H.-M. LI, “Automated high uptake regions
    recognition and lymphoma detection based on fully convolutional networks on chest
    and abdomen pet image,” *DEStech Transactions on Biology and Health*, no. icmsb,
    2017.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[178] C.-L. DENG, H.-Y. JIANG, 和 H.-M. LI，"基于全卷积网络的高摄取区域识别与淋巴瘤检测，针对胸部和腹部PET图像"，*DEStech生物与健康学会文集*，第
    icmsb 期，2017年。'
- en: '[179] K. Kawauchi, S. Furuya, K. Hirata, C. Katoh, O. Manabe, K. Kobayashi,
    S. Watanabe, and T. Shiga, “A convolutional neural network-based system to classify
    patients using fdg pet/ct examinations,” *BMC cancer*, vol. 20, no. 1, pp. 1–10,
    2020.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[179] K. Kawauchi, S. Furuya, K. Hirata, C. Katoh, O. Manabe, K. Kobayashi,
    S. Watanabe, 和 T. Shiga，"基于卷积神经网络的系统，用于通过 FDG PET/CT 检查对患者进行分类"，*BMC癌症*，第20卷，第1期，第1–10页，2020年。'
- en: '[180] A. Teramoto, H. Fujita, O. Yamamuro, and T. Tamaki, “Automated detection
    of pulmonary nodules in pet/ct images: Ensemble false-positive reduction using
    a convolutional neural network technique,” *Medical physics*, vol. 43, no. 6Part1,
    pp. 2821–2827, 2016.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[180] A. Teramoto, H. Fujita, O. Yamamuro, 和 T. Tamaki，"PET/CT 图像中的肺结节自动检测：使用卷积神经网络技术的集成假阳性减少"，*医学物理学*，第43卷，第6期第1部分，第2821–2827页，2016年。'
- en: '[181] L. Xu, G. Tetteh, J. Lipkova, Y. Zhao, H. Li, P. Christ, M. Piraud, A. Buck,
    K. Shi, and B. H. Menze, “Automated whole-body bone lesion detection for multiple
    myeloma on 68ga-pentixafor pet/ct imaging using deep learning methods,” *Contrast
    media & molecular imaging*, vol. 2018, 2018.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[181] L. Xu, G. Tetteh, J. Lipkova, Y. Zhao, H. Li, P. Christ, M. Piraud, A.
    Buck, K. Shi, 和 B. H. Menze，"使用深度学习方法在 68GA-Pentixafor PET/CT 成像上自动检测多发性骨髓瘤全身骨损伤"，*对比媒体与分子成像*，第2018卷，2018年。'
- en: '[182] A. R. Jamieson, K. Drukker, and M. L. Giger, “Breast image feature learning
    with adaptive deconvolutional networks,” in *Medical Imaging 2012: Computer-Aided
    Diagnosis*, vol. 8315.   International Society for Optics and Photonics, 2012,
    p. 831506.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[182] A. R. Jamieson, K. Drukker, 和 M. L. Giger，"使用自适应反卷积网络的乳腺图像特征学习"，在 *医学成像2012：计算机辅助诊断*，第8315卷。
    国际光学与光子学学会，2012年，第831506页。'
- en: '[183] X. Liu, J. Shi, and Q. Zhang, “Tumor classification by deep polynomial
    network and multiple kernel learning on small ultrasound image dataset,” in *International
    Workshop on Machine Learning in Medical Imaging*.   Springer, 2015, pp. 313–320.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[183] X. Liu, J. Shi, 和 Q. Zhang，"通过深度多项式网络和多核学习对小型超声图像数据集进行肿瘤分类"，在 *国际医学成像机器学习研讨会*。
    Springer，2015年，第313–320页。'
- en: '[184] J. Shi, S. Zhou, X. Liu, Q. Zhang, M. Lu, and T. Wang, “Stacked deep
    polynomial network based representation learning for tumor classification with
    small ultrasound image dataset,” *Neurocomputing*, vol. 194, pp. 87–94, 2016.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[184] J. Shi, S. Zhou, X. Liu, Q. Zhang, M. Lu, 和 T. Wang，"基于堆叠深度多项式网络的肿瘤分类表征学习，针对小型超声图像数据集"，*神经计算*，第194卷，第87–94页，2016年。'
- en: '[185] S. Han, H.-K. Kang, J.-Y. Jeong, M.-H. Park, W. Kim, W.-C. Bang, and
    Y.-K. Seong, “A deep learning framework for supporting the classification of breast
    lesions in ultrasound images,” *Physics in Medicine & Biology*, vol. 62, no. 19,
    p. 7714, 2017.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[185] S. Han, H.-K. Kang, J.-Y. Jeong, M.-H. Park, W. Kim, W.-C. Bang, 和 Y.-K.
    Seong，"一个支持乳腺病变分类的深度学习框架"，*医学与生物物理学*，第62卷，第19期，第7714页，2017年。'
- en: '[186] N. Antropova, B. Q. Huynh, and M. L. Giger, “A deep feature fusion methodology
    for breast cancer diagnosis demonstrated on three imaging modality datasets,”
    *Medical physics*, vol. 44, no. 10, pp. 5162–5171, 2017.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[186] N. Antropova, B. Q. Huynh, 和 M. L. Giger，"一种深度特征融合方法，用于乳腺癌诊断，展示在三个成像模式数据集上"，*医学物理学*，第44卷，第10期，第5162–5171页，2017年。'
- en: '[187] T. Liu, S. Xie, Y. Zhang, J. Yu, L. Niu, and W. Sun, “Feature selection
    and thyroid nodule classification using transfer learning,” in *2017 IEEE 14th
    International Symposium on Biomedical Imaging (ISBI 2017)*.   IEEE, 2017, pp.
    1096–1099.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[187] T. Liu, S. Xie, Y. Zhang, J. Yu, L. Niu, 和 W. Sun，“特征选择与甲状腺结节分类的迁移学习，”发表于*2017
    IEEE第14届生物医学成像国际研讨会 (ISBI 2017)*。IEEE，2017年，第1096–1099页。'
- en: '[188] T. Liu, S. Xie, J. Yu, L. Niu, and W. Sun, “Classification of thyroid
    nodules in ultrasound images using deep model based transfer learning and hybrid
    features,” in *2017 IEEE International Conference on Acoustics, Speech and Signal
    Processing (ICASSP)*.   IEEE, 2017, pp. 919–923.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[188] T. Liu, S. Xie, J. Yu, L. Niu, 和 W. Sun，“基于深度模型的迁移学习和混合特征的甲状腺结节分类，”发表于*2017
    IEEE国际声学、语音与信号处理会议 (ICASSP)*。IEEE，2017年，第919–923页。'
- en: '[189] S. Petscharnig, K. Schöffmann, and M. Lux, “An inception-like cnn architecture
    for gi disease and anatomical landmark classification.” in *MediaEval*, 2017.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[189] S. Petscharnig, K. Schöffmann, 和 M. Lux，“一种类似于Inception的CNN架构用于GI疾病和解剖学标志分类。”发表于*MediaEval*，2017年。'
- en: '[190] R. J. Borgli, H. K. Stensland, M. A. Riegler, and P. Halvorsen, “Automatic
    hyperparameter optimization for transfer learning on medical image datasets using
    bayesian optimization,” in *2019 13th International Symposium on Medical Information
    and Communication Technology (ISMICT)*.   IEEE, 2019, pp. 1–6.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[190] R. J. Borgli, H. K. Stensland, M. A. Riegler, 和 P. Halvorsen，“基于贝叶斯优化的医学图像数据集迁移学习的自动超参数优化，”发表于*2019年第13届医学信息与通信技术国际研讨会
    (ISMICT)*。IEEE，2019年，第1–6页。'
- en: '[191] T. Agrawal, R. Gupta, and S. Narayanan, “On evaluating cnn representations
    for low resource medical image classification,” in *ICASSP 2019-2019 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP)*.   IEEE, 2019,
    pp. 1363–1367.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[191] T. Agrawal, R. Gupta, 和 S. Narayanan，“评估CNN表示在低资源医学图像分类中的表现，”发表于*ICASSP
    2019-2019 IEEE国际声学、语音与信号处理会议 (ICASSP)*。IEEE，2019年，第1363–1367页。'
- en: '[192] D. Ahmedt-Aristizabal, C. Fookes, S. Denman, K. Nguyen, T. Fernando,
    S. Sridharan, and S. Dionisio, “A hierarchical multimodal system for motion analysis
    in patients with epilepsy,” *Epilepsy & Behavior*, vol. 87, pp. 46–58, 2018.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[192] D. Ahmedt-Aristizabal, C. Fookes, S. Denman, K. Nguyen, T. Fernando,
    S. Sridharan, 和 S. Dionisio，“一种用于癫痫患者运动分析的分层多模态系统，”*癫痫与行为*，第87卷，第46–58页，2018年。'
- en: '[193] D. Ahmedt-Aristizabal, K. Nguyen, S. Denman, S. Sridharan, S. Dionisio,
    and C. Fookes, “Deep motion analysis for epileptic seizure classification,” in
    *2018 40th Annual International Conference of the IEEE Engineering in Medicine
    and Biology Society (EMBC)*.   IEEE, 2018, pp. 3578–3581.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[193] D. Ahmedt-Aristizabal, K. Nguyen, S. Denman, S. Sridharan, S. Dionisio,
    和 C. Fookes，“癫痫发作分类的深度运动分析，”发表于*2018年第40届IEEE医学与生物学工程学会年会 (EMBC)*。IEEE，2018年，第3578–3581页。'
- en: '[194] D. Ahmedt-Aristizabal, M. S. Sarfraz, S. Denman, K. Nguyen, C. Fookes,
    S. Dionisio, and R. Stiefelhagen, “Motion signatures for the analysis of seizure
    evolution in epilepsy,” in *2019 41st Annual International Conference of the IEEE
    Engineering in Medicine and Biology Society (EMBC)*.   IEEE, 2019, pp. 2099–2105.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[194] D. Ahmedt-Aristizabal, M. S. Sarfraz, S. Denman, K. Nguyen, C. Fookes,
    S. Dionisio, 和 R. Stiefelhagen，“癫痫发作演变分析的运动特征，”发表于*2019年第41届IEEE医学与生物学工程学会年会 (EMBC)*。IEEE，2019年，第2099–2105页。'
- en: '[195] D. Ahmedt-Aristizabal, C. Fookes, S. Denman, K. Nguyen, S. Sridharan,
    and S. Dionisio, “Aberrant epileptic seizure identification: A computer vision
    perspective,” *Seizure*, vol. 65, pp. 65–71, 2019.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[195] D. Ahmedt-Aristizabal, C. Fookes, S. Denman, K. Nguyen, S. Sridharan,
    和 S. Dionisio，“异常癫痫发作识别：计算机视觉视角，”*癫痫*，第65卷，第65–71页，2019年。'
- en: '[196] Y. Gurovich, Y. Hanani, O. Bar, G. Nadav, N. Fleischer, D. Gelbman, L. Basel-Salmon,
    P. M. Krawitz, S. B. Kamphausen, M. Zenker *et al.*, “Identifying facial phenotypes
    of genetic disorders using deep learning,” *Nature medicine*, vol. 25, no. 1,
    pp. 60–64, 2019.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[196] Y. Gurovich, Y. Hanani, O. Bar, G. Nadav, N. Fleischer, D. Gelbman, L.
    Basel-Salmon, P. M. Krawitz, S. B. Kamphausen, M. Zenker *等*，“利用深度学习识别遗传疾病的面部表型，”*自然医学*，第25卷，第1期，第60–64页，2019年。'
- en: '[197] F. Marbach, C. F. Rustad, A. Riess, D.ukić, T.-C. Hsieh, I. Jobani, T. Prescott,
    A. Bevot, F. Erger, G. Houge *et al.*, “The discovery of a lemd2-associated nuclear
    envelopathy with early progeroid appearance suggests advanced applications for
    ai-driven facial phenotyping,” *The American Journal of Human Genetics*, vol.
    104, no. 4, pp. 749–757, 2019.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[197] F. Marbach, C. F. Rustad, A. Riess, D. ukić, T.-C. Hsieh, I. Jobani,
    T. Prescott, A. Bevot, F. Erger, G. Houge *等*，“发现一种与lemd2相关的核包膜病伴有早期早衰样表现，表明了对AI驱动的面部表型分析的高级应用，”*美国人类遗传学杂志*，第104卷，第4期，第749–757页，2019年。'
- en: '[198] J. Yang, K. Zhang, H. Fan, Z. Huang, Y. Xiang, J. Yang, L. He, L. Zhang,
    Y. Yang, R. Li *et al.*, “Development and validation of deep learning algorithms
    for scoliosis screening using back images,” *Communications biology*, vol. 2,
    no. 1, pp. 1–8, 2019.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[198] J. Yang、K. Zhang、H. Fan、Z. Huang、Y. Xiang、J. Yang、L. He、L. Zhang、Y. Yang、R.
    Li *等*，“用于脊柱侧弯筛查的深度学习算法的发展与验证，基于背部图像”，*通讯生物学*，第 2 卷，第 1 期，页 1–8，2019 年。'
- en: '[199] Z. Wu, S. Zhao, Y. Peng, X. He, X. Zhao, K. Huang, X. Wu, W. Fan, F. Li,
    M. Chen *et al.*, “Studies on different cnn algorithms for face skin disease classification
    based on clinical images,” *IEEE Access*, vol. 7, pp. 66 505–66 511, 2019.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[199] Z. Wu、S. Zhao、Y. Peng、X. He、X. Zhao、K. Huang、X. Wu、W. Fan、F. Li、M. Chen
    *等*，“基于临床图像的不同 CNN 算法在面部皮肤病分类中的研究”，*IEEE 访问*，第 7 卷，页 66 505–66 511，2019 年。'
- en: '[200] A. Subasi, *Practical guide for biomedical signals analysis using machine
    learning techniques: A MATLAB based approach*.   Academic Press, 2019.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[200] A. Subasi，*基于机器学习技术的生物医学信号分析实用指南：一种基于 MATLAB 的方法*。 Academic Press，2019
    年。'
- en: '[201] W. Liu, Q. Huang, S. Chang, H. Wang, and J. He, “Multiple-feature-branch
    convolutional neural network for myocardial infarction diagnosis using electrocardiogram,”
    *Biomedical Signal Processing and Control*, vol. 45, pp. 22–32, 2018.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[201] W. Liu、Q. Huang、S. Chang、H. Wang 和 J. He，“基于多特征分支卷积神经网络的心肌梗死诊断，使用心电图”，*生物医学信号处理与控制*，第
    45 卷，页 22–32，2018 年。'
- en: '[202] J. Takalo-Mattila, J. Kiljander, and J.-P. Soininen, “Inter-patient ecg
    classification using deep convolutional neural networks,” in *2018 21st Euromicro
    Conference on Digital System Design (DSD)*.   IEEE, 2018, pp. 421–425.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[202] J. Takalo-Mattila、J. Kiljander 和 J.-P. Soininen， “使用深度卷积神经网络进行患者间 ECG
    分类”，见于 *2018年第21届欧罗微数字系统设计会议（DSD）*。 IEEE，2018，页 421–425。'
- en: '[203] F. Plesinger, P. Nejedly, I. Viscor, J. Halamek, and P. Jurak, “Automatic
    detection of atrial fibrillation and other arrhythmias in holter ecg recordings
    using rhythm features and neural networks,” in *2017 Computing in Cardiology (CinC)*.   IEEE,
    2017, pp. 1–4.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[203] F. Plesinger、P. Nejedly、I. Viscor、J. Halamek 和 P. Jurak，“利用节律特征和神经网络在
    Holter ECG 记录中自动检测房颤和其他心律失常”，见于 *2017 年计算心脏病学会议（CinC）*。 IEEE，2017，页 1–4。'
- en: '[204] T. J. Jun, H. M. Nguyen, D. Kang, D. Kim, D. Kim, and Y.-H. Kim, “Ecg
    arrhythmia classification using a 2-d convolutional neural network,” *arXiv preprint
    arXiv:1804.06812*, 2018.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[204] T. J. Jun、H. M. Nguyen、D. Kang、D. Kim、D. Kim 和 Y.-H. Kim，“使用 2D 卷积神经网络进行
    ECG 心律失常分类”，*arXiv 预印本 arXiv:1804.06812*，2018 年。'
- en: '[205] U. R. Acharya, H. Fujita, S. L. Oh, Y. Hagiwara, J. H. Tan, M. Adam,
    and R. San Tan, “Deep convolutional neural network for the automated diagnosis
    of congestive heart failure using ecg signals,” *Applied Intelligence*, vol. 49,
    no. 1, pp. 16–27, 2019.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[205] U. R. Acharya、H. Fujita、S. L. Oh、Y. Hagiwara、J. H. Tan、M. Adam 和 R. San
    Tan，“基于 ECG 信号的充血性心力衰竭自动诊断的深度卷积神经网络”，*应用智能*，第 49 卷，第 1 期，页 16–27，2019 年。'
- en: '[206] S. Singh, S. K. Pandey, U. Pawar, and R. R. Janghel, “Classification
    of ecg arrhythmia using recurrent neural networks,” *Procedia computer science*,
    vol. 132, pp. 1290–1297, 2018.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[206] S. Singh、S. K. Pandey、U. Pawar 和 R. R. Janghel，“使用递归神经网络对 ECG 心律失常进行分类”，*程序计算机科学*，第
    132 卷，页 1290–1297，2018 年。'
- en: '[207] P. Schwab, G. C. Scebba, J. Zhang, M. Delai, and W. Karlen, “Beat by
    beat: Classifying cardiac arrhythmias with recurrent neural networks,” in *2017
    Computing in Cardiology (CinC)*.   IEEE, 2017, pp. 1–4.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[207] P. Schwab、G. C. Scebba、J. Zhang、M. Delai 和 W. Karlen，“逐搏分类：使用递归神经网络对心律失常进行分类”，见于
    *2017 年计算心脏病学会议（CinC）*。 IEEE，2017，页 1–4。'
- en: '[208] V. Sujadevi, K. Soman, and R. Vinayakumar, “Real-time detection of atrial
    fibrillation from short time single lead ecg traces using recurrent neural networks,”
    in *The International Symposium on Intelligent Systems Technologies and Applications*.   Springer,
    2017, pp. 212–221.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[208] V. Sujadevi、K. Soman 和 R. Vinayakumar，“使用递归神经网络从短时间单导联 ECG 记录中实时检测房颤”，见于
    *国际智能系统技术与应用研讨会*。 Springer，2017，页 212–221。'
- en: '[209] O. Faust, A. Shenfield, M. Kareem, T. R. San, H. Fujita, and U. R. Acharya,
    “Automated detection of atrial fibrillation using long short-term memory network
    with rr interval signals,” *Computers in biology and medicine*, vol. 102, pp.
    327–335, 2018.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[209] O. Faust、A. Shenfield、M. Kareem、T. R. San、H. Fujita 和 U. R. Acharya，“使用长短期记忆网络和
    RR 间隔信号自动检测房颤”，*计算机生物医学*，第 102 卷，页 327–335，2018 年。'
- en: '[210] M. Liu and Y. Kim, “Classification of heart diseases based on ecg signals
    using long short-term memory,” in *2018 40th Annual International Conference of
    the IEEE Engineering in Medicine and Biology Society (EMBC)*.   IEEE, 2018, pp.
    2707–2710.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[210] M. Liu 和 Y. Kim，“基于 ECG 信号的心脏疾病分类，使用长短期记忆网络，” 见 *2018 年第 40 届国际 IEEE
    医学与生物工程学会年会（EMBC）*。   IEEE，2018 年，第 2707–2710 页。'
- en: '[211] Ö. Yildirim, “A novel wavelet sequence based on deep bidirectional lstm
    network model for ecg signal classification,” *Computers in biology and medicine*,
    vol. 96, pp. 189–202, 2018.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[211] Ö. Yildirim，“一种基于深度双向 LSTM 网络模型的新型小波序列用于 ECG 信号分类，” *生物医学与医学计算机*，第 96
    卷，第 189–202 页，2018 年。'
- en: '[212] C. Zhang, G. Wang, J. Zhao, P. Gao, J. Lin, and H. Yang, “Patient-specific
    ecg classification based on recurrent neural networks and clustering technique,”
    in *2017 13th IASTED International Conference on Biomedical Engineering (BioMed)*.   IEEE,
    2017, pp. 63–67.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[212] C. Zhang, G. Wang, J. Zhao, P. Gao, J. Lin, 和 H. Yang，“基于递归神经网络和聚类技术的患者特定
    ECG 分类，” 见 *2017 年第 13 届 IASTED 国际生物医学工程会议（BioMed）*。   IEEE，2017 年，第 63–67 页。'
- en: '[213] L. Chu, R. Qiu, H. Liu, Z. Ling, T. Zhang, and J. Wang, “Individual recognition
    in schizophrenia using deep learning methods with random forest and voting classifiers:
    Insights from resting state eeg streams,” *arXiv preprint arXiv:1707.03467*, 2017.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[213] L. Chu, R. Qiu, H. Liu, Z. Ling, T. Zhang, 和 J. Wang，“使用随机森林和投票分类器的深度学习方法在精神分裂症中的个体识别：基于静息状态
    EEG 流的见解，” *arXiv 预印本 arXiv:1707.03467*，2017 年。'
- en: '[214] D. Ahmedt Aristizabal, T. Fernando, S. Denman, J. E. Robinson, S. Sridharan,
    P. J. Johnston, K. R. Laurens, and C. Fookes, “Identification of children at risk
    of schizophrenia via deep learning and eeg responses,” *IEEE Journal of Biomedical
    and Health Informatics*, pp. 1–7, 2020.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[214] D. Ahmedt Aristizabal, T. Fernando, S. Denman, J. E. Robinson, S. Sridharan,
    P. J. Johnston, K. R. Laurens, 和 C. Fookes，“通过深度学习和 EEG 反应识别风险精神分裂症的儿童，” *IEEE
    生物医学与健康信息学杂志*，第 1–7 页，2020 年。'
- en: '[215] U. R. Acharya, S. L. Oh, Y. Hagiwara, J. H. Tan, and H. Adeli, “Deep
    convolutional neural network for the automated detection and diagnosis of seizure
    using eeg signals,” *Computers in biology and medicine*, vol. 100, pp. 270–278,
    2018.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[215] U. R. Acharya, S. L. Oh, Y. Hagiwara, J. H. Tan, 和 H. Adeli，“用于自动检测和诊断癫痫的深度卷积神经网络，基于
    EEG 信号，” *生物医学与医学计算机*，第 100 卷，第 270–278 页，2018 年。'
- en: '[216] A. O’Shea, G. Lightbody, G. Boylan, and A. Temko, “Investigating the
    impact of cnn depth on neonatal seizure detection performance,” in *2018 40th
    Annual International Conference of the IEEE Engineering in Medicine and Biology
    Society (EMBC)*.   IEEE, 2018, pp. 5862–5865.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[216] A. O’Shea, G. Lightbody, G. Boylan, 和 A. Temko，“研究 CNN 深度对新生儿癫痫检测性能的影响，”
    见 *2018 年第 40 届国际 IEEE 医学与生物工程学会年会（EMBC）*。   IEEE，2018 年，第 5862–5865 页。'
- en: '[217] P. Thodoroff, J. Pineau, and A. Lim, “Learning robust features using
    deep learning for automatic seizure detection,” in *Machine learning for healthcare
    conference*, 2016, pp. 178–190.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[217] P. Thodoroff, J. Pineau, 和 A. Lim，“使用深度学习学习鲁棒特征以实现自动癫痫检测，” 见 *医疗保健机器学习会议*，2016
    年，第 178–190 页。'
- en: '[218] I. Ullah, M. Hussain, H. Aboalsamh *et al.*, “An automated system for
    epilepsy detection using eeg brain signals based on deep learning approach,” *Expert
    Systems with Applications*, vol. 107, pp. 61–71, 2018.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[218] I. Ullah, M. Hussain, H. Aboalsamh *等*，“基于深度学习方法的 EEG 脑信号自动癫痫检测系统，” *专家系统与应用*，第
    107 卷，第 61–71 页，2018 年。'
- en: '[219] A. O’Shea, G. Lightbody, G. Boylan, and A. Temko, “Neonatal seizure detection
    using convolutional neural networks,” in *2017 IEEE 27th International Workshop
    on Machine Learning for Signal Processing (MLSP)*.   IEEE, 2017, pp. 1–6.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[219] A. O’Shea, G. Lightbody, G. Boylan, 和 A. Temko，“使用卷积神经网络的新生儿癫痫检测，” 见
    *2017 IEEE 第 27 届机器学习信号处理国际研讨会（MLSP）*。   IEEE，2017 年，第 1–6 页。'
- en: '[220] S. S. Talathi, “Deep recurrent neural networks for seizure detection
    and early seizure detection systems,” *arXiv preprint arXiv:1706.03283*, 2017.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[220] S. S. Talathi，“用于癫痫检测和早期癫痫检测系统的深度递归神经网络，” *arXiv 预印本 arXiv:1706.03283*，2017
    年。'
- en: '[221] R. Hussein, H. Palangi, R. Ward, and Z. J. Wang, “Epileptic seizure detection:
    A deep learning approach,” *arXiv preprint arXiv:1803.09848*, 2018.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[221] R. Hussein, H. Palangi, R. Ward, 和 Z. J. Wang，“癫痫发作检测：一种深度学习方法，” *arXiv
    预印本 arXiv:1803.09848*，2018 年。'
- en: '[222] M. A. Naderi and H. Mahdavi-Nasab, “Analysis and classification of eeg
    signals using spectral analysis and recurrent neural networks,” in *2010 17th
    Iranian Conference of Biomedical Engineering (ICBME)*.   IEEE, 2010, pp. 1–4.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[222] M. A. Naderi 和 H. Mahdavi-Nasab，“利用频谱分析和递归神经网络分析和分类 EEG 信号，” 见 *2010
    年第 17 届伊朗生物医学工程会议（ICBME）*。   IEEE，2010 年，第 1–4 页。'
- en: '[223] G. Ruffini, D. Ibañez, M. Castellano, L. Dubreuil-Vall, A. Soria-Frisch,
    R. Postuma, J.-F. Gagnon, and J. Montplaisir, “Deep learning with eeg spectrograms
    in rapid eye movement behavior disorder,” *Frontiers in neurology*, vol. 10, 2019.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[223] G. Ruffini, D. Ibañez, M. Castellano, L. Dubreuil-Vall, A. Soria-Frisch,
    R. Postuma, J.-F. Gagnon, 和 J. Montplaisir, “使用 EEG 频谱图进行快速眼动行为障碍的深度学习，” *神经学前沿*,
    第 10 卷, 2019 年。'
- en: '[224] I. A. Khowailed and A. Abotabl, “Neural muscle activation detection:
    A deep learning approach using surface electromyography,” *Journal of biomechanics*,
    vol. 95, p. 109322, 2019.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[224] I. A. Khowailed 和 A. Abotabl, “神经肌肉激活检测：一种使用表面肌电图的深度学习方法，” *生物力学杂志*,
    第 95 卷, 页码 109322, 2019 年。'
- en: '[225] A. E. Olsson, P. Sager, E. Andersson, A. Björkman, N. Malešević, and
    C. Antfolk, “Extraction of multi-labelled movement information from the raw hd-semg
    image with time-domain depth,” *Scientific reports*, vol. 9, no. 1, pp. 1–10,
    2019.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[225] A. E. Olsson, P. Sager, E. Andersson, A. Björkman, N. Malešević, 和 C.
    Antfolk, “从原始 hd-semg 图像中提取多标签运动信息，带时间域深度，” *科学报告*, 第 9 卷，第 1 期, 页码 1–10, 2019
    年。'
- en: '[226] H. Dantas, D. J. Warren, S. M. Wendelken, T. S. Davis, G. A. Clark, and
    V. J. Mathews, “Deep learning movement intent decoders trained with dataset aggregation
    for prosthetic limb control,” *IEEE Transactions on Biomedical Engineering*, vol. 66,
    no. 11, pp. 3192–3203, 2019.'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[226] H. Dantas, D. J. Warren, S. M. Wendelken, T. S. Davis, G. A. Clark, 和
    V. J. Mathews, “通过数据集聚合训练的深度学习运动意图解码器用于假肢控制，” *IEEE 生物医学工程学报*, 第 66 卷，第 11 期,
    页码 3192–3203, 2019 年。'
- en: '[227] W. Zhang, J. Han, and S. Deng, “Abnormal heart sound detection using
    temporal quasi-periodic features and long short-term memory without segmentation,”
    *Biomedical Signal Processing and Control*, vol. 53, 8 2019.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[227] W. Zhang, J. Han, 和 S. Deng, “使用时间准周期特征和长短期记忆进行异常心音检测，无需分段，” *生物医学信号处理与控制*,
    第 53 卷, 2019 年 8 月。'
- en: '[228] V. Maknickas and A. Maknickas, “Recognition of normal-abnormal phonocardiographic
    signals using deep convolutional neural networks and mel-frequency spectral coefficients,”
    *Physiological Measurement*, vol. 38, no. 8, pp. 1671–1684, 7 2017.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[228] V. Maknickas 和 A. Maknickas, “使用深度卷积神经网络和梅尔频率谱系数识别正常-异常心音信号，” *生理测量*,
    第 38 卷，第 8 期, 页码 1671–1684, 2017 年 7 月。'
- en: '[229] C. Potes, S. Parvaneh, A. Rahman, and B. Conroy, “Ensemble of feature-based
    and deep learning-based classifiers for detection of abnormal heart sounds,” in
    *2016 Computing in Cardiology Conference (CinC)*.   IEEE, 2016, pp. 621–624.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[229] C. Potes, S. Parvaneh, A. Rahman, 和 B. Conroy, “基于特征的和基于深度学习的分类器集成用于异常心音检测，”
    在 *2016年计算心脏病学会议（CinC）*。IEEE, 2016 年, 页码 621–624。'
- en: '[230] G. Sannino, N. Bouguila, G. De Pietro, and A. Celesti, “Artificial intelligence
    for mobile health data analysis and processing,” *Mobile Information Systems*,
    vol. 2019, 2019.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[230] G. Sannino, N. Bouguila, G. De Pietro, 和 A. Celesti, “用于移动健康数据分析和处理的人工智能，”
    *移动信息系统*, 第 2019 卷, 2019 年。'
- en: '[231] S. Potluri, S. Ravuri, C. Diedrich, and L. Schega, “Deep learning based
    gait abnormality detection using wearable sensor system,” in *2019 41st Annual
    International Conference of the IEEE Engineering in Medicine and Biology Society
    (EMBC)*.   IEEE, 2019, pp. 3613–3619.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[231] S. Potluri, S. Ravuri, C. Diedrich, 和 L. Schega, “基于深度学习的步态异常检测使用可穿戴传感器系统，”
    在 *2019年第41届国际医学与生物工程学会年会（EMBC）*。IEEE, 2019 年, 页码 3613–3619。'
- en: '[232] T. R. Mauldin, M. E. Canby, V. Metsis, A. H. Ngu, and C. C. Rivera, “Smartfall:
    A smartwatch-based fall detection system using deep learning,” *Sensors*, vol. 18,
    no. 10, p. 3363, 2018.'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[232] T. R. Mauldin, M. E. Canby, V. Metsis, A. H. Ngu, 和 C. C. Rivera, “Smartfall:
    一种基于智能手表的跌倒检测系统，使用深度学习，” *传感器*, 第 18 卷，第 10 期, 页码 3363, 2018 年。'
- en: '[Deep Learning for Medical Anomaly Detection - A Survey: Supplementary Material]'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: '[医疗异常检测的深度学习 - 调查：补充材料]'
- en: Appendix A Types of Data
  id: totrans-542
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 数据类型
- en: A-A Biomedical Imagining
  id: totrans-543
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A-A 生物医学成像
- en: 'X-ray radiography: X-rays have shorter wave lengths than visible light and
    can pass through most tissue types in the human body. However, the calcium contained
    in bones is denser and scatters the x-rays. The film that sits on the opposite
    side of the x-ray source is a negative image such that areas that are exposed
    to more light appear darker. Therefore, as more x-rays penetrate tissues such
    as lungs and mussels, these areas are darkened on the film and the bones appear
    as brighter regions. X-ray imaging is typically used for various diagnostic purposes,
    including detecting bone fractures, dental problems, pneumonia, and certain types
    of tumor.'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: X光放射摄影：X光的波长比可见光短，能穿透人体大部分组织。然而，骨头中的钙更为密集，能散射X光。位于X光源对面的一张胶卷呈现负片图像，曝光更多光线的区域显得更暗。因此，X光穿透肺部和肌肉等组织越多，这些区域在胶卷上会显得越暗，而骨头则显得更亮。X光成像通常用于各种诊断目的，包括检测骨折、牙齿问题、肺炎和某些类型的肿瘤。
- en: Considering application of deep learning models for abnormality detection using
    X-ray images, in [[158](#bib.bib158)] the authors utilised a CNN architecture
    to detect abnormalities in chest x-ray images, while in [[159](#bib.bib159), [160](#bib.bib160)]
    the authors investigate the utilisation of different off-the-shelf pre-trained
    CNN architecture such as VGG-16 and GoogLeNet to classify X-ray images. In [[161](#bib.bib161)]
    the authors purpose an architecture called ChestNet where a two branch framework
    is proposed for diagnosis. A classification branch detects abnormalities, and
    an attention branch is introduced which tries to uncover the correlation between
    class labels and the locations of pathological abnormalities. In a different line
    of work, the authors of [[162](#bib.bib162)] exploit the ability of a multi-label
    classification framework to capture the hierarchical dependencies among different
    abnormality classes. Instead of performing binary normal/abnormal classification,
    they formulate the task as multi-class classification where the model predicts
    the abnormality class of the input x-ray. Most recently, deep learning methods
    have been introduced for screening COVID-19 using chest x-rays [[163](#bib.bib163),
    [164](#bib.bib164)]
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 针对使用X光图像进行异常检测的深度学习模型应用，在 [[158](#bib.bib158)] 中，作者利用CNN架构检测胸部X光图像中的异常，而在 [[159](#bib.bib159),
    [160](#bib.bib160)] 中，作者研究了使用不同的预训练CNN架构，如VGG-16和GoogLeNet，对X光图像进行分类。在 [[161](#bib.bib161)]
    中，作者提出了一种称为ChestNet的架构，其中提出了一个双分支框架用于诊断。分类分支检测异常，另一个引入了注意力分支，旨在揭示类别标签与病理异常位置之间的关联。在不同的研究中，[[162](#bib.bib162)]
    的作者利用多标签分类框架来捕捉不同异常类别之间的层次依赖关系。他们将任务设定为多类分类，而不是二元正常/异常分类，模型预测输入X光的异常类别。最近，深度学习方法被引入用于使用胸部X光筛查COVID-19
    [[163](#bib.bib163), [164](#bib.bib164)]。
- en: 'Computed Tomography scan (CT): In CT imaging, cross sectional images of the
    body are generated using a narrow beam of x-rays that are emitted while the patient
    is quickly rotated. CT imaging collects a number of cross sectional slices which
    are stacked together to generate a 3 dimensional representation, which is more
    informative than a conventional X-ray image. Fig. [19](#A1.F19 "Figure 19 ‣ A-A
    Biomedical Imagining ‣ Appendix A Types of Data ‣ Deep Learning for Medical Anomaly
    Detection - A Survey") illustrates an example of the CT scan procedure of the
    abdomen.'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机断层扫描（CT）：在CT成像中，通过在患者快速旋转时发射的一束狭窄的X光生成身体的横截面图像。CT成像收集多个横截面切片，将它们叠加生成三维表示，这比传统的X光图像更具信息量。图
    [19](#A1.F19 "图 19 ‣ A-A 生物医学成像 ‣ 附录 A 数据类型 ‣ 医学异常检测的深度学习 - 调查") 说明了腹部CT扫描过程的一个例子。
- en: '![Refer to caption](img/819dade353b8e42006cb18ba87cd8a2c.png)'
  id: totrans-547
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/819dade353b8e42006cb18ba87cd8a2c.png)'
- en: 'Figure 19: Illustration of the Computed Tomography scan (CT) procedure. Image
    [source](https://www.cancer.gov/publications/dictionaries/cancer-terms/def/computed-tomography-scan)'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19：计算机断层扫描（CT）过程的示意图。图像 [来源](https://www.cancer.gov/publications/dictionaries/cancer-terms/def/computed-tomography-scan)
- en: CT scans are a popular diagnostic tool when identifying disease or injury within
    various regions of the body. Applications include detecting tumors or lesions
    in the abdomen, and localising head injuries, tumors, and clots. They are also
    used for diagnosing complex bone fractures and bone tumors. Fig. [20](#A1.F20
    "Figure 20 ‣ A-A Biomedical Imagining ‣ Appendix A Types of Data ‣ Deep Learning
    for Medical Anomaly Detection - A Survey") shows an examples of chest CT scans
    of healthy and diseased patients. This example is taken from [SARS-CoV-2 CT scan
    dataset](https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset) where the
    diseased subject has COVID-19 symptoms.
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: CT扫描在识别身体不同区域的疾病或伤害时是一种常见的诊断工具。应用包括检测腹部肿瘤或病变，以及定位头部伤害、肿瘤和血块。它们也用于诊断复杂的骨折和骨肿瘤。图[20](#A1.F20
    "Figure 20 ‣ A-A Biomedical Imagining ‣ Appendix A Types of Data ‣ Deep Learning
    for Medical Anomaly Detection - A Survey")展示了健康和患病患者的胸部CT扫描示例。此示例取自[SARS-CoV-2
    CT扫描数据集](https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset)，其中患病对象显示出COVID-19症状。
- en: '![Refer to caption](img/3e3ed60cc4376183b3f35384c84548bf.png)'
  id: totrans-550
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/3e3ed60cc4376183b3f35384c84548bf.png)'
- en: 'Figure 20: Lung CT scans of healthy and diseased subjects taken from the [SARS-CoV-2
    CT scan dataset](https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset)'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 图20：健康和患病对象的肺部CT扫描，来自[SARS-CoV-2 CT扫描数据集](https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset)
- en: There exist a multitude of works that utilise deep learning for diagnosing symptoms
    in CT scans. For instance, in [[165](#bib.bib165), [166](#bib.bib166), [167](#bib.bib167),
    [168](#bib.bib168), [169](#bib.bib169)] authors utilise chest CT scans to detect
    COVID-19 pneumonia symptoms. Makde et. al [[170](#bib.bib170)] proposed an algorithm
    to detect kidney tumors in CT images while [[171](#bib.bib171), [172](#bib.bib172)]
    detect lung cancers using CT scans.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 现存许多研究利用深度学习进行CT扫描症状诊断。例如，在[[165](#bib.bib165), [166](#bib.bib166), [167](#bib.bib167),
    [168](#bib.bib168), [169](#bib.bib169)]中，作者利用胸部CT扫描检测COVID-19肺炎症状。Makde等[[170](#bib.bib170)]提出了一种检测CT图像中肾肿瘤的算法，而[[171](#bib.bib171),
    [172](#bib.bib172)]使用CT扫描检测肺癌。
- en: 'Magnetic Resonance Imaging (MRI): As the name implies MRI employs a magnetic
    field for imagining by forcing protons in the body to align with the applied field.
    Fig. [21](#A1.F21 "Figure 21 ‣ A-A Biomedical Imagining ‣ Appendix A Types of
    Data ‣ Deep Learning for Medical Anomaly Detection - A Survey") (a) provides an
    illustration of the MRI procedure.'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 磁共振成像（MRI）：顾名思义，MRI通过强迫体内质子与施加的磁场对齐来使用磁场进行成像。图[21](#A1.F21 "Figure 21 ‣ A-A
    Biomedical Imagining ‣ Appendix A Types of Data ‣ Deep Learning for Medical Anomaly
    Detection - A Survey") (a)提供了MRI过程的示例。
- en: '![Refer to caption](img/df7a101e696ad696aa5b3407d4894642.png)'
  id: totrans-554
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/df7a101e696ad696aa5b3407d4894642.png)'
- en: (a)
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/5e9bea84e47e466a2932d5462b9c3838.png)'
  id: totrans-556
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/5e9bea84e47e466a2932d5462b9c3838.png)'
- en: (b)
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 21: (a)An example of the Magnetic Resonance Imaging (MRI) system. Image
    [source](https://commons.wikimedia.org/wiki/Main_Page). (b) An MRI image with
    a brain tumor taken from [Kaggle Brain MRI Images for Brain Tumor Detection dataset.](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection)'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 图21： (a) 磁共振成像（MRI）系统的示例。图像来源[原链接](https://commons.wikimedia.org/wiki/Main_Page)。
    (b) 来自[Kaggle脑部MRI图像用于脑肿瘤检测数据集](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection)的脑肿瘤MRI图像。
- en: Specifically, the protons in the human body spin and create a small magnetic
    field. When a strong magnetic field such as from the MRI machine is introduced,
    the protons align with that field. Then a radio frequency pulse is introduced
    which disrupts the alignment. When the radio frequency pulse is turned off the
    protons discharge energy and try to re-align with the magnetic field. The energy
    released varies for different tissue types, allowing the MRI scan to segregate
    different regions. Therefore, MRIs are typically used to image non-bony or soft
    tissue regions of the human body. Comparison studies have shown that the brain,
    spinal cord, nerves and muscles are better captured by MRIs than CT scans. Therefore,
    MRI is the modality of choice for tasks such as brain tumor detection and identifying
    tissue damage.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，人体内的质子旋转并产生一个小的磁场。当引入强磁场（如MRI机器的磁场）时，质子会与该磁场对齐。随后引入射频脉冲，扰乱质子的对齐。当射频脉冲关闭时，质子释放能量并试图重新对齐磁场。释放的能量因组织类型不同而异，从而使MRI扫描能够区分不同区域。因此，MRI通常用于成像人体的非骨质或软组织区域。比较研究显示，MRI比CT扫描更能清晰捕捉大脑、脊髓、神经和肌肉。因此，MRI是检测脑肿瘤和识别组织损伤等任务的首选方法。
- en: A multitude of research has focused on applying deep learning techniques to
    detect abnormalities in MRIs. For instance, in [[173](#bib.bib173), [174](#bib.bib174),
    [175](#bib.bib175)] a Convolutional Neural Network (CNN) is utilised to detect
    abnormalities, while in [[176](#bib.bib176)] a hybrid model using a combination
    of CNNs and a Recurrent Neural Network (RNN) is employed. In [[177](#bib.bib177)]
    the authors carried out an investigation to see how CNN activations are transferred
    from a pre-training natural image classification task to the MRI domain for a
    brain tumor detection task.
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 大量研究集中在应用深度学习技术来检测 MRI 中的异常。例如，在[[173](#bib.bib173)、[174](#bib.bib174)、[175](#bib.bib175)]中，使用了卷积神经网络（CNN）来检测异常，而在[[176](#bib.bib176)]中，则采用了结合
    CNN 和递归神经网络（RNN）的混合模型。在[[177](#bib.bib177)]中，作者进行了一项研究，探讨了 CNN 激活如何从预训练的自然图像分类任务转移到
    MRI 领域，以进行脑肿瘤检测任务。
- en: 'Positron Emission Tomography (PET): PET works by injecting, swallowing or inhaling
    a radioactive material (tracer), and this material is collected in regions with
    higher levels of chemical activity which usually correspond to areas of disease.
    The emitted energy from the radioactive material is detected by a ring of detector
    placed within the PET scanner. PET scans are valuable for revealing or evaluating
    several conditions including different cancers types (Esophageal, Melanoma, Thyroid,
    Cervical, etc), heart conditions such as decreased blood flow to the heart, and
    brain disorders. Fig. [22](#A1.F22 "Figure 22 ‣ A-A Biomedical Imagining ‣ Appendix
    A Types of Data ‣ Deep Learning for Medical Anomaly Detection - A Survey") illustrates
    a PET brain image.'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 正电子发射断层扫描（PET）：PET 通过注射、吞咽或吸入放射性物质（示踪剂）来工作，这些物质会在化学活动水平较高的区域聚集，这些区域通常对应于疾病区域。来自放射性物质的能量由
    PET 扫描仪内的探测器环检测。PET 扫描对于揭示或评估多种状况具有重要价值，包括不同类型的癌症（食管癌、黑色素瘤、甲状腺癌、宫颈癌等）、心脏病如心脏血流减少以及脑部疾病。图
    [22](#A1.F22 "Figure 22 ‣ A-A Biomedical Imagining ‣ Appendix A Types of Data
    ‣ Deep Learning for Medical Anomaly Detection - A Survey") 显示了一个 PET 脑部图像。
- en: '![Refer to caption](img/d9a9e1100cc5113eafc415301d19b99b.png)'
  id: totrans-562
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d9a9e1100cc5113eafc415301d19b99b.png)'
- en: 'Figure 22: An example PET scan. Image taken from [PET radiomics challenges](https://www.kaggle.com/c/pet-radiomics-challenges)'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 图 22：一个 PET 扫描的示例。图像来源于 [PET 放射组学挑战](https://www.kaggle.com/c/pet-radiomics-challenges)
- en: Regarding deep learning based anomaly detection using PET data, the work of
    Deng et. al [[178](#bib.bib178)] purposes a framework to detect lymphomas. A CNN
    based system is proposed in [[179](#bib.bib179)] which can classify whole-body
    fluorodeoxyglucose PET scans. A PET-CT hybrid system is proposed in [[180](#bib.bib180)]
    where the authors employ a CNN to extract features from the PET and CT images,
    and an ensemble of rule based and SVM classifiers are employed to get the final
    classification. An automated whole-body bone lesion detection framework is proposed
    in [[181](#bib.bib181)] which also uses a combination of CT and PET scans, and
    in this work a complete deep learning pipeline in contrast to the two stage approach
    of [[180](#bib.bib180)].
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 关于基于深度学习的 PET 数据异常检测，Deng 等人[[178](#bib.bib178)]提出了一个检测淋巴瘤的框架。[[179](#bib.bib179)]中提出了一种基于
    CNN 的系统，可以对全身氟脱氧葡萄糖 PET 扫描进行分类。[[180](#bib.bib180)]中提出了一种 PET-CT 混合系统，作者使用 CNN
    从 PET 和 CT 图像中提取特征，并采用规则基础和支持向量机（SVM）分类器的组合来获得最终分类。[[181](#bib.bib181)]中提出了一种自动化的全身骨病变检测框架，也使用了
    CT 和 PET 扫描的组合，并且在这项工作中采用了完整的深度学习管道，与[[180](#bib.bib180)]的两阶段方法形成对比。
- en: 'Ultrasound: The main component in an ultrasound imaging device is a transducer
    which converts electrical energy to sound waves. This is done using an array of
    piezoelectric crystals in the transducer, which vibrate when an electric signal
    is applied and generate high frequency sound waves. These ultrasound waves travel
    through the body and they are reflected back by different tissues with different
    characteristics at different depths. The piezoelectric crystals detect the reflected
    ultrasound waves, and generate back the electric signal. The returned electric
    signal is converted to an image via computer.'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 超声：超声成像设备的主要组件是转换器，它将电能转换为声波。这是通过在转换器中使用一组压电晶体来完成的，当施加电信号时，这些晶体会振动并产生高频声波。这些超声波穿过身体，并由不同深度的不同组织反射回来。压电晶体检测到反射的超声波，并生成电信号。返回的电信号通过计算机转换为图像。
- en: Ultrasound is a non-invasive method for imaging internal organs. One of the
    primary applications of ultrasound is to monitor the growth and development of
    the fetus during pregnancy. They are also used as tool to detect abnormalities
    in the heart, blood vessels, breasts, abdominal organs, etc. One key characteristic
    of ultrasound imaging is it’s ability to be displayed in either 2D, 3D, or 4D
    (where the 3D image is visualised together with motion).
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 超声是一种非侵入性的内部器官成像方法。超声的主要应用之一是监测胎儿在妊娠期间的生长和发育。它们还用于检测心脏、血管、乳腺、腹部器官等的异常。超声成像的一个关键特性是能够以2D、3D或4D（其中3D图像与运动一起可视化）显示。
- en: '![Refer to caption](img/ac45f548c08fcf7a38d1f564a49ecc7b.png)'
  id: totrans-567
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ac45f548c08fcf7a38d1f564a49ecc7b.png)'
- en: (a)
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/b8f3004d4ef918fb5f137b2219e70368.png)'
  id: totrans-569
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/b8f3004d4ef918fb5f137b2219e70368.png)'
- en: (b)
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 23: (a)Illustration of an ultrasound scan. Image [source](https://commons.wikimedia.org/wiki/Main_Page).
    (b) An ultrasound image of the neck which is taken from [Kaggle Ultrasound Nerve
    Segmentation dataset.](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection)'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: '图23: (a) 超声扫描的示意图。图像 [来源](https://commons.wikimedia.org/wiki/Main_Page)。 (b)
    来自 [Kaggle 超声神经分割数据集](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection)
    的颈部超声图像。'
- en: One of the first studies that applied deep learning to ultrasound images was
    conducted by Jamieson et. al in [[182](#bib.bib182)], where they proposed an unsupervised
    deep learning model to classify breast tumors in ultrasound images. Subsequently,
    supervised deep learning techniques [[183](#bib.bib183), [184](#bib.bib184), [185](#bib.bib185)]
    have been extensively applied for abnormality detection in ultrasound images.
    Furthermore, strategies to fuse features extracted from pre-trained deep learning
    models and hand crafted features are proposed in [[186](#bib.bib186), [187](#bib.bib187),
    [188](#bib.bib188)].
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一项首次将深度学习应用于超声图像的研究是由 Jamieson 等人进行的[[182](#bib.bib182)]，他们提出了一种无监督深度学习模型来对超声图像中的乳腺肿瘤进行分类。随后，监督深度学习技术[[183](#bib.bib183),
    [184](#bib.bib184), [185](#bib.bib185)] 已被广泛应用于超声图像的异常检测。此外，[[186](#bib.bib186),
    [187](#bib.bib187), [188](#bib.bib188)] 中提出了融合从预训练深度学习模型中提取的特征与手工特征的策略。
- en: Medical Optical Imaging Optical Imagining is similar to X-ray and PET imaging
    techniques which were discussed earlier, however, in contrast to those techniques
    which use radiation to create images, optical imaging uses visible light. This
    is a key advantage of medical optical imaging as it reduces the exposure of the
    patient to harmful radiation. Furthermore, optical imaging is particularly useful
    when imaging soft-tissue as they have different absorption characteristics when
    exposed to light. Optical imaging is often used as a complimentary modality to
    other techniques such as MRI or X-rays, and can be designed to capture higher
    resolution images.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 医学光学成像类似于之前讨论的X射线和PET成像技术，但与使用辐射创建图像的技术不同，光学成像使用可见光。这是医学光学成像的一个关键优势，因为它减少了患者接触有害辐射的风险。此外，光学成像在成像软组织时特别有用，因为软组织在暴露于光线时具有不同的吸收特性。光学成像通常作为MRI或X射线等其他技术的补充模式，并且可以设计为捕获更高分辨率的图像。
- en: The endoscopy is one of the most common optical imaging techniques where a physician
    inserts an imaging device and light source inside the patient and a series of
    images are taken for later diagnosis. For example, when diagnosing abnormalities
    in the digestive system, the endoscope is inserted through the patient’s mouth
    and the captured images can be used to diagnose conditions such bowel diseases,
    gastrointestinal bleeding and cancer. Fig. [24](#A1.F24 "Figure 24 ‣ A-A Biomedical
    Imagining ‣ Appendix A Types of Data ‣ Deep Learning for Medical Anomaly Detection
    - A Survey") (a) shows an image of a capsule endoscopy device, where a small wireless
    camera is placed within a capsule like component. The patient swallows this capsule
    and the endoscopy device takes a video of the patient’s gastrointestinal tract.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 内窥镜是最常见的光学成像技术之一，其中医生将成像设备和光源插入患者体内，并拍摄一系列图像以供后续诊断。例如，在诊断消化系统异常时，内窥镜通过患者的口腔插入，捕获的图像可用于诊断如肠道疾病、胃肠道出血和癌症等情况。图
    [24](#A1.F24 "Figure 24 ‣ A-A Biomedical Imagining ‣ Appendix A Types of Data
    ‣ Deep Learning for Medical Anomaly Detection - A Survey") (a) 显示了一个胶囊内窥镜设备的图像，其中一个小型无线摄像头被放置在一个胶囊状组件内。患者吞下这个胶囊，内窥镜设备对患者的胃肠道进行视频记录。
- en: '![Refer to caption](img/5efc6c3e997cdd57c17785b6edce07ca.png)'
  id: totrans-575
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/5efc6c3e997cdd57c17785b6edce07ca.png)'
- en: (a)
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/29352b1074912a9602490f364b161a22.png)'
  id: totrans-577
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/29352b1074912a9602490f364b161a22.png)'
- en: (b)
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 24: (a)An image of a capsule endoscopy device. Image [source](https://commons.wikimedia.org/wiki/Main_Page).
    (b) An endoscopy image of the gastrointestinal tract which is taken from [The
    Nerthus endoscopy dataset.](https://datasets.simula.no/nerthus/)'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 图 24： (a) 胶囊内窥镜设备的图像。图像 [来源](https://commons.wikimedia.org/wiki/Main_Page)。
    (b) 从[The Nerthus内窥镜数据集](https://datasets.simula.no/nerthus/)中拍摄的胃肠道内窥镜图像。
- en: Deep learning techniques have predominately been applied to extract discriminative
    features from pre-trained CNNs in computer aided video endoscopy analysis [[5](#bib.bib5),
    [189](#bib.bib189), [190](#bib.bib190)]. The authors of these works leverage the
    transferability of the learned features among different visual datasets, and try
    to adapt feature extraction models trained on large data corpora such as ImageNet
    [[71](#bib.bib71)] to extract features from small scale endoscopy datasets. In
    [[191](#bib.bib191)], the authors tested multiple existing pre-trained CNN network
    features to better detect abnormalities.
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习技术主要应用于从预训练的CNN中提取判别特征，用于计算机辅助的视频内窥镜分析[[5](#bib.bib5)、[189](#bib.bib189)、[190](#bib.bib190)]。这些研究的作者利用学习到的特征在不同视觉数据集之间的可迁移性，并尝试将训练于大型数据集（如ImageNet[[71](#bib.bib71)]）的特征提取模型适配到小规模内窥镜数据集上。在[[191](#bib.bib191)]中，作者测试了多种现有的预训练CNN网络特征，以更好地检测异常。
- en: Apart from endoscopy image analysis, optical images and videos have been use
    for other diagnostic purposes. For instance, in [[192](#bib.bib192), [193](#bib.bib193),
    [194](#bib.bib194), [195](#bib.bib195)] the authors use deep learning to obtain
    semiological features to classify different types of epilepsy. Specifically, they
    extract facial features together with upper-body, hand movement features, and
    pose features using deep learning techniques for classification. Facial features
    extracted from deep learning techniques have also been extensively analysed in
    [[196](#bib.bib196), [197](#bib.bib197)] for identification of genetic disorders
    from facial images. In addition, works such as [[198](#bib.bib198)] have tested
    the viability of optical images for scoliosis screening, and in [[199](#bib.bib199)]
    for skin disease recognition.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 除了内窥镜图像分析，光学图像和视频也用于其他诊断目的。例如，在[[192](#bib.bib192)、[193](#bib.bib193)、[194](#bib.bib194)、[195](#bib.bib195)]中，作者利用深度学习获得半语义特征，以分类不同类型的癫痫。具体来说，他们提取面部特征以及上半身、手部运动特征和姿势特征，并使用深度学习技术进行分类。通过深度学习技术提取的面部特征在[[196](#bib.bib196)、[197](#bib.bib197)]中也被广泛分析，用于从面部图像中识别遗传性疾病。此外，像[[198](#bib.bib198)]这样的研究测试了光学图像在脊柱侧弯筛查中的可行性，以及在[[199](#bib.bib199)]中用于皮肤疾病识别。
- en: Summary
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要
- en: In summary, most biomedical imaging techniques utilise similar types of imagining
    sensors together with different energy sources, such as X-ray or visible light
    for imaging, producing images with 2 or more dimensions. One interesting characteristic
    of biomedical imaging is its ability to create multi-dimensional spatial representations
    ranging from 2D (such as X-ray), 3D (such as CT) and 4D (such as ultrasound).This
    has motivated most of the abnormality detection techniques in biomedical imaging
    to use CNN based architectures to model this data. Please refer to Sec. 2.2 and
    Sec. 2.3 of the main document where we discuss such approaches in detail.
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，大多数生物医学成像技术利用相似类型的成像传感器以及不同的能源来源，例如X射线或可见光，生成具有2个或更多维度的图像。生物医学成像的一个有趣特点是其创建多维空间表示的能力，从2D（如X射线）、3D（如CT）到4D（如超声）。这促使大多数生物医学成像中的异常检测技术使用基于CNN的架构来建模这些数据。请参见主文档的第2.2节和第2.3节，我们将在这些部分详细讨论这些方法。
- en: Tab. [III](#A1.T3 "TABLE III ‣ A-A Biomedical Imagining ‣ Appendix A Types of
    Data ‣ Deep Learning for Medical Anomaly Detection - A Survey") summarises a list
    of datasets for biomedical imagining which are publicly available and have been
    extensively applied in machine learning research.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [III](#A1.T3 "表 III ‣ A-A 生物医学成像 ‣ 附录 A 数据类型 ‣ 医学异常检测的深度学习 - 调查") 总结了可公开获取并在机器学习研究中被广泛应用的生物医学成像数据集列表。
- en: 'TABLE III: List of publicly available datasets for biomedical imaging'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 表 III：公开可用的生物医学成像数据集列表
- en: Data Type Task Dataset Name Description References X-ray Chest radiography CheXpert
    The dataset consists of 224,316 chest radiographs of 65,240 patients labeled for
    the presence of 14 common chest radiographic observations. [link](https://stanfordmlgroup.github.io/competitions/chexpert/)
    ChestX-ray8 Comprises 108,948 frontal view X-ray images of 32,717 unique patients
    with the text mined for eight disease labels [link](https://github.com/TRKuan/cxr8)
    Bone radiography MURA (musculoskeletal radiographs) Contains 9,045 normal and
    5,818 abnormal musculoskeletal radiographic studies of the upper extremities including
    the shoulder, humerus, elbow, forearm, wrist, hand, and finger. [link](https://stanfordmlgroup.github.io/competitions/mura/)
    MRI Assessment of Alzheimer’s Disease ADNI The dataset consists of 819 subjects
    (229 Normal, 398 with mild cognitive impairment, and 192 with Alzheimer disease)
    . [link](http://adni.loni.usc.edu/data-samples/access-data/) Autism Disorders
    Identification Autism Brain Imaging Data Exchange (ABIDE) 539 individuals suffering
    from Autism spectrum disorders and 573 healthy control subjects. [link](http://preprocessed-connectomes-project.org/abide/)
    Ultrasound Cardiac functionality assessment EchoNet-Dynamic includes 10,030 labeled
    echocardiogram videos and human expert annotations (measurements, tracings, and
    calculations) . [link](https://echonet.github.io/dynamic/index.html#access) CT
    Lung cancer Detection Lung Image Database Consortium (LIDC) includes data from
    1018 Participants which comprises 244,527 images. [link](https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI#)
    RIDER Lung CT 32 patients with lung cancer, each of whom underwent two CT scans
    of the chest within 15 minutes time lag [link](https://wiki.cancerimagingarchive.net/display/Public/RIDER+Lung+CT)
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 数据类型 任务 数据集名称 描述 参考 X-ray 胸部放射成像 CheXpert 该数据集包括 65,240 名患者的 224,316 张胸部 X 光片，并标记了
    14 种常见胸部 X 光观察结果的存在。 [link](https://stanfordmlgroup.github.io/competitions/chexpert/)
    ChestX-ray8 包括 32,717 名独特患者的 108,948 张正面 X 光图像，并挖掘了八种疾病标签 [link](https://github.com/TRKuan/cxr8)
    骨骼放射成像 MURA（肌肉骨骼放射成像） 包含 9,045 张正常和 5,818 张异常的肌肉骨骼放射成像研究，涉及肩部、肱骨、肘部、前臂、手腕、手和手指。
    [link](https://stanfordmlgroup.github.io/competitions/mura/) MRI 阿尔茨海默病评估 ADNI
    该数据集包括 819 名受试者（229 名正常，398 名轻度认知障碍患者，192 名阿尔茨海默病患者）。 [link](http://adni.loni.usc.edu/data-samples/access-data/)
    自闭症障碍识别 自闭症脑影像数据交换（ABIDE） 539 名自闭症谱系障碍患者和 573 名健康对照者。 [link](http://preprocessed-connectomes-project.org/abide/)
    超声心脏功能评估 EchoNet-Dynamic 包括 10,030 个标记的超声心动图视频和人工专家注释（测量、描记和计算）。 [link](https://echonet.github.io/dynamic/index.html#access)
    CT 肺癌检测 肺部图像数据库联盟（LIDC）包含来自 1018 名参与者的数据，共 244,527 张图像。 [link](https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI#)
    RIDER 肺部 CT 32 名肺癌患者，每位患者在 15 分钟内接受了两次胸部 CT 扫描 [link](https://wiki.cancerimagingarchive.net/display/Public/RIDER+Lung+CT)
- en: A-B Electrical Biomedical Signals
  id: totrans-587
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A-B 电生物医学信号
- en: 'Electrocardiogram (ECG): ECG is a tool to visualise electricity flowing through
    the heart which creates the heart beat, and starts at the top of the heart and
    travels to the bottom. At rest, heart cells are negatively charged compared to
    the outside environment and when they become depolarized they become positively
    charged. The difference in polarization is captured by the ECG. There are two
    types of information which can be extracted by analysing the ECG [[17](#bib.bib17)].
    First, by measuring time intervals on an ECG one can screen for irregular electrical
    activities. Second, the strength of the electrical activity provides an indication
    of the regions of the heart that are over worked or stressed. Fig. [25](#A1.F25
    "Figure 25 ‣ A-B Electrical Biomedical Signals ‣ Appendix A Types of Data ‣ Deep
    Learning for Medical Anomaly Detection - A Survey") provides samples of normal
    and abnormal (Atrial Premature Contraction) ECG signals. ECG is used as a preliminary
    tool to screen heart arrhythmia and other cardiovascular diseases such as blocked
    or narrowed arteries.'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 心电图（ECG）：ECG 是一个用于可视化流经心脏的电流的工具，这些电流产生心跳，从心脏的顶部开始，传到底部。在静息状态下，心脏细胞相对于外部环境呈负电荷，当它们去极化时，它们变为正电荷。ECG
    捕捉到的极化差异。通过分析 ECG 可以提取两种类型的信息[[17](#bib.bib17)]。首先，通过测量 ECG 上的时间间隔可以筛查不规则的电活动。其次，电活动的强度提供了心脏工作过度或受压的区域的指示。图[25](#A1.F25
    "Figure 25 ‣ A-B Electrical Biomedical Signals ‣ Appendix A Types of Data ‣ Deep
    Learning for Medical Anomaly Detection - A Survey")提供了正常和异常（心房早期收缩）ECG 信号的样本。ECG
    被用作筛查心律失常和其他心血管疾病（如阻塞或狭窄的动脉）的初步工具。
- en: '![Refer to caption](img/2a94997686e2d9e3421eff2d51fe24be.png)'
  id: totrans-589
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/2a94997686e2d9e3421eff2d51fe24be.png)'
- en: 'Figure 25: Illustration of normal and abnormal ECG signals. Recreated from
    [[200](#bib.bib200)]'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: '图 25: 正常和异常 ECG 信号的示意图。重建自 [[200](#bib.bib200)]'
- en: Many works have exploited deep learning for ECG analysis. For instance, CNN-based
    ECG arrhythmia detection is investigated in [[201](#bib.bib201), [202](#bib.bib202),
    [203](#bib.bib203), [204](#bib.bib204), [205](#bib.bib205)]. When applying 2D
    CNN architectures the authors have considered the temporal representation of the
    1D signal as an image and passed the 2D representation through CNN kernals for
    feature extraction. Another area of investigation has been the use of Recurrent
    Neural Networks (RNNs) to model the temporal evolution of the ECG signal. For
    instance, in [[206](#bib.bib206), [207](#bib.bib207), [208](#bib.bib208), [209](#bib.bib209),
    [210](#bib.bib210), [211](#bib.bib211)] the authors have investigated variants
    of RNNs such as LSTMs and GRUs while in [[212](#bib.bib212)] the authors employ
    RNNs to model features and then use clustering techniques to identify abnormalities.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究利用深度学习进行 ECG 分析。例如，基于 CNN 的 ECG 心律失常检测在 [[201](#bib.bib201), [202](#bib.bib202),
    [203](#bib.bib203), [204](#bib.bib204), [205](#bib.bib205)] 中进行了研究。应用 2D CNN 架构时，作者将
    1D 信号的时间表示视为图像，并通过 CNN 核进行特征提取。另一个研究领域是使用递归神经网络（RNNs）来建模 ECG 信号的时间演变。例如，在 [[206](#bib.bib206),
    [207](#bib.bib207), [208](#bib.bib208), [209](#bib.bib209), [210](#bib.bib210),
    [211](#bib.bib211)] 中，作者研究了 LSTMs 和 GRUs 等 RNN 变体，而在 [[212](#bib.bib212)] 中，作者使用
    RNN 来建模特征，然后使用聚类技术来识别异常。
- en: 'Electroencephalogram (EEG): The EEG detects electrical activity in the brain,
    which uses electrical impulses to communicate. To capture the electrical activity,
    small metal discs (electrodes) are placed on the scalp. The electrical signals
    captured by these electrodes are amplified in to better visualise brain activity.'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 脑电图 (EEG)：EEG 检测大脑中的电活动，利用电脉冲进行通信。为了捕捉电活动，小金属圆盘（电极）被放置在头皮上。这些电极捕捉到的电信号被放大，以便更好地可视化脑活动。
- en: There exist different standards for placing the electrodes on the scalp. Fig.
    [26](#A1.F26 "Figure 26 ‣ A-B Electrical Biomedical Signals ‣ Appendix A Types
    of Data ‣ Deep Learning for Medical Anomaly Detection - A Survey") (a) shows one
    popular standard, termed the 10-20 system. The brain regions are divided into
    pre-frontal (Fp), frontal (F), temporal (T), parietal (P), occipital (O), and
    central (C). The number associated with the electrode reflects whether it is placed
    on the left or right side of the brain. If it is an even-number (2,4,6,8) the
    electrode is place on the right side of the head, whereas odd numbers (1,3,5,7)
    are are on the left. Two reference electrodes labelled ‘A1’ and ‘A2’ are placed
    behind the outer ear.
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 在头皮上放置电极有不同的标准。图 [26](#A1.F26 "Figure 26 ‣ A-B Electrical Biomedical Signals
    ‣ Appendix A Types of Data ‣ Deep Learning for Medical Anomaly Detection - A Survey")
    (a) 显示了一种流行的标准，称为 10-20 系统。脑区被划分为额前区 (Fp)、额区 (F)、颞区 (T)、顶区 (P)、枕区 (O) 和中央区 (C)。与电极相关的数字反映了它是放置在大脑的左侧还是右侧。如果是偶数（2,4,6,8），电极放置在头部右侧，而奇数（1,3,5,7）则在左侧。两个标记为‘A1’和‘A2’的参考电极放置在外耳后面。
- en: (a)
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/936aade847de4b6b7ad5962aaa305e69.png)'
  id: totrans-595
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/936aade847de4b6b7ad5962aaa305e69.png)'
- en: (b)
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 26: (a)Illustration of the 10-20 EEG electrode placement system. (b)
    Variations of the EEG recording before and after a seizure.'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: '图 26: (a) 10-20 EEG 电极放置系统的示意图。 (b) 癫痫发作前后的 EEG 记录变化。'
- en: EEGs are a prominent tool for observing the cognitive process of a subject.
    They are often used to study sleep patterns, psychological disorders, brain damage
    from head injury, and epilepsy. Fig. [26](#A1.F26 "Figure 26 ‣ A-B Electrical
    Biomedical Signals ‣ Appendix A Types of Data ‣ Deep Learning for Medical Anomaly
    Detection - A Survey") (b) shows how clearly the change in brain activity is captured
    by the EEG when a patient suffers an epileptic seizure.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: EEG 是观察受试者认知过程的一个重要工具。它们常用于研究睡眠模式、心理障碍、头部伤害造成的脑损伤以及癫痫。图 [26](#A1.F26 "Figure
    26 ‣ A-B Electrical Biomedical Signals ‣ Appendix A Types of Data ‣ Deep Learning
    for Medical Anomaly Detection - A Survey") (b) 显示了当患者发生癫痫发作时 EEG 如何清晰地捕捉到脑活动的变化。
- en: Similar to ECG based analysis, CNNs and RNNs have been a popular choice for
    EEG analysis. For instance, a CNN based feature extractor is applied in [[213](#bib.bib213)]
    for EEG based Schizophrenia detection while in [[214](#bib.bib214)] the authors
    use a hybrid of a CNN and LSTM. CNNs are also widely used to analyse EEGs for
    Epilepsy Detection [[215](#bib.bib215), [216](#bib.bib216), [217](#bib.bib217),
    [218](#bib.bib218), [219](#bib.bib219)]; though RNNs are also commonly used as
    in [[220](#bib.bib220), [221](#bib.bib221), [222](#bib.bib222)]. When considering
    deep learning based studies on sleep abnormality detection using EEGs, the authors
    in [[223](#bib.bib223)] have assessed CNN and RNN architectures together with
    spectrogram features for diagnosing sleep disorders.
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于 ECG 的分析类似，CNN 和 RNN 也成为 EEG 分析中的热门选择。例如，在 [[213](#bib.bib213)] 中应用了基于 CNN
    的特征提取器用于 EEG 基于的精神分裂症检测，而在 [[214](#bib.bib214)] 中，作者使用了 CNN 和 LSTM 的混合体。CNN 也广泛用于分析
    EEG 以检测癫痫 [[215](#bib.bib215), [216](#bib.bib216), [217](#bib.bib217), [218](#bib.bib218),
    [219](#bib.bib219)]；尽管 RNN 也常被使用，如 [[220](#bib.bib220), [221](#bib.bib221), [222](#bib.bib222)]
    中所示。在考虑基于深度学习的 EEG 睡眠异常检测研究时，[[223](#bib.bib223)] 中的作者评估了 CNN 和 RNN 架构以及频谱图特征用于诊断睡眠障碍。
- en: 'Magnetoencephalography (MEG): s a functional neuroimaging mechanism which captures
    the magnetic fields produced by the brain’s electrical activity, hence, we group
    MEG with other electrical biomedical signals. Fig. 9 illustrates this process.
    During synaptic transmission ionic currents flow in the dendrites of neurons and
    produce a magnetic field. MEG is readily used for the recognition of perceptual
    and cognitive brain processes, as well as for localising abnormal regions in the
    brain.'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: 磁脑电图（MEG）：是一种功能性神经成像机制，它捕捉大脑电活动产生的磁场，因此，我们将 MEG 与其他电生物医学信号归为一类。图 9 说明了这一过程。在突触传递过程中，离子电流在神经元的树突中流动并产生磁场。MEG
    被广泛用于识别知觉和认知脑过程，以及定位大脑中的异常区域。
- en: '![Refer to caption](img/f9b1549db76ce083312c693346eb396e.png)'
  id: totrans-601
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f9b1549db76ce083312c693346eb396e.png)'
- en: 'Figure 27: Illustration of brain’s magnetic field. Image [source](https://commons.wikimedia.org/wiki/Main_Page)'
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 图 27：大脑磁场的示意图。图片 [来源](https://commons.wikimedia.org/wiki/Main_Page)
- en: Several studies [[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22),
    [23](#bib.bib23), [24](#bib.bib24)] have investigated the utility of MEG signals
    for the detection of anomalous brain activities and conditions. Specifically,
    in [[22](#bib.bib22)] the authors propose a spatio-temporal neural network structure
    to identify ocular and cardiac activities. 1D and 2D CNN architectures for early
    detection of Alzheimer’s disease based on MEG signals is proposed in [[23](#bib.bib23)].
    The authors hand-craft 870 features to extract from the MEG signal, and apply
    a 1D convolution followed by two fully connected layers prior to generating a
    binary classification (i.e. healthy or Mild Cognitive Impairment). For the 2D
    CNN architecture, the authors first reshape the 870 features to a matrix, which
    constitutes the input to the 2D convolution layer. In a different line of work,
    a deep learning architecture which operates on raw MEG signals is proposed in
    [[24](#bib.bib24)]. Specifically, authors propose a method to distinguish between
    patients with epilepsy, spinal cord injuries and healthy subjects. The input to
    the model is a 160-channel MEG signal which is processed using a series of convolution
    and pooling layers. Prior to classification the authors concatenate the resultant
    feature vector from this network together with a Fourier transformation of the
    input MEG signal which is then passed through a series of fully-connected layers
    to generate the 3 class classification.
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究 [[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22),
    [23](#bib.bib23), [24](#bib.bib24)] 探讨了 MEG 信号在检测异常脑活动和状况中的应用。具体而言，在 [[22](#bib.bib22)]
    中，作者提出了一种时空神经网络结构来识别眼动和心脏活动。在 [[23](#bib.bib23)] 中，提出了基于 MEG 信号的早期阿尔茨海默病检测的 1D
    和 2D CNN 架构。作者手工制作了 870 个特征从 MEG 信号中提取，并应用 1D 卷积层，之后是两个全连接层，然后生成二元分类（即健康或轻度认知障碍）。对于
    2D CNN 架构，作者首先将 870 个特征重塑为矩阵，作为 2D 卷积层的输入。在另一项工作中，[[24](#bib.bib24)] 中提出了一种操作原始
    MEG 信号的深度学习架构。具体来说，作者提出了一种方法来区分癫痫患者、脊髓损伤患者和健康受试者。模型的输入是 160 通道的 MEG 信号，使用一系列卷积和池化层处理。在分类之前，作者将该网络的结果特征向量与输入
    MEG 信号的傅里叶变换连接，然后通过一系列全连接层生成三类分类。
- en: 'Electromyography (EMG): EMG is the process of recording electric potential
    generated by muscle cells to diagnose the health of muscles and motor neurons.
    Depending on the study either needle or surface electrodes are placed to measure
    electrical activity. Fig. [28](#A1.F28 "Figure 28 ‣ A-B Electrical Biomedical
    Signals ‣ Appendix A Types of Data ‣ Deep Learning for Medical Anomaly Detection
    - A Survey") illustrates an example of normal and abnormal EMG signals. The needle
    electrode can directly measure the electrical activity of the a muscle while surface
    electrodes are used to measure the electrical signal that is traveling between
    two or more points. EMGs are frequently used to diagnose muscle disorders such
    as muscular dystrophy and polymyositis, disorders that affect the motor neurons
    (eg. amyotrophic lateral sclerosis or polio), nerves and muscles (eg. myasthenia
    gravis).'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: 电动肌图（EMG）：EMG 是记录肌肉细胞生成的电位以诊断肌肉和运动神经元健康的过程。根据研究的不同，可能会使用针电极或表面电极来测量电活动。图 [28](#A1.F28
    "图 28 ‣ A-B 电生物医学信号 ‣ 附录 A 数据类型 ‣ 医疗异常检测的深度学习 - 调查") 显示了正常和异常 EMG 信号的示例。针电极可以直接测量肌肉的电活动，而表面电极用于测量在两个或多个点之间传播的电信号。EMG
    常用于诊断肌肉疾病，如肌营养不良和多发性肌炎，以及影响运动神经元（如肌萎缩侧索硬化症或小儿麻痹症）、神经和肌肉（如重症肌无力）的疾病。
- en: '![Refer to caption](img/6e87c23447e04df92b18d2638892b8d6.png)'
  id: totrans-605
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/6e87c23447e04df92b18d2638892b8d6.png)'
- en: 'Figure 28: Illustration of normal and abnormal EMG signals. Recreated from
    [[200](#bib.bib200)]'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 图 28：正常和异常 EMG 信号的示意图。重绘自 [[200](#bib.bib200)]
- en: Considering the existing literature we observe that EMG based abnormality detection
    in not widely studied. However, there does exist deep learning based research
    conducted using EMGs to detect muscle activation [[224](#bib.bib224)], to extract
    information on muscle movement [[225](#bib.bib225)] and to predict movement intent
    [[226](#bib.bib226)]
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到现有的文献，我们观察到基于 EMG 的异常检测研究还不广泛。然而，确实存在基于深度学习的研究，利用 EMG 来检测肌肉激活 [[224](#bib.bib224)]，提取肌肉运动信息
    [[225](#bib.bib225)]，以及预测运动意图 [[226](#bib.bib226)]。
- en: Summary
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要
- en: Similar to biomedical imaging sensors we observe that electrical biomedical
    sensors also have similar designs and signal characteristics among different sensor
    types. However, in contrast to biomedical imaging, the electrical biomedical signals
    carry temporal information. Hence, it is vital to model the temporal evolution
    of the signal and to identify how different characteristics of the signal change
    over time. Therefore, temporal modelling has become vital when detecting abnormalities
    in electrical biomedical signals, and several different such architectures have
    emerged. Please refer to Sec. 2.2 of the main document for detail comparison between
    such architectures.
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于生物医学成像传感器，我们观察到电生物医学传感器在不同传感器类型之间也具有相似的设计和信号特征。然而，与生物医学成像不同的是，电生物医学信号携带了时间信息。因此，建模信号的时间演变以及识别信号特征如何随时间变化是至关重要的。因此，时间建模在检测电生物医学信号的异常时变得至关重要，已经出现了几种不同的这种架构。有关这些架构的详细比较，请参见主文档第
    2.2 节。
- en: Tab. [IV](#A1.T4 "TABLE IV ‣ A-B Electrical Biomedical Signals ‣ Appendix A
    Types of Data ‣ Deep Learning for Medical Anomaly Detection - A Survey") summarises
    datasets with electrical biomedical signals which are publicly available and extensively
    used in machine learning research.
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [IV](#A1.T4 "表 IV ‣ A-B 电生物医学信号 ‣ 附录 A 数据类型 ‣ 医疗异常检测的深度学习 - 调查") 总结了公开获取的电生物医学信号数据集，这些数据集在机器学习研究中被广泛使用。
- en: 'TABLE IV: List of publicly available datasets with electrical biomedical signals.'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 表 IV：公开获取的电生物医学信号数据集列表。
- en: Data Type Task Dataset Name Description No Channels No Subjects References ECG
    Cardiac Abnormality Detection PhysioNet-CinC 2020 Identify clinical diagnoses
    12 43,135 [link](https://physionet.org/content/challenge-2020/1.0.0/) MIT-BIH
    Atrial Fibrillation Database Subjects with atrial fibrillation. 2 25 (records)
    [link](https://physionet.org/content/afdb/1.0.0/) MIT-BIH Arrhythmia Database
    Evaluation of arrhythmia detectors 2 48 [link](https://www.physionet.org/content/mitdb/1.0.0/)
    BIDMC Congestive heart failure detection 2 15 [link](https://physionet.org/content/chfdb/1.0.0/)
    Fantasia Congestive heart failure detection 2 40 [link](https://physionet.org/content/fantasia/1.0.0/)
    INCART Arrhythmia detection 12 32 [link](https://physionet.org/content/incartdb/1.0.0/)
    CCDD Cardiovascular disease diagnosis 12 1500 (records) [link](https://ieeexplore.ieee.org/document/5521712)
    CSE Cardiovascular disease diagnosis 12 1000 (records) [link](https://archive.physionet.org/physiobank/other.shtml)
    EEG Epilepsy Bonn University Epilepsy detection 1 25 [link](http://epileptologie-bonn.de/cms/upload/workgroup/lehnertz/eegdata.html)
    TUH Abnormal EEG database Brain disorders diagnosis 24-36 10874 [link](https://www.isip.piconepress.com/projects/tuh_eeg/)
    Freiburg Hospital Epilepsy detection 128 200 [link](https://epilepsy.uni-freiburg.de/database)
    EPILEPSIAE Epilepsy detection 122 30 [link](http://epilepsy-database.eu/) MSSM
    Epilepsy detection 22 28 [link](https://icahn.mssm.edu/research/portal?tab=Labs)
    CHB-MIT Epilepsy detection 23 22 [link](https://icahn.mssm.edu/research/portal?tab=Labs)
    Sleep Sleep EDF database Sleep disorder diagnosis 2 197 (records) [link](https://physionet.org/content/sleep-edfx/)
    Cyclic Alternating Pattern (CAP) of EEG Activity dataset Sleep disorder diagnosis
    3 108 [link](https://physionet.org/content/capslpdb/1.0.0/) MEG Brain Functions
    Cam-CAN Age-related segregation of brain functions 306 674 [link](https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/)
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 数据类型 任务 数据集名称 描述 通道数量 受试者数量 参考文献 心电图 心脏异常检测 PhysioNet-CinC 2020 识别临床诊断 12 43,135
    [link](https://physionet.org/content/challenge-2020/1.0.0/) MIT-BIH 房颤数据库 房颤患者。
    2 25 (记录) [link](https://physionet.org/content/afdb/1.0.0/) MIT-BIH 心律失常数据库 心律失常检测评估
    2 48 [link](https://www.physionet.org/content/mitdb/1.0.0/) BIDMC 充血性心力衰竭检测 2
    15 [link](https://physionet.org/content/chfdb/1.0.0/) Fantasia 充血性心力衰竭检测 2 40
    [link](https://physionet.org/content/fantasia/1.0.0/) INCART 心律失常检测 12 32 [link](https://physionet.org/content/incartdb/1.0.0/)
    CCDD 心血管疾病诊断 12 1500 (记录) [link](https://ieeexplore.ieee.org/document/5521712)
    CSE 心血管疾病诊断 12 1000 (记录) [link](https://archive.physionet.org/physiobank/other.shtml)
    脑电图 癫痫 Bonn University 癫痫检测 1 25 [link](http://epileptologie-bonn.de/cms/upload/workgroup/lehnertz/eegdata.html)
    TUH 异常脑电图数据库 脑部疾病诊断 24-36 10874 [link](https://www.isip.piconepress.com/projects/tuh_eeg/)
    Freiburg Hospital 癫痫检测 128 200 [link](https://epilepsy.uni-freiburg.de/database)
    EPILEPSIAE 癫痫检测 122 30 [link](http://epilepsy-database.eu/) MSSM 癫痫检测 22 28 [link](https://icahn.mssm.edu/research/portal?tab=Labs)
    CHB-MIT 癫痫检测 23 22 [link](https://icahn.mssm.edu/research/portal?tab=Labs) 睡眠
    EDF 数据库 睡眠障碍诊断 2 197 (记录) [link](https://physionet.org/content/sleep-edfx/) 脑电图活动的周期交替模式
    (CAP) 数据集 睡眠障碍诊断 3 108 [link](https://physionet.org/content/capslpdb/1.0.0/) 头磁图
    大脑功能 Cam-CAN 与年龄相关的大脑功能分离 306 674 [link](https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/)
- en: A-C Miscellaneous data types
  id: totrans-613
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A-C 杂项数据类型
- en: 'Phonocardiography (PCG): PCG is the recording of the sounds observed during
    cardiac auscultation. This is a fundamental step of a physical examination in
    clinical practice. It has proven to be one of the most cost effective methods
    for screening for numerous heart abnormalities, including arrhythmia, valve disease
    and heart failure. In each heart cycle the variation in blood pressure produced
    by the closure of the mitral and tricuspid valves and their vibrations causes
    the first heart sound (S1). Then the second heart sound (S2) is generated by the
    closure of the aortic and pulmonary valves and their vibrations. The window between
    S1 and S2 is termed the systole interval, and the diastole interval is from S2
    to the beginning of S1 in the next heart cycle. Fig. [29](#A1.F29 "Figure 29 ‣
    A-C Miscellaneous data types ‣ Appendix A Types of Data ‣ Deep Learning for Medical
    Anomaly Detection - A Survey") (a) shows how the first and second heart sounds
    appear in a typical PCG recording.'
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 心音图（PCG）：PCG 是记录在心脏听诊期间观察到的声音。这是临床实践中体格检查的一个基本步骤。它被证明是筛查多种心脏异常（包括心律失常、瓣膜病和心力衰竭）最具成本效益的方法之一。在每个心动周期中，由二尖瓣和三尖瓣关闭引起的血压变化及其震动产生第一心音（S1）。接着，由主动脉瓣和肺动脉瓣关闭及其震动产生第二心音（S2）。S1
    和 S2 之间的窗口称为收缩间期，而舒张间期是从 S2 到下一个心动周期的 S1 开始。图 [29](#A1.F29 "Figure 29 ‣ A-C Miscellaneous
    data types ‣ Appendix A Types of Data ‣ Deep Learning for Medical Anomaly Detection
    - A Survey") (a) 显示了在典型 PCG 记录中，第一心音和第二心音的出现方式。
- en: '![Refer to caption](img/a766d9e56a82af447a4f95d40cde066e.png)'
  id: totrans-615
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a766d9e56a82af447a4f95d40cde066e.png)'
- en: (a)
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/14fb36b2a659cb6868be5c008946874f.png)'
  id: totrans-617
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/14fb36b2a659cb6868be5c008946874f.png)'
- en: (b)
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 29: (a)Illustration of heart states and systole / diastole intervals.
    (b) Illustration of [Stethee®](https://www.stethee.com/)a wireless electronic
    stethoscope)'
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: '图 29: (a)心脏状态及收缩/舒张间期的示意图。 (b) [Stethee®](https://www.stethee.com/)无线电子听诊器的示意图'
- en: The availability of electronic stethoscopes such as Littmann, Cardionics E-Scope
    and Stethee which digitise the analogue audio recordings, and the public availability
    of large scale datasets such as 2016 PhysioNet/CinC Challenge [[6](#bib.bib6)]
    has encouraged many deep learning practitioners to apply deep learning techniques
    to detect abnormal heart sounds. For instance, in [[227](#bib.bib227)] the authors
    propose the use of temporal quasi-periodic features together with an LSTM network
    to detect abnormal heart sounds. In contrast [[228](#bib.bib228), [91](#bib.bib91)]
    employed a convolutional neural network structure and extracted Mel-frequency
    cepstral coefficients (MFCCs) from the heart sound recordings. In [[229](#bib.bib229)]
    the authors propose using a hand crafted set of features such as PCG Amplitudes,
    and Power spectral and Frequency-based features together with a CNN.
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 电子听诊器如 Littmann、Cardionics E-Scope 和 Stethee，它们将模拟音频录音数字化，以及大规模数据集如 2016 PhysioNet/CinC
    Challenge [[6](#bib.bib6)] 的公开可用性，鼓励了许多深度学习从业者应用深度学习技术来检测异常心音。例如，在 [[227](#bib.bib227)]
    中，作者提出结合时间准周期特征和 LSTM 网络来检测异常心音。相反，[[228](#bib.bib228), [91](#bib.bib91)] 采用卷积神经网络结构，并从心音录音中提取
    Mel 频率倒谱系数（MFCCs）。在 [[229](#bib.bib229)] 中，作者提出使用手工制作的特征集，如 PCG 振幅、功率谱和基于频率的特征，并结合
    CNN。
- en: 'Wearable Medical Devices: Wearable sensing devices are an emerging technology
    to monitor the wearer’s health and detect abnormalities. Modern wearable devices
    such as smartwatches, smart clothing, smart footwear, and fitness trackers have
    the ability to measure various parameters, including, heart rate, body temperature,
    muscle activity, and blood/tissue oxygenation [[230](#bib.bib230)].'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: '可穿戴医疗设备: 可穿戴传感设备是一项新兴技术，用于监测佩戴者的健康状况和检测异常。现代可穿戴设备如智能手表、智能服装、智能鞋履和健身追踪器具有测量各种参数的能力，包括心率、体温、肌肉活动以及血液/组织氧合
    [[230](#bib.bib230)]。'
- en: There exists a small number of deep learning approaches for anomaly detection
    using such wearable devices. In [[231](#bib.bib231)] the authors detect gait abnormalities
    using data captured by an array of insole sensors. These sensors measure the pressure
    distribution during walking and standing and analyse the collected data using
    an LSTM based architecture. In another line of work [[232](#bib.bib232)], accelerometer
    data collected from smartwatches is leveraged to design a fall detection system.
    The authors proposed to run their RNN anomaly detection framework on a smart phone
    which has been paired with the smart watch to generate alarms when a fall is detected.
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 针对使用这些可穿戴设备的异常检测，现有的深度学习方法相对较少。在 [[231](#bib.bib231)] 中，作者使用阵列鞋垫传感器捕获的数据检测步态异常。这些传感器测量行走和站立期间的压力分布，并利用基于LSTM的架构分析收集的数据。在另一项研究中
    [[232](#bib.bib232)]，利用从智能手表收集的加速度计数据设计了一个跌倒检测系统。作者提出在与智能手表配对的智能手机上运行他们的RNN异常检测框架，以在检测到跌倒时发出警报。
- en: Summary Despite the vast differences in sensory types that we discussed, ranging
    from auditory sensors, motion senors to temperature sensors, all of the above
    devices capture temporal signals similar to electrical biomedical sensors. Therefore,
    in the existing literature similar model architectures are utilised to capture
    temporal information within these biomedical signals. In Sec. 2.3 of the main
    document we discuss such algorithms in detail.
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们讨论的传感器类型差异巨大，包括听觉传感器、运动传感器到温度传感器，所有上述设备都捕获了类似于电生物医学传感器的时间信号。因此，在现有文献中，类似的模型架构被用于捕捉这些生物医学信号中的时间信息。在主文档的第2.3节中，我们详细讨论了这些算法。
- en: Tab. [V](#A1.T5 "TABLE V ‣ A-C Miscellaneous data types ‣ Appendix A Types of
    Data ‣ Deep Learning for Medical Anomaly Detection - A Survey") summarises a list
    of audio and wearable device datasets that are publicly available for machine
    learning research.
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [V](#A1.T5 "TABLE V ‣ A-C Miscellaneous data types ‣ Appendix A Types of Data
    ‣ Deep Learning for Medical Anomaly Detection - A Survey") 总结了一份公开可用于机器学习研究的音频和可穿戴设备数据集清单。
- en: 'TABLE V: List of publicly available audio, vital sign and wearable device datasets.'
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 表 V：公开可用的音频、生命体征和可穿戴设备数据集清单。
- en: 'Data Type Task Dataset Name Description No recordings Other Modalities References
    PCG Heart sound Anomaly Detection PhysioNet-CinC 2016 Identifying cardiovascular
    diseases 3,126 ECG for subset (a) [link](https://physionet.org/content/challenge-2016/)
    Fetal Heart sound database constructed using recordings made from pregnant women
    109 PCG from mother and the fetal [link](https://physionet.org/content/sufhsdb/)
    PASCAL Identifying cardiovascular diseases 461 NO [link](http://www.peterjbentley.com/heartchallenge/)
    Murmur database Identifying cardiovascular diseases 1000 NO [link](https://github.com/yaseen21khan/Classification-of-Heart-Sound-Signal-Using-Multiple-Features-)
    Respiratory Sounds Classification of Respiratory Diseases Respiratory Sound Database
    Detection of respiratory cycles and abnormalties 920 NO [link](https://www.kaggle.com/vbookshelf/respiratory-sound-database)
    R.A.L.E Detection of respiratory cycles and abnormalties 50 NO [link](http://www.rale.ca/LungSounds.htm)
    HF Lung V1 Detection of respiratory cycles and abnormalties 9765 NO [link](https://gitlab.com/techsupportHF/HF_Lung_V1/-/tree/master/)
    Vital Sign Patient Monitoring The University of Queensland Vital Signs Dataset
    Anesthesia Patient Monitoring 32 EEG, ECG, pulse oximeter, capnograph, arterial
    blood pressure [link](https://outbox.eait.uq.edu.au/uqdliu3/uqvitalsignsdataset/browse.html)
    MIMIC-III Mortality and length-of-stay predictions 34,472 ECG, respiration waveform,
    arterial blood pressure [link](https://mimic.physionet.org/) MIMIC II: Waveform
    Database Abnormality detection and blood pressure predictions 23,180 ECG, respiration
    waveform, arterial blood pressure, plethysmograph [link](https://archive.physionet.org/mimic2/mimic2_waveform_overview.shtml)
    Wearable Devices Stress and Affect Detection WESAD affective states and emotion
    identification 15 skin temperature, ECG, blood volume pulse, respiration, accelerometers
    [link](https://archive.ics.uci.edu/ml/datasets/WESAD+%28Wearable+Stress+and+Affect+Detection%29)
    Fall Detection MobiFall and MobiAct Fall detection in active daily living scenarios
    3200 accelerometer, gyroscope [link](https://bmi.hmu.gr/the-mobifall-and-mobiact-datasets-2/)
    UR Fall Detection Dataset Fall detection in active daily living scenarios 70 accelerometer,
    RGB images, depth images [link](http://fenix.univ.rzeszow.pl/~mkepski/ds/uf.html)
    TST V2 Fall detection in active daily living scenarios 264 accelerometer, RGB
    images, depth images [link](https://ieee-dataport.org/documents/tst-fall-detection-dataset-v2)
    UniMiB SHAR Motion abnormalities and fall detection 11,771 accelerometer [link](http://www.sal.disco.unimib.it/technologies/unimib-shar/)'
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
