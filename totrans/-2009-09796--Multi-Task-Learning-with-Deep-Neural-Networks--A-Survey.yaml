- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:59:25'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2009.09796] Multi-Task Learning with Deep Neural Networks: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2009.09796](https://ar5iv.labs.arxiv.org/html/2009.09796)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Multi-Task Learning with Deep Neural Networks: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Michael Crawshaw
  prefs: []
  type: TYPE_NORMAL
- en: Department of Computer Science
  prefs: []
  type: TYPE_NORMAL
- en: George Mason University
  prefs: []
  type: TYPE_NORMAL
- en: mcrawsha@gmu.edu
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Multi-task learning (MTL) is a subfield of machine learning in which multiple
    tasks are simultaneously learned by a shared model. Such approaches offer advantages
    like improved data efficiency, reduced overfitting through shared representations,
    and fast learning by leveraging auxiliary information. However, the simultaneous
    learning of multiple tasks presents new design and optimization challenges, and
    choosing which tasks should be learned jointly is in itself a non-trivial problem.
    In this survey, we give an overview of multi-task learning methods for deep neural
    networks, with the aim of summarizing both the well-established and most recent
    directions within the field. Our discussion is structured according to a partition
    of the existing deep MTL techniques into three groups: architectures, optimization
    methods, and task relationship learning. We also provide a summary of common multi-task
    benchmarks.'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Multi-task learning is a training paradigm in which machine learning models
    are trained with data from multiple tasks simultaneously, using shared representations
    to learn the common ideas between a collection of related tasks. These shared
    representations increase data efficiency and can potentially yield faster learning
    speed for related or downstream tasks, helping to alleviate the well-known weaknesses
    of deep learning: large-scale data requirements and computational demand. However,
    achieving such effects has not proven easy and is an active area of research today.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We believe that MTL reflects the learning process of human beings more accurately
    than single task learning in that integrating knowledge across domains is a central
    tenant of human intelligence. When a newborn baby learns to walk or use its hands,
    it accumulates general motor skills which rely on abstract notions of balance
    and intuitive physics. Once these motor skills and abstract concepts are learned,
    they can be reused and augmented for more complex tasks later in life, such as
    riding a bike or tightrope walking. Any time that a human attempts to learn something
    new, we bring a tremendous amount of prior knowledge to the table. It’s no wonder
    that neural networks require such numerous training examples and computation time:
    every task is learned from scratch. Imagine trying to learn to tightrope walk
    without first learning to walk! The human ability to rapidly learn with few examples
    is dependent on this process of learning concepts which are generalizable across
    multiple settings and leveraging these concepts for fast learning; we believe
    that developing systems to perform this process should be the goal of multi-task
    learning and the related fields of meta-learning [Hospedales et al., [2020](#bib.bib63)],
    transfer learning [Zhuang et al., [2019](#bib.bib175)], and continuous/lifelong
    learning [Parisi et al., [2019](#bib.bib118)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'Learning concepts for multiple tasks does bring difficulties which aren’t present
    in single task learning. In particular, it may be the case that different tasks
    have conflicting needs. In this case, increasing the performance of a model on
    one task will hurt performance on a task with different needs, a phenomenon referred
    to as negative transfer or destructive interference. Minimizing negative transfer
    is a key goal for MTL methods. Many architectures are designed with specific features
    to decrease negative transfer, such as task-specific feature spaces and attention
    mechanisms, but division of information between tasks is a fine line to walk:
    we want to allow information flow between tasks that yields positive transfer,
    and discourage sharing when it would create negative transfer. The question of
    how exactly to design such a system is being actively investigated in MTL research.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The existing methods of MTL have often been partitioned into two groups with
    a familiar dichotomy: hard parameter sharing vs. soft parameter sharing. Hard
    parameter sharing is the practice of sharing model weights between multiple tasks,
    so that each weight is trained to jointly minimize multiple loss functions. Under
    soft parameter sharing, different tasks have individual task-specific models with
    separate weights, but the distance between the model parameters of different tasks
    is added to the joint objective function. Though there is no explicit parameter
    sharing, there is an incentive for the task-specific models to have similar parameters.
    This is a useful dichotomy, but the nature of multi-task methods has grown extremely
    diverse in the past few years, and we feel that these two categories alone are
    not broad enough to accurately describe the entire field. Instead, we widen the
    scope of the members of this dichotomy to cover more ground. We generalize the
    class of hard parameter sharing methods to multi-task architectures, while soft
    parameter sharing is broadened into multi-task optimization. When combined, architecture
    design and optimization techniques provide a nearly complete image of modern MTL.
    However, there is still an important direction within the field that is missing
    even from this generalized dichotomy: task relationship learning. Task relationship
    laerning (or TRL) methods focus on learning an explicit representation of the
    relationships between tasks, such as task embeddings or transfer learning affinities,
    and these types of methods don’t quite fit into either architecture design or
    optimization. Broadly speaking, these three directions - architecture design,
    optimization, and task relationship learning - make up the existing methods of
    modern deep multi-task learning.'
  prefs: []
  type: TYPE_NORMAL
- en: Many different researchers have used the term multi-task learning to refer to
    different settings, and we feel that it is important to clarify the scope of this
    review. As a convention, we interpret MTL to only contain learning settings in
    which a fixed set of tasks is learned simultaneously, and each task is treated
    equally. This means that we don’t consider training settings that have only a
    single “main task" with one or more auxiliary tasks, as well as settings in which
    the set of tasks to learn changes over time. We may, however, discuss models which
    were designed for such settings, if the ideas from the model are easily applicable
    to MTL.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the survey is outlined as follows. Section [2](#S2 "2 Multi-Task
    Architectures ‣ Multi-Task Learning with Deep Neural Networks: A Survey") contains
    a discussion of neural network architectures for multi-task learning. In section
    [3](#S3 "3 Optimization for Multi-Task Learning ‣ Multi-Task Learning with Deep
    Neural Networks: A Survey"), we discuss MTL optimization strategies, and we discuss
    methods for learning explicit task relationships in section [4](#S4 "4 Task Relationship
    Learning ‣ Multi-Task Learning with Deep Neural Networks: A Survey"). Section
    [5](#S5 "5 Multi-Task Benchmarks ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey") contains an overview of common multi-task benchmark for various domains.
    Finally, we conclude with section [6](#S6 "6 Conclusion ‣ Multi-Task Learning
    with Deep Neural Networks: A Survey"). Within each subsection or subsubsection,
    the methods are mostly presented in order of publication, from earliest to most
    recent. It should be noted that we do not discuss any classical (non-neural) multi-task
    learning methods, though a thorough review can be found in Zhang and Yang [[2017](#bib.bib170)],
    Ruder [[2017](#bib.bib129)].'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Multi-Task Architectures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A large portion of the MTL literature is devoted to the design of multi-task
    neural network architectures. There are many different factors to consider when
    creating a shared architecture, such as the portion of the model’s parameters
    that will be shared between tasks, and how to parameterize and combine task-specific
    and shared modules. More variations arise when considering architectures for a
    specific problem domain, like how to partition convolutional filters into shared
    and task-specific groups for a set of vision tasks. Many of the proposed architectures
    for MTL play a balancing game with the degree of information sharing between tasks:
    Too much sharing will lead to negative transfer and can cause worse performance
    of joint multi-task models than individual models for each task, while too little
    sharing doesn’t allow the model to effectively leverage information between tasks.
    The best performing architectures for MTL are those which balance sharing well.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We partition the MTL architectures into four groups: architectures for a particular
    task domain, multi-modal architectures, learned architectures, and conditional
    architectures. For single-domain architectures, we consider the domains of computer
    vision, natural language processing, and reinforcement learning. Multi-modal architectures
    handle tasks with input in more than one mode, such as visual question answering
    with both a visual and a language component. It should be noted that we only consider
    multi-modal architectures which handle multiple tasks. For a more complete discussion
    of multi-modal methods, see Baltrusaitis et al. [[2019](#bib.bib11)]. Lastly,
    We make the following distinction between learned architectures and conditional
    architectures: Learned architectures are fixed between steps of architecture learning,
    so the same computation is performed for each input from the same task. In conditional
    architectures, the architecture used for a given piece of data is dependent on
    the data itself.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Architectures for Computer Vision
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the single-task setting, many major developments for computer vision architectures
    have focused on novel network components and connections to improve optimization
    and extract more meaningful features, such as batch normalization Ioffe and Szegedy
    [[2015](#bib.bib66)], residual networks He et al. [[2016](#bib.bib60)], and squeeze
    and excitation blocks Hu et al. [[2018](#bib.bib64)]. In contrast, many multi-task
    architectures for computer vision focus on partitioning the network into task-specific
    and shared components in a way that allows for generalization through sharing
    and information flow between tasks, while minimizing negative transfer.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.1 Shared Trunk
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Traditionally, many multi-task architectures in computer vision follow a simple
    outline: A global feature extractor made of convolutional layers shared by all
    tasks followed by an individual output branch for each task, as in figure [1](#S2.F1
    "Figure 1 ‣ 2.1.1 Shared Trunk ‣ 2.1 Architectures for Computer Vision ‣ 2 Multi-Task
    Architectures ‣ Multi-Task Learning with Deep Neural Networks: A Survey"). We
    will refer to this template as a shared trunk.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/628983ce7d3d85457300aaa12f1856b3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Architecture for TCDCN Zhang et al. [[2014](#bib.bib171)]. The base
    feature extractor is made of a series of convolutional layers which are shared
    between all tasks, and the extracted features are used as input to task-specific
    output heads.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Zhang et al. [[2014](#bib.bib171)], Dai et al. [[2016](#bib.bib37)], Zhao et al.
    [[2018](#bib.bib173)], Liu et al. [[2019](#bib.bib93)], Ma et al. [[2018](#bib.bib105)]
    propose architectures which are variations on the shared trunk idea. Zhang et al.
    [[2014](#bib.bib171)], the earliest of these works, introduces Tasks-Constrained
    Deep Convolutional Network (TCDCN), whose architecture is shown in figure [1](#S2.F1
    "Figure 1 ‣ 2.1.1 Shared Trunk ‣ 2.1 Architectures for Computer Vision ‣ 2 Multi-Task
    Architectures ‣ Multi-Task Learning with Deep Neural Networks: A Survey"). The
    authors propose to improve performance on a facial landmark detection task by
    jointly learning head pose estimation and facial attribute inference. Dai et al.
    [[2016](#bib.bib37)] introduces Multi-task Network Cascades (MNCs). The architecture
    of MNCs is similar to TCDCN, with an important difference: the output of each
    task-specific branch is appended to the input of the next task-specific branch,
    forming the “cascade" of information flow after which the method is named. This
    type of architecture is similar to the cascaded information networks for NLP discussed
    in section [2.2.3](#S2.SS2.SSS3 "2.2.3 Cascaded Information ‣ 2.2 Architectures
    for Natural Language Processing ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning
    with Deep Neural Networks: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/16daa7aa0c7914ba748f1d388a8aed2e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Illustration of Multi-task Network Cascades Dai et al. [[2016](#bib.bib37)].
    The output of the first task is used as an input for the second task, the second
    task’s output is used as an input for the third task, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Zhao et al. [[2018](#bib.bib173)], Liu et al. [[2019](#bib.bib93)] each build
    on this original template with the introduction of task-specific modules which
    can be placed within existing shared architectures. By doing this, the computation
    of features relies on both the shared parameters of the feature extractor and
    the task-specific parameters of modules placed through the network, so that features
    of different tasks may differ before the task-specific output branches. Zhao et al.
    [[2018](#bib.bib173)] introduces a modulation module in the form of a task-specific
    channel-wise linear projection of feature maps, and the authors design a convolutional
    architecture with these modules following convolutional layers in the latter half
    of the network. Interestingly, it is empirically shown that the inclusion of these
    task-specific projection modules decreases the chance that gradient update directions
    for different tasks point in opposite directions, implying that this architecture
    decreases the occurence of negative transfer. Liu et al. [[2019](#bib.bib93)]
    proposes task-specific attention modules. Each attention module takes as input
    the features from some intermediate layer of the shared network concatenated with
    the output of the previous attention module, if one exists. Each module computes
    an attention map by passing its input through a Conv-BN-ReLU layer followed by
    a Conv-BN-Sigmoid layer. The attention map is then element-wise multiplied with
    features from a successive shared layer, and this product is the output of the
    attention module. This attention module allows the network to emphasize features
    in the network which are more important for the corresponding task, and downplay
    the effect of unimportant features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multi-gate Mixture-of-Experts Ma et al. [[2018](#bib.bib105)] is a recently
    proposed shared trunk model, with a twist: the network contains multiple shared
    trunks, and each task-specific output head receives as input a linear combination
    of the outputs of each shared trunk. The weights of the linear combination are
    computed by a separate gating function, which performs a linear transformation
    on the network input to compute the linear combination weights. The gating function
    can either be shared between all tasks, so that each task-specific output head
    receives the same input, or task-specific, so that each output head receives a
    different mixture of the shared trunk outputs. This model bears resemblance to
    Cross-Stitch networks Misra et al. [[2016](#bib.bib113)] (see section [2.1.2](#S2.SS1.SSS2
    "2.1.2 Cross-Talk ‣ 2.1 Architectures for Computer Vision ‣ 2 Multi-Task Architectures
    ‣ Multi-Task Learning with Deep Neural Networks: A Survey")), but performs a single
    linear combination of shared components instead of multiple feature combinations
    from task-specific layers. This method wasn’t empirically evaluated on computer
    vision tasks, but is discussed here due to its close relationship with the other
    CV architectures Zhang et al. [[2014](#bib.bib171)], Misra et al. [[2016](#bib.bib113)].'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.2 Cross-Talk
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Not all MTL architectures for computer vision consist of a shared, global feature
    extractor with task-specific output branches or modules. Misra et al. [[2016](#bib.bib113)],
    Ruder et al. [[2019](#bib.bib130)], Gao et al. [[2019](#bib.bib53)] take a separate
    approach. Instead of a single shared extractor, these architectures have a separate
    network for each task, with information flow between parallel layers in the task
    networks, referred to as cross-talk. Figure [3](#S2.F3 "Figure 3 ‣ 2.1.2 Cross-Talk
    ‣ 2.1 Architectures for Computer Vision ‣ 2 Multi-Task Architectures ‣ Multi-Task
    Learning with Deep Neural Networks: A Survey") depicts this idea with the Cross-Stitch
    network architecture from Misra et al. [[2016](#bib.bib113)].'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c49d18e058f50a5e133eef8c771ad3ec.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Cross-Stitch network architecture Misra et al. [[2016](#bib.bib113)].
    Each task has a separate network, but cross-stitch units combine information from
    parallel layers of the different task networks with a linear combination.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A Cross-Stitch network is composed of individual networks for each task, but
    the input to each layer is a linear combination of the outputs of the previous
    layer from every task network. The weights of each linear combination are learned
    and task-specific, so that each layer can choose which tasks to leverage information
    from. Ruder et al. [[2019](#bib.bib130)] generalizes this idea with the introduction
    of the Sluice network. In the Sluice network, each layer is divided into task-specific
    and shared subspaces, and the input to each layer is a linear combination of the
    task-specific and shared outputs of the previous layer from each task network.
    This way, each layer can choose whether to focus on task specific or shared features
    from previous layers. The task-specific and shared subspaces of each layer are
    also encouraged to be orthogal, by adding an auxiliary term to the loss function
    to minimize the squared Frobenius norm of the product of each task-specific subspace
    with its corresponding shared subspace. It should be noted that Sluice networks
    are presented in a domain-agnostic way, but we discuss them here due to their
    relation to Cross-Stitch networks. Finally, Gao et al. [[2019](#bib.bib53)] generalizes
    the feature fusion operation at parallel layers with Neural Discriminative Dimensionality
    Reduction (NDDR-CNN). Instead of using a linear combination to combine features
    from parallel layers of the task networks, NDDR-CNN concatenates the outputs from
    each layer and pass the result through a 1x1 convolution. The parameters of this
    convolution are task specific, as are the linear combination weights in Cross-Stitch
    networks. A diagram is shown in figure [4](#S2.F4 "Figure 4 ‣ 2.1.2 Cross-Talk
    ‣ 2.1 Architectures for Computer Vision ‣ 2 Multi-Task Architectures ‣ Multi-Task
    Learning with Deep Neural Networks: A Survey"). Note that this method for feature
    fusion is a generalization of Cross-Stitch networks. The 1x1 convolutional parameters
    can be learned in such a way to mimic a Cross-Stitch network, but most parameter
    combinations lead to feature fusion operations which can’t be implemented with
    a Cross-Stitch network.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/68e3c609f3aa3e61fc2a997f8158f208.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: NDDR-CNN network architecture Gao et al. [[2019](#bib.bib53)]. Instead
    of combining information from different task networks with a linear combination
    of parallel features (as in Cross-Stitch networks Misra et al. [[2016](#bib.bib113)]),
    NDDR-CNN uses concatenation and a 1x1 convolution to fuse features from separate
    task networks.'
  prefs: []
  type: TYPE_NORMAL
- en: Yang and Hospedales [[2016a](#bib.bib161)] proposes an architecture which is
    related to the cross-talk template, though perhaps only tangentially. In the Sluice
    network, task-specific and shared parameter tensors from each layer are simply
    concatenated to form the layer’s parameters. The architecture of Yang and Hospedales
    [[2016a](#bib.bib161)] also creates an explicit separation between task-specific
    and shared parameters, but does so using tensor factorization, a well-known approach
    in the classical MTL literature Evgeniou and Pontil [[2004](#bib.bib50)], Argyriou
    et al. [[2008](#bib.bib10)], Kumar and Daume III [[2012](#bib.bib79)]. Tensor
    factorization is used in MTL to represent a multi-task model’s parameter tensor
    as a product of two smaller tensors, one shared between tasks and one task-specific,
    which enforces a different type of division of shared/task-specific feature spaces
    than, for example, Sluice networks. Yang and Hospedales [[2016a](#bib.bib161)]
    extends this approach to the deep learning setting in order to learn the sharing
    structure at each layer within a deep network. Unfortunately, there is no empirical
    comparison of this tensor factorization approach with the other cross-talk architectures,
    and there hasn’t been much work extending the tensor factorization approach of
    Yang and Hospedales [[2016a](#bib.bib161)] for deep MTL.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.3 Prediction Distillation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A major tenant and popular justification of MTL is that learned features from
    one task may be useful in performing another related task. Prediction distillation
    techniques are based on a natural extension of this principle: that the answers
    to one task may help learning of another. Vandenhende et al. [[2020](#bib.bib152)]
    provides a great motivating example of this phenomenon: In an MTL setup for jointly
    learning depth prediction and semantic segmentation, discontinuities in the depth
    map imply likely discontinuities in semantic segmentation labels, and vice versa.
    PAD-Net Xu et al. [[2018a](#bib.bib158)], Pattern-Affinitive Propagation Zhang
    et al. [[2019](#bib.bib172)], and MTI-Net Vandenhende et al. [[2020](#bib.bib152)]
    each take advantage of this phenomenon for the multi-task learning of computer
    vision tasks by making preliminary predictions for each task, then combining these
    predictions to produced final, refined outputs.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/665d75cbe7f25786a62660b8f995918b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: PAD-Net architecture for prediction distillation Xu et al. [[2018a](#bib.bib158)].
    Preliminary predictions are made for four tasks, then these predictions are re-combined
    and used to compute final, refined predictions for two output tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: 'PAD-Net Xu et al. [[2018a](#bib.bib158)] is the earliest of these works, introducing
    an architecture to combine preliminary predictions for depth prediction, scene
    parsing, surface normal estimation, and contour prediction to produce refined
    predictions for depth prediction and scene parsing, as pictured in figure [5](#S2.F5
    "Figure 5 ‣ 2.1.3 Prediction Distillation ‣ 2.1 Architectures for Computer Vision
    ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey"). The preliminary predictions are recombined using one of three novel
    variations of a multi-modal distillation module, either using naive feature concatenation,
    message passing, or attention-guided message passing. Pattern-Affinitive Propagation
    (PAP) Zhang et al. [[2019](#bib.bib172)] expands on this architecture by introducing
    an affinity learning layer which learns to represent pair-wise relationships of
    tasks and combines features from various tasks according to these relationships.
    PAP also does away with the extra auxiliary tasks of PAD-Net and instead produces
    both preliminary and final predictions for depth prediction, surface normal estimation,
    and semantic segmentation. Both of these methods, at the times of their publication,
    reached state of the art performance on at least one task from the NYU-v2 dataset
    Silberman et al. [[2012](#bib.bib137)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'This style of architecture is further extended by the recently proposed MTI-Net
    Vandenhende et al. [[2020](#bib.bib152)], which models task interactions at multiple
    scales of the receptive field. Specifically, the architecture consists of a backbone
    that extracts multi-scale features, and features from each scale are used to make
    preliminary task predictions. The initial predictions from the 1/32 scale are
    combined with 1/16 scale features to form the input for predictions at the 1/16
    scale, then the predictions from the 1/16 scale are used as input to make predictions
    at the 1/8 scale, etc. After predictions are made from each scale, the predictions
    are distilled between tasks and aggregated across scales to make the final refined
    task predictions. The motivation behind this multi-scale interaction network comes
    from the fact that one task’s features or ground-truth outputs may only be informative
    for learning another task at some (but not all) scales. The authors consider an
    example of adjacent cars: at the local level, when only considering small image
    patches, the depth discontinuity between cars suggests that there should be a
    change in the semantic labels across this discontinuity. At the global level,
    however, one can see that the objects surrounding the depth discontinuity have
    the same semantic label, which contradicts the supposed task interaction at the
    local level. This scenario suggests that multi-scale information should be considered
    when distilling predictions across tasks, and indeed this model does show a larger
    improvement over single-task counterparts than high-performing baselines.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.4 Task Routing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Despite their success, shared trunk and cross-talk architectures are somewhat
    rigid in their parameter sharing scheme. Strezoski et al. [[2019a](#bib.bib143)]
    presents an architecture which is more flexible, allowing for fine-grained parameter
    sharing between tasks that occurs at the feature level instead of the layer level.
    The novel component of this architecture is the Task Routing Layer which applies
    a task-specific binary mask to the output of a convolutional layer to which it
    is applied, zeroing out a subset of the computed features and effectively assigning
    a subnetwork to each task which overlaps with that of other tasks. The binary
    masks are not learned, instead they are randomly initialized at the beginning
    of training and fixed from that point on. Although this random initialization
    doesn’t allow for the possibility of a principled parameter sharing scheme between
    tasks, the user still has control over the degree of sharing between tasks through
    the use of a hyperparameter $\sigma$, known as the sharing ratio. $\sigma$ takes
    values between 0 and 1, specifying the proportion of units in each layer which
    are task-specific, and the random initialization of the binary masks in each layer
    are executed in a way to fit this constraint. The proposed architecture only requires
    a small increase in the number of parameters as the number of tasks increases,
    and experiments demonstrate superior performance over MTL baselines such as the
    Cross-Stitch network. Impressively, the Task Routing Layer allows for the network
    to scale up to handle up to 312 tasks simultaneously while maintaining decent
    performance. The Task Routing Layer is strongly related to the learned architectures
    Piggyback Mallya et al. [[2018](#bib.bib106)] and Sparse Sharing Architectures
    Sun et al. [[2019a](#bib.bib146)] (discussed in section [2.5.4](#S2.SS5.SSS4 "2.5.4
    Fine-Grained Sharing ‣ 2.5 Learned Architectures ‣ 2 Multi-Task Architectures
    ‣ Multi-Task Learning with Deep Neural Networks: A Survey")), though in these
    works the binary masks which assign a set of units to each task are learned.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.5 Single Tasking
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Nearly every multi-task architecture for computer vision produces output for
    multiple tasks from the same given input, and each one we have discussed so far
    satisfies this condition. Maninis et al. [[2019](#bib.bib107)] is, to our knowledge,
    the only such method which handles a single task at once, but can be used for
    multiple tasks with multiple forward passes. The authors argue that, since the
    network only performs inference for a single task at a time, the network is better
    able to leverage task-specific information and disregard information useful for
    other tasks. This focusing is accomplished through the use of two different attention
    mechanisms: task-specific data-dependent modulation Perez et al. [[2018](#bib.bib121)]
    and task-specific Residual Adapter blocks Rebuffi et al. [[2018](#bib.bib126)].
    The network is also trained with an adversarial loss Liu et al. [[2017](#bib.bib92)]
    to encourage the gradients from each task to be indistinguishable. The idea of
    using an adversarial setup to encourage similar gradient directions between tasks
    has also been explored outside of the realm of computer vision, and is discussed
    further in section [3.4.1](#S3.SS4.SSS1 "3.4.1 Adversarial Gradient Modulation
    ‣ 3.4 Gradient Modulation ‣ 3 Optimization for Multi-Task Learning ‣ Multi-Task
    Learning with Deep Neural Networks: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Architectures for Natural Language Processing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Natural language processing naturally lends itself well to MTL, due to the abundance
    of related questions one can ask about a given piece of text and the task-agnostic
    representations which are so often used in modern NLP techniques. The development
    in neural architectures for NLP has gone through phases in recent years, with
    traditional feed-forward architectures evolving into recurrent models, and recurrent
    models being succeeded by attention based architectures. These phases are reflected
    in the application of these NLP architectures for MTL.
  prefs: []
  type: TYPE_NORMAL
- en: It should also be noted that many NLP techniques could be considered as multi-task
    in that they construct general representations which are task-agnostic (such as
    word embeddings), and under this interpretation a discussion of multi-task NLP
    would include a large number of methods which are better known as general NLP
    techniques. Here, for the sake of practicality, we restrict our discussion to
    mostly include techniques which explicitly learn multiple tasks simultaneously
    for the end goal of performing these tasks simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.1 Traditional Feed-Forward
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Collobert and Weston [[2008](#bib.bib33)], Collobert et al. [[2011](#bib.bib34)],
    Liu et al. [[2015a](#bib.bib95)] all use traditional feed-forward (non-attention
    based) architectures for multi-task NLP. Many of these architectures have a structural
    resemblance to the early shared architectures of computer vision: a shared, global
    feature extractor followed by task-specific output branches. In this case, however,
    the features are word representations. Collobert and Weston [[2008](#bib.bib33)]
    uses a shared lookup table layer to learn word representations, where the parameters
    of each word vector are directly learned through gradient descent. The remainder
    of the architecture is task-specific, and comprised of convolutions, max over
    time, fully connected layers, and a softmax output. The seminal work Collobert
    et al. [[2011](#bib.bib34)] is motivated by the general principles of MTL: representations
    which are shared across tasks generalize better, and sharing can improve performance
    on all tasks. Their architecture is similar to that of Collobert and Weston [[2008](#bib.bib33)],
    with lookup tables followed by sequences of convolutions and linear transformations.
    The main architectural difference is that the first hidden layer (whether it be
    linear or convolutional) following the lookup tables is shared between tasks.
    Following this trend, the architecture of Liu et al. [[2015a](#bib.bib95)] has
    a similar degree of sharing, and is pictured in figure [6](#S2.F6 "Figure 6 ‣
    2.2.1 Traditional Feed-Forward ‣ 2.2 Architectures for Natural Language Processing
    ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey"). In this case word vectors aren’t learned directly. Instead, the input
    sentence or document is converted into a bag-of-words representation, and hashed
    into letter 3-grams. These features are then fed into a shared linear projection
    followed by a tanh activation function, and then fed to task specific output branches.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dd53620c9492dbf46725485c7d40eecf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Network architecture of Liu et al. [[2015a](#bib.bib95)]. The input
    is converted to a bag-of-words representation and hashed into letter 3-grams,
    followed by a shared linear transformation and nonlinear activation function.
    This shared representation is passed to task-specific outhead heads to compute
    final outputs for each task.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.2 Recurrence
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The introduction of modern recurrent neural networks for NLP yielded a new family
    of models for multi-task NLP, with novel recurrent architectures introduced in
    Luong et al. [[2015](#bib.bib104)], Liu et al. [[2016a](#bib.bib90), [b](#bib.bib91)],
    Dong et al. [[2015](#bib.bib43)]. Sequence to sequence learning Sutskever et al.
    [[2014](#bib.bib148)] was adapted for multi-task learning in Luong et al. [[2015](#bib.bib104)].
    In this work, the authors explore three variants of parameter sharing schemes
    for multi-task seq2seq models, which they name one-to-many, many-to-one, and many-to-many.
    In one-to-many, the encoder is shared through all tasks, and the decoder is task-specific.
    This is useful to handle sets of tasks which require differently formatted output,
    such as translating a piece of text into multiple target languages. In many-to-one,
    the encoder is task-specific, while the decoder is shared. This is an inversion
    of the usual parameter sharing scheme in which earlier layers are shared and feed
    into task-specific branches. The many-to-one variant is applicable when the set
    of tasks require output in the same format, such as in image captioning and machine
    translation into the same target language. Lastly, the authors explore the many-to-many
    variant, in which there are multiple shared or task-specific encoders and decoders.
    They use this variant, for example, to jointly train an english to german and
    a german to english translation system, with both an english and german encoder
    and decoder. The english encoder also feeds into the english decoder to perform
    an autoencoder reconstruction task, as does the german encoder. A similar sequence
    to sequence architecture for machine translation is proposed in Dong et al. [[2015](#bib.bib43)]
    with a focus on training a multi-task network to translate one source language
    into multiple target languages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Liu et al. [[2016a](#bib.bib90)] also explores several variants of recurrent
    multi-task architectures, though in the text classification regime instead of
    sequence to sequence learning. These parameter sharing schemes are generally more
    fine-grained than those described in Luong et al. [[2015](#bib.bib104)], with
    a focus on different methods to allow information flow betwen tasks. The authors
    explore three parameter sharing schemes: the Uniform-Layer, Coupled-Layer, and
    Shared-Layer architectures, which are shown in figure [7](#S2.F7 "Figure 7 ‣ 2.2.2
    Recurrence ‣ 2.2 Architectures for Natural Language Processing ‣ 2 Multi-Task
    Architectures ‣ Multi-Task Learning with Deep Neural Networks: A Survey"). In
    the Uniform-Layer architecture, each task has its own embedding layer, and all
    tasks share an embedding layer and an LSTM layer. Let $i$ be a task index, $t$
    be the recurrent timestep, and $x_{t}$ be the $t$-th word in an input sentence.
    Then the input to the shared LSTM layer for task $i$ on timestep $t$ is the concatenation
    of the $i$-th task specific embedding of $x_{t}$ with the shared embedding of
    $x_{t}$. For the Coupled-Layer model, each task has its own separate LSTM layer,
    but each task can read from the LSTM layers of the other tasks. More specifically,
    the memory content of the LSTM for a given task at timestep $t$ is modified to
    include a weighted sum of the hidden states of the LSTM layers of each task at
    timestep $t-1$, while preserving all other components of the LSTM. Finally, the
    Shared-Layer architecture allocates a separate LSTM layer for each task, as well
    as a shared bi-directional LSTM layer that feeds into the task-specific LSTMs.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8d24b7bbe0d2fd3681af4acaf306200c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: From top to bottom: Uniform-Layer, Coupled-Layer, and Shared-Layer
    architectures of Liu et al. [[2016a](#bib.bib90)]. Each architecture presents
    a novel partition of recurrent architecture components into shared and task-specific
    modules.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to these recurrent architectures, Liu et al. [[2016b](#bib.bib91)]
    augments the LSTM architecture with a memory mechanism. To form a shared architecture,
    each task has its own LSTM parameters, but the memory is shared among all tasks.
    The memory mechanism is inspired by the memory enhanced LSTM (ME-LSTM) Sukhbaatar
    et al. [[2015](#bib.bib145)]. The novel contribution of Liu et al. [[2016b](#bib.bib91)]
    is in a fusion mechanism that allows the memory to be read from and written to
    jointly by all tasks. With this addition, the hidden state of each task’s LSTM
    is computed from a gated sum of the LSTM’s internal memory and the information
    held in the shared external memory. The authors also introduce a variant in which
    each task has its own private external memory, and the shared global external
    memory is read/written by each task-specific memory module.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.3 Cascaded Information
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In all of the NLP architectures we have discussed so far, the sub-architectures
    corresponding to each task have been symmetric. In particular, the output branch
    of each task occurs at the maximum network depth for each task, meaning that supervision
    for the task-specific features of each task occurs at the same depth. Several
    works Søgaard and Goldberg [[2016](#bib.bib139)], Hashimoto et al. [[2016](#bib.bib59)],
    Sanh et al. [[2019](#bib.bib132)] propose supervising “lower-level" tasks at earlier
    layers so that the features learned for these tasks may be used by higher-level
    tasks. By doing this we form an explicit task hierarchy, and provide a direct
    way for information from one task to aid in the solution of another. We refer
    to this template for iterated inference and feature combination as cascaded information,
    with an example pictured in figure [8](#S2.F8 "Figure 8 ‣ 2.2.3 Cascaded Information
    ‣ 2.2 Architectures for Natural Language Processing ‣ 2 Multi-Task Architectures
    ‣ Multi-Task Learning with Deep Neural Networks: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Søgaard and Goldberg [[2016](#bib.bib139)] forms this hierarchy by choosing
    POS tagging as a low-level task to inform syntactic chunking and CCG supertagging.
    Their network architecture is made of a series of bi-directional RNN layers, and
    for each task $i$ there is an associated layer $\ell_{i}$ from which the task-specific
    classifier for task $i$ stems. In this case, the associated layer for POS tagging
    occurs earlier in the network than the associated layers of syntactic chunking
    and CCG supertagging, so that the learned POS features can inform the tasks of
    syntactic chunking and CCG supertagging. Not long after the publication of Søgaard
    and Goldberg [[2016](#bib.bib139)], Hashimoto et al. [[2016](#bib.bib59)] achieved
    a mix of SOTA and SOTA-competitive results on several language tasks by constructing
    a similarly supervised architecture with 5 tasks: POS tagging, chunking, dependency
    parsing, semantic relatedness, and textual entailment. The authors also replace
    the bi-directional RNN units of Søgaard and Goldberg [[2016](#bib.bib139)] with
    bi-directional LSTM units. Figure [8](#S2.F8 "Figure 8 ‣ 2.2.3 Cascaded Information
    ‣ 2.2 Architectures for Natural Language Processing ‣ 2 Multi-Task Architectures
    ‣ Multi-Task Learning with Deep Neural Networks: A Survey") shows their architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9dfaf2da26bc93ea28a08377d3d378c1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Various task supervision in various layers from Hashimoto et al.
    [[2016](#bib.bib59)]. Lower level tasks are supervised at earlier layers.'
  prefs: []
  type: TYPE_NORMAL
- en: Besides the increase in the number of tasks, this method also introduces a regularization
    term to avoid training interference between the tasks. Each time a task’s dataset
    is sampled for training, the squared Euclidean distance between the pre-update
    parameters and the current model parameters is added to the loss function. This
    encourages the network parameters not to stray too far from the parameter configuration
    which was learned by training on a different task on the previous epoch.
  prefs: []
  type: TYPE_NORMAL
- en: Following these two works, Sanh et al. [[2019](#bib.bib132)] introduces a similarly
    inspired model for a different set of tasks, achieving SOTA results for Named
    Entity Recognition, Entity Mention Detection and Relation Extraction. In order
    from lowest to highest, the task hierarchy in this work is NER, EMD, and coreference
    resolution/relation extraction (equally ranked as highest level).
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.4 Adversarial Feature Separation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In a novel application of adversarial methods, Liu et al. [[2017](#bib.bib92)]
    introduces an adversarial learning framework for multi-task learning in order
    to distill learned features into task-specific and task-agnostic subspaces. Their
    architecture is comprised of a single shared LSTM layer and one task-specific
    LSTM layer per task. Once the input sentence from a task is passed through the
    shared LSTM layer and the task-specific LSTM layer, the two outputs are concatenated
    and used as the final features to perform inference on. However, the features
    produced by the shared LSTM layer are also fed into the task discriminator. The
    task discriminator is a linear transformation followed by a softmax layer that
    is trained to predict which task the original input sentence came from. The shared
    LSTM layer is then trained to jointly minimize the task loss along with the discriminator
    loss, so that the features produced by the shared LSTM do not contain any task-specific
    information. In addition, the shared features and the task specific features are
    encouraged to encode separate information with the use of an orthogonality penalty
    (similar to Ruder et al. [[2019](#bib.bib130)]) on the resulting features. More
    specifically, the orthogonality loss is defined as the squared Frobenius norm
    of the product of the task-specific features and the shared features. This loss
    is added to the overall training objective, in order to encourage the task-specific
    and the shared features to be orthogonal. These two auxiliary losses enforce the
    separation of task-specific and task-agnostic information in the shared network.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.5 BERT for MTL
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Despite the popularity of the Bidirectional Encoder Representations from Transformers
    (BERT) Devlin et al. [[2018](#bib.bib41)], there have been surprisingly little
    applications of the text encoding method for MTL. Liu et al. [[2019b](#bib.bib96)]
    extends the work of Liu et al. [[2015a](#bib.bib95)] by adding shared BERT embedding
    layers into the architecture. The network architecture overall is quite similar
    to Liu et al. [[2019b](#bib.bib96)], the only difference being the addition of
    BERT contextual embedding layers following the input embedding vectors in figure
    [6](#S2.F6 "Figure 6 ‣ 2.2.1 Traditional Feed-Forward ‣ 2.2 Architectures for
    Natural Language Processing ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning
    with Deep Neural Networks: A Survey"). This new MTL architecture, named MT-DNN,
    achieved SOTA performance on eight out of nine GLUE tasks Wang et al. [[2018](#bib.bib153)]
    at the time of its publication.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Architectures for Reinforcement Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In recent years, many of the advances in reinforcement learning have focused
    on optimization and training methods Schulman et al. [[2017](#bib.bib133)], Haarnoja
    et al. [[2018](#bib.bib58)], Akkaya et al. [[2019](#bib.bib4)]. Since many RL
    problems don’t necessarily involve complex perception, such as working with words
    or pixels, the architectural demand isn’t as high for many RL problems. Because
    of this, many deep networks for RL are simple fully-connected, convolutional,
    or recurrent architectures. However, in the multi-task case, there are several
    instances of interesting works which leverage information between tasks to create
    improved architectures for RL.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.1 Joint Task Training
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Several works in RL have found that task performance can be improved by simply
    training for multiple tasks jointly, with or without parameter sharing. Pinto
    and Gupta [[2017](#bib.bib122)] uses a shared trunk architecture (shown in figure
    [9](#S2.F9 "Figure 9 ‣ 2.3.1 Joint Task Training ‣ 2.3 Architectures for Reinforcement
    Learning ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey") to jointly learn robotic grasping, pushing, and poking from pixels.
    The shared feature extractor consists of three convolutional layers, and these
    shared features are fed to three task-specific output branches. The grasping and
    poking output branches are made of three fully-connected layers each, and the
    pushing branch has one convolutional layer, followed by two fully-connected layers.
    This shared network is trained with a supervised loss which is an average of cross-entropy
    and squared Euclidean losses, one for each task. The network actions are parameterized
    in such a way to allow for supervised training. The authors find that this shared
    network trained with 2500 examples of both pushing and grasping outperforms a
    task-specific grasping network trained with 5000 examples. Zeng et al. [[2018](#bib.bib167)]
    also finds advantages by jointly training with robotic pushing and grasping, though
    their architecture does not employ any parameter sharing. The network is comprised
    of two separate fully convolutional Q-networks, one for pushing and one for grasping.
    The two networks are, however, given a joint training signal. The reward for a
    timestep $t$ is defined as follows: if a grasping action is chosen at timestep
    $t$ and the grasp is successful, the reward is 1\. If a pushing action is chosen
    at timestep $t$ and the action causes a sufficiently large change in the environment,
    then the reward is 0.5\. From this reward, there is no explicit encouragement
    of one task to aid another. But when both networks are jointly trained to maximize
    the same reward, the pushing network learns to push in a way that influences the
    environment to maximize the grasping reward. This joint training setup was shown
    to be much more sample efficient than baselines, making training on a physical
    robot feasible with only a few hours of training.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c5ddc5ea7eb69968f8bf48451c27ddc4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Shared architecture for robotic grasping, pushing, and poking Pinto
    and Gupta [[2017](#bib.bib122)].'
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.2 Modular Policies
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There have been many similarities between the various parameter sharing schemes
    that we have discussed so far, but modular networks are present a novel family
    of parameter sharing methods which are totally different from the shared trunk
    or cross-talk architectures from sections [2.1.1](#S2.SS1.SSS1 "2.1.1 Shared Trunk
    ‣ 2.1 Architectures for Computer Vision ‣ 2 Multi-Task Architectures ‣ Multi-Task
    Learning with Deep Neural Networks: A Survey") and [2.1.2](#S2.SS1.SSS2 "2.1.2
    Cross-Talk ‣ 2.1 Architectures for Computer Vision ‣ 2 Multi-Task Architectures
    ‣ Multi-Task Learning with Deep Neural Networks: A Survey"). In modular learning
    setups, each task’s network architecture is composed of a combination of smaller
    sub-networks, and these smaller sub-networks are combined in different ways for
    different tasks. Just as MTL is motivated by generality through shared representations,
    modular learning offers generality of computation through shared neural building
    blocks. The goal of these setups is to learn building blocks which are general
    enough to be useful as a part of the network architecture for multiple tasks.
    We discuss several other learned modular architectures in sections [2.5](#S2.SS5
    "2.5 Learned Architectures ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning
    with Deep Neural Networks: A Survey") and [2.6](#S2.SS6 "2.6 Conditional Architectures
    ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey"), but here we only discuss those modular methods for which the parameters
    of the building blocks are learned and the configuration of building blocks for
    each task remains fixed. Discussion of modular methods with learned building block
    combinations can be found in the aforementioned sections.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Within weeks of each other, Heess et al. [[2016](#bib.bib61)] and Devin et al.
    [[2017](#bib.bib40)] both introduced modular neural network policies for multi-task
    learning across various robots. The architectures of each of these works are depicted
    in figures [10](#S2.F10 "Figure 10 ‣ 2.3.2 Modular Policies ‣ 2.3 Architectures
    for Reinforcement Learning ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning
    with Deep Neural Networks: A Survey") and [11](#S2.F11 "Figure 11 ‣ 2.3.2 Modular
    Policies ‣ 2.3 Architectures for Reinforcement Learning ‣ 2 Multi-Task Architectures
    ‣ Multi-Task Learning with Deep Neural Networks: A Survey"), respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5f0fcd56211269c55366808c7edd719d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Shared modular architecture for locomotion with multiple robots
    Heess et al. [[2016](#bib.bib61)]. Note that the high-level module updates the
    modulated input to the low-level module at a different frequency than it itself
    receives input from the environment.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/082f6230ad6f2645582a0a748afddd50.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Shared modular architecture for multi-task and multi-robot transfer
    Devin et al. [[2017](#bib.bib40)]. Each network is made of two modules, one robot
    module and one task module. Each robot module can be combined with a task module
    to form a network to perform each (task, robot) pair.'
  prefs: []
  type: TYPE_NORMAL
- en: The task architecture of Heess et al. [[2016](#bib.bib61)] is made of two modules,
    a low-level “spinal" network and a high-level “cortical" network. The spinal network
    has access to proprioceptive information like muscle tension, and it chooses motor
    actions, while the cortical network has access to all observations and modulates
    inputs to the spinal network. It is important to note that the proprioceptive
    information given to the spinal network is always task-independent, so that the
    spinal network must learn task-independent representations. In their experiments,
    the low-level/spinal network is feed-forward, while the high-level/cortical network
    is recurrent. The combination of the division of labor between the two modules
    and the information hiding from the spinal network allows for a pre-trained spinal
    network to be deployed with a new cortical network to quickly solve a new task
    with the same robot body. The usage of the pre-trained spinal network allows for
    effective exploration in the robot body, despite the new task.
  prefs: []
  type: TYPE_NORMAL
- en: 'The architecture of Devin et al. [[2017](#bib.bib40)] is similarly inspired,
    but employs parameter sharing for the network controllers between different robots
    as well as between tasks. Each task and robot has its own network module. The
    network for each task/robot pair is composed of the corresponding task-specific
    module, followed by the corresponding robot-specific module, as shown in figure
    [11](#S2.F11 "Figure 11 ‣ 2.3.2 Modular Policies ‣ 2.3 Architectures for Reinforcement
    Learning ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey") Because each module is shared between tasks and robots, it is constrained
    to learn information which is general across its domains. The authors also show
    that the learned modules can be paired in combinations unseen during training,
    to instantiate a policy with zero-shot generalization capabilities. This method
    also gives partial information to the task module; each observation is decomposed
    into a task-specific portion and a robot-specific portion. The task-specific module
    only receives the task-specific observation as input, and the robot-specific module
    receives the robot-specific observation as well as the output of the task-specific
    module.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Both of these architectures exhibit an interesting strategy for learning general
    representations across tasks: information hiding. We have so far discussed parameter
    sharing, adversarial methods, and orthogonality constraints as regularization
    strategies for multi-task methods. But the division of labor brought forth by
    the modularity in these two architectures allows for information to be restricted
    to certain modules in the network, forcing the modules missing this information
    to learn representations which are invariant to the omitted information. In this
    case, we obtain modules which are invariant to the task at hand.'
  prefs: []
  type: TYPE_NORMAL
- en: 'RL with Policy Sketches Andreas et al. [[2017](#bib.bib8)] is another template
    for policy modularity which was proposed soon after Heess et al. [[2016](#bib.bib61)]
    and Devin et al. [[2017](#bib.bib40)], in which the policy for a task is composed
    of several subpolicies, and each subpolicy is a neural network whose parameters
    are shared between tasks. The composition of subpolicies for each task is defined
    by a human-provided “policy sketch", which roughly outlines the steps to complete
    a task. For example, in the minecraft-inspired environment used for evaluation
    in the paper, the tasks “Make Planks" and “Make Sticks" may have the policy sketches
    (get wood, use workbench) and (get wood, use toolshed), respectively. In this
    case, the policies for these tasks would use the subpolicies $\pi_{\text{wood}}$,
    $\pi_{\text{bench}}$, and $\pi_{\text{shed}}$, with the compositions $\pi_{\text{planks}}=(\pi_{\text{wood}},\pi_{\text{bench}})$
    and $\pi_{\text{sticks}}=(\pi_{\text{wood}},\pi_{\text{shed}})$. The weak supervision
    provided by the policy sketches defines a sharing structure of subpolicies between
    tasks, which was shown to be more beneficial to learning than unsupervised option
    discovery. This process is similar to how the syntactical strcture of a question
    defines the composition of subpolicies in Neural Module Networks Andreas et al.
    [[2016](#bib.bib7)] (discussed in section [2.6](#S2.SS6 "2.6 Conditional Architectures
    ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey")), though in that example the composed architecture is dependent on
    each individual given question, while the composition of subpolicies remains fixed
    for each task with Policy Sketches. It is important to note that module composition
    takes two different forms with Policy Sketches and the architectures of Heess
    et al. [[2016](#bib.bib61)] and Devin et al. [[2017](#bib.bib40)]: subpolicies
    in Policy Sketches behave as in hierarchical reinforcement learning Kulkarni et al.
    [[2016](#bib.bib78)], where a subpolicy is chosen to act as the policy until some
    termination condition is met, as opposed to composition in the sense of function
    composition as in Heess et al. [[2016](#bib.bib61)] and Devin et al. [[2017](#bib.bib40)].'
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.3 Multiple Auxiliary Tasks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Jaderberg et al. [[2016](#bib.bib67)] introduces several unsupervised auxiliary
    tasks to be learned in conjuction with a main task, as an additional form of supervision.
    These auxiliary tasks encourage general representations in the usual sense for
    MTL, but they also help to decrease the sparsity of rewards in the original task.
    The architecture is a CNN-LSTM actor-critic with a shared trunk, and output branches
    for each auxiliary task that requires its own output. The auxiliary tasks themselves
    are called pixel control, feature control, and reward prediction. Pixel control
    shares parameters from the agent CNN and LSTM, and branches off into a task-specific
    branch that chooses its own actions. The actions are rewarded for causing maximal
    change in the pixel intesity of the pixels observed as a result of the chosen
    action. Feature control does not require an output, and instead the agent is rewarded
    for activating the hidden units of a given hidden layer of the agent network.
    Lastly, reward prediction uses the agent’s CNN to map three recent frames to a
    prediction of the reward on the next step. These auxiliary tasks do not require
    any supervision that isn’t provided by the environment dynamics and are general
    enough to apply to many different problem settings. Training an agent with these
    simple auxiliary tasks led to SOTA performance on the Arcade Learning Environment
    Bellemare et al. [[2013](#bib.bib14)].
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Multi-Modal Architectures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In sections [2.1](#S2.SS1 "2.1 Architectures for Computer Vision ‣ 2 Multi-Task
    Architectures ‣ Multi-Task Learning with Deep Neural Networks: A Survey"), [2.2](#S2.SS2
    "2.2 Architectures for Natural Language Processing ‣ 2 Multi-Task Architectures
    ‣ Multi-Task Learning with Deep Neural Networks: A Survey"), and [2.3](#S2.SS3
    "2.3 Architectures for Reinforcement Learning ‣ 2 Multi-Task Architectures ‣ Multi-Task
    Learning with Deep Neural Networks: A Survey"), we discussed the multi-task architectures
    which were specifically designed to handle data in one fixed domain. Here, we
    describe architectures to handle multiple tasks using data from multiple domains,
    which is usually some combination of visual and linguistic data. Multi-modal learning
    is an interesting extension of many of the motivating principles behind multi-task
    learning: sharing representations across domains decreases overfitting and increases
    data efficiency. In the multi-task single modality case, the representations are
    shared across tasks but within in a single modality. However, in the multi-task
    multi-modal case, representations are shared across tasks and across modes, providing
    another layer of abstraction through which the learned representations must generalize.
    This suggests that multi-task multi-modal learning may yield an increase in the
    benefits already exhibited by multi-task learning.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Nguyen and Okatani [[2019](#bib.bib117)] introduces an architecture for shared
    vision and language tasks by using dense co-attention layers Nguyen and Okatani
    [[2018](#bib.bib116)], in which tasks are organized into a hierarchy and low-level
    tasks are supervised at earlier layers in the network. Dense co-attention layers
    were developed for visual question answering, specifically for the integration
    of visual and linguistic information. This setup of task supervision is similar
    to the cascaded information architectures discussed in section [2.2.3](#S2.SS2.SSS3
    "2.2.3 Cascaded Information ‣ 2.2 Architectures for Natural Language Processing
    ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey"). However, instead of hand-designing a hierarchy of tasks, this method
    performs a search over the layers for each task in order to learn the task hierarchy.
    The architecture of Akhtar et al. [[2019](#bib.bib3)] handles visual, audio, and
    text input to classify emotion and sentiment in a video of a human speaker, using
    bi-directional GRU layers along with pairwise attention mechanisms for each pair
    of modes to learn a shared representation incorporating all modes of input.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Both Nguyen and Okatani [[2019](#bib.bib117)], Akhtar et al. [[2019](#bib.bib3)]
    are focused on a set of tasks which all share the same fixed set of modalities.
    Instead, Kaiser et al. [[2017](#bib.bib71)] and Pramanik et al. [[2019](#bib.bib124)]
    focus on building a “universal multi-modal multi-task model", in which a single
    model can handle multiple tasks with varying input domains. The architecture introduced
    in Kaiser et al. [[2017](#bib.bib71)] is comprised of an input encoder, an I/O
    mixer, and an autoregressive decoder. Each of these three blocks is made of a
    mix of convolutions, attention layers, and sparsely-gated mixture-of-experts layers.
    The authors also demonstrate that the large degree of sharing between tasks yields
    significantly increased performance for tasks with limited training data. Instead
    of aggregating mechanisms from various modes of deep learning, Pramanik et al.
    [[2019](#bib.bib124)] introduces an architecture called OmniNet with a spatio-temporal
    cache mechanism to learn dependencies across spatial dimensions of data as well
    as the temporal dimension. A diagram is shown in figure [12](#S2.F12 "Figure 12
    ‣ 2.4 Multi-Modal Architectures ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning
    with Deep Neural Networks: A Survey"). Each input modality has a corresponding
    “peripheral" network, and the outputs of these networks are aggregated and fed
    into the Central Neural Processor, whose output is fed to task-specific output
    heads. The CNP has an encoder-decoder architecture with a spatial cache and a
    temporal cache. OmniNet reached SOTA-competitive performance on POS tagging, image
    captioning, visual question answering, and video activity recognition.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/947207e85bb9673f8d0b01a8161d0964.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: OmniNet architecture proposed in Pramanik et al. [[2019](#bib.bib124)].
    Each modality has a separate network to handle inputs, and the aggregated outputs
    are processed by an encoder-decoder called the Central Neural Processor. The output
    of the CNP is then passed to several task-specific output heads.'
  prefs: []
  type: TYPE_NORMAL
- en: Most recently, Lu et al. [[2020](#bib.bib102)] introduces a multi-task model
    that handles 12 different datasets simultaneously, aptly named 12-in-1\. Their
    model achieves superior performance over the corresponding single-task models
    on 11 out of 12 of these tasks, and using multi-task training as a pre-training
    step leads to SOTA performance on 7 of these tasks. The architecture is based
    on the ViLBERT model Lu et al. [[2020](#bib.bib102)], and is trained using a mix
    of methods such as dynamic task scheduling, curriculum learning, and hyperparameter
    heuristics.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5 Learned Architectures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we have already seen in the preceding sections, there have been many developments
    in the design of shared architectures to emphasize the strengths of multi-task
    learning while mitigating the weaknesses. Another approach to architecture design
    for multi-task learning is to learn the architecture as well as the weights of
    the resulting model. Many of the following methods for learning shared architectures
    allow for the model to learn how parameters should be shared between tasks. With
    a varying parameter sharing scheme, the model can shift the overlap between tasks
    in such a way that similar tasks have a higher degree of sharing than unrelated
    tasks. This is one potential method for mitigating negative transfer between tasks:
    if two tasks exhibit negative transfer, the model may learn to keep the parameters
    for those tasks separate. Going further, it may be the case that two tasks exhibit
    positive transfer in some parts of the network, and negative transfer in others.
    In this case, designing a parameter sharing scheme by hand to accommodate various
    task similarites at different parts of the network becomes infeasible, especially
    as the number of tasks and the size of the network grows. Learned parameter sharing
    offers a way to facilitate adaptive sharing between tasks to a level of precision
    that isn’t realistic for hand designed shared architectures.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We roughly categorize the methods for learned architectures into four groups:
    architecture search, branched sharing, modular sharing, and fine-grained sharing.
    The boundaries between these groups aren’t concrete, and they are often blurred,
    but we believe this is a useful way to broadly characterize the patterns in the
    recently developed methods. Branched sharing methods are a coarse-grained way
    to share parameters between tasks. Once the computation graphs for two tasks differ,
    they never rejoin (see figure [13](#S2.F13 "Figure 13 ‣ 2.5.2 Branched Sharing
    ‣ 2.5 Learned Architectures ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning
    with Deep Neural Networks: A Survey")). Modular sharing represents a more fine-grained
    approach, in which a set of neural network modules is shared between tasks, where
    the architecture for each task is made by a task-specific combination of some
    or all of the modules, as in figure [16](#S2.F16 "Figure 16 ‣ 2.5.3 Modular Sharing
    ‣ 2.5 Learned Architectures ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning
    with Deep Neural Networks: A Survey"). Lastly, the most fine-grained approach
    to parameter sharing is what we simply call fine-grained sharing, in which sharing
    decisions occur at the parameter level instead of the layer level, as shown in
    figure [17](#S2.F17 "Figure 17 ‣ 2.5.4 Fine-Grained Sharing ‣ 2.5 Learned Architectures
    ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.1 Architecture Search
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Each of Wong and Gesmundo [[2017](#bib.bib156)], Liang et al. [[2018](#bib.bib85)],
    Gao et al. [[2020](#bib.bib54)] introduces a method for multi-task architecture
    search, but with completely different approaches. Wong and Gesmundo [[2017](#bib.bib156)]
    introduces the Multi-task Neural Model Search (MNMS) controller. This method doesn’t
    involve a single network which is shared between all tasks. Instead, the MNMS
    controller is trained simultaneously on all tasks to generate one individual architecture
    for each task. The method is an extension of Zoph and Le [[2016](#bib.bib176)],
    where an RNN controller iteratively makes architecture design choices, and is
    trained with reinforcement learning to maximize the expected performance of the
    resulting network. In the multi-task variant, the RNN also uses task embeddings,
    which are learned jointly with the MNMS controller, to condition architectural
    design choices on the nature of the task.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, Liang et al. [[2018](#bib.bib85)] introduces several variations
    of a multi-task neural architecture search algorithm that uses evolutionary strategies
    to learn neural network modules which can be reordered differently for various
    tasks. This method is an extension of the Soft Layer Ordering introduced in Meyerson
    and Miikkulainen [[2017](#bib.bib110)] (discussed in section [2.3.2](#S2.SS3.SSS2
    "2.3.2 Modular Policies ‣ 2.3 Architectures for Reinforcement Learning ‣ 2 Multi-Task
    Architectures ‣ Multi-Task Learning with Deep Neural Networks: A Survey")). Just
    as in Meyerson and Miikkulainen [[2017](#bib.bib110)], the method of Liang et al.
    [[2018](#bib.bib85)] involves learning neural network modules jointly with their
    ordering for various tasks. In the architecture search extension, the architecture
    of the modules is learned along with their routing for individual tasks. The most
    sophisticated variant of this algorithm is called Coevolution of Modules and Task
    Routing (CMTR), in which the CoDeepNEAT algorithm Miikkulainen et al. [[2019](#bib.bib112)]
    is used to evolve the architecture of the shared group modules in an outer loop,
    and the task specific routings of these modules are evolved in an inner loop.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most recently, Gao et al. [[2020](#bib.bib54)] proposes MTL-NAS as a method
    for gradient-based architecture search in MTL. All architectures in this search
    space are made of a set of fixed-architecture single-task backbone networks, one
    for each task, and the search process operates over feature fusion operations
    between different layers of these single-task networks. The feature fusion operations
    are parameterized by NDDR (from NDDR-CNN Gao et al. [[2019](#bib.bib53)], see
    section [2.1.2](#S2.SS1.SSS2 "2.1.2 Cross-Talk ‣ 2.1 Architectures for Computer
    Vision ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey")), which is essentially a $1\times 1$ convolution acting on concatenations
    of feature maps from different tasks. This method also introduces a minimum entropy
    objective on the weights of the fusion operations, so that the search process
    converges to a discrete architecture during the architecture search phase, which
    diminishes the need for a discretization of a soft combination of architectures
    as in other NAS works Liu et al. [[2018](#bib.bib89)] and closes the performance
    gap between learned soft architectures and the final discretized version. The
    final learned architectures were shown to outperform common multi-task baselines
    on the NYU-v2 Silberman et al. [[2012](#bib.bib137)] and Taskonomy Zamir et al.
    [[2018](#bib.bib166)] datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.2 Branched Sharing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Lu et al. [[2017](#bib.bib103)] is one of the earliest methods for learned
    parameter sharing in multi-task deep learning. The idea is to start with a network
    which is shared between all tasks up to task-specific output heads, then iteratively
    decouple parameters between tasks layer by layer, starting with the layer closest
    to the output heads, and moving to the earlier layers. A diagram of this process
    is shown in figure [13](#S2.F13 "Figure 13 ‣ 2.5.2 Branched Sharing ‣ 2.5 Learned
    Architectures ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural
    Networks: A Survey"). When a shared layer splits into multiple task specific layers,
    tasks are clustered based on an estimate of pairwise task affinity. These task
    affinities are computed according to the following principle: two tasks are likely
    related if the same input data is equally easy/difficult for the models corresponding
    to each task.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/87203ba212f7586ae96c6b00846a4af7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Learned branching architecture proposed in Lu et al. [[2017](#bib.bib103)].
    At the beginning of training, each task shares all layers of the network. As training
    goes on, less related tasks branch into clusters, so that only highly related
    tasks share as many parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: 'More recently, Vandenhende et al. [[2019](#bib.bib151)] proposes a similar
    method with a different criterion for task grouping. Instead of concurrent sample
    difficulty, this algorithm uses representation similarity analysis (RSA) Kriegeskorte
    [[2008](#bib.bib76)] as a measure of task affinity. RSA is built on the principle
    that similar tasks will rely on similar features of the input, and will therefore
    learn similar feature representations. The other important difference between
    these methods is that Vandenhende et al. [[2019](#bib.bib151)] computes the branching
    structure globally instead of greedily by layer. However, the search over all
    branching structures is computationally expensive, so the authors resort to a
    beam search strategy for computing the branching structure from the representation
    similarities across tasks in different parts of the network. This paper includes
    a direct comparison of the two methods, and the RSA-based variant is shown to
    be superior. RSA is also used in some methods to learn explicit task relationships,
    which are discussed in section [4](#S4 "4 Task Relationship Learning ‣ Multi-Task
    Learning with Deep Neural Networks: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.3 Modular Sharing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The earliest work on modular parameter sharing in multi-task learning that
    we are aware of is PathNet Fernando et al. [[2017](#bib.bib51)]. A PathNet model
    is one large neural network which is used for multiple tasks, though different
    tasks have different computation pathways within the larger model. A diagram is
    shown in figure [14](#S2.F14 "Figure 14 ‣ 2.5.3 Modular Sharing ‣ 2.5 Learned
    Architectures ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural
    Networks: A Survey"). The pathway for each task is learned through a tournament
    selection genetic algorithm, in which many different candidate pathways compete
    and evolve towards an optimal subnetwork of the larger network. While this idea
    is mostly general and can be applied to various settings, such as multi-task learning
    and meta-learning, the authors deploy this model for continual learning with two
    reinforcement learning tasks. The weights learned during training on the first
    task are fixed during training of the second task, during which new pathways through
    the network are evolved to complete the task at hand.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2d8a0b5971be34a3eb5acd2aecd594c4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: Example PathNet architecture Fernando et al. [[2017](#bib.bib51)].
    A large network is shared by many tasks, but each task only uses a subnetwork
    which is evolved through a tournament selection genetic algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Soft Layer Ordering Meyerson and Miikkulainen [[2017](#bib.bib110)] and Modular
    Meta-Learning Alet et al. [[2018](#bib.bib5)] are two concurrent works of modular
    MTL, similar but with an important difference. Each of these methods learns a
    shared set of neural network modules which are combined in different ways for
    different tasks, with the hope that a network “building block" will learn generally
    applicable knowledge if it is used in various contexts within the different task
    networks. Soft Layer Ordering parameterizes a task network by computing a convex
    combination of each module’s output at each layer of the network, as shown in
    figure [15](#S2.F15 "Figure 15 ‣ 2.5.3 Modular Sharing ‣ 2.5 Learned Architectures
    ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey"). With this parameterization, each learned module can contribute to
    each level of depth in the network. In contrast, Modular Meta-Learning learns
    a computation graph over the modules, meaning that each step of the computation
    is a discrete composition of a small number of modules, instead of a soft combination
    of all of them. The difference in the parameterization of the computation graph
    between these methods leads to different optimization strategies, namely, the
    computation graph in Soft Layer Ordering architectures can be optimized with gradient
    descent jointly with the network weights, since the composition of the modules
    is a differentiable operation. In comparison, the computation graph in Modular
    Meta-Learning is a discrete structure, so gradient-based optimization methods
    cannot be used to learn the graph over modules for each task. Instead, the authors
    employ simulated annealing, a black box optimization method, to learn the computation
    graph. While this two-level optimization incurs computational cost, the discrete
    nature of the computation graph affords the ability to produce an inductive bias
    in the resulting model, which the soft sharing of layers does not exhibit. These
    methods represent two realizations of a broadly generalizable template that many
    other methods have employed: Learn individual network pieces, and learn how to
    combine them.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/95c269f7b4d8e2f2c38b6a74e8d2ab19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: Soft Layer Ordering with three learned layers Meyerson and Miikkulainen
    [[2017](#bib.bib110)]. Each layer of the network is a linear combination of several
    network modules, and the weights of these combinations are task-specific.'
  prefs: []
  type: TYPE_NORMAL
- en: The method of Chen et al. [[2018](#bib.bib28)] is another strategy in this spirit,
    and closely resembles NAS Zoph and Le [[2016](#bib.bib176)]. This paper proposes
    a method that fits the template described above, but the composition of modules
    is not directly parameterized and learned such as in Soft Layer Ordering and Modular
    Meta-Learning. Instead, this method trains an RNN controller to choose a layer
    from a fixed set of layers to iteratively build an architecture as a sequence
    of modules, and the module is again trained with reinforcement learning to maximize
    the expected performance of the constructed architecture. This method bears a
    strong resemblance to the previously discussed Multi-task Neural Model Search
    controller Wong and Gesmundo [[2017](#bib.bib156)], with the main difference being
    that the RNN controller used in Chen et al. [[2018](#bib.bib28)] simply chooses
    between a set of network modules, while the MNMS controller makes architectural
    design decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most recently, AdaShare Sun et al. [[2019b](#bib.bib147)] is an algorithm for
    modular MTL in which each task architecture is comprised of a sequence of network
    layers. Each layer in the shared set is either included or omitted from the network
    for each task. An example is shown in figure [16](#S2.F16 "Figure 16 ‣ 2.5.3 Modular
    Sharing ‣ 2.5 Learned Architectures ‣ 2 Multi-Task Architectures ‣ Multi-Task
    Learning with Deep Neural Networks: A Survey"). Along with the weights of each
    layer, AdaShare learns an $N\times L$ array of binary values, where $N$ is the
    number of tasks, $L$ is the total number of shared layers, and the $(i,\ell)$-th
    element of the binary array denotes whether layer $\ell$ is included in the model
    of the $i$-th task. Since the output of a task’s network is not differentiable
    with respect to these binary values, the method adopts Gumbel-Softmax sampling
    Jang et al. [[2016](#bib.bib69)] to optimize these parameters with gradient descent
    jointly with the network weights. This strategy makes an interesting medium between
    Soft Layer Ordering Meyerson and Miikkulainen [[2017](#bib.bib110)] and Modular
    Meta-Learning Alet et al. [[2018](#bib.bib5)], in which each shared module is
    shared discretely instead of softly, but the computation graph can still be learned
    with gradient descent. AdaShare also employs several regularization terms to encourage
    sharing in the lower-level modules and sparsity in the resulting task-specific
    networks, which are discussed in section [3.2](#S3.SS2 "3.2 Regularization ‣ 3
    Optimization for Multi-Task Learning ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/707af06e2ff52a68515e7d6705c3fe1b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: A learned parameter sharing scheme with AdaShare Sun et al. [[2019b](#bib.bib147)].
    Each layer in the network is either included or ignored by each task, so that
    each task uses a subnetwork which is (likely) overlapping with other tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.4 Fine-Grained Sharing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Fine-grained parameter sharing schemes are the most recently introduced MTL
    architecture type, and they allow for more flexible information flow between tasks
    than sharing at the layer or multi-layer level. Piggyback Mallya et al. [[2018](#bib.bib106)]
    is a method for adapting a pre-trained network on a related task by learning to
    mask out individual weights of the original network. This allows for the storage
    of a newly trained model with a storage cost of only one additional bit per parameter
    of the original model while preserving the original network function. Despite
    the fact that the network output is not differentiable with respect to these network
    masks, these network masks are optimized through gradient descent jointly with
    the network weights by using a continuous relaxation of the mask values as a noisy
    estimate of the binary mask values. This method of optimizing such mask values
    is justified in prior work on binarized neural networks Courbariaux et al. [[2015](#bib.bib36)].
  prefs: []
  type: TYPE_NORMAL
- en: Newell et al. [[2019](#bib.bib115)] and Bragman et al. [[2019](#bib.bib22)]
    are concurrent works that each propose a parameter sharing scheme for multi-task
    CNNs in which sharing occurs at the filter level. For each convolutional layer
    of a multi-task network, the method of Newell et al. [[2019](#bib.bib115)] learns
    a binary valued $N\times C$ array $M$, where $N$ is again the number of tasks
    and $C$ is the number of feature channels in a given layer of the network. The
    $(i,c)$-th element of $M$ denotes whether the model of the $i$-th task should
    include the $c$-th feature map in the considered layer. Instead of optimizing
    this binary valued array with a Gumbel-Softmax Jang et al. [[2016](#bib.bib69)]
    distribution, the authors do not learn these values directly. Rather, the method
    learns a real-valued matrix $P$ of size $N\times N$, with values in the range
    $[0,1]$, where the $(i,j)$-th element of $P$ represents the proportion of feature
    channels which are shared by both the models for task $i$ and task $j$. In this
    way, the relationships between tasks are learned directly, and an array $M$ which
    satisfies $P=\frac{1}{C}M^{T}M$ is sampled after each new value of $P$ is computed.
    With this parameterization of $M$, the network architecture isn’t directly learned,
    but is instead sampled so that the learned task affinity matrix dictates the amount
    of overlap between task parameters. This task affinity matrix, $P$, is learned
    through evoluationary strategies. Bragman et al. [[2019](#bib.bib22)] proposes
    Stochastic Filter Groups (SFGs), in which the assignment of a convolutional filter
    to task-specific or shared is learned through variational inference. More specifically,
    SFGs are trained by learning the posterior distribution over the possible assignment
    of convolutional filters to task-specific or shared roles. As far as we know,
    SFGs are the only probabilistic approach to multi-task architecture learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sun et al. [[2019a](#bib.bib146)] introduces an algorithm for learning a fine-grained
    parameter sharing scheme by extracting sparse subnetworks of a single fully shared
    model. From a randomly initialized, overparameterized network, the authors employ
    Iterative Magnitude Pruning (IMP) Frankle and Carbin [[2018](#bib.bib52)] to extract
    a sparse subnetwork from the larger network for each individual task. IMP prunes
    a network by training for a small number of epochs, then removing the weights
    which have the smallest magnitude until a desired level of sparsity is reached.
    Given a reasonable level of sparsity, the extracted subnetworks for each task
    will overlap and exhibit fine-grained parameter sharing between tasks. A diagram
    is shown in figure [17](#S2.F17 "Figure 17 ‣ 2.5.4 Fine-Grained Sharing ‣ 2.5
    Learned Architectures ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with
    Deep Neural Networks: A Survey"). It is important to note that the degree of overlap
    between the extracted subnetworks of two tasks is not necessarily correlated with
    the relatedness of those two tasks, which suggests the need for a fine-grained
    parameter sharing scheme which incorporates information of task affinity to construct
    appropriate sharing mechanisms between tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/30d7d2800422bd29e5ed97e9efbdaa3d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17: Learned fine-grained sharing architecture from Sun et al. [[2019a](#bib.bib146)].
    Each task has a sparse subnetwork which may or may not overlap with that of other
    tasks. Each subnetwork is extracted using Iterative Magnitude Pruning Frankle
    and Carbin [[2018](#bib.bib52)] on the entire randomly initialized network before
    training.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.6 Conditional Architectures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Conditional or adaptive computation Bengio et al. [[2013](#bib.bib17)] is a
    method in which parts of a neural network architecture are selected for execution
    depending on the input to the network. Conditional computation is used in many
    areas outside of multi-task learning, such as to decrease model computational
    cost and in hierarchical reinforcement learning Kulkarni et al. [[2016](#bib.bib78)].
    In the multi-task case, a conditional architecture is dynamic between inputs as
    well as between tasks, though the components of these dynamically instantiated
    architectures are shared, which encourages these components to be generalizable
    between various inputs and tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Neural Module Networks Andreas et al. [[2016](#bib.bib7)] are an early work
    of conditional computation which were specifically designed for visual question
    answering. This method leverages the compositional structure of questions in natural
    language to train and deploy modules specifically catered for the individual parts
    of a question. The structure of a given question is determined by a non-neural
    semantic parser, specifically the Stanford Parser Klein and Manning [[2003](#bib.bib75)].
    The output of the parser is used to determine the compositional pieces of the
    question and the relationships between them, and the corresponding neural modules
    are used to dynamically instantiate a model for the given question. This process
    is shown in figure [18](#S2.F18 "Figure 18 ‣ 2.6 Conditional Architectures ‣ 2
    Multi-Task Architectures ‣ Multi-Task Learning with Deep Neural Networks: A Survey").
    While this work paved the way for future methods of conditional computation, it
    is lakcing in the sense that the composition of modules is not learned. Therefore,
    the role of each module and combination of modules is fixed and cannot be improved.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7bbda7fc6d53c53cc7cd4c2d8ab79fcd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18: Example Neural Module Network execution Andreas et al. [[2016](#bib.bib7)].
    The semantic structure of a given question is used to dynamically instantiate
    a network made of modules that correspond to the elements of the question.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Routing Networks Rosenbaum et al. [[2017](#bib.bib127)] and the Compositional
    Recursive Learner (CRL) Chang et al. [[2018](#bib.bib25)] are more recent related
    works of conditional computation in which the composition of modules is learned
    in addition to the weights of the modules themselves. A Routing Network is comprised
    of a router and a set of neural network modules. Given a piece of input data,
    the router iteratively chooses a module from the set of network modules to apply
    to the input for a fixed number of iterations; this process is shown in figure
    [19](#S2.F19 "Figure 19 ‣ 2.6 Conditional Architectures ‣ 2 Multi-Task Architectures
    ‣ Multi-Task Learning with Deep Neural Networks: A Survey"). The router can also
    choose a “pass" action instead of a module, which simply continues to the next
    iteration of routing. The module weights can be learned directly through backpropagation,
    and the router weights are learned with reinforcement learning to maximize the
    performance of the dynamically instantiated networks on their inputs. The Compositional
    Recursive Learner of Chang et al. [[2018](#bib.bib25)] is similar, though with
    some key differences. Given a piece of input data, the CRL also iteratively chooses
    a network module from a fixed set of modules through which to route the input.
    In the case of the CRL, any task specific information (such as a task ID) is intentionally
    hidden from the network modules, to ensure that the modules learn task-agnostic
    and therefore generalizable information. CRL is also trained with reinforcement
    learning on a curriculum, to encourage the re-use of modules learned on easier
    problems.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2ccd175456c7a91a68e317a481fc118c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19: Example Routing Network execution Rosenbaum et al. [[2017](#bib.bib127)].
    The router iteratively chooses a layer to apply to the input to dynamically instantiate
    a network for each input.'
  prefs: []
  type: TYPE_NORMAL
- en: Ahn et al. [[2019](#bib.bib2)] introduces a very similar architecture in which
    layers of varying configuration and scale are chosen from a larger backbone network
    through which to route the input. The router (called the selector network in this
    variant) is again trained with reinforcement learning.
  prefs: []
  type: TYPE_NORMAL
- en: The architecture of Kirsch et al. [[2018](#bib.bib74)] is similarly inspired
    to Routing Networks and the CRL, but takes a local view of routing rather than
    a global one. In Routing Networks and the CRL, any of the network modules can
    be placed into an instantiated network at any depth. In contrast, Kirsch et al.
    [[2018](#bib.bib74)] proposes a conditional architecture in which routing decisions
    are made only within layers of the network. The architecture is made of a series
    of modular layers, each having $m$ network modules. When a layer is to be applied
    to an input, the input is passed through a controller, which selects $k$ modules
    from the set of $m$ modules belonging to the layer. The layer input is then individually
    passed through each of the $k$ selected modules, and the results are added or
    concatenated to form the output of the layer. The controllers in these modular
    layers are trained not with reinforcement learning but with variational methods,
    where the module choice is treated as a latent variable. The authors argue that
    the architectural differences in their model from past works on conditional computation
    diminish the occurence of module collapse, a well-known weakness of conditional
    models. When module collapse occurs, the router selects only a small number of
    modules from the available set, while the remaining modules remain mostly unused,
    and the resulting models do not exhibit modularity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most recently, Soft Modularization Yang et al. [[2020](#bib.bib160)] is another
    conditional approach, which can be seen as a soft relaxation of Routing Networks.
    Soft Modularization uses both a router network and a policy network composed of
    $L$ layers, each with $m$ modules. Instead of making a discrete decision and choosing
    one module at each step of computation, as Routing Networks do, the input to each
    module is a linear combination of the outputs of modules from the previous layer.
    Specifically, the router network takes as input an observation and the corresponding
    task index, and outputs an $m\times m$ matrix of linear combination weights for
    each layer after the first, so that the element in the $i$-th row and $j$-th column
    of the weight matrix for layer $\ell$ denotes the weight of module $i$ from layer
    $\ell-1$ in the input to module $j$ from layer $\ell$. The soft relaxation from
    Routing Networks eliminates the need to train the router separately from the policy,
    and instead the entire network can be trained end-to-end. This architecture is
    also related to Soft Layer Ordering Meyerson and Miikkulainen [[2017](#bib.bib110)]
    (see section [2.3.2](#S2.SS3.SSS2 "2.3.2 Modular Policies ‣ 2.3 Architectures
    for Reinforcement Learning ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning
    with Deep Neural Networks: A Survey")), though with Soft Modularization the linear
    combination weights aren’t directly learned, instead they are dynamically computed
    by a separate network (the router network) at each step of computation. When combined
    with Soft Actor-Critic Haarnoja et al. [[2018](#bib.bib58)], the Soft Modularization
    agent reaches 60% success rate on MT50 from the Meta-World benchmark Yu et al.
    [[2019](#bib.bib164)].'
  prefs: []
  type: TYPE_NORMAL
- en: A thorough discussion of the strengths and weaknesses of routing based approaches
    can be found in Rosenbaum et al. [[2019](#bib.bib128)] and Ramachandran and Le
    [[2019](#bib.bib125)].
  prefs: []
  type: TYPE_NORMAL
- en: 3 Optimization for Multi-Task Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With MTL architecture design as the modern generalization of hard parameter
    sharing on one side, MTL optimization is the broader version of soft parameter
    sharing on the other. Soft parameter sharing is a way to regularize model parameters
    by penalizing the distance from model parameters to corresponding parameters of
    a model for a different, but related task. While MTL optimization methods do include
    regularization strategies that penalize parameter distance, many other regularization
    strategies are being actively developed. When the challenge of negative transfer
    is viewed through an optimization lens, new methods for dealing with negative
    transfer - aside from various parameter sharing schemes - begin to appear.
  prefs: []
  type: TYPE_NORMAL
- en: 'We partition the existing MTL optimization methods into six distinct groups:
    loss weighting, regularization, gradient modulation, task scheduling, multi-objective
    optimization, and knowledge distillation. Just as in previous sections of this
    review, the boundaries between these groups are not always concrete. Certain methods
    may be interpreted as existing in more than one of these groups, but we believe
    that this partition is useful for conceptualizing the various directions of research
    in MTL optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Loss Weighting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A very common approach to ease multi-task optimization is to balance the individual
    loss functions for different tasks. When a model is to be trained on more than
    one task, the various task-specific loss functions must be combined into a single
    aggregated loss function which the model is trained to minimize. A natural question
    to ask then, is how to exactly to combine multiple loss functions into one that
    is suitable for MTL. Most of the methods we describe here parameterize the aggregated
    loss function as a weighted sum of the task-specific loss functions, and the contribution
    of each method is in the computation these weights. Gong et al. [[2019](#bib.bib55)]
    contains an empirical comparison of existing loss weighting methods.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that there are several related works Xu et al. [[2018b](#bib.bib159)],
    Du et al. [[2018](#bib.bib45)] which introduce methods for weighting the loss
    of auxiliary tasks relative to a main task loss. While these methods are interesting
    and potentially useful for MTL, they were designed for a setting that lies outside
    MTL, namely one in which there is a main task accompanied by one or more auxiliary
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 Weighting by Uncertainty
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the earliest methods for learning loss weights is Kendall et al. [[2017](#bib.bib72)].
    In this work, the authors treat the multi-task network as a probabilistic model,
    and derive a weighted multi-task loss function by maximizing the likelihood of
    the ground truth output. For the case of training on $N$ simultaneous regression
    tasks, the distribution computed by the network output for task $i$ is the Gaussian
    $\mathcal{N}(f_{i}(x),\sigma_{i}^{2})$, where $f_{i}(x)$ is the network output
    for task $i$ and $\sigma_{i}$ is a learned parameter which signifies the task-dependent
    (or homoscedastic) uncertainty for task $i$. The resulting loss function to jointly
    maximize the likelihood of each such distribution is
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\sum_{i}\frac{1}{2\sigma^{2}}\&#124;y_{i}-f_{i}(x)\&#124;^{2}+\text{log}~{}\sigma_{i}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: Here $y_{i}$ is the ground-truth label for task $i$. From this derived loss
    function, we can see that each task’s loss is weighted by the inverse of it’s
    task-dependent uncertainty, so that tasks with less uncertainty will be given
    more weight. Also, each task’s loss is regularized by $\text{log}~{}\sigma_{i}$,
    so that the optimization process isn’t incentivized to follow the degenerate strategy
    of increasing the $\sigma_{i}$’s indefinitely. A very similar formula arises for
    training on classification tasks, and this method for weighting task losses is
    the main contribution of this work. Interestingly, the models trained with this
    method of weighting were shown to outperform identical models which were trained
    with the best performing constant loss weights.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 Weighting by Learning Speed
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Following Kendall et al. [[2017](#bib.bib72)], several methods of weighting
    multi-task loss functions were introduced which weigh a task’s loss by the learning
    speed on that task Chen et al. [[2017](#bib.bib30)], Liu et al. [[2019](#bib.bib93)],
    Zheng et al. [[2018](#bib.bib174)], Liu et al. [[2019a](#bib.bib94)], with slightly
    varying approaches. The majority of these methods increase a task’s loss weight
    when the learning speed for that task is low, in order to balance learning between
    tasks, though this is not the case for all methods discussed here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Liu et al. [[2019](#bib.bib93)] and Liu et al. [[2019a](#bib.bib94)] each explicitly
    set a task’s loss weight using a ratio of the current loss to a previous loss.
    Let $\mathcal{L}_{i}(t)$ be the loss for task $i$ at timestep $t$, and let $N$
    be the number of tasks. Dynamic Weight Averaging Liu et al. [[2019](#bib.bib93)]
    sets the task weights in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\lambda_{i}(t)=\frac{N~{}\text{exp}(r_{i}(t-1)/T)}{\sum_{j}\text{exp}(r_{j}(t-1)/T)}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $r_{i}(t-1)=\mathcal{L}_{i}(t-1)/\mathcal{L}_{i}(t-2)$ and $T$ is a temperature
    hyperparameter. In other words, the loss weight vector is a softmax over the ratios
    of successive loss values over the last two training steps for each task, multipled
    by the number of tasks. Similarly, Loss Balanced Task Weighting Liu et al. [[2019a](#bib.bib94)]
    sets
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\lambda_{i}(t)=\left(\frac{\mathcal{L}_{i}(t)}{\mathcal{L}_{i}(0)}\right)^{\alpha}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\alpha$ is a hyperparameter. Notice that LBTW measures learning speed
    as the ratio of the current loss to the initial loss, while DWA measures it as
    the ratio of the losses from the last two training steps. LBTW also does not normalize
    the weight values to sum to a fixed value.
  prefs: []
  type: TYPE_NORMAL
- en: GradNorm Chen et al. [[2017](#bib.bib30)] is similarly inspired to these two
    methods, but doesn’t compute loss weights explicitly. Instead, the weights are
    optimized to minimize an auxiliary loss which measures the difference between
    each task’s gradient and a desired task gradient based on the average task loss
    gradient and the learning speed of each task. To define this auxiliary loss, we
    first must define $G_{i}(t)=\|\nabla_{\theta}\lambda_{i}(t)\mathcal{L}_{i}(t)\|_{2}$
    (weighted gradient for task $i$), $\bar{G}(t)$ as the average of all such $G_{i}(t)$,
    $\tilde{\mathcal{L}}_{i}(t)=\mathcal{L}_{i}(t)/\mathcal{L}_{i}(0)$ (learning speed
    for task $k$), and $r_{i}(t)=\tilde{\mathcal{L}}_{i}(t)/\mathbb{E}_{j}[\tilde{\mathcal{L}}_{j}(t)]$
    (relative learning speed for task $i$). Then the auxiliary loss is defined as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}_{\text{grad}}(\lambda(t))=\sum_{j}\&#124;G_{j}(t)-\bar{G}(t)\times[r_{i}(t)]^{\alpha}\&#124;_{1}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\alpha$ is again a hyperparameter. By optimizing the task weights $\lambda_{i}(t)$
    to minimize $\mathcal{L}_{\text{grad}}$, the weights are shifted so that tasks
    with a higher learning speed yield gradients with smaller magnitude, and tasks
    with a lower learning speed yield gradients with a larger magnitude. It should
    be noted that this separate optimization adds some compute cost, though the authors
    only apply GradNorm to the last layer of shared weights in the network in order
    to minimize the added cost. Even with this restriction, GradNorm outperforms baselines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that all of the methods introduced so far in [3.1.2](#S3.SS1.SSS2 "3.1.2
    Weighting by Learning Speed ‣ 3.1 Loss Weighting ‣ 3 Optimization for Multi-Task
    Learning ‣ Multi-Task Learning with Deep Neural Networks: A Survey") increase
    the weight of a given task’s loss when learning on that task is slower than other
    tasks. In comparison, Zheng et al. [[2018](#bib.bib174)] assigns a loss weight
    to a task which decreases as learning speed increases, assigning a weight of zero
    if the loss increased on the previous training step. More specifically, the weight
    for task $i$ on timestep $t$ is defined in the following way: Let $\mathcal{L}_{i}(t)$
    be the loss from task $i$ on timestep $t$, let $\tilde{\mathcal{L}}_{i}(t)=\alpha\mathcal{L}_{i}(t)+(1-\alpha)\tilde{\mathcal{L}}_{i}(t-1)$,
    and $p_{i}(t)=\text{min}(\tilde{\mathcal{L}}_{i}(t),\tilde{\mathcal{L}}_{i}(t-1))/\tilde{\mathcal{L}}_{i}(t-1)$
    where $\alpha$ is a hyperparameter. Then the weight for task $i$ on timestep $t$
    is set to'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\lambda_{i}(t)=-(1-p_{i}(t))^{\gamma}\text{log}(p_{i}(t))$ |  |'
  prefs: []
  type: TYPE_TB
- en: similar to the Focal Loss Lin et al. [[2017](#bib.bib87)]. The rationale behind
    this strategy is that if the loss for task $i$ has increased (i.e. $p_{i}(t)=1$),
    there may be a local minimum in the loss landscape of that task. By assigning
    a weight for this task to zero, training steps will only depend on gradients from
    tasks whose loss is still decreasing, and gradient descent will (hopefully) escape
    from the task-specific local minimum in the landscape of the task whose loss has
    just increased.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.3 Weighting by Performance
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Weighting task’s losses by performance is similar to weighting by learning speed.
    These two categories are distinguished by the fact that learning speed can be
    thought of as the rate of change of performance. Given that there are numerous
    works which introduced methods for weighting by learning speed, there are surprisingly
    few methods for weighting by performance. To our knowledge, the only such works
    are Dynamic Task Prioritization Guo et al. [[2018](#bib.bib57)] and the implicit
    schedule in Jean et al. [[2019](#bib.bib70)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Dynamic Task Prioritization Guo et al. [[2018](#bib.bib57)] was inspired by
    the non-neural MTL work Self-Paced Multi-Task Learning Li et al. [[2016](#bib.bib84)].
    Dynamic Task Prioritization (or DTP) prioritizes difficult tasks and examples
    by assigning weights both at the task level and the example level. DTP employs
    the Focal Loss Lin et al. [[2017](#bib.bib87)] to weigh examples within a task
    and performance metrics such as classification accuracy to weigh tasks themselves,
    where both the example and task level of weights emphasize difficult data over
    easy data. These are the distinguishing factors of this work: usage of performance
    metrics other than the loss function to weigh tasks, and loss weighting at both
    the example and the task level.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The method for loss weighting introduced in Jean et al. [[2019](#bib.bib70)]
    is deemed an implicit task schedule, in reference to the connection between loss
    weighting and task scheduling (see section [3.3](#S3.SS3 "3.3 Task Scheduling
    ‣ 3 Optimization for Multi-Task Learning ‣ Multi-Task Learning with Deep Neural
    Networks: A Survey")). In this work, the $i$-th task is assigned the weight'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\lambda_{i}=1+(\text{sign}(\bar{S}-S_{i}))~{}\text{min}(\gamma,(\text{max}_{j}~{}S_{j})^{\alpha}&#124;\bar{S}-S_{i}&#124;^{\beta})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $S_{i}$ is the ratio of the current validation performance to a target
    validation performance, $\bar{S}$ is the average over all $S_{i}$’s, $\gamma$
    is a hyperparameter which limits the difference between task weights, $\alpha$
    is a hyperparameter that adjusts how quickly the weights deviate from uniformity,
    and $\beta$ is a hyperparameter that adjusts the emphasis on deviations of a task’s
    score from the mean score. While the formula to compute the loss weights in this
    implicit schedule looks quite different from the focal loss, they have the same
    intention: focus on tasks with poor performance. Interestingly, this work also
    includes a discussion of the difference between scaling learning rates and scaling
    gradients (there is no difference for vanilla SGD), which is an often overlooked
    but important detail of choosing loss coefficients.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.4 Weighting by Reward Magnitude
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It is a well known issue in multi-task learning that a difference in the scale
    of loss functions between tasks can cause imbalanced learning dynamics when training
    jointly on such tasks. For example, consider an MTL setting with two tasks, $T_{1}$
    and $T_{2}$, both classification tasks. Suppose that the loss $\mathcal{L}_{1}$
    for task $T_{1}$ is a standard cross-entropy loss, and the loss $\mathcal{L}_{2}$
    for $T_{2}$ is equal to the standard cross-entropy loss multiplied by a constant
    factor of 1000\. It is clear in this case that the gradient for the joint task
    loss $\mathcal{L}=\mathcal{L}_{1}+\mathcal{L}_{2}$ will be mostly dependent on
    the network’s performance on $T_{2}$ and very little on that of $T_{1}$, so that
    the multi-task learning will actually be focused mostly on $T_{2}$. While this
    is a somewhat contrived example, the same principle applies to MTL settings in
    the wild, where the scale of loss functions may differ greatly. One approach to
    tackle this issue is to compute task loss weights based on the magnitude of each
    task’s loss function.
  prefs: []
  type: TYPE_NORMAL
- en: Hessel et al. [[2018](#bib.bib62)] uses PopArt normalization van Hasselt et al.
    [[2016](#bib.bib150)] to perform loss weighting for multi-task deep reinforcement
    learning. The authors derive a scale-invariant update rule for actor-critic methods,
    then extend it to a multi-task setting. The main idea is to keep a running estimate
    of the mean and standard deviation of the return from each timestep, then replace
    the returns with the normalized versions. The REINFORCE Williams [[1992](#bib.bib155)]
    algorithm uses an update rule in which the gradient of the objective with respect
    to the policy parameter is
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $(R(t)-v(s_{t}))\nabla_{\theta}\text{log}~{}\pi(a_{t}&#124;s_{t})$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $R(t)$ is the return from step $t$, $v$ is the value function, $\theta$
    are the parameters of the policy $\pi$, and $s_{t}$ and $a_{t}$ are the state
    and action at step $t$. This work replaces this update rule with
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\left(\frac{R_{i}(t)-\mu_{i}}{\sigma_{i}}-\tilde{v}_{i}(s_{t})\right)\nabla_{\theta}\text{log}~{}\pi(a_{t}&#124;s_{t})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $R_{i}(t)$ is the return on step $t$ for task $i$, $\mu_{i}$ and $\sigma_{i}$
    are running estimates of the mean and standard deviation of $R_{i}(t)$, and $\tilde{v}_{i}$
    is a normalized value function for task $i$. A similar replacement is made for
    the update rule of the value function, and the details can be found in Hessel
    et al. [[2018](#bib.bib62)]. This normalization constrains the reward function
    from each task to have a similar contribution to the update, so that the relative
    importance of each task is agnostic to the scale of the reward functions. Applying
    PopArt to multi-task deep reinforcement learning significantly improves performance
    of agents trained with IMPALA Espeholt et al. [[2018](#bib.bib49)] on the DeepMind
    Lab Beattie et al. [[2016](#bib.bib13)] collection of tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.5 Geometric Mean of Losses
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: While most MTL methods model the network loss as a weighted average of individual
    task losses, Chennupati et al. [[2019](#bib.bib31)] proposes to compute the geometric
    mean of task losses as an alternative. The authors claim that using a geometric
    mean facilitates balanced training of all tasks, and that this loss function handles
    differences in learning speeds of various tasks better than the traditional weighted
    average loss function. However, there is no rigorous evidence to support these
    claims. The results presented in their work show that models trained with the
    geometric outperform baselines, but there has been little work done on analyzing
    the specific properties of optimization using these loss functions in the MTL
    setting, which may be an interesting direction for future research.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Regularization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Regularization has long played in important role in multi-task learning, mostly
    in the form of soft parameter sharing. Soft parameter sharing is one of two popular
    techniques for MTL (the other being hard parameter sharing) in which parameters
    aren’t shared between task models, but instead the $L_{2}$ distance between the
    parameters of task models is added to the training objective, in order to encourage
    similar model parameters between different tasks. Soft parameter sharing is simple
    to implement and has been employed extensively in MTL methods.
  prefs: []
  type: TYPE_NORMAL
- en: Duong et al. [[2015](#bib.bib46)] is a well-known method which uses soft parameter
    sharing instead of hard parameter sharing. The authors employ the architecture
    of Chen and Manning [[2014](#bib.bib27)] for dependency parsing in multiple languages,
    but train separate copies of the same network, one for each language. Only a small
    fraction of the parameters in the network are softly shared between tasks, namely
    the layers which transform the embedded POS tags and the embedded arc labels.
    The use of soft parameter sharing across models for different languages was shown
    to greatly increase performance in the small data setting.
  prefs: []
  type: TYPE_NORMAL
- en: An interesting variant of soft parameter sharing is introduced in Yang and Hospedales
    [[2016b](#bib.bib162)], in which the $L_{2}$ distance between parameter vectors
    is replaced by the tensor trace norm of the tensor formed by stacking corresponding
    parameter vectors from different tasks. The trace norm of a matrix is the sum
    of the singular values of that matrix, and it can be thought of as a convex relaxation
    of rank, i.e. the number of non-zero singular values. Therefore, minimizing the
    trace norm of a matrix is a good surrogate for minimizing the rank of that matrix.
    By extending the trace norm from matrices to tensors and minimizing the tensor
    trace norm of stacked parameter vectors, this method encourages the learning of
    parameter vectors across tasks which are similar, just as in traditional soft
    parameter sharing. In this case, however, similarity is measured by the existence
    of linear dependencies between parameter vectors (i.e. low tensor rank), instead
    of $L_{2}$ distance. The authors interpret the resulting trace norms after training
    as a measure of sharing strength between corresponding layers in different task
    models (low trace norm means stronger sharing), and interestingly, the sharing
    strength was found to decrease with layer depth. This conincides with the common
    intuition in MTL that representations in earlier layers should be less task-dependent
    than those of deeper layers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides soft parameter sharing, MTL models can also be regularized by placing
    prior distributions on the network parameters. Multilinear Relationship Networks
    (MRNs) Long et al. [[2017](#bib.bib99)] do exactly this by imposing a tensor normal
    distribution as a prior over the parameters in task-specific layers of multi-task
    models. A tensor normal distribution is essentially a multivariate normal distribution
    with the extra assumption that the covariance matrix can be decomposed into the
    Kronecker product of $K$ covariance matrices, where $K$ is the order of a tensor
    following this distribution. Each of these covariance matrices represents the
    covariance between rows of various matricizations of a tensor following the distribution.
    To impose this distribution on the parameter tensor of a multi-task network, the
    covariance is constructed as the Kronecker product of three covariance matrices:
    a covariance matrix representing the relationships between features, another indicating
    the relationships between classification classes, and the last modeling the relationships
    between tasks. It is this construction that allows the model to learn relationships
    between tasks, as its name suggests. At the time of its publication, MRNs reached
    state of the art performance on three different MTL benchmarks.'
  prefs: []
  type: TYPE_NORMAL
- en: Deep Asymmetric Multitask Feature Learning (Deep-AMTFL) Lee et al. [[2018](#bib.bib83)]
    is a method of regularizing deep multi-task neural networks by introducing an
    autoencoder term to the objective function. This auxiliary task involves reconstructing
    the features from the second to last layer of a network from the network output,
    so that each of the task predictions is used to construct the features for all
    other tasks, a task which was proposed by Asymmetric Multi-Task Learning Lee et al.
    [[2016](#bib.bib82)]. The motivation behind these methods is to allow for information
    to flow from tasks which the model does well to tasks which the model does poorly,
    but not the other way around, hence the “asymmetric" in the names.
  prefs: []
  type: TYPE_NORMAL
- en: 'AdaShare Sun et al. [[2019b](#bib.bib147)] (architecture discussed in section
    [2.5.3](#S2.SS5.SSS3 "2.5.3 Modular Sharing ‣ 2.5 Learned Architectures ‣ 2 Multi-Task
    Architectures ‣ Multi-Task Learning with Deep Neural Networks: A Survey")) introduces
    a novel regularization scheme for MTL methods by regularizing sharing parameters
    instead of module parameters. AdaShare uses a set of neural network blocks which
    are shared between many tasks, though not all blocks are used by every task. The
    sharing parameters of this architecture encode the usage of blocks by different
    tasks, as shown in figure [16](#S2.F16 "Figure 16 ‣ 2.5.3 Modular Sharing ‣ 2.5
    Learned Architectures ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with
    Deep Neural Networks: A Survey"). AdaShare regularizes these sharing parameters
    $\alpha_{i}$ instead of the network weights. Specifically, the training objective
    includes two auxiliary terms'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}_{sparsity}=\sum_{\ell\leq L,i\leq N}\text{log}~{}\alpha_{i,\ell}\qquad\mathcal{L}_{sharing}=\sum_{i,j\leq
    N}\sum_{\ell\leq L}\frac{L-\ell}{L}\&#124;\alpha_{i,\ell}-\alpha_{j,\ell}\&#124;_{1}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $N$ is the number of tasks and $L$ is the number of blocks. $\mathcal{L}_{sparsity}$
    encourages each task’s network to be sparse, while $\mathcal{L}_{sharing}$ encourages
    similarity in the sharing parameters of different tasks. Notice that the coefficient
    $\frac{L-\ell}{L}$ in the definition of $\mathcal{L}_{sharing}$ linearly decreases
    the importance of sharing in deeper layers, which follows the observation in Yang
    and Hospedales [[2016b](#bib.bib162)] that more sharing should occur in earlier
    layers, though in this case it is explicitly encouraged. Both of these regularization
    terms are very general, and could potentially be applied to Soft Layer Ordering
    Meyerson and Miikkulainen [[2017](#bib.bib110)], Modular Meta Learning Alet et al.
    [[2018](#bib.bib5)], Stochastic Filter Groups Bragman et al. [[2019](#bib.bib22)],
    and many other architectures which learn what to share between tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'A related type of regularization is introduced for conditional computation
    models, specifically Routing Networks (discussed in section [2.6](#S2.SS6 "2.6
    Conditional Architectures ‣ 2 Multi-Task Architectures ‣ Multi-Task Learning with
    Deep Neural Networks: A Survey")), in Cases et al. [[2019](#bib.bib24)]. In this
    case, the regularizer is shaping the decisions of module selection between tasks
    by encouraging diversity of choices made by the router, but it takes a slightly
    different form compared to the AdaShare regularization, due to the differences
    between Routing Networks and the AdaShare architecture. Specifically, Routing
    Networks iteratively construct a network layer by layer, choosing between the
    set of all layers at each step, so that any permutation (with repetitions) of
    layers can be combined into a network by the router. In particular, this means
    that the router can ignore many or most layers and only utilize a few layers per
    task, which is a well known occurence in training Routing Networks called module
    collapse Rosenbaum et al. [[2019](#bib.bib128)]. Module collapse causes a waste
    of network components as well as a decrease in modularity. The issue of module
    collapse is addressed by the regularization technique used in Cases et al. [[2019](#bib.bib24)],
    which rewards diversity of choices made by the router, so that no layer is ignored.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, Maximum Roaming Pascal et al. [[2020](#bib.bib120)] is a multi-task
    regularization method that can be thought of as a variant of Dropout Srivastava
    et al. [[2014](#bib.bib141)] specifically made for MTL networks. While most MTL
    methods partition parameters between tasks in either a fixed or principally learned
    way, Maximum Roaming randomly varies the parameter partitioning during training,
    under the constraint that each parameter must be assigned to a maximal number
    of tasks. Despite the unorthodoxy of this idea, it is empirically demonstrated
    to be beneficial for performance on the CelebA Liu et al. [[2015b](#bib.bib98)],
    CityScapes Cordts et al. [[2016](#bib.bib35)], and NYU-v2 Silberman et al. [[2012](#bib.bib137)]
    datasets. The intuitive explanation of the benefit of roaming is that it allows
    for each unit to learn from all tasks throughout training without the constraint
    that each parameter is always shared between all tasks, which is a likely contributor
    to negative transfer. Intuition aside, this phenomenon is not yet rigorously understood
    and further work is certainly needed to fully utilize the potential gains.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Task Scheduling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Task scheduling is the process of choosing which task or tasks to train on at
    each training step. Most MTL models make this decision in a very simple way, either
    training on all tasks at each step or randomly sampling a subset of tasks to train
    on, though there is some variation in these simple task schedulers. For example,
    when training on a single task at each update step in supervised learning settings,
    it is common to employ either uniform task sampling Dong et al. [[2015](#bib.bib43)],
    where each task has the same probability of being chosen, or proportional task
    sampling Sanh et al. [[2019](#bib.bib132)], in which the probability of choosing
    a task is proportional to the size of its dataset. Despite the fact that most
    methods use these baseline task schedulers, it is a well known fact that optimized
    task scheduling can significantly improve model performance Bengio et al. [[2009](#bib.bib16)].
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to note that the problem of scheduling tasks is strongly tied
    to the problem of weighting task losses. To see this, consider an MTL setting
    with two tasks, $T_{1}$ and $T_{2}$, with corresponding loss functions $\mathcal{L}_{1}$
    and $\mathcal{L}_{2}$, and consider two separate training setups for this setting.
    In the first setup, the model is trained by minimizing the joint loss $\mathcal{L}_{1}+2\mathcal{L}_{2}$,
    and each training batch holds an equal amount of data from both tasks. In the
    second setup, each training batch either holds data exclusively from $T_{1}$ or
    $T_{2}$, where the chances of the batch containing $T_{1}$ data and $T_{2}$ data
    are $1/3$ and $2/3$, respectively. If a batch is from $T_{1}$, the training step
    will minimize $\mathcal{L}_{1}$, and if a batch is from $T_{2}$, the step will
    minimize $\mathcal{L}_{2}$. It isn’t hard to intuit that these setups will, on
    average, lead to similar results. The training processes won’t be numerically
    equivalent, but each setup jointly optimizes for the tasks in a way that prioritizes
    $T_{2}$ twice as much as $T_{1}$. Loss weighting can be seen as a continuous relaxation
    of task scheduling, so that many task schedulers can easily be adapted to loss
    weighting methods, and vice versa. However, most works adhere to the conventions
    of their subfield and only use one of these two framings: multi-task computer
    vision methods frequently use loss weighting Dai et al. [[2016](#bib.bib37)],
    Misra et al. [[2016](#bib.bib113)], Ruder et al. [[2019](#bib.bib130)], while
    multi-task NLP methods often employ task scheduling Liu et al. [[2015a](#bib.bib95)],
    Luong et al. [[2015](#bib.bib104)], Liu et al. [[2019b](#bib.bib96)].'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3a20c8689e048a6bb460542f76efa79b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20: Task scheduling visualization from Sharma et al. [[2017](#bib.bib135)].
    A meta task-decider is trained to sample tasks with a training signal that encourages
    tasks with worse relative performance to be chosen more frequently.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sharma et al. [[2017](#bib.bib135)] proposes a method for task scheduling in
    multi-task RL which is based on active learning, with three different variants.
    The common idea behind these three variants is to assign task scheduling probabilities
    based on relative performance to a target level: the further the model is from
    the target performance on a given task, the more likely it is that the task will
    be scheduled. This is akin to the loss weighting methods that increase the loss
    weight of a task that exhibits slow learning. Figure [20](#S3.F20 "Figure 20 ‣
    3.3 Task Scheduling ‣ 3 Optimization for Multi-Task Learning ‣ Multi-Task Learning
    with Deep Neural Networks: A Survey") shows a visualization of the task scheduling
    process. The difference between the three variants is in the implementation of
    the “meta task-decider", the component which computes task sampling probabilities.
    In one way or another, each variant uses the values $m_{i}=1-a_{i}/b_{i}$ to compute
    these probabilities, where $i$ is a task index, $b_{i}$ is the target performance
    for task $i$, and $a_{i}$ is the current model performance for task $i$. Notice
    that $m_{i}$ is a measure of the difference between the current model perfomance
    and the baseline performance for task $i$. The first variant, A5C, doesn’t learn
    a sampling distribution, but instead computes a softmax over all $m_{i}$’s to
    construct the sampling distriubtion over tasks. The second variant, UA4C, treats
    the task sampling problem as a non-stationary multi-armed bandit problem in which
    the reward for the meta task-decider when picking task $i$ is $m_{i}$. This way,
    the agent is rewarded for choosing tasks which are furthest from their respective
    target performances. Lastly, the third variant, EA4C, treats the sequence of task
    sampling decisions as a reinforcement learning problem, so that the meta task-decider
    can learn to choose sequences of tasks which help the agent to learn over time.
    In this case, the reward for the meta task-decider when choosing task $i$ is'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\lambda m_{i}+(1-\lambda)\left(\frac{1}{3}\sum_{j\in\mathbb{L}}(1-m_{j})\right)$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbb{L}$ is the task indices of the three tasks with the worst current
    performance and $\lambda$ is a hyperparameter. This reward function then incentivizes
    the meta task-decider to choose tasks which are furthest from their target performance
    while simultaneously choosing tasks which ensure that the performance on the worst
    tasks are still improving. Agents trained with these three variants vastly outperform
    an identical agent with uniform sampling probability on various collections of
    Atari games ranging in size from 6 games to 21 games.
  prefs: []
  type: TYPE_NORMAL
- en: The A5C variant of the algorithm of Sharma et al. [[2017](#bib.bib135)] is very
    similar to a more recently proposed method for task scheduling Jean et al. [[2019](#bib.bib70)].
    In this work, each task is assigned an unnormalized score
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\lambda_{i}=\frac{1}{\text{min}(1,\frac{a_{i}}{b_{i}})^{\alpha}+\epsilon}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $a_{i}$ and $b_{i}$ are defined similarly as above, and $\alpha$ and
    $\epsilon$ are hyperparameters. The unnormalized scores are simply divided by
    their sums to obtain the task sampling probabilities. The novel portion of this
    method is the inclusion of $\epsilon$ for numerical stability and $\alpha$ to
    control the degree of over and under sampling of tasks. Jean et al. [[2019](#bib.bib70)]
    also provides a discussion of task scheduling vs. loss weighting, in which loss
    weighting is referred to as “implicit task scheduling", as well as a loss weighting
    method which is discussed in section [3.1.3](#S3.SS1.SSS3 "3.1.3 Weighting by
    Performance ‣ 3.1 Loss Weighting ‣ 3 Optimization for Multi-Task Learning ‣ Multi-Task
    Learning with Deep Neural Networks: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Gradient Modulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the main challenges in MTL is negative transfer, when the joint training
    of tasks hurts learning instead of helping it. From an optimization perspective,
    negative transfer manifests as the presence of conflicting task gradients. When
    two tasks have gradients which point in opposing directions, following the gradient
    for one task will decrease the performance on the other task, and following the
    average of the two gradients means that neither task sees the same improvement
    it would in a single-task training setting. Among many other approaches to alleviate
    the conflict in learning dynamics between different tasks, explicit gradient modulation
    has arisen as a potential solution. The methods presented here work by modifying
    training gradients, either through the use of adversarial methods or by simply
    replacing gradient vectors when conflicts arise.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.1 Adversarial Gradient Modulation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If a multi-task model is training on a collection of related tasks, then ideally
    the gradients from these tasks should point in similar directions. Gradient Adversarial
    Training (GREAT) Sinha et al. [[2018](#bib.bib138)] explicitly enforces this condition
    by including an adversarial loss term that encourages gradients from different
    sources to have statistically indistinguishable distributions. GREAT is a general
    framework which can be applied for adversarial defense and knowledge distillation
    (and likely other settings) besides multi-task learning. In the MTL setup, the
    model is augmented with an auxiliary discriminator network which attempts to classify
    the tasks corresponding to gradients of the task decoders, as pictured in figure
    [21](#S3.F21 "Figure 21 ‣ 3.4.1 Adversarial Gradient Modulation ‣ 3.4 Gradient
    Modulation ‣ 3 Optimization for Multi-Task Learning ‣ Multi-Task Learning with
    Deep Neural Networks: A Survey"). During the backward pass, the gradients are
    modified by Gradient Alignment Layers (GALs) through element-wise scaling to minimize
    the performance of the auxiliary network in distinguishing between the task gradients.
    A similar adversarial setup to enforce gradient similarity between tasks is used
    in Maninis et al. [[2019](#bib.bib107)].'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/31e529932c28ec7590272adb7e6a08d3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21: Multi-task GREAT model Sinha et al. [[2018](#bib.bib138)]. An auxiliary
    network takes a gradient vector for a single task’s loss and tries to classify
    which task the gradient vector came from. The network gradients are then modulated
    to minimize the performance of the auxiliary network, to enforce the condition
    that gradients from different task functions have statistically indistinguishable
    distributions.'
  prefs: []
  type: TYPE_NORMAL
- en: While the motivation for the model is intuitively plausible, the premise of
    adversarial training isn’t rigorously justified. Just because two tasks are related,
    how can we be sure that their gradient distributions should be identical? Furthermore,
    it seems likely that the distribution of a task’s gradients will change throughout
    training, so how likely can it be that each task’s gradient distributions move
    together? The existence of negative transfer in the first place tells us that
    similar tasks do not necessarily have aligning gradients. Can we actually alleviate
    negative transfer by enforcing gradients to be similar, even when the original
    gradients of the loss function are conflicting? Without theoretical justification,
    we can’t be sure of the answers to these questions. Nevertheless, the experiments
    presented in this work show that GREAT does increase the performance of multi-task
    models, and that it outperforms other multi-task optimization baselines such as
    GradNorm. The nature of both the premise and the results of this model are still
    unanswered questions.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.2 Gradient Replacement
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An entirely different approach to gradient modulation is explored in Lopez-Paz
    and Ranzato [[2017](#bib.bib100)], Chaudhry et al. [[2018](#bib.bib26)], Yu et al.
    [[2020](#bib.bib165)]. The main idea behind these three works is to replace a
    task gradient vector which conflicts with another by a modified version which
    has no conflicts. This idea is broad, but the implementations of each of these
    works are similar at heart and we will present a rigorous definition of each.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lopez-Paz and Ranzato [[2017](#bib.bib100)] introduces Gradient Episodic Memory
    (GEM) for continual learning, a problem formulation in which a model learns multiple
    tasks sequentially, instead of simultaneously as in MTL. GEM keeps an episodic
    memory of training examples from past learned tasks, and enforces the following
    constraint at each update step $t$ when training on task $i$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\forall j<i:G_{i}(t)^{T}G_{j}(t)\geq 0$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $G_{i}(t)$ is the gradient vector for task $i$ (the current task) and
    $G_{j}(t)$ is the gradient of the loss on the data in episodic memory from task
    $j$, at training step $t$. The condition that the dot product between two gradient
    vectors is non-negative is equivalent to the condition that the angle between
    the two gradient vectors is less than 90 degrees, so that they don’t point in
    opposing directions. If this condition isn’t met for some $j$, then $G_{i}(t)$
    is replaced by $\tilde{G}_{i}(t)$, the solution to the following optimization
    problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | minimize: | $\displaystyle\frac{1}{2}\&#124;G_{i}(t)-\tilde{G}_{i}(t)\&#124;^{2}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | subject to: | $\displaystyle\forall j<i:\tilde{G}_{i}(t)^{T}G_{j}(t)\geq
    0$ |  |'
  prefs: []
  type: TYPE_TB
- en: This quadratic optimization problem can be solved efficiently by instead solving
    the dual and recovering the corresponding value of $\tilde{G}_{i}(t)$. Even so,
    GEM introduces significant increase in computation time compared to traditional
    training. Averaged GEM (A-GEM) Chaudhry et al. [[2018](#bib.bib26)] was proposed
    to alleviate the computation burden. The authors point out that it is much more
    efficient to relax the GEM constraint to
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $G_{i}(t)^{T}G_{\text{avg}}(t)\geq 0$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $G_{\text{avg}}(t)=\frac{1}{i-1}\sum_{j<i}G_{j}(t)$. In other words,
    instead of requiring the new gradient to be non-conflicting with the task gradient
    of each previous task, A-GEM only requires that the new gradient be non-conflicting
    with the average of the previous tasks’ gradients. By doing this, the modified
    optimization problem has the following closed form solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\tilde{G}_{i}(t)=G_{i}(t)-\frac{G_{i}(t)^{T}G_{\text{avg}}(t)}{G_{\text{avg}}(t)^{T}G_{\text{avg}}(t)}G_{\text{avg}}(t)$
    |  |'
  prefs: []
  type: TYPE_TB
- en: This slight relaxation of the constraints yields a huge improvement in computation
    time while maintaining the performance of GEM.
  prefs: []
  type: TYPE_NORMAL
- en: 'This exact update rule is adapted for the MTL setting in Yu et al. [[2020](#bib.bib165)]
    with a method named PCGrad. Besides the theoretical analysis in the paper, the
    PCGrad algorithm itself is near identical to A-GEM. The main difference is due
    to the difference in problem formulations: PCGrad is meant to be used when learning
    multiple tasks simultaneously, so multiple gradient vectors must be checked for
    conflicts with others at each update step. When combined with Soft Actor-Critic
    Haarnoja et al. [[2018](#bib.bib58)], PCGrad is able to successfully complete
    70% of the tasks in the MT50 benchmark of the Meta-World environment Yu et al.
    [[2019](#bib.bib164)], a challenging, recently proposed environment for multi-task
    and meta-learning with robotic manipulation tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: The success of gradient modulation methods demonstrate that minimizing the presence
    of conflicting gradients between tasks is an effective way to decrease negative
    transfer. Continuing to develop such methods may be an important part of MTL optimization
    in future research.
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 Knowledge Distillation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Originally introduced for compressing large ensembles of non-neural machine
    learning models into a single model Bucila et al. [[2006](#bib.bib23)], knowledge
    distillation has found many applications outside of its originally intended domain.
    In MTL, the most common use of knowledge distillation is to instill a single multi-task
    “student" network with the knowledge of many individual single-task “teacher"
    networks. Interestingly, the performance of the student network has been shown
    to surpass that of the teacher networks in some domains, making knowledge distillation
    a desirable method not just for saving memory, but also for increasing performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first applications of policy distillation for multi-task learning came
    from two separate papers at the same time (uploaded to arXiv on the exact same
    day!), namely Policy Distillation Rusu et al. [[2015](#bib.bib131)] and Actor-Mimic
    Parisotto et al. [[2015](#bib.bib119)]. Both of these methods are designed for
    reinforcement learning, and follow roughly the same template: For each task in
    a collection of tasks, use reinforcement learning to train a task specific policy
    to convergence, and after training, use supervised learning to train a single
    student policy to mimic the outputs of the task-specific teacher policies, such
    as with a mean-square error or cross-entropy loss. Additionally, Actor-Mimic includes
    a feature regression objective, where each teacher network has a corresponding
    feature prediction network which attempts to predict the hidden activations of
    the teacher network from the hidden activations of the student network. The gradients
    of this objective are propagated through the student network, so that the student
    network is trained to compute features which contain the same information as each
    teacher network. Actor-Mimic was also shown to demonstrate impressive transfer
    performance. Transfer to new tasks was performed by removing the last layer of
    the distilled student policy and using the weights as the initialization for a
    single-task policy. The transferred policies were able to learn some new tasks
    faster than policies trained from scratch, though occasionally this transfer would
    slow down learning on new tasks. Also, both of these papers show similar results
    for the student network in the Atari domain: the distilled student network either
    matches or outperforms the single-task teachers. This is somewhat surprising,
    given that the student network is not trained to maximize in-game reward, it is
    only trained to mimic the behavior of the teacher networks.'
  prefs: []
  type: TYPE_NORMAL
- en: A common intuitive explanation for the phenomenon of student networks outperforming
    their teachers is that the student networks are provided with a more rich training
    signal than the teacher. For example, in classification, each single-task network
    is provided with a ground truth label for each input in the form of a one-hot
    vector. Meanwhile, the student’s training signal will be a “softer" version of
    this, namely the teachers’ output, a dense vector which may contain information
    about similarity of classes to the ground-truth class and other information not
    found in the ground truth one-hot vector.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/68b23ffaabb623573c136443b6295301.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22: Two architectures from the Distral framework for RL Teh et al. [[2017](#bib.bib149)].
    On the left is an architecture which employs both of the main ideas behind Distral:
    KL-regularization of single-task policies with the multi-task policy and a two-column
    policy for each task, where one column is shared between all tasks. On the right
    is an architecture which only employs KL-regularization of the single-task policies.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is interesting to note that most knowledge distillation algorithms (these
    two included) have an asymmetric information flow between student and teacher,
    namely that information travels from teacher to student, but not the other way
    around. This observation raises the question: should the single-task teacher networks
    receive information from the distilled multi-task student network? This isn’t
    possible with the methods discussed so far, since the teacher networks are done
    training before the student network starts it. On the other hand, the Distral
    framework for multi-task reinforcement learning Teh et al. [[2017](#bib.bib149)]
    provides a setting which accomplishes exactly this symmetric information flow
    between student and teacher. Distral is a very general framework which leads to
    several different loss functions and architectures, though each variant is driven
    by one or both of two main ideas: The single-task policies are regularized by
    minimizing the KL-divergence between single-task policies and the shared multi-task
    policy as a part of the training objective, and the policies for each task are
    formed by adding the output of the corresponding single-task policy with the output
    of the shared multi-task policy. Two of the resulting architecture variants are
    pictured in figure [22](#S3.F22 "Figure 22 ‣ 3.5 Knowledge Distillation ‣ 3 Optimization
    for Multi-Task Learning ‣ Multi-Task Learning with Deep Neural Networks: A Survey").
    The details of each variation and the motivation behind the design choices can
    be found in the original work. It should be noted, though, that the lines between
    different approaches to multi-task RL being to blur when considering Distral.
    This framework does not use knowledge distillation in the same sense as Policy
    Distillation and Actor-Mimic, since the shared multi-task network isn’t explicitly
    trained to mimic the outputs of the single-task network.'
  prefs: []
  type: TYPE_NORMAL
- en: Most recently, knowledge distillation was applied to multi-task NLP with MT-DNN
    ensembles Liu et al. [[2019c](#bib.bib97)] and Born-Again Multi-tasking networks
    (BAM) Clark et al. [[2019](#bib.bib32)]. Both works mainly use the original template
    for multi-task knowledge distillation, but the authors of BAM also introduce a
    training trick to help student networks surpass their teachers which they name
    teacher annealing. For model input $x$, ground truth label $y$, and teacher output
    $f_{T}(x)$, the usual target output for the student on a given example $x$ is
    $f_{T}(x)$. With teacher annealing, the student’s target output is replaced by
    $\lambda y+(1-\lambda)f_{T}(x)$, where $\lambda$ is linearly annealed from 0 to
    1 throughout student training. This way, by the end of the student training process,
    the student is trying to output the ground truth labels for each input and is
    no longer trying to mimic the teacher, so that the student isn’t inherently limited
    by the teacher’s weaknesses. Ablation studies in this work show that teacher annealing
    does improve student performance on the GLUE benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6 Multi-Objective Optimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The need to optimize for multiple - possibly conflicting - loss functions is
    a fundamental difficulty of MTL. The standard formulation of machine learning
    involves the optimization of a single loss function, so that the methods created
    to solve such problems only consider a single loss function. As we’ve seen so
    far, most MTL methods circumvent this challenge by combining many loss functions
    into one using a weighted average, though this fix isn’t perfect. The map from
    a tuple of loss values $(\mathcal{L}_{1}(t),\mathcal{L}_{2}(t),...,\mathcal{L}_{N}(t))$
    to their weighted average $\sum_{i}\lambda_{i}\mathcal{L}_{i}(t)$ isn’t an injective
    mapping, meaning that some information is lost when we transform a collection
    of loss functions into a single weighted loss function ¹¹1It is a well known fact
    in mathematical analysis that there is no continuous injective mapping from $\mathbb{R}^{d}$
    to $\mathbb{R}$ for $d\geq 2$, so unfortunately there is no immediate candidate
    for a multi-task loss function which is superior to the weighted average in the
    sense of injectivity.. Constructing this weighted average also necessitates a
    choice of weights, which is prone to error. Using multi-objective optimization
    for MTL is an alternative optimization method which doesn’t suffer from these
    weaknesses.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multi-objective optimization is exactly the process of optimizing several objective
    functions simultaneously. Notice that in a multi-objective problem, there is not
    necessarily a solution which is a global minimum for all objective functions,
    meaning that typically there are no globally optimal solutions for multi-objective
    optimization problems. Instead, we consider solutions which are Pareto optimal.
    Pareto optimal solutions to a multi-objective problem are those for which the
    performance for any of the objectives can only be improved by worsening performance
    on another objective. In other words, Pareto optimal solutions represent the best
    feasible options for solving a multi-objective optimization problem, up to a trade-off
    between objectives. The set of Pareto optimal solutions to a multi-objective optimization
    problem is called the Pareto frontier, and is visualized in figure [23](#S3.F23
    "Figure 23 ‣ 3.6 Multi-Objective Optimization ‣ 3 Optimization for Multi-Task
    Learning ‣ Multi-Task Learning with Deep Neural Networks: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b1a2f6aa8e0b5c322882589cd2fa627e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 23: Visualization of Pareto optimal solutions for a two-objective optimization
    problem Dréo [[2006](#bib.bib44)]. The Pareto frontier is made of all points along
    the red curve.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite being a natural fit for MTL and a well-studied problem Miettinen [[1998](#bib.bib111)],
    it has only recently been applied to multi-task problems. Sener and Koltun [[2018](#bib.bib134)]
    brought gradient-based multi-objective optimization algorithms to the field of
    deep multi-task learning by extending the well known Multiple Gradient Descent
    Algorithm (MGDA) Désidéri [[2012](#bib.bib48)] to a form that scales well to the
    high dimensionality of deep learning problems. This is accomplished by minimizing
    an upper bound to the MGDA loss, and doing so incurs only a small amount of computational
    overhead compared to traditional MTL. Pareto Multi-Task Learning Lin et al. [[2019](#bib.bib88)]
    takes this extension one step further by generalizing the algorithm proposed in
    Sener and Koltun [[2018](#bib.bib134)] in order to compute multiple Pareto optimal
    solutions. Since no Pareto optimal solution is a priori superior to any other,
    a set of Pareto optimal solutions which is representative of the Pareto frontier
    is more flexible and likely more useful than a single solution. Pareto MTL works
    by decomposing the multi-objective optimization problem into multiple subproblems,
    each with varying preferences between objectives. Interestingly, the authors show
    that Pareto MTL and the algorithm presented in Sener and Koltun [[2018](#bib.bib134)]
    can actually be formulated as methods to compute adaptive loss weights, similar
    to those discussed in section [3.1](#S3.SS1 "3.1 Loss Weighting ‣ 3 Optimization
    for Multi-Task Learning ‣ Multi-Task Learning with Deep Neural Networks: A Survey").
    This is somewhat counterintuitive, since multi-objective optimization methods
    are intended to be of a fundamentally different nature than methods which optimize
    a weighted average over loss functions. With further exploration, the surprising
    connection between these two directions could potentially lead to a better understanding
    of existing multi-task optimization methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Task Relationship Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have now discussed MTL architectures and optimization methods, completing
    a broader analogue of the popular dichotomy specified by hard and soft parameter
    sharing. However, there is a lesser known third wheel to this pair of approaches:
    task relationship learning. Task relationship learning (or TRL) is a separate
    approach that doesn’t quite fit into either architecture design or optimization,
    and is more specific to MTL. The goal of TRL is to learn an explicit representation
    of tasks or relationships between tasks, such as clustering tasks into groups
    by similarity, and leveraging the learned task relationships to improve learning
    on the tasks at hand.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section we discuss three research directions within TRL. The first is
    grouping tasks, where the goal is to partition a collection of tasks into groups
    such that simultaneous training of tasks in a group is beneficial. The second
    is learning transfer relationships, which includes methods that attempt to analyze
    and understand when transferring knowledge from one task to another is beneficial
    for learning. Finally, we discuss task embedding methods, which learn an embedding
    space for tasks themselves.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Grouping Tasks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As a solution to negative transfer, many MTL methods are designed to adaptively
    share information between related tasks and separate information from tasks which
    might hurt each other’s learning. The papers discussed here use task grouping
    as an alternative solution: if two tasks exhibit negative transfer, simply separate
    their learning from the start. However, doing so requires significant computation
    time for trial and error in training networks jointly for various sets of tasks,
    and there are currently very few methods which can accurately determine the joint
    learning dynamics of groups of tasks without this kind of brute force trial and
    error.'
  prefs: []
  type: TYPE_NORMAL
- en: Two early concurrent works of learning to group tasks are Alonso and Plank [[2016](#bib.bib6)]
    and Bingel and Søgaard [[2017](#bib.bib19)]. Both of these papers are empirical
    studies analyzing the effectiveness of various task groupings in MTL for natural
    language processing, with a focus on choosing one or two auxiliary tasks (such
    as POS tagging, syntactic chunking, and word counting) to help learning on a main
    task (such as named entity recognition and semantic frame detection) by training
    a multi-task network on many combinations of tasks. In these studies, a single-task
    network is trained for each individual main task, and its performance is compared
    to the performance of a multi-task network trained on the main task jointly with
    one or two auxiliary tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Alonso and Plank [[2016](#bib.bib6)] trains 1440 task combinations, each with
    a main task and one or two auxiliary tasks, and finds that performance on the
    main task improves the most with auxiliary tasks whose label distributions have
    high entropy and low kurtosis. This is consistent with the findings of Bingel
    and Søgaard [[2017](#bib.bib19)], in which 90 pairs of tasks (one main, one auxiliary)
    are trained. Using the results of these training runs as data, this work trains
    a logistic regression model to predict whether an auxiliary task will help or
    hurt main task performance based on features from the datasets and learning curves
    of the two tasks. They also find that entropy of the auxiliary label distribution
    is highly correlated with improvement on the main task, though the features most
    highly correlated with main task improvement are the gradients of the main task
    learning curve when trained on its own. Specifically, if the learning curve of
    a task (when trained in a single-task setup) begins to plateau during the first
    20% to 30% of training, including an auxiliary task in training is likely to improve
    the performance on the main task. The authors speculate that this may be because
    a main task whose learning curve has an early plateau is likely to be stuck in
    a non-optimal local minimum, and the inclusion of an auxiliary task helps the
    optimization process to escape this minimum. Somewhat surprising is their finding
    that the difference in sizes of the main and auxiliary task dataset was not found
    to be indicative of the main task performance gain when including the auxiliary
    task. Despite the fact that these studies don’t treat all tasks identically, as
    is usually the case with MTL, the conditions they find which imply positive transfer
    between tasks are general enough that they may be useful in the multi-task setting.
  prefs: []
  type: TYPE_NORMAL
- en: An empirical study on the joint training of computer vision tasks is performed
    in Doersch and Zisserman [[2017](#bib.bib42)], with a focus on self-supervised
    tasks, namely relative position regression, colorization, motion segmentation,
    and exemplar matching. This study is less in-depth, as it is not the sole focus
    of the paper, but the authors come to the interesting conclusion that multi-task
    training always improved performance compared to the single-task baselines. This
    fact is very surprising given the inconsistency of improvement that MTL usually
    affords over single-task training. The consistent improvement may be due to the
    relationships between the tasks or the nature of their self-supervised labels,
    but none of these answers are certain.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/cbd33de1d0d03002edfce2ea201a188b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 24: An example partitioning of a group of tasks into clusters with positive
    transfer Standley et al. [[2019](#bib.bib142)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'Adjacent to these empirical studies to analyze multi-task task relationships
    is a principled method for learning these relationships online during training
    without trial-and-error task grouping, called Selective Sharing Strezoski et al.
    [[2019b](#bib.bib144)]. Selective sharing uses a shared trunk architecture to
    handle multiple tasks, and clusters tasks into groups based on the similarity
    of their gradient vectors throughout training. This clustering is motivated by
    the fact that the task-specific branches are all initialized with identical parameters,
    so that the similarity between task gradients is indicative of the similarity
    of tasks. As the clusters of tasks are updated throughout training, the task branches
    of the network are merged so that tasks which are clustered together share parameters,
    and this process continues until the clusters stop changing. Aside from the obvious
    benefit of decreased computation cost compared to large scale empirical studies
    to determine groups of tasks, this method uses learned task features to understand
    the relationships between tasks, which is a powerful and inexpensive approach
    to TRL that is also employed in Kriegeskorte [[2008](#bib.bib76)], Song et al.
    [[2019](#bib.bib140)] (see section [4.2](#S4.SS2 "4.2 Transfer Relationships ‣
    4 Task Relationship Learning ‣ Multi-Task Learning with Deep Neural Networks:
    A Survey") for further discussion). It should be noted, however, that their model
    is based on an assumption which breaks down more and more during training. It
    may be true that gradient vectors are indicative of task similarity at the beginning
    of training, when parameters across tasks are still relatively similar. But as
    training continues and model parameters get further apart, similarity between
    task gradients becomes less and less representative of the similarity between
    tasks, and this signal will devolve into noise with a sufficiently non-convex
    loss landscape. Still, the approach is empirically shown to be effective for computing
    task relationships with proper configuration.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most recently, Standley et al. [[2019](#bib.bib142)] includes an in-depth empirical
    study of task grouping with the Taskonomy dataset Zamir et al. [[2018](#bib.bib166)]
    and a method to partition a group of tasks into clusters which each exhibit positive
    transfer between their respective tasks. Such a partitioning of tasks is pictured
    in figure [24](#S4.F24 "Figure 24 ‣ 4.1 Grouping Tasks ‣ 4 Task Relationship Learning
    ‣ Multi-Task Learning with Deep Neural Networks: A Survey"). Using four different
    training settings with varying amounts of training data and network sizes to train
    each pair of tasks within groups of five tasks, the authors find several interesting
    trends with a more thorough analysis than the previous studies. First, there were
    mixed results on whether or not multi-task training improved over the single-task
    baselines, with many multi-task networks performing worse than the single-task
    counterparts. Next, the performance gain from single-task to multi-task training
    varies wildly with the training setting, implying that the effectiveness of MTL
    is not as dependent on the relationship of the tasks themselves as we might have
    once thought. Surprisingly, the study also finds no correlation between the multi-task
    affinity and the transfer affinity between tasks, which again shows that there
    are many more factors behind joint task learning dynamics (in both multi-task
    and transfer learning) than just the nature of the tasks in consideration. To
    find a partition of a group of tasks into clusters with desirable learning dynamics,
    this work uses both approximations of the performance of multi-task networks at
    convergence and a branch-and-bound algorithm that uses these approximations to
    select a set of multi-task networks to collectively perform all tasks. Using this
    method of grouping tasks, the resulting multi-task networks consistently outperform
    the single task baselines, which is a vast improvement over the multi-task setups
    from the empirical study in which every single pair of tasks is trained jointly.
    To our knowledge, this is the only computational framework for deciding which
    tasks to train together in multi-task learning that allows for more than two tasks
    to be trained jointly.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Transfer Relationships
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Learning transfer relationships between tasks in MTL is related to the problem
    of learning to group tasks for joint learning, though they don’t always correlate,
    as noted above. However, unlike learning tasks simultaneously, transfer learning
    already plays an important role in the wider deep learning research effort; most
    natural language processing and computer vision models start not from scratch,
    but transferring a pre-trained model to use on a new task. Be that as it may,
    research into methods that can explicitly learn transfer relationships between
    tasks is only somewhat recent. With the large existing applicability of transfer
    learning today, these methods have the potential to make a strong impact on the
    larger research community.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first (and certainly most well known) work which attempted to learn transfer
    affinities between tasks is Taskonomy Zamir et al. [[2018](#bib.bib166)]. Aside
    from the Taskonomy dataset with 4 million images labeled for 26 tasks, this paper
    introduces a computational method to automatically construct a taxonomy of visual
    tasks based on transfer relationships between tasks. To do this, a single-task
    network is trained on each individual task, then transfer relationships are computed
    by answering the following question for each pair of tasks: How well can we perform
    task $i$ by training a decoder on top of a feature extractor which was trained
    on task $j$? This is a bit of a simplification, as the actual training setup involves
    transferring from multiple source tasks to a single target task, but the main
    idea is the same. Once the transfer affinities are computed, the problem of constructing
    a task taxonomy is characterized as choosing the ideal source task or tasks for
    each target task in a way that satisfies a budget on the number of source tasks.
    The motivation here is to limit the number of tasks which have access to the full
    amount of supervised data (these are the source tasks), and to learn the remainder
    of tasks by transferring from the source tasks, with only a small amount of training
    data to train the decoder on top of the transferred feature extractor. The problem
    of choosing the ideal set of source tasks and which source tasks to use for each
    target task (given the task transfer affinities) is encoded as a Boolean Integer
    Programming problem. The solution can be represented as a directed graph in which
    the nodes are tasks, and the presence of an edge from task $i$ to task $j$ means
    that task $i$ is included in the set of source tasks for task $j$. Some resulting
    taxonomies for varying supervision budgets and transfer order (maximum number
    of source tasks for each target task) are shown in figure [25](#S4.F25 "Figure
    25 ‣ 4.2 Transfer Relationships ‣ 4 Task Relationship Learning ‣ Multi-Task Learning
    with Deep Neural Networks: A Survey"). Taskonomy is the first large scale empirical
    study to analyze task transfer relationships and compute an explicit hierarchy
    of tasks based on their transfer relationships, and by doing so they are able
    to compute optimal transfer policies for learning a group of related tasks with
    limited supervision. However, their method of doing so is extremely expensive,
    since it involves training for a huge number of combinations of source/target
    tasks. The entire process of constructing task taxonomies took 47,886 GPU hours.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e148affc72c9e60ebf3cf7af46ded8f6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 25: Task taxonomies for a collection of computer vision tasks as computed
    in Taskonomy Zamir et al. [[2018](#bib.bib166)]. An edge from task $i$ to task
    $j$ denotes that task $i$ is an ideal source task to perform transfer learning
    on task $j$.'
  prefs: []
  type: TYPE_NORMAL
- en: A similarly inspired but much more efficient method for learning task transfer
    relationships is introduced in Dwivedi and Roig [[2019](#bib.bib47)], which uses
    Representation Similarity Analysis (RSA) Kriegeskorte [[2008](#bib.bib76)] to
    compute a measure of similarity between tasks. RSA is a commonly used tool in
    computational neuroscience to quantitatively compare measures of neural activity,
    and it has been adopted for analyzing neural network activations by the deep learning
    community in recent years Vandenhende et al. [[2019](#bib.bib151)]. The underlying
    assumption behind the RSA transfer model in Dwivedi and Roig [[2019](#bib.bib47)]
    is that if two tasks would exhibit positive transfer, then single-task networks
    trained on each of them will tend to learn similar representations, and so RSA
    will be an accurate measure of the transfer affinities of the task at hand. Because
    RSA only involves comparing the representations of different networks, there is
    no need to actually perform any transfer learning between each pair of tasks,
    making the RSA transfer model orders of magnitude faster than Taskonomy. Furthermore,
    the authors find that the computed task affinities from RSA are nearly independent
    of the size of the models used to train on the tasks, so that the computation
    of the task relationships can be done with very small models in order to cut computation
    cost even more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most recently, Song et al. [[2019](#bib.bib140)] follows a similar approach
    as the RSA transfer model: compare the similarity of single-task networks to compute
    task transfer affinities, instead of actually performing transfer learning. Instead
    of comparing the networks’ learned representations, the method presented in Song
    et al. [[2019](#bib.bib140)] compares their attribution maps on the same input
    data. An attribution map is a scoring over the individual units of a network’s
    input which represents the relevance of each unit to the network’s output. In
    computer vision, for example, an attribution map assigns a relevance score to
    each pixel in the input. Just as the RSA transfer model assumes that tasks with
    positive transfer will learn similar representations, the attribution map transfer
    model assumes that such tasks will pay attention to the same parts of an input.
    This approach shows similar results as the RSA transfer model: orders of magnitude
    speedup compared to Taskonomy without degradation of the results. Unfortunately,
    this work doesn’t include any direct comparison with the RSA transfer model, so
    there is no evidence of superiority of either model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The existing methods for learning task transfer relationships are all very
    recent, and there is much more work to be done in this area. One interesting thing
    to note is the manner in which the RSA and attribution map transfer models Kriegeskorte
    [[2008](#bib.bib76)], Song et al. [[2019](#bib.bib140)] achieve efficiency while
    computing nontrivial information. To summarize succinctly, these models use the
    network to train the network. Both methods leverage information learned by the
    single-task networks (either intermediate representations or relevance scoring)
    in order to inform training downstream. Taskonomy, on the other hand, trains extra
    networks to do what these two methods did without any extra training. It goes
    to show that the rich information learned by deep networks isn’t only useful for
    the network’s forward pass. In general, even outside of MTL, this information
    can and should be leveraged to further inform model training: Use the network
    to train the network.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Task Embeddings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although they are mostly used for meta-learning, task embeddings are a very
    general form of learning task relationships, and are strongly related to the methods
    we have so far discussed in this section. Even with this strong tie between models,
    there is a significant lack of methods in MTL which utilize task embeddings. This
    shouldn’t come as a surprise, though. Task embeddings find their most use in situations
    where a new task is given after already learning a number of tasks from the same
    distribution, and this new task must be localized with respect to tasks already
    learned. If the set of tasks for a model to learn is fixed - as is the case with
    MTL - why should one assign a vector representation to each task? Still, we feel
    that the connection to TRL is important, so we provide a brief summary of several
    task embedding methods in the meta-learning literature.
  prefs: []
  type: TYPE_NORMAL
- en: James et al. [[2018](#bib.bib68)] uses metric learning to construct a task embedding
    for imitation learning of various robotic manipulation tasks. This model, named
    TecNet, is comprised of an embedding network and a control network. The embedding
    network produces a vector representation of a task given many examples from that
    task, while the control network takes an observation and a task representation
    as input to produce an action. Instead of computing a task embedding from expert
    demonstrations, Achille et al. [[2019](#bib.bib1)] constructs them from the Fisher
    Information Matrix of a pre-trained network. Lastly, Lan et al. [[2019](#bib.bib81)]
    trains a shared policy for meta-reinforcement learning which is conditioned on
    task embeddings. These task embeddings are the outputs of a task encoder which
    is trained to output embeddings based on experience from each task.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Multi-Task Benchmarks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we give a short overview of commonly used benchmarks in various
    domains of multi-task learning, including benchmarks for computer vision, natural
    language processing, reinforcement learning, and multi-modal problems. It should
    be noted that, while there are a few benchmarks specifically designed for multi-task
    learning (such as Taskonomy Zamir et al. [[2018](#bib.bib166)] and Meta-World
    Yu et al. [[2019](#bib.bib164)]), these are few and far between. Most MTL methods
    are evaluated in multi-task settings which use generic benchmarks that include
    supervision for multiple tasks, such as NYU-v2 Silberman et al. [[2012](#bib.bib137)].
    Lastly, the benchmarks discussed here aren’t an exhaustive list, just a highlight
    of some of the most commonly used MTL benchmarks. The benchmarks within each domain
    are sorted by release date starting with the earliest.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Computer Vision Benchmarks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NYU-v2 Silberman et al. [[2012](#bib.bib137)] is a dataset of RGB-depth images
    from 464 indoor scenes with 1449 densely labeled images and over 400,000 unlabeled
    images. The labeled images are labeled for instance segmentation, semantic segmentation,
    and scene classification, and all images contain depth values for each pixel.
    All images are frames extracted from video sequences.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MS-COCO Lin et al. [[2014](#bib.bib86)] contains 328,000 images of natural scenes
    with a total of 2.5 million object instances spanning 91 object types. The images
    contain labels for image classification, semantic segmentation, and instance segmentation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CelebA Liu et al. [[2015b](#bib.bib98)] has 200,000 images of celebrity faces,
    with 20 images of 10,000 different people. Each image is labeled with 40 face
    attributes and five keypoints, for a total of 8 million facial attribute labels.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OmniGlot Lake et al. [[2015](#bib.bib80)] contains images of characters, unlike
    many of the other popular natural image benchmarks. The dataset contains images
    of 1623 characters from 50 different alphabets, operating in a low-data regime.
    Omniglot was designed with a focus on few-shot learning and meta-learning in image
    classification and generative modeling.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CityScapes Cordts et al. [[2016](#bib.bib35)] is comprised of video frames shot
    in the streets of 50 urban cities. The densely labeled subset of the dataset contains
    5000 images with pixel-level annotations, while 20000 other images are coarsely
    labeled. The images are labeled for image classification, semantic segmentation,
    and instance segmentation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taskonomy Zamir et al. [[2018](#bib.bib166)] may be the only large scale computer
    vision dataset specifically intended for research with multi-task learning. The
    dataset consists of 4 million images of indoor scenes from 600 different buildings,
    and each image is annotated for 26 different visual tasks, including 2D, 2.5D,
    and 3D tasks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 5.2 Natural Language Processing Benchmarks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unless otherwise specified, it can be assumed that the text within a corpus
    is English.
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Penn Treebank Marcus et al. [[1993](#bib.bib108)] is a corpus of text consisting
    of 4.5 million words. The text is aggregated from multiple sources including scientific
    abstracts, news stories, book chapters, computer manuals, and more, and contains
    Part-of-Speech tags and syntactical structure annotations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OntoNotes 5.0 Weischedel et al. [[2013](#bib.bib154)] is a multi-lingual corpus
    of Arabic, English, and Chinese text with 2.9 million words total, labeled for
    syntax and predicate argument structure, coreference resolution, and word sense
    disambiguation. The text sources consist of written news, broadcast news, web
    data, and more.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WMT 14 Bojar et al. [[2014](#bib.bib20)] is a dataset from the 2014 Workshop
    on Statistical Machine Translation, with parallel corpuses of many language pairs,
    including French-English, German-English, Hindi-English, Russian-English, and
    Czech-English. These corpuses vary in size between 90 million total English sentences
    and 1 million total Hindi sentences.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stanford Natural Language Inference Bowman et al. [[2015](#bib.bib21)] contains
    570,000 sentence pairs, where each pair contains a label describing their relationship
    as either neutral, entailment, or contradiction. The dataset was acquired through
    Amazon Turk, with the instructions displaying a captioned image and asking for
    one alternative caption, one caption that may be correct, and one caption that
    is certainly incorrect.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SciTail Khot et al. [[2018](#bib.bib73)] is a textual entailment dataset consisting
    of scientific statements. The corpus was constructed by converting multiple choice
    questions on science exams (and web data) into entailed and non-entailed pairs,
    for a total of 27,000 total examples.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GLUE Wang et al. [[2018](#bib.bib153)] consists of nine NLP tasks accompanied
    with data from previously existing NLP corpuses. The benchmark is intended to
    be used to evaluate general language understanding models that can handle all
    or multiple tasks simulataneously. Some tasks are intentionally provided with
    small amounts of training data to encourage information sharing between tasks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'decaNLP McCann et al. [[2018](#bib.bib109)] is a collection of ten NLP tasks
    which are all posed as question answering. This is a new approach to NLP benchmarking:
    instead of the task being specified by explicit constraints on the input/output,
    each task is given to the model with a description in natural language. Each example
    is a 3-tuple of question, context, and answer.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 5.3 Reinforcement Learning Benchmarks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arcade Learning Environment Bellemare et al. [[2013](#bib.bib14)] (or ALE) is
    a diverse collection of hundreds of Atari 2600 games, where observations are given
    to the agent as raw pixels. These games were originally designed to be a challenge
    for the human video game player, so they present a challenge for modern RL agents
    in aspects such as exploration and learning with sparse rewards.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DeepMind Lab Beattie et al. [[2016](#bib.bib13)] is a 3D first person game platform
    which requires the agent to make actions from raw pixels. DeepMind Lab offers
    the ability to customize environments through the observations, termination conditions,
    reward functions, and more. The 3D nature of the environment makes for a challenge
    not just in strategic decision making but also in perception.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meta-World Yu et al. [[2019](#bib.bib164)] is a collection of robotic manipulation
    tasks designed to encourage research in multi-task learning and meta-learning.
    The collection consists of 50 tasks for a simulated Sawyer robotic arm, each task
    with its own parametric variations, such as goal position. The multi-task benchmarks
    within Meta-World are MT10 and MT50, which consist of simultaneously learning
    10 and 50 tasks, respectively, while the meta-learning benchmarks are ML10 and
    ML45, which consist of learning on 10 and 45 tasks before being asked to quickly
    adapt to new unseen tasks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 5.4 Multi-Modal Benchmarks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flickr30K Captions Young et al. [[2014](#bib.bib163)] is a collection of 30,000
    photographs obtained from the image hosting website Flickr, with over 150,000
    corresponding captions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MS-COCO Captions Chen et al. [[2015](#bib.bib29)] contains over 1.5 million
    captions of more than 300,000 photos from the MS-COCO Lin et al. [[2014](#bib.bib86)]
    dataset. These captions were collected using Amazon Mechanical Turk.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visual Genome Krishna et al. [[2017](#bib.bib77)] is made of over 100,000 densely
    annotated images with a focus on a grounding connection between visual and linguistic
    concepts. Each image contains over 40 regions which each have their own description,
    17 (on average) question-answer pairs per image, an average of 21 object annotations
    per image, attribute labels per object, and relationship annotations between objects.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flickr30K Entities Plummer et al. [[2015](#bib.bib123)] augments the Flickr30K
    dataset with 276,000 annotated bounding boxes and 244,000 coreference chains.
    The coreference chains identify when references to objects in different captions
    of the same image are referring to the same object.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GuessWhat?! De Vries et al. [[2017](#bib.bib38)] is not just a dataset, but
    a dialogue-based guessing game in which a questioner asks an oracle about an unknown
    object pictured in a given image. The paper includes a collection of 150,000 games
    played by humans, with 800,000 visual question answer pairs on 66,000 images.
    The intention of GuessWhat?! is to introduce a task which bridges visual question
    answering with dialogue.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VQA 2.0 Goyal et al. [[2017](#bib.bib56)] is a visual question answering dataset
    constructed by balancing the VQA Antol et al. [[2015](#bib.bib9)] dataset with
    a focus on the visual aspect of visual question answering. The paper points out
    that a model can reach decent performance on many VQA benchmarks based only on
    scene regularities and the question at hand while ignoring the visual input. VQA
    2.0 is balanced in the sense that every question is accompanied by two images
    that lead to different answers, so that a successful model must pay attention
    to the visual content of a given image.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GQA Hudson and Manning [[2019](#bib.bib65)] is another visual question answering
    dataset, constructed by leveraging scene graphs to create 22 million questions
    for their corresponding images. The programmatic construction of the dataset allowed
    for each question to be accompanied by a functional program which characterizes
    the question semantics, and for the distribution of answers to be tuned to minimize
    bias.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 6 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have presented a review of the field of multi-task learning, covering the
    three broad directions of architecture design, optimization techniques, and task
    relationship learning. Currently, key techniques for the construction of multi-task
    neural networks include shared feature extractors with task-specific decoders,
    varying parameter sharing schemes in existing network architectures, sharing and
    recombination of neural network modules, learning what to share, and fine-grained
    parameter sharing. The most prominent directions within optimization are per-task
    loss weighting, such as by uncertainty or learning speed, regularization with
    $L_{2}$ and trace norms, gradient modulation and replacement to avoid conflicting
    gradients between tasks, and multi-objective optimization. Finally, several methods
    have been proposed to learn relationships between tasks, such as large-scale empirical
    studies to determine which tasks exhibit positive learning dynamics when learned
    simultaneously, comparing representations of networks to determine task similarity,
    and learning task embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite the progress the community has made so far to develop multi-task learning
    for deep networks, there is one direction of research that has had less development
    than others, and that we have not discussed at all so far: theory. This shouldn’t
    come as a surprise, given that this is also true of deep learning in general.
    Still, many non-neural multi-task learning methods are motivated and justified
    by strong theory Baxter [[2000](#bib.bib12)], Ben-David and Borbely [[2008](#bib.bib15)],
    Zhang [[2015](#bib.bib169)], Lounici et al. [[2009](#bib.bib101)], but aside from
    a small pool of recent work Shui et al. [[2019](#bib.bib136)], Ndirango and Lee
    [[2019](#bib.bib114)], D’Eramo et al. [[2020](#bib.bib39)], Wu et al. [[2020](#bib.bib157)],
    Zhang et al. [[2020](#bib.bib168)], Bettgenhäuser et al. [[2020](#bib.bib18)],
    there is a lack of theoretical understanding of MTL with deep neural networks.
    This is an important area to promote a deeper understanding of the field as a
    whole, and we hope to see more development in this direction in the coming years.'
  prefs: []
  type: TYPE_NORMAL
- en: We believe that the development of multi-task learning (and the related fields
    of meta-learning, transfer learning, and continuous/lifelong learning) is an important
    step towards developing artificial intelligence with more human-like qualities.
    In order to build machines that can learn as quickly and robustly as humans, we
    must create techniques for learning general underlying concepts which are applicable
    between tasks and applying these concepts to new and unfamiliar situations. Building
    systems that truly exhibit these qualities will require approaches from many different
    directions, likely including many that researchers haven’t yet discovered. The
    field has come a long way, but continued effort from the research community is
    needed to fully achieve the potential of multi-task methods.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Achille et al. [2019] Alessandro Achille, Michael Lam, Rahul Tewari, Avinash
    Ravichandran, Subhransu Maji, Charless C Fowlkes, Stefano Soatto, and Pietro Perona.
    Task2vec: Task embedding for meta-learning. In *Proceedings of the IEEE International
    Conference on Computer Vision*, pages 6430–6439, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ahn et al. [2019] Chanho Ahn, Eunwoo Kim, and Songhwai Oh. Deep elastic networks
    with model selection for multi-task learning. In *Proceedings of the IEEE International
    Conference on Computer Vision*, pages 6529–6538, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akhtar et al. [2019] Md Shad Akhtar, Dushyant Singh Chauhan, Deepanway Ghosal,
    Soujanya Poria, Asif Ekbal, and Pushpak Bhattacharyya. Multi-task learning for
    multi-modal emotion recognition and sentiment analysis. *arXiv preprint arXiv:1905.05812*,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akkaya et al. [2019] Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz
    Litwin, Bob McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell,
    Raphael Ribas, et al. Solving rubik’s cube with a robot hand. *arXiv preprint
    arXiv:1910.07113*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alet et al. [2018] Ferran Alet, Tomás Lozano-Pérez, and Leslie P Kaelbling.
    Modular meta-learning. *arXiv preprint arXiv:1806.10166*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alonso and Plank [2016] Héctor Martínez Alonso and Barbara Plank. When is multitask
    learning effective? semantic sequence prediction under varying data conditions.
    *arXiv preprint arXiv:1612.02251*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Andreas et al. [2016] Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan
    Klein. Neural module networks. In *Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition*, pages 39–48, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Andreas et al. [2017] Jacob Andreas, Dan Klein, and Sergey Levine. Modular multitask
    reinforcement learning with policy sketches. In *International Conference on Machine
    Learning*, pages 166–175, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Antol et al. [2015] Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret
    Mitchell, Dhruv Batra, C Lawrence Zitnick, and Devi Parikh. Vqa: Visual question
    answering. In *Proceedings of the IEEE international conference on computer vision*,
    pages 2425–2433, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Argyriou et al. [2008] Andreas Argyriou, Theodoros Evgeniou, and Massimiliano
    Pontil. Convex multi-task feature learning. *Machine Learning*, 73(3):243–272,
    January 2008. doi: 10.1007/s10994-007-5040-8. URL [https://doi.org/10.1007/s10994-007-5040-8](https://doi.org/10.1007/s10994-007-5040-8).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Baltrusaitis et al. [2019] Tadas Baltrusaitis, Chaitanya Ahuja, and Louis-Philippe
    Morency. Multimodal machine learning: A survey and taxonomy. *IEEE Trans. Pattern
    Anal. Mach. Intell.*, 41(2):423–443, February 2019. ISSN 0162-8828. doi: 10.1109/TPAMI.2018.2798607.
    URL [https://doi.org/10.1109/TPAMI.2018.2798607](https://doi.org/10.1109/TPAMI.2018.2798607).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baxter [2000] Jonathan Baxter. A model of inductive bias learning. *Journal
    of artificial intelligence research*, 12:149–198, 2000.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beattie et al. [2016] Charles Beattie, Joel Z Leibo, Denis Teplyashin, Tom Ward,
    Marcus Wainwright, Heinrich Küttler, Andrew Lefrancq, Simon Green, Víctor Valdés,
    Amir Sadik, et al. Deepmind lab. *arXiv preprint arXiv:1612.03801*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bellemare et al. [2013] Marc G Bellemare, Yavar Naddaf, Joel Veness, and Michael
    Bowling. The arcade learning environment: An evaluation platform for general agents.
    *Journal of Artificial Intelligence Research*, 47:253–279, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ben-David and Borbely [2008] Shai Ben-David and Reba Schuller Borbely. A notion
    of task relatedness yielding provable multiple-task learning guarantees. *Mach.
    Learn.*, 73(3):273–287, December 2008. ISSN 0885-6125. doi: 10.1007/s10994-007-5043-5.
    URL [https://doi.org/10.1007/s10994-007-5043-5](https://doi.org/10.1007/s10994-007-5043-5).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bengio et al. [2009] Yoshua Bengio, Jérôme Louradour, Ronan Collobert, and
    Jason Weston. Curriculum learning. In *Proceedings of the 26th Annual International
    Conference on Machine Learning*, ICML ’09, page 41–48, New York, NY, USA, 2009.
    Association for Computing Machinery. ISBN 9781605585161. doi: 10.1145/1553374.1553380.
    URL [https://doi.org/10.1145/1553374.1553380](https://doi.org/10.1145/1553374.1553380).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bengio et al. [2013] Yoshua Bengio, Nicholas Léonard, and Aaron Courville. Estimating
    or propagating gradients through stochastic neurons for conditional computation.
    *arXiv preprint arXiv:1308.3432*, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bettgenhäuser et al. [2020] Gabriele Bettgenhäuser, Michael A Hedderich, and
    Dietrich Klakow. Learning functions to study the benefit of multitask learning.
    *arXiv preprint arXiv:2006.05561*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bingel and Søgaard [2017] Joachim Bingel and Anders Søgaard. Identifying beneficial
    task relations for multi-task learning in deep neural networks. *arXiv preprint
    arXiv:1702.08303*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bojar et al. [2014] Ondřej Bojar, Christian Buck, Christian Federmann, Barry
    Haddow, Philipp Koehn, Johannes Leveling, Christof Monz, Pavel Pecina, Matt Post,
    Herve Saint-Amand, Radu Soricut, Lucia Specia, and Aleš Tamchyna. Findings of
    the 2014 workshop on statistical machine translation. In *Proceedings of the Ninth
    Workshop on Statistical Machine Translation*, pages 12–58, Baltimore, Maryland,
    USA, June 2014\. Association for Computational Linguistics. doi: 10.3115/v1/W14-3302.
    URL [https://www.aclweb.org/anthology/W14-3302](https://www.aclweb.org/anthology/W14-3302).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bowman et al. [2015] Samuel R. Bowman, Gabor Angeli, Christopher Potts, and
    Christopher D. Manning. A large annotated corpus for learning natural language
    inference. In *Proceedings of the 2015 Conference on Empirical Methods in Natural
    Language Processing*, pages 632–642, Lisbon, Portugal, September 2015\. Association
    for Computational Linguistics. doi: 10.18653/v1/D15-1075. URL [https://www.aclweb.org/anthology/D15-1075](https://www.aclweb.org/anthology/D15-1075).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bragman et al. [2019] Felix JS Bragman, Ryutaro Tanno, Sebastien Ourselin,
    Daniel C Alexander, and Jorge Cardoso. Stochastic filter groups for multi-task
    cnns: Learning specialist and generalist convolution kernels. In *Proceedings
    of the IEEE International Conference on Computer Vision*, pages 1385–1394, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bucila et al. [2006] Cristian Bucila, Rich Caruana, and Alexandru Niculescu-Mizil.
    Model compression. In *Proceedings of the 12th ACM SIGKDD International Conference
    on Knowledge Discovery and Data Mining*, KDD ’06, page 535–541, New York, NY,
    USA, 2006\. Association for Computing Machinery. ISBN 1595933395. doi: 10.1145/1150402.1150464.
    URL [https://doi.org/10.1145/1150402.1150464](https://doi.org/10.1145/1150402.1150464).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cases et al. [2019] Ignacio Cases, Clemens Rosenbaum, Matthew Riemer, Atticus
    Geiger, Tim Klinger, Alex Tamkin, Olivia Li, Sandhini Agarwal, Joshua D. Greene,
    Dan Jurafsky, Christopher Potts, and Lauri Karttunen. Recursive routing networks:
    Learning to compose modules for language understanding. In *Proceedings of the
    2019 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)*, pages
    3631–3648, Minneapolis, Minnesota, June 2019\. Association for Computational Linguistics.
    doi: 10.18653/v1/N19-1365. URL [https://www.aclweb.org/anthology/N19-1365](https://www.aclweb.org/anthology/N19-1365).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chang et al. [2018] Michael B Chang, Abhishek Gupta, Sergey Levine, and Thomas L
    Griffiths. Automatically composing representation transformations as a means for
    generalization. *arXiv preprint arXiv:1807.04640*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chaudhry et al. [2018] Arslan Chaudhry, Marc’Aurelio Ranzato, Marcus Rohrbach,
    and Mohamed Elhoseiny. Efficient lifelong learning with a-gem. *arXiv preprint
    arXiv:1812.00420*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen and Manning [2014] Danqi Chen and Christopher Manning. A fast and accurate
    dependency parser using neural networks. In *Proceedings of the 2014 Conference
    on Empirical Methods in Natural Language Processing (EMNLP)*, pages 740–750, Doha,
    Qatar, October 2014\. Association for Computational Linguistics. doi: 10.3115/v1/D14-1082.
    URL [https://www.aclweb.org/anthology/D14-1082](https://www.aclweb.org/anthology/D14-1082).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2018] Junkun Chen, Kaiyu Chen, Xinchi Chen, Xipeng Qiu, and Xuanjing
    Huang. Exploring shared structures and hierarchies for multiple nlp tasks. *arXiv
    preprint arXiv:1808.07658*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. [2015] Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam,
    Saurabh Gupta, Piotr Dollár, and C Lawrence Zitnick. Microsoft coco captions:
    Data collection and evaluation server. *arXiv preprint arXiv:1504.00325*, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. [2017] Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, and Andrew
    Rabinovich. Gradnorm: Gradient normalization for adaptive loss balancing in deep
    multitask networks, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chennupati et al. [2019] Sumanth Chennupati, Ganesh Sistu, Senthil Yogamani,
    and Samir A Rawashdeh. Multinet++: Multi-stream feature aggregation and geometric
    loss strategy for multi-task learning, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clark et al. [2019] Kevin Clark, Minh-Thang Luong, Urvashi Khandelwal, Christopher D
    Manning, and Quoc V Le. Bam! born-again multi-task networks for natural language
    understanding. *arXiv preprint arXiv:1907.04829*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Collobert and Weston [2008] Ronan Collobert and Jason Weston. A unified architecture
    for natural language processing: Deep neural networks with multitask learning.
    In *Proceedings of the 25th International Conference on Machine Learning*, ICML
    ’08, page 160–167, New York, NY, USA, 2008\. Association for Computing Machinery.
    ISBN 9781605582054. doi: 10.1145/1390156.1390177. URL [https://doi.org/10.1145/1390156.1390177](https://doi.org/10.1145/1390156.1390177).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collobert et al. [2011] Ronan Collobert, Jason Weston, Léon Bottou, Michael
    Karlen, Koray Kavukcuoglu, and Pavel Kuksa. Natural language processing (almost)
    from scratch. *Journal of machine learning research*, 12(Aug):2493–2537, 2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cordts et al. [2016] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld,
    Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele.
    The cityscapes dataset for semantic urban scene understanding. In *Proceedings
    of the IEEE conference on computer vision and pattern recognition*, pages 3213–3223,
    2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Courbariaux et al. [2015] Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre
    David. Binaryconnect: Training deep neural networks with binary weights during
    propagations. In *Advances in neural information processing systems*, pages 3123–3131,
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dai et al. [2016] Jifeng Dai, Kaiming He, and Jian Sun. Instance-aware semantic
    segmentation via multi-task network cascades. In *Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition*, pages 3150–3158, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: De Vries et al. [2017] Harm De Vries, Florian Strub, Sarath Chandar, Olivier
    Pietquin, Hugo Larochelle, and Aaron Courville. Guesswhat?! visual object discovery
    through multi-modal dialogue. In *Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition*, pages 5503–5512, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: D’Eramo et al. [2020] Carlo D’Eramo, Davide Tateo, Andrea Bonarini, Marcello
    Restelli, and Jan Peters. Sharing knowledge in multi-task deep reinforcement learning.
    In *International Conference on Learning Representations*, 2020. URL [https://openreview.net/forum?id=rkgpv2VFvr](https://openreview.net/forum?id=rkgpv2VFvr).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Devin et al. [2017] Coline Devin, Abhishek Gupta, Trevor Darrell, Pieter Abbeel,
    and Sergey Levine. Learning modular neural network policies for multi-task and
    multi-robot transfer. In *2017 IEEE International Conference on Robotics and Automation
    (ICRA)*, pages 2169–2176\. IEEE, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. [2018] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. Bert: Pre-training of deep bidirectional transformers for language
    understanding. *arXiv preprint arXiv:1810.04805*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doersch and Zisserman [2017] Carl Doersch and Andrew Zisserman. Multi-task self-supervised
    visual learning. In *Proceedings of the IEEE International Conference on Computer
    Vision*, pages 2051–2060, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dong et al. [2015] Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and Haifeng Wang.
    Multi-task learning for multiple language translation. In *Proceedings of the
    53rd Annual Meeting of the Association for Computational Linguistics and the 7th
    International Joint Conference on Natural Language Processing (Volume 1: Long
    Papers)*, pages 1723–1732, Beijing, China, July 2015\. Association for Computational
    Linguistics. doi: 10.3115/v1/P15-1166. URL [https://www.aclweb.org/anthology/P15-1166](https://www.aclweb.org/anthology/P15-1166).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dréo [2006] Johann Dréo. Pareto front. *Wikipedia Commons*, 2006. URL [https://commons.wikimedia.org/wiki/File:Front_pareto.svg](https://commons.wikimedia.org/wiki/File:Front_pareto.svg).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Du et al. [2018] Yunshu Du, Wojciech M. Czarnecki, Siddhant M. Jayakumar, Razvan
    Pascanu, and Balaji Lakshminarayanan. Adapting auxiliary losses using gradient
    similarity, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Duong et al. [2015] Long Duong, Trevor Cohn, Steven Bird, and Paul Cook. Low
    resource dependency parsing: Cross-lingual parameter sharing in a neural network
    parser. In *Proceedings of the 53rd Annual Meeting of the Association for Computational
    Linguistics and the 7th International Joint Conference on Natural Language Processing
    (Volume 2: Short Papers)*, pages 845–850, Beijing, China, July 2015\. Association
    for Computational Linguistics. doi: 10.3115/v1/P15-2139. URL [https://www.aclweb.org/anthology/P15-2139](https://www.aclweb.org/anthology/P15-2139).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dwivedi and Roig [2019] Kshitij Dwivedi and Gemma Roig. Representation similarity
    analysis for efficient task taxonomy & transfer learning. In *Proceedings of the
    IEEE Conference on Computer Vision and Pattern Recognition*, pages 12387–12396,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Désidéri [2012] Jean-Antoine Désidéri. Multiple-gradient descent algorithm
    (mgda) for multiobjective optimization. *Comptes Rendus Mathematique*, 350(5):313
    – 318, 2012. ISSN 1631-073X. doi: https://doi.org/10.1016/j.crma.2012.03.014.
    URL [http://www.sciencedirect.com/science/article/pii/S1631073X12000738](http://www.sciencedirect.com/science/article/pii/S1631073X12000738).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Espeholt et al. [2018] Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan,
    Volodymir Mnih, Tom Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning,
    et al. Impala: Scalable distributed deep-rl with importance weighted actor-learner
    architectures. *arXiv preprint arXiv:1802.01561*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Evgeniou and Pontil [2004] Theodoros Evgeniou and Massimiliano Pontil. Regularized
    multi–task learning. In *Proceedings of the Tenth ACM SIGKDD International Conference
    on Knowledge Discovery and Data Mining*, KDD ’04, page 109–117, New York, NY,
    USA, 2004\. Association for Computing Machinery. ISBN 1581138881. doi: 10.1145/1014052.1014067.
    URL [https://doi.org/10.1145/1014052.1014067](https://doi.org/10.1145/1014052.1014067).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fernando et al. [2017] Chrisantha Fernando, Dylan Banarse, Charles Blundell,
    Yori Zwols, David Ha, Andrei A Rusu, Alexander Pritzel, and Daan Wierstra. Pathnet:
    Evolution channels gradient descent in super neural networks. *arXiv preprint
    arXiv:1701.08734*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Frankle and Carbin [2018] Jonathan Frankle and Michael Carbin. The lottery
    ticket hypothesis: Finding sparse, trainable neural networks. *arXiv preprint
    arXiv:1803.03635*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. [2019] Yuan Gao, Jiayi Ma, Mingbo Zhao, Wei Liu, and Alan L Yuille.
    Nddr-cnn: Layerwise feature fusing in multi-task cnns by neural discriminative
    dimensionality reduction. In *Proceedings of the IEEE Conference on Computer Vision
    and Pattern Recognition*, pages 3205–3214, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. [2020] Yuan Gao, Haoping Bai, Zequn Jie, Jiayi Ma, Kui Jia, and
    Wei Liu. Mtl-nas: Task-agnostic neural architecture search towards general-purpose
    multi-task learning. In *Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition*, pages 11543–11552, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gong et al. [2019] Ting Gong, Tyler Lee, Cory Stephenson, Venkata Renduchintala,
    Suchismita Padhy, Anthony Ndirango, Gokce Keskin, and Oguz H. Elibol. A comparison
    of loss weighting strategies for multi task learning in deep neural networks,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Goyal et al. [2017] Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra,
    and Devi Parikh. Making the v in vqa matter: Elevating the role of image understanding
    in visual question answering. In *Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition*, pages 6904–6913, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. [2018] Michelle Guo, Albert Haque, De-An Huang, Serena Yeung, and
    Li Fei-Fei. Dynamic task prioritization for multitask learning. In Vittorio Ferrari,
    Martial Hebert, Cristian Sminchisescu, and Yair Weiss, editors, *Computer Vision
    – ECCV 2018*, pages 282–299, Cham, 2018\. Springer International Publishing. ISBN
    978-3-030-01270-0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Haarnoja et al. [2018] Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey
    Levine. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning
    with a stochastic actor. *arXiv preprint arXiv:1801.01290*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hashimoto et al. [2016] Kazuma Hashimoto, Caiming Xiong, Yoshimasa Tsuruoka,
    and Richard Socher. A joint many-task model: Growing a neural network for multiple
    nlp tasks. *arXiv preprint arXiv:1611.01587*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. [2016] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep
    residual learning for image recognition. In *The IEEE Conference on Computer Vision
    and Pattern Recognition (CVPR)*, June 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heess et al. [2016] Nicolas Heess, Greg Wayne, Yuval Tassa, Timothy Lillicrap,
    Martin Riedmiller, and David Silver. Learning and transfer of modulated locomotor
    controllers. *arXiv preprint arXiv:1610.05182*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hessel et al. [2018] Matteo Hessel, Hubert Soyer, Lasse Espeholt, Wojciech Czarnecki,
    Simon Schmitt, and Hado van Hasselt. Multi-task deep reinforcement learning with
    popart, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hospedales et al. [2020] Timothy Hospedales, Antreas Antoniou, Paul Micaelli,
    and Amos Storkey. Meta-learning in neural networks: A survey. *arXiv preprint
    arXiv:2004.05439*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. [2018] Jie Hu, Li Shen, and Gang Sun. Squeeze-and-excitation networks.
    In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
    (CVPR)*, June 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hudson and Manning [2019] Drew A Hudson and Christopher D Manning. Gqa: A new
    dataset for real-world visual reasoning and compositional question answering.
    In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*,
    pages 6700–6709, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ioffe and Szegedy [2015] Sergey Ioffe and Christian Szegedy. Batch normalization:
    Accelerating deep network training by reducing internal covariate shift. *arXiv
    preprint arXiv:1502.03167*, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jaderberg et al. [2016] Max Jaderberg, Volodymyr Mnih, Wojciech Marian Czarnecki,
    Tom Schaul, Joel Z Leibo, David Silver, and Koray Kavukcuoglu. Reinforcement learning
    with unsupervised auxiliary tasks. *arXiv preprint arXiv:1611.05397*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: James et al. [2018] Stephen James, Michael Bloesch, and Andrew J Davison. Task-embedded
    control networks for few-shot imitation learning. *arXiv preprint arXiv:1810.03237*,
    2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jang et al. [2016] Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization
    with gumbel-softmax. *arXiv preprint arXiv:1611.01144*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jean et al. [2019] Sébastien Jean, Orhan Firat, and Melvin Johnson. Adaptive
    scheduling for multi-task learning. *arXiv preprint arXiv:1909.06434*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kaiser et al. [2017] Lukasz Kaiser, Aidan N Gomez, Noam Shazeer, Ashish Vaswani,
    Niki Parmar, Llion Jones, and Jakob Uszkoreit. One model to learn them all. *arXiv
    preprint arXiv:1706.05137*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kendall et al. [2017] Alex Kendall, Yarin Gal, and Roberto Cipolla. Multi-task
    learning using uncertainty to weigh losses for scene geometry and semantics, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Khot et al. [2018] Tushar Khot, A. Sabharwal, and Peter Clark. Scitail: A textual
    entailment dataset from science question answering. In *AAAI*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kirsch et al. [2018] Louis Kirsch, Julius Kunze, and David Barber. Modular
    networks: Learning to decompose neural computation. In *Advances in Neural Information
    Processing Systems*, pages 2408–2418, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Klein and Manning [2003] Dan Klein and Christopher D. Manning. Accurate unlexicalized
    parsing. In *Proceedings of the 41st Annual Meeting on Association for Computational
    Linguistics - Volume 1*, ACL ’03, page 423–430, USA, 2003. Association for Computational
    Linguistics. doi: 10.3115/1075096.1075150. URL [https://doi.org/10.3115/1075096.1075150](https://doi.org/10.3115/1075096.1075150).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kriegeskorte [2008] Nikolaus Kriegeskorte. Representational similarity analysis
    – connecting the branches of systems neuroscience. *Frontiers in Systems Neuroscience*,
    2008. doi: 10.3389/neuro.06.004.2008. URL [https://doi.org/10.3389/neuro.06.004.2008](https://doi.org/10.3389/neuro.06.004.2008).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Krishna et al. [2017] Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson,
    Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A
    Shamma, et al. Visual genome: Connecting language and vision using crowdsourced
    dense image annotations. *International journal of computer vision*, 123(1):32–73,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kulkarni et al. [2016] Tejas D Kulkarni, Karthik Narasimhan, Ardavan Saeedi,
    and Josh Tenenbaum. Hierarchical deep reinforcement learning: Integrating temporal
    abstraction and intrinsic motivation. In *Advances in neural information processing
    systems*, pages 3675–3683, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kumar and Daume III [2012] Abhishek Kumar and Hal Daume III. Learning task grouping
    and overlap in multi-task learning. *arXiv preprint arXiv:1206.6417*, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lake et al. [2015] Brenden M. Lake, Ruslan Salakhutdinov, and Joshua B. Tenenbaum.
    Human-level concept learning through probabilistic program induction. *Science*,
    350(6266):1332–1338, 2015. ISSN 0036-8075. doi: 10.1126/science.aab3050. URL [https://science.sciencemag.org/content/350/6266/1332](https://science.sciencemag.org/content/350/6266/1332).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lan et al. [2019] Lin Lan, Zhenguo Li, Xiaohong Guan, and Pinghui Wang. Meta
    reinforcement learning with task embedding and shared policy. *arXiv preprint
    arXiv:1905.06527*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee et al. [2016] Giwoong Lee, Eunho Yang, and Sung Hwang. Asymmetric multi-task
    learning based on task relatedness and loss. In Maria Florina Balcan and Kilian Q.
    Weinberger, editors, *Proceedings of The 33rd International Conference on Machine
    Learning*, volume 48 of *Proceedings of Machine Learning Research*, pages 230–238,
    New York, New York, USA, 20–22 Jun 2016\. PMLR. URL [http://proceedings.mlr.press/v48/leeb16.html](http://proceedings.mlr.press/v48/leeb16.html).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee et al. [2018] Hae Beom Lee, Eunho Yang, and Sung Ju Hwang. Deep asymmetric
    multi-task feature learning. In *International Conference on Machine Learning*,
    pages 2956–2964, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2016] Changsheng Li, Junchi Yan, Fan Wei, Weishan Dong, Qingshan
    Liu, and Hongyuan Zha. Self-paced multi-task learning. *arXiv preprint arXiv:1604.01474*,
    2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. [2018] Jason Liang, Elliot Meyerson, and Risto Miikkulainen. Evolutionary
    architecture search for deep multitask networks. In *Proceedings of the Genetic
    and Evolutionary Computation Conference*, pages 466–473, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. [2014] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
    Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. Microsoft coco:
    Common objects in context. In *European conference on computer vision*, pages
    740–755. Springer, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. [2017] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and
    Piotr Dollár. Focal loss for dense object detection. In *Proceedings of the IEEE
    international conference on computer vision*, pages 2980–2988, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. [2019] Xi Lin, Hui-Ling Zhen, Zhenhua Li, Qing-Fu Zhang, and Sam
    Kwong. Pareto multi-task learning. In *Advances in Neural Information Processing
    Systems*, pages 12060–12070, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. [2018] Hanxiao Liu, Karen Simonyan, and Yiming Yang. Darts: Differentiable
    architecture search. *arXiv preprint arXiv:1806.09055*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2016a] Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. Recurrent neural
    network for text classification with multi-task learning. *arXiv preprint arXiv:1605.05101*,
    2016a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2016b] Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. Deep multi-task
    learning with shared memory. *arXiv preprint arXiv:1609.07222*, 2016b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2017] Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. Adversarial multi-task
    learning for text classification. *arXiv preprint arXiv:1704.05742*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2019] S. Liu, E. Johns, and A. J. Davison. End-to-end multi-task
    learning with attention. In *2019 IEEE/CVF Conference on Computer Vision and Pattern
    Recognition (CVPR)*, pages 1871–1880, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2019a] Shengchao Liu, Yingyu Liang, and Anthony Gitter. Loss-balanced
    task weighting to reduce negative transfer in multi-task learning. In *Proceedings
    of the AAAI Conference on Artificial Intelligence*, volume 33, pages 9977–9978,
    2019a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. [2015a] Xiaodong Liu, Jianfeng Gao, Xiaodong He, Li Deng, Kevin
    Duh, and Ye-yi Wang. Representation learning using multi-task deep neural networks
    for semantic classification and information retrieval. In *Proceedings of the
    2015 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies*, pages 912–921, Denver, Colorado, May–June
    2015a. Association for Computational Linguistics. doi: 10.3115/v1/N15-1092. URL
    [https://www.aclweb.org/anthology/N15-1092](https://www.aclweb.org/anthology/N15-1092).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2019b] Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao.
    Multi-task deep neural networks for natural language understanding. *arXiv preprint
    arXiv:1901.11504*, 2019b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2019c] Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao.
    Improving multi-task deep neural networks via knowledge distillation for natural
    language understanding. *arXiv preprint arXiv:1904.09482*, 2019c.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2015b] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep
    learning face attributes in the wild. In *Proceedings of the IEEE international
    conference on computer vision*, pages 3730–3738, 2015b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. [2017] Mingsheng Long, Zhangjie Cao, Jianmin Wang, and S Yu Philip.
    Learning multiple tasks with multilinear relationship networks. In *Advances in
    neural information processing systems*, pages 1594–1603, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lopez-Paz and Ranzato [2017] David Lopez-Paz and Marc’Aurelio Ranzato. Gradient
    episodic memory for continual learning. In *Advances in neural information processing
    systems*, pages 6467–6476, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lounici et al. [2009] Karim Lounici, Massimiliano Pontil, Alexandre B Tsybakov,
    and Sara Van De Geer. Taking advantage of sparsity in multi-task learning. *arXiv
    preprint arXiv:0903.1468*, 2009.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. [2020] Jiasen Lu, Vedanuj Goswami, Marcus Rohrbach, Devi Parikh,
    and Stefan Lee. 12-in-1: Multi-task vision and language representation learning.
    In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    pages 10437–10446, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu et al. [2017] Yongxi Lu, Abhishek Kumar, Shuangfei Zhai, Yu Cheng, Tara Javidi,
    and Rogerio Feris. Fully-adaptive feature sharing in multi-task networks with
    applications in person attribute classification. In *Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition*, pages 5334–5343, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luong et al. [2015] Minh-Thang Luong, Quoc V Le, Ilya Sutskever, Oriol Vinyals,
    and Lukasz Kaiser. Multi-task sequence to sequence learning. *arXiv preprint arXiv:1511.06114*,
    2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ma et al. [2018] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and
    Ed H. Chi. Modeling task relationships in multi-task learning with multi-gate
    mixture-of-experts. In *Proceedings of the 24th ACM SIGKDD International Conference
    on Knowledge Discovery & Data Mining*, KDD ’18, page 1930–1939, New York, NY,
    USA, 2018\. Association for Computing Machinery. ISBN 9781450355520. doi: 10.1145/3219819.3220007.
    URL [https://doi.org/10.1145/3219819.3220007](https://doi.org/10.1145/3219819.3220007).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mallya et al. [2018] Arun Mallya, Dillon Davis, and Svetlana Lazebnik. Piggyback:
    Adapting a single network to multiple tasks by learning to mask weights. In *Proceedings
    of the European Conference on Computer Vision (ECCV)*, pages 67–82, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maninis et al. [2019] Kevis-Kokitsi Maninis, Ilija Radosavovic, and Iasonas
    Kokkinos. Attentive single-tasking of multiple tasks. In *Proceedings of the IEEE
    Conference on Computer Vision and Pattern Recognition*, pages 1851–1860, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Marcus et al. [1993] Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz.
    Building a large annotated corpus of English: The Penn Treebank. *Computational
    Linguistics*, 19(2):313–330, 1993. URL [https://www.aclweb.org/anthology/J93-2004](https://www.aclweb.org/anthology/J93-2004).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'McCann et al. [2018] Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, and
    Richard Socher. The natural language decathlon: Multitask learning as question
    answering. *arXiv preprint arXiv:1806.08730*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Meyerson and Miikkulainen [2017] Elliot Meyerson and Risto Miikkulainen. Beyond
    shared hierarchies: Deep multitask learning through soft layer ordering. *arXiv
    preprint arXiv:1711.00108*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miettinen [1998] Kaisa Miettinen. *Nonlinear multiobjective optimization*, volume 12
    of *International series in operations research and management science*. Kluwer,
    1998. ISBN 978-0-7923-8278-2.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miikkulainen et al. [2019] Risto Miikkulainen, Jason Liang, Elliot Meyerson,
    Aditya Rawal, Daniel Fink, Olivier Francon, Bala Raju, Hormoz Shahrzad, Arshak
    Navruzyan, Nigel Duffy, et al. Evolving deep neural networks. In *Artificial Intelligence
    in the Age of Neural Networks and Brain Computing*, pages 293–312\. Elsevier,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Misra et al. [2016] Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, and Martial
    Hebert. Cross-stitch networks for multi-task learning. In *Proceedings of the
    IEEE Conference on Computer Vision and Pattern Recognition*, pages 3994–4003,
    2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ndirango and Lee [2019] Anthony Ndirango and Tyler Lee. Generalization in multitask
    deep neural classifiers: a statistical physics approach. In *Advances in Neural
    Information Processing Systems*, pages 15862–15871, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Newell et al. [2019] Alejandro Newell, Lu Jiang, Chong Wang, Li-Jia Li, and
    Jia Deng. Feature partitioning for efficient multi-task architectures. *arXiv
    preprint arXiv:1908.04339*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nguyen and Okatani [2018] Duy-Kien Nguyen and Takayuki Okatani. Improved fusion
    of visual and language representations by dense symmetric co-attention for visual
    question answering. In *Proceedings of the IEEE Conference on Computer Vision
    and Pattern Recognition*, pages 6087–6096, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nguyen and Okatani [2019] Duy-Kien Nguyen and Takayuki Okatani. Multi-task learning
    of hierarchical vision-language representation. In *Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition*, pages 10492–10501, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Parisi et al. [2019] German I Parisi, Ronald Kemker, Jose L Part, Christopher
    Kanan, and Stefan Wermter. Continual lifelong learning with neural networks: A
    review. *Neural Networks*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Parisotto et al. [2015] Emilio Parisotto, Jimmy Lei Ba, and Ruslan Salakhutdinov.
    Actor-mimic: Deep multitask and transfer reinforcement learning. *arXiv preprint
    arXiv:1511.06342*, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pascal et al. [2020] Lucas Pascal, Pietro Michiardi, Xavier Bost, Benoit Huet,
    and Maria A Zuluaga. Maximum roaming multi-task learning. *arXiv preprint arXiv:2006.09762*,
    2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Perez et al. [2018] Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin,
    and Aaron Courville. Film: Visual reasoning with a general conditioning layer.
    In *Thirty-Second AAAI Conference on Artificial Intelligence*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pinto and Gupta [2017] Lerrel Pinto and Abhinav Gupta. Learning to push by
    grasping: Using multiple tasks for effective learning. In *2017 IEEE International
    Conference on Robotics and Automation (ICRA)*, pages 2161–2168\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Plummer et al. [2015] Bryan A Plummer, Liwei Wang, Chris M Cervantes, Juan C
    Caicedo, Julia Hockenmaier, and Svetlana Lazebnik. Flickr30k entities: Collecting
    region-to-phrase correspondences for richer image-to-sentence models. In *Proceedings
    of the IEEE international conference on computer vision*, pages 2641–2649, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pramanik et al. [2019] Subhojeet Pramanik, Priyanka Agrawal, and Aman Hussain.
    Omninet: A unified architecture for multi-modal multi-task learning. *arXiv preprint
    arXiv:1907.07804*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ramachandran and Le [2019] Prajit Ramachandran and Quoc V. Le. Diversity and
    depth in per-example routing models. In *International Conference on Learning
    Representations*, 2019. URL [https://openreview.net/forum?id=BkxWJnC9tX](https://openreview.net/forum?id=BkxWJnC9tX).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rebuffi et al. [2018] Sylvestre-Alvise Rebuffi, Hakan Bilen, and Andrea Vedaldi.
    Efficient parametrization of multi-domain deep neural networks. In *Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition*, pages 8119–8127,
    2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rosenbaum et al. [2017] Clemens Rosenbaum, Tim Klinger, and Matthew Riemer.
    Routing networks: Adaptive selection of non-linear functions for multi-task learning.
    *arXiv preprint arXiv:1711.01239*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rosenbaum et al. [2019] Clemens Rosenbaum, Ignacio Cases, Matthew Riemer, and
    Tim Klinger. Routing networks and the challenges of modular and compositional
    computation. *arXiv preprint arXiv:1904.12774*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ruder [2017] Sebastian Ruder. An overview of multi-task learning in deep neural
    networks. *arXiv preprint arXiv:1706.05098*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ruder et al. [2019] Sebastian Ruder, Joachim Bingel, Isabelle Augenstein, and
    Anders Søgaard. Latent multi-task architecture learning. In *Proceedings of the
    AAAI Conference on Artificial Intelligence*, volume 33, pages 4822–4829, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rusu et al. [2015] Andrei A Rusu, Sergio Gomez Colmenarejo, Caglar Gulcehre,
    Guillaume Desjardins, James Kirkpatrick, Razvan Pascanu, Volodymyr Mnih, Koray
    Kavukcuoglu, and Raia Hadsell. Policy distillation. *arXiv preprint arXiv:1511.06295*,
    2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sanh et al. [2019] Victor Sanh, Thomas Wolf, and Sebastian Ruder. A hierarchical
    multi-task approach for learning embeddings from semantic tasks. In *Proceedings
    of the AAAI Conference on Artificial Intelligence*, volume 33, pages 6949–6956,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schulman et al. [2017] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec
    Radford, and Oleg Klimov. Proximal policy optimization algorithms. *arXiv preprint
    arXiv:1707.06347*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sener and Koltun [2018] Ozan Sener and Vladlen Koltun. Multi-task learning as
    multi-objective optimization. In *Advances in Neural Information Processing Systems*,
    pages 527–538, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharma et al. [2017] Sahil Sharma, Ashutosh Jha, Parikshit Hegde, and Balaraman
    Ravindran. Learning to multi-task by active sampling. *arXiv preprint arXiv:1702.06053*,
    2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shui et al. [2019] Changjian Shui, Mahdieh Abbasi, Louis-Émile Robitaille, Boyu
    Wang, and Christian Gagné. A principled approach for learning task similarity
    in multitask learning. *arXiv preprint arXiv:1903.09109*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Silberman et al. [2012] Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob
    Fergus. Indoor segmentation and support inference from rgbd images. In *Computer
    Vision – ECCV 2012*, pages 746–760, Berlin, Heidelberg, 2012\. Springer Berlin
    Heidelberg. ISBN 978-3-642-33715-4.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sinha et al. [2018] Ayan Sinha, Zhao Chen, Vijay Badrinarayanan, and Andrew
    Rabinovich. Gradient adversarial training of neural networks. *arXiv preprint
    arXiv:1806.08028*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Søgaard and Goldberg [2016] Anders Søgaard and Yoav Goldberg. Deep multi-task
    learning with low level tasks supervised at lower layers. In *Proceedings of the
    54th Annual Meeting of the Association for Computational Linguistics (Volume 2:
    Short Papers)*, pages 231–235, Berlin, Germany, August 2016\. Association for
    Computational Linguistics. doi: 10.18653/v1/P16-2038. URL [https://www.aclweb.org/anthology/P16-2038](https://www.aclweb.org/anthology/P16-2038).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Song et al. [2019] Jie Song, Yixin Chen, Xinchao Wang, Chengchao Shen, and Mingli
    Song. Deep model transferability from attribution maps. In *Advances in Neural
    Information Processing Systems*, pages 6182–6192, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Srivastava et al. [2014] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
    Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: A simple way to prevent neural
    networks from overfitting. *Journal of Machine Learning Research*, 15(56):1929–1958,
    2014. URL [http://jmlr.org/papers/v15/srivastava14a.html](http://jmlr.org/papers/v15/srivastava14a.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Standley et al. [2019] Trevor Standley, Amir R Zamir, Dawn Chen, Leonidas Guibas,
    Jitendra Malik, and Silvio Savarese. Which tasks should be learned together in
    multi-task learning? *arXiv preprint arXiv:1905.07553*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strezoski et al. [2019a] Gjorgji Strezoski, Nanne van Noord, and Marcel Worring.
    Many task learning with task routing. In *Proceedings of the IEEE International
    Conference on Computer Vision*, pages 1375–1384, 2019a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strezoski et al. [2019b] Gjorgji Strezoski, Nanne van Noord, and Marcel Worring.
    Learning task relatedness in multi-task learning for images in context. In *Proceedings
    of the 2019 on International Conference on Multimedia Retrieval*, pages 78–86,
    2019b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sukhbaatar et al. [2015] Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al.
    End-to-end memory networks. In *Advances in neural information processing systems*,
    pages 2440–2448, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. [2019a] Tianxiang Sun, Yunfan Shao, Xiaonan Li, Pengfei Liu, Hang
    Yan, Xipeng Qiu, and Xuanjing Huang. Learning sparse sharing architectures for
    multiple tasks. *arXiv preprint arXiv:1911.05034*, 2019a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. [2019b] Ximeng Sun, Rameswar Panda, and Rogerio Feris. Adashare:
    Learning what to share for efficient deep multi-task learning. *arXiv preprint
    arXiv:1911.12423*, 2019b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sutskever et al. [2014] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence
    to sequence learning with neural networks. In *Advances in neural information
    processing systems*, pages 3104–3112, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Teh et al. [2017] Yee Teh, Victor Bapst, Wojciech M Czarnecki, John Quan, James
    Kirkpatrick, Raia Hadsell, Nicolas Heess, and Razvan Pascanu. Distral: Robust
    multitask reinforcement learning. In *Advances in Neural Information Processing
    Systems*, pages 4496–4506, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: van Hasselt et al. [2016] Hado P van Hasselt, Arthur Guez, Matteo Hessel, Volodymyr
    Mnih, and David Silver. Learning values across many orders of magnitude. In *Advances
    in Neural Information Processing Systems*, pages 4287–4295, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vandenhende et al. [2019] Simon Vandenhende, Stamatios Georgoulis, Bert De Brabandere,
    and Luc Van Gool. Branched multi-task networks: deciding what layers to share.
    *arXiv preprint arXiv:1904.02920*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vandenhende et al. [2020] Simon Vandenhende, Stamatios Georgoulis, and Luc
    Van Gool. Mti-net: Multi-scale task interaction networks for multi-task learning.
    *arXiv preprint arXiv:2001.06902*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. [2018] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill,
    Omer Levy, and Samuel R Bowman. Glue: A multi-task benchmark and analysis platform
    for natural language understanding. *arXiv preprint arXiv:1804.07461*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weischedel et al. [2013] Ralph Weischedel, Martha Palmer, Mitchell Marcus, Eduard
    Hovy, Sameer Pradhan, Lance Ramshaw, Nianwen Zue, Ann Taylor, Jeff Kaufman, Michelle
    Franchini, Mohammed El-Bachouti, Robert Belvin, and Ann Houston. Ontonotes release
    5.0. *Linguistic Data Consortium*, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Williams [1992] Ronald J. Williams. Simple statistical gradient-following algorithms
    for connectionist reinforcement learning. *Machine Learning*, 8(3-4):229–256,
    May 1992. doi: 10.1007/bf00992696. URL [https://doi.org/10.1007/bf00992696](https://doi.org/10.1007/bf00992696).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wong and Gesmundo [2017] Catherine Wong and Andrea Gesmundo. Transfer learning
    to learn with multitask neural model search. *arXiv preprint arXiv:1710.10776*,
    2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. [2020] Sen Wu, Hongyang R Zhang, and Christopher Ré. Understanding
    and improving information transfer in multi-task learning. *arXiv preprint arXiv:2005.00944*,
    2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. [2018a] Dan Xu, Wanli Ouyang, Xiaogang Wang, and Nicu Sebe. Pad-net:
    Multi-tasks guided prediction-and-distillation network for simultaneous depth
    estimation and scene parsing. In *Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition*, pages 675–684, 2018a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. [2018b] Yichong Xu, Xiaodong Liu, Yelong Shen, Jingjing Liu, and Jianfeng
    Gao. Multi-task learning with sample re-weighting for machine reading comprehension,
    2018b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. [2020] Ruihan Yang, Huazhe Xu, Yi Wu, and Xiaolong Wang. Multi-task
    reinforcement learning with soft modularization. *arXiv preprint arXiv:2003.13661*,
    2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang and Hospedales [2016a] Yongxin Yang and Timothy Hospedales. Deep multi-task
    representation learning: A tensor factorisation approach. *arXiv preprint arXiv:1605.06391*,
    2016a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang and Hospedales [2016b] Yongxin Yang and Timothy M Hospedales. Trace norm
    regularised deep multi-task learning. *arXiv preprint arXiv:1606.04038*, 2016b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Young et al. [2014] Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier.
    From image descriptions to visual denotations: New similarity metrics for semantic
    inference over event descriptions. *Transactions of the Association for Computational
    Linguistics*, 2:67–78, 2014. doi: 10.1162/tacl_a_00166. URL [https://www.aclweb.org/anthology/Q14-1006](https://www.aclweb.org/anthology/Q14-1006).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yu et al. [2019] Tianhe Yu, Deirdre Quillen, Zhanpeng He, Ryan Julian, Karol
    Hausman, Chelsea Finn, and Sergey Levine. Meta-world: A benchmark and evaluation
    for multi-task and meta reinforcement learning. *arXiv preprint arXiv:1910.10897*,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu et al. [2020] Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol
    Hausman, and Chelsea Finn. Gradient surgery for multi-task learning. *arXiv preprint
    arXiv:2001.06782*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zamir et al. [2018] Amir R Zamir, Alexander Sax, William Shen, Leonidas J Guibas,
    Jitendra Malik, and Silvio Savarese. Taskonomy: Disentangling task transfer learning.
    In *Proceedings of the IEEE conference on computer vision and pattern recognition*,
    pages 3712–3722, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zeng et al. [2018] Andy Zeng, Shuran Song, Stefan Welker, Johnny Lee, Alberto
    Rodriguez, and Thomas Funkhouser. Learning synergies between pushing and grasping
    with self-supervised deep reinforcement learning. In *2018 IEEE/RSJ International
    Conference on Intelligent Robots and Systems (IROS)*, pages 4238–4245\. IEEE,
    2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2020] Amy Zhang, Shagun Sodhani, Khimya Khetarpal, and Joelle
    Pineau. Multi-task reinforcement learning as a hidden-parameter block mdp. *arXiv
    preprint arXiv:2007.07206*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang [2015] Yu Zhang. Multi-task learning and algorithmic stability. In *Proceedings
    of the Twenty-Ninth AAAI Conference on Artificial Intelligence*, pages 3181–3187,
    2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang and Yang [2017] Yu Zhang and Qiang Yang. A survey on multi-task learning.
    *arXiv preprint arXiv:1707.08114*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2014] Zhanpeng Zhang, Ping Luo, Chen Change Loy, and Xiaoou Tang.
    Facial landmark detection by deep multi-task learning. In David Fleet, Tomas Pajdla,
    Bernt Schiele, and Tinne Tuytelaars, editors, *Computer Vision – ECCV 2014*, pages
    94–108, Cham, 2014. Springer International Publishing. ISBN 978-3-319-10599-4.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2019] Zhenyu Zhang, Zhen Cui, Chunyan Xu, Yan Yan, Nicu Sebe,
    and Jian Yang. Pattern-affinitive propagation across depth, surface normal and
    semantic segmentation. In *Proceedings of the IEEE Conference on Computer Vision
    and Pattern Recognition*, pages 4106–4115, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. [2018] Xiangyun Zhao, Haoxiang Li, Xiaohui Shen, Xiaodan Liang,
    and Ying Wu. A modulation module for multi-task learning with applications in
    image retrieval. In Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and
    Yair Weiss, editors, *Computer Vision – ECCV 2018*, pages 415–432, Cham, 2018\.
    Springer International Publishing. ISBN 978-3-030-01246-5.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zheng et al. [2018] Feng Zheng, Cheng Deng, Xing Sun, Xinyang Jiang, Xiaowei
    Guo, Zongqiao Yu, Feiyue Huang, and Rongrong Ji. Pyramidal person re-identification
    via multi-loss dynamic training, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhuang et al. [2019] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun
    Zhu, Hengshu Zhu, Hui Xiong, and Qing He. A comprehensive survey on transfer learning.
    *arXiv preprint arXiv:1911.02685*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zoph and Le [2016] Barret Zoph and Quoc V Le. Neural architecture search with
    reinforcement learning. *arXiv preprint arXiv:1611.01578*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
