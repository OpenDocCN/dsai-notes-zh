- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:56:45'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:56:45
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2103.00550] A Survey on Deep Semi-supervised Learning'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2103.00550] 关于深度半监督学习的调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2103.00550](https://ar5iv.labs.arxiv.org/html/2103.00550)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2103.00550](https://ar5iv.labs.arxiv.org/html/2103.00550)
- en: A Survey on Deep Semi-supervised Learning
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于深度半监督学习的调查
- en: Xiangli Yang, Zixing Song, Irwin King,  Zenglin Xu X. Yang is with the School
    of Computer Science and Engineering, University of Electronic Science and Technology
    of China, Chengdu, China
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**向力阳**，**左兴宋**，**厄尔文·金**，**徐增林** X. Yang 现于中国电子科技大学计算机科学与工程学院，成都，中国'
- en: 'E-mail: xlyang@std.uestc.edu.cn Z. Xu is with the School of Computer Science
    and Technology, Harbin Institute of Technology, Shenzhen, China, and Peng Cheng
    Lab, Shenzhen, China.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 电子邮件：xlyang@std.uestc.edu.cn Z. Xu 现于哈尔滨工业大学计算机科学与技术学院，深圳，中国，以及鹏城实验室，深圳，中国。
- en: 'Email: xuzenglin@hit.edu.cn I. King and Z. Song are with the Department of
    Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong,
    China'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 电子邮件：xuzenglin@hit.edu.cn I. King 和 Z. Song 现于中国香港中文大学计算机科学与工程系，香港，中国
- en: 'Email: king@cse.cuhk.edu.hk, zxsong@cse.cuhk.edu.hk Corresponding author: Zenglin Xu.
    Manuscript received xx xx, xx; revised xx xx, xx.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 电子邮件：king@cse.cuhk.edu.hk，zxsong@cse.cuhk.edu.hk 通讯作者：**徐增林**。手稿收到日期：xx xx,
    xx；修订日期：xx xx, xx。
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep semi-supervised learning is a fast-growing field with a range of practical
    applications. This paper provides a comprehensive survey on both fundamentals
    and recent advances in deep semi-supervised learning methods from perspectives
    of model design and unsupervised loss functions. We first present a taxonomy for
    deep semi-supervised learning that categorizes existing methods, including deep
    generative methods, consistency regularization methods, graph-based methods, pseudo-labeling
    methods, and hybrid methods. Then we provide a comprehensive review of 52 representative
    methods and offer a detailed comparison of these methods in terms of the type
    of losses, contributions, and architecture differences. In addition to the progress
    in the past few years, we further discuss some shortcomings of existing methods
    and provide some tentative heuristic solutions for solving these open problems.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 深度半监督学习是一个快速发展的领域，具有广泛的实际应用。本文从模型设计和无监督损失函数的角度提供了关于深度半监督学习方法的全面调查。我们首先提出了深度半监督学习的分类法，涵盖了现有方法，包括深度生成方法、一致性正则化方法、基于图的方法、伪标签方法以及混合方法。然后，我们对52种代表性方法进行了全面的评审，并在损失类型、贡献和架构差异等方面进行了详细比较。除了过去几年的进展外，我们还讨论了现有方法的一些不足之处，并提出了一些初步的启发式解决方案以解决这些开放问题。
- en: 'Index Terms:'
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 索引术语：
- en: Deep semi-supervised learning, image classification, machine learning, survey
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 深度半监督学习，图像分类，机器学习，调查
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Deep learning has been an active research field with abundant applications in
    pattern recognition [[1](#bib.bib1), [2](#bib.bib2)], data mining [[3](#bib.bib3)],
    statistical learning [[4](#bib.bib4)], computer vision [[5](#bib.bib5), [6](#bib.bib6)],
    natural language processing [[7](#bib.bib7), [8](#bib.bib8)], etc. It has achieved
    great successes in both theory and practice [[9](#bib.bib9), [10](#bib.bib10)],
    especially in supervised learning scenarios, by leveraging a large amount of high-quality
    labeled data. However, labeled samples are often difficult, expensive, or time-consuming
    to obtain. The labeling process usually requires experts’ efforts, which is one
    of the major limitations to train an excellent fully-supervised deep neural network.
    For example, in medical tasks, the measurements are made with expensive machinery,
    and labels are drawn from a time-consuming analysis of multiple human experts.
    If only a few labeled samples are available, it is challenging to build a successful
    learning system. By contrast, the unlabeled data is usually abundant and can be
    easily or inexpensively obtained. Consequently, it is desirable to leverage a
    large number of unlabeled data for improving the learning performance given a
    small number of labeled samples. For this reason, semi-supervised learning (SSL)
    has been a hot research topic in machine learning in the last decade [[11](#bib.bib11),
    [12](#bib.bib12)].
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习一直是一个活跃的研究领域，具有在模式识别[[1](#bib.bib1), [2](#bib.bib2)]、数据挖掘[[3](#bib.bib3)]、统计学习[[4](#bib.bib4)]、计算机视觉[[5](#bib.bib5),
    [6](#bib.bib6)]、自然语言处理[[7](#bib.bib7), [8](#bib.bib8)]等领域中的丰富应用。在理论和实践中都取得了巨大成功[[9](#bib.bib9),
    [10](#bib.bib10)]，尤其是在监督学习场景中，通过利用大量高质量的标记数据。然而，标记样本通常难以获得，成本高昂或耗时。标记过程通常需要专家的努力，这是训练优秀的全监督深度神经网络的主要限制之一。例如，在医学任务中，测量使用昂贵的设备进行，标签则来自耗时的多位专家分析。如果仅有少量标记样本，构建成功的学习系统是具有挑战性的。相比之下，未标记数据通常丰富且容易或便宜地获得。因此，利用大量未标记数据来提高学习性能是可取的，即使只有少量标记样本。因此，半监督学习（SSL）在过去十年中成为机器学习的热门研究课题[[11](#bib.bib11),
    [12](#bib.bib12)]。
- en: '![Refer to caption](img/63a3e8215773938b67fbc6c85f3b7f7a.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/63a3e8215773938b67fbc6c85f3b7f7a.png)'
- en: 'Figure 1: The taxonomy of major deep semi-supervised learning methods based
    on loss function and model design.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：基于损失函数和模型设计的主要深度半监督学习方法的分类。
- en: 'SSL is a learning paradigm associated with constructing models that use both
    labeled and unlabeled data. SSL methods can improve learning performance by using
    additional unlabeled instances compared to supervised learning algorithms, which
    can use only labeled data. It is easy to obtain SSL algorithms by extending supervised
    learning algorithms or unsupervised learning algorithms. SSL algorithms provide
    a way to explore the latent patterns from unlabeled examples, alleviating the
    need for a large number of labels [[13](#bib.bib13)]. Depending on the key objective
    function of the systems, one may have a semi-supervised classification, a semi-supervised
    clustering, or a semi-supervised regression. We provide the definitions as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: SSL 是一种学习范式，涉及构建使用标记和未标记数据的模型。与仅能使用标记数据的监督学习算法相比，SSL 方法可以通过使用额外的未标记实例来提高学习性能。通过扩展监督学习算法或无监督学习算法，容易获得
    SSL 算法。SSL 算法提供了一种从未标记样本中探索潜在模式的方法，从而缓解对大量标签的需求[[13](#bib.bib13)]。根据系统的关键目标函数，可能会有半监督分类、半监督聚类或半监督回归。我们提供如下定义：
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Semi-supervised classification. Given a training dataset that consists of both
    labeled instances and unlabeled instances, semi-supervised classification aims
    to train a classifier from both the labeled and unlabeled data, such that it is
    better than the supervised classifier trained only on the labeled data.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 半监督分类。给定一个包含标记实例和未标记实例的训练数据集，半监督分类旨在从标记和未标记数据中训练一个分类器，使其优于仅在标记数据上训练的监督分类器。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Semi-supervised clustering. Given a training dataset that consists of unlabeled
    instances, and some supervised information about the clusters, the goal of semi-supervised
    clustering is to obtain better clustering than the clustering from unlabeled data
    alone. Semi-supervised clustering is also known as constrained clustering.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 半监督聚类。给定一个包含未标记实例的训练数据集，以及关于聚类的一些监督信息，半监督聚类的目标是获得比仅从未标记数据中得到的聚类更好的聚类结果。半监督聚类也被称为约束聚类。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Semi-supervised regression. Given a training dataset that consists of both labeled
    instances and unlabeled instances, the goal of semi-supervised regression is to
    improve the performance of a regression algorithm from a regression algorithm
    with labeled data alone, which predicts a real-valued output instead of a class
    label.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 半监督回归。给定一个由有标签实例和无标签实例组成的训练数据集，半监督回归的目标是提升回归算法的性能，相比仅使用有标签数据的回归算法，后者预测的是一个实值输出而不是类别标签。
- en: In order to explain SSL clearly and concretely, we focus on the problem of image
    classification. The ideas described in this survey can be adapted without difficulty
    to other situations, such as object detection, semantic segmentation, clustering,
    or regression. Therefore, we primarily review image classification methods with
    the aid of unlabeled data in this survey.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰具体地解释SSL，我们重点关注图像分类问题。本调查中描述的思想可以很容易地适应其他情况，如目标检测、语义分割、聚类或回归。因此，我们在本调查中主要回顾了利用无标签数据的图像分类方法。
- en: Since the 1970s when the concept of SSL first came to the fore [[14](#bib.bib14),
    [15](#bib.bib15), [16](#bib.bib16)], there have been a wide variety of SSL methods,
    including generative models [[17](#bib.bib17), [18](#bib.bib18)], semi-supervised
    support vector machines [[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21),
    [22](#bib.bib22)], graph-based methods [[23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25),
    [26](#bib.bib26)], and co-training [[27](#bib.bib27)]. We refer interested readers
    to [[28](#bib.bib28), [12](#bib.bib12)], which provide a comprehensive overview
    of traditional SSL methods. Nowadays, deep neural networks have played a dominating
    role in many research areas. It is important to adopt the classic SSL framework
    and develop novel SSL methods for deep learning settings, which leads to deep
    semi-supervised learning (DSSL). DSSL studies how to effectively utilize both
    labeled and unlabeled data by deep neural networks. A considerable amount of DSSL
    methods have been proposed. According to the most distinctive features in semi-supervised
    loss functions and model designs, we classify DSSL into five categories, i.e.,
    generative methods, consistency regularization methods, graph-based methods, pseudo-labeling
    methods, and hybrid methods. The overall taxonomy used in this literature is shown
    in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ A Survey on Deep Semi-supervised
    Learning").
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 自从1970年代SSL概念首次出现[[14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16)]以来，出现了多种多样的SSL方法，包括生成模型[[17](#bib.bib17),
    [18](#bib.bib18)]、半监督支持向量机[[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21),
    [22](#bib.bib22)]、基于图的方法[[23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25),
    [26](#bib.bib26)]和协同训练[[27](#bib.bib27)]。我们建议感兴趣的读者参考[[28](#bib.bib28), [12](#bib.bib12)]，这些文献提供了传统SSL方法的全面概述。如今，深度神经网络在许多研究领域中发挥了主导作用。重要的是采用经典的SSL框架，并为深度学习环境开发新颖的SSL方法，这引出了深度半监督学习（DSSL）。DSSL研究如何通过深度神经网络有效利用有标签和无标签的数据。已经提出了大量的DSSL方法。根据半监督损失函数和模型设计中的最显著特征，我们将DSSL分为五类，即生成方法、一致性正则化方法、基于图的方法、伪标签方法和混合方法。本文献中使用的整体分类法如图[1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ A Survey on Deep Semi-supervised Learning")所示。
- en: Some representative works of SSL were described in the early survey [[28](#bib.bib28),
    [12](#bib.bib12)], however, emerging technologies based on deep learning, such
    as adversarial training which generates new training data for SSL, have not been
    included. Besides, [[13](#bib.bib13)] focuses on unifying the evaluation indices
    of SSL, and [[29](#bib.bib29)] only reviews generative models and teacher-student
    models in SSL without making a comprehensive overview of SSL. Although [[30](#bib.bib30)]
    tries to present a whole picture of SSL, the taxonomy is quite different from
    ours. A recent review by Ouali et al. [[31](#bib.bib31)] gives a similar notion
    of DSSL as we do. However, it does not compare the presented methods based on
    their taxonomy and provide perspectives on future trends and existing issues.
    Summarizing both previous and the latest research on SSL, we survey the fundamental
    theories and compare the deep semi-supervised methods. In summary, our contributions
    are listed as follows.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的综述中描述了一些SSL的代表性工作[[28](#bib.bib28), [12](#bib.bib12)]，但基于深度学习的新兴技术，如生成新训练数据的对抗训练，并未被纳入其中。此外，[[13](#bib.bib13)]专注于统一SSL的评估指标，而[[29](#bib.bib29)]仅回顾了SSL中的生成模型和教师-学生模型，没有对SSL进行全面概述。尽管[[30](#bib.bib30)]尝试呈现SSL的整体图景，但其分类与我们的差异较大。Ouali等人的最新综述[[31](#bib.bib31)]给出了与我们相似的DSSL概念，但未根据分类比较呈现的方法，也未提供对未来趋势和现有问题的观点。总结以前和最新的SSL研究，我们调查了基本理论并比较了深度半监督方法。总之，我们的贡献如下。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We provide a detailed review of DSSL methods and introduce a taxonomy of major
    DSSL methods, background knowledge, and various models. One can quickly grasp
    the frontier ideas of DSSL.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对DSSL方法进行了详细的综述，并介绍了主要DSSL方法的分类、背景知识和各种模型。可以迅速掌握DSSL的前沿思想。
- en: •
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We categorize DSSL methods into several categories, i.e., generative methods,
    consistency regularization methods, graph-based methods, pseudo-labeling methods,
    and hybrid methods, with particular genres inside each one. We review the variants
    on each category and give standardized descriptions and unified sketch maps.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将DSSL方法分类为几类，即生成方法、一致性正则化方法、基于图的方法、伪标签方法和混合方法，每一类中还有特定的子类。我们回顾了每个类别的变体，并给出了标准化描述和统一的示意图。
- en: •
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We identify several open problems in this field and discuss the future direction
    for DSSL.
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们识别了该领域的若干开放问题，并讨论了DSSL的未来方向。
- en: This survey is organized as follows. In Section [2](#S2 "2 Background ‣ A Survey
    on Deep Semi-supervised Learning"), we introduce SSL background knowledge, including
    assumptions in SSL, classical SSL methods, related concepts, and datasets used
    in various applications. Section [4](#S4 "4 Consistency Regularization ‣ A Survey
    on Deep Semi-supervised Learning") to Section [7](#S7 "7 Hybrid methods ‣ A Survey
    on Deep Semi-supervised Learning") introduce the primary deep semi-supervised
    techniques, i.e., generative methods in Section [3](#S3 "3 Generative methods
    ‣ A Survey on Deep Semi-supervised Learning"), consistency regularization methods
    in Section [4](#S4 "4 Consistency Regularization ‣ A Survey on Deep Semi-supervised
    Learning"), graph-based methods in Section [5](#S5 "5 Graph-based methods ‣ A
    Survey on Deep Semi-supervised Learning"), pseudo-labeling methods in Section [6](#S6
    "6 Pseudo-labeling methods ‣ A Survey on Deep Semi-supervised Learning") and hybrid
    methods in Section [7](#S7 "7 Hybrid methods ‣ A Survey on Deep Semi-supervised
    Learning"). In Section [8](#S8 "8 Challenges and future directions ‣ A Survey
    on Deep Semi-supervised Learning"), we discuss the challenges in semi-supervised
    learning and provide some heuristic solutions and future directions for these
    open problems.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查报告的组织结构如下。在第[2](#S2 "2 背景 ‣ 深度半监督学习综述")节中，我们介绍了SSL的背景知识，包括SSL中的假设、经典SSL方法、相关概念以及在各种应用中使用的数据集。从第[4](#S4
    "4 一致性正则化 ‣ 深度半监督学习综述")节到第[7](#S7 "7 混合方法 ‣ 深度半监督学习综述")节，我们介绍了主要的深度半监督技术，即第[3](#S3
    "3 生成方法 ‣ 深度半监督学习综述")节中的生成方法，第[4](#S4 "4 一致性正则化 ‣ 深度半监督学习综述")节中的一致性正则化方法，第[5](#S5
    "5 基于图的方法 ‣ 深度半监督学习综述")节中的基于图的方法，第[6](#S6 "6 伪标签方法 ‣ 深度半监督学习综述")节中的伪标签方法，以及第[7](#S7
    "7 混合方法 ‣ 深度半监督学习综述")节中的混合方法。在第[8](#S8 "8 挑战与未来方向 ‣ 深度半监督学习综述")节中，我们讨论了半监督学习中的挑战，并提供了一些启发式解决方案和未来方向。
- en: 2 Background
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景
- en: Before presenting an overview of the techniques of SSL, we first introduce the
    notations. To illustrate the DSSL framework, we limit our focus on the single-label
    classification tasks which are simple to describe and implement. We refer interested
    readers to [[32](#bib.bib32), [33](#bib.bib33), [34](#bib.bib34)] for multi-label
    classification tasks. Let $X=\{X_{L},X_{U}\}$ denote the entire data set, including
    a small labeled subset $X_{L}=\{x_{i}\}_{i=1}^{L}$ with labels $Y_{L}=(y_{1},y_{2},\ldots,y_{L})$
    and a large scale unlabeled subset $X_{U}=\{(x_{i})\}_{i=1}^{U}$, and generally
    we assume $L\ll U$. We assume that the dataset contains $K$ classes and the first
    $L$ examples within $X$ are labeled by $\{y_{i}\}_{i=1}^{L}\in(y^{1},y^{2},\ldots,y^{K})$.
    Formally, SSL aims to solve the following optimization problem,
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍SSL技术概述之前，我们首先介绍符号说明。为了说明DSSL框架，我们将重点放在单标签分类任务上，这些任务简单易于描述和实现。对于多标签分类任务，请参考
    [[32](#bib.bib32), [33](#bib.bib33), [34](#bib.bib34)]。设 $X=\{X_{L},X_{U}\}$ 表示整个数据集，包括一个小的带标签子集
    $X_{L}=\{x_{i}\}_{i=1}^{L}$，标签为 $Y_{L}=(y_{1},y_{2},\ldots,y_{L})$，以及一个大规模的无标签子集
    $X_{U}=\{(x_{i})\}_{i=1}^{U}$，通常我们假设 $L\ll U$。我们假设数据集包含 $K$ 个类别，并且 $X$ 中的前 $L$
    个样本由 $\{y_{i}\}_{i=1}^{L}\in(y^{1},y^{2},\ldots,y^{K})$ 标签标记。正式地，SSL 旨在解决以下优化问题，
- en: '|  | $\min_{\theta}\underset{\text{supervised loss}}{\underbrace{\sum_{x\in
    X_{L},y\in Y_{L}}\mathcal{L}_{s}(x,y,\theta)}}+\alpha\underset{\text{unsupervised
    loss}}{\underbrace{\sum_{x\in X_{U}}\mathcal{L}_{u}(x,\theta)}}+\beta\underset{\text{regularization}}{\underbrace{\sum_{x\in
    X}\mathcal{R}(x,\theta)}},$ |  | (1) |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{\theta}\underset{\text{监督损失}}{\underbrace{\sum_{x\in X_{L},y\in
    Y_{L}}\mathcal{L}_{s}(x,y,\theta)}}+\alpha\underset{\text{无监督损失}}{\underbrace{\sum_{x\in
    X_{U}}\mathcal{L}_{u}(x,\theta)}}+\beta\underset{\text{正则化}}{\underbrace{\sum_{x\in
    X}\mathcal{R}(x,\theta)}},$ |  | (1) |'
- en: where $\mathcal{L}_{s}$ denotes the per-example supervised loss, e.g., cross-entropy
    for classification, $\mathcal{L}_{u}$ denotes the per-example unsupervised loss,
    and $\mathcal{R}$ denotes the per-example regularization, e.g., consistency loss
    or a designed regularization term. Note that unsupervised loss terms are often
    not strictly distinguished from regularization terms, as regularization terms
    are normally not guided by label information. Lastly, $\theta$ denotes the model
    parameters and $\alpha,\beta\in\mathbb{R}_{>0}$ denotes the trade-off. Different
    choices of the unsupervised loss functions and regularization terms lead to different
    semi-supervised models. Note that we do not make a clear distinction between unsupervised
    loss and regularization terms in many cases. Unless particularly specified, the
    notations used in this paper are illustrated in TABLE [I](#S2.T1 "TABLE I ‣ 2.1
    Assumptions for semi-supervised learning ‣ 2 Background ‣ A Survey on Deep Semi-supervised
    Learning").
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{L}_{s}$ 表示每个样本的监督损失，例如分类的交叉熵，$\mathcal{L}_{u}$ 表示每个样本的无监督损失，而 $\mathcal{R}$
    表示每个样本的正则化，例如一致性损失或设计的正则化项。请注意，无监督损失项通常与正则化项没有严格区分，因为正则化项通常不受标签信息的指导。最后，$\theta$
    表示模型参数，$\alpha,\beta\in\mathbb{R}_{>0}$ 表示权衡。不同的无监督损失函数和正则化项的选择会导致不同的半监督模型。请注意，在许多情况下，我们没有明确区分无监督损失和正则化项。除非特别说明，本文中使用的符号在表格
    [I](#S2.T1 "TABLE I ‣ 2.1 Assumptions for semi-supervised learning ‣ 2 Background
    ‣ A Survey on Deep Semi-supervised Learning") 中进行了说明。
- en: 'Regarding whether test data are wholly available in the training process, semi-supervised
    learning can be classified into two settings: the transductive setting and the
    inductive learning setting. Transductive learning assumes that the unlabeled samples
    in the training process are exactly the data to be predicted, and the purpose
    of the transductive learning is to generalize over these unlabeled samples, while
    inductive learning supposes that the learned semi-supervised classifier will be
    still applicable to new unseen data. In fact, most graph-based methods are transductive
    while most other kinds of SSL methods are inductive.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 关于测试数据是否在训练过程中完全可用，半监督学习可以分为两种设置：传导设置和归纳学习设置。传导学习假设在训练过程中无标签样本正是待预测的数据，而传导学习的目的是在这些无标签样本上进行泛化，而归纳学习则假设学习到的半监督分类器仍然适用于新的未见数据。实际上，大多数基于图的方法是传导的，而其他大多数SSL方法则是归纳的。
- en: 2.1 Assumptions for semi-supervised learning
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 半监督学习的假设
- en: 'SSL aims to predict more accurately with the aid of unlabeled data than supervised
    learning that uses only labeled data. However, an essential prerequisite is that
    the data distribution should be under some assumptions. Otherwise, SSL may not
    improve supervised learning and may even degrade the prediction accuracy by misleading
    inferences. Following [[12](#bib.bib12)] and [[28](#bib.bib28)], the related assumptions
    in SSL include:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: SSL旨在通过利用未标记的数据比仅使用标记数据的监督学习更准确地进行预测。然而，一个基本的前提是数据分布应该满足某些假设。否则，SSL可能不会改善监督学习，甚至可能由于误导推断而降低预测准确性。根据[[12](#bib.bib12)]和[[28](#bib.bib28)]，SSL中的相关假设包括：
- en: Self-training assumption. The predictions of the self-training model, especially
    those with high confidence, tend to be correct. We can assume that when the hypothesis
    is satisfied, those high-confidence predictions are considered to be ground-truth.
    This can happen when classes form well-separated clusters.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 自我训练假设。自我训练模型的预测，特别是那些高置信度的预测，往往是正确的。我们可以假设，当假设满足时，那些高置信度的预测被认为是真实的。这种情况可能发生在类别形成良好分隔的簇时。
- en: 'Co-training assumption. Different reasonable assumptions lead to different
    combinations of labeled and unlabeled data, and accordingly, different algorithms
    are designed to take advantage of these combinations. For example, Blum et al.
    [[27](#bib.bib27)] proposed a co-training model, which works under the assumptions:
    instance $x$ has two conditionally independent views, and each view is sufficient
    for a classification task.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 共同训练假设。不同的合理假设会导致标记数据和未标记数据的不同组合，从而设计出不同的算法来利用这些组合。例如，Blum等人[[27](#bib.bib27)]提出了一种共同训练模型，该模型在以下假设下工作：实例
    $x$ 具有两个条件独立的视图，每个视图都足以完成分类任务。
- en: Generative model assumption. Generally, it is assumed that data are generated
    from a mixture of distributions. When the number of mixed components, a prior
    $p(y)$ and a conditional distribution $p(x|y)$ are correct, data can be assumed
    to come from the mixed model. This assumption suggests that if the generative
    model is correct enough, we can establish a valid link between the distribution
    of unlabeled data and the category labels by $p(x,y)=p(y)p(x|y)$.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型假设。通常，假设数据是从一个分布混合体中生成的。当混合成分的数量、先验 $p(y)$ 和条件分布 $p(x|y)$ 是正确的时，可以假设数据来自混合模型。这个假设表明，如果生成模型足够准确，我们可以通过
    $p(x,y)=p(y)p(x|y)$ 建立未标记数据分布和类别标签之间的有效联系。
- en: Cluster assumption. If two points $x_{1}$ and $x_{2}$ are in the same cluster,
    they should belong to the same category [[28](#bib.bib28)]. This assumption refers
    to the fact that data in a single class tend to form a cluster, and when the data
    points can be connected by short curves that do not pass through any low-density
    regions, they belong to the same class cluster [[28](#bib.bib28)]. According to
    this assumption, the decision boundary should not cross high-density areas but
    instead lie in low-density regions [[35](#bib.bib35)]. Therefore, the learning
    algorithm can use a large amount of unlabeled data to adjust the classification
    boundary.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 簇假设。如果两个点 $x_{1}$ 和 $x_{2}$ 位于同一个簇中，它们应该属于同一个类别[[28](#bib.bib28)]。这个假设指的是，单一类别中的数据往往形成一个簇，当数据点可以通过短曲线连接且不经过任何低密度区域时，它们属于同一类别簇[[28](#bib.bib28)]。根据这个假设，决策边界不应穿越高密度区域，而应位于低密度区域[[35](#bib.bib35)]。因此，学习算法可以利用大量未标记的数据来调整分类边界。
- en: Low-density separation. The decision boundary should be in a low-density region,
    not through a high-density area [[28](#bib.bib28)]. The low-density separation
    assumption is closely related to the cluster assumption. We can consider the clustering
    assumption from another perspective by assuming that the class is separated by
    areas of low density [[28](#bib.bib28)]. Since the decision boundary in a high-density
    region would cut a cluster into two different classes and within such a part would
    violate the cluster assumption.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 低密度分离。决策边界应该位于低密度区域，而不是穿过高密度区域[[28](#bib.bib28)]。低密度分离假设与簇假设紧密相关。我们可以从另一个角度考虑簇假设，假设类别由低密度区域分隔[[28](#bib.bib28)]。因为在高密度区域的决策边界会将簇分割成两个不同的类别，并且这样的部分会违反簇假设。
- en: Manifold assumption. If two points $x_{1}$ and $x_{2}$ are located in a local
    neighborhood in the low-dimensional manifold, they have similar class labels [[28](#bib.bib28)].
    This assumption reflects the local smoothness of the decision boundary. It is
    well known that one of the problems of machine learning algorithms is the curse
    of dimensionality. It is hard to estimate the actual data distribution when volume
    grows exponentially with the dimensions in high dimensional spaces. If the data
    lie on a low-dimensional manifold, the learning algorithms can avoid the curse
    of dimensionality and operate in the corresponding low-dimension space.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 流形假设。如果两个点 $x_{1}$ 和 $x_{2}$ 位于低维流形的局部邻域中，它们具有相似的类别标签[[28](#bib.bib28)]。这一假设反映了决策边界的局部光滑性。众所周知，机器学习算法的一个问题是维度灾难。当体积随着高维空间中的维度呈指数增长时，很难估计实际的数据分布。如果数据位于低维流形上，学习算法可以避免维度灾难，并在相应的低维空间中进行操作。
- en: 'TABLE I: Notations'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '表 I: 符号说明'
- en: '| Symbol | Explanation |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 符号 | 说明 |'
- en: '| $\mathcal{X}$ | Input space, for example $\mathcal{X}=\mathbb{R}^{n}$ |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{X}$ | 输入空间，例如 $\mathcal{X}=\mathbb{R}^{n}$ |'
- en: '| $\mathcal{Y}$ | Output space. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{Y}$ | 输出空间。 |'
- en: '|  | Classification: $\mathcal{Y}=\{y^{1},y^{2},\ldots,y^{K}\}$. |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|  | 分类: $\mathcal{Y}=\{y^{1},y^{2},\ldots,y^{K}\}$。 |'
- en: '|  | Regression: $\mathcal{Y}=\mathbb{R}$ |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | 回归: $\mathcal{Y}=\mathbb{R}$ |'
- en: '| $X_{L}$ | Labeled dataset. $x_{i}\in\mathcal{X},y_{i}\in\mathcal{Y}$ |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| $X_{L}$ | 标记数据集。 $x_{i}\in\mathcal{X},y_{i}\in\mathcal{Y}$ |'
- en: '| $X_{U}$ | Unlabeled dataset. $x_{i}\in\mathcal{X}$ |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| $X_{U}$ | 未标记数据集。 $x_{i}\in\mathcal{X}$ |'
- en: '| $X$ | Input dataset $X$. $N=L+U,L\ll U$ |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| $X$ | 输入数据集 $X$。 $N=L+U,L\ll U$ |'
- en: '| $\mathcal{L}$ | Loss Function |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{L}$ | 损失函数 |'
- en: '| $G$ | Generator |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| $G$ | 生成器 |'
- en: '| $D$ | Discriminator |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| $D$ | 判别器 |'
- en: '| $C$ | Classifier |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| $C$ | 分类器 |'
- en: '| $H$ | Entropy |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| $H$ | 熵 |'
- en: '| $\mathbb{E}$ | Expectation |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbb{E}$ | 期望 |'
- en: '| $\mathcal{R}$ | Consistency constraint |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{R}$ | 一致性约束 |'
- en: '| $\mathcal{T}_{x}$ | Consistency target |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{T}_{x}$ | 一致性目标 |'
- en: '| $\mathcal{G}$ | A graph |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{G}$ | 一个图 |'
- en: '| $\mathcal{V}$ | The set of vertices in a graph |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{V}$ | 图中的顶点集合 |'
- en: '| $\mathcal{E}$ | The set of edges in a graph |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{E}$ | 图中的边集合 |'
- en: '| $v$ | A node $v\in\mathcal{V}$ |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| $v$ | 节点 $v\in\mathcal{V}$ |'
- en: '| $e_{ij}$ | An edge linked between node $i$ and $j$, $e_{ij}\in\mathcal{E}$
    |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| $e_{ij}$ | 连接节点 $i$ 和 $j$ 的边，$e_{ij}\in\mathcal{E}$ |'
- en: '| ${A}$ | The adjacency matrix of a graph |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| ${A}$ | 图的邻接矩阵 |'
- en: '| ${D}$ | The degree matrix of a graph |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| ${D}$ | 图的度矩阵 |'
- en: '| $D_{ii}$ | The degree of node $i$ |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| $D_{ii}$ | 节点 $i$ 的度 |'
- en: '| $W$ | The weight matrix |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| $W$ | 权重矩阵 |'
- en: '| $W_{ij}$ | The weight associated with edge $e_{ij}$ |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| $W_{ij}$ | 与边 $e_{ij}$ 相关的权重 |'
- en: '| $\mathcal{N}(v)$ | The neighbors of a node $v$ |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{N}(v)$ | 节点 $v$ 的邻居 |'
- en: '| $\mathbf{Z}$ | Embedding matrix |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{Z}$ | 嵌入矩阵 |'
- en: '| $\mathbf{z}_{v}$ | An embedding for node $v$ |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{z}_{v}$ | 节点 $v$ 的嵌入 |'
- en: '| $\mathbf{S}$ | Similarity matrix of a graph |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{S}$ | 图的相似性矩阵 |'
- en: '| $\mathbf{S}[u,v]$ | Similarity measurement between node $u$ and $v$ |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{S}[u,v]$ | 节点 $u$ 和 $v$ 之间的相似性测量 |'
- en: '| $\mathbf{h}_{v}^{(k)}$ | Hidden embedding for node $v$ in $k$th layer |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{h}_{v}^{(k)}$ | 节点 $v$ 在第 $k$ 层的隐藏嵌入 |'
- en: '| $\mathbf{m}_{\mathcal{N}(v)}$ | Message aggregated from node $v$’s neighborhoods
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{m}_{\mathcal{N}(v)}$ | 从节点 $v$ 的邻域聚合的信息 |'
- en: 2.2 Classical Semi-supervised learning Methods
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 经典的半监督学习方法
- en: In the following, we briefly introduce some representative SSL methods motivated
    from the above described assumptions.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在下文中，我们简要介绍一些受上述假设启发的代表性SSL方法。
- en: In the 1970s, the concept of SSL first came to the fore [[14](#bib.bib14), [15](#bib.bib15),
    [16](#bib.bib16)]. Perhaps the earliest method has been established as self-learning
    — an iterative mechanism that uses initial labeled data to train a model to predict
    some unlabeled samples. Then the most confident prediction is marked as the best
    prediction of the current supervised model, thus providing more training data
    for the supervised algorithm, until all the unlabelled examples have been predicted.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在1970年代，SSL的概念首次浮现[[14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16)]。也许最早的方法是自学习——一种迭代机制，利用初始标记数据来训练模型预测一些未标记样本。然后，最有信心的预测被标记为当前监督模型的最佳预测，从而为监督算法提供更多训练数据，直到所有未标记的样本都被预测。
- en: Co-training [[27](#bib.bib27)] provides a similar solution by training two different
    models on two different views. Confident predictions of one view are then used
    as labels for the other model. More relevant literature of this method also includes
    [[36](#bib.bib36), [37](#bib.bib37), [38](#bib.bib38)], etc.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 协同训练[[27](#bib.bib27)]提供了类似的解决方案，通过在两个不同视角上训练两个不同的模型。一个视角的自信预测被用作另一个模型的标签。与这种方法相关的文献还包括[[36](#bib.bib36),
    [37](#bib.bib37), [38](#bib.bib38)]等。
- en: Generative models assume a model $p(x,y)=p(y)p(x|y)$, where the density function
    $p(x|y)$ is an identifiable distribution, for example, polynomial, Gaussian mixture
    distribution, etc., and the uncertainty is the parameters of $p(x|y)$. Generative
    models can be optimized by using iterative algorithms. [[17](#bib.bib17), [18](#bib.bib18)]
    apply EM algorithm for classification. They compute the parameters of $p(x|y)$
    and then classify unlabeled instances according to the Bayesian full probability
    formula. Moreover, generative models are harsh on some assumptions. Once the hypothetical
    $p(x|y)$ is poorly matched with the actual distribution, it can lead to classifier
    performance degradation.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型假设一个模型 $p(x,y)=p(y)p(x|y)$，其中密度函数 $p(x|y)$ 是一个可识别的分布，例如多项式、高斯混合分布等，而不确定性是
    $p(x|y)$ 的参数。生成模型可以通过迭代算法进行优化。[[17](#bib.bib17), [18](#bib.bib18)] 应用了EM算法进行分类。他们计算
    $p(x|y)$ 的参数，然后根据贝叶斯全概率公式对未标记实例进行分类。此外，生成模型对一些假设要求严格。一旦假设的 $p(x|y)$ 与实际分布不匹配，就可能导致分类器性能下降。
- en: A representative example following the low-density separation principle is Transductive
    Support Vector Machines (TSVMs) [[19](#bib.bib19), [20](#bib.bib20), [35](#bib.bib35),
    [39](#bib.bib39), [40](#bib.bib40)]. As regular SVMs, TSVMs optimize the gap between
    decision boundaries and data points, and then expand this gap based on the distance
    from unlabeled data to the decision margin. To address the corresponding non-convex
    optimization problem, a number of optimization algorithms have been proposed.
    For instance, in [[35](#bib.bib35)], a smooth loss function substitutes the hinge
    loss of the TSVM, and for the decision boundary in a low-density space, a gradient
    descent technique may be used.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循低密度分离原则的一个代表性例子是**传导支持向量机**（TSVMs）[[19](#bib.bib19), [20](#bib.bib20), [35](#bib.bib35),
    [39](#bib.bib39), [40](#bib.bib40)]。与常规支持向量机（SVMs）一样，TSVMs优化决策边界与数据点之间的间隙，然后根据未标记数据到决策边界的距离扩展这个间隙。为了解决相应的非凸优化问题，已经提出了多种优化算法。例如，在[[35](#bib.bib35)]中，用平滑损失函数替代了TSVM的铰链损失，对于低密度空间中的决策边界，可以使用梯度下降技术。
- en: Graph-based methods rely on the geometry of the data induced by both labeled
    and unlabeled examples. This geometry is represented by an empirical graph $\mathcal{G}=(\mathcal{V,E})$,
    where nodes $\mathcal{V}$ represent the training data points with $|\mathcal{V}|=n$
    and edges $\mathcal{E}$ represent similarities between the points. By exploiting
    the graph or manifold structure of data, it is possible to learn with very few
    labels to propagate information through the graph [[41](#bib.bib41), [23](#bib.bib23),
    [42](#bib.bib42), [25](#bib.bib25), [26](#bib.bib26), [24](#bib.bib24)]. For example,
    Label propagation [[41](#bib.bib41)] is to predict the label information of unlabeled
    nodes from labeled nodes. Each node label propagates to its neighbors according
    to the similarity.At each step of node propagation, each node updates its label
    according to its neighbors’ label information. In the label propagation label,
    the label of the labeled data is fixed so that it propagates the label to the
    unlabeled data. The label propagation method can be applied to deep learning [[43](#bib.bib43)].
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的方法依赖于由标记和未标记样本诱发的数据几何。这种几何由经验图 $\mathcal{G}=(\mathcal{V,E})$ 表示，其中节点 $\mathcal{V}$
    代表训练数据点，$|\mathcal{V}|=n$，边 $\mathcal{E}$ 代表点之间的相似性。通过利用数据的图结构或流形结构，可以在标签很少的情况下进行学习，通过图传播信息[[41](#bib.bib41),
    [23](#bib.bib23), [42](#bib.bib42), [25](#bib.bib25), [26](#bib.bib26), [24](#bib.bib24)]。例如，标签传播[[41](#bib.bib41)]是从标记节点预测未标记节点的标签信息。每个节点标签根据相似性传播到其邻居。在每一步节点传播中，每个节点根据邻居的标签信息更新其标签。在标签传播中，标记数据的标签是固定的，以便将标签传播到未标记数据。标签传播方法可以应用于深度学习[[43](#bib.bib43)]。
- en: 2.3 Related Learning Paradigms
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 相关学习范式
- en: There are many learning paradigms that can make use of an extra data source
    to boost learning performance. Based on the availability of labels or the distribution
    difference in the extra data source, there are several learning paradigms related
    to semi-supervised learning.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多学习范式可以利用额外的数据源来提升学习性能。根据额外数据源的标签可用性或分布差异，有几种与半监督学习相关的学习范式。
- en: Transfer learning. Transfer learning [[44](#bib.bib44), [45](#bib.bib45), [46](#bib.bib46)]
    aims to apply knowledge from one or more source domains to a target domain in
    order to improve performance on the target task. In contrast to SSL, which works
    well under the hypothesis that the training set and the testing set are independent
    and identically distributed (i.i.d.), transfer learning allows domains, tasks,
    and distributions used in training and testing be different but related.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习。迁移学习 [[44](#bib.bib44), [45](#bib.bib45), [46](#bib.bib46)] 旨在将一个或多个源领域的知识应用于目标领域，以提高在目标任务上的表现。与SSL不同，SSL假设训练集和测试集是独立同分布（i.i.d.），迁移学习允许训练和测试中使用的领域、任务和分布可以不同但相关。
- en: 'Weakly-supervised learning. Weakly-supervised learning [[47](#bib.bib47)] relaxes
    the data dependence that requires ground-truth labels to be given for a large
    amount of training data set in strong supervision. There are three types of weakly
    supervised data: incomplete supervised data, inexact supervised data, and inaccurate
    supervised data. Incomplete supervised data means only a subset of training data
    is labeled. In this case, representative approaches are SSL and domain adaptation.
    Inexact supervised data suggests that the labels of training examples are coarse-grained,
    e.g., in the scenario of multi-instance learning. Inaccurate supervised data means
    that the given labels are not always ground-truth, such as in the situation of
    label noise learning.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 弱监督学习。弱监督学习 [[47](#bib.bib47)] 放宽了强监督中需要为大量训练数据集提供真实标签的数据依赖。弱监督数据有三种类型：不完全监督数据、不精确监督数据和不准确监督数据。不完全监督数据意味着只有部分训练数据被标记。在这种情况下，代表性的方法有SSL和领域适应。不精确监督数据表示训练样本的标签是粗粒度的，例如在多实例学习的场景中。不准确监督数据意味着给定的标签不总是实际的，例如在标签噪声学习的情况下。
- en: Positive and unlabeled learning. Positive and unlabeled (PU) learning [[48](#bib.bib48),
    [49](#bib.bib49)] is a variant of positive and negative binary classification,
    where the training data consists of positive samples and unlabeled samples. Each
    unlabeled instance can be either the positive and negative class. During the training
    procedure, only positive samples and unlabeled samples are available. We can think
    of PU learning as a special case of SSL.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 正负样本学习。正负样本（PU）学习 [[48](#bib.bib48), [49](#bib.bib49)] 是正负二分类的变体，其中训练数据包含正样本和未标记样本。每个未标记的实例可以是正类或负类。在训练过程中，只能使用正样本和未标记样本。我们可以将PU学习视为半监督学习（SSL）的一个特殊情况。
- en: Meta-learning. Meta-learning [[50](#bib.bib50), [51](#bib.bib51), [52](#bib.bib52),
    [53](#bib.bib53), [54](#bib.bib54)], also known as “learning to learn”, aims to
    learn new skills or adapt to new tasks rapidly with previous knowledge and a few
    training examples. It is well known that a good machine learning model often requires
    a large number of samples for training. The meta-learning model is expected to
    adapt and generalize to new environments that have been encountered during the
    training process. The adaptation process is essentially a mini learning session
    that occurs during the test but has limited exposure to new task configurations.
    Eventually, the adapted model can be trained on various learning tasks and optimized
    on the distribution of functions, including potentially unseen tasks.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 元学习。元学习 [[50](#bib.bib50), [51](#bib.bib51), [52](#bib.bib52), [53](#bib.bib53),
    [54](#bib.bib54)]，也称为“学习如何学习”，旨在利用之前的知识和少量训练样本快速学习新技能或适应新任务。众所周知，一个好的机器学习模型通常需要大量样本进行训练。元学习模型预计能够适应并推广到在训练过程中遇到的新环境。适应过程本质上是在测试期间发生的一个小型学习阶段，但对新任务配置的暴露有限。最终，适应后的模型可以在各种学习任务上进行训练，并在函数分布上进行优化，包括潜在的未见任务。
- en: Self-supervised learning. Self-supervised learning [[55](#bib.bib55), [56](#bib.bib56),
    [57](#bib.bib57)] has gained popularity due to its ability to prevent the expense
    of annotating large-scale datasets. It can leverage input data as supervision
    and use the learned feature representations for many downstream tasks. In this
    sense, self-supervised learning meets our expectations for efficient learning
    systems with fewer labels, fewer samples, or fewer trials. Since there is no manual
    label involved, self-supervised learning can be regarded as a branch of unsupervised
    learning.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习。自监督学习 [[55](#bib.bib55), [56](#bib.bib56), [57](#bib.bib57)] 因其能够避免注释大规模数据集的费用而受到了广泛关注。它可以利用输入数据作为监督，并将学习到的特征表示用于许多下游任务。从这个意义上讲，自监督学习符合我们对高效学习系统的期望，这些系统需要较少的标签、样本或试验。由于没有涉及人工标签，自监督学习可以视为无监督学习的一个分支。
- en: 2.4 Datasets and applications
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 数据集和应用
- en: SSL has many applications across different tasks and domains, such as image
    classification, object detection, semantic segmentation, etc. in the domain of
    computer vision, and text classification, sequence learning, etc. in the field
    of Natural Language Processing (NLP). As shown in TABLE [II](#S2.T2 "TABLE II
    ‣ 2.4 Datasets and applications ‣ 2 Background ‣ A Survey on Deep Semi-supervised
    Learning"), we summarize some of the most widely used datasets and representative
    references according to the applications area. In this survey, we mainly discuss
    the methods applied to image classification since these methods can be extended
    to other applications, such as [[58](#bib.bib58)] applied consistency training
    to object detection, [[59](#bib.bib59)] modified Semi-GANs to fit the scenario
    of semantic segmentation. There are many works that have achieved state-of-the-art
    performance within different applications. Most of these methods share details
    of the implementation and source code, and we refer the interested readers to
    a more detailed review of the datasets and corresponding references in TABLE [II](#S2.T2
    "TABLE II ‣ 2.4 Datasets and applications ‣ 2 Background ‣ A Survey on Deep Semi-supervised
    Learning").
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习在计算机视觉领域有许多应用，如图像分类、对象检测、语义分割等，在自然语言处理（NLP）领域也有应用，如文本分类、序列学习等。如表[II](#S2.T2
    "TABLE II ‣ 2.4 Datasets and applications ‣ 2 Background ‣ A Survey on Deep Semi-supervised
    Learning")所示，我们总结了一些最广泛使用的数据集和代表性参考文献，按应用领域进行分类。在这项调查中，我们主要讨论了应用于图像分类的方法，因为这些方法可以扩展到其他应用中，例如
    [[58](#bib.bib58)] 将一致性训练应用于对象检测，[[59](#bib.bib59)] 修改了Semi-GANs以适应语义分割的场景。许多工作在不同应用中取得了最先进的表现。这些方法中的大多数分享了实现细节和源代码，我们建议感兴趣的读者参考表[II](#S2.T2
    "TABLE II ‣ 2.4 Datasets and applications ‣ 2 Background ‣ A Survey on Deep Semi-supervised
    Learning")中的数据集和相关参考文献的更详细评述。
- en: 'TABLE II: Summary of Applications and Datasets'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：应用和数据集总结
- en: '| Applications | Datasets | Citations |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 应用 | 数据集 | 引用 |'
- en: '| Image classification | MNIST [[60](#bib.bib60)], SVHN [[61](#bib.bib61)],
    STL-10 [[62](#bib.bib62)], Cifar-10,Cifar-100 [[63](#bib.bib63)], ImageNet [[64](#bib.bib64)]
    | [[65](#bib.bib65), [66](#bib.bib66), [67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69),
    [70](#bib.bib70), [71](#bib.bib71), [72](#bib.bib72), [73](#bib.bib73)] |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | MNIST [[60](#bib.bib60)], SVHN [[61](#bib.bib61)], STL-10 [[62](#bib.bib62)],
    Cifar-10, Cifar-100 [[63](#bib.bib63)], ImageNet [[64](#bib.bib64)] | [[65](#bib.bib65),
    [66](#bib.bib66), [67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69), [70](#bib.bib70),
    [71](#bib.bib71), [72](#bib.bib72), [73](#bib.bib73)] |'
- en: '| Object detection | PASCAL VOC [[74](#bib.bib74)], MSCOCO [[75](#bib.bib75)],
    ILSVRC [[76](#bib.bib76)] | [[77](#bib.bib77), [58](#bib.bib58), [78](#bib.bib78),
    [79](#bib.bib79)] |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 对象检测 | PASCAL VOC [[74](#bib.bib74)], MSCOCO [[75](#bib.bib75)], ILSVRC [[76](#bib.bib76)]
    | [[77](#bib.bib77), [58](#bib.bib58), [78](#bib.bib78), [79](#bib.bib79)] |'
- en: '| 3D object detection | SUN RGB-D [[80](#bib.bib80)], ScanNet [[81](#bib.bib81)],
    KITTI [[82](#bib.bib82)] | [[83](#bib.bib83), [84](#bib.bib84)] |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 3D对象检测 | SUN RGB-D [[80](#bib.bib80)], ScanNet [[81](#bib.bib81)], KITTI
    [[82](#bib.bib82)] | [[83](#bib.bib83), [84](#bib.bib84)] |'
- en: '| Video salient object detection | VOS [[85](#bib.bib85)], DAVIS [[86](#bib.bib86)],
    FBMS [[87](#bib.bib87)] | [[88](#bib.bib88)] |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 视频显著对象检测 | VOS [[85](#bib.bib85)], DAVIS [[86](#bib.bib86)], FBMS [[87](#bib.bib87)]
    | [[88](#bib.bib88)] |'
- en: '| Semantic segmentation | PASCAL VOC [[74](#bib.bib74)], PASCAL context [[89](#bib.bib89)],
    MS COCO [[75](#bib.bib75)], Cityscapes [[90](#bib.bib90)], CamVid [[91](#bib.bib91)],
    SiftFlow [[92](#bib.bib92), [93](#bib.bib93)], StanfordBG [[94](#bib.bib94)] |
    [[95](#bib.bib95), [96](#bib.bib96), [97](#bib.bib97), [59](#bib.bib59), [98](#bib.bib98),
    [99](#bib.bib99), [100](#bib.bib100), [101](#bib.bib101), [102](#bib.bib102),
    [103](#bib.bib103)] |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 语义分割 | PASCAL VOC [[74](#bib.bib74)], PASCAL context [[89](#bib.bib89)],
    MS COCO [[75](#bib.bib75)], Cityscapes [[90](#bib.bib90)], CamVid [[91](#bib.bib91)],
    SiftFlow [[92](#bib.bib92), [93](#bib.bib93)], StanfordBG [[94](#bib.bib94)] |
    [[95](#bib.bib95), [96](#bib.bib96), [97](#bib.bib97), [59](#bib.bib59), [98](#bib.bib98),
    [99](#bib.bib99), [100](#bib.bib100), [101](#bib.bib101), [102](#bib.bib102),
    [103](#bib.bib103)] |'
- en: '| Text classification | AG News [[104](#bib.bib104)], BPpedia [[105](#bib.bib105)],
    Yahoo! Answers[[106](#bib.bib106)], IMDB [[107](#bib.bib107)], Yelp review [[104](#bib.bib104)],
    Snippets [[108](#bib.bib108)], Ohsumed [[109](#bib.bib109)], TagMyNews [[110](#bib.bib110)],
    MR [[111](#bib.bib111)], Elec [[112](#bib.bib112)], Rotten Tomatoes [[111](#bib.bib111)],
    RCV1 [[113](#bib.bib113)] | [[114](#bib.bib114), [115](#bib.bib115), [116](#bib.bib116),
    [117](#bib.bib117), [118](#bib.bib118), [119](#bib.bib119)] |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 文本分类 | AG News [[104](#bib.bib104)], BPpedia [[105](#bib.bib105)], Yahoo!
    Answers[[106](#bib.bib106)], IMDB [[107](#bib.bib107)], Yelp 评价 [[104](#bib.bib104)],
    Snippets [[108](#bib.bib108)], Ohsumed [[109](#bib.bib109)], TagMyNews [[110](#bib.bib110)],
    MR [[111](#bib.bib111)], Elec [[112](#bib.bib112)], Rotten Tomatoes [[111](#bib.bib111)],
    RCV1 [[113](#bib.bib113)] | [[114](#bib.bib114), [115](#bib.bib115), [116](#bib.bib116),
    [117](#bib.bib117), [118](#bib.bib118), [119](#bib.bib119)] |'
- en: '| Dialogue policy learning | MultiWOZ [[120](#bib.bib120)] | [[121](#bib.bib121)]
    |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 对话策略学习 | MultiWOZ [[120](#bib.bib120)] | [[121](#bib.bib121)] |'
- en: '| Dialogue generation | Cornell Movie Dialogs Corpus [[122](#bib.bib122)],
    Ubuntu Dialogue Corpus [[123](#bib.bib123)] | [[124](#bib.bib124)] |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 对话生成 | Cornell Movie Dialogs Corpus [[122](#bib.bib122)], Ubuntu Dialogue
    Corpus [[123](#bib.bib123)] | [[124](#bib.bib124)] |'
- en: '| Sequence learning | IMDB [[107](#bib.bib107)], Rotten Tomatoes [[111](#bib.bib111)],
    20 Newsgroups [[125](#bib.bib125)], DBpedia [[105](#bib.bib105)], CoNLL 2003 NER
    task [[126](#bib.bib126)], CoNLL 2000 Chunking task [[127](#bib.bib127)], Twitter
    POS Dataset [[128](#bib.bib128), [129](#bib.bib129)], Universal Dependencies(UD)
    [[130](#bib.bib130)], Combinatory Categorial Grammar (CCG) supertagging [[131](#bib.bib131)]
    | [[132](#bib.bib132), [133](#bib.bib133), [134](#bib.bib134), [135](#bib.bib135)]
    |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 序列学习 | IMDB [[107](#bib.bib107)], Rotten Tomatoes [[111](#bib.bib111)], 20
    Newsgroups [[125](#bib.bib125)], DBpedia [[105](#bib.bib105)], CoNLL 2003 NER
    任务 [[126](#bib.bib126)], CoNLL 2000 Chunking 任务 [[127](#bib.bib127)], Twitter
    POS 数据集 [[128](#bib.bib128), [129](#bib.bib129)], Universal Dependencies(UD) [[130](#bib.bib130)],
    组合范畴语法 (CCG) 超标记 [[131](#bib.bib131)] | [[132](#bib.bib132), [133](#bib.bib133),
    [134](#bib.bib134), [135](#bib.bib135)] |'
- en: '| Semantic role labeling | CoNLL-2009 [[136](#bib.bib136)], CoNLL-2013 [[137](#bib.bib137)]
    | [[138](#bib.bib138), [139](#bib.bib139), [140](#bib.bib140)] |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 语义角色标注 | CoNLL-2009 [[136](#bib.bib136)], CoNLL-2013 [[137](#bib.bib137)]
    | [[138](#bib.bib138), [139](#bib.bib139), [140](#bib.bib140)] |'
- en: '| Question answering | SQuAD [[141](#bib.bib141)], TriviaQA [[142](#bib.bib142)]
    | [[143](#bib.bib143), [144](#bib.bib144), [145](#bib.bib145)] |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 问答 | SQuAD [[141](#bib.bib141)], TriviaQA [[142](#bib.bib142)] | [[143](#bib.bib143),
    [144](#bib.bib144), [145](#bib.bib145)] |'
- en: 3 Generative methods
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 生成方法
- en: As discussed in Subsection [2.2](#S2.SS2 "2.2 Classical Semi-supervised learning
    Methods ‣ 2 Background ‣ A Survey on Deep Semi-supervised Learning"), generative
    methods can learn the implicit features of data to better model data distributions.
    They model the real data distribution from the training dataset and then generate
    new data with this distribution. In this section, we review the deep generative
    semi-supervised methods based on the Generative Adversarial Network (GAN) framework
    and the Variational AutoEncoder (VAE) framework, respectively.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如在小节 [2.2](#S2.SS2 "2.2 经典半监督学习方法 ‣ 2 背景 ‣ 深度半监督学习概述")中讨论的那样，生成方法可以学习数据的隐含特征，以更好地建模数据分布。它们从训练数据集中建模真实的数据分布，然后生成具有该分布的新数据。在这一部分，我们将分别回顾基于生成对抗网络（GAN）框架和变分自编码器（VAE）框架的深度生成半监督方法。
- en: '![Refer to caption](img/ec30c67af15797b49d520e176b83f96a.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ec30c67af15797b49d520e176b83f96a.png)'
- en: 'Figure 2: A glimpse of the diverse range of architectures used for GAN-based
    deep generative semi-supervised methods. The characters ‘$`D,G$” and “$E$” represent
    *Discriminator*, *Generator* and *Encoder*, respectively. In Figure (6), Localized
    GAN is equipped with a local generator $G(x,z)$, so we use the yellow box to distinguish
    it. Similarly, in CT-GAN, the purple box is used to denote a discriminator that
    introduces consistency constraint.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：展示了用于基于 GAN 的深度生成半监督方法的各种架构。字符‘$`D,G$” 和 “$E$” 分别代表 *判别器*、*生成器* 和 *编码器*。在图（6）中，本地化
    GAN 配备了一个局部生成器 $G(x,z)$，因此我们使用黄色框进行区分。类似地，在 CT-GAN 中，紫色框用于表示引入一致性约束的判别器。
- en: 3.1 Semi-supervised GANs
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 半监督 GANs
- en: 'A typical GAN [[146](#bib.bib146)] consists of a generator $G$ and a discriminator
    $D$ (see Fig. [2](#S3.F2 "Figure 2 ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning")(2)). The goal of $G$ is to learn a distribution $p_{g}$ over data $x$
    given a prior on input noise variables $p_{z}(z)$. The fake samples $G(z)$ generated
    by the generator $G$ are used to confuse the discriminator $D$. The discriminator
    $D$ is used to maximize the distinction between real training samples $x$ and
    fake samples $G(z)$. As we can see, $D$ and $G$ play the following two-player
    minimax game with the value function $V(G,D)$:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的 GAN [[146](#bib.bib146)] 由一个生成器 $G$ 和一个判别器 $D$ 组成（见图 [2](#S3.F2 "Figure
    2 ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(2)）。$G$
    的目标是学习一个数据 $x$ 上的分布 $p_{g}$，该数据给定了输入噪声变量 $p_{z}(z)$ 的先验。生成器 $G$ 生成的虚假样本 $G(z)$
    被用来迷惑判别器 $D$。判别器 $D$ 的任务是最大化真实训练样本 $x$ 和虚假样本 $G(z)$ 之间的区别。正如我们所见，$D$ 和 $G$ 通过值函数
    $V(G,D)$ 玩着以下双人博弈：
- en: '|  | $\displaystyle\min\limits_{G}\max\limits_{D}V(D,G)=\mathbb{E}_{x\sim p(x)}[\text{log}D(x)]$
    |  |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\min\limits_{G}\max\limits_{D}V(D,G)=\mathbb{E}_{x\sim p(x)}[\text{log}D(x)]$
    |  |'
- en: '|  | $\displaystyle+\mathbb{E}_{z\sim p_{z}}[\text{log}(1-D(G(z)))].$ |  |
    (2) |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle+\mathbb{E}_{z\sim p_{z}}[\text{log}(1-D(G(z)))].$ |  |
    (2) |'
- en: Since GANs can learn the distribution of real data from unlabeled samples, it
    can be used to facilitate SSL. There are many ways to use GANs in SSL settings.
    Inspired by [[147](#bib.bib147)], we have identified four main themes in how to
    use GANs for SSL, i.e., (a) re-using the features from the discriminator, (b)
    using GAN-generated samples to regularize a classifier, (c) learning an inference
    model, and (d) using samples produced by a GAN as additional training data.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 GANs 可以从未标记的样本中学习真实数据的分布，因此它可以用于促进 SSL。在 SSL 设置中使用 GAN 的方式有很多。受 [[147](#bib.bib147)]
    启发，我们确定了使用 GAN 进行 SSL 的四个主要主题，即：（a）重新利用来自判别器的特征，（b）使用 GAN 生成的样本来规范化分类器，（c）学习推断模型，以及（d）使用
    GAN 生成的样本作为额外的训练数据。
- en: A simple SSL approach is to combine supervised and unsupervised loss during
    training. [[148](#bib.bib148)] demonstrates that a hierarchical representation
    of the GAN-discriminator is useful for object classification. These findings indicate
    that a simple and efficient SSL method can be provided by combining an unsupervised
    GAN value function with a supervised classification objective function, e.g.,
    $\mathbb{E}_{(x,y)\in X_{l}}[\log D(y|x)]$. In the following, we review several
    representative methods of semi-supervised GANs.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 一种简单的 SSL 方法是在训练过程中结合有监督和无监督损失。[[148](#bib.bib148)] 证明了 GAN-判别器的层次表示对于对象分类是有用的。这些发现表明，通过将无监督
    GAN 值函数与有监督分类目标函数结合，例如 $\mathbb{E}_{(x,y)\in X_{l}}[\log D(y|x)]$，可以提供一种简单而有效的
    SSL 方法。接下来，我们回顾几种代表性的半监督 GAN 方法。
- en: 'CatGAN. Categorical Generative Adversarial Network (CatGAN) [[149](#bib.bib149)]
    modifies the GAN’s objective function to take into account the mutual information
    between observed examples and their predicted categorical class distributions.
    In particular, the optimization problem is different from the standard GAN (Eq. ([2](#S3.E2
    "In 3.1 Semi-supervised GANs ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning"))). The structure is illustrated in Fig. [2](#S3.F2 "Figure 2 ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")(3). This method aims to
    learn a discriminator which distinguishes the samples into $K$ categories by labeling
    $y$ to each $x$, instead of learning a binary discriminator value function. Moreover,
    in the CatGAN discriminator loss function, the supervised loss is also a cross-entropy
    term between the predicted conditional distribution $p(y|x,D)$ and the true label
    distribution of examples. It consists of three parts: (1) entropy $H[p(y|x,D)]$
    which to obtain certain category assignment for samples; (2) $H[p(y|G(z),D)]$
    for uncertain predictions from generated samples; and (3) the marginal class entropy
    $H[p(y|D)]$ to uniform usage of all classes. The proposed framework uses the feature
    space learned by the discriminator for the final learning task. For the labeled
    data, the supervised loss is also a cross-entropy term between the conditional
    distribution $p(y|x,D)$ and the samples’ true label distribution.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: CatGAN。分类生成对抗网络（CatGAN）[[149](#bib.bib149)] 修改了GAN的目标函数，以考虑观察样本与其预测的类别分布之间的互信息。特别地，优化问题与标准GAN不同（见
    Eq. ([2](#S3.E2 "In 3.1 Semi-supervised GANs ‣ 3 Generative methods ‣ A Survey
    on Deep Semi-supervised Learning"))）。该结构如图 [2](#S3.F2 "Figure 2 ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")(3) 所示。该方法旨在学习一个判别器，该判别器通过给每个
    $x$ 标注 $y$，将样本区分为 $K$ 类，而不是学习一个二值判别器值函数。此外，在 CatGAN 的判别器损失函数中，监督损失也是一个交叉熵项，表示预测的条件分布
    $p(y|x,D)$ 和样本的真实标签分布之间的差异。它由三部分组成：（1）熵 $H[p(y|x,D)]$，用于获得样本的特定类别分配；（2）$H[p(y|G(z),D)]$，用于来自生成样本的不确定预测；（3）边际类别熵
    $H[p(y|D)]$，用于所有类别的均匀使用。提出的框架使用判别器学习到的特征空间用于最终的学习任务。对于标记数据，监督损失也是一个交叉熵项，表示条件分布
    $p(y|x,D)$ 和样本的真实标签分布之间的差异。
- en: CCGAN. Context-Conditional Generative Adversarial Networks (CCGAN) [[150](#bib.bib150)]
    is proposed to use an adversarial loss for harnessing unlabeled image data based
    on image in-painting. The architecture of the CCGAN is shown in Fig. [2](#S3.F2
    "Figure 2 ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(4).
    The main highlight of this work is context information provided by the surrounding
    parts of the image. The method trains a GAN where the generator is to generate
    pixels within a missing hole. The discriminator is to discriminate between the
    real unlabeled images and these in-painted images. More formally, $m\odot x$ as
    input to a generator, where $m$ denotes a binary mask to drop out a specified
    portion of an image and $\odot$ denotes element-wise multiplication. Thus the
    in-painted image $x_{I}=(1-m)\odot x_{G}+m\odot x$ with generator outputs $x_{G}=G(m\odot
    x,z)$. The in-painted examples provided by the generator cause the discriminator
    to learn features that generalize to the related task of classifying objects.
    The penultimate layer of components of the discriminator is then shared with the
    classifier, whose cross-entropy loss is used combined with the discriminator loss.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: CCGAN。上下文条件生成对抗网络（CCGAN）[[150](#bib.bib150)] 的提出是为了利用对抗损失来利用基于图像修补的未标记图像数据。CCGAN的架构如图
    [2](#S3.F2 "Figure 2 ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning")(4) 所示。这项工作的主要亮点是图像周围部分提供的上下文信息。该方法训练一个生成对抗网络（GAN），其中生成器用于生成缺失区域内的像素。判别器则用于区分真实的未标记图像和这些修补后的图像。更正式地，$m\odot
    x$ 作为生成器的输入，其中 $m$ 表示一个二进制掩模，用于丢弃图像的指定部分，$\odot$ 表示逐元素乘法。因此，修补后的图像 $x_{I}=(1-m)\odot
    x_{G}+m\odot x$ 由生成器输出 $x_{G}=G(m\odot x,z)$。生成器提供的修补示例使得判别器能够学习到对分类对象相关任务的特征。然后，判别器的倒数第二层组件与分类器共享，分类器的交叉熵损失与判别器损失结合使用。
- en: Improved GAN. There are several methods to adapt GANs into a semi-supervised
    classification scenario. CatGAN [[149](#bib.bib149)] forces the discriminator
    to maximize the mutual information between examples and their predicted class
    distributions instead of training the discriminator to learn a binary classification.
    To overcome the learned representations’ bottleneck of CatGAN, Semi-supervised
    GAN (SGAN) [[151](#bib.bib151)] learns a generator and a classifier simultaneously.
    The classifier network can have $(K+1)$ output units corresponding to $[y_{1},y_{2},\ldots,y_{K},y_{K+1}]$,
    where the $y_{K+1}$ represents the outputs generated by $G$. Similar to SGAN,
    Improved GAN [[152](#bib.bib152)] solves a $(K+1)$-class classification problem.
    The structure of Improved GAN is shown in Fig. [2](#S3.F2 "Figure 2 ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")(5). Real examples for one
    of the first $K$ classes and the additional $(K+1)$th class consisted of the synthetic
    images generated by the generator $G$. This work proposes the improved techniques
    to train the GANs, i.e., feature matching, minibatch discrimination, historical
    averaging one-sided label smoothing, and virtual batch normalization, where feature
    matching is used to train the generator. It is trained by minimizing the discrepancy
    between features of the real and the generated examples, that is $\|\mathbb{E}_{x\in
    X}D(x)-\mathbb{E}_{z\sim p(z)}D(G(z))\|_{2}^{2}$, rather than maximizing the likelihood
    of its generated examples classified to $K$ real classes. The loss function for
    training the classifier becomes
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 改进的GAN。有几种方法可以将GAN适应于半监督分类场景。CatGAN [[149](#bib.bib149)] 强制鉴别器最大化示例及其预测类别分布之间的互信息，而不是训练鉴别器来学习二分类。为了解决CatGAN学习表示的瓶颈，半监督GAN（SGAN）[[151](#bib.bib151)]
    同时学习生成器和分类器。分类器网络可以具有 $(K+1)$ 个输出单元，对应于 $[y_{1},y_{2},\ldots,y_{K},y_{K+1}]$，其中
    $y_{K+1}$ 代表由 $G$ 生成的输出。类似于SGAN，改进的GAN [[152](#bib.bib152)] 解决了一个 $(K+1)$ 类分类问题。改进GAN的结构如图[2](#S3.F2
    "Figure 2 ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(5)所示。前
    $K$ 个类别的真实示例和额外的 $(K+1)$ 类由生成器 $G$ 生成的合成图像组成。本工作提出了训练GAN的改进技术，即特征匹配、小批量判别、历史平均单边标签平滑和虚拟批量归一化，其中特征匹配用于训练生成器。它通过最小化真实和生成示例特征之间的差异
    $\|\mathbb{E}_{x\in X}D(x)-\mathbb{E}_{z\sim p(z)}D(G(z))\|_{2}^{2}$ 进行训练，而不是最大化其生成示例被分类为
    $K$ 个真实类别的可能性。用于训练分类器的损失函数变为
- en: '|  |  | $\displaystyle\max_{D}\mathbb{E}_{(x,y)\sim p(x,y)}\log p_{D}(y&#124;x,y\leq
    K)$ |  | (3) |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\max_{D}\mathbb{E}_{(x,y)\sim p(x,y)}\log p_{D}(y\mid
    x,y\leq K)$ |  | (3) |'
- en: '|  |  | $\displaystyle+\mathbb{E}_{x\sim p(x)}\log p_{D}(y\leq K&#124;x)+\mathbb{E}_{x\sim
    p_{G}}\log p_{D}(y=K+1&#124;x),$ |  |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle+\mathbb{E}_{x\sim p(x)}\log p_{D}(y\leq K\mid x)+\mathbb{E}_{x\sim
    p_{G}}\log p_{D}(y=K+1\mid x),$ |  |'
- en: where the first term of Eq. ([3](#S3.E3 "In 3.1 Semi-supervised GANs ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")) denotes the supervised
    cross-entropy loss, The last two terms of Eq. ([3](#S3.E3 "In 3.1 Semi-supervised
    GANs ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")) are
    the unsupervised losses from the unlabeled and generated data, respectively.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 方程式（[3](#S3.E3 "In 3.1 Semi-supervised GANs ‣ 3 Generative methods ‣ A Survey
    on Deep Semi-supervised Learning")）中的第一个项表示监督交叉熵损失，方程式（[3](#S3.E3 "In 3.1 Semi-supervised
    GANs ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")）中的最后两个项分别是来自未标记数据和生成数据的无监督损失。
- en: GoodBadGAN. GoodBadGAN [[153](#bib.bib153)] realizes that the generator and
    discriminator in [[152](#bib.bib152)] may not be optimal simultaneously, i.e.,
    the discriminator achieves good performance in SSL, while the generator may generate
    visually unrealistic samples. The structure of GoodBadGAN is shown in Fig. [2](#S3.F2
    "Figure 2 ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(5).
    The method gives theoretical justifications of why using bad samples from the
    generator can boost the SSL performance. Generally, the generated samples, along
    with the loss function (Eq. ([3](#S3.E3 "In 3.1 Semi-supervised GANs ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning"))), can force the boundary
    of the discriminator to lie between the data manifolds of different categories,
    which improves the generalization of the discriminator. Due to the analysis, GoodBadGAN
    learns a bad generator by explicitly adding a penalty term $\mathbb{E}_{x\sim
    p_{G}}\log p(x)\mathbb{I}[p(x)>\epsilon]$ to generate bad samples, where $\mathbb{I}[\cdot]$
    is an indicator function and $\epsilon$ is a threshold, which ensures that only
    high-density samples are penalized while low-density samples are unaffected. Further,
    to guarantee the strong true-fake belief in the optimal conditions, a conditional
    entropy term $\mathbb{E}_{x\sim p_{x}}\sum_{k=1}^{K}\log p_{D}(k|x)$ is added
    to the discriminator objective function in Eq. ([3](#S3.E3 "In 3.1 Semi-supervised
    GANs ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: GoodBadGAN。GoodBadGAN [[153](#bib.bib153)] 认识到[[152](#bib.bib152)]中的生成器和判别器可能不是同时最优的，即判别器在SSL中表现良好，而生成器可能生成视觉上不现实的样本。GoodBadGAN的结构如图 [2](#S3.F2
    "Figure 2 ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(5)所示。该方法对为何使用生成器的不良样本可以提升SSL性能进行了理论上的论证。通常，生成的样本以及损失函数（Eq. ([3](#S3.E3
    "In 3.1 Semi-supervised GANs ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning"))），可以迫使判别器的边界位于不同类别的数据流形之间，从而提高判别器的泛化能力。通过分析，GoodBadGAN通过显式添加一个惩罚项$\mathbb{E}_{x\sim
    p_{G}}\log p(x)\mathbb{I}[p(x)>\epsilon]$来学习一个劣质生成器，以生成不良样本，其中$\mathbb{I}[\cdot]$是指示函数，$\epsilon$是一个阈值，确保只有高密度样本受到惩罚，而低密度样本不受影响。此外，为了保证在最佳条件下的强烈真假信念，在Eq. ([3](#S3.E3
    "In 3.1 Semi-supervised GANs ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning"))的判别器目标函数中添加了条件熵项$\mathbb{E}_{x\sim p_{x}}\sum_{k=1}^{K}\log p_{D}(k|x)$。
- en: Localized GAN. Localized GAN [[154](#bib.bib154)] focuses on using local coordinate
    charts to parameterize local geometry of data transformations across different
    locations manifold rather than the global one. This work suggests that Localized
    GAN can help train a locally consistent classifier by exploring the manifold geometry.
    The architecture of Localized GAN is shown in Fig. [2](#S3.F2 "Figure 2 ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")(6). Like the methods introduced
    in [[152](#bib.bib152), [153](#bib.bib153)], Localized GAN attempts to solve the
    $K+1$ classification problem that outputs the probability of $x$ being assigned
    to a class. For a classifier, $\nabla_{z}D(G(x,z))$ depicts the change of the
    classification decision on the manifold formed by $G(x,z)$, and the evolution
    of $D(\cdot)$ restricted on $G(x,z)$ can be written as
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 局部化GAN。局部化GAN [[154](#bib.bib154)] 侧重于使用局部坐标图来参数化数据变换的局部几何，而不是全局几何。这项工作表明，局部化GAN通过探索流形几何，可以帮助训练一个局部一致的分类器。局部化GAN的架构如图 [2](#S3.F2
    "Figure 2 ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(6)所示。与[[152](#bib.bib152),
    [153](#bib.bib153)]中介绍的方法类似，局部化GAN试图解决$K+1$分类问题，该问题输出$x$被分配到某一类别的概率。对于一个分类器，$\nabla_{z}D(G(x,z))$描述了在$G(x,z)$形成的流形上分类决策的变化，$D(\cdot)$在$G(x,z)$上的演化可以写成
- en: '|  | $&#124;D(G(x,z+\sigma z))-D(G(x,z))&#124;^{2}\approx\&#124;\nabla_{x}^{G}D(x)\&#124;^{2}\sigma
    z,$ |  | (4) |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '|  | $&#124;D(G(x,z+\sigma z))-D(G(x,z))&#124;^{2}\approx\&#124;\nabla_{x}^{G}D(x)\&#124;^{2}\sigma
    z,$ |  | (4) |'
- en: which shows that penalizing $\|\nabla_{x}^{G}D(x)\|^{2}$ can train a robust
    classifier with a small perturbation $\sigma z$ on a manifold. This probabilistic
    classifier can be introduced by adding $\sum_{k=1}^{K}\mathbb{E}_{x\sim p_{x}}\|\nabla_{x}^{G}\log
    p(y=k|x)\|^{2}$, where $\nabla_{x}^{G}\log p(y=k|x)$ is the gradient of the log-likelihood
    along with the manifold $G(x,z)$.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明，通过惩罚$\|\nabla_{x}^{G}D(x)\|^{2}$可以在流形上训练一个对小扰动$\sigma z$具有鲁棒性的分类器。可以通过添加$\sum_{k=1}^{K}\mathbb{E}_{x\sim
    p_{x}}\|\nabla_{x}^{G}\log p(y=k|x)\|^{2}$来引入这种概率分类器，其中$\nabla_{x}^{G}\log p(y=k|x)$是沿流形$G(x,z)$的对数似然的梯度。
- en: CT-GAN. CT-GAN [[155](#bib.bib155)] combines consistency training with WGAN
    [[156](#bib.bib156)] applied to semi-supervised classification problems. And the
    structure of CT-GAN is shown in Fig. [2](#S3.F2 "Figure 2 ‣ 3 Generative methods
    ‣ A Survey on Deep Semi-supervised Learning")(7). Following [[157](#bib.bib157)],
    this method also lays the Lipschitz continuity condition over the manifold of
    the real data to improve the improved training of WGAN. Moreover, CT-GAN devises
    a regularization over a pair of samples drawn near the manifold following the
    most basic definition of the 1-Lipschitz continuity. In particular, each real
    instance $x$ is perturbed twice and uses a Lipschitz constant to bound the difference
    between the discriminator’s responses to the perturbed instances $x^{\prime},x^{\prime\prime}$.
    Formally, since the value function of WGAN is
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: CT-GAN。CT-GAN [[155](#bib.bib155)] 将一致性训练与应用于半监督分类问题的 WGAN [[156](#bib.bib156)]
    相结合。CT-GAN 的结构如图 [2](#S3.F2 "图 2 ‣ 3 生成方法 ‣ 深度半监督学习概述")(7) 所示。按照 [[157](#bib.bib157)]，该方法还在真实数据的流形上施加
    Lipschitz 连续性条件，以改进 WGAN 的训练。此外，CT-GAN 针对在流形附近抽取的一对样本设计了一种正则化，遵循 1-Lipschitz 连续性的最基本定义。特别地，每个真实样本
    $x$ 被扰动两次，并使用 Lipschitz 常数来限制扰动实例 $x^{\prime},x^{\prime\prime}$ 的判别器响应之间的差异。形式上，由于
    WGAN 的值函数是
- en: '|  | $\min_{G}\max_{D}\mathbb{E}_{x\sim p_{x}}D(x)-\mathbb{E}_{z\sim p_{z}}D(G(z)),$
    |  | (5) |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{G}\max_{D}\mathbb{E}_{x\sim p_{x}}D(x)-\mathbb{E}_{z\sim p_{z}}D(G(z)),$
    |  | (5) |'
- en: 'where $D$ is one of the sets of 1-Lipschitz function. The objective function
    for updating the discriminator include: (a) basic Wasserstein distance in Eq. ([5](#S3.E5
    "In 3.1 Semi-supervised GANs ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning")), (b) gradient penalty $GP|_{\hat{x}}$ [[157](#bib.bib157)] used in
    the improved training of WGAN, where $\hat{x}=\epsilon x+(1-\epsilon)G(z)$, and
    (c) A consistency regularization $CT|_{x^{\prime},x^{\prime\prime}}$. For semi-supervised
    classification, CT-GAN uses the Eq. ([3](#S3.E3 "In 3.1 Semi-supervised GANs ‣
    3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")) for training
    the discriminator instead of the Eq.( [5](#S3.E5 "In 3.1 Semi-supervised GANs
    ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")), and then
    adds the consistency regularization $CT|_{x^{\prime},x^{\prime\prime}}$.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$D$ 是 1-Lipschitz 函数集之一。用于更新判别器的目标函数包括：（a）公式 ([5](#S3.E5 "在 3.1 半监督 GAN ‣
    3 生成方法 ‣ 深度半监督学习概述")) 中的基本 Wasserstein 距离，（b）改进的 WGAN 训练中使用的梯度惩罚 $GP|_{\hat{x}}$
    [[157](#bib.bib157)]，其中 $\hat{x}=\epsilon x+(1-\epsilon)G(z)$，以及 （c）一致性正则化 $CT|_{x^{\prime},x^{\prime\prime}}$。对于半监督分类，CT-GAN
    使用公式 ([3](#S3.E3 "在 3.1 半监督 GAN ‣ 3 生成方法 ‣ 深度半监督学习概述")) 来训练判别器，而不是公式 ([5](#S3.E5
    "在 3.1 半监督 GAN ‣ 3 生成方法 ‣ 深度半监督学习概述"))，然后添加一致性正则化 $CT|_{x^{\prime},x^{\prime\prime}}$。
- en: BiGAN. Bidirectional Generative Adversarial Networks (BiGANs) [[158](#bib.bib158)]
    is an unsupervised feature learning framework. The architecture of BiGAN is shown
    in Fig. [2](#S3.F2 "Figure 2 ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning")(8). In contrast to the standard GAN framework, BiGAN adds an encoder
    $E$ to this framework, which maps data $x$ to $z^{\prime}$, resulting in a data
    pair $(x,z^{\prime})$. The data pair $(x,z^{\prime})$ and the data pair generated
    by generator $G$ constitute two kinds of true and fake data pairs. The BiGAN discriminator
    $D$ is to distinguish the true and fake data pairs. In this work, the value function
    for training the discriminator becomes,
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: BiGAN。双向生成对抗网络（BiGANs）[[158](#bib.bib158)] 是一个无监督特征学习框架。BiGAN 的架构如图 [2](#S3.F2
    "图 2 ‣ 3 生成方法 ‣ 深度半监督学习概述")(8) 所示。与标准 GAN 框架相比，BiGAN 向该框架添加了一个编码器 $E$，它将数据 $x$
    映射到 $z^{\prime}$，从而得到一对数据 $(x,z^{\prime})$。数据对 $(x,z^{\prime})$ 和生成器 $G$ 生成的数据对构成了两种真实和虚假的数据对。BiGAN
    判别器 $D$ 的任务是区分真实和虚假的数据对。在这项工作中，训练判别器的值函数变为，
- en: '|  | $\displaystyle\min_{G,E}\max_{D}V(D,E,G)=\mathbb{E}_{x\sim\mathcal{X}}\underset{\log
    D(x,E(x))}{\underbrace{\left[\mathbb{E}_{z\sim p_{E}\left(\cdot&#124;x\right)}\left[\log
    D\left(x,z\right)\right]\right]}}$ |  | (6) |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\min_{G,E}\max_{D}V(D,E,G)=\mathbb{E}_{x\sim\mathcal{X}}\underset{\log
    D(x,E(x))}{\underbrace{\left[\mathbb{E}_{z\sim p_{E}\left(\cdot|x\right)}\left[\log
    D\left(x,z\right)\right]\right]}}$ |  | (6) |'
- en: '|  | $\displaystyle+\mathbb{E}_{z\sim p\left(z\right)}\underset{\log\left(1-D\left(G\left(z\right),z\right)\right)}{\underbrace{\left[\mathbb{E}_{x\sim
    p_{G}\left(\cdot&#124;z\right)}\left[\log\left(1-D\left(x,z\right)\right)\right]\right]}}.$
    |  |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle+\mathbb{E}_{z\sim p\left(z\right)}\underset{\log\left(1-D\left(G\left(z\right),z\right)\right)}{\underbrace{\left[\mathbb{E}_{x\sim
    p_{G}\left(\cdot|z\right)}\left[\log\left(1-D\left(x,z\right)\right)\right]\right]}}.$
    |  |'
- en: ALI. Adversarially Learned Inference (ALI) [[159](#bib.bib159)] is a GAN-like
    adversarial framework based on the combination of an inference network and a generative
    model. This framework consists of three networks, a generator, an inference network
    and a discriminator. The generative network $G$ is used as a decoder to map latent
    variables $z$ (with a prior distribution) to data distribution $x^{\prime}=G(z)$,
    which can be formed as joint pairs $(x^{\prime},z)$. The inference network $E$
    attempts to encode training samples $x$ to latent variables $z^{\prime}=E(x)$,
    and joint pairs $(x,z^{\prime})$ are similarly drawn. The discriminator network
    $D$ is required to distinguish the joint pairs $(x,z^{\prime})$ from the joint
    pairs $(x^{\prime},z)$. As discussed above, the central architecture of ALI is
    regarded as similar to the BiGAN’s (see Fig. [2](#S3.F2 "Figure 2 ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")(8). In semi-supervised settings,
    this framework adapts the discriminator network proposed in [[152](#bib.bib152)],
    and shows promising performance on semi-supervised benchmarks on SVHN and CIFAR
    10\. The objective function can be rewritten as an extended version similar to
    Eq. ([6](#S3.E6 "In 3.1 Semi-supervised GANs ‣ 3 Generative methods ‣ A Survey
    on Deep Semi-supervised Learning")).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ALI（对抗性学习推断，Adversarially Learned Inference）[[159](#bib.bib159)] 是一种类似于GAN的对抗性框架，它基于推断网络和生成模型的组合。该框架由三个网络组成：生成器、推断网络和判别器。生成网络
    $G$ 用作解码器，将潜在变量 $z$（具有先验分布）映射到数据分布 $x^{\prime}=G(z)$，这些数据可以形成联合对 $(x^{\prime},z)$。推断网络
    $E$ 试图将训练样本 $x$ 编码为潜在变量 $z^{\prime}=E(x)$，并以类似方式生成联合对 $(x,z^{\prime})$。判别器网络 $D$
    需要区分联合对 $(x,z^{\prime})$ 和 $(x^{\prime},z)$。正如上文所讨论的，ALI 的核心架构被认为与 BiGAN 类似（见图
    [2](#S3.F2 "Figure 2 ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning") (8)）。在半监督设置中，该框架采用了 [[152](#bib.bib152)] 中提出的判别器网络，并在 SVHN 和 CIFAR
    10 的半监督基准上展示了有前景的性能。目标函数可以被重写为类似于 Eq. ([6](#S3.E6 "In 3.1 Semi-supervised GANs
    ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")) 的扩展版本。
- en: Augmented BiGAN. Kumar et al. [[160](#bib.bib160)] propose an extension of BiGAN
    called Augmented BiGAN for SSL. This framework has a BiGAN-like architecture that
    consists of an encoder, a generator and a discriminator. Since trained GANs produce
    realistic images, the generator can be considered to obtain the tangent spaces
    of the image manifold. The estimated tangents infer the desirable invariances
    which can be injected into the discriminator to improve SSL performance. In particular,
    the Augmented BiGAN uses feature matching loss [[152](#bib.bib152)], $\|\mathbb{E}_{x\in
    X}D(E(x),x)-\mathbb{E}_{z\sim p(z)}D(z,G(z))\|^{2}_{2}$ to optimize the generator
    network and the encoder network. Moreover, to avoid the issue of class-switching
    (the class of $G(E(x))$ changed during the decoupled training), a third pair $(E(x),G(E(x)))$
    loss term $\mathbb{E}_{x\sim p(x)}[\log(1-D(E(x),G_{x}(E(x))))]$ is added to the
    objective function Eq. ([6](#S3.E6 "In 3.1 Semi-supervised GANs ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展 BiGAN。Kumar 等人 [[160](#bib.bib160)] 提出了一个名为扩展 BiGAN 的 BiGAN 扩展用于 SSL。该框架具有类似
    BiGAN 的架构，包括编码器、生成器和判别器。由于训练好的 GAN 生成逼真的图像，生成器可以被视为获得图像流形的切线空间。估计的切线推断出所需的不变性，这些不变性可以被注入判别器以提高
    SSL 性能。特别地，扩展 BiGAN 使用特征匹配损失 [[152](#bib.bib152)]，$\|\mathbb{E}_{x\in X}D(E(x),x)-\mathbb{E}_{z\sim
    p(z)}D(z,G(z))\|^{2}_{2}$ 来优化生成器网络和编码器网络。此外，为了避免类切换问题（$G(E(x))$ 的类别在解耦训练过程中发生变化），在目标函数
    Eq. ([6](#S3.E6 "In 3.1 Semi-supervised GANs ‣ 3 Generative methods ‣ A Survey
    on Deep Semi-supervised Learning")) 中添加了第三对 $(E(x),G(E(x)))$ 损失项 $\mathbb{E}_{x\sim
    p(x)}[\log(1-D(E(x),G_{x}(E(x))))]$。
- en: Triple GAN. Triple GAN [[161](#bib.bib161)] is presented to address the issue
    that the generator and discriminator of GAN have incompatible loss functions,
    i.e., the generator and the discriminator can not be optimal at the same time
    [[152](#bib.bib152)]. The problem has been mentioned in [[153](#bib.bib153)],
    but the solution is different. As shown in Fig. [2](#S3.F2 "Figure 2 ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")(9), the Triple GAN tackles
    this problem by playing a three-player game. This three-player framework consists
    of three parts, a generator $G$ using a conditional network to generate the corresponding
    fake samples for the true labels, a classifier $C$ that generates pseudo labels
    for given real data, and a discriminator $D$ distinguishing whether a data-label
    pair is from the real-label dataset or not. This Triple GAN loss function may
    be written as
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Triple GAN。Triple GAN [[161](#bib.bib161)] 被提出以解决生成对抗网络（GAN）中的生成器和鉴别器具有不兼容损失函数的问题，即生成器和鉴别器不能同时达到最佳
    [[152](#bib.bib152)]。这一问题在 [[153](#bib.bib153)] 中已被提及，但解决方案有所不同。如图 [2](#S3.F2
    "Figure 2 ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(9)
    所示，Triple GAN 通过玩三方博弈来解决这个问题。这个三方框架包括三个部分：一个使用条件网络生成对应于真实标签的伪样本的生成器 $G$，一个为给定真实数据生成伪标签的分类器
    $C$，以及一个区分数据-标签对是否来自真实标签数据集的鉴别器 $D$。Triple GAN 的损失函数可以写作
- en: '|  | $\displaystyle\min_{C,G}\max_{D}V(C,G,D)=\mathbb{E}_{\left(x,y\right)\sim
    p\left(x,y\right)}\left[\log D\left(x,y\right)\right]$ |  | (7) |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\min_{C,G}\max_{D}V(C,G,D)=\mathbb{E}_{\left(x,y\right)\sim
    p\left(x,y\right)}\left[\log D\left(x,y\right)\right]$ |  | (7) |'
- en: '|  | $\displaystyle+~{}\alpha\mathbb{E}_{\left(x,y\right)\sim p_{c}\left(x,y\right)}\left[\log\left(1-D\left(x,y\right)\right)\right]$
    |  |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle+~{}\alpha\mathbb{E}_{\left(x,y\right)\sim p_{c}\left(x,y\right)}\left[\log\left(1-D\left(x,y\right)\right)\right]$
    |  |'
- en: '|  | $\displaystyle+\left(1-\alpha\right)\mathbb{E}_{\left(x,y\right)\sim p_{g}\left(x,y\right)}\left[\log\left(1-D\left(G\left(y,z\right),y\right)\right)\right],$
    |  |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle+\left(1-\alpha\right)\mathbb{E}_{\left(x,y\right)\sim p_{g}\left(x,y\right)}\left[\log\left(1-D\left(G\left(y,z\right),y\right)\right)\right],$
    |  |'
- en: where $D$ obtains label information about unlabeled data from the classifier
    $C$ and forces the generator $G$ to generate the realistic image-label samples.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $D$ 从分类器 $C$ 获取未标记数据的标签信息，并迫使生成器 $G$ 生成逼真的图像-标签样本。
- en: Enhanced TGAN. Based on the architecture of Triple GAN [[162](#bib.bib162)],
    Enhanced TGAN [[163](#bib.bib163)] modifies the Triple-GAN by re-designing the
    generator loss function and the classifier network. The generator generates images
    conditioned on class distribution and is regularized by class-wise mean feature
    matching. The classifier network includes two classifiers that collaboratively
    learn to provide more categorical information for generator training. Additionally,
    a semantic matching term is added to enhance the semantics consistency with respect
    to the generator and the classifier network. The discriminator $D$ learned to
    distinguish the labeled data pair $(x,y)$ from the synthesized data pair $(G(z),\tilde{y})$
    and predicted data pair $(x,\bar{y})$. The corresponding objective function is
    similar to Eq. ([7](#S3.E7 "In 3.1 Semi-supervised GANs ‣ 3 Generative methods
    ‣ A Survey on Deep Semi-supervised Learning")), where $(G(z),\tilde{y})$ is sampling
    from the pre-specified distribution $p_{g}$, and $(x,\bar{y})$ denotes the predicted
    data pair determined by $p_{c}(x)$.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Enhanced TGAN。基于 Triple GAN 的架构 [[162](#bib.bib162)]，Enhanced TGAN [[163](#bib.bib163)]
    通过重新设计生成器损失函数和分类器网络对 Triple-GAN 进行了修改。生成器生成基于类别分布的图像，并通过类别均值特征匹配进行正则化。分类器网络包括两个分类器，它们协同学习以为生成器训练提供更多的类别信息。此外，增加了一个语义匹配项，以增强生成器和分类器网络之间的语义一致性。鉴别器
    $D$ 学会区分标记数据对 $(x,y)$ 与合成数据对 $(G(z),\tilde{y})$ 和预测数据对 $(x,\bar{y})$。相应的目标函数类似于
    Eq. ([7](#S3.E7 "In 3.1 Semi-supervised GANs ‣ 3 Generative methods ‣ A Survey
    on Deep Semi-supervised Learning"))，其中 $(G(z),\tilde{y})$ 采样自预设的分布 $p_{g}$，$(x,\bar{y})$
    表示由 $p_{c}(x)$ 确定的预测数据对。
- en: MarginGAN. MarginGAN [[164](#bib.bib164)] is another extension framework based
    on Triple GAN [[162](#bib.bib162)]. From the perspective of classification margin,
    this framework works better than Triple GAN when used for semi-supervised classification.
    The architecture of MarginGAN is presented in Fig. [2](#S3.F2 "Figure 2 ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")(10). MarginGAN includes
    three components like Triple GAN, a generator $G$ which tries to maximize the
    margin of generated samples, a classifier $C$ used for decreasing margin of fake
    images, and a discriminator $D$ trained as usual to distinguish real samples from
    fake images. This method solves the problem that performance is damaged due to
    the inaccurate pseudo label in SSL, and improves the accuracy rate of SSL.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: MarginGAN。MarginGAN [[164](#bib.bib164)] 是基于 Triple GAN [[162](#bib.bib162)]
    的另一个扩展框架。从分类边际的角度来看，当用于半监督分类时，该框架比 Triple GAN 更有效。MarginGAN 的架构如图 [2](#S3.F2 "图
    2 ‣ 3 生成方法 ‣ 深度半监督学习调查")(10) 所示。MarginGAN 包含与 Triple GAN 相同的三个组件，一个生成器 $G$，试图最大化生成样本的边际，一个分类器
    $C$，用于减少虚假图像的边际，以及一个判别器 $D$，按常规训练以区分真实样本和虚假图像。该方法解决了由于 SSL 中伪标签不准确而导致性能受损的问题，并提高了
    SSL 的准确率。
- en: Triangle GAN. Triangle Generative Adversarial Network ($\triangle$-GAN) [[162](#bib.bib162)]
    introduces a new architecture to match cross-domain joint distributions. The architecture
    of the $\triangle$-GAN is shown in Fig. [2](#S3.F2 "Figure 2 ‣ 3 Generative methods
    ‣ A Survey on Deep Semi-supervised Learning")(11). The $\triangle$-GAN can be
    considered as an extended version of BiGAN [[158](#bib.bib158)] or ALI [[159](#bib.bib159)].
    This framework is a four-branch model that consists of two generators $E$ and
    $G$, and two discriminators $D_{1}$ and $D_{2}$. The two generators can learn
    two different joint distributions by two-way matching between two different domains.
    At the same time, the discriminators are used as an implicit ternary function,
    where $D_{2}$ determines whether the data pair is from $(x,y^{\prime})$ or from
    $(G(z),y)$ , and $D_{1}$ distinguishes real data pair $(x,y)$ from the fake data
    pair $(G(z),y)$.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Triangle GAN。Triangle Generative Adversarial Network ($\triangle$-GAN) [[162](#bib.bib162)]
    引入了一种新的架构来匹配跨领域的联合分布。$\triangle$-GAN 的架构如图 [2](#S3.F2 "图 2 ‣ 3 生成方法 ‣ 深度半监督学习调查")(11)
    所示。$\triangle$-GAN 可以被视为 BiGAN [[158](#bib.bib158)] 或 ALI [[159](#bib.bib159)]
    的扩展版本。该框架是一个四分支模型，由两个生成器 $E$ 和 $G$ 以及两个判别器 $D_{1}$ 和 $D_{2}$ 组成。两个生成器可以通过两个领域之间的双向匹配学习两个不同的联合分布。同时，判别器作为隐式三元函数，其中
    $D_{2}$ 确定数据对是否来自 $(x,y^{\prime})$ 或 $(G(z),y)$，而 $D_{1}$ 区分真实数据对 $(x,y)$ 和虚假数据对
    $(G(z),y)$。
- en: Structured GAN. Structured GAN [[165](#bib.bib165)] studies the problem of semi-supervised
    conditional generative modeling based on designated semantics or structures. The
    architecture of Structured GAN (see Fig. [2](#S3.F2 "Figure 2 ‣ 3 Generative methods
    ‣ A Survey on Deep Semi-supervised Learning")(12)) is similar to Triangle GAN
    [[162](#bib.bib162)]. Specifically, Structured GAN assumes that the samples $x$
    are generated conditioned on two independent latent variables, i.e., $y$ that
    encodes the designated semantics and $z$ contains other variation factors. Training
    Structured GAN involves solving two adversarial games that have their equilibrium
    concentrating at the true joint data distributions $p(x,z)$ and $p(x,y)$. The
    synthesized data pair $(x^{\prime},y)$ and $(x^{\prime},z)$ are generated by generator
    $G(y,z)$, where $(x^{\prime},y)$ mix real sample pair $(x,y)$ together as input
    for training discriminator $D(x,y)$ and $(x^{\prime}z)$ blends the $E$’s outputs
    pair $(x,z^{\prime})$ for discriminator $D(x,z)$.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化 GAN。结构化 GAN [[165](#bib.bib165)] 研究了基于指定语义或结构的半监督条件生成建模问题。结构化 GAN 的架构（见图
    [2](#S3.F2 "图 2 ‣ 3 生成方法 ‣ 深度半监督学习调查")(12)）类似于 Triangle GAN [[162](#bib.bib162)]。具体来说，结构化
    GAN 假设样本 $x$ 是在两个独立的潜变量条件下生成的，即编码指定语义的 $y$ 和包含其他变异因素的 $z$。训练结构化 GAN 涉及解决两个对抗性博弈，其平衡点集中在真实的联合数据分布
    $p(x,z)$ 和 $p(x,y)$ 上。合成数据对 $(x^{\prime},y)$ 和 $(x^{\prime},z)$ 是由生成器 $G(y,z)$
    生成的，其中 $(x^{\prime},y)$ 将真实样本对 $(x,y)$ 作为输入混合到训练判别器 $D(x,y)$ 中，而 $(x^{\prime}z)$
    将 $E$ 的输出对 $(x,z^{\prime})$ 融合到判别器 $D(x,z)$ 中。
- en: $\bm{R^{3}}$-CGAN. Liu et al. [[166](#bib.bib166)] propose a Class-conditional
    GAN with Random Regional Replacement (R3-regularization) technique, called $R^{3}$-CGAN.
    Their framework and training strategy relies on Triangle GAN [[162](#bib.bib162)].
    The $R^{3}$-CGAN architecture comprises four parts, a generator $G$ to synthesize
    fake images with specified class labels, a classifier $C$ to generate instance-label
    pairs of real unlabeled images with pseudo-labels, a discriminator $D_{1}$ to
    identify real or fake pairs, and another discriminator $D_{2}$ to distinguish
    two types of fake data. Specifically, CutMix [[167](#bib.bib167)], a Random Regional
    Replacement strategy, is used to construct two types of between-class instances
    (cross-category instances and real-fake instances). These instances are used to
    regularize the classifier $C$ and discriminator $D_{1}$. Through the minimax game
    among the four players, the class-specific information is effectively used for
    the downstream.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: $\bm{R^{3}}$-CGAN。Liu 等人 [[166](#bib.bib166)] 提出了一个带有随机区域替换（R3-正则化）技术的条件类生成对抗网络（$R^{3}$-CGAN）。他们的框架和训练策略依赖于Triangle
    GAN [[162](#bib.bib162)]。$R^{3}$-CGAN 架构包括四个部分：一个生成器 $G$ 用于合成具有指定类别标签的假图像，一个分类器
    $C$ 用于生成带有伪标签的真实未标记图像实例-标签对，一个鉴别器 $D_{1}$ 用于识别真实或假对，另一个鉴别器 $D_{2}$ 用于区分两种类型的假数据。具体来说，CutMix
    [[167](#bib.bib167)]，一种随机区域替换策略，用于构建两种类别间的实例（跨类别实例和真实-假实例）。这些实例用于对分类器 $C$ 和鉴别器
    $D_{1}$ 进行正则化。通过四个玩家之间的极小极大博弈，类特定的信息被有效地用于下游任务。
- en: Summary. Comparing with the above discussed Semi-GANs methods, we find that
    the main difference lies in the number and type of the basic modules, such as
    generator, encoder, discriminator, and classifier. As shown in Fig. [2](#S3.F2
    "Figure 2 ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(1),
    we find the evolutionary relationship of the Semi-GANs models. Overall, CatGAN
    [[149](#bib.bib149)] and CCGAN [[150](#bib.bib150)] extend the basic GAN by including
    additional information in the model, such as category information and in-painted
    images. Based on Improved GAN [[152](#bib.bib152)], Localized GAN [[154](#bib.bib154)]
    and CT-GAN [[155](#bib.bib155)] consider the local information and consistency
    regularization, respectively. BiGAN [[158](#bib.bib158)] and ALI [[159](#bib.bib159)]
    learn an inference model during the training process by adding an Encoder module.
    In order to solve the problem that the generator and discriminator can not be
    optimal at the same time, Triple-GAN [[161](#bib.bib161)] adds an independent
    classifier instead of using a discriminator as a classifier.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要。与上述讨论的Semi-GANs方法相比，我们发现主要的区别在于基本模块的数量和类型，如生成器、编码器、鉴别器和分类器。如图[2](#S3.F2 "图
    2 ‣ 3 生成方法 ‣ 深度半监督学习综述")所示，我们发现了Semi-GANs模型的进化关系。总体而言，CatGAN [[149](#bib.bib149)]
    和 CCGAN [[150](#bib.bib150)] 通过在模型中加入额外的信息（如类别信息和填补图像）来扩展基本的GAN。基于改进的GAN [[152](#bib.bib152)]，Localized
    GAN [[154](#bib.bib154)] 和 CT-GAN [[155](#bib.bib155)] 分别考虑了局部信息和一致性正则化。BiGAN
    [[158](#bib.bib158)] 和 ALI [[159](#bib.bib159)] 通过添加编码器模块在训练过程中学习推断模型。为了解决生成器和鉴别器不能同时达到最优的问题，Triple-GAN
    [[161](#bib.bib161)] 添加了一个独立的分类器，而不是使用鉴别器作为分类器。
- en: 3.2 Semi-supervised VAE
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 半监督VAE
- en: '![Refer to caption](img/ff7ee6a517d9fcaa15c77e8b58625590.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ff7ee6a517d9fcaa15c77e8b58625590.png)'
- en: 'Figure 3: A glimpse of probabilistic graphical models used for VAE-based deep
    generative semi-supervised methods. Each method contains two models, the generative
    model $P$ and the inference model $Q$. The variational parameters $\theta$ and
    $\phi$ are learned jointly by the incoming connections (i.e., deep neural networks).'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：基于VAE的深度生成半监督方法中使用的概率图模型的概览。每种方法包含两个模型，生成模型 $P$ 和推断模型 $Q$。变分参数 $\theta$
    和 $\phi$ 通过输入连接（即深度神经网络）联合学习。
- en: Variational AutoEncoders (VAEs) [[168](#bib.bib168), [169](#bib.bib169)] are
    flexible models which combine deep autoencoders with generative latent-variable
    models. The generative model captures representations of the distributions rather
    than the observations of the dataset, and defines the joint distribution in the
    form of $p(x,z)=p(z)p(x|z)$, where $p(z)$ is a prior distribution over latent
    variables $z$. Since the true posterior $p(z|x)$ is generally intractable, the
    generative model is trained with the aid of an approximate posterior distribution
    $q(z|x)$. The architecture of VAEs is a two-stage network, an encoder to construct
    a variational approximation $q(z|x)$ to the posterior $p(z|x)$, and a decoder
    to parameterize the likelihood $p(x|z)$. The variational approximation of the
    posterior maximizes the marginal likelihood, and the evidence lower bound (ELBO)
    may be written as
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 变分自编码器（VAEs）[[168](#bib.bib168), [169](#bib.bib169)] 是灵活的模型，它们将深度自编码器与生成潜在变量模型结合起来。生成模型捕捉分布的表示，而不是数据集的观测，并以
    $p(x,z)=p(z)p(x|z)$ 的形式定义联合分布，其中 $p(z)$ 是潜在变量 $z$ 的先验分布。由于真实的后验 $p(z|x)$ 通常是不可处理的，因此生成模型借助近似后验分布
    $q(z|x)$ 进行训练。VAEs 的架构是一个两阶段网络，一个编码器构造变分近似 $q(z|x)$ 以接近后验 $p(z|x)$，另一个解码器参数化似然
    $p(x|z)$。后验的变分近似最大化边际似然，证据下界（ELBO）可以写作
- en: '|  | $\displaystyle\log p(x)=\log\mathbb{E}_{q(z&#124;x)}[\frac{p(z)p(x&#124;z)}{q(z&#124;x)}]$
    |  | (8) |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\log p(x)=\log\mathbb{E}_{q(z&#124;x)}[\frac{p(z)p(x&#124;z)}{q(z&#124;x)}]$
    |  | (8) |'
- en: '|  | $\displaystyle\geq\mathbb{E}_{q(z&#124;x)}[\log p(z)p(x&#124;z)-\log q(z&#124;x)].$
    |  | (9) |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\geq\mathbb{E}_{q(z&#124;x)}[\log p(z)p(x&#124;z)-\log q(z&#124;x)].$
    |  | (9) |'
- en: 'There are three reasons why latent-variable models can be useful for SSL: (a)
    It is a natural way to incorporate unlabeled data, (b) The ability to disentangle
    representations can be easily implemented via the configuration of latent variables,
    and (c) It also allows us to use variational neural methods. In the following,
    we review several representative latent variable methods for semi-supervised learning.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在变量模型对于半监督学习（SSL）有三个原因是有用的：（a）它是一种自然地融合未标记数据的方式，（b）通过潜在变量的配置可以轻松实现表示的解耦，以及（c）它还允许我们使用变分神经方法。接下来，我们回顾几种代表性的潜在变量方法用于半监督学习。
- en: SSVAEs. SSVAEs denotes the VAE-based generative models with latent encoder representation
    proposed in [[170](#bib.bib170)]. The first one, i.e., the latent-feature discriminative
    model, referred to M1 [[170](#bib.bib170)], can provide more robust latent features
    with a deep generative model of the data. As shown in Fig. [3](#S3.F3 "Figure
    3 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning")(1), $p_{\theta}(x|z)$ is a non-linear transformation, e.g., a deep
    neural network. Latent variables $z$ can be selected as a Gaussian distribution
    or a Bernoulli distribution. An approximate sample of the posterior distribution
    on the latent variable $q_{\phi}(z|x)$ is used as the classifier feature for the
    class label $y$. The second one, namely Generative semi-supervised model, referred
    to M2 [[170](#bib.bib170)], describes the data generated by a latent class variable
    $y$ and a continuous latent variable $z$, is expressed as $p_{\theta}(x|z,y)p(z)p(y)$
    (as depicted in Fig. [3](#S3.F3 "Figure 3 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")(2)). $p(y)$ is the multinomial
    distribution, where the class labels $y$ are treated as latent variables for unlabeled
    data. $p_{\theta}(x|z,y)$ is a suitable likelihood function. The inferred posterior
    distribution $q_{\phi}(z|y,x)$ can predict any missing labels.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: SSVAEs。SSVAEs 指的是基于 VAE 的生成模型，具有在[[170](#bib.bib170)]中提出的潜在编码器表示。第一个模型，即潜在特征判别模型，称为
    M1 [[170](#bib.bib170)]，可以通过数据的深度生成模型提供更稳健的潜在特征。如图[3](#S3.F3 "Figure 3 ‣ 3.2 Semi-supervised
    VAE ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(1)所示，$p_{\theta}(x|z)$
    是一种非线性变换，例如深度神经网络。潜在变量 $z$ 可以选择为高斯分布或伯努利分布。后验分布 $q_{\phi}(z|x)$ 的近似样本作为类别标签 $y$
    的分类器特征。第二个模型，即生成式半监督模型，称为 M2 [[170](#bib.bib170)]，描述了由潜在类变量 $y$ 和连续潜在变量 $z$ 生成的数据，表示为
    $p_{\theta}(x|z,y)p(z)p(y)$（如图[3](#S3.F3 "Figure 3 ‣ 3.2 Semi-supervised VAE ‣
    3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(2)所示）。$p(y)$
    是多项分布，其中类别标签 $y$ 被视为未标记数据的潜在变量。$p_{\theta}(x|z,y)$ 是一个合适的似然函数。推断后的后验分布 $q_{\phi}(z|y,x)$
    可以预测任何缺失的标签。
- en: 'Stacked generative semi-supervised model, called M1+M2, uses the generative
    model M1 to learn the new latent representation $z_{1}$, and uses the embedding
    from $z_{1}$ instead of the raw data $x$ to learn a generative semi-supervised
    model M2\. As shown in Fig. [3](#S3.F3 "Figure 3 ‣ 3.2 Semi-supervised VAE ‣ 3
    Generative methods ‣ A Survey on Deep Semi-supervised Learning")(3), the whole
    process can be abstracted as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠生成半监督模型，称为 M1+M2，使用生成模型 M1 来学习新的潜在表示 $z_{1}$，并利用来自 $z_{1}$ 的嵌入，而不是原始数据 $x$，来学习生成半监督模型
    M2。正如图 [3](#S3.F3 "图 3 ‣ 3.2 半监督 VAE ‣ 3 生成方法 ‣ 深度半监督学习综述")(3) 所示，整个过程可以抽象如下：
- en: '|  | $p_{\theta}(x,y,z_{1},z_{2})=p(y)p(z_{2})p_{\theta}(z_{1}&#124;y,z_{2})p_{\theta}(x&#124;z_{1}),$
    |  | (10) |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '|  | $p_{\theta}(x,y,z_{1},z_{2})=p(y)p(z_{2})p_{\theta}(z_{1}&#124;y,z_{2})p_{\theta}(x&#124;z_{1}),$
    |  | (10) |'
- en: where $p_{\theta}(z_{1}|y,z_{2})$ and $p_{\theta}(x|z_{1})$ are parameterised
    as deep neural networks. In all the above models, $q_{\phi}({z|x})$ is used to
    approximate the true posterior distribution $p({z|x})$, and following the variational
    principle, the boundary approximation lower bound of the model is derived to ensure
    that the approximate posterior probability is as close to the true posterior probability
    as possible.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p_{\theta}(z_{1}|y,z_{2})$ 和 $p_{\theta}(x|z_{1})$ 被参数化为深度神经网络。在上述所有模型中，$q_{\phi}({z|x})$
    用于近似真实的后验分布 $p({z|x})$，并根据变分原理，推导出模型的边界近似下界，以确保近似后验概率尽可能接近真实的后验概率。
- en: ADGM. Auxiliary Deep Generative Models (ADGM) [[171](#bib.bib171)] extends SSVAEs
    [[170](#bib.bib170)] with auxiliary variables, as depicted in Fig. [3](#S3.F3
    "Figure 3 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods ‣ A Survey on Deep
    Semi-supervised Learning")(4). The auxiliary variables can improve the variational
    approximation and make the variational distribution more expressive by training
    deep generative models with multiple stochastic layers.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ADGM。辅助深度生成模型（ADGM）[[171](#bib.bib171)] 通过辅助变量扩展了 SSVAEs [[170](#bib.bib170)]，如图 [3](#S3.F3
    "图 3 ‣ 3.2 半监督 VAE ‣ 3 生成方法 ‣ 深度半监督学习综述")(4) 所示。辅助变量通过训练具有多个随机层的深度生成模型，可以改进变分近似，使变分分布更具表现力。
- en: 'Adding the auxiliary variable $a$ leaves the generative model of $x,y$ unchanged
    while significantly improving the representative power of the posterior approximation.
    An additional inference network is introduced such that:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 添加辅助变量 $a$ 不会改变 $x,y$ 的生成模型，同时显著提高后验近似的代表性能力。引入了一个额外的推理网络，具体如下：
- en: '|  | $q_{\phi}(a,y,z&#124;x)=q_{\phi}(z&#124;a,y,x)q_{\phi}(y&#124;a,x)q_{\phi}(a&#124;x).$
    |  | (11) |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|  | $q_{\phi}(a,y,z&#124;x)=q_{\phi}(z&#124;a,y,x)q_{\phi}(y&#124;a,x)q_{\phi}(a&#124;x).$
    |  | (11) |'
- en: The framework has the generative model $p$ defined as $p_{\theta}(a)p_{\theta}(y)p_{\theta}(z)p_{\theta}(x|z,y)$,
    where $a,y,z$ are the auxiliary variable, class label, and latent features, respectively.
    Learning the posterior distribution is intractable. Thus we define the approximation
    as $q_{\phi}(a|{x})q_{\phi}({z}|y,{x})$ and a classifier $q_{\phi}(y|a,{x})$.
    The auxiliary unit $a$ actually introduces a class-specific latent distribution
    between $x$ and $y$, resulting in a more expressive distribution $q_{\phi}(y|a,x)$.
    Formally, [[171](#bib.bib171)] employs the similar variational lower bound $\mathbb{E}_{q_{\phi}(a,z|x)}[\log
    p_{\theta}(a,x,y,z)-\log q_{\phi}(a,z|x,y)]$ on the marginal likelihood, with
    $q_{\phi}(a,z|x,y)=q_{\phi}(a|x)q_{\phi}(z|y,x)$. Similarly, the unlabeled ELBO
    is $\mathbb{E}_{q_{\phi}(a,y,z|x)}[\log p_{\theta}(a,x,y,z)-\log q_{\phi}(a,y,z|x)]$
    with $q_{\phi}(a,y,z|x)=q_{\phi}(z|y,x)q_{\phi}(y|a,x)q_{\phi}(a|x)$.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架具有定义为 $p_{\theta}(a)p_{\theta}(y)p_{\theta}(z)p_{\theta}(x|z,y)$ 的生成模型，其中
    $a,y,z$ 分别是辅助变量、类别标签和潜在特征。学习后验分布是不可处理的。因此，我们将近似定义为 $q_{\phi}(a|{x})q_{\phi}({z}|y,{x})$
    和分类器 $q_{\phi}(y|a,{x})$。辅助单元 $a$ 实际上在 $x$ 和 $y$ 之间引入了一个类别特定的潜在分布，从而产生了更具表现力的分布
    $q_{\phi}(y|a,x)$。正式地，[[171](#bib.bib171)] 使用类似的变分下界 $\mathbb{E}_{q_{\phi}(a,z|x)}[\log
    p_{\theta}(a,x,y,z)-\log q_{\phi}(a,z|x,y)]$ 对边际似然进行近似，其中 $q_{\phi}(a,z|x,y)=q_{\phi}(a|x)q_{\phi}(z|y,x)$。类似地，无标签
    ELBO 是 $\mathbb{E}_{q_{\phi}(a,y,z|x)}[\log p_{\theta}(a,x,y,z)-\log q_{\phi}(a,y,z|x)]$，其中
    $q_{\phi}(a,y,z|x)=q_{\phi}(z|y,x)q_{\phi}(y|a,x)q_{\phi}(a|x)$。
- en: Interestingly, by reversing the direction of the dependence between $x$ and
    $a$, a model similar to the stacked version of M1 and M2 is recovered (Fig. [3](#S3.F3
    "Figure 3 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods ‣ A Survey on Deep
    Semi-supervised Learning")(3)), with what the authors denote skip connections
    from the second stochastic layer and the labels to the inputs $x$. In this case
    the generative model is affected, and the authors call this the Skip Deep Generative
    Model (SDGM). This model is able to be trained end to end using stochastic gradient
    descent (SGD) (according to the [[171](#bib.bib171)] the skip connection between
    $z$ and $x$ is crucial for training to converge). Unsurprisingly, joint training
    for the model improves significantly upon the performance presented in [[170](#bib.bib170)].
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，通过反转 $x$ 和 $a$ 之间的依赖方向，恢复了类似于 M1 和 M2 堆叠版本的模型（图 [3](#S3.F3 "Figure 3 ‣
    3.2 Semi-supervised VAE ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning")(3)），作者称之为从第二个随机层和标签到输入 $x$ 的跳跃连接。在这种情况下，生成模型受到影响，作者称之为跳跃深度生成模型（SDGM）。该模型能够通过随机梯度下降（SGD）进行端到端的训练（根据
    [[171](#bib.bib171)]，$z$ 和 $x$ 之间的跳跃连接对训练收敛至关重要）。毫不奇怪，该模型的联合训练显著改善了 [[170](#bib.bib170)]
    中呈现的性能。
- en: Infinite VAE. Infinite VAE [[172](#bib.bib172)] proposes a mixture model for
    combining variational autoencoders, a non-parametric Bayesian approach. This model
    can adapt to suit the input data by mixing coefficients by a Dirichlet process.It
    combines Gibbs sampling and variational inference that enables the model to learn
    the input’s underlying structures efficiently. Formally, Infinite VAE employs
    the mixing coefficients to assist SSL by combining the unsupervised generative
    model and a supervised discriminative model. The infinite mixture generative model
    as,
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Infinite VAE。Infinite VAE [[172](#bib.bib172)] 提出了一个用于结合变分自编码器的混合模型，这是一种非参数贝叶斯方法。该模型通过
    Dirichlet 过程混合系数来适应输入数据。它结合了 Gibbs 采样和变分推断，使模型能够高效地学习输入的潜在结构。形式上，Infinite VAE
    使用混合系数来辅助 SSL，通过结合无监督生成模型和监督判别模型。无限混合生成模型为，
- en: '|  | $p(c,\pi,x,z)=p(c&#124;\pi)p_{\alpha}(\pi)p_{\theta}(x&#124;c,z)p(z),$
    |  | (12) |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '|  | $p(c,\pi,x,z)=p(c\vert \pi)p_{\alpha}(\pi)p_{\theta}(x\vert c,z)p(z),$
    |  | (12) |'
- en: where $c$ denotes the assignment matrix for each instance to a VAE component
    where the VAE-$i$ can best reconstruct instance $i$. $\pi$ is the mixing coefficient
    prior for $c$, drawn from a Dirichlet distribution with parameter $\alpha$. Each
    latent variable $z_{i}$ in each VAE is drawn from a Gaussian distribution.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $c$ 表示将每个实例分配给一个 VAE 组件的赋值矩阵，其中 VAE-$i$ 可以最佳地重建实例 $i$。$\pi$ 是 $c$ 的混合系数先验，从具有参数
    $\alpha$ 的 Dirichlet 分布中抽取。每个 VAE 中的潜在变量 $z_{i}$ 是从高斯分布中抽取的。
- en: Disentangled VAE. Disentangled VAE [[173](#bib.bib173)] attempts to learn disentangled
    representations using partially-specified graphical model structures and distinct
    encoding aspects of the data into separate variables. It explores the graphical
    model for modeling a general dependency on observed and unobserved latent variables
    with neural networks, and a stochastic computation graph [[174](#bib.bib174)]
    is used to infer with and train the resultant generative model. For this purpose,
    importance sampling estimates are used to maximize the lower bound of both the
    supervised and semi-supervised likelihoods. Formally, this framework considers
    the conditional probability $q_{y,z|x}$, which has a factorization $q_{\phi}(y,z|x)=q_{\phi}(y|x,z)q_{\phi}(z|x)$
    rather than $q_{\phi}(y,z|x)=q_{\phi}(z|x,y)q_{\phi}(y|x)$ in [[170](#bib.bib170)],
    which means we can no longer compute a simple Monte Carlo estimator by sampling
    from the unconditional distribution $q_{\phi}(z|x)$. Thus, the variational lower
    bound for supervised term expand below,
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 解耦 VAE。解耦 VAE [[173](#bib.bib173)] 试图使用部分指定的图形模型结构和数据的不同编码方面将其学习为解耦表示。它探索了用于建模对观察到的和未观察到的潜在变量的通用依赖性的图形模型，利用神经网络和一个随机计算图
    [[174](#bib.bib174)] 来推断并训练生成模型。为此，使用重要性采样估计来最大化监督和半监督似然的下界。形式上，该框架考虑了条件概率 $q_{y,z|x}$，其因子化为
    $q_{\phi}(y,z|x)=q_{\phi}(y|x,z)q_{\phi}(z|x)$，而不是 [[170](#bib.bib170)] 中的 $q_{\phi}(y,z|x)=q_{\phi}(z|x,y)q_{\phi}(y|x)$，这意味着我们不能再通过从无条件分布
    $q_{\phi}(z|x)$ 中采样来计算简单的蒙特卡洛估计量。因此，监督项的变分下界展开如下，
- en: '|  | $\mathbb{E}_{q_{\phi}(z&#124;x,y)}[\log p_{\theta}(x&#124;y,z)p(y)p(z)-q_{\phi}(y,z&#124;x)].$
    |  | (13) |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{q_{\phi}(z\vert x,y)}[\log p_{\theta}(x\vert y,z)p(y)p(z)-q_{\phi}(y,z\vert
    x)].$ |  | (13) |'
- en: 'SDVAE. Semi-supervised Disentangled VAE (SDVAE) [[175](#bib.bib175)] incorporates
    the label information to the latent representations by encoding the input disentangled
    representation and non-interpretable representation. The disentangled variable
    captures categorical information, and the non-interpretable variable consists
    of other uncertain information from the data. As shown in Fig. [3](#S3.F3 "Figure
    3 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning")(5), SDVAE assumes the disentangled variable $v$ and the non-interpretable
    variable $u$ are independent condition on $x$, i.e., $q_{\phi}(u,v|x)=q_{\phi}(u|x)q_{\phi}(v|x)$.
    This means that $q_{\phi}(v|x)$ is the encoder for the disentangled representation,
    and $q_{\phi}(u|x)$ denotes the encoder for non-interpretable representation.
    Based on those assumptions, the variational lower bound is written as:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: SDVAE。半监督解耦变分自编码器（SDVAE）[[175](#bib.bib175)] 通过编码输入的解耦表示和不可解释表示，将标签信息融入潜在表示中。解耦变量捕获分类信息，而不可解释变量包含来自数据的其他不确定信息。如图[3](#S3.F3
    "图3 ‣ 3.2 半监督VAE ‣ 3 生成方法 ‣ 深度半监督学习概述")(5)所示，SDVAE 假设解耦变量 $v$ 和不可解释变量 $u$ 在 $x$
    条件下是独立的，即 $q_{\phi}(u,v|x)=q_{\phi}(u|x)q_{\phi}(v|x)$。这意味着 $q_{\phi}(v|x)$ 是解耦表示的编码器，而
    $q_{\phi}(u|x)$ 表示不可解释表示的编码器。基于这些假设，变分下界可以写作：
- en: '|  | $\mathbb{E}_{q(u&#124;x),q(v&#124;x)}[\log p(x&#124;u,v)p(v)p(u)-\log
    q(u&#124;x)q(v&#124;x)].$ |  | (14) |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{q(u|x),q(v|x)}[\log p(x|u,v)p(v)p(u)-\log q(u|x)q(v|x)].$
    |  | (14) |'
- en: '![Refer to caption](img/7f88fbe6c6df9406b2dbb4dbb48ec230.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7f88fbe6c6df9406b2dbb4dbb48ec230.png)'
- en: 'Figure 4: A glimpse of the diverse range of architectures used for consistency
    regularization semi-supervised methods. In addition to the identifiers in the
    figure, $\zeta$ denotes the perturbation noise, and $\mathcal{R}$ is the consistency
    constraint.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：展示了用于一致性正则化半监督方法的多样化架构。除了图中的标识符外，$\zeta$ 表示扰动噪声，$\mathcal{R}$ 是一致性约束。
- en: ReVAE. Reparameterized VAE (ReVAE) [[176](#bib.bib176)] develops a novel way
    to encoder supervised information, which can capture label information through
    auxiliary variables instead of latent variables in the prior work [[170](#bib.bib170)].
    The graphical model is illustrated in Fig. [3](#S3.F3 "Figure 3 ‣ 3.2 Semi-supervised
    VAE ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(6). In
    contrast to SSVAEs, ReVAE captures meaningful representations of data with a principled
    variational objective. Moreover, ReVAE carefully designed the mappings between
    auxiliary and latent variables. In this model, a conditional generative model
    $p_{\psi}(z|y)$ is introduced to address the requirement for inference at test
    time. Similar to [[170](#bib.bib170)] and [[171](#bib.bib171)], ReVAE treats $y$
    as a known observation when the label is available in the supervised setting,
    and as an additional variable in the unsupervised case. In particular, the latent
    space can be partitioned into two disjoint subsets under the assumption that label
    information captures only specific aspects.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ReVAE。重参数化变分自编码器（ReVAE）[[176](#bib.bib176)] 开发了一种编码监督信息的新方法，可以通过辅助变量捕获标签信息，而不是先前工作中的潜在变量[[170](#bib.bib170)]。图[3](#S3.F3
    "图3 ‣ 3.2 半监督VAE ‣ 3 生成方法 ‣ 深度半监督学习概述")(6)中展示了图形模型。与SSVAEs相比，ReVAE 通过有原则的变分目标捕获数据的有意义表示。此外，ReVAE
    精心设计了辅助变量和潜在变量之间的映射。在这个模型中，引入了条件生成模型 $p_{\psi}(z|y)$ 以解决测试时推理的需求。类似于[[170](#bib.bib170)]和[[171](#bib.bib171)]，ReVAE
    在监督设置中将 $y$ 视为已知观测，而在无监督情况下则视为额外变量。特别是，潜在空间可以在标签信息仅捕获特定方面的假设下分为两个不相交的子集。
- en: Summary. As the name indicates, Semi-supervised VAE applies the VAE architecture
    for handling SSL problems. An advantage of these methods is that meaningful representations
    of data can be learned by the generative latent-variable models. The basic framework
    of these Semi-supervised VAE methods is M2 [[170](#bib.bib170)]. On the basis
    of the M2 framework, ADGM [[171](#bib.bib171)] and ReVAE [[176](#bib.bib176)]
    consider introducing additional auxiliary variables, although the roles of the
    auxiliary variables in the two models are different. Infinite VAE [[172](#bib.bib172)]
    is a hybrid of several VAE models to improve the performance of the entire framework.
    Disentangled VAE [[173](#bib.bib173)] and SDVAE [[175](#bib.bib175)] solve the
    semi-supervised VAE problem by different disentangled methods. Under semi-supervised
    conditions, when a large number of labels are unobserved, the key to this kind
    of method is how to deal with the latent variables and label information.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要。顾名思义，半监督 VAE 将 VAE 架构应用于处理 SSL 问题。这些方法的一个优点是生成潜变量模型可以学习数据的有意义表示。这些半监督 VAE
    方法的基本框架是 M2 [[170](#bib.bib170)]。在 M2 框架的基础上，ADGM [[171](#bib.bib171)] 和 ReVAE
    [[176](#bib.bib176)] 考虑引入额外的辅助变量，尽管两个模型中的辅助变量角色不同。Infinite VAE [[172](#bib.bib172)]
    是几个 VAE 模型的混合体，以提高整个框架的性能。Disentangled VAE [[173](#bib.bib173)] 和 SDVAE [[175](#bib.bib175)]
    通过不同的解缠方法解决半监督 VAE 问题。在半监督条件下，当大量标签未被观测时，这类方法的关键在于如何处理潜变量和标签信息。
- en: 4 Consistency Regularization
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 一致性正则化
- en: In this section, we introduce the consistency regularization methods for semi-supervised
    deep learning. In these methods, a consistency regularization term is applied
    to the final loss function to specify the prior constraints assumed by researchers.
    Consistency regularization is based on the manifold assumption or the smoothness
    assumption, and describes a category of methods that the realistic perturbations
    of the data points should not change the output of the model [[13](#bib.bib13)].
    Consequently, consistency regularization can be regarded to find a smooth manifold
    on which the dataset lies by leveraging the unlabeled data [[177](#bib.bib177)].
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了半监督深度学习的一致性正则化方法。在这些方法中，一致性正则化项被应用于最终的损失函数，以指定研究人员假设的先验约束。一致性正则化基于流形假设或光滑性假设，描述了一类方法，即数据点的实际扰动不应改变模型的输出[[13](#bib.bib13)]。因此，一致性正则化可以被看作是通过利用未标记数据来寻找数据集所在的光滑流形[[177](#bib.bib177)]。
- en: 'The most common structure of consistency regularization SSL methods is the
    Teacher-Student structure. As a student, the model learns as before, and as a
    teacher, the model generates targets simultaneously. Since the model itself generates
    targets, they may be incorrect and then used by themselves as students for learning.
    In essence, the consistency regularization methods suffer from confirmation bias
    [[68](#bib.bib68)], a risk that can be mitigated by improving the target’s quality.
    Formally, following [[178](#bib.bib178)], we assume that dataset $X$ consists
    of a labeled subset $X_{l}$ and an unlabeled subset $X_{u}$. Let $\theta^{\prime}$
    denote the weight of the target, and $\theta$ denote the weights of the basic
    student. The consistency constraint is defined as:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的一致性正则化 SSL 方法的结构是教师-学生结构。作为学生，模型如以前一样进行学习，而作为教师，模型则同时生成目标。由于模型本身生成目标，这些目标可能是错误的，然后被用作学生进行学习。实质上，一致性正则化方法面临确认偏差的风险[[68](#bib.bib68)]，这一风险可以通过提高目标的质量来减轻。形式上，遵循[[178](#bib.bib178)]，我们假设数据集
    $X$ 包含一个标记子集 $X_{l}$ 和一个未标记子集 $X_{u}$。设 $\theta^{\prime}$ 表示目标的权重，$\theta$ 表示基本学生的权重。一致性约束定义为：
- en: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),\mathcal{T}_{x}),$ |  | (15)
    |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),\mathcal{T}_{x}),$ |  | (15)
    |'
- en: where $f(\theta,x)$ is the prediction from model $f(\theta)$ for input $x$.
    $\mathcal{T}_{x}$ is the consistency target of the teacher. $\mathcal{R}(\cdot,\cdot)$
    measures the distance between two vectors and is usually set to Mean Squared Error
    (MSE) or KL-divergence. Different consistency regularization techniques vary in
    how they generate the target. There are several ways to boost the target $\mathcal{T}_{x}$
    quality. One strategy is to select the perturbation rather than additive or multiplicative
    noise carefully. Another technique is to consider the teacher model carefully
    instead of replicating the student model.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$f(\theta,x)$是模型$f(\theta)$对输入$x$的预测。$\mathcal{T}_{x}$是教师的一致性目标。$\mathcal{R}(\cdot,\cdot)$衡量两个向量之间的距离，通常设置为均方误差（MSE）或KL散度。不同的一致性正则化技术在生成目标的方式上有所不同。有几种方法可以提高目标$\mathcal{T}_{x}$的质量。一种策略是仔细选择扰动，而不是添加或乘法噪声。另一种技术是仔细考虑教师模型，而不是复制学生模型。
- en: Ladder Network. Ladder Network [[65](#bib.bib65), [179](#bib.bib179)] is the
    first successful attempt towards using a Teacher-Student model that is inspired
    by a deep denoising AutoEncoder. The structure of the Ladder Network is shown
    in Fig. [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods
    ‣ A Survey on Deep Semi-supervised Learning")(1). In Encoder, noise $\zeta$ is
    injected into all hidden layers as the corrupted feedforward path $x+\zeta\rightarrow\frac{\text{Encoder}}{f(\cdot)}\rightarrow\tilde{z}_{1}\rightarrow\tilde{z}_{2}\,\,$
    and shares the mappings $f(\cdot)$ with the clean encoder feedforward path $x\rightarrow\frac{\text{Encoder}}{f(\cdot)}\rightarrow
    z_{1}\rightarrow z_{2}\rightarrow y$. The decoder path $\tilde{z}_{1}\rightarrow\tilde{z}_{2}\rightarrow\frac{\text{Decoder}}{g(\cdot,\cdot)}\rightarrow\hat{z}_{2}\rightarrow\hat{z}_{1}$
    consists of the denoising functions $g(\cdot,\cdot)$ and the unsupervised denoising
    square error $\mathcal{R}$ on each layer consider as consistency loss between
    $\hat{z}_{i}$ and $z_{i}$. Through latent skip connections, the ladder network
    is differentiated from regular denoising AutoEncoder. This feature allows the
    higher layer features to focus on more abstract invariant features for the task.
    Formally, the ladder network unsupervised training loss $\mathcal{L}_{u}$ or the
    consistency loss is computed as the MSE between the activation of the clean encoder
    $z_{i}$ and the reconstructed activations $\hat{z}_{i}$. Generally, $\mathcal{L}_{u}$
    is
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度网络。梯度网络 [[65](#bib.bib65), [179](#bib.bib179)] 是首次成功使用启发于深度去噪自编码器的教师-学生模型。梯度网络的结构如图[4](#S3.F4
    "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods ‣ A Survey on Deep
    Semi-supervised Learning")(1)所示。在编码器中，噪声$\zeta$被注入所有隐藏层，作为腐蚀的前馈路径$x+\zeta\rightarrow\frac{\text{Encoder}}{f(\cdot)}\rightarrow\tilde{z}_{1}\rightarrow\tilde{z}_{2}\,\,$，并与干净编码器的前馈路径$x\rightarrow\frac{\text{Encoder}}{f(\cdot)}\rightarrow
    z_{1}\rightarrow z_{2}\rightarrow y$共享映射$f(\cdot)$。解码器路径$\tilde{z}_{1}\rightarrow\tilde{z}_{2}\rightarrow\frac{\text{Decoder}}{g(\cdot,\cdot)}\rightarrow\hat{z}_{2}\rightarrow\hat{z}_{1}$由去噪函数$g(\cdot,\cdot)$组成，且每一层的无监督去噪平方误差$\mathcal{R}$被视为$\hat{z}_{i}$和$z_{i}$之间的一致性损失。通过潜在的跳跃连接，梯度网络与常规的去噪自编码器有所不同。这一特性使得更高层的特征可以关注于任务的更抽象的不变特征。形式上，梯度网络的无监督训练损失$\mathcal{L}_{u}$或一致性损失被计算为干净编码器$z_{i}$和重构激活$\hat{z}_{i}$之间的均方误差（MSE）。通常，$\mathcal{L}_{u}$是
- en: '|  | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x\right),g\left(f\left(\theta,x+\zeta\right)\right)\right).$
    |  | (16) |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x\right),g\left(f\left(\theta,x+\zeta\right)\right)\right).$
    |  | (16) |'
- en: $\bm{\Pi}$ Model. Unlike the perturbation used in Ladder Network, $\Pi$ Model
    [[66](#bib.bib66)] is to create two random augmentations of a sample for both
    labeled and unlabeled data. Some techniques with non-deterministic behavior, such
    as randomized data augmentation, dropout, and random max-pooling, make an input
    sample pass through the network several times, leading to different predictions.
    The structure of the $\Pi$ Model is shown in Fig. [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised
    VAE ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(2). In
    each epoch of the training process for $\Pi$ Model, the same unlabeled sample
    propagates forward twice, while random perturbations are introduced by data augmentations
    and dropout. The forward propagation of the same sample may result in different
    predictions, and the $\Pi$ Model expects the two predictions to be as consistent
    as possible. Therefore, it provides an unsupervised consistency loss function,
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: $\bm{\Pi}$ 模型。与梯度网络中使用的扰动不同，$\Pi$ 模型 [[66](#bib.bib66)] 是为标记和未标记数据创建样本的两个随机增强。一些具有非确定性行为的技术，如随机数据增强、丢弃（dropout）和随机最大池化，会使输入样本通过网络多次，从而产生不同的预测。$\Pi$
    模型的结构如图 [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods
    ‣ A Survey on Deep Semi-supervised Learning")(2) 所示。在每个训练周期中，$\Pi$ 模型将相同的未标记样本前向传播两次，同时通过数据增强和丢弃引入随机扰动。相同样本的前向传播可能导致不同的预测，$\Pi$
    模型希望这两个预测尽可能一致。因此，它提供了一个无监督的一致性损失函数，
- en: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x,\zeta_{1}),f(\theta,x,\zeta_{2})),$
    |  | (17) |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x,\zeta_{1}),f(\theta,x,\zeta_{2})),$
    |  | (17) |'
- en: which minimizes the difference between the two predictions.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 该损失函数最小化两个预测之间的差异。
- en: 'Temporal Ensembling. Temporal Ensembling [[67](#bib.bib67)] is similar to the
    $\Pi$ Model, which forms a consensus prediction under different regularization
    and input augmentation conditions. The structure of Temporal Ensembling is shown
    in Fig. [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods
    ‣ A Survey on Deep Semi-supervised Learning")(3). It modifies the $\Pi$ Model
    by leveraging the Exponential Moving Average (EMA) of past epochs predictions.
    In other words, while $\Pi$ Model needs to forward a sample twice in each iteration,
    Temporal Ensembling reduces this computational overhead by using EMA to accumulate
    the predictions over epochs as $\mathcal{T}_{x}$. Specifically, the ensemble outputs
    $Z_{i}$ is updated with the network outputs $z_{i}$ after each training epoch,
    i.e., $Z_{i}\leftarrow\alpha Z_{i}+\left(1-\alpha\right)z_{i}$, where $\alpha$
    is a momentum term. During the training process, the $Z$ can be considered to
    contain an average ensemble of $f(\cdot)$ outputs due to Dropout and stochastic
    augmentations. Thus, consistency loss is:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 时间集成。时间集成 [[67](#bib.bib67)] 类似于 $\Pi$ 模型，它在不同的正则化和输入增强条件下形成共识预测。时间集成的结构如图 [4](#S3.F4
    "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods ‣ A Survey on Deep
    Semi-supervised Learning")(3) 所示。它通过利用过去周期预测的指数移动平均（EMA）来修改 $\Pi$ 模型。换句话说，虽然 $\Pi$
    模型需要在每次迭代中前向传播样本两次，但时间集成通过使用 EMA 在周期中累积预测作为 $\mathcal{T}_{x}$ 来减少计算开销。具体而言，集成输出
    $Z_{i}$ 在每个训练周期后用网络输出 $z_{i}$ 更新，即 $Z_{i}\leftarrow\alpha Z_{i}+\left(1-\alpha\right)z_{i}$，其中
    $\alpha$ 是一个动量项。在训练过程中，由于丢弃和随机增强，$Z$ 可以被认为包含 $f(\cdot)$ 输出的平均集成。因此，一致性损失是：
- en: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x,\zeta_{1}),\text{EMA}(f(\theta,x,\zeta_{2}))).$
    |  | (18) |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x,\zeta_{1}),\text{EMA}(f(\theta,x,\zeta_{2}))).$
    |  | (18) |'
- en: 'TABLE III: Summary of Consistency Regularization Methods'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 表 III：一致性正则化方法总结
- en: '| Methods | Techniques | Transformations | Consistency Constraints |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 技术 | 转换 | 一致性约束 |'
- en: '| Ladder Network | Additional Gaussian Noise in every neural layer | input
    | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),f(\theta,x+\zeta))$ |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 梯度网络 | 每个神经层中的额外高斯噪声 | 输入 | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),f(\theta,x+\zeta))$
    |'
- en: '| $\Pi$ Model | Different Stochastic Augmentations | input | $\mathbb{E}_{x\in
    X}\mathcal{R}\left(f\left(\theta,x,\zeta_{1}\right),f\left(\theta,x,\zeta_{2}\right)\right)$
    |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| $\Pi$ 模型 | 不同的随机增强 | 输入 | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x,\zeta_{1}\right),f\left(\theta,x,\zeta_{2}\right)\right)$
    |'
- en: '| Temporal Ensembling | Different Stochastic Augmentation and EMA the predictions
    | input, predictions | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x,\zeta_{1}\right),\text{EMA}\left(f\left(\theta,x,\zeta_{2}\right)\right)\right)$
    |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| Temporal Ensembling | 不同的随机增强和EMA预测 | 输入，预测 | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x,\zeta_{1}\right),\text{EMA}\left(f\left(\theta,x,\zeta_{2}\right)\right)\right)$
    |'
- en: '| Mean Teacher | Different Stochastic Augmentation and EMA the weights | input,
    weights | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x,\zeta\right),f\left(\text{EMA}\left(\theta\right),x,\zeta\right)\right)$
    |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| Mean Teacher | 不同的随机增强和EMA权重 | 输入，权重 | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x,\zeta\right),f\left(\text{EMA}\left(\theta\right),x,\zeta\right)\right)$
    |'
- en: '| VAT | Adversarial perturbation | input | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x\right),f\left(\theta,x,\gamma^{adv}\right)\right)$
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| VAT | 对抗扰动 | 输入 | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x\right),f\left(\theta,x,\gamma^{adv}\right)\right)$
    |'
- en: '| Dual Student | Stable sample and stabilization constraint | input, weights
    | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\text{STA}\left(\theta,x_{i}\right),\zeta_{1}\right),f\left(\text{STA}\left(\theta,x_{j}\right),\zeta_{2}\right)\right)$
    |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| Dual Student | 稳定样本和稳定性约束 | 输入，权重 | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\text{STA}\left(\theta,x_{i}\right),\zeta_{1}\right),f\left(\text{STA}\left(\theta,x_{j}\right),\zeta_{2}\right)\right)$
    |'
- en: '| SWA | Stochastic Weight Averaging | input, weights | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x\right),f\left(\text{SWA}\left(\theta\right),x,\zeta\right)\right)$
    |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| SWA | 随机权重平均 | 输入，权重 | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x\right),f\left(\text{SWA}\left(\theta\right),x,\zeta\right)\right)$
    |'
- en: '| VAdD | Adversarial perturbation and Stochastic Augmentation (dropout mask)
    | input, weights | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x,\epsilon^{s}\right),f\left(\theta,x,\epsilon^{adv}\right)\right)$
    |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| VAdD | 对抗扰动和随机增强（dropout蒙版） | 输入，权重 | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x,\epsilon^{s}\right),f\left(\theta,x,\epsilon^{adv}\right)\right)$
    |'
- en: '| UDA | AutoAugment/RandAugment for image; Back-Translation for text | input
    | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x\right),f\left(\theta,x,\zeta\right)\right)$
    |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| UDA | 自动增强/随机增强适用于图像；文本的背向翻译 | 输入 | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x\right),f\left(\theta,x,\zeta\right)\right)$
    |'
- en: '| WCP | Additive perturbation on network weights, DropConnect perturbation
    for network structure | input, network structure | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x\right),g\left(\theta+\zeta,x\right)\right)$
    |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| WCP | 对网络权重进行加性扰动，对网络结构进行DropConnect扰动 | 输入，网络结构 | $\mathbb{E}_{x\in X}\mathcal{R}\left(f\left(\theta,x\right),g\left(\theta+\zeta,x\right)\right)$
    |'
- en: 'Mean Teacher. Mean Teacher [[68](#bib.bib68)] averages model weights using
    EMA over training steps and tends to produce a more accurate model instead of
    directly using output predictions. The structure of Mean Teacher is shown in Fig. [4](#S3.F4
    "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods ‣ A Survey on Deep
    Semi-supervised Learning")(4). Mean Teacher consists of two models called Student
    and Teacher. The student model is a regular model similar to the $\Pi$ Model,
    and the teacher model has the same architecture as the student model with exponential
    moving averaging the student weights. Then Mean Teacher applied a consistency
    constraint between the two predictions of student and teacher:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 'Mean Teacher. Mean Teacher [[68](#bib.bib68)] 通过在训练步骤中使用EMA对模型权重进行平均，并 tend
    to produce a more accurate model instead of directly using output predictions.
    The structure of Mean Teacher is shown in Fig. [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised
    VAE ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(4). Mean
    Teacher consists of two models called Student and Teacher. The student model is
    a regular model similar to the $\Pi$ Model, and the teacher model has the same
    architecture as the student model with exponential moving averaging the student
    weights. Then Mean Teacher applied a consistency constraint between the two predictions
    of student and teacher:'
- en: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x,\zeta),f(\text{EMA}(\theta),x,\zeta^{\prime})).$
    |  | (19) |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x,\zeta),f(\text{EMA}(\theta),x,\zeta^{\prime})).$
    |  | (19) |'
- en: VAT. Virtual Adversarial Training [[180](#bib.bib180)] proposes the concept
    of adversarial attack for consistency regularization. The structure of VAT is
    shown in Fig. [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods
    ‣ A Survey on Deep Semi-supervised Learning")(5). This technique aims to generate
    an adversarial transformation of a sample, which can change the model prediction.
    Specifically, the adversarial training technique is used to find the optimal adversarial
    perturbation $\gamma$ of a real input instance $x$ such that $\gamma\leq\delta$.
    Afterward, the consistency constraint is applied between the model’s output of
    the original input sample and the perturbed one, i.e.,
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: VAT。虚拟对抗训练 [[180](#bib.bib180)] 提出了用于一致性正则化的对抗攻击概念。VAT 的结构如图 [4](#S3.F4 "Figure
    4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning")(5) 所示。该技术旨在生成样本的对抗性变换，这可以改变模型的预测。具体来说，对抗训练技术用于找到真实输入实例 $x$ 的最优对抗扰动
    $\gamma$，使得 $\gamma\leq\delta$。之后，一致性约束应用于原始输入样本和扰动样本的模型输出，即：
- en: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),g(\theta,x+\gamma^{adv})),$
    |  | (20) |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),g(\theta,x+\gamma^{adv})),$
    |  | (20) |'
- en: where $\gamma^{adv}=\operatornamewithlimits{argmax}_{\gamma;\|\gamma\|\leqslant\delta}\mathcal{R}(f(\theta,x),g(\theta,x+\gamma))$.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\gamma^{adv}=\operatornamewithlimits{argmax}_{\gamma;\|\gamma\|\leqslant\delta}\mathcal{R}(f(\theta,x),g(\theta,x+\gamma))$。
- en: 'Dual Student. Dual Student [[178](#bib.bib178)] extends the Mean Teacher model
    by replacing the teacher with another student. The structure of Dual Student is
    shown in Fig. [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods
    ‣ A Survey on Deep Semi-supervised Learning")(6). The two students start from
    different initial states and are optimized through individual paths during training.
    The authors also defined a novel concept, “stable sample”, along with a stabilization
    constraint to avoid the performance bottleneck produced by a coupled EMA Teacher-Student
    model. Hence, their weights may not be tightly coupled, and each learns its own
    knowledge. Formally, Dual Student checks whether $x$ is a stable sample for student
    $i$:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: Dual Student。Dual Student [[178](#bib.bib178)] 通过用另一个学生替代教师，扩展了 Mean Teacher
    模型。Dual Student 的结构如图 [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")(6) 所示。这两个学生从不同的初始状态开始，并在训练过程中通过各自的路径进行优化。作者还定义了一个新概念“稳定样本”，以及一个稳定性约束，以避免由耦合
    EMA Teacher-Student 模型产生的性能瓶颈。因此，它们的权重可能不会紧密耦合，每个学生学习自己的知识。形式上，Dual Student 检查
    $x$ 是否是学生 $i$ 的稳定样本：
- en: '|  | $\mathcal{C}_{x}^{i}=\left\{p_{x}^{i}=p_{\bar{x}}^{i}\right\}_{1}\&amp;\left(\left\{\mathcal{M}_{x}^{i}>\xi\right\}_{1}\left\&#124;\left\{\mathcal{M}_{\bar{x}}^{i}>\xi\right\}_{1}\right.\right),$
    |  | (21) |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{C}_{x}^{i}=\left\{p_{x}^{i}=p_{\bar{x}}^{i}\right\}_{1}\&amp;\left(\left\{\mathcal{M}_{x}^{i}>\xi\right\}_{1}\left\&#124;\left\{\mathcal{M}_{\bar{x}}^{i}>\xi\right\}_{1}\right.\right),$
    |  | (21) |'
- en: 'where $\mathcal{M}_{x}^{i}=\left\|f\left(\theta^{i},x\right)\right\|_{\infty}$,
    and the stabilization constraint:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{M}_{x}^{i}=\left\|f\left(\theta^{i},x\right)\right\|_{\infty}$，以及稳定性约束：
- en: '|  | <math   alttext="\mathcal{L}^{i}_{sta}=\begin{cases}\left\{\varepsilon^{i}>\varepsilon^{j}\right\}_{1}\mathcal{R}\left(f\left(\theta^{i},x\right),f\left(\theta^{j},x\right)\right)&amp;\mathcal{C}^{i}=\mathcal{C}^{j}=1\\
    \mathcal{C}^{i}\mathcal{R}\left(f\left(\theta^{i},x\right),f\left(\theta^{j},x\right)\right)&amp;\text{otherwise}\\'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\mathcal{L}^{i}_{sta}=\begin{cases}\left\{\varepsilon^{i}>\varepsilon^{j}\right\}_{1}\mathcal{R}\left(f\left(\theta^{i},x\right),f\left(\theta^{j},x\right)\right)&amp;\mathcal{C}^{i}=\mathcal{C}^{j}=1\\
    \mathcal{C}^{i}\mathcal{R}\left(f\left(\theta^{i},x\right),f\left(\theta^{j},x\right)\right)&amp;\text{otherwise}\\'
- en: \end{cases}." display="block"><semantics ><mrow ><mrow  ><msubsup ><mi >ℒ</mi><mrow
    ><mi  >s</mi><mo lspace="0em" rspace="0em"  >​</mo><mi >t</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi >a</mi></mrow><mi >i</mi></msubsup><mo >=</mo><mrow ><mo  >{</mo><mtable
    columnspacing="5pt" displaystyle="true" rowspacing="0pt" ><mtr  ><mtd columnalign="left"  ><mrow
    ><msub ><mrow  ><mo >{</mo><mrow ><msup ><mi >ε</mi><mi >i</mi></msup><mo >></mo><msup
    ><mi >ε</mi><mi >j</mi></msup></mrow><mo >}</mo></mrow><mn >1</mn></msub><mo lspace="0em"
    rspace="0em"  >​</mo><mi >ℛ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo
    >(</mo><mrow ><mi >f</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo >(</mo><msup
    ><mi >θ</mi><mi >i</mi></msup><mo >,</mo><mi >x</mi><mo >)</mo></mrow></mrow><mo
    >,</mo><mrow ><mi >f</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo >(</mo><msup
    ><mi >θ</mi><mi >j</mi></msup><mo >,</mo><mi >x</mi><mo >)</mo></mrow></mrow><mo
    >)</mo></mrow></mrow></mtd><mtd columnalign="left"  ><mrow ><msup ><mi >𝒞</mi><mi
    >i</mi></msup><mo >=</mo><msup  ><mi >𝒞</mi><mi >j</mi></msup><mo >=</mo><mn >1</mn></mrow></mtd></mtr><mtr
    ><mtd  columnalign="left" ><mrow ><msup  ><mi >𝒞</mi><mi >i</mi></msup><mo lspace="0em"
    rspace="0em"  >​</mo><mi >ℛ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo
    >(</mo><mrow ><mi >f</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo >(</mo><msup
    ><mi >θ</mi><mi >i</mi></msup><mo >,</mo><mi >x</mi><mo >)</mo></mrow></mrow><mo
    >,</mo><mrow ><mi >f</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo >(</mo><msup
    ><mi >θ</mi><mi >j</mi></msup><mo >,</mo><mi >x</mi><mo >)</mo></mrow></mrow><mo
    >)</mo></mrow></mrow></mtd><mtd columnalign="left"  ><mtext >otherwise</mtext></mtd></mtr></mtable></mrow></mrow><mo
    lspace="0em"  >.</mo></mrow><annotation-xml encoding="MathML-Content" ><apply
    ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >ℒ</ci><ci >𝑖</ci></apply><apply ><ci  >𝑠</ci><ci >𝑡</ci><ci
    >𝑎</ci></apply></apply><apply ><csymbol cd="latexml"  >cases</csymbol><apply ><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><set ><apply ><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >𝜀</ci><ci >𝑖</ci></apply><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >𝜀</ci><ci >𝑗</ci></apply></apply></set><cn type="integer"
    >1</cn></apply><ci >ℛ</ci><interval closure="open"  ><apply ><ci >𝑓</ci><interval
    closure="open" ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝜃</ci><ci
    >𝑖</ci></apply><ci >𝑥</ci></interval></apply><apply ><ci >𝑓</ci><interval closure="open"
    ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝜃</ci><ci >𝑗</ci></apply><ci
    >𝑥</ci></interval></apply></interval></apply><apply ><apply ><apply  ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci >𝒞</ci><ci >𝑖</ci></apply><apply ><csymbol
    cd="ambiguous" >superscript</csymbol><ci >𝒞</ci><ci >𝑗</ci></apply></apply><apply
    ><cn type="integer" >1</cn></apply></apply><apply ><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >𝒞</ci><ci >𝑖</ci></apply><ci >ℛ</ci><interval closure="open"
    ><apply ><ci >𝑓</ci><interval closure="open" ><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >𝜃</ci><ci >𝑖</ci></apply><ci >𝑥</ci></interval></apply><apply
    ><ci >𝑓</ci><interval closure="open" ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >𝜃</ci><ci >𝑗</ci></apply><ci >𝑥</ci></interval></apply></interval></apply><ci
    ><mtext >otherwise</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >\mathcal{L}^{i}_{sta}=\begin{cases}\left\{\varepsilon^{i}>\varepsilon^{j}\right\}_{1}\mathcal{R}\left(f\left(\theta^{i},x\right),f\left(\theta^{j},x\right)\right)&\mathcal{C}^{i}=\mathcal{C}^{j}=1\\
    \mathcal{C}^{i}\mathcal{R}\left(f\left(\theta^{i},x\right),f\left(\theta^{j},x\right)\right)&\text{otherwise}\\
    \end{cases}.</annotation></semantics></math> |  | (22) |
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: \end{cases}." display="block"><semantics ><mrow ><mrow  ><msubsup ><mi >ℒ</mi><mrow
    ><mi  >s</mi><mo lspace="0em" rspace="0em"  >​</mo><mi >t</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi >a</mi></mrow><mi >i</mi></msubsup><mo >=</mo><mrow ><mo  >{</mo><mtable
    columnspacing="5pt" displaystyle="true" rowspacing="0pt" ><mtr  ><mtd columnalign="left"  ><mrow
    ><msub ><mrow  ><mo >{</mo><mrow ><msup ><mi >ε</mi><mi >i</mi></msup><mo >></mo><msup
    ><mi >ε</mi><mi >j</mi></msup></mrow><mo >}</mo></mrow><mn >1</mn></msub><mo lspace="0em"
    rspace="0em"  >​</mo><mi >ℛ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo
    >(</mo><mrow ><mi >f</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo >(</mo><msup
    ><mi >θ</mi><mi >i</mi></msup><mo >,</mo><mi >x</mi><mo >)</mo></mrow></mrow><mo
    >,</mo><mrow ><mi >f</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo >(</mo><msup
    ><mi >θ</mi><mi >j</mi></msup><mo >,</mo><mi >x</mi><mo >)</mo></mrow></mrow><mo
    >)</mo></mrow></mrow></mtd><mtd columnalign="left"  ><mrow ><msup ><mi >𝒞</mi><mi
    >i</mi></msup><mo >=</mo><msup  ><mi >𝒞</mi><mi >j</mi></msup><mo >=</mo><mn >1</mn></mrow></mtd></mtr><mtr
    ><mtd  columnalign="left" ><mrow ><msup  ><mi >𝒞</mi><mi >i</mi></msup><mo lspace="0em"
    rspace="0em"  >​</mo><mi >ℛ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo
    >(</mo><mrow ><mi >f</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo >(</mo><msup
    ><mi >θ</mi><mi >i</mi></msup><mo >,</mo><mi >x</mi><mo >)</mo></mrow></mrow><mo
    >,</mo><mrow ><mi >f</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo >(</mo><msup
    ><mi >θ</mi><mi >j</mi></msup><mo >,</mo><mi >x</mi><mo >)</mo></mrow></mrow><mo
    >)</mo></mrow></mrow></mtd><mtd columnalign="left"  ><mtext >otherwise</mtext></mtd></mtr></mtable></mrow></mrow><mo
    lspace="0em"  >.</mo></mrow><annotation-xml encoding="MathML-Content" ><apply
    ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >ℒ</ci><ci >𝑖</ci></apply><apply ><ci  >𝑠</ci><ci >𝑡</ci><ci
    >𝑎</ci></apply></apply><apply ><csymbol cd="latexml"  >cases</csymbol><apply ><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><set ><apply ><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >𝜀</ci><ci >𝑖</ci></apply><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >𝜀</ci><ci >𝑗</ci></apply></apply></set><cn type="integer"
    >1</cn></apply><ci >ℛ</ci><interval closure="open"  ><apply ><ci >𝑓</ci><interval
    closure="open" ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝜃</ci><ci
    >𝑖</ci></apply><ci >𝑥</ci></interval></apply><apply ><ci >𝑓</ci><interval closure="open"
    ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝜃</ci><ci >𝑗</ci></apply><ci
    >𝑥</ci></interval></apply></interval></apply><apply ><apply ><apply  ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci >𝒞</ci><ci >𝑖</ci></apply><apply ><csymbol
    cd="ambiguous" >superscript</csymbol><ci >𝒞</ci><ci >𝑗</ci></apply></apply><apply
    ><cn type="integer" >1</cn></apply></apply><apply ><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >𝒞</ci><ci >𝑖</ci></apply><ci >ℛ</ci><interval closure="open"
    ><apply ><ci >𝑓</ci><interval closure="open" ><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >𝜃</ci><ci >𝑖</ci></apply><ci >𝑥</ci></interval></apply><apply
    ><ci >𝑓</ci><interval closure="open" ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >𝜃</ci><ci >𝑗</ci></apply><ci >𝑥</ci></interval></apply></interval></apply><ci
    ><mtext >otherwise</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >\mathcal{L}^{i}_{sta}=\begin{cases}\left\{\varepsilon^{i}>\varepsilon^{j}\right\}_{1}\mathcal{R}\left(f\left(\theta^{i},x\right),f\left(\theta^{j},x\right)\right)&\mathcal{C}^{i}=\mathcal{C}^{j}=1\\
    \mathcal{C}^{i}\mathcal{R}\left(f\left(\theta^{i},x\right),f\left(\theta^{j},x\right)\right)&\text{otherwise}\\
    \end{cases}.</annotation></semantics></math> |  | (22) |
- en: 'SWA. Stochastic Weight Averaging (SWA) [[181](#bib.bib181)] improves generalization
    than conventional training. The aim is to average multiple points along the trajectory
    of stochastic gradient descent (SGD) with a cyclical learning rate and seek much
    flatter solutions than SGD. The consistency-based SWA [[182](#bib.bib182)] observes
    that SGD fails to converge on the consistency loss but continues to explore many
    solutions with high distances apart in predictions on the test data. The structure
    of SWA is shown in Fig. [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")(7). The SWA procedure also
    approximates the Teacher-Student approach, such as $\Pi$ Model and Mean Teacher
    with a single model. The authors propose fast-SWA, which adapts the SWA to increase
    the distance between the averaged weights by using a longer cyclical learning
    rate schedule and diversity of the corresponding predictions by averaging multiple
    network weights within each cycle. Generally, the consistency loss can be rewritten
    as follows:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: SWA。随机权重平均（SWA）[[181](#bib.bib181)] 比传统训练更能提高泛化能力。其目的是沿着随机梯度下降（SGD）的轨迹平均多个点，并通过使用循环学习率寻找比
    SGD 更平坦的解。一致性基础的 SWA [[182](#bib.bib182)] 观察到 SGD 无法在一致性损失上收敛，但继续探索在测试数据上预测差异较大的多个解。SWA
    的结构如图 [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods ‣
    A Survey on Deep Semi-supervised Learning")(7) 所示。SWA 程序还近似于教师-学生方法，例如 $\Pi$ 模型和均值教师，使用单一模型。作者提出了快速-SWA，通过使用更长的循环学习率计划和通过在每个周期内平均多个网络权重来增加平均权重之间的距离和相应预测的多样性，从而将
    SWA 适配。一般来说，一致性损失可以重写如下：
- en: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),f(\text{SWA}(\theta),x,\zeta)).$
    |  | (23) |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),f(\text{SWA}(\theta),x,\zeta)).$
    |  | (23) |'
- en: 'VAdD. In VAT, the adversarial perturbation is defined as an additive noise
    unit vector applied to the input or embedding spaces, which has improved the generalization
    performance of SSL. Similarly, Virtual Adversarial Dropout (VAdD) [[183](#bib.bib183)]
    also employs adversarial training in addition to the $\Pi$ Model. The structure
    of VAdD is shown in Fig. [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning")(8). Following the design
    of $\Pi$ Model, the consistency constraint of VAdD is computed from two different
    dropped networks: one dropped network uses a random dropout mask, and the other
    applies adversarial training to the optimized dropout network. Formally, $f(\theta,x,\epsilon)$
    denotes an output of a neural network with a random dropout mask, and the consistency
    loss incorporated adversarial dropout is described as:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: VAdD。在 VAT 中，对抗扰动被定义为施加到输入或嵌入空间的加性噪声单位向量，这提高了 SSL 的泛化性能。类似地，虚拟对抗丢弃（VAdD）[[183](#bib.bib183)]
    也在 $\Pi$ 模型的基础上应用了对抗训练。VAdD 的结构如图 [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised VAE
    ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(8) 所示。根据
    $\Pi$ 模型的设计，VAdD 的一致性约束是通过两个不同的丢弃网络计算的：一个丢弃网络使用随机丢弃掩码，另一个则对优化后的丢弃网络进行对抗训练。形式上，$f(\theta,x,\epsilon)$
    表示一个具有随机丢弃掩码的神经网络的输出，一致性损失中包含对抗丢弃的描述如下：
- en: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x,\epsilon^{s}),f(\theta,x,\epsilon^{adv})),$
    |  | (24) |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x,\epsilon^{s}),f(\theta,x,\epsilon^{adv})),$
    |  | (24) |'
- en: where $\epsilon^{adv}=\operatornamewithlimits{argmax}_{\epsilon;\|\epsilon^{s}-\epsilon\|_{2}\leq\delta
    H}\mathcal{R}(f(\theta,x,\epsilon^{s}),f(\theta,x,\epsilon))$; $f(\theta,x,\epsilon^{adv})$
    represents an adversarial target; $\epsilon^{adv}$ is an adversarial dropout mask;
    $\epsilon^{s}$ is a sampled random dropout mask instance; $\delta$ is a hyperparameter
    controlling the intensity of the noise, and $H$ is the dropout layer dimension.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\epsilon^{adv}=\operatornamewithlimits{argmax}_{\epsilon;\|\epsilon^{s}-\epsilon\|_{2}\leq\delta
    H}\mathcal{R}(f(\theta,x,\epsilon^{s}),f(\theta,x,\epsilon))$; $f(\theta,x,\epsilon^{adv})$
    代表对抗目标; $\epsilon^{adv}$ 是对抗丢弃掩码; $\epsilon^{s}$ 是采样的随机丢弃掩码实例; $\delta$ 是控制噪声强度的超参数，$H$
    是丢弃层维度。
- en: WCP. A novel regularization mechanism for training deep SSL by minimizing the
    Worse-case Perturbation (WCP) is presented by Zhang et al. [[69](#bib.bib69)].
    The structure of WCP is shown in Fig. [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised
    VAE ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised Learning")(9). WCP
    considers two forms of WCP regularizations – additive and DropConnect perturbations,
    which impose additive perturbation on network weights and make structural changes
    by dropping the network connections, respectively. Instead of generating an ensemble
    of randomly corrupted networks, the WCP suggests enhancing the most vulnerable
    part of a network by making the most resilient weights and connections against
    the worst-case perturbations. It enforces an additive noise on the model parameters
    $\zeta$, along with a constraint on the norm of the noise. In this case, the WCP
    regularization becomes,
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: WCP. 张等人提出了一种新颖的正则化机制，用于通过最小化最坏情况扰动（WCP）来训练深度SSL[[69](#bib.bib69)]。WCP的结构如图[4](#S3.F4
    "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods ‣ A Survey on Deep
    Semi-supervised Learning")(9)所示。WCP考虑了两种形式的WCP正则化——加性和DropConnect扰动，分别对网络权重施加加性扰动，并通过丢弃网络连接进行结构性改变。WCP建议通过使最具韧性的权重和连接抵御最坏情况扰动，从而增强网络中最脆弱的部分，而不是生成一个随机腐蚀的网络集成。它对模型参数$\zeta$施加加性噪声，并对噪声的范数施加约束。在这种情况下，WCP正则化变为，
- en: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),g(\theta+\zeta,x)).$ |  |
    (25) |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),g(\theta+\zeta,x)).$ |  |
    (25) |'
- en: The second perturbation is at the network structure level by DropConnect, which
    drops some network connections. Specifically, for parameters $\theta$, the perturbed
    version is $(1-\alpha)\theta$, and the $\alpha=1$ denotes a dropped connection
    while $\alpha=0$ indicates an intact one. By applying the consistency constraint,
    we have
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种扰动是在网络结构层级，由DropConnect引起，它丢弃了一些网络连接。具体来说，对于参数$\theta$，扰动版本为$(1-\alpha)\theta$，其中$\alpha=1$表示丢弃的连接，而$\alpha=0$表示完整的连接。通过应用一致性约束，我们得到
- en: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),f((1-\alpha)\theta,x)).$ |  |
    (26) |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),f((1-\alpha)\theta,x)).$ |  |
    (26) |'
- en: 'UDA. UDA stands for Unsupervised Data Augmentation [[184](#bib.bib184)] for
    image classification and text classification. The structure of UDA is shown in
    Fig. [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods ‣ A
    Survey on Deep Semi-supervised Learning")(10). This method investigates the role
    of noise injection in consistency training and substitutes simple noise operations
    with high-quality data augmentation methods, such as AutoAugment [[185](#bib.bib185)],
    RandAugment [[186](#bib.bib186)] for images, and Back-Translation [[187](#bib.bib187),
    [188](#bib.bib188)] for text. Following the consistency regularization framework,
    the UDA [[184](#bib.bib184)] extends the advancement in supervised data augmentation
    to SSL. As discussed above, let $f(\theta,x,\zeta)$ be the augmentation transformation
    from which one can draw an augmented example $(x,\zeta)$ based on an original
    example $x$. The consistency loss is:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: UDA. UDA代表无监督数据增强[[184](#bib.bib184)]，用于图像分类和文本分类。UDA的结构如图[4](#S3.F4 "Figure
    4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative methods ‣ A Survey on Deep Semi-supervised
    Learning")(10)所示。该方法探讨了噪声注入在一致性训练中的作用，并用高质量的数据增强方法（如AutoAugment [[185](#bib.bib185)]、RandAugment
    [[186](#bib.bib186)]用于图像，Back-Translation [[187](#bib.bib187), [188](#bib.bib188)]用于文本）代替简单的噪声操作。遵循一致性正则化框架，UDA
    [[184](#bib.bib184)]将监督数据增强的进展扩展到SSL。如上所述，令$f(\theta,x,\zeta)$为从中可以基于原始示例$x$生成增强示例$(x,\zeta)$的增强变换。其一致性损失为：
- en: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),f(\theta,x,\zeta)),$ |  |
    (27) |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,x),f(\theta,x,\zeta)),$ |  |
    (27) |'
- en: where $\zeta$ represents the data augmentation operator to create an augmented
    version of an input $x$.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\zeta$表示数据增强操作符，用于创建输入$x$的增强版本。
- en: 'Summary. The core idea of consistency regularization methods is that the output
    of the model remains unchanged under realistic perturbation. As shown in TABLE [III](#S4.T3
    "TABLE III ‣ 4 Consistency Regularization ‣ A Survey on Deep Semi-supervised Learning"),
    Consistency constraints can be considered at three levels: input dataset, neural
    networks and training process. From the input dataset perspective, perturbations
    are usually added to the input examples: additive noise, random augmentation,
    or even adversarial training. We can drop some layers or connections for the networks,
    as WCP [[69](#bib.bib69)]. From the training process, we can use SWA to make the
    SGD fit the consistency training or EMA parameters of the model for some training
    epochs as new parameters.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 总结。一致性正则化方法的核心思想是模型的输出在实际扰动下保持不变。如TABLE [III](#S4.T3 "TABLE III ‣ 4 Consistency
    Regularization ‣ A Survey on Deep Semi-supervised Learning")所示，一致性约束可以在三个层次上考虑：输入数据集、神经网络和训练过程。从输入数据集的角度来看，扰动通常被添加到输入示例中：附加噪声、随机增强，甚至对抗训练。我们可以为网络丢弃一些层或连接，如WCP
    [[69](#bib.bib69)]。从训练过程来看，我们可以使用SWA使SGD适应一致性训练，或将模型的EMA参数作为一些训练周期的新参数。
- en: 5 Graph-based methods
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 图基方法
- en: Graph-based semi-supervised learning (GSSL) has always been a hot subject for
    research with a vast number of successful models[[189](#bib.bib189), [190](#bib.bib190),
    [191](#bib.bib191)] because of its wide variety of applicability. The basic assumption
    in GSSL is that a graph can be extracted from the raw dataset where each node
    represents a training sample, and each edge denotes some similarity measurement
    of the node pair. In this section, we review graph embedding SSL methods, and
    the principal goal is to encode the nodes as small-scale vectors representing
    their role and the structure information of their neighborhood.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的半监督学习（GSSL）由于其广泛的适用性，一直是研究的热门话题，并有大量成功的模型[[189](#bib.bib189), [190](#bib.bib190),
    [191](#bib.bib191)]。GSSL的基本假设是可以从原始数据集中提取出一个图，其中每个节点表示一个训练样本，每条边表示节点对的某种相似性度量。在本节中，我们回顾图嵌入SSL方法，主要目标是将节点编码为小规模向量，表示它们的角色和邻域的结构信息。
- en: '![Refer to caption](img/cbc095b5f5995e74c4d4c32554c3c336.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/cbc095b5f5995e74c4d4c32554c3c336.png)'
- en: 'Figure 5: A glimpse of the diverse range of architectures used for graph-based
    semi-supervised methods. Specifically, in figure (3), “PPMI” is short for positive
    pointwise mutual information. In figure (4), $A$ denotes the adjacency matrix,
    and in figure (5), pink A represents node A.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：展示了用于图基半监督方法的各种架构。具体而言，在图（3）中，“PPMI”是正点对点互信息的缩写。在图（4）中，$A$表示邻接矩阵，而在图（5）中，粉色的A代表节点A。
- en: For graph embedding methods, we have the formal definition for the embedding
    on the node level. Given the graph $\mathcal{G}(\mathcal{V},\mathcal{E})$, the
    node that has been embedded is a mapping result of $f_{\mathbf{z}}:v\rightarrow\mathbf{z}_{v}\in\mathbb{R}^{d},\forall
    v\in{\mathcal{V}}$ such that $d\ll|{\mathcal{V}}|$, and the $f_{\mathbf{z}}$ function
    retains some of the measurement of proximity, defined in the graph $\mathcal{G}$.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图嵌入方法，我们有关于节点级别嵌入的正式定义。给定图$\mathcal{G}(\mathcal{V},\mathcal{E})$，已嵌入的节点是函数$f_{\mathbf{z}}:v\rightarrow\mathbf{z}_{v}\in\mathbb{R}^{d},\forall
    v\in{\mathcal{V}}$的映射结果，其中$d\ll|{\mathcal{V}}|$，而$f_{\mathbf{z}}$函数保留了图$\mathcal{G}$中某些接近度的测量。
- en: The unified form of the loss function is shown as Eq. ([28](#S5.E28 "In 5 Graph-based
    methods ‣ A Survey on Deep Semi-supervised Learning")) for graph embedding methods.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图嵌入方法的损失函数的统一形式见公式 ([28](#S5.E28 "In 5 Graph-based methods ‣ A Survey on Deep
    Semi-supervised Learning"))。
- en: '|  | $\displaystyle\mathcal{L}(f_{\mathbf{z}})=$ | $\displaystyle\sum_{(x,y)\in
    X_{l}}(x,y,f_{\mathbf{z}})+\alpha\sum_{x\in X}\mathcal{R}(x,f_{\mathbf{z}}),$
    |  | (28) |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}(f_{\mathbf{z}})=$ | $\displaystyle\sum_{(x,y)\in
    X_{l}}(x,y,f_{\mathbf{z}})+\alpha\sum_{x\in X}\mathcal{R}(x,f_{\mathbf{z}}),$
    |  | (28) |'
- en: where $f_{\mathbf{z}}$ is the embedding function.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$f_{\mathbf{z}}$是嵌入函数。
- en: Besides, we can divide graph embedding methods into shallow embedding and deep
    embedding based on the use or not use of deep learning techniques. The encoder’s
    function, as a simple lookup function based on node ID, is built with shallow
    embedding methods including DeepWalk [[192](#bib.bib192)], LINE [[193](#bib.bib193)]
    and node2vec [[194](#bib.bib194)], whereas the deep embedding encoder is far more
    complicated, and the deep learning frameworks have to make full use of node attributes.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以根据是否使用深度学习技术将图嵌入方法分为浅层嵌入和深层嵌入。浅层嵌入方法包括DeepWalk [[192](#bib.bib192)]、LINE [[193](#bib.bib193)]和node2vec [[194](#bib.bib194)]，其编码器的功能作为基于节点ID的简单查找函数构建，而深层嵌入编码器则复杂得多，深度学习框架必须充分利用节点属性。
- en: 'As deep learning progresses, recent GSSL research has switched from shallow
    embedding methods to deep embedding methods in which the $f_{\mathbf{z}}$ embedding
    term in the Eq. ([28](#S5.E28 "In 5 Graph-based methods ‣ A Survey on Deep Semi-supervised
    Learning")) is focused on deep learning models. Two classes can be identified
    among all deep embedding methods: AutoEncoder-based methods and GNN-based methods.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习的进步，最近的GSSL研究已经从浅层嵌入方法转向了深层嵌入方法，其中Eq. ([28](#S5.E28 "在 5 基于图的方法 ‣ 深度半监督学习调研"))中的$f_{\mathbf{z}}$嵌入项集中在深度学习模型上。所有深层嵌入方法中可以识别出两类：基于AutoEncoder的方法和基于GNN的方法。
- en: 5.1 AutoEncoder-based methods
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 基于AutoEncoder的方法
- en: 'AutoEncoder-based approaches also differ as a result of using a unary decoder
    rather than a pairwise method. More precisely, every node, ${i}$, is correlated
    to a neighborhood vector $\mathbf{s}_{i}\in\mathbb{R}^{|{\mathcal{V}}|}$. The
    $\mathbf{s}_{i}$ vector contains ${i}$’s similarity with all other graph nodes
    and acts as a high-dimensional vector representation of ${i}$ in the neighborhood.
    The aim of the auto-encoding technique is to embed nodes using hidden embedding
    vectors like $\mathbf{s}_{i}$ in so as to reconstruct the original information
    from such embeddings (Fig. [5](#S5.F5 "Figure 5 ‣ 5 Graph-based methods ‣ A Survey
    on Deep Semi-supervised Learning")(1)):'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 基于AutoEncoder的方法也会因为使用单向解码器而与成对方法有所不同。更具体地说，每个节点${i}$与一个邻域向量$\mathbf{s}_{i}\in\mathbb{R}^{|{\mathcal{V}}|}$相关。$\mathbf{s}_{i}$向量包含了节点${i}$与所有其他图节点的相似性，并且作为${i}$在邻域中的高维向量表示。Auto-encoding技术的目的是使用像$\mathbf{s}_{i}$这样的隐藏嵌入向量来嵌入节点，以便从这些嵌入中重建原始信息（图 [5](#S5.F5
    "图 5 ‣ 5 基于图的方法 ‣ 深度半监督学习调研")(1)）。
- en: '|  | $\operatorname{Dec}\left(\operatorname{Enc}\left(\mathbf{s}_{i}\right)\right)=\operatorname{Dec}\left(\mathbf{z}_{i}\right)\approx\mathbf{s}_{i}.$
    |  | (29) |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '|  | $\operatorname{Dec}\left(\operatorname{Enc}\left(\mathbf{s}_{i}\right)\right)=\operatorname{Dec}\left(\mathbf{z}_{i}\right)\approx\mathbf{s}_{i}.$
    |  | (29) |'
- en: 'In other words, the loss for these methods takes the following form:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，这些方法的损失函数呈现以下形式：
- en: '|  | $\mathcal{L}=\sum_{{i}\in{V}}\left\&#124;\operatorname{Dec}\left(\mathbf{z}_{i}\right)-\mathbf{s}_{i}\right\&#124;_{2}^{2}.$
    |  | (30) |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}=\sum_{{i}\in{V}}\left\| \operatorname{Dec}\left(\mathbf{z}_{i}\right)-\mathbf{s}_{i}\right\|_{2}^{2}.$
    |  | (30) |'
- en: 'SDNE. Structural deep network embedding (SDNE) is developed by Wang  et al. [[195](#bib.bib195)]
    by using deep autoencoders to maintain the first and second-order network proximities.
    This is managed by optimizing the two proximities simultaneously. The process
    utilizes highly nonlinear functions to obtain its embedding. This framework consists
    of two parts: unsupervised and supervised. The first is an autoencoder to identify
    an embedding for a node to rebuild the neighborhood. The second is based on Laplacian
    Eigenmaps [[196](#bib.bib196)], which imposes a penalty when related vertices
    are distant from each other.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: SDNE。结构化深度网络嵌入（SDNE）由Wang等人[[195](#bib.bib195)]开发，通过使用深度Autoencoders来维持一阶和二阶网络相似性。这是通过同时优化这两个相似性来实现的。该过程利用高度非线性函数来获得其嵌入。该框架由两个部分组成：无监督和监督。第一部分是一个Autoencoder，用于识别节点的嵌入以重建邻域。第二部分基于Laplacian
    Eigenmaps [[196](#bib.bib196)]，当相关顶点彼此距离较远时施加惩罚。
- en: 'DNGR. (DNGR) [[197](#bib.bib197)] combines random surfing with autoencoders.
    The model includes three components: random surfing, positive pointwise mutual
    information (PPMI) calculation, and stacked denoising autoencoders. The random
    surfing design is used to create a stochastic matrix equivalent to the similarity
    measure matrix in HOPE [[198](#bib.bib198)] on the input graph. The matrix is
    transformed into a PPMI matrix and fed into a stacked denoising autoencoder to
    obtain the embedding. The PPMI matrix input ensures that the autoencoder model
    captures a higher proximity order. The use of stacked denoising autoencoders also
    helps make the model robust in the event of noise in the graph, as well as in
    seizing the internal structure needed for downstream tasks.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: DNGR。 (DNGR) [[197](#bib.bib197)] 将随机游走与自动编码器相结合。该模型包括三个组件：随机游走、正点对点互信息 (PPMI)
    计算和堆叠去噪自动编码器。随机游走设计用于在输入图上创建一个等效于 HOPE [[198](#bib.bib198)] 中相似度测量矩阵的随机矩阵。该矩阵被转换为
    PPMI 矩阵，并输入到堆叠去噪自动编码器中以获得嵌入。PPMI 矩阵输入确保了自动编码器模型能够捕获更高的接近度顺序。使用堆叠去噪自动编码器还可以使模型在图中存在噪声的情况下保持鲁棒性，并抓住下游任务所需的内部结构。
- en: GAE & VGAE. Both MLP-based and RNN-based strategies only consider the contextual
    information and ignore the feature information of the nodes. To encode both, GAE [[199](#bib.bib199)]
    uses GCN [[200](#bib.bib200)]. The encoder is in the form,
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: GAE & VGAE。MLP 基础和 RNN 基础的策略仅考虑上下文信息，忽略节点的特征信息。为了编码这两者，GAE [[199](#bib.bib199)]
    使用了 GCN [[200](#bib.bib200)]。编码器的形式是
- en: '|  | $\operatorname{Enc}({A},{X})=\operatorname{GraphConv}\left(\sigma(\operatorname{GraphConv}({A},{X}))\right),$
    |  | (31) |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '|  | $\operatorname{Enc}({A},{X})=\operatorname{GraphConv}\left(\sigma(\operatorname{GraphConv}({A},{X}))\right),$
    |  | (31) |'
- en: where $\operatorname{GraphConv}(\cdot)$ is a graph convolutional layer defined
    in [[200](#bib.bib200)], $\sigma(\cdot)$ is the activation function and $A$ ,
    $X$ is adjacency matrix and attribute matrix respectively. The decoder of GAE
    is defined as
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\operatorname{GraphConv}(\cdot)$ 是定义在 [[200](#bib.bib200)] 中的图卷积层，$\sigma(\cdot)$
    是激活函数，而 $A$ 和 $X$ 分别是邻接矩阵和属性矩阵。GAE 的解码器定义为
- en: '|  | $\operatorname{Dec}{(\mathbf{z}_{u},\mathbf{z}_{v})}=\mathbf{z}_{u}^{T}\mathbf{z}_{v}.$
    |  | (32) |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '|  | $\operatorname{Dec}{(\mathbf{z}_{u},\mathbf{z}_{v})}=\mathbf{z}_{u}^{T}\mathbf{z}_{v}.$
    |  | (32) |'
- en: Variational GAE (VGAE) [[199](#bib.bib199)] learns about the distribution of
    the data in which the variation lower bound $\mathcal{L}$ is optimized directly
    by reconstructing the adjacency matrix.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 变分 GAE (VGAE) [[199](#bib.bib199)] 通过重建邻接矩阵直接优化变差下界 $\mathcal{L}$ 来学习数据的分布。
- en: '|  | $\mathcal{L}=\mathbb{E}_{q(\mathbf{Z}\mid{X},{A})}[\log p({A}\mid\mathbf{Z})]-\operatorname{KL}[q(\mathbf{Z}\mid{X},{A})\&#124;p(\mathbf{Z})],$
    |  | (33) |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}=\mathbb{E}_{q(\mathbf{Z}\mid{X},{A})}[\log p({A}\mid\mathbf{Z})]-\operatorname{KL}[q(\mathbf{Z}\mid{X},{A})\|p(\mathbf{Z})],$
    |  | (33) |'
- en: where $\operatorname{KL}[q(\cdot)\|p(\cdot)]$ is the Kullback-Leibler divergence
    between $q(\cdot)$ and $p(\cdot)$. Moreover, we have
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\operatorname{KL}[q(\cdot)\|p(\cdot)]$ 是 $q(\cdot)$ 和 $p(\cdot)$ 之间的 Kullback-Leibler
    散度。此外，我们有
- en: '|  | $q(\mathbf{Z}\mid{X},{A})=\prod_{i=1}^{N}\mathcal{N}\left(\mathbf{z}_{i}\mid{\mu}_{i},\operatorname{diag}\left({\sigma}_{i}^{2}\right)\right),$
    |  | (34) |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '|  | $q(\mathbf{Z}\mid{X},{A})=\prod_{i=1}^{N}\mathcal{N}\left(\mathbf{z}_{i}\mid{\mu}_{i},\operatorname{diag}\left({\sigma}_{i}^{2}\right)\right),$
    |  | (34) |'
- en: and
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '|  | $p({A}\mid\mathbf{Z})=\prod_{i=1}^{N}A_{ij}\sigma\left(\mathbf{z}_{i}^{\top}\mathbf{z}_{j}\right)+\left(1-A_{ij}\right)\left(1-\sigma\left(\mathbf{z}_{i}^{\top}\mathbf{z}_{j}\right)\right).$
    |  | (35) |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '|  | $p({A}\mid\mathbf{Z})=\prod_{i=1}^{N}A_{ij}\sigma\left(\mathbf{z}_{i}^{\top}\mathbf{z}_{j}\right)+\left(1-A_{ij}\right)\left(1-\sigma\left(\mathbf{z}_{i}^{\top}\mathbf{z}_{j}\right)\right).$
    |  | (35) |'
- en: Summary. It should be noted from Eq. ([29](#S5.E29 "In 5.1 AutoEncoder-based
    methods ‣ 5 Graph-based methods ‣ A Survey on Deep Semi-supervised Learning"))
    that the encoder unit does depend on the specific $\mathbf{s}_{i}$ vector, which
    gives the crucial information relating to the local community structure of $v_{i}$.
    TABLE [IV](#S5.T4 "TABLE IV ‣ 5.1 AutoEncoder-based methods ‣ 5 Graph-based methods
    ‣ A Survey on Deep Semi-supervised Learning") sums up the main components of these
    methods, and their architectures are compared as Fig. [5](#S5.F5 "Figure 5 ‣ 5
    Graph-based methods ‣ A Survey on Deep Semi-supervised Learning").
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 总结。从 Eq. ([29](#S5.E29 "在 5.1 自动编码器基础的方法 ‣ 5 基于图的方法 ‣ 深度半监督学习调查")) 中可以看出，编码单元确实依赖于特定的
    $\mathbf{s}_{i}$ 向量，这提供了与 $v_{i}$ 的局部社区结构相关的关键信息。TABLE [IV](#S5.T4 "TABLE IV ‣
    5.1 自动编码器基础的方法 ‣ 5 基于图的方法 ‣ 深度半监督学习调查") 总结了这些方法的主要组件，它们的架构与 Fig. [5](#S5.F5 "图
    5 ‣ 5 基于图的方法 ‣ 深度半监督学习调查") 进行比较。
- en: 'TABLE IV: Summary of AutoEncoder-based Deep Graph Embedding Methods'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 表 IV：基于自编码器的深度图嵌入方法总结
- en: '| Method | Encoder | Decoder | Similarity Measure | Loss Function | Time Complexity
    |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 编码器 | 解码器 | 相似度度量 | 损失函数 | 时间复杂度 |'
- en: '| SDNE [[195](#bib.bib195)] | MLP | MLP | $\mathbf{s}_{u}$ | $\sum_{{u}\in\mathcal{V}}\left\&#124;\operatorname{Dec}\left(\mathbf{z}_{u}\right)-\mathbf{s}_{u}\right\&#124;_{2}^{2}$
    | ${O}(&#124;\mathcal{V}\&#124;\mathcal{E}&#124;)$ |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| SDNE [[195](#bib.bib195)] | MLP | MLP | $\mathbf{s}_{u}$ | $\sum_{{u}\in\mathcal{V}}\left\&#124;\operatorname{Dec}\left(\mathbf{z}_{u}\right)-\mathbf{s}_{u}\right\&#124;_{2}^{2}$
    | ${O}(&#124;\mathcal{V}\&#124;\mathcal{E}&#124;)$ |'
- en: '| DNGR [[197](#bib.bib197)] | MLP | MLP | $\mathbf{s}_{u}$ | $\sum_{{u}\in{\mathcal{V}}}\left\&#124;\operatorname{Dec}\left(\mathbf{z}_{u}\right)-\mathbf{s}_{u}\right\&#124;_{2}^{2}$
    | ${O}\left(&#124;\mathcal{V}&#124;^{2}\right)$ |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| DNGR [[197](#bib.bib197)] | MLP | MLP | $\mathbf{s}_{u}$ | $\sum_{{u}\in{\mathcal{V}}}\left\&#124;\operatorname{Dec}\left(\mathbf{z}_{u}\right)-\mathbf{s}_{u}\right\&#124;_{2}^{2}$
    | ${O}\left(&#124;\mathcal{V}&#124;^{2}\right)$ |'
- en: '| GAE [[199](#bib.bib199)] | GCN | $\mathbf{z}_{u}^{\top}\mathbf{z}_{v}$ |
    $A_{uv}$ | $\sum_{{u}\in{\mathcal{V}}}\left\&#124;\operatorname{Dec}\left(\mathbf{z}_{u}\right)-{A}_{u}\right\&#124;_{2}^{2}$
    | ${O}(&#124;\mathcal{V}\&#124;\mathcal{E}&#124;)$ |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| GAE [[199](#bib.bib199)] | GCN | $\mathbf{z}_{u}^{\top}\mathbf{z}_{v}$ |
    $A_{uv}$ | $\sum_{{u}\in{\mathcal{V}}}\left\&#124;\operatorname{Dec}\left(\mathbf{z}_{u}\right)-{A}_{u}\right\&#124;_{2}^{2}$
    | ${O}(&#124;\mathcal{V}\&#124;\mathcal{E}&#124;)$ |'
- en: '| VGAE [[199](#bib.bib199)] | GCN | $\mathbf{z}_{u}^{\top}\mathbf{z}_{v}$ |
    $A_{uv}$ | $\mathbb{E}_{q(\mathbf{Z}\mid{X},{A})}[\log p({A}\mid\mathbf{Z})]-\operatorname{KL}[q(\mathbf{Z}\mid{X},{A})\&#124;p(\mathbf{Z})]$
    | ${O}(&#124;\mathcal{V}\&#124;\mathcal{E}&#124;)$ |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| VGAE [[199](#bib.bib199)] | GCN | $\mathbf{z}_{u}^{\top}\mathbf{z}_{v}$ |
    $A_{uv}$ | $\mathbb{E}_{q(\mathbf{Z}\mid{X},{A})}[\log p({A}\mid\mathbf{Z})]-\operatorname{KL}[q(\mathbf{Z}\mid{X},{A})\&#124;p(\mathbf{Z})]$
    | ${O}(&#124;\mathcal{V}\&#124;\mathcal{E}&#124;)$ |'
- en: 5.2 GNN-based methods
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 基于GNN的方法
- en: Several updated, deep embedding strategies are designed to resolve major autoencoder-based
    method disadvantages by building certain specific functions that rely on the local
    community of the node but not necessarily the whole graph (Fig. [5](#S5.F5 "Figure
    5 ‣ 5 Graph-based methods ‣ A Survey on Deep Semi-supervised Learning")(5)). The
    GNN, which is widely used in state-of-the-art deep embedding approaches, can be
    regarded as a general guideline for the definition of deep neural networks on
    graphs.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 几种更新后的深度嵌入策略被设计用来解决主要的基于自编码器的方法缺陷，通过构建依赖于节点局部社区而不必依赖整个图的特定函数（图 [5](#S5.F5 "Figure
    5 ‣ 5 Graph-based methods ‣ A Survey on Deep Semi-supervised Learning")(5)）。广泛应用于最新深度嵌入方法中的GNN，可以被视为图上深度神经网络定义的一般指南。
- en: 'Like other deep node-level embedding methods, a classifier is trained to predict
    class labels for the labeled nodes. Then it can be applied to the unlabeled nodes
    based on the final, hidden state of the GNN-based model. Since GNN consists of
    two primary operations: the aggregate operation and the update operation, the
    basic GNN is provided, and then some popular GNN extensions are reviewed with
    a view to enhancing each process, respectively.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他深度节点级嵌入方法类似，训练一个分类器以预测标记节点的类别标签。然后，可以根据GNN模型的最终隐藏状态将其应用于未标记的节点。由于GNN由两个主要操作组成：聚合操作和更新操作，因此提供了基本GNN，然后回顾一些流行的GNN扩展，以期分别增强每个过程。
- en: Basic GNN. As Gilmer et al. [[201](#bib.bib201)] point out, the critical aspect
    of a basic GNN is that the benefit of neural message passing is to exchange and
    update messages between each node pair by using neural networks.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 基本GNN。如Gilmer等 [[201](#bib.bib201)] 指出，基本GNN的关键在于，神经消息传递的好处在于通过使用神经网络在每对节点之间交换和更新消息。
- en: 'More specifically, a hidden embedding $\mathbf{h}_{u}^{(k)}$ in each neural
    message passing through the GNN basic iteration is updated according to message
    or information from the neighborhood within $\mathcal{N}(u)$ according to each
    node $u$. This general message can be expressed according to the update rule:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，每个神经消息传递中的隐藏嵌入 $\mathbf{h}_{u}^{(k)}$ 是根据每个节点 $u$ 的邻域内的消息或信息来更新的。这条一般信息可以根据更新规则表示为：
- en: '|  |  | $\displaystyle\mathbf{h}_{u}^{(k+1)}$ |  | (36) |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\mathbf{h}_{u}^{(k+1)}$ |  | (36) |'
- en: '|  |  | $\displaystyle=\text{ Update }^{(k)}\left(\mathbf{h}_{u}^{(k)},\text{
    Aggregate }^{(k)}\left(\left\{\mathbf{h}_{v}^{(k)},\forall v\in\mathcal{N}(u)\right\}\right)\right)$
    |  |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\text{ 更新 }^{(k)}\left(\mathbf{h}_{u}^{(k)},\text{ 聚合
    }^{(k)}\left(\left\{\mathbf{h}_{v}^{(k)},\forall v\in\mathcal{N}(u)\right\}\right)\right)$
    |  |'
- en: '|  |  | $\displaystyle=\text{ Update }^{(k)}\left(\mathbf{h}_{u}^{(k)},\mathbf{m}_{\mathcal{N}(u)}^{(k)}\right),$
    |  |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
- en: where
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{m}_{\mathcal{N}(u)}^{(k)}=\text{ Aggregate }^{(k)}\left(\left\{\mathbf{h}_{v}^{(k)},\forall
    v\in\mathcal{N}(u)\right\}\right).$ |  | (37) |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
- en: It is worth noting that the functions Update and Aggregate must generally be
    differentiable in Eq. (LABEL:message_passing_update_rule). The new state is generated
    in accordance with Eq. (LABEL:message_passing_update_rule) when the neighborhood
    message is combined with the previous hidden embedding state. After a number of
    iterations, the last hidden embedding state converges so that each node’s final
    status is created as the output. Formally, we have, $\mathbf{z}_{u}=\mathbf{h}_{u}^{(K)},\forall
    u\in\mathcal{V}$.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: The basic GNN model is introduced before reviewing many other GNN-based methods
    designed to perform SSL tasks. The basic version of GNN aims to simplify the original
    GNN model, proposed by Scarselli et al. [[202](#bib.bib202)].
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic GNN message passing is defined as:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{h}_{u}^{(k)}=\sigma\left(\mathbf{W}_{\text{self }}^{(k)}\mathbf{h}_{u}^{(k-1)}+\mathbf{W}_{\text{neigh
    }}^{(k)}\sum_{v\in\mathcal{N}(u)}\mathbf{h}_{v}^{(k-1)}+\mathbf{b}^{(k)}\right),$
    |  | (38) |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{W}_{\text{self }}^{(k)},\mathbf{W}_{\text{neigh }}^{(k)}$ are
    trainable parameters and $\sigma$ is the activation function. In principle, the
    messages from the neighbors are summarized first. Then, the neighborhood information
    and the previously hidden node results are integrated by an essential linear combination.
    Finally, the joint information uses a nonlinear activation function. It is worth
    noting that the GNN layer can be easily stacked together following Eq. ([38](#S5.E38
    "In 5.2 GNN-based methods ‣ 5 Graph-based methods ‣ A Survey on Deep Semi-supervised
    Learning")). The last layer’s output in the GNN model is regarded as the final
    node embedding result to train a classifier for the downstream SSL tasks.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: As previously mentioned, GNN models have all sorts of variants that try to some
    degree boost their efficiency and robustness. All of them, though, obey the Eq. (LABEL:message_passing_update_rule)
    neural message passing structure, regardless of the GNN version explored previously.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: GCN. As mentioned above, the most simple neighborhood aggregation operation
    only calculates the sum of the neighborhood encoding states. The critical issue
    with this approach is that nodes with a large degree appear to derive a better
    benefit from more neighbors compared to those with a lower number of neighbors.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: One typical and straightforward approach to this problem is to normalize the
    aggregation process depending on the central node degree. The most popular method
    is to use the following symmetric normalization Eq. ([39](#S5.E39 "In 5.2 GNN-based
    methods ‣ 5 Graph-based methods ‣ A Survey on Deep Semi-supervised Learning"))
    employed by Kipf et al. [[200](#bib.bib200)] in the graph convolutional network
    (GCN) model as Eq. ([39](#S5.E39 "In 5.2 GNN-based methods ‣ 5 Graph-based methods
    ‣ A Survey on Deep Semi-supervised Learning")).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 一种典型且直接的方法是根据中心节点的度来规范化聚合过程。最流行的方法是使用以下对称规范化公式 Eq. ([39](#S5.E39 "In 5.2 GNN-based
    methods ‣ 5 Graph-based methods ‣ A Survey on Deep Semi-supervised Learning"))，由
    Kipf 等人 [[200](#bib.bib200)] 在图卷积网络（GCN）模型中应用，如公式 Eq. ([39](#S5.E39 "In 5.2 GNN-based
    methods ‣ 5 Graph-based methods ‣ A Survey on Deep Semi-supervised Learning"))。
- en: '|  | $\mathbf{m}_{\mathcal{N}(u)}=\sum_{v\in\mathcal{N}(u)}\frac{\mathbf{h}_{v}}{\sqrt{&#124;\mathcal{N}(u)&#124;\mid\mathcal{N}(v)}\mid}$
    |  | (39) |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{m}_{\mathcal{N}(u)}=\sum_{v\in\mathcal{N}(u)}\frac{\mathbf{h}_{v}}{\sqrt{|\mathcal{N}(u)|\mid|\mathcal{N}(v)|}}$
    |  | (39) |'
- en: GCN fully uses the uniform neighborhood grouping technique. Consequently, the
    GCN model describes the update function as Eq. ([40](#S5.E40 "In 5.2 GNN-based
    methods ‣ 5 Graph-based methods ‣ A Survey on Deep Semi-supervised Learning")).
    As it is indirectly specified in the update function, no aggregation operation
    is defined.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: GCN 完全利用了均匀邻域分组技术。因此，GCN 模型将更新函数描述为公式 Eq. ([40](#S5.E40 "In 5.2 GNN-based methods
    ‣ 5 Graph-based methods ‣ A Survey on Deep Semi-supervised Learning"))。由于在更新函数中间接指定，因此没有定义聚合操作。
- en: '|  | $\mathbf{h}_{u}^{(k)}=\sigma\left(\mathbf{W}^{(k)}\sum_{v\in\mathcal{N}(u)\cup\{u\}}\frac{\mathbf{h}_{v}}{\sqrt{&#124;\mathcal{N}(u)&#124;&#124;\mathcal{N}(v)&#124;}}\right)$
    |  | (40) |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{h}_{u}^{(k)}=\sigma\left(\mathbf{W}^{(k)}\sum_{v\in\mathcal{N}(u)\cup\{u\}}\frac{\mathbf{h}_{v}}{\sqrt{|\mathcal{N}(u)|\mid|\mathcal{N}(v)|}}\right)$
    |  | (40) |'
- en: A vast range of GCN variants is available to boost SSL performance from various
    aspects [[203](#bib.bib203), [204](#bib.bib204)]. Li et al. [[205](#bib.bib205)]
    were the first to have a detailed insight into the performance and lack of GCN
    in SSL tasks. Subsequently, GCN extensions for SSL started to propagate [[206](#bib.bib206)] [[207](#bib.bib207)] [[208](#bib.bib208)] [[209](#bib.bib209)] [[210](#bib.bib210)].
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 大量的 GCN 变体可用来从不同方面提升 SSL 性能 [[203](#bib.bib203), [204](#bib.bib204)]。Li 等人 [[205](#bib.bib205)]
    首次对 GCN 在 SSL 任务中的性能和不足进行了详细的洞察。随后，GCN 在 SSL 中的扩展开始传播 [[206](#bib.bib206)] [[207](#bib.bib207)]
    [[208](#bib.bib208)] [[209](#bib.bib209)] [[210](#bib.bib210)]。
- en: 'GAT. In addition to more general ways of set aggregation, another common approach
    for improving the aggregation layer of GNNs is to introduce certain attention
    mechanisms [[211](#bib.bib211)]. The basic theory is to give each neighbor a weight
    or value of significance which is used to weight the influence of this neighbor
    during the aggregation process. The first GNN to use this focus was Cucurull et al.’s
    Graph Attention Network (GAT), which uses attention weights to describe a weighted
    neighboring amount:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: GAT。除了更一般的集合聚合方式外，另一种常见的方法是引入某些注意力机制 [[211](#bib.bib211)]。基本理论是给予每个邻居一个权重或重要性值，该值用于在聚合过程中加权该邻居的影响。第一个使用这种关注机制的
    GNN 是 Cucurull 等人的图注意力网络（GAT），它使用注意力权重来描述加权邻居的数量：
- en: '|  | $\mathbf{m}_{\mathcal{N}(u)}=\sum_{v\in\mathcal{N}(u)}\alpha_{u,v}\mathbf{h}_{v},$
    |  | (41) |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{m}_{\mathcal{N}(u)}=\sum_{v\in\mathcal{N}(u)}\alpha_{u,v}\mathbf{h}_{v},$
    |  | (41) |'
- en: where $\alpha_{u,v}$ denotes the attention on neighbor $v\in\mathcal{N}(u)$
    when we are aggregating information at node $u$. In the original GAT paper, the
    attention weights are defined as
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\alpha_{u,v}$ 表示在我们在节点 $u$ 上聚合信息时对邻居 $v\in\mathcal{N}(u)$ 的注意力。在原始 GAT 论文中，注意力权重定义为
- en: '|  | $\alpha_{u,v}=\frac{\exp\left(\mathbf{a}^{\top}\left[\mathbf{W}\mathbf{h}_{u}\oplus\mathbf{W}\mathbf{h}_{v}\right]\right)}{\sum_{v^{\prime}\in\mathcal{N}(u)}\exp\left(\mathbf{a}^{\top}\left[\mathbf{Wh}_{u}\oplus\mathbf{Wh}_{v^{\prime}}\right]\right)},$
    |  | (42) |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '|  | $\alpha_{u,v}=\frac{\exp\left(\mathbf{a}^{\top}\left[\mathbf{W}\mathbf{h}_{u}\oplus\mathbf{W}\mathbf{h}_{v}\right]\right)}{\sum_{v^{\prime}\in\mathcal{N}(u)}\exp\left(\mathbf{a}^{\top}\left[\mathbf{W}\mathbf{h}_{u}\oplus\mathbf{W}\mathbf{h}_{v^{\prime}}\right]\right)},$
    |  | (42) |'
- en: where $\mathbf{a}$ is a trainable attention vector, $\mathbf{W}$ is a trainable
    matrix, and denotes the concatenation operation.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathbf{a}$ 是一个可训练的注意力向量，$\mathbf{W}$ 是一个可训练的矩阵，表示连接操作。
- en: GraphSAGE. Over-smoothing is an obvious concern for GNN. Over-smoothing after
    several message iterations is almost unavoidable as the node-specific information
    is “washed away.” The use of vector concatenations or skip connections, which
    both preserve information directly from the previous rounds of the update, is
    one fair way to lessen this concern. For general purposes, $\text{Update}_{\text{base}}$
    denotes a basic update rule.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: GraphSAGE。过度平滑是GNN的一个明显问题。经过几轮消息传递后的过度平滑几乎不可避免，因为节点特定的信息会被“洗掉”。使用向量连接或跳过连接，这两者都直接保留了来自前几轮更新的信息，是减轻这个问题的一种有效方法。对于一般目的，$\text{Update}_{\text{base}}$
    表示基本更新规则。
- en: 'One of the simplest updates in GraphSage [[212](#bib.bib212)] for skip connection
    uses a concatenation vector to contain more node-level information during a messages
    passage process:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在GraphSage [[212](#bib.bib212)]中用于跳过连接的最简单更新之一是使用连接向量在消息传递过程中包含更多的节点级信息：
- en: '|  | $\text{Update}\left(\mathbf{h}_{u},\mathbf{m}_{\mathcal{N}}(u)\right)=\left[\text{Update}_{\text{base}}\left(\mathbf{h}_{u},\mathbf{m}_{\mathcal{N}(u)}\right)\oplus\mathbf{h}_{u}\right],$
    |  | (43) |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '|  | $\text{Update}\left(\mathbf{h}_{u},\mathbf{m}_{\mathcal{N}}(u)\right)=\left[\text{Update}_{\text{base}}\left(\mathbf{h}_{u},\mathbf{m}_{\mathcal{N}(u)}\right)\oplus\mathbf{h}_{u}\right],$
    |  | (43) |'
- en: where the output from the basic update function is concatenated with the previous
    layer representation of the node. The critical observation is that this designed
    model is encouraged to detach information during the message passing operation.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 其中基本更新函数的输出与节点的上一层表示连接。关键观察是，该设计模型在消息传递操作过程中被鼓励分离信息。
- en: GGNN. Parallel to the above work, researchers also are motivated by the approaches
    taken by recurrent neural networks (RNNs) to improve stability. One way to view
    the GNN message propagation algorithm is to gather an observation from neighbors
    of the aggregation process and then change each node’s hidden state. In this respect,
    specific approaches can be used explicitly based on observations to check the
    hidden states of RNN architectures.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: GGNN。与上述工作平行，研究人员也受到递归神经网络（RNN）方法的启发，以提高稳定性。可以将GNN消息传播算法视为从邻居的聚合过程中收集观察结果，然后改变每个节点的隐藏状态。在这方面，可以显式地使用特定方法基于观察来检查RNN架构的隐藏状态。
- en: For example, one of the earliest GNN variants which put this idea into practice
    is proposed by Li et al. [[213](#bib.bib213)], in which the update operation is
    defined as Eq. ([44](#S5.E44 "In 5.2 GNN-based methods ‣ 5 Graph-based methods
    ‣ A Survey on Deep Semi-supervised Learning"))
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，早期的一种GNN变体就是Li等人提出的[[213](#bib.bib213)]，其中更新操作定义为公式 ([44](#S5.E44 "在5.2 GNN-based方法
    ‣ 5 基于图的方法 ‣ 深度半监督学习综述"))
- en: '|  | $\mathbf{h}_{u}^{(k)}=\operatorname{GRU}\left(\mathbf{h}_{u}^{(k-1)},\mathbf{m}_{\mathcal{N}(u)}^{(k)}\right),$
    |  | (44) |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{h}_{u}^{(k)}=\operatorname{GRU}\left(\mathbf{h}_{u}^{(k-1)},\mathbf{m}_{\mathcal{N}(u)}^{(k)}\right),$
    |  | (44) |'
- en: where GRU is a gating mechanism function in recurrent neural networks, introduced
    by Kyunghyun Cho et al. [[214](#bib.bib214)]. Another related approach would be
    similar improvements based on the LSTM architecture [[215](#bib.bib215)].
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 其中GRU是由Kyunghyun Cho等人引入的递归神经网络中的一个门控机制函数 [[214](#bib.bib214)]。另一种相关的方法是基于LSTM架构的类似改进 [[215](#bib.bib215)]。
- en: Summary. The main point of graph-based models for DSSL is to perform label inference
    on a constructed similarity graph so that the label information can be propagated
    from the labeled samples to the unlabeled ones by incorporating both the topological
    and feature knowledge. Moreover, the involvement of deep learning models in GSSL
    helps generate more discriminative embedding representations that are beneficial
    for the downstream SSL tasks, thanks to the more complex encoder functions.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 总结。基于图的DSSL模型的关键点是对构建的相似性图进行标签推断，以便通过结合拓扑知识和特征知识，将标签信息从已标记样本传播到未标记样本。此外，深度学习模型在GSSL中的参与有助于生成更具区分性的嵌入表示，这对于下游SSL任务非常有利，因为更复杂的编码器函数。
- en: 6 Pseudo-labeling methods
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 种伪标签方法
- en: The pseudo-labeling methods differ from the consistency regularization methods
    in that the consistency regularization methods usually rely on consistency constraint
    of rich data transformations. In contrast, pseudo-labeling methods rely on the
    high confidence of pseudo-labels, which can be added to the training data set
    as labeled data. There are two main patterns, one is to improve the performance
    of the whole framework based on the disagreement of views or multiple networks,
    and the other is self-training, in particular, the success of self-supervised
    learning in unsupervised domain makes some self-training self-supervised methods
    realized.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 伪标签方法与一致性正则化方法的不同之处在于，一致性正则化方法通常依赖于丰富的数据转换的一致性约束。相比之下，伪标签方法依赖于伪标签的高置信度，这些伪标签可以作为标记数据添加到训练数据集中。主要有两种模式，一种是基于视角或多个网络的分歧来提高整个框架的性能，另一种是自训练，特别是自监督学习在无监督领域的成功使得一些自训练自监督方法得以实现。
- en: '![Refer to caption](img/f1e1de7c01d50acdd01f8f3c6d925787.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f1e1de7c01d50acdd01f8f3c6d925787.png)'
- en: 'Figure 6: A glimpse of the diverse range of architectures used for pseudo-label
    semi-supervised methods. The same color and structure have the same meaning as
    shown in Figure [4](#S3.F4 "Figure 4 ‣ 3.2 Semi-supervised VAE ‣ 3 Generative
    methods ‣ A Survey on Deep Semi-supervised Learning"). $M_{s}$ denotes shared
    module, $M_{1},M_{2}$ and $M_{3}$ are three different modules in Tri-Net. “Rotation
    ” and “Exemplar” represent $S^{4}L$-Rotation and $S^{4}L$-Exemplar, respectively.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：伪标签半监督方法使用的各种架构的概览。相同的颜色和结构在图[4](#S3.F4 "图 4 ‣ 3.2 半监督 VAE ‣ 3 生成方法 ‣ 深度半监督学习调查")中具有相同的含义。$M_{s}$表示共享模块，$M_{1},M_{2}$和$M_{3}$是Tri-Net中的三个不同模块。“Rotation
    ”和“Exemplar”分别代表$S^{4}L$-Rotation和$S^{4}L$-Exemplar。
- en: 6.1 Disagreement-based models
  id: totrans-299
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 基于分歧的模型
- en: The idea of disagreement-based SSL is to train multiple learners for the task
    and exploit the disagreement during the learning process [[216](#bib.bib216)].
    In such model designs, two or three different networks are trained simultaneously
    and label unlabeled samples for each other.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 基于分歧的自监督学习（SSL）理念是为任务训练多个学习者，并利用学习过程中的分歧[[216](#bib.bib216)]。在这样的模型设计中，同时训练两个或三个不同的网络，并且这些网络会相互标记未标记的样本。
- en: 'Deep co-training. Co-training [[27](#bib.bib27)] framework assumes each data
    $x$ in the dataset has two different and complementary views, and each view is
    sufficient for training a good classifier. Because of this assumption, Co-training
    learns two different classifiers on these two views (see Fig. [6](#S6.F6 "Figure
    6 ‣ 6 Pseudo-labeling methods ‣ A Survey on Deep Semi-supervised Learning")(1)).
    Then the two classifiers are applied to predict each view’s unlabeled data and
    label the most confident candidates for the other model. This procedure is iteratively
    repeated till unlabeled data are exhausted, or some condition is met (such as
    the maximum number of iterations is reached). Let $v_{1}$ and $v_{2}$ as two different
    views of data such that $x=(v_{1},v_{2})$. Co-training assumes that $\mathcal{C}_{1}$
    as the classifier trained on View-$1$ $v_{1}$ and $\mathcal{C}_{2}$ as the classifier
    trained on View-$2$ $v_{2}$ have consistent predictions on $\mathcal{X}$. In the
    objective function, the Co-training assumption can be model as:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 深度协同训练。协同训练[[27](#bib.bib27)]框架假设数据集中每个数据$x$具有两种不同且互补的视角，每种视角足以训练出一个好的分类器。由于这一假设，协同训练在这两种视角上学习两个不同的分类器（见图[6](#S6.F6
    "图 6 ‣ 6 伪标签方法 ‣ 深度半监督学习调查")(1)）。然后，这两个分类器被应用于预测每种视角的未标记数据，并为另一个模型标记最有信心的候选项。这个过程会迭代进行，直到未标记数据用尽，或满足某些条件（如达到最大迭代次数）。设$v_{1}$和$v_{2}$为数据的两个不同视角，使得$x=(v_{1},v_{2})$。协同训练假设$\mathcal{C}_{1}$是基于视角-$1$
    $v_{1}$训练的分类器，$\mathcal{C}_{2}$是基于视角-$2$ $v_{2}$训练的分类器，在$\mathcal{X}$上具有一致的预测。在目标函数中，协同训练假设可以建模为：
- en: '|  | $\mathcal{L}_{ct}=H(\frac{1}{2}(\mathcal{C}_{1}(v_{1})+\mathcal{C}_{2}(v_{2})))-\frac{1}{2}(H(\mathcal{C}_{1}(v_{1}))+H(\mathcal{C}_{2}(v_{2}))),$
    |  | (45) |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}_{ct}=H(\frac{1}{2}(\mathcal{C}_{1}(v_{1})+\mathcal{C}_{2}(v_{2})))-\frac{1}{2}(H(\mathcal{C}_{1}(v_{1}))+H(\mathcal{C}_{2}(v_{2}))),$
    |  | (45) |'
- en: where $H(\cdot)$ denotes the entropy, the Co-training assumption is formulated
    as $\mathcal{C}(x)=\mathcal{C}_{1}(v_{1})=\mathcal{C}_{2}(v_{2}),\forall x=(v_{1},v_{2})\sim\mathcal{X}$.
    On the labeled dataset $X_{L}$, the supervised loss function can be the standard
    cross-entropy loss
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $H(\cdot)$ 表示熵，Co-training 假设被表述为 $\mathcal{C}(x)=\mathcal{C}_{1}(v_{1})=\mathcal{C}_{2}(v_{2}),\forall
    x=(v_{1},v_{2})\sim\mathcal{X}$。在标记数据集 $X_{L}$ 上，监督损失函数可以是标准的交叉熵损失。
- en: '|  | $\mathcal{L}_{s}=H(y,\mathcal{C}_{1}(v_{1}))+H(y,\mathcal{C}_{2}(v_{2})),$
    |  | (46) |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}_{s}=H(y,\mathcal{C}_{1}(v_{1}))+H(y,\mathcal{C}_{2}(v_{2})),$
    |  | (46) |'
- en: where $H(p,q)$ is the cross-entropy between distribution $p$ and $q$.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $H(p,q)$ 是分布 $p$ 和 $q$ 之间的交叉熵。
- en: 'The key to the success of Co-training is that the two views are different and
    complementary. However, the loss function $\mathcal{L}_{ct}$ and $\mathcal{L}_{s}$
    only ensure the model tends to be consistent for the predictions on the dataset.
    To address this problem, [[217](#bib.bib217)] forces to add the View Difference
    Constraint to the previous Co-training model, and formulated as:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: Co-training 成功的关键在于两个视角是不同且互补的。然而，损失函数 $\mathcal{L}_{ct}$ 和 $\mathcal{L}_{s}$
    仅确保模型在数据集上的预测趋于一致。为了解决这个问题，[[217](#bib.bib217)] 强制在之前的 Co-training 模型中添加视角差异约束，其公式为：
- en: '|  | $\exists\mathcal{X}^{\prime}:\mathcal{C}_{1}(v_{1})\neq\mathcal{C}_{2}(v_{2}),\forall
    x=(v_{1},v_{2})\sim\mathcal{X}^{\prime},$ |  | (47) |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '|  | $\exists\mathcal{X}^{\prime}:\mathcal{C}_{1}(v_{1})\neq\mathcal{C}_{2}(v_{2}),\forall
    x=(v_{1},v_{2})\sim\mathcal{X}^{\prime},$ |  | (47) |'
- en: 'where $\mathcal{X}^{\prime}$ denotes the adversarial examples of $\mathcal{X}$,
    thus $\mathcal{X}^{\prime}\cap\mathcal{X}=\emptyset$. In the loss function, the
    View Difference Constraint can be model by minimizing the cross-entropy between
    $\mathcal{C}_{2}(x)$ and $\mathcal{C}_{1}(g_{2}(x))$, where $g(\cdot)$ denotes
    the adversarial examples generated by the generative model. Then, this part loss
    function is:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{X}^{\prime}$ 表示 $\mathcal{X}$ 的对抗样本，因此 $\mathcal{X}^{\prime}\cap\mathcal{X}=\emptyset$。在损失函数中，视角差异约束可以通过最小化
    $\mathcal{C}_{2}(x)$ 和 $\mathcal{C}_{1}(g_{2}(x))$ 之间的交叉熵来建模，其中 $g(\cdot)$ 表示生成模型生成的对抗样本。然后，这部分的损失函数为：
- en: '|  | $\mathcal{L}_{dif}(x)=H(\mathcal{C}_{1}(x),\mathcal{C}_{2}(g_{1}(x)))+H(\mathcal{C}_{2}(x),p_{1}(g_{2}(x))).$
    |  | (48) |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}_{dif}(x)=H(\mathcal{C}_{1}(x),\mathcal{C}_{2}(g_{1}(x)))+H(\mathcal{C}_{2}(x),p_{1}(g_{2}(x))).$
    |  | (48) |'
- en: Some other research works also explore to apply co-training into neural network
    model training. For example, [[218](#bib.bib218)] treats the RGB and depth of
    an image as two independent views for object recognition. Then, co-training is
    performed to train two networks on the two views. Next, a fusion layer is added
    to combine the two-stream networks for recognition, and the overall model is jointly
    trained. Besides, in sentiment classification, [[219](#bib.bib219)] considers
    the original review and the automatically constructed anonymous review as two
    opposite sides of one review and then apply the co-training algorithm. One crucial
    property of [[219](#bib.bib219)] is that two views are opposing and therefore
    associated with opposite class labels.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 一些其他研究也探索了将 co-training 应用到神经网络模型训练中。例如，[[218](#bib.bib218)] 将图像的 RGB 和深度视为两个独立的视角进行对象识别。然后，进行
    co-training 来训练两个视角上的网络。接下来，添加一个融合层来结合这两个流网络进行识别，并且整体模型进行联合训练。此外，在情感分类中，[[219](#bib.bib219)]
    将原始评论和自动构建的匿名评论视为一个评论的两个对立面，然后应用 co-training 算法。[[219](#bib.bib219)] 的一个关键特性是两个视角是对立的，因此与对立的类别标签相关联。
- en: Tri-Net. Tri-net [[220](#bib.bib220)], a deep learning-based method inspired
    by the tri-training [[221](#bib.bib221)]. The tri-training learns three classifiers
    from three different training sets, which are obtained by utilizing bootstrap
    sampling. The framework (as shown in Fig. [6](#S6.F6 "Figure 6 ‣ 6 Pseudo-labeling
    methods ‣ A Survey on Deep Semi-supervised Learning")(2)) of tri-net can be intuitively
    described as follows. Output smearing [[222](#bib.bib222)] is used to add random
    noise to the labeled sample to generate different training sets and help learn
    three initial modules. The three models then predict the pseudo-label for unlabeled
    data. With the predictions of two modules for unlabeled instances consistent,
    the pseudo-label is considered to be confident and stable. The labeled sample
    is added to the training set of the third module, and then the third module is
    fine-tuned on the augmented training set. During the augmentation process, the
    three modules become more and more similar, so the three modules are fine-tuned
    on the training sets respectively to ensure diversity. Formally, the output smearing
    is used to construct three different training sets $\{\mathcal{L}_{os}^{j}=(x_{i},\hat{y}_{i}^{j}),j=1,2,3\}$
    from the initial labeled set $X_{L}$. Then tri-net can be initialized by minimizing
    the sum of standard softmax cross-entropy loss function from the three training
    sets,
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: Tri-Net。Tri-net [[220](#bib.bib220)] 是一种基于深度学习的方法，灵感来源于三重训练 [[221](#bib.bib221)]。三重训练从三个不同的训练集学习三个分类器，这些训练集是通过使用自助抽样获得的。Tri-net
    的框架（如图 [6](#S6.F6 "Figure 6 ‣ 6 Pseudo-labeling methods ‣ A Survey on Deep Semi-supervised
    Learning")(2) 所示）可以直观地描述如下。输出涂抹 [[222](#bib.bib222)] 用于向标记样本添加随机噪声以生成不同的训练集，并帮助学习三个初始模块。然后，这三个模型预测未标记数据的伪标签。当两个模块对未标记实例的预测一致时，伪标签被认为是可靠和稳定的。标记样本被添加到第三个模块的训练集中，然后对增强的训练集进行微调。在增强过程中，三个模块变得越来越相似，因此为了确保多样性，三个模块分别在训练集上进行微调。形式上，输出涂抹用于从初始标记集
    $X_{L}$ 构造三个不同的训练集 $\{\mathcal{L}_{os}^{j}=(x_{i},\hat{y}_{i}^{j}),j=1,2,3\}$。然后，tri-net
    可以通过最小化来自三个训练集的标准 softmax 交叉熵损失函数的总和来初始化，
- en: '|  | $\displaystyle\mathcal{L}=$ | $\displaystyle\frac{1}{L}\sum_{i=1}^{L}\left\{\mathcal{L}_{y}(M_{1}(M_{S}(x_{i})),\hat{y}_{i}^{1})+\mathcal{L}_{y}(M_{2}(M_{S}(x_{i})),\hat{y}_{i}^{2})\right.$
    |  |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}=$ | $\displaystyle\frac{1}{L}\sum_{i=1}^{L}\left\{\mathcal{L}_{y}(M_{1}(M_{S}(x_{i})),\hat{y}_{i}^{1})+\mathcal{L}_{y}(M_{2}(M_{S}(x_{i})),\hat{y}_{i}^{2})\right.$
    |  |'
- en: '|  |  | $\displaystyle\left.+\mathcal{L}_{y}(M_{3}(M_{S}(x_{i})),\hat{y}_{i}^{3})\right\},$
    |  | (49) |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\left.+\mathcal{L}_{y}(M_{3}(M_{S}(x_{i})),\hat{y}_{i}^{3})\right\},$
    |  | (49) |'
- en: where $\mathcal{L}_{y}$ is the standard softmax cross-entropy loss function;
    $M_{S}$ denote a shared module, and $M_{1},M_{2},M_{3}$ is the three different
    modules; $M_{j}(M_{S}(x_{i})),j=1,2,3$ denotes the outputs of the shared features
    generated by $M_{S}$. In the whole procedure, the unlabeled sample can be pseudo-labeled
    by the maximum posterior probability,
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{L}_{y}$ 是标准的 softmax 交叉熵损失函数；$M_{S}$ 表示一个共享模块，$M_{1},M_{2},M_{3}$
    是三个不同的模块；$M_{j}(M_{S}(x_{i})),j=1,2,3$ 表示由 $M_{S}$ 生成的共享特征的输出。在整个过程中，可以通过最大后验概率为未标记样本生成伪标签，
- en: '|  | $\displaystyle y=$ | $\displaystyle\operatornamewithlimits{argmax}_{k\in\{1,2,\dots,K\}}\left\{p(M_{1}(M_{S}(x))=k&#124;x)+\right.$
    |  |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle y=$ | $\displaystyle\operatornamewithlimits{argmax}_{k\in\{1,2,\dots,K\}}\left\{p(M_{1}(M_{S}(x))=k&#124;x)+\right.$
    |  |'
- en: '|  |  | $\displaystyle\left.p(M_{2}(M_{S}(x))=k&#124;x)+p(M_{3}(M_{S}(x))=k&#124;x)\right\}.$
    |  |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\left.p(M_{2}(M_{S}(x))=k&#124;x)+p(M_{3}(M_{S}(x))=k&#124;x)\right\}.$
    |  |'
- en: Summary. The disagreement-based SSL methods exploit the unlabeled data by training
    multiple learners, and the “disagreement” among these learners is crucial. When
    the data has two sufficient redundancy and conditional independence views, Deep
    Co-training [[217](#bib.bib217)] improves the disagreement by designing a View
    Difference Constraint. Tri-Net [[220](#bib.bib220)] obtains three labeled datasets
    by bootstrap sampling and trains three different learners. These methods in this
    category are less affected by model assumptions, non-convexity of the loss function
    and the scalability of the learning algorithms.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 总结。基于不一致的 SSL 方法通过训练多个学习者来利用未标记数据，而这些学习者之间的“意见不一致”至关重要。当数据具有两个充分的冗余和条件独立视图时，Deep
    Co-training [[217](#bib.bib217)] 通过设计视图差异约束来提高不一致性。Tri-Net [[220](#bib.bib220)]
    通过自助抽样获得三个标记数据集并训练三个不同的学习者。这类方法不易受到模型假设、损失函数的非凸性和学习算法的可扩展性的影响。
- en: 6.2 Self-training models
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 自训练模型
- en: Self-training algorithm leverages the model’s own confident predictions to produce
    the pseudo labels for unlabeled data. In other words, it can add more training
    data by using existing labeled data to predict the labels of unlabeled data.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 自训练算法利用模型自身的自信预测来生成未标记数据的伪标签。换句话说，它可以通过使用现有标记数据预测未标记数据的标签来增加更多的训练数据。
- en: EntMin. Entropy Minimization (EntMin) [[223](#bib.bib223)] is a method of entropy
    regularization, which can be used to realize SSL by encouraging the model to make
    low-entropy predictions for unlabeled data and then using the unlabeled data in
    a standard supervised learning setting. In theory, entropy minimization can prevent
    the decision boundary from passing through a high-density data points region,
    otherwise it would be forced to produce low-confidence predictions for unlabeled
    data.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: EntMin. 熵最小化（EntMin）[[223](#bib.bib223)]是一种熵正则化方法，可以通过鼓励模型对未标记数据做出低熵预测，然后在标准的监督学习环境中使用这些未标记数据来实现SSL。从理论上讲，熵最小化可以防止决策边界穿过高密度数据点区域，否则它将被迫对未标记数据生成低置信度预测。
- en: Pseudo-label. Pseudo-label [[224](#bib.bib224)] proposes a simple and efficient
    formulation of training neural networks in a semi-supervised fashion, in which
    the network is trained in a supervised way with labeled and unlabeled data simultaneously.
    As illustrated in Fig. [6](#S6.F6 "Figure 6 ‣ 6 Pseudo-labeling methods ‣ A Survey
    on Deep Semi-supervised Learning")(3), the model is trained on labeled data in
    a usual supervised manner with a cross-entropy loss. For unlabeled data, the same
    model is used to get predictions for a batch of unlabeled samples. The maximum
    confidence prediction is called a pseudo-label, which has the maximum predicted
    probability.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 伪标签。伪标签[[224](#bib.bib224)]提出了一种简单高效的神经网络半监督训练公式，其中网络同时使用标记数据和未标记数据进行监督训练。如图[6](#S6.F6
    "Figure 6 ‣ 6 Pseudo-labeling methods ‣ A Survey on Deep Semi-supervised Learning")(3)所示，该模型在标记数据上使用交叉熵损失进行通常的监督训练。对于未标记数据，相同的模型用于获取一批未标记样本的预测。最大置信度预测称为伪标签，它具有最大预测概率。
- en: 'That is, the pseudo-label model trains a neural network with the loss function
    $\mathcal{L}$, where:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，伪标签模型用损失函数 $\mathcal{L}$ 训练神经网络，其中：
- en: '|  | $\mathcal{L}=\frac{1}{n}\sum_{m=1}^{n}\sum_{i=1}^{K}\mathcal{R}(y_{i}^{m},f_{i}^{m})+\alpha(t)\frac{1}{n^{\prime}}\sum_{m=1}^{n^{\prime}}\sum_{i=1}^{K}\mathcal{R}(y_{i}^{{}^{\prime}m},f_{i}^{{}^{\prime}m}),$
    |  | (50) |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}=\frac{1}{n}\sum_{m=1}^{n}\sum_{i=1}^{K}\mathcal{R}(y_{i}^{m},f_{i}^{m})+\alpha(t)\frac{1}{n^{\prime}}\sum_{m=1}^{n^{\prime}}\sum_{i=1}^{K}\mathcal{R}(y_{i}^{{}^{\prime}m},f_{i}^{{}^{\prime}m}),$
    |  | (50) |'
- en: where $n$ is the number of mini-batch in labeled data for SGD, $n^{\prime}$
    for unlabeled data, $f_{i}^{m}$ is the output units of $m$’s sample in labeled
    data, $y_{i}^{m}$ is the label of that, $y_{i}^{{}^{\prime}m}$ for unlabeled data,
    $y_{i}^{{}^{\prime}m}$ is the pseudo-label of that for unlabeled data, $\alpha(t)$
    is a coefficient balancing the supervised and unsupervised loss terms.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $n$ 是标记数据中用于SGD的小批量数量，$n^{\prime}$ 是未标记数据的数量，$f_{i}^{m}$ 是标记数据中 $m$ 样本的输出单元，$y_{i}^{m}$
    是该样本的标签，$y_{i}^{{}^{\prime}m}$ 是未标记数据的伪标签，$\alpha(t)$ 是平衡监督和无监督损失项的系数。
- en: Noisy Student. Noisy Student [[225](#bib.bib225)] proposes a semi-supervised
    method inspired by knowledge distillation [[226](#bib.bib226)] with equal-or-larger
    student models. The framework is shown in Fig. [6](#S6.F6 "Figure 6 ‣ 6 Pseudo-labeling
    methods ‣ A Survey on Deep Semi-supervised Learning")(4). The teacher EfficientNet
    [[227](#bib.bib227)] model is first trained on labeled images to generate pseudo
    labels for unlabeled examples. Then a larger EfficientNet model as a student is
    trained on the combination of labeled and pseudo-labeled examples. These combined
    instances are augmented using data augmentation techniques such as RandAugment
    [[228](#bib.bib228)], and model noise such as Dropout and stochastic depth are
    also incorporated in the student model during training. After a few iterations
    of this algorithm, the student model becomes the new teacher to relabel the unlabeled
    data and this process is repeated.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: Noisy Student。Noisy Student [[225](#bib.bib225)] 提出了一个半监督方法，该方法受到知识蒸馏 [[226](#bib.bib226)]
    的启发，使用等同或更大的学生模型。框架如图 [6](#S6.F6 "Figure 6 ‣ 6 Pseudo-labeling methods ‣ A Survey
    on Deep Semi-supervised Learning")(4) 所示。首先，教师 EfficientNet [[227](#bib.bib227)]
    模型在标记的图像上进行训练，以生成未标记样本的伪标签。然后，使用一个更大的 EfficientNet 模型作为学生，在标记和伪标记样本的组合上进行训练。这些组合实例使用数据增强技术如
    RandAugment [[228](#bib.bib228)] 进行扩展，并且在训练过程中，学生模型也引入了 Dropout 和随机深度等模型噪声。经过几次迭代后，学生模型成为新的教师，以重新标记未标记的数据，并重复这一过程。
- en: $\bm{S^{4}L}$. Self-supervised Semi-supervised Learning ($S^{4}L$) [[229](#bib.bib229)]
    tackles the problem of SSL by employing self-supervised learning [[230](#bib.bib230)]
    techniques to learn useful representations from the image databases. The architecture
    of $S^{4}L$ is shown in Fig. [6](#S6.F6 "Figure 6 ‣ 6 Pseudo-labeling methods
    ‣ A Survey on Deep Semi-supervised Learning")(5). The conspicuous self-supervised
    techniques are predicting image rotation [[231](#bib.bib231)] and exemplar [[232](#bib.bib232),
    [233](#bib.bib233)]. Predicting image rotation is a pretext task that anticipates
    an angle of the rotation transformation applied to an input example. In $S^{4}L$,
    there are four rotation degrees $\{0^{\circ},90^{\circ},180^{\circ},270^{\circ}\}$
    to rotate input images. The $S^{4}L$-Rotation loss is the cross-entropy loss on
    outputs predicted by those rotated images. $S^{4}L$-Exemplar introduces an exemplar
    loss which encourages the model to learn a representation that is invariant to
    heavy image augmentations. Specifically, eight different instances of each image
    are produced by inception cropping [[234](#bib.bib234)], random horizontal mirroring,
    and HSV-space color randomization as in [[232](#bib.bib232)]. Following [[230](#bib.bib230)],
    the loss term on unsupervised images uses the batch hard triplet loss [[235](#bib.bib235)]
    with a soft margin.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: $\bm{S^{4}L}$。自监督半监督学习 ($S^{4}L$) [[229](#bib.bib229)] 通过采用自监督学习 [[230](#bib.bib230)]
    技术，从图像数据库中学习有用的表示来解决 SSL 问题。$S^{4}L$ 的架构如图 [6](#S6.F6 "Figure 6 ‣ 6 Pseudo-labeling
    methods ‣ A Survey on Deep Semi-supervised Learning")(5) 所示。显著的自监督技术包括预测图像旋转 [[231](#bib.bib231)]
    和示例 [[232](#bib.bib232), [233](#bib.bib233)]。预测图像旋转是一个预文本任务，预测应用于输入示例的旋转变换的角度。在
    $S^{4}L$ 中，有四个旋转角度 $\{0^{\circ},90^{\circ},180^{\circ},270^{\circ}\}$ 用于旋转输入图像。$S^{4}L$-Rotation
    损失是对这些旋转图像预测输出的交叉熵损失。$S^{4}L$-Exemplar 引入了一种示例损失，鼓励模型学习对强图像增强不变的表示。具体而言，通过 inception
    cropping [[234](#bib.bib234)]、随机水平镜像和 HSV 空间颜色随机化生成每张图像的八个不同实例，如 [[232](#bib.bib232)]
    所示。按照 [[230](#bib.bib230)] 的方法，未监督图像上的损失项使用批量硬三元组损失 [[235](#bib.bib235)] 以及软边界。
- en: MPL. In the SSL, the target distributions are often generated on unlabeled data
    by a shaped teacher model trained on labeled data. The constructions for target
    distributions are heuristics that are designed prior to training, and cannot adapt
    to the learning state of the network training. Meta Pseudo Labels (MPL) [[236](#bib.bib236)]
    designs a teacher model that assigns distributions to input examples to train
    the student model. Throughout the course of the student’s training, the teacher
    observes the student’s performance on a held-out validation set, and learns to
    generate target distributions so that if the student learns from such distributions,
    the student will achieve good validation performance. The training procedure of
    MPL involves two alternating processes. As shown in Fig. [6](#S6.F6 "Figure 6
    ‣ 6 Pseudo-labeling methods ‣ A Survey on Deep Semi-supervised Learning")(6),
    the teacher $g_{\phi}(\cdot)$ produces the conditional class distribution $g_{\phi}(x)$
    to train the student. The pair $(x,g_{\phi}(x))$ is then fed into the student
    network $f_{\theta}(\cdot)$ to update its parameters $\theta$ from the cross-entropy
    loss. After the student network updates its parameters, the model evaluates the
    new parameters $\theta^{\prime}$ based on the samples from the held-out validation
    dataset. Since the new parameters of the student depend on the teacher, the dependency
    allows us to compute the gradient of the loss to update the teacher’s parameters.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: EnAET. Different from the previous semi-supervised methods and $S^{4}L$ [[229](#bib.bib229)],
    EnAET [[237](#bib.bib237)] trains an Ensemble of Auto-Encoding Transformations
    to enhance the learning ability of the model. The core part of this framework
    is that EnAET integrates an ensemble of spatial and non-spatial transformations
    to self-train a good feature representation [[238](#bib.bib238)]. EnAET incorporates
    four spatial transformations and a combined non-spatial transformation. The spatial
    transformations are Projective transformation, Affine transformation, Similarity
    transformation and Euclidean transformation. The non-spatial transformation is
    composed of different colors, contrast, brightness and sharpness with four strength
    parameters. As shown in Fig. [6](#S6.F6 "Figure 6 ‣ 6 Pseudo-labeling methods
    ‣ A Survey on Deep Semi-supervised Learning")(7), EnAET learns an encoder $E:x\rightarrow
    E(x),t(x)\rightarrow E(t(x))$ on an original instance and its transformations.
    Meanwhile, a decoder $D:[E(x),E(t(x))]\rightarrow\hat{t}$ is learned to estimate
    $\hat{t}$ of input transformation. Then, we can get an AutoEncoding Transformation
    (AET) loss,
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}_{AET}=\mathbb{E}_{x,t(x)}\&#124;D[E(x),E(t(x))]-t(x)\&#124;^{2},$
    |  | (51) |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
- en: and EnAET adds the AET loss to the SSL loss as a regularization term. Apart
    from the AET loss, EnAET explore a pseudo-labeling consistency by minimizing the
    KL divergence between $P(y|x)$ on an original sample $x$ and $P(y|t(x))$ on a
    transformation $t(x)$.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: 'SimCLRv2. SimCLRv2 [[239](#bib.bib239)] modifies SimCLR [[240](#bib.bib240)]
    for SSL problems. Following the paradigm of supervised fine-tuning after unsupervised
    pretraining, SimCLRv2 uses unlabeled samples in a task-agnostic way, and shows
    that a big (deep and wide) model can surperisingly effective for semi-supervised
    learning. As shown in Fig. [6](#S6.F6 "Figure 6 ‣ 6 Pseudo-labeling methods ‣
    A Survey on Deep Semi-supervised Learning")(8), the SimCLRv2 can be summarized
    in three steps: unsupervised or self-supervised pre-training, supervised fine-tuning
    on 1% or 10% labeled samples, and self-training with task-specific unlabeled examples.
    In the pre-training step, SimCLRv2 learns representations by maximizing the contrastive
    learning loss function in latent space, and the loss function is constructed based
    on the consistency of different augmented views of the same example. The contrastive
    loss is'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\ell_{i,j}=-\log\frac{\exp(sim(z_{i},z_{j})/\tau)}{\sum_{k=1}^{2N}\mathbb{I}_{[k\neq
    i]}\exp(sim(z_{i},z_{k})/\tau)},$ |  | (52) |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
- en: where $(i,j)$ is a pair of positive example augmented from the same sample.
    $sim(\cdot,\cdot)$ is cosine similarity, and $\tau$ is a temperature parameter.
    In the self-training step, SimCLRv2 uses task-specific unlabeled samples, and
    the fine-tuning network acts as a teacher model to minimize the following distillation
    loss,
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}^{\text{distill}}=-\sum_{x_{i}\in X}\big{[}\sum_{y}P^{T}(y&#124;x_{i};\tau)\log
    P^{S}(y&#124;x_{i};\tau)\big{]},$ |  | (53) |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
- en: where $P^{T}(y|x_{i};\tau)$ and $P^{S}(y|x_{i};\tau)$ are produced by teacher
    network and student network, respectively.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: Summary. In general, self-training is a way to get more training data by a series
    of operations to get pseudo-labels of unlabeled data. Both EntMin [[223](#bib.bib223)]
    and Pseudo-label [[224](#bib.bib224)] use entropy minimization to get the pseudo-label
    with the highest confidence as the ground truth for unlabeled data. Noisy Student
    [[225](#bib.bib225)] utilizes a variety of techniques when training the student
    network, such as data augmentation, dropout and stochastic depth. $S^{4}L$ [[229](#bib.bib229)]
    not only uses data augmentation techniques, but also adds another $4$-category
    task to improve model performance. MPL [[236](#bib.bib236)] modifies Pseudo-label
    [[224](#bib.bib224)] by deriving the teacher network’s update rule from the feedback
    of the student network. Emerging techniques (e.g., rich data augmentation strategies,
    meta-learning, self-supervised learning ) and network architectures (e.g., EfficientNet
    [[227](#bib.bib227)], SimCLR [[240](#bib.bib240)]) provide powerful support for
    the development of self-training methods.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: 7 Hybrid methods
  id: totrans-337
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hybrid methods combine ideas from the above-mentioned methods such as pseudo-label,
    consistency regularization and entropy minimization for performance improvement.
    Moreover, a learning principle, namely Mixup [[241](#bib.bib241)], is introduced
    in those hybrid methods. It can be considered as a simple, data-agnostic data
    augmentation approach, a convex combination of paired samples and their respective
    labels. Formally, Mixup constructs virtual training examples,
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\tilde{x}=\lambda x_{i}+(1-\lambda)x_{j},\quad\tilde{y}=\lambda y_{i}+(1-\lambda)y_{j},$
    |  | (54) |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
- en: where $(x_{i},y_{i})$ and $(x_{j},y_{j})$ are two instances from the training
    data, and $\lambda\in[0,1]$. Therefore, Mixup extends the training data set by
    a hard constraint that linear interpolations of samples should lead to the linear
    interpolations of the corresponding labels.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/de88be23ee1acc0b3f27718f4d720f73.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: A glimpse of the diverse range of architectures used for hybrid semi-supervised
    methods. “Mixup” is Mixup operator [[241](#bib.bib241)]. “MixMatch” is MixMatch
    [[71](#bib.bib71)] in figure (2). “GMM” is short for Gaussian Mixture Model. “SAug”
    and “WAug” represent Strong Augmentation and Weak Augmentation, respectively.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: 'ICT. Interpolation Consistency Training (ICT) [[70](#bib.bib70)] regularizes
    SSL by encouraging the prediction at an interpolation of two unlabeled examples
    to be consistent with the interpolation of the predictions at those points. The
    architecture is shown in Fig.[7](#S7.F7 "Figure 7 ‣ 7 Hybrid methods ‣ A Survey
    on Deep Semi-supervised Learning")(1). The low-density separation assumption inspires
    this method, and Mixup can achieve broad margin decision boundaries. It is done
    by training the model $f(\theta)$ to predict $\text{Mix}_{\lambda}(\hat{y}_{j},\hat{y}_{k})$
    at location $\text{Mix}_{\lambda}(x_{j},x_{k})$ with the Mixup operation: $\text{Mix}_{\lambda}(a,b)=\lambda
    a+(1-\lambda)b$. In semi-supervised settings, ICT extends Mixup by training the
    model $f(\theta,x)$ to predict the “fake label” $\text{Mix}_{\lambda}(f(\theta,x_{j}),f(\theta,x_{k}))$
    at location $\text{Mix}_{\lambda}(x_{j},x_{k})$. Moreover, the model $f_{\theta}$
    predict the fake label $\text{Mix}_{\lambda}(f_{\theta^{\prime}}(x_{i}),f_{\theta^{\prime}}(x_{j}))$
    at location $\text{Mix}_{\lambda}(x_{i},x_{j})$, where $\theta^{\prime}$ is a
    moving average of $\theta$, like [[68](#bib.bib68)], for a more conservation consistent
    regularization. Thus, the ICT term is'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbb{E}_{x\in X}\mathcal{R}(f(\theta,\text{Mix}_{\lambda}(x_{i},x_{j})),\text{Mix}_{\lambda}(f(\theta^{\prime},x_{i}),f(\theta^{\prime},x_{j})).$
    |  | (55) |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
- en: 'MixMatch. MixMatch [[71](#bib.bib71)] combines consistency regularization and
    entropy minimization in a unified loss function. This model operates by producing
    pseudo-labels for each unlabeled instance and then training the original labeled
    data with the pseudo-labels for the unlabeled data using fully-supervised techniques.
    The main aim of this algorithm is to create the collections $X^{\prime}_{L}$ and
    $X^{\prime}_{U}$, which are made up of augmented labeled and unlabeled samples
    that were generated using Mixup. Formally, MixMatch produces an augmentation of
    each labeled instance $(x_{i},y_{i})$ and $K$ weakly augmented version of each
    unlabeled instance $(x_{j})$ with $k\in\{1,\ldots,K\}$. Then, it generates a pseudo-label
    $\bar{y}_{j}$ for each $x_{j}$ by computing the average prediction across the
    $K$ augmentations. The pseudo-label distribution is then sharpened by adjusting
    temperature scaling to get the final pseudo-label $\tilde{y}_{j}$. After the data
    augmentation, the batches of augmented labeled examples and unlabeled with pseudo-label
    examples are combined, then the whole group is shuffled. This group is divided
    into two parts: the first $L$ samples were taken as $\mathcal{W}_{L}$, and the
    remaining taken as $\mathcal{W}_{U}$. The group $\mathcal{W}_{L}$ and the augmented
    labeled batch $\tilde{X}_{L}$ are fed into the Mixup algorithm to compute examples
    $(x^{\prime},y^{\prime})$ where $x^{\prime}=\lambda x_{1}+(1-\lambda)x_{2}$ for
    $\lambda\sim\text{Beta}(\alpha,\alpha)$. Similarly, Mixup is applied between the
    remaining $\mathcal{W}_{U}$ and the augmented unlabeled group $\tilde{X}_{U}$.
    MixMatch conducts traditional fully-supervised training with a standard cross-entropy
    loss for a supervised dataset and a mean square error for unlabeled data given
    these mixed-up samples.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: ReMixMatch. ReMixMatch [[72](#bib.bib72)] extends MixMatch [[71](#bib.bib71)]
    by introducing distribution alignment and augmentation anchoring. Distribution
    alignment encourages the marginal distribution of aggregated class predictions
    on unlabeled data close to the marginal distribution of ground-truth labels. Augmentation
    anchoring replaces the consistency regularization component of MixMatch. This
    technique generates multiple strongly augmented versions of input and encourages
    each output to be close to predicting a weakly-augmented variant of the same input.
    A variant of AutoAugment [[185](#bib.bib185)] dubbed “CTAugment” is also proposed
    to produce strong augmentations, which learns the augmentation policy alongside
    the model training. As the procedure of ReMixmatch presented in Fig. [7](#S7.F7
    "Figure 7 ‣ 7 Hybrid methods ‣ A Survey on Deep Semi-supervised Learning")(3),
    an “anchor” is generated by applying weak augmentation to a given unlabeled example
    and then $K$ strongly-augmented versions of the same unlabeled example using CTAugment.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: DivideMix. DivideMix [[73](#bib.bib73)] presents a new SSL framework to handle
    the problem of learning with noisy labels. As shown in Fig. [7](#S7.F7 "Figure
    7 ‣ 7 Hybrid methods ‣ A Survey on Deep Semi-supervised Learning")(4), DivideMix
    proposes co-divide, a process that trains two networks simultaneously. For each
    network, a dynamic Gauss Mixed Model (GMM) is fitted on the loss distribution
    of each sample to divide the training set into labeled data and unlabeled data.
    The separated data sets are then used to train the next epoch’s networks. In the
    follow-up SSL process, co-refinement and co-guessing are used to improve MixMatch
    [[71](#bib.bib71)] and solve the problem of learning with noisy labels.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: FixMatch. FixMatch [[242](#bib.bib242)] combines consistency regularization
    and pseudo-labeling while vastly simplifying the overall method. The key innovation
    comes from the combination of these two ingredients, and the use of a separate
    weak and strong augmentation in the consistency regularization approach. Given
    an instance, only when the model predicts a high-confidence label can the predicted
    pseudo-label be identified as ground-truth. As shown in Fig.[7](#S7.F7 "Figure
    7 ‣ 7 Hybrid methods ‣ A Survey on Deep Semi-supervised Learning")(5), given an
    instance $x_{j}$, FixMatch firstly generates pseudo-label $\hat{y}_{j}$ for weakly-augmented
    unlabeled instances $\hat{x}_{j}$. Then, the model trained on the weakly-augmented
    samples is used to predict pseudo-label in the strongly-augmented version of $x_{j}$.
    In FixMatch, weak augmentation is a standard flip-and-shift augmentation strategy,
    randomly flipping images horizontally with a probability. For strong augmentation,
    there are two approaches which are based on [[185](#bib.bib185)], i.e., RandAugment
    [[228](#bib.bib228)] and CTAugment [[72](#bib.bib72)]. Moreover, Cutout [[243](#bib.bib243)]
    is followed by either of these strategies.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: Summary. As discussed above, the hybrid methods unit the most successful approaches
    in SSL, such as pseudo-labeling, entropy minimization and consistency regularization,
    and adapt them to achieve state-of-the-art performance. In TABLE [V](#S7.T5 "TABLE
    V ‣ 7 Hybrid methods ‣ A Survey on Deep Semi-supervised Learning"), we summarize
    some techniques that can be used in consistency training to improve model performance.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE V: Summary of Input Augmentations and Neural Network Transformations'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Techniques | Methods |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
- en: '| Input augmentations | Additional Noise | Ladder Network [[65](#bib.bib65)],
    WCP [[69](#bib.bib69)] |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
- en: '|  | Stochastic Augmentation | $\Pi$ Model [[66](#bib.bib66)], Temporal Ensembling
    [[67](#bib.bib67)], Mean Teacher [[68](#bib.bib68)], Dual Student [[178](#bib.bib178)],
    MixMatch [[71](#bib.bib71)], ReMixMatch [[72](#bib.bib72)], FixMatch [[242](#bib.bib242)]
    |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
- en: '|  | Adversarial perturbation | VAT [[180](#bib.bib180)], VAdD [[183](#bib.bib183)]
    |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
- en: '|  | AutoAugment | UDA [[184](#bib.bib184)], Noisy Student [[225](#bib.bib225)]
    |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
- en: '|  | RandAugment | UDA [[184](#bib.bib184)], FixMatch [[242](#bib.bib242)]
    |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
- en: '|  | CTAugment | ReMixMatch [[72](#bib.bib72)], FixMatch [[242](#bib.bib242)]
    |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
- en: '|  | Mixup | ICT [[70](#bib.bib70)], MixMatch [[71](#bib.bib71)], ReMixMatch
    [[72](#bib.bib72)], DivideMix [[73](#bib.bib73)] |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
- en: '| Neural network transformations | Dropout | $\Pi$ Model [[66](#bib.bib66)],
    Temporal Ensembling [[67](#bib.bib67)], Mean Teacher [[68](#bib.bib68)], Dual
    Student [[178](#bib.bib178)], VAdD [[183](#bib.bib183)],Noisy Student [[225](#bib.bib225)]
    |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
- en: '|  | EMA | Mean Teacher [[68](#bib.bib68)], ICT [[70](#bib.bib70)] |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
- en: '|  | SWA | SWA [[182](#bib.bib182)] |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
- en: '|  | Stochastic depth | Noisy Student [[225](#bib.bib225)] |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
- en: '|  | DropConnect | WCP [[69](#bib.bib69)] |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
- en: 8 Challenges and future directions
  id: totrans-364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although exceptional performance and achieved promising DSSL progress, there
    are still several open research questions for future work. We outline some of
    these issues and future directions below.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: Theoretical analysis. Existing semi-supervised approaches predominantly use
    unlabeled samples to generate constraints and then update the model with labeled
    data and these constraints. However, the internal mechanism of DSSL and the role
    of various techniques, such as data augmentations, training methods and loss functions,etc.,
    are not clear. Generally, there is a single weight to balance the supervised and
    unsupervised loss, which means that all unlabeled instances are equally weighted.
    However, not all unlabeled data is equally appropriate for the model in practice.
    To counter this issue, [[244](#bib.bib244)] considers how to use a different weight
    for every unlabeled example. For consistency regularization SSL, [[182](#bib.bib182)]
    investigates how loss geometry interacts with training process. [[245](#bib.bib245)]
    experimentally explores the effects of data augmentation and labeled dataset size
    on pre-training and self-training, as well as the limitations and interactions
    of pre-training and self-training. [[246](#bib.bib246)] analyzes the property
    of the consistency regularization methods when data instances lie in the neighborhood
    of low-dimensional manifolds, especially in the case of efficient data augmentations
    or perturbations schemes.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: Incorporation of domain knowledge. Most of the SSL approaches listed above can
    obtain satisfactory results only in ideal situations in which the training dataset
    meets the designed assumptions and contains sufficient information to learn an
    insightful learning system. However, in practice, the distribution of the dataset
    is unknown and does not necessarily meet these ideal conditions. When the distributions
    of labeled and unlabeled data do not belong to the same one or the model assumptions
    are incorrect, the more unlabeled data is utilized, the worse the performance
    will be. Therefore, we can attempt to incorporate richer and more reliable domain
    knowledge into the model to mitigate the degradation performance. Recent works
    focusing on this direction have proposed [[247](#bib.bib247), [248](#bib.bib248),
    [249](#bib.bib249), [250](#bib.bib250), [251](#bib.bib251)] for DSSL.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: Learning with noisy labels. In this survey, models discussed typically consider
    the labeled data is generally accurate to learn a standard cross-entropy loss
    function. An interesting consideration is to explore how SSL can be performed
    for cases where corresponding labeled instances with noisy initial labels. For
    example, the labeling of samples may be contributed by the community, so we can
    only obtain noisy labels for the training dataset. One solution to this problem
    is [[252](#bib.bib252)], which augments the prediction objective with consistency
    where the same prediction is made given similar percepts. Based on graph SSL,
    [[253](#bib.bib253)] introduces a new $L_{1}$-norm formulation of Laplacian regularization
    inspired by sparse coding. [[254](#bib.bib254)] deals with this problem from the
    perspective of memorization effects, which proposed a learning paradigm combining
    co-training and mean teacher.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: Imbalanced semi-supervised learning. The problem of class imbalance is naturally
    widespread in real-world applications. When the training data is highly imbalanced,
    most learning frameworks will show bias towards the majority class, and in some
    extreme cases, may completely ignore the minority class [[255](#bib.bib255)],
    as a result, the efficiency of predictive models will be significantly affected.
    Nevertheless, to handle the semi-supervised problem, it is commonly assumed that
    training dataset is uniformly distributed over all class labels. Recently, more
    and more works have focused on this problem. [[256](#bib.bib256)] aligns pseudo-labels
    with the desirable class distribution in the unlabeled data for SSL with imbalanced
    labeled data. Based on graph-based semi-supervised methods, [[257](#bib.bib257)]
    copes with various degrees of class imbalance in a given dataset.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: Robust semi-supervised learning. The common of the latest state-of-the-art approaches
    is the application of consistency training on augmented unlabeled data without
    changing the model predictions. One attempt is made by VAT [[180](#bib.bib180)]
    and VAdD [[183](#bib.bib183)]. Both of them employ adversarial training to find
    the optimal adversarial example. Another promising approach is data augmentation
    (adding noise or random perturbations, CutOut [[243](#bib.bib243)], RandomErasing
    [[258](#bib.bib258)], HideAndSeek [[259](#bib.bib259)] and GridMask [[260](#bib.bib260)]),
    especially advanced data augmentation, such as AutoAugment [[185](#bib.bib185)],
    RandAugment [[228](#bib.bib228)], CTAugment [[72](#bib.bib72)], and Mixup [[241](#bib.bib241)]
    which also can be considered as a form of regularization.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: Safe semi-supervised learning. In SSL, it is generally accepted that unlabeled
    data can help improve learning performance, especially when labeled data is scarce.
    Although it is remarkable that unlabeled data can improve learning performance
    under appropriate assumptions or conditions, some empirical studies [[261](#bib.bib261),
    [262](#bib.bib262), [263](#bib.bib263)] have shown that the use of unlabeled data
    may lead to performance degeneration, making the generalization performance even
    worse than a model learned only with labeled data in real-world applications.
    Thus, safe semi-supervised learning approaches are desired, which never significantly
    degrades learning performance when unlabeled data is used.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: 9 Conclusion
  id: totrans-372
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Deep semi-supervised learning is a promising research field with important
    real-world applications. The success of deep learning approaches has led to the
    rapid growth of DSSL techniques. This survey provides a taxonomy of existing DSSL
    methods, and groups DSSL methods into five categories: Generative models, Consistency
    Regularization models, Graph-based models, Pseudo-labeling models, and Hybrid
    models. We provide illustrative figures to compare the differences between the
    approaches within the same category. Finally, we discuss the challenges of DSSL
    and some future research directions that are worth further studies.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgment
  id: totrans-374
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This paper was partially supported by the National Key Research and Development
    Program of China (No. 2018AAA0100204), and a key program of fundamental research
    from Shenzhen Science and Technology Innovation Commission (No. JCYJ20200109113403826).
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] J. Padmanabhan and J. M. J. Premkumar, “Advanced deep neural networks for
    pattern recognition: An experimental study,” in *SoCPaR*, ser. Advances in Intelligent
    Systems and Computing, vol. 614.   Springer, 2016, pp. 166–175.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] K. Yun, A. Huyen, and T. Lu, “Deep neural networks for pattern recognition,”
    *CoRR*, vol. abs/1809.09645, 2018.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Q. Zhang, L. T. Yang, Z. Chen, and P. Li, “A survey on deep learning for
    big data,” *Inf. Fusion*, vol. 42, pp. 146–157, 2018.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] T. Tran, T. Pham, G. Carneiro, L. J. Palmer, and I. D. Reid, “A bayesian
    data augmentation approach for learning deep models,” in *NIPS*, 2017, pp. 2797–2806.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
    with deep convolutional neural networks,” *Commun. ACM*, vol. 60, no. 6, pp. 84–90,
    2017.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
    recognition,” in *CVPR*.   IEEE Computer Society, 2016, pp. 770–778.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] J. Devlin, M. Chang, K. Lee, and K. Toutanova, “BERT: pre-training of deep
    bidirectional transformers for language understanding,” in *NAACL-HLT*.   Association
    for Computational Linguistics, 2019, pp. 4171–4186.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] A. Torfi, R. A. Shirvani, Y. Keneshloo, N. Tavvaf, and E. A. Fox, “Natural
    language processing advancements by deep learning: A survey,” *CoRR*, vol. abs/2003.01200,
    2020.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] I. J. Goodfellow, Y. Bengio, and A. C. Courville, *Deep Learning*, ser.
    Adaptive computation and machine learning.   MIT Press, 2016.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Y. LeCun, Y. Bengio, and G. E. Hinton, “Deep learning,” *Nat.*, vol. 521,
    no. 7553, pp. 436–444, 2015.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] O. Chapelle, B. Schölkopf, and A. Zien, “Introduction to semi-supervised
    learning,” in *Semi-Supervised Learning*.   The MIT Press, 2006, pp. 1–12.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] X. Zhu and A. B. Goldberg, *Introduction to Semi-Supervised Learning*,
    ser. Synthesis Lectures on Artificial Intelligence and Machine Learning.   Morgan
    & Claypool Publishers, 2009.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] A. Oliver, A. Odena, C. Raffel, E. D. Cubuk, and I. J. Goodfellow, “Realistic
    evaluation of deep semi-supervised learning algorithms,” in *NeurIPS*, 2018, pp.
    3239–3250.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] A. K. Agrawala, “Learning with a probabilistic teacher,” *IEEE Trans.
    Inf. Theory*, vol. 16, no. 4, pp. 373–379, 1970.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] S. C. Fralick, “Learning to recognize patterns without a teacher,” *IEEE
    Trans. Inf. Theory*, vol. 13, no. 1, pp. 57–64, 1967.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] H. J. S. III, “Probability of error of some adaptive pattern-recognition
    machines,” *IEEE Trans. Inf. Theory*, vol. 11, no. 3, pp. 363–371, 1965.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] D. J. Miller and H. S. Uyar, “A mixture of experts classifier with learning
    based on both labelled and unlabelled data,” in *NIPS*.   MIT Press, 1996, pp.
    571–577.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] K. Nigam, A. McCallum, S. Thrun, and T. M. Mitchell, “Text classification
    from labeled and unlabeled documents using EM,” *Mach. Learn.*, vol. 39, no. 2/3,
    pp. 103–134, 2000.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] T. Joachims, “Transductive inference for text classification using support
    vector machines,” in *ICML*.   Morgan Kaufmann, 1999, pp. 200–209.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] K. P. Bennett and A. Demiriz, “Semi-supervised support vector machines,”
    in *NIPS*.   The MIT Press, 1998, pp. 368–374.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Z. Xu, R. Jin, J. Zhu, I. King, and M. R. Lyu, “Efficient convex relaxation
    for transductive support vector machine,” in *Advances in Neural Information Processing
    Systems 20*, J. C. Platt, D. Koller, Y. Singer, and S. T. Roweis, Eds.   Curran
    Associates, Inc., 2007, pp. 1641–1648.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Z. Xu, R. Jin, J. Zhu, I. King, M. R. Lyu, and Z. Yang, “Adaptive regularization
    for transductive support vector machine,” in *Advances in Neural Information Processing
    Systems 22*, Y. Bengio, D. Schuurmans, J. D. Lafferty, C. K. I. Williams, and
    A. Culotta, Eds.   Curran Associates, Inc., 2009, pp. 2125–2133.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] X. Zhu, Z. Ghahramani, and J. D. Lafferty, “Semi-supervised learning using
    gaussian fields and harmonic functions,” in *ICML*.   AAAI Press, 2003, pp. 912–919.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] M. Belkin, P. Niyogi, and V. Sindhwani, “Manifold regularization: A geometric
    framework for learning from labeled and unlabeled examples,” *J. Mach. Learn.
    Res.*, vol. 7, pp. 2399–2434, 2006.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] A. Blum and S. Chawla, “Learning from labeled and unlabeled data using
    graph mincuts,” in *ICML*.   Morgan Kaufmann, 2001, pp. 19–26.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and B. Schölkopf, “Learning
    with local and global consistency,” in *NIPS*.   MIT Press, 2003, pp. 321–328.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] A. Blum and T. M. Mitchell, “Combining labeled and unlabeled data with
    co-training,” in *COLT*.   ACM, 1998, pp. 92–100.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] O. Chapelle, B. Schölkopf, and A. Zien, Eds., *Semi-Supervised Learning*.   The
    MIT Press, 2006.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] G. Qi and J. Luo, “Small data challenges in big data era: A survey of
    recent progress on unsupervised and semi-supervised methods,” *CoRR*, vol. abs/1903.11260,
    2019.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] J. E. van Engelen and H. H. Hoos, “A survey on semi-supervised learning,”
    *Mach. Learn.*, vol. 109, no. 2, pp. 373–440, 2020.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Y. Ouali, C. Hudelot, and M. Tami, “An overview of deep semi-supervised
    learning,” *CoRR*, vol. abs/2006.05278, 2020.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] H. Cevikalp, B. Benligiray, Ö. N. Gerek, and H. Saribas, “Semi-supervised
    robust deep neural networks for multi-label classification,” in *CVPR Workshops*.   Computer
    Vision Foundation / IEEE, 2019, pp. 9–17.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] L. Wang, Y. Liu, C. Qin, G. Sun, and Y. Fu, “Dual relation semi-supervised
    multi-label learning,” in *AAAI*.   AAAI Press, 2020, pp. 6227–6234.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] H. Cevikalp, B. Benligiray, and Ö. N. Gerek, “Semi-supervised robust deep
    neural networks for multi-label image classification,” *Pattern Recognit.*, vol.
    100, p. 107164, 2020.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] O. Chapelle and A. Zien, “Semi-supervised classification by low density
    separation,” in *AISTATS*.   Society for Artificial Intelligence and Statistics,
    2005.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] D. Yarowsky, “Unsupervised word sense disambiguation rivaling supervised
    methods,” in *ACL*.   Morgan Kaufmann Publishers / ACL, 1995, pp. 189–196.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] V. R. de Sa, “Learning classification with unlabeled data,” in *NIPS*.   Morgan
    Kaufmann, 1993, pp. 112–119.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] J. Vittaut, M. Amini, and P. Gallinari, “Learning classification with
    both labeled and unlabeled data,” in *ECML*, ser. Lecture Notes in Computer Science,
    vol. 2430.   Springer, 2002, pp. 468–479.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] O. Chapelle, M. Chi, and A. Zien, “A continuation method for semi-supervised
    svms,” in *ICML*, ser. ACM International Conference Proceeding Series, vol. 148.   ACM,
    2006, pp. 185–192.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] Z. Xu, R. Jin, J. Zhu, I. King, and M. R. Lyu, “Efficient convex relaxation
    for transductive support vector machine,” in *NIPS*.   Curran Associates, Inc.,
    2007, pp. 1641–1648.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] X. Zhu, “Learning from labeled and unlabeled data with label propagation,”
    *Tech Report*, 2002.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] Y. Bengio, O. Delalleau, and N. L. Roux, “Label propagation and quadratic
    criterion,” in *Semi-Supervised Learning*.   The MIT Press, 2006, pp. 192–216.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] J. Weston, F. Ratle, H. Mobahi, and R. Collobert, “Deep learning via semi-supervised
    embedding,” in *Neural Networks: Tricks of the Trade (2nd ed.)*, ser. Lecture
    Notes in Computer Science.   Springer, 2012, vol. 7700, pp. 639–655.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] S. J. Pan and Q. Yang, “A survey on transfer learning,” *IEEE Trans. Knowl.
    Data Eng.*, vol. 22, no. 10, pp. 1345–1359, 2010.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] C. Tan, F. Sun, T. Kong, W. Zhang, C. Yang, and C. Liu, “A survey on deep
    transfer learning,” in *ICANN*, ser. Lecture Notes in Computer Science, vol. 11141.   Springer,
    2018, pp. 270–279.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] F. Zhuang, Z. Qi, K. Duan, D. Xi, Y. Zhu, H. Zhu, H. Xiong, and Q. He,
    “A comprehensive survey on transfer learning,” *Proc. IEEE*, vol. 109, no. 1,
    pp. 43–76, 2021.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] Y. Li, L. Guo, and Z. Zhou, “Towards safe weakly supervised learning,”
    *IEEE Trans. Pattern Anal. Mach. Intell.*, vol. 43, no. 1, pp. 334–346, 2021.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] K. Jaskie and A. Spanias, “Positive and unlabeled learning algorithms
    and applications: A survey,” in *IISA*.   IEEE, 2019, pp. 1–8.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] J. Bekker and J. Davis, “Learning from positive and unlabeled data: a
    survey,” *Mach. Learn.*, vol. 109, no. 4, pp. 719–760, 2020.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] T. M. Hospedales, A. Antoniou, P. Micaelli, and A. J. Storkey, “Meta-learning
    in neural networks: A survey,” *CoRR*, vol. abs/2004.05439, 2020.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] H. Peng, “A comprehensive overview and survey of recent advances in meta-learning,”
    *CoRR*, vol. abs/2004.11149, 2020.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] J. Vanschoren, “Meta-learning: A survey,” *CoRR*, vol. abs/1810.03548,
    2018.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] W. Yin, “Meta-learning for few-shot natural language processing: A survey,”
    *CoRR*, vol. abs/2007.09604, 2020.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] M. Huisman, J. N. van Rijn, and A. Plaat, “A survey of deep meta-learning,”
    *CoRR*, vol. abs/2010.03522, 2020.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] L. Jing and Y. Tian, “Self-supervised visual feature learning with deep
    neural networks: A survey,” *CoRR*, vol. abs/1902.06162, 2019.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] X. Liu, F. Zhang, Z. Hou, Z. Wang, L. Mian, J. Zhang, and J. Tang, “Self-supervised
    learning: Generative or contrastive,” *CoRR*, vol. abs/2006.08218, 2020.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] A. Jaiswal, A. R. Babu, M. Z. Zadeh, D. Banerjee, and F. Makedon, “A survey
    on contrastive self-supervised learning,” *CoRR*, vol. abs/2011.00362, 2020.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] J. Jeong, S. Lee, J. Kim, and N. Kwak, “Consistency-based semi-supervised
    learning for object detection,” in *NeurIPS*, 2019, pp. 10 758–10 767.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] N. Souly, C. Spampinato, and M. Shah, “Semi supervised semantic segmentation
    using generative adversarial network,” in *ICCV*.   IEEE Computer Society, 2017,
    pp. 5689–5697.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] Y. LeCun, “The mnist database of handwritten digits,” *http://yann. lecun.
    com/exdb/mnist/*, 1998.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng, “Reading
    digits in natural images with unsupervised feature learning,” in *NIPS Workshop
    on Deep Learning and Unsupervised Feature Learning 2011*, 2011.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] A. Coates, A. Y. Ng, and H. Lee, “An analysis of single-layer networks
    in unsupervised feature learning,” in *AISTATS*, ser. JMLR Proceedings, vol. 15.   JMLR.org,
    2011, pp. 215–223.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] A. Krizhevsky, “Learning multiple layers of features from tiny images,”
    in *https://www.cs.toronto.edu/ kriz/cifar.html/*, 2009.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
    with deep convolutional neural networks,” in *NIPS*, 2012, pp. 1106–1114.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] A. Rasmus, M. Berglund, M. Honkala, H. Valpola, and T. Raiko, “Semi-supervised
    learning with ladder networks,” in *NIPS*, 2015, pp. 3546–3554.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] M. Sajjadi, M. Javanmardi, and T. Tasdizen, “Regularization with stochastic
    transformations and perturbations for deep semi-supervised learning,” in *NIPS*,
    2016, pp. 1163–1171.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] S. Laine and T. Aila, “Temporal ensembling for semi-supervised learning,”
    in *ICLR*.   OpenReview.net, 2017.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] A. Tarvainen and H. Valpola, “Mean teachers are better role models: Weight-averaged
    consistency targets improve semi-supervised deep learning results,” in *NIPS*,
    2017, pp. 1195–1204.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] L. Zhang and G. Qi, “WCP: worst-case perturbations for semi-supervised
    deep learning,” in *CVPR*.   IEEE, 2020, pp. 3911–3920.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] V. Verma, A. Lamb, J. Kannala, Y. Bengio, and D. Lopez-Paz, “Interpolation
    consistency training for semi-supervised learning,” in *IJCAI*.   ijcai.org, 2019,
    pp. 3635–3641.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] D. Berthelot, N. Carlini, I. J. Goodfellow, N. Papernot, A. Oliver, and
    C. Raffel, “Mixmatch: A holistic approach to semi-supervised learning,” in *NeurIPS*,
    2019, pp. 5050–5060.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] D. Berthelot, N. Carlini, E. D. Cubuk, A. Kurakin, K. Sohn, H. Zhang,
    and C. Raffel, “Remixmatch: Semi-supervised learning with distribution matching
    and augmentation anchoring,” in *ICLR*.   OpenReview.net, 2020.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] J. Li, R. Socher, and S. C. H. Hoi, “Dividemix: Learning with noisy labels
    as semi-supervised learning,” in *ICLR*.   OpenReview.net, 2020.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] M. Everingham, L. V. Gool, C. K. I. Williams, J. M. Winn, and A. Zisserman,
    “The pascal visual object classes (VOC) challenge,” *Int. J. Comput. Vis.*, vol. 88,
    no. 2, pp. 303–338, 2010.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] T. Lin, M. Maire, S. J. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár,
    and C. L. Zitnick, “Microsoft COCO: common objects in context,” in *ECCV*, ser.
    Lecture Notes in Computer Science, vol. 8693.   Springer, 2014, pp. 740–755.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang,
    A. Karpathy, A. Khosla, M. S. Bernstein, A. C. Berg, and F. Li, “Imagenet large
    scale visual recognition challenge,” *Int. J. Comput. Vis.*, vol. 115, no. 3,
    pp. 211–252, 2015.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] Y. Tang, J. Wang, B. Gao, E. Dellandréa, R. J. Gaizauskas, and L. Chen,
    “Large scale semi-supervised object detection using visual and semantic knowledge
    transfer,” in *CVPR*.   IEEE Computer Society, 2016, pp. 2119–2128.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] J. Gao, J. Wang, S. Dai, L. Li, and R. Nevatia, “NOTE-RCNN: noise tolerant
    ensemble RCNN for semi-supervised object detection,” in *ICCV*.   IEEE, 2019,
    pp. 9507–9516.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] K. Sohn, Z. Zhang, C. Li, H. Zhang, C. Lee, and T. Pfister, “A simple
    semi-supervised learning framework for object detection,” *CoRR*, vol. abs/2005.04757,
    2020.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] S. Song, S. P. Lichtenberg, and J. Xiao, “SUN RGB-D: A RGB-D scene understanding
    benchmark suite,” in *CVPR*.   IEEE Computer Society, 2015, pp. 567–576.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] A. Dai, A. X. Chang, M. Savva, M. Halber, T. A. Funkhouser, and M. Nießner,
    “Scannet: Richly-annotated 3d reconstructions of indoor scenes,” in *CVPR*.   IEEE
    Computer Society, 2017, pp. 2432–2443.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] A. Geiger, P. Lenz, and R. Urtasun, “Are we ready for autonomous driving?
    the KITTI vision benchmark suite,” in *CVPR*.   IEEE Computer Society, 2012, pp.
    3354–3361.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] N. Zhao, T. Chua, and G. H. Lee, “SESS: self-ensembling semi-supervised
    3d object detection,” in *CVPR*.   IEEE, 2020, pp. 11 076–11 084.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] Y. S. Tang and G. H. Lee, “Transferable semi-supervised 3d object detection
    from RGB-D data,” in *ICCV*.   IEEE, 2019, pp. 1931–1940.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] J. Li, C. Xia, and X. Chen, “A benchmark dataset and saliency-guided stacked
    autoencoders for video-based salient object detection,” *IEEE Trans. Image Process.*,
    vol. 27, no. 1, pp. 349–364, 2018.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] F. Perazzi, J. Pont-Tuset, B. McWilliams, L. V. Gool, M. H. Gross, and
    A. Sorkine-Hornung, “A benchmark dataset and evaluation methodology for video
    object segmentation,” in *CVPR*.   IEEE Computer Society, 2016, pp. 724–732.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] T. Brox and J. Malik, “Object segmentation by long term analysis of point
    trajectories,” in *ECCV*, ser. Lecture Notes in Computer Science, vol. 6315.   Springer,
    2010, pp. 282–295.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] P. Yan, G. Li, Y. Xie, Z. Li, C. Wang, T. Chen, and L. Lin, “Semi-supervised
    video salient object detection using pseudo-labels,” in *ICCV*.   IEEE, 2019,
    pp. 7283–7292.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] R. Mottaghi, X. Chen, X. Liu, N. Cho, S. Lee, S. Fidler, R. Urtasun, and
    A. L. Yuille, “The role of context for object detection and semantic segmentation
    in the wild,” in *CVPR*.   IEEE Computer Society, 2014, pp. 891–898.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson,
    U. Franke, S. Roth, and B. Schiele, “The cityscapes dataset for semantic urban
    scene understanding,” in *CVPR*.   IEEE Computer Society, 2016, pp. 3213–3223.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] G. J. Brostow, J. Shotton, J. Fauqueur, and R. Cipolla, “Segmentation
    and recognition using structure from motion point clouds,” in *ECCV*, ser. Lecture
    Notes in Computer Science, vol. 5302.   Springer, 2008, pp. 44–57.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] C. Liu, J. Yuen, and A. Torralba, “SIFT flow: Dense correspondence across
    scenes and its applications,” *IEEE Trans. Pattern Anal. Mach. Intell.*, vol. 33,
    no. 5, pp. 978–994, 2011.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba, “SUN database:
    Large-scale scene recognition from abbey to zoo,” in *CVPR*.   IEEE Computer Society,
    2010, pp. 3485–3492.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] S. Gould, R. Fulton, and D. Koller, “Decomposing a scene into geometric
    and semantically consistent regions,” in *ICCV*.   IEEE Computer Society, 2009,
    pp. 1–8.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] J. Dai, K. He, and J. Sun, “Boxsup: Exploiting bounding boxes to supervise
    convolutional networks for semantic segmentation,” in *ICCV*.   IEEE Computer
    Society, 2015, pp. 1635–1643.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] S. Hong, H. Noh, and B. Han, “Decoupled deep neural network for semi-supervised
    semantic segmentation,” in *NIPS*, 2015, pp. 1495–1503.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] G. Papandreou, L. Chen, K. P. Murphy, and A. L. Yuille, “Weakly-and semi-supervised
    learning of a deep convolutional network for semantic image segmentation,” in
    *ICCV*.   IEEE Computer Society, 2015, pp. 1742–1750.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] Y. Wei, H. Xiao, H. Shi, Z. Jie, J. Feng, and T. S. Huang, “Revisiting
    dilated convolution: A simple approach for weakly- and semi-supervised semantic
    segmentation,” in *CVPR*.   IEEE Computer Society, 2018, pp. 7268–7277.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] J. Lee, E. Kim, S. Lee, J. Lee, and S. Yoon, “Ficklenet: Weakly and semi-supervised
    semantic image segmentation using stochastic inference,” in *CVPR*.   Computer
    Vision Foundation / IEEE, 2019, pp. 5267–5276.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] S. Mittal, M. Tatarchenko, and T. Brox, “Semi-supervised semantic segmentation
    with high- and low-level consistency,” *CoRR*, vol. abs/1908.05724, 2019.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] T. Kalluri, G. Varma, M. Chandraker, and C. V. Jawahar, “Universal semi-supervised
    semantic segmentation,” in *ICCV*.   IEEE, 2019, pp. 5258–5269.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] M. S. Ibrahim, A. Vahdat, M. Ranjbar, and W. G. Macready, “Semi-supervised
    semantic image segmentation with self-correcting networks,” in *CVPR*.   IEEE,
    2020, pp. 12 712–12 722.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] Y. Ouali, C. Hudelot, and M. Tami, “Semi-supervised semantic segmentation
    with cross-consistency training,” in *CVPR*.   IEEE, 2020, pp. 12 671–12 681.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] X. Zhang, J. J. Zhao, and Y. LeCun, “Character-level convolutional networks
    for text classification,” in *NIPS*, 2015, pp. 649–657.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] P. N. Mendes, M. Jakob, and C. Bizer, “Dbpedia for nlp: A multilingual
    cross-domain knowledge base,” in *Proceedings of the Eight International Conference
    on Language Resources and Evaluation (LREC’12)*, Istanbul, Turkey, May 2012.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] M. Chang, L. Ratinov, D. Roth, and V. Srikumar, “Importance of semantic
    representation: Dataless classification,” in *AAAI*.   AAAI Press, 2008, pp. 830–835.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] A. L. Maas, R. E. Daly, P. T. Pham, D. Huang, A. Y. Ng, and C. Potts,
    “Learning word vectors for sentiment analysis,” in *ACL*.   The Association for
    Computer Linguistics, 2011, pp. 142–150.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] X. H. Phan, M. L. Nguyen, and S. Horiguchi, “Learning to classify short
    and sparse text & web with hidden topics from large-scale data collections,” in
    *WWW*.   ACM, 2008, pp. 91–100.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] L. Yao, C. Mao, and Y. Luo, “Graph convolutional networks for text classification,”
    in *AAAI*.   AAAI Press, 2019, pp. 7370–7377.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] D. Vitale, P. Ferragina, and U. Scaiella, “Classification of short texts
    by deploying topical annotations,” in *ECIR*, ser. Lecture Notes in Computer Science,
    vol. 7224.   Springer, 2012, pp. 376–387.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] B. Pang and L. Lee, “Seeing stars: Exploiting class relationships for
    sentiment categorization with respect to rating scales,” in *ACL*.   The Association
    for Computer Linguistics, 2005, pp. 115–124.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] R. Johnson and T. Zhang, “Semi-supervised convolutional neural networks
    for text categorization via region embedding,” in *NIPS*, 2015, pp. 919–927.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] D. D. Lewis, Y. Yang, T. G. Rose, and F. Li, “RCV1: A new benchmark collection
    for text categorization research,” *J. Mach. Learn. Res.*, vol. 5, pp. 361–397,
    2004.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] W. Xu, H. Sun, C. Deng, and Y. Tan, “Variational autoencoder for semi-supervised
    text classification,” in *AAAI*.   AAAI Press, 2017, pp. 3358–3364.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] T. Miyato, A. M. Dai, and I. J. Goodfellow, “Adversarial training methods
    for semi-supervised text classification,” in *ICLR*.   OpenReview.net, 2017.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[116] D. S. Sachan, M. Zaheer, and R. Salakhutdinov, “Revisiting LSTM networks
    for semi-supervised text classification via mixed objective function,” in *AAAI*.   AAAI
    Press, 2019, pp. 6940–6948.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[117] L. Hu, T. Yang, C. Shi, H. Ji, and X. Li, “Heterogeneous graph attention
    networks for semi-supervised short text classification,” in *EMNLP/IJCNLP*.   Association
    for Computational Linguistics, 2019, pp. 4820–4829.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[118] H. Jo and C. Cinarel, “Delta-training: Simple semi-supervised text classification
    using pretrained word embeddings,” in *EMNLP/IJCNLP*.   Association for Computational
    Linguistics, 2019, pp. 3456–3461.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[119] J. Chen, Z. Yang, and D. Yang, “Mixtext: Linguistically-informed interpolation
    of hidden space for semi-supervised text classification,” in *ACL*.   Association
    for Computational Linguistics, 2020, pp. 2147–2157.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[120] P. Budzianowski, T. Wen, B. Tseng, I. Casanueva, S. Ultes, O. Ramadan,
    and M. Gasic, “Multiwoz - A large-scale multi-domain wizard-of-oz dataset for
    task-oriented dialogue modelling,” in *EMNLP*.   Association for Computational
    Linguistics, 2018, pp. 5016–5026.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[121] X. Huang, J. Qi, Y. Sun, and R. Zhang, “Semi-supervised dialogue policy
    learning via stochastic reward estimation,” in *ACL*.   Association for Computational
    Linguistics, 2020, pp. 660–670.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[122] C. Danescu-Niculescu-Mizil and L. Lee, “Chameleons in imagined conversations:
    A new approach to understanding coordination of linguistic style in dialogs,”
    in *CMCL@ACL*.   Association for Computational Linguistics, 2011, pp. 76–87.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[123] R. Lowe, N. Pow, I. Serban, and J. Pineau, “The ubuntu dialogue corpus:
    A large dataset for research in unstructured multi-turn dialogue systems,” in
    *SIGDIAL Conference*.   The Association for Computer Linguistics, 2015, pp. 285–294.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[124] J. Chang, R. He, L. Wang, X. Zhao, T. Yang, and R. Wang, “A semi-supervised
    stable variational network for promoting replier-consistency in dialogue generation,”
    in *EMNLP/IJCNLP*.   Association for Computational Linguistics, 2019, pp. 1920–1930.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[125] K. Lang, “Newsweeder: Learning to filter netnews,” in *ICML*.   Morgan
    Kaufmann, 1995, pp. 331–339.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[126] E. F. T. K. Sang and F. D. Meulder, “Introduction to the conll-2003 shared
    task: Language-independent named entity recognition,” in *CoNLL*.   ACL, 2003,
    pp. 142–147.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[127] E. F. T. K. Sang and S. Buchholz, “Introduction to the conll-2000 shared
    task chunking,” in *CoNLL/LLL*.   ACL, 2000, pp. 127–132.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[128] K. Gimpel, N. Schneider, B. O’Connor, D. Das, D. Mills, J. Eisenstein,
    M. Heilman, D. Yogatama, J. Flanigan, and N. A. Smith, “Part-of-speech tagging
    for twitter: Annotation, features, and experiments,” in *ACL*.   The Association
    for Computer Linguistics, 2011, pp. 42–47.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[129] O. Owoputi, B. O’Connor, C. Dyer, K. Gimpel, N. Schneider, and N. A.
    Smith, “Improved part-of-speech tagging for online conversational text with word
    clusters,” in *HLT-NAACL*.   The Association for Computational Linguistics, 2013,
    pp. 380–390.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[130] R. T. McDonald, J. Nivre, Y. Quirmbach-Brundage, Y. Goldberg, D. Das,
    K. Ganchev, K. B. Hall, S. Petrov, H. Zhang, O. Täckström, C. Bedini, N. B. Castelló,
    and J. Lee, “Universal dependency annotation for multilingual parsing,” in *ACL*.   The
    Association for Computer Linguistics, 2013, pp. 92–97.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[131] J. Hockenmaier and M. Steedman, “Ccgbank: A corpus of CCG derivations
    and dependency structures extracted from the penn treebank,” *Comput. Linguistics*,
    vol. 33, no. 3, pp. 355–396, 2007.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[132] A. M. Dai and Q. V. Le, “Semi-supervised sequence learning,” in *NIPS*,
    2015, pp. 3079–3087.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[133] M. E. Peters, W. Ammar, C. Bhagavatula, and R. Power, “Semi-supervised
    sequence tagging with bidirectional language models,” in *ACL*.   Association
    for Computational Linguistics, 2017, pp. 1756–1765.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[134] M. Rei, “Semi-supervised multitask learning for sequence labeling,” in
    *ACL*.   Association for Computational Linguistics, 2017, pp. 2121–2130.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[135] K. Clark, M. Luong, C. D. Manning, and Q. V. Le, “Semi-supervised sequence
    modeling with cross-view training,” in *EMNLP*.   Association for Computational
    Linguistics, 2018, pp. 1914–1925.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[136] J. Hajic, M. Ciaramita, R. Johansson, D. Kawahara, M. A. Martí, L. Màrquez,
    A. Meyers, J. Nivre, S. Padó, J. Stepánek, P. Stranák, M. Surdeanu, N. Xue, and
    Y. Zhang, “The conll-2009 shared task: Syntactic and semantic dependencies in
    multiple languages,” in *CoNLL Shared Task*.   ACL, 2009, pp. 1–18.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[137] S. Pradhan, A. Moschitti, N. Xue, H. T. Ng, A. Björkelund, O. Uryupina,
    Y. Zhang, and Z. Zhong, “Towards robust linguistic analysis using ontonotes,”
    in *CoNLL*.   ACL, 2013, pp. 143–152.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[138] M. G. Carneiro, T. H. Cupertino, L. Zhao, and J. L. G. Rosa, “Semi-supervised
    semantic role labeling for brazilian portuguese,” *J. Inf. Data Manag.*, vol. 8,
    no. 2, pp. 117–130, 2017.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[139] S. V. Mehta, J. Y. Lee, and J. G. Carbonell, “Towards semi-supervised
    learning for deep semantic role labeling,” in *EMNLP*.   Association for Computational
    Linguistics, 2018, pp. 4958–4963.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[140] R. Cai and M. Lapata, “Semi-supervised semantic role labeling with cross-view
    training,” in *EMNLP/IJCNLP*.   Association for Computational Linguistics, 2019,
    pp. 1018–1027.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[141] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang, “Squad: 100, 000+ questions
    for machine comprehension of text,” in *EMNLP*.   The Association for Computational
    Linguistics, 2016, pp. 2383–2392.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[142] M. Joshi, E. Choi, D. S. Weld, and L. Zettlemoyer, “Triviaqa: A large
    scale distantly supervised challenge dataset for reading comprehension,” in *ACL*.   Association
    for Computational Linguistics, 2017, pp. 1601–1611.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[143] J. Oh, K. Torisawa, C. Hashimoto, R. Iida, M. Tanaka, and J. Kloetzer,
    “A semi-supervised learning approach to why-question answering,” in *AAAI*.   AAAI
    Press, 2016, pp. 3022–3029.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[144] B. Dhingra, D. Pruthi, and D. Rajagopal, “Simple and effective semi-supervised
    question answering,” in *NAACL-HLT*.   Association for Computational Linguistics,
    2018, pp. 582–587.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[145] S. Zhang and M. Bansal, “Addressing semantic drift in question generation
    for semi-supervised question answering,” in *EMNLP/IJCNLP*.   Association for
    Computational Linguistics, 2019, pp. 2495–2509.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[146] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
    S. Ozair, A. C. Courville, and Y. Bengio, “Generative adversarial nets,” in *NIPS*,
    2014, pp. 2672–2680.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[147] L. Schoneveld, “Semi-supervised learning with generative adversarial
    networks,” in *Doctoral dissertation, Ph.D. Dissertation*, 2017.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[148] A. Radford, L. Metz, and S. Chintala, “Unsupervised representation learning
    with deep convolutional generative adversarial networks,” in *ICLR*, 2016.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[149] J. T. Springenberg, “Unsupervised and semi-supervised learning with categorical
    generative adversarial networks,” in *ICLR*, 2016.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[150] E. L. Denton, S. Gross, and R. Fergus, “Semi-supervised learning with
    context-conditional generative adversarial networks,” *CoRR*, vol. abs/1611.06430,
    2016.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[151] A. Odena, “Semi-supervised learning with generative adversarial networks,”
    *CoRR*, vol. abs/1606.01583, 2016.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[152] T. Salimans, I. J. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and
    X. Chen, “Improved techniques for training gans,” in *NIPS*, 2016, pp. 2226–2234.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[153] Z. Dai, Z. Yang, F. Yang, W. W. Cohen, and R. Salakhutdinov, “Good semi-supervised
    learning that requires a bad GAN,” in *NIPS*, 2017, pp. 6510–6520.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[154] G. Qi, L. Zhang, H. Hu, M. Edraki, J. Wang, and X. Hua, “Global versus
    localized generative adversarial nets,” in *CVPR*.   IEEE Computer Society, 2018,
    pp. 1517–1525.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[155] X. Wei, B. Gong, Z. Liu, W. Lu, and L. Wang, “Improving the improved
    training of wasserstein gans: A consistency term and its dual effect,” in *ICLR*.   OpenReview.net,
    2018.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[156] M. Arjovsky, S. Chintala, and L. Bottou, “Wasserstein GAN,” *CoRR*, vol.
    abs/1701.07875, 2017.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[157] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville,
    “Improved training of wasserstein gans,” in *NIPS*, 2017, pp. 5767–5777.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[158] J. Donahue, P. Krähenbühl, and T. Darrell, “Adversarial feature learning,”
    in *ICLR*.   OpenReview.net, 2017.'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[159] V. Dumoulin, I. Belghazi, B. Poole, A. Lamb, M. Arjovsky, O. Mastropietro,
    and A. C. Courville, “Adversarially learned inference,” in *ICLR*.   OpenReview.net,
    2017.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[160] A. Kumar, P. Sattigeri, and T. Fletcher, “Semi-supervised learning with
    gans: Manifold invariance with improved inference,” in *NIPS*, 2017, pp. 5534–5544.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[161] C. Li, T. Xu, J. Zhu, and B. Zhang, “Triple generative adversarial nets,”
    in *NIPS*, 2017, pp. 4088–4098.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[162] Z. Gan, L. Chen, W. Wang, Y. Pu, Y. Zhang, H. Liu, C. Li, and L. Carin,
    “Triangle generative adversarial networks,” in *NIPS*, 2017, pp. 5247–5256.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[163] S. Wu, G. Deng, J. Li, R. Li, Z. Yu, and H. Wong, “Enhancing triplegan
    for semi-supervised conditional instance synthesis and classification,” in *CVPR*.   Computer
    Vision Foundation / IEEE, 2019, pp. 10 091–10 100.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[164] J. Dong and T. Lin, “Margingan: Adversarial training in semi-supervised
    learning,” in *NeurIPS*, 2019, pp. 10 440–10 449.'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[165] Z. Deng, H. Zhang, X. Liang, L. Yang, S. Xu, J. Zhu, and E. P. Xing,
    “Structured generative adversarial networks,” in *NIPS*, 2017, pp. 3899–3909.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[166] Y. Liu, G. Deng, X. Zeng, S. Wu, Z. Yu, and H.-S. Wong, “Regularizing
    discriminative capability of cgans for semi-supervised generative learning,” in
    *CVPR*, 2020.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[167] S. Yun, D. Han, S. Chun, S. J. Oh, Y. Yoo, and J. Choe, “Cutmix: Regularization
    strategy to train strong classifiers with localizable features,” in *ICCV*.   IEEE,
    2019, pp. 6022–6031.'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[168] D. P. Kingma and M. Welling, “Auto-encoding variational bayes,” in *ICLR*,
    2014.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[169] D. J. Rezende, S. Mohamed, and D. Wierstra, “Stochastic backpropagation
    and approximate inference in deep generative models,” in *ICML*, ser. JMLR Workshop
    and Conference Proceedings, vol. 32.   JMLR.org, 2014, pp. 1278–1286.'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[170] D. P. Kingma, S. Mohamed, D. J. Rezende, and M. Welling, “Semi-supervised
    learning with deep generative models,” in *NIPS*, 2014, pp. 3581–3589.'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[171] L. Maaløe, C. K. Sønderby, S. K. Sønderby, and O. Winther, “Auxiliary
    deep generative models,” in *ICML*, ser. JMLR Workshop and Conference Proceedings,
    vol. 48.   JMLR.org, 2016, pp. 1445–1453.'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[172] M. E. Abbasnejad, A. R. Dick, and A. van den Hengel, “Infinite variational
    autoencoder for semi-supervised learning,” in *CVPR*.   IEEE Computer Society,
    2017, pp. 781–790.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[173] S. Narayanaswamy, B. Paige, J. van de Meent, A. Desmaison, N. D. Goodman,
    P. Kohli, F. D. Wood, and P. H. S. Torr, “Learning disentangled representations
    with semi-supervised deep generative models,” in *NIPS*, 2017, pp. 5925–5935.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[174] J. Schulman, N. Heess, T. Weber, and P. Abbeel, “Gradient estimation
    using stochastic computation graphs,” in *NIPS*, 2015, pp. 3528–3536.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[175] Y. Li, Q. Pan, S. Wang, H. Peng, T. Yang, and E. Cambria, “Disentangled
    variational auto-encoder for semi-supervised learning,” *Inf. Sci.*, vol. 482,
    pp. 73–85, 2019.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[176] T. Joy, S. M. Schmon, P. H. S. Torr, N. Siddharth, and T. Rainforth,
    “Rethinking semi-supervised learning in vaes,” *CoRR*, vol. abs/2006.10102, 2020.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[177] M. Belkin and P. Niyogi, “Laplacian eigenmaps and spectral techniques
    for embedding and clustering,” in *NIPS*.   MIT Press, 2001, pp. 585–591.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[178] Z. Ke, D. Wang, Q. Yan, J. S. J. Ren, and R. W. H. Lau, “Dual student:
    Breaking the limits of the teacher in semi-supervised learning,” in *ICCV*.   IEEE,
    2019, pp. 6727–6735.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[179] M. Pezeshki, L. Fan, P. Brakel, A. C. Courville, and Y. Bengio, “Deconstructing
    the ladder network architecture,” in *ICML*, ser. JMLR Workshop and Conference
    Proceedings, vol. 48.   JMLR.org, 2016, pp. 2368–2376.'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[180] T. Miyato, S. Maeda, M. Koyama, and S. Ishii, “Virtual adversarial training:
    A regularization method for supervised and semi-supervised learning,” *IEEE Trans.
    Pattern Anal. Mach. Intell.*, vol. 41, no. 8, pp. 1979–1993, 2019.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[181] P. Izmailov, D. Podoprikhin, T. Garipov, D. P. Vetrov, and A. G. Wilson,
    “Averaging weights leads to wider optima and better generalization,” in *UAI*.   AUAI
    Press, 2018, pp. 876–885.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[182] B. Athiwaratkun, M. Finzi, P. Izmailov, and A. G. Wilson, “There are
    many consistent explanations of unlabeled data: Why you should average,” in *ICLR*.   OpenReview.net,
    2019.'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[183] S. Park, J. Park, S. Shin, and I. Moon, “Adversarial dropout for supervised
    and semi-supervised learning,” in *AAAI*.   AAAI Press, 2018, pp. 3917–3924.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[184] Q. Xie, Z. Dai, E. H. Hovy, T. Luong, and Q. Le, “Unsupervised data augmentation
    for consistency training,” in *NeurIPS*, 2020.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[185] E. D. Cubuk, B. Zoph, D. Mane, V. Vasudevan, and Q. V. Le, “Autoaugment:
    Learning augmentation strategies from data,” in *CVPR*.   Computer Vision Foundation
    / IEEE, 2019, pp. 113–123.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[186] E. D. Cubuk, B. Zoph, J. Shlens, and Q. V. Le, “Randaugment: Practical
    data augmentation with no separate search,” *CoRR*, vol. abs/1909.13719, 2019.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[187] R. Sennrich, B. Haddow, and A. Birch, “Improving neural machine translation
    models with monolingual data,” in *ACL*.   The Association for Computer Linguistics,
    2016.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[188] S. Edunov, M. Ott, M. Auli, and D. Grangier, “Understanding back-translation
    at scale,” in *EMNLP*.   Association for Computational Linguistics, 2018, pp.
    489–500.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[189] A. Iscen, G. Tolias, Y. Avrithis, and O. Chum, “Label propagation for
    deep semi-supervised learning,” in *CVPR*.   Computer Vision Foundation / IEEE,
    2019, pp. 5070–5079.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[190] P. Chen, T. Ma, X. Qin, W. Xu, and S. Zhou, “Data-efficient semi-supervised
    learning by reliable edge mining,” in *CVPR*.   IEEE, 2020, pp. 9189–9198.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[191] S. Li, B. Liu, D. Chen, Q. Chu, L. Yuan, and N. Yu, “Density-aware graph
    for deep semi-supervised visual recognition,” in *CVPR*.   IEEE, 2020, pp. 13 397–13 406.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[192] B. Perozzi, R. Al-Rfou, and S. Skiena, “Deepwalk: online learning of
    social representations,” in *KDD*.   ACM, 2014, pp. 701–710.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[193] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei, “LINE: large-scale
    information network embedding,” in *WWW*.   ACM, 2015, pp. 1067–1077.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[194] A. Grover and J. Leskovec, “node2vec: Scalable feature learning for networks,”
    in *KDD*.   ACM, 2016, pp. 855–864.'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[195] D. Wang, P. Cui, and W. Zhu, “Structural deep network embedding,” in
    *KDD*.   ACM, 2016, pp. 1225–1234.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[196] M. Belkin and P. Niyogi, “Laplacian eigenmaps and spectral techniques
    for embedding and clustering,” in *NIPS*.   MIT Press, 2001, pp. 585–591.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[197] S. Cao, W. Lu, and Q. Xu, “Deep neural networks for learning graph representations,”
    in *AAAI*.   AAAI Press, 2016, pp. 1145–1152.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[198] M. Ou, P. Cui, J. Pei, Z. Zhang, and W. Zhu, “Asymmetric transitivity
    preserving graph embedding,” in *KDD*.   ACM, 2016, pp. 1105–1114.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[199] T. N. Kipf and M. Welling, “Variational graph auto-encoders,” *CoRR*,
    vol. abs/1611.07308, 2016.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[200] ——, “Semi-supervised classification with graph convolutional networks,”
    in *ICLR*.   OpenReview.net, 2017.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[201] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl,
    “Neural message passing for quantum chemistry,” in *ICML*, ser. Proceedings of
    Machine Learning Research, vol. 70.   PMLR, 2017, pp. 1263–1272.'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[202] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini,
    “The graph neural network model,” *IEEE Trans. Neural Networks*, vol. 20, no. 1,
    pp. 61–80, 2009.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[203] H. Wang, C. Zhou, X. Chen, J. Wu, S. Pan, and J. Wang, “Graph stochastic
    neural networks for semi-supervised learning,” in *NeurIPS*, 2020.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[204] W. Feng, J. Zhang, Y. Dong, Y. Han, H. Luan, Q. Xu, Q. Yang, E. Kharlamov,
    and J. Tang, “Graph random neural networks for semi-supervised learning on graphs,”
    in *NeurIPS*, 2020.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[205] Q. Li, Z. Han, and X. Wu, “Deeper insights into graph convolutional networks
    for semi-supervised learning,” in *AAAI*.   AAAI Press, 2018, pp. 3538–3545.'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[206] R. Liao, M. Brockschmidt, D. Tarlow, A. L. Gaunt, R. Urtasun, and R. S.
    Zemel, “Graph partition neural networks for semi-supervised classification,” in
    *ICLR*.   OpenReview.net, 2018.'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[207] Y. Zhang, S. Pal, M. Coates, and D. Üstebay, “Bayesian graph convolutional
    neural networks for semi-supervised classification,” in *AAAI*.   AAAI Press,
    2019, pp. 5829–5836.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[208] S. Vashishth, P. Yadav, M. Bhandari, and P. P. Talukdar, “Confidence-based
    graph convolutional networks for semi-supervised learning,” in *AISTATS*, ser.
    Proceedings of Machine Learning Research, vol. 89.   PMLR, 2019, pp. 1792–1801.'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[209] C. Zhuang and Q. Ma, “Dual graph convolutional networks for graph-based
    semi-supervised classification,” in *WWW*.   ACM, 2018, pp. 499–508.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[210] F. Hu, Y. Zhu, S. Wu, L. Wang, and T. Tan, “Hierarchical graph convolutional
    networks for semi-supervised node classification,” in *IJCAI*.   ijcai.org, 2019,
    pp. 4532–4539.'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[211] D. Bahdanau, K. Cho, and Y. Bengio, “Neural machine translation by jointly
    learning to align and translate,” in *ICLR*, 2015.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[212] W. L. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation learning
    on large graphs,” in *NIPS*, 2017, pp. 1024–1034.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[213] Y. Li, D. Tarlow, M. Brockschmidt, and R. S. Zemel, “Gated graph sequence
    neural networks,” in *ICLR*, 2016.'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[214] J. Chung, Ç. Gülçehre, K. Cho, and Y. Bengio, “Empirical evaluation of
    gated recurrent neural networks on sequence modeling,” *CoRR*, vol. abs/1412.3555,
    2014.'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[215] D. Selsam, M. Lamm, B. Bünz, P. Liang, L. de Moura, and D. L. Dill, “Learning
    a SAT solver from single-bit supervision,” in *ICLR*.   OpenReview.net, 2019.'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[216] Z. Zhou and M. Li, “Semi-supervised learning by disagreement,” *Knowl.
    Inf. Syst.*, vol. 24, no. 3, pp. 415–439, 2010.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[217] S. Qiao, W. Shen, Z. Zhang, B. Wang, and A. L. Yuille, “Deep co-training
    for semi-supervised image recognition,” in *ECCV*, ser. Lecture Notes in Computer
    Science, vol. 11219.   Springer, 2018, pp. 142–159.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[218] Y. Cheng, X. Zhao, R. Cai, Z. Li, K. Huang, and Y. Rui, “Semi-supervised
    multimodal deep learning for RGB-D object recognition,” in *IJCAI*.   IJCAI/AAAI
    Press, 2016, pp. 3345–3351.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[219] R. Xia, C. Wang, X. Dai, and T. Li, “Co-training for semi-supervised
    sentiment classification based on dual-view bags-of-words representation,” in
    *ACL*.   The Association for Computer Linguistics, 2015, pp. 1054–1063.'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[220] D. Chen, W. Wang, W. Gao, and Z. Zhou, “Tri-net for semi-supervised deep
    learning,” in *IJCAI*.   ijcai.org, 2018, pp. 2014–2020.'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[221] Z. Zhou and M. Li, “Tri-training: Exploiting unlabeled data using three
    classifiers,” *IEEE Trans. Knowl. Data Eng.*, vol. 17, no. 11, pp. 1529–1541,
    2005.'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[222] L. Breiman, “Randomizing outputs to increase prediction accuracy,” *Mach.
    Learn.*, vol. 40, no. 3, pp. 229–242, 2000.'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[223] Y. Grandvalet and Y. Bengio, “Semi-supervised learning by entropy minimization,”
    in *NIPS*, 2004, pp. 529–536.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[224] D.-H. Lee, “Pseudo-label: The simple and efficient semi-supervised learning
    method for deep neural networks,” in *Workshop on challenges in representation
    learning, ICML*, vol. 3, no. 2, 2013.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[225] Q. Xie, M. Luong, E. H. Hovy, and Q. V. Le, “Self-training with noisy
    student improves imagenet classification,” in *CVPR*.   IEEE, 2020, pp. 10 684–10 695.'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[226] G. E. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a
    neural network,” *CoRR*, vol. abs/1503.02531, 2015.'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[227] M. Tan and Q. V. Le, “Efficientnet: Rethinking model scaling for convolutional
    neural networks,” in *ICML*, ser. Proceedings of Machine Learning Research, vol. 97.   PMLR,
    2019, pp. 6105–6114.'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[228] E. D. Cubuk, B. Zoph, J. Shlens, and Q. V. Le, “Randaugment: Practical
    automated data augmentation with a reduced search space,” in *CVPR Workshops*.   IEEE,
    2020, pp. 3008–3017.'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[229] L. Beyer, X. Zhai, A. Oliver, and A. Kolesnikov, “S4L: self-supervised
    semi-supervised learning,” in *ICCV*.   IEEE, 2019, pp. 1476–1485.'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[230] A. Kolesnikov, X. Zhai, and L. Beyer, “Revisiting self-supervised visual
    representation learning,” in *CVPR*.   Computer Vision Foundation / IEEE, 2019,
    pp. 1920–1929.'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[231] S. Gidaris, P. Singh, and N. Komodakis, “Unsupervised representation
    learning by predicting image rotations,” in *ICLR*.   OpenReview.net, 2018.'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[232] A. Dosovitskiy, J. T. Springenberg, M. A. Riedmiller, and T. Brox, “Discriminative
    unsupervised feature learning with convolutional neural networks,” in *NIPS*,
    2014, pp. 766–774.'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[233] A. Dosovitskiy, P. Fischer, J. T. Springenberg, M. A. Riedmiller, and
    T. Brox, “Discriminative unsupervised feature learning with exemplar convolutional
    neural networks,” *IEEE Trans. Pattern Anal. Mach. Intell.*, vol. 38, no. 9, pp.
    1734–1747, 2016.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[234] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. E. Reed, D. Anguelov, D. Erhan,
    V. Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,” in *CVPR*.   IEEE
    Computer Society, 2015, pp. 1–9.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[235] A. Hermans, L. Beyer, and B. Leibe, “In defense of the triplet loss for
    person re-identification,” *CoRR*, vol. abs/1703.07737, 2017.'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[236] H. Pham, Q. Xie, Z. Dai, and Q. V. Le, “Meta pseudo labels,” *CoRR*,
    vol. abs/2003.10580, 2020.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[237] X. Wang, D. Kihara, J. Luo, and G. Qi, “Enaet: A self-trained framework
    for semi-supervised and supervised learning with ensemble transformations,” *IEEE
    Trans. Image Process.*, vol. 30, pp. 1639–1647, 2021.'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[238] L. Zhang, G. Qi, L. Wang, and J. Luo, “AET vs. AED: unsupervised representation
    learning by auto-encoding transformations rather than data,” in *CVPR*.   Computer
    Vision Foundation / IEEE, 2019.'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[239] T. Chen, S. Kornblith, K. Swersky, M. Norouzi, and G. E. Hinton, “Big
    self-supervised models are strong semi-supervised learners,” in *NeurIPS*, 2020.'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[240] T. Chen, S. Kornblith, M. Norouzi, and G. E. Hinton, “A simple framework
    for contrastive learning of visual representations,” in *ICML*, ser. Proceedings
    of Machine Learning Research, vol. 119.   PMLR, 2020, pp. 1597–1607.'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[241] H. Zhang, M. Cissé, Y. N. Dauphin, and D. Lopez-Paz, “mixup: Beyond empirical
    risk minimization,” in *ICLR*.   OpenReview.net, 2018.'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[242] K. Sohn, D. Berthelot, N. Carlini, Z. Zhang, H. Zhang, C. Raffel, E. D.
    Cubuk, A. Kurakin, and C. Li, “Fixmatch: Simplifying semi-supervised learning
    with consistency and confidence,” in *NeurIPS*, 2020.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[243] T. Devries and G. W. Taylor, “Improved regularization of convolutional
    neural networks with cutout,” *CoRR*, vol. abs/1708.04552, 2017.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[244] Z. Ren, R. A. Yeh, and A. G. Schwing, “Not all unlabeled data are equal:
    Learning to weight data in semi-supervised learning,” in *NeurIPS*, 2020.'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[245] B. Zoph, G. Ghiasi, T. Lin, Y. Cui, H. Liu, E. D. Cubuk, and Q. Le, “Rethinking
    pre-training and self-training,” in *NeurIPS*, 2020.'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[246] A. Ghosh and A. H. Thiery, “On data-augmentation and consistency-based
    semi-supervised learning,” in *ICLR*.   OpenReview.net, 2021.'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[247] Z. Hu, X. Ma, Z. Liu, E. H. Hovy, and E. P. Xing, “Harnessing deep neural
    networks with logic rules,” in *ACL*.   The Association for Computer Linguistics,
    2016.'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[248] Y. Tang, J. Wang, X. Wang, B. Gao, E. Dellandréa, R. J. Gaizauskas, and
    L. Chen, “Visual and semantic knowledge transfer for large scale semi-supervised
    object detection,” *IEEE Trans. Pattern Anal. Mach. Intell.*, vol. 40, no. 12,
    pp. 3045–3058, 2018.'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[249] M. Qi, Y. Wang, J. Qin, and A. Li, “KE-GAN: knowledge embedded generative
    adversarial networks for semi-supervised scene parsing,” in *CVPR*.   Computer
    Vision Foundation / IEEE, 2019, pp. 5237–5246.'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[250] S. Yu, X. Yang, and W. Zhang, “PKGCN: prior knowledge enhanced graph
    convolutional network for graph-based semi-supervised learning,” *Int. J. Machine
    Learning & Cybernetics*, vol. 10, no. 11, pp. 3115–3127, 2019.'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[251] P. Swarup, D. Chakrabarty, A. Sapru, H. Tulsiani, H. Arsikere, and S. Garimella,
    “Knowledge distillation and data selection for semi-supervised learning in CTC
    acoustic models,” *CoRR*, vol. abs/2008.03923, 2020.'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[252] S. E. Reed, H. Lee, D. Anguelov, C. Szegedy, D. Erhan, and A. Rabinovich,
    “Training deep neural networks on noisy labels with bootstrapping,” in *ICLR*,
    2015.'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[253] Z. Lu and L. Wang, “Noise-robust semi-supervised learning via fast sparse
    coding,” *Pattern Recognit.*, vol. 48, no. 2, pp. 605–612, 2015.'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[254] B. Han, Q. Yao, X. Yu, G. Niu, M. Xu, W. Hu, I. W. Tsang, and M. Sugiyama,
    “Co-teaching: Robust training of deep neural networks with extremely noisy labels,”
    in *NeurIPS*, 2018, pp. 8536–8546.'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[255] J. M. Johnson and T. M. Khoshgoftaar, “Survey on deep learning with class
    imbalance,” *J. Big Data*, vol. 6, p. 27, 2019.'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[256] J. Kim, Y. Hur, S. Park, E. Yang, S. J. Hwang, and J. Shin, “Distribution
    aligning refinery of pseudo-label for imbalanced semi-supervised learning,” in
    *NeurIPS*, 2020.'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[257] J. Deng and J. Yu, “A simple graph-based semi-supervised learning approach
    for imbalanced classification,” *Pattern Recognit.*, vol. 118, p. 108026, 2021.'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[258] Z. Zhong, L. Zheng, G. Kang, S. Li, and Y. Yang, “Random erasing data
    augmentation,” in *AAAI*.   AAAI Press, 2020, pp. 13 001–13 008.'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[259] K. K. Singh, H. Yu, A. Sarmasi, G. Pradeep, and Y. J. Lee, “Hide-and-seek:
    A data augmentation technique for weakly-supervised localization and beyond,”
    *CoRR*, vol. abs/1811.02545, 2018.'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[260] P. Chen, S. Liu, H. Zhao, and J. Jia, “Gridmask data augmentation,” *CoRR*,
    vol. abs/2001.04086, 2020.'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[261] A. Singh, R. D. Nowak, and X. Zhu, “Unlabeled data: Now it helps, now
    it doesn’t,” in *NIPS*.   Curran Associates, Inc., 2008, pp. 1513–1520.'
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[262] T. Yang and C. E. Priebe, “The effect of model misspecification on semi-supervised
    classification,” *IEEE Trans. Pattern Anal. Mach. Intell.*, vol. 33, no. 10, pp.
    2093–2103, 2011.'
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[263] N. V. Chawla and G. I. Karakoulas, “Learning from labeled and unlabeled
    data: An empirical study across techniques and domains,” *J. Artif. Intell. Res.*,
    vol. 23, pp. 331–366, 2005.'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
