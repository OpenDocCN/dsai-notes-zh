- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:42:31'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2301.01354] Cosmological constraints from HSC survey first-year data using
    deep learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2301.01354](https://ar5iv.labs.arxiv.org/html/2301.01354)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Cosmological constraints from HSC survey first-year data using deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Tianhuan Lu](https://orcid.org/0000-0003-1040-2639) Department of Astronomy,
    Columbia University, New York, NY 10027, USA [Zoltán Haiman](https://orcid.org/0000-0003-3633-5403)
    Department of Astronomy, Columbia University, New York, NY 10027, USA Department
    of Physics, Columbia University, New York, NY 10027, USA [Xiangchong Li](https://orcid.org/0000-0003-2880-5102)
    Department of Physics, McWilliams Center for Cosmology, Carnegie Mellon University,
    Pittsburgh, PA 15213, USA'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We present cosmological constraints from the Subaru Hyper Suprime-Cam (HSC)
    first-year weak lensing shear catalogue using convolutional neural networks (CNNs)
    and conventional summary statistics. We crop 19 $3\times 3\,\mathrm{{deg}^{2}}$
    sub-fields from the first-year area, divide the galaxies with redshift $0.3\leq
    z\leq 1.5$ into four equally-spaced redshift bins, and perform tomographic analyses.
    We develop a pipeline to generate simulated convergence maps from cosmological
    $N$-body simulations, where we account for effects such as intrinsic alignments
    (IAs), baryons, photometric redshift errors, and point spread function errors,
    to match characteristics of the real catalogue. We train CNNs that can predict
    the underlying parameters from the simulated maps, and we use them to construct
    likelihood functions for Bayesian analyses. In the $\Lambda$ cold dark matter
    model with two free cosmological parameters $\Omega_{\mathrm{m}}$ and $\sigma_{8}$,
    we find $\Omega_{\mathrm{m}}=0.278_{-0.035}^{+0.037}$, $S_{8}\equiv(\Omega_{\mathrm{m}}/0.3)^{0.5}\sigma_{8}=0.793_{-0.018}^{+0.017}$,
    and the IA amplitude $A_{\mathrm{IA}}=0.20_{-0.58}^{+0.55}$. In a model with four
    additional free baryonic parameters, we find $\Omega_{\mathrm{m}}=0.268_{-0.036}^{+0.040}$,
    $S_{8}=0.819_{-0.024}^{+0.034}$, and $A_{\mathrm{IA}}=-0.16_{-0.58}^{+0.59}$,
    with the baryonic parameters not being well-constrained. We also find that statistical
    uncertainties of the parameters by the CNNs are smaller than those from the power
    spectrum (5–24 percent smaller for $S_{8}$ and a factor of 2.5–3.0 smaller for
    $\Omega_{\mathrm{m}}$), showing the effectiveness of CNNs for uncovering additional
    cosmological information from the HSC data. With baryons, the $S_{8}$ discrepancy
    between HSC first-year data and Planck 2018 is reduced from $\sim 2.2\,\sigma$
    to $0.3\text{--}0.5\,\sigma$.
  prefs: []
  type: TYPE_NORMAL
- en: 'gravitational lensing: weak – cosmology: theory – cosmological parameters –
    large-scale structure of Universe'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: According to general relativity, the light originating from a distant galaxy
    is bent by inhomogeneities in the foreground matter distribution, which typically
    leads to a small distortion to the apparent shape of the galaxy – an effect called
    weak lensing. With the measurements of millions of galaxy shapes, we can reconstruct
    weighted projections of the matter density in our Universe and use these to infer
    the underlying cosmological model. Weak lensing has been proposed to be a powerful
    tool to constrain some of the cosmological parameters, such as the mean matter
    density $\Omega_{\mathrm{m}}$ and the normalisation of matter fluctuation $\sigma_{8}$
    in a $\Lambda$ cold dark matter ($\Lambda$CDM) universe (see, e.g. Bartelmann
    & Schneider, [2001](#bib.bib10); Refregier, [2003](#bib.bib61); Kilbinger, [2015](#bib.bib35),
    for reviews), among many other probes such as the cosmic microwave background
    (e.g. Hinshaw et al., [2013](#bib.bib29); Planck Collaboration et al., [2020](#bib.bib58))
    and baryon acoustic oscillations (e.g. Anderson et al., [2014](#bib.bib7); Alam
    et al., [2017](#bib.bib6)). The current weak lensing surveys are referred to as
    the “Stage III” surveys, such as the Dark Energy Survey (DES; Abbott et al., [2016](#bib.bib1)),
    the Hyper Suprime-Cam (HSC) survey (Aihara et al., [2018a](#bib.bib4)), and the
    Kilo-Degree survey (KiDS; Kuijken et al., [2015](#bib.bib42)). Due to their large
    survey area and depth, these surveys are currently able to yield constraints on
    the parameter $S_{8}\equiv(\Omega_{\mathrm{m}}/0.3)^{0.5}\sigma_{8}$ with $\lesssim
    5\text{ percent}$ relative error (see e.g. Hikage et al., [2019](#bib.bib26);
    Hamana et al., [2020](#bib.bib22); Heymans et al., [2021](#bib.bib25); Abbott
    et al., [2022](#bib.bib2)).
  prefs: []
  type: TYPE_NORMAL
- en: In general, cosmological parameters are constrained by fitting the observation
    to a theoretical model through some summary statistics. The most widely used of
    these are two-point statistics such as the two-point correlation function (2PCF)
    and the power spectrum of the lensing shear, which are considered optimal in extracting
    Gaussian information from weak lensing signals (see e.g. Fu et al., [2014](#bib.bib19);
    Köhlinger et al., [2016](#bib.bib38); Hikage et al., [2019](#bib.bib26); Hamana
    et al., [2020](#bib.bib22); Heymans et al., [2021](#bib.bib25); Abbott et al.,
    [2022](#bib.bib2)). One limitation of these two-point statistics is their inability
    to fully utilise non-Gaussian information on small, non-linear scales (below a
    few arcmin). Hence, many non-Gaussian summary statistics have been proposed and
    shown certain improvements over the 2PCF and power spectrum, e.g. three-point
    functions (Takada & Jain, [2003](#bib.bib68); Vafaei et al., [2010](#bib.bib74)),
    bispectra (Takada & Jain, [2004](#bib.bib69); Dodelson & Zhang, [2005](#bib.bib15)),
    peak counts (Jain & Van Waerbeke, [2000](#bib.bib32); Dietrich & Hartlap, [2010](#bib.bib14);
    Kratochvil et al., [2010](#bib.bib39); Kilbinger, [2015](#bib.bib35); Liu et al.,
    [2015](#bib.bib47); Martinet et al., [2018](#bib.bib53)), and Minkowski functionals
    (Munshi et al., [2011](#bib.bib54); Kratochvil et al., [2012](#bib.bib40); Petri
    et al., [2013](#bib.bib55)).
  prefs: []
  type: TYPE_NORMAL
- en: An alternative approach to extracting information from weak lensing signals
    is to use machine learning, where an algorithm is designed to identify features
    from the signal, usually in the form of lensing shear maps or convergence maps,
    and uses them to estimate the parameters. Convolutional neural networks (CNNs;
    LeCun et al., [1998](#bib.bib45)) are considered one of the promising methods
    due to their success in image classification and object detection tasks (Krizhevsky
    et al., [2012](#bib.bib41); He et al., [2016](#bib.bib24); Ren et al., [2015](#bib.bib62);
    Redmon et al., [2016](#bib.bib60)). In the context of weak lensing, multiple recent
    studies have investigated the use of CNNs (with different network architectures)
    and shown that they can outperform handcrafted summary statistics. Using suites
    of idealised noiseless simulated convergence maps, Gupta et al. ([2018](#bib.bib20))
    showed that the CNN achieved $\Omega_{\mathrm{m}}\text{--}\sigma_{8}$ constraints
    that are five times tighter than those from the power spectrum. Ribli et al. ([2019](#bib.bib63))
    found $2.4–2.8$ times tighter constraints from the CNNs than the power spectrum
    on noisy maps in an LSST-like survey. In the first application to real observations,
    Fluri et al. ([2019](#bib.bib17)) analysed the KiDS-450 survey and derived a 30
    percent improvement in constraining $S_{8}$ by using the CNNs compared to the
    power spectrum. Fluri et al. ([2022](#bib.bib18)) subsequently found a 16 percent
    improvement using KiDS-1000 data.
  prefs: []
  type: TYPE_NORMAL
- en: Despite yielding tighter constraints, using CNNs to extract information from
    weak lensing signals comes with two challenges. First, we need to establish a
    pipeline to simulate the lensing shear maps or convergence maps. Usually, a large
    number of cosmological simulations that cover the whole parameter space need to
    be run, and mock lensing maps that match the target survey are generated from
    them. This is unlike the 2PCF and power spectrum, for which theoretical predictions
    can be calculated from the non-linear matter power spectrum calibrated by a small
    number of simulations (e.g. Kilbinger et al., [2009](#bib.bib36); Takahashi et al.,
    [2012](#bib.bib71)). Second, since we have very little control over what features
    the CNNs are focusing on, we need to carefully account for the systematic effects
    on a pixel-by-pixel level so that the CNNs will not make predictions based on
    features that are wrongly presented in the simulated maps.
  prefs: []
  type: TYPE_NORMAL
- en: In this study, we perform weak lensing analyses applying CNNs to data from the
    HSC Subaru Strategic Program (HSC SSP; Aihara et al., [2018b](#bib.bib5)). $137\,\mathrm{{deg}^{2}}$
    of galaxy shear measurements are currently publicly available from this survey.
    In our simulation pipeline, we produce mock shear catalogues and convergence maps
    based on a large $N$-body simulation suite, which then incorporates systematic
    effects including the intrinsic alignments, baryonic effects, photometric redshift
    estimation uncertainties, shear measurement biases, and point spread function
    (PSF) modelling errors.
  prefs: []
  type: TYPE_NORMAL
- en: This paper is organised as follows. In Section [2](#S2 "2 catalogue preparation
    ‣ Cosmological constraints from HSC survey first-year data using deep learning"),
    we describe how we prepare the HSC first-year catalogue, as well as the generation
    of mock catalogues from the simulations by Takahashi et al. ([2017](#bib.bib70))
    (T17 hereafter). In Section [3](#S3 "3 Simulation pipeline ‣ Cosmological constraints
    from HSC survey first-year data using deep learning"), we present our own simulation
    pipeline in detail, including the $N$-body simulations, ray-tracing, baryonic
    model, intrinsic alignments, and treatments of other systematics. In Section [4](#S4
    "4 Summary statistics ‣ Cosmological constraints from HSC survey first-year data
    using deep learning"), we describe the calculation of conventional summary statistics—power
    spectrum, and peak counts—and the CNNs, which we argue can be regarded as a different
    type of summary statistic. We then describe the process of parameter inference
    using Bayesian analyses in Section [5](#S5 "5 Parameter inference ‣ Cosmological
    constraints from HSC survey first-year data using deep learning"), and we present
    the cosmological constraints using various models in Section [6](#S6 "6 Cosmological
    constraints ‣ Cosmological constraints from HSC survey first-year data using deep
    learning"). In Section [7](#S7 "7 Discussion ‣ Cosmological constraints from HSC
    survey first-year data using deep learning"), we discuss the impact of CNN hyper-parameters,
    the choice of smoothing scale, the origin of non-Gaussian information, and we
    compare our constraints to Planck 2018 results. Finally, we summarise our main
    conclusions in Section [8](#S8 "8 Conclusions ‣ Cosmological constraints from
    HSC survey first-year data using deep learning").
  prefs: []
  type: TYPE_NORMAL
- en: 2 catalogue preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1 HSC first-year catalogues
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/61cd89ead5cd5f09e39b1f6fc31fcc76.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The galaxy number density in the HSC first-year shear catalogue.
    The red squares shows the 19 sub-fields cropped from the catalogue and used in
    forward modelling with our ray-tracing simulations.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0d08fe2dddb75c640130115962ffaac5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The relation between ephor_AB $z_{\mathrm{best}}$ and the assigned
    ray-tracing redshifts $z_{\mathrm{rt}}$ for each redshift bin. The light grey
    shade in each bin shows the $\pm 1\sigma_{\Delta z}$ range around $z_{\mathrm{rt}}=z_{\mathrm{best}}$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The cosmological inference in this work is based on the HSC first-year shear
    catalogue prepared by Mandelbaum et al. ([2018a](#bib.bib51)). Apart from masked
    regions due to bright stars, the catalogue covers $136.9\,\mathrm{{deg}^{2}}$
    of sky area with an unweighted galaxy number density of $24.6\,\mathrm{{arcmin}^{-2}}$
    (Mandelbaum et al., [2018a](#bib.bib51)), as is shown in Figure [1](#S2.F1 "Figure
    1 ‣ 2.1 HSC first-year catalogues ‣ 2 catalogue preparation ‣ Cosmological constraints
    from HSC survey first-year data using deep learning"). To facilitate our $N$-body
    simulation and ray-tracing pipeline, we crop 19 sub-fields from the catalogue,
    each of which can be projected onto a $3\times 3\,\mathrm{{deg}^{2}}$ map using
    the flat sky projection (Coxeter & Coxeter, [1989](#bib.bib13); Liu et al., [2015](#bib.bib47)):'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle x$ | $\displaystyle=$ | $\displaystyle r^{-1}\cos\alpha\sin(\delta-\delta_{0}),$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle y$ | $\displaystyle=$ | $\displaystyle r^{-1}\left(\cos\alpha_{0}\sin\alpha-\sin\alpha_{0}\cos\alpha\cos(\delta-\delta_{0})\right),$
    |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle r$ | $\displaystyle=$ | $\displaystyle\sin\alpha_{0}\sin\alpha+\cos\alpha_{0}\cos\alpha\cos(\delta-\delta_{0}),$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: where $(\alpha,\delta)$ is the $(\mathrm{RA},\mathrm{Dec})$ coordinate of the
    galaxy, $(\alpha_{0},\delta_{0})$ the center of the sub-field, and $(x,y)$ the
    projected position of the galaxy. Figure [1](#S2.F1 "Figure 1 ‣ 2.1 HSC first-year
    catalogues ‣ 2 catalogue preparation ‣ Cosmological constraints from HSC survey
    first-year data using deep learning") shows the boundaries of these sub-fields
    in red squares.
  prefs: []
  type: TYPE_NORMAL
- en: To perform tomographic analyses, we gather the photometric redshifts (photo-$z$)
    of the galaxies from the HSC photo-$z$ catalogue (see Tanaka et al., [2018](#bib.bib72)).
    Following Hikage et al. ([2019](#bib.bib26)), we put the galaxies between $z=0.3$
    and $z=1.5$ into four equally-spaced redshift bins according to their ephor_AB
    $z_{\mathrm{best}}$ from the catalogue. The galaxies outside this redshift range
    will not be used in this paper. Out of 11.9 million galaxies in the original catalogue,
    29 percent are discarded by sub-field cropping (5 percent) and redshift binning
    (24 percent), leaving us with 8.5 million galaxies.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, our pipeline is dependent on the redshift distribution of the
    galaxies within each bin. Note that although the $z_{\mathrm{best}}$ estimations
    are considered *best* for individual galaxies, the distribution of all $z_{\mathrm{best}}$
    estimations is a biased estimate of the true redshift distribution, which can
    degrade the cosmological constraints (see e.g. Abruzzo & Haiman, [2019](#bib.bib3)).
    To address this issue, we adopt the COSMOS (Laigle et al., [2016](#bib.bib43))
    re-weighting method from Hikage et al. ([2019](#bib.bib26)) to get reliable redshift
    distributions. The weighted COSMOS photo-$z$ catalogue¹¹1https://hsc-release.mtk.nao.ac.jp/doc/index.php/s17a-wide-cosmos/
    includes 30-band photo-$z$ estimations, much more accurate than the HSC 5-band
    photo-$z$, but they are only available for a small number of galaxies compared
    to the full shear catalogue. So each of those galaxies is assigned a weight such
    that the colour magnitude distribution of all galaxies matches that in the first-year
    shear catalogue. For the $b^{\text{th}}$ redshift bin ($b=1,2,3,4$), we pick the
    representative galaxies that are both in the $b^{\text{th}}$ bin and in the COSMOS
    catalogue, and we consider their weighted 30-band photo-$z$ distribution to be
    a good estimation for the true redshift distribution $p_{b}(z)$.
  prefs: []
  type: TYPE_NORMAL
- en: With $z_{\mathrm{best}}$ and $p_{b}(z)$, we now assign *ray-tracing redshifts*
    ($z_{\mathrm{rt}}$) to the galaxies with the following steps. First, we randomly
    sample $N_{b}$ candidate $z_{\mathrm{rt}}$ values from $p_{b}(z)$, where $N_{b}$
    is number of galaxies in the bin. Then, the $i^{\text{th}}$ lowest $z_{\mathrm{rt}}$
    is assigned to the galaxy with the $i^{\text{th}}$ lowest $z_{\mathrm{best}}$
    for $i=1,2,\cdots,N_{b}$. Such assignments ensure that the distribution of $z_{\mathrm{rt}}$
    reproduces the true redshift distribution of galaxies within the bin, and since
    $z_{\mathrm{rt}}$ has the same ordering as $z_{\mathrm{best}}$, the distance information
    is partially retained. Figure [2](#S2.F2 "Figure 2 ‣ 2.1 HSC first-year catalogues
    ‣ 2 catalogue preparation ‣ Cosmological constraints from HSC survey first-year
    data using deep learning") shows the mappings from $z_{\mathrm{best}}$ to $z_{\mathrm{rt}}$.
    Compared to an alternative approach where the $z_{\mathrm{rt}}$ are assigned randomly
    without considering $z_{\mathrm{best}}$, we find the difference in the statistical
    properties of the lensing signal to be negligible for HSC first-year data according
    to our tests.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 T17 mock shear catalogues
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In parallel with the cosmological analyses on the real HSC data, we perform
    analyses on mock catalogues based on the $N$-body simulations and full-sky ray-tracing
    by T17\. The purpose of using external catalogues is to check the validity of
    our pipeline–cosmological constraints that are consistent with the mock cosmology
    suggests correct implementations of our algorithms. Their mock simulations use
    a flat $\Lambda$CDM cosmological model with the following cosmological parameters:
    $h=0.7$, $\Omega_{\mathrm{m}}=0.279$, $\Omega_{\mathrm{b}}=0.046$, $\sigma_{8}=0.82$,
    $n_{\mathrm{s}}=0.97$.'
  prefs: []
  type: TYPE_NORMAL
- en: To generate the mock catalogues, we first download the first four realisations
    of the ray-tracing simulations with $N_{\mathrm{side}}=8192$, which is the highest
    resolution with multiple realisations available. For each mock catalogue realisation,
    we randomly crop 19 $3\times 3\,\mathrm{{deg}^{2}}$ sub-fields from a ray-tracing
    realisation and extract shears $\boldsymbol{\gamma}\equiv(\gamma_{1},\gamma_{2})$
    and convergences $\kappa$ at the positions $\boldsymbol{x}\equiv(x,y)$ and redshifts
    $z$ of the galaxies. Since the snapshots in the ray-tracing simulations from T17
    are taken at discrete redshifts, we linearly interpolate between adjacent snapshots
    to get the shears and convergences at arbitrary redshifts, i.e.
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\kappa(\boldsymbol{x},z)=\frac{z_{i+1}-z}{z_{i+1}-z_{i}}\kappa(\boldsymbol{x},z_{i})+\frac{z-z_{i}}{z_{i+1}-z_{i}}\kappa(\boldsymbol{x},z_{i+1}),$
    |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\boldsymbol{\gamma}(\boldsymbol{x},z)=\frac{z_{i+1}-z}{z_{i+1}-z_{i}}\boldsymbol{\gamma}(\boldsymbol{x},z_{i})+\frac{z-z_{i}}{z_{i+1}-z_{i}}\boldsymbol{\gamma}(\boldsymbol{x},z_{i+1}),$
    |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: where $z_{i}$ denotes the redshift of the $i^{\text{th}}$ snapshot, and $z_{i}\leq
    z\leq z_{i+1}$. This process of randomly cropping sub-fields and extracting shears
    is repeated ten times on each ray-tracing simulation, making 40 T17 mock catalogue
    realisations in total.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Simulation pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/df4bc8de02ea060a710d9abb7a269753.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: An overview of our simulation pipeline (green). Some of the operations
    are also used in processing real data (yellow).'
  prefs: []
  type: TYPE_NORMAL
- en: Conceptually, our simulation pipeline is a forward modelling process that takes
    a set of parameters describing the cosmology, baryonic model, and systematics,
    and yields random realisations of weak lensing $\kappa$ maps. The simulated maps
    have similar statistical properties as the maps from the real data, so by varying
    the input cosmological parameters, the distribution of observables from the simulated
    maps can be used to constrain the cosmological model of the real Universe. In
    addition, we use those simulated maps to train deep learning models that can predict
    their underlying parameters, and the trained models can be applied to either another
    set of simulated maps or the real maps from the data, in the same way.
  prefs: []
  type: TYPE_NORMAL
- en: Figure [3](#S3.F3 "Figure 3 ‣ 3 Simulation pipeline ‣ Cosmological constraints
    from HSC survey first-year data using deep learning") shows the flowchart diagram
    of our analysis pipeline, and in this section, we describe each of these steps
    in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 N-body simulation setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/346e6a4779bdb423539b74b1ee60bf78.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: The cosmological parameters $(\Omega_{\mathrm{m}},\sigma_{8})$ in
    our suite of $N$-body simulations, where $S_{8}$ is defined as $(\Omega_{\mathrm{m}}/0.3)^{0.5}\sigma_{8}$.
    The red dot denotes the fiducial cosmology $\Omega_{\mathrm{m}}=0.3,\sigma_{8}=0.8$.
    The light blue triangle pattern shows the Delaunay triangulation of the grid used
    for interpolation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our simulation suite consists of 79 DM-only $N$-body simulations with flat
    $\Lambda$CDM cosmology. Each simulation has its unique pair of $(\Omega_{\mathrm{m}},\sigma_{8})$,
    with the rest of the cosmological parameters taken to be the marginalised means
    from the Planck 2018 results (TT,TE,EE+lowE+lensing): $h_{0}=0.6736$, $n_{\mathrm{s}}=0.9649$,
    and $\Omega_{\mathrm{b}}=0.0493$ (Planck Collaboration et al., [2020](#bib.bib58)).
    Our choices for $\Omega_{\mathrm{m}}$ and $\sigma_{8}$, shown in Figure [4](#S3.F4
    "Figure 4 ‣ 3.1 N-body simulation setup ‣ 3 Simulation pipeline ‣ Cosmological
    constraints from HSC survey first-year data using deep learning"), are placed
    along constant $S_{8}$ values, which is close to the best-constrained parameter
    combination in most weak lensing analyses. The range $0.662\leq S_{8}\leq 0.966$
    is chosen to cover the posterior distributions from recent surveys including HSC
    Y1 (Hikage et al., [2019](#bib.bib26); Hamana et al., [2020](#bib.bib22)), DES
    Y1 (Troxel et al., [2018](#bib.bib73)), and KiDS-1000 (Asgari et al., [2021](#bib.bib9)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'For each set of cosmological parameters, we use music (Hahn & Abel, [2011](#bib.bib21))
    to generate the initial condition of the DM-only simulation at $z_{\mathrm{start}}=50$,
    with a $500h^{-1}\mathrm{Mpc}$ box size and $1024^{3}$ particles. Then, we use
    pkdgrav3 (Potter et al., [2017](#bib.bib59)) to evolve the simulation box from
    $z=50$ to $z=0$ with 500 time steps. We choose the default schedule for the opening
    angle parameter: $\theta=0.4$ at $z>20$, $\theta=0.55$ at $2<z<20$, and $\theta=0.7$
    at $z<2$, where large $\theta$ means higher force accuracy. We refer the reader
    to Potter et al. ([2017](#bib.bib59)) for a detailed explanation.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Index | $z_{\mathrm{snap}}$ | $\chi_{\mathrm{fid}}$ | Index | $z_{\mathrm{snap}}$
    | $\chi_{\mathrm{fid}}$ | Index | $z_{\mathrm{snap}}$ | $\chi_{\mathrm{fid}}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | [$h^{-1}\mathrm{Mpc}$] |  |  | [$h^{-1}\mathrm{Mpc}$] |  |  | [$h^{-1}\mathrm{Mpc}$]
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0.020 | 60 | 13 | 0.579 | 1500 | 25 | 1.413 | 2940 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 0.060 | 180 | 14 | 0.635 | 1620 | 26 | 1.504 | 3060 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 0.102 | 300 | 15 | 0.693 | 1740 | 27 | 1.600 | 3180 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 0.145 | 420 | 16 | 0.753 | 1860 | 28 | 1.700 | 3300 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 0.188 | 540 | 17 | 0.815 | 1980 | 29 | 1.806 | 3420 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 0.232 | 660 | 18 | 0.879 | 2100 | 30 | 1.917 | 3540 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 0.278 | 780 | 19 | 0.946 | 2220 | 31 | 2.034 | 3660 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 0.325 | 900 | 20 | 1.016 | 2340 | 32 | 2.158 | 3780 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 0.373 | 1020 | 21 | 1.089 | 2460 | 33 | 2.290 | 3900 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 0.422 | 1140 | 22 | 1.164 | 2580 | 34 | 2.429 | 4020 |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | 0.473 | 1260 | 23 | 1.244 | 2700 | 35 | 2.576 | 4140 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 0.525 | 1380 | 24 | 1.327 | 2820 | 36 | 2.733 | 4260 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: The indices, redshifts, and comoving distances (fiducial cosmology)
    of the snapshots.'
  prefs: []
  type: TYPE_NORMAL
- en: We take 36 snapshots at fixed redshifts for all cosmologies between $z=0.020$
    and $z=2.733$ as listed in Table [1](#S3.T1 "Table 1 ‣ 3.1 N-body simulation setup
    ‣ 3 Simulation pipeline ‣ Cosmological constraints from HSC survey first-year
    data using deep learning"). The redshifts $z_{\mathrm{snap}}^{(i)}$ are selected
    such that their corresponding comoving distances at the fiducial cosmology ($\Omega_{\mathrm{m}}=0.3$,
    $\sigma_{8}=0.8$) are
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\chi_{\mathrm{fid}}^{(i)}=(i-0.5)\times 120h^{-1}\mathrm{Mpc}\;(i=1,2,\cdots,36).$
    |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: 'We note that because the snapshots can only be taken at the end of time steps,
    the actual redshifts are lower than the values in Table [1](#S3.T1 "Table 1 ‣
    3.1 N-body simulation setup ‣ 3 Simulation pipeline ‣ Cosmological constraints
    from HSC survey first-year data using deep learning"). But since the number of
    steps is large, the deviations are very small: $|\Delta z|\sim 0.003$ and $|\Delta\chi|\sim
    5h^{-1}\mathrm{Mpc}$, which are negligible compared to the estimated systematic
    error of photo-$z$ (see Section [3.2](#S3.SS2 "3.2 Ray-tracing ‣ 3 Simulation
    pipeline ‣ Cosmological constraints from HSC survey first-year data using deep
    learning")).'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Ray-tracing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c74d673c92cd4928b024e9df6580371a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The thickness of the slab as a function of the slab index and $\Omega_{\mathrm{m}}$.
    When $\Omega_{\mathrm{m}}=0.3$, all slabs have a constant thickness of $120h^{-1}\mathrm{Mpc}$.'
  prefs: []
  type: TYPE_NORMAL
- en: In the real Universe, the shape of a galaxy at $z_{\mathrm{s}}$ is distorted
    by the foreground matter distribution between $z=0$ and $z=z_{\mathrm{s}}$ due
    to general relativity. *Ray-tracing* reproduces this process by tracing the light
    through the matter distribution from an $N$-body simulation. Ray-tracing is necessary
    for cosmological inference from small angular scales, using beyond-Gaussian statistics (Petri
    et al., [2017](#bib.bib57)). The multi-lens-plane algorithm (Jain et al., [2000](#bib.bib31);
    Hilbert et al., [2009](#bib.bib27)) is a popular implementation of ray-tracing.
    In this algorithm, the foreground matter distribution is discretised into multiple
    density slabs, which are taken from simulation snapshots. Then, each slab is viewed
    as a thin plane located at the centre of its thickness. When the light rays are
    traced from the observer at $z=0$ to the source galaxies, they only bend at the
    locations of those planes.
  prefs: []
  type: TYPE_NORMAL
- en: Given the redshifts of the snapshots $z_{\mathrm{snap}}^{(i)}$, we can calculate
    the desired thickness of the $i^{\text{th}}$ slab by
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\Delta\chi^{(i)}=\frac{1}{2}\left[\chi_{\mathrm{snap}}^{(i+1)}-\chi_{\mathrm{snap}}^{(i-1)}\right],$
    |  | (7) |'
  prefs: []
  type: TYPE_TB
- en: 'where $\chi_{\mathrm{snap}}^{(i)}$ denotes the comoving distance at $z_{\mathrm{snap}}^{(i)}$.
    We note that the thickness of the slabs is dependent on the cosmology: for the
    fiducial cosmology, the slabs have a constant thickness of $120h^{-1}\mathrm{Mpc}$
    across all redshifts due to the snapshots being equally spaced in comoving distance,
    while for other cosmologies, the thickness at high redshifts can vary from $80h^{-1}\mathrm{Mpc}$
    to $200h^{-1}\mathrm{Mpc}$, as shown in Figure [5](#S3.F5 "Figure 5 ‣ 3.2 Ray-tracing
    ‣ 3 Simulation pipeline ‣ Cosmological constraints from HSC survey first-year
    data using deep learning"). We cut two to six slabs from each snapshots along
    each of the three axes, depending on the slab thickness. Then, we generate density
    planes from the slabs by calculating the column density on a $8192\times 8192$
    grid, followed by generating potential planes through solving the two-dimensional
    Poisson equation.'
  prefs: []
  type: TYPE_NORMAL
- en: Our implementation of the ray-tracing algorithm strictly follows that presented
    by Petri et al. ([2013](#bib.bib55)). Each ray-tracing run starts from creating
    a stack of potential planes, where the plane at each redshift is randomly chosen,
    flipped, rotated (in multiples of $90^{\circ}$), and translated. We trace the
    light ray from the observer towards the direction of each galaxy until its ray-tracing
    redshift $z_{\mathrm{rt}}$ and calculate the total distortion in terms of lensing
    shears $\boldsymbol{\gamma}$ and the convergence $\kappa$.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Redshift distribution uncertainty
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In Section [2.1](#S2.SS1 "2.1 HSC first-year catalogues ‣ 2 catalogue preparation
    ‣ Cosmological constraints from HSC survey first-year data using deep learning"),
    we have estimated the redshift distribution $p_{b}(z)$ using the COSMOS reweighting
    method and assigned the ray-tracing redshifts $z_{\mathrm{rt}}$ to the galaxies,
    which are used as their source redshifts in § [3.2](#S3.SS2 "3.2 Ray-tracing ‣
    3 Simulation pipeline ‣ Cosmological constraints from HSC survey first-year data
    using deep learning"). While this method addresses the uncertainty of individual
    redshifts, the uncertainty of the whole distribution can remain a problem. In
    Figure [2](#S2.F2 "Figure 2 ‣ 2.1 HSC first-year catalogues ‣ 2 catalogue preparation
    ‣ Cosmological constraints from HSC survey first-year data using deep learning"),
    one can find systematic differences between ephor_AB $z_{\mathrm{best}}$ and $z_{\mathrm{rt}}$,
    suggesting that $p_{b}(z)$ may be systematically biased along the redshift axis
    due to our choice of the photo-$z$ algorithm. In addition, the discrepancies in
    the average $z_{\mathrm{best}}$ among various photo-$z$ algorithm, even trained
    with the same COSMOS 30-band redshift, suggest that photo-$z$ algorithms are associated
    with intrinsic statistical errors (Tanaka et al., [2018](#bib.bib72); Hikage et al.,
    [2019](#bib.bib26); Hamana et al., [2020](#bib.bib22)).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this work, we follow Hikage et al. ([2019](#bib.bib26)) to model the uncertainty
    in each redshift distribution. The uncertainty of $p_{b}(z)$ is parameterised
    with a translation by $\Delta z_{b}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\tilde{p}_{b}(z)=p_{b}(z+\Delta z_{b}),$ |  | (8) |'
  prefs: []
  type: TYPE_TB
- en: and hence,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\tilde{z}_{\mathrm{rt}}=z_{\mathrm{rt}}+\Delta z_{b},$ |  | (9) |'
  prefs: []
  type: TYPE_TB
- en: 'where $\tilde{p}_{b}(z)$ denotes the redshift distribution without the overall
    redshift error, and $\tilde{z}_{\mathrm{rt}}$ the ray-tracing redshift sampled
    from $\tilde{p}_{b}(z)$. The priors of $\Delta z_{b}$ follow normal distributions
    $\mathcal{N}(0,\sigma_{\Delta z_{b}})$, and Hikage et al. ([2019](#bib.bib26))
    have estimated the values of $\sigma_{\Delta z_{b}}$ to be: 0.0285 ($0.3<z<0.6$),
    0.0135 ($0.6<z<0.9$), 0.0383 ($0.9<z<1.2$), and 0.0376 ($1.2<z<1.5$), shown in
    Figure [2](#S2.F2 "Figure 2 ‣ 2.1 HSC first-year catalogues ‣ 2 catalogue preparation
    ‣ Cosmological constraints from HSC survey first-year data using deep learning").
    Hamana et al. ([2020](#bib.bib22)) have shown that the two-point correlation function
    of the HSC first-year catalogue cannot provide better constraints on $\Delta z_{b}$
    than their priors. Therefore, we do not include $\Delta z_{b}$ as free parameters,
    but instead we simply add randomly sampled $\Delta z_{b}$ values to $z_{\mathrm{rt}}$
    during ray-tracing—effectively marginalising over the priors of $\Delta z_{b}$.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Baryonic model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Parameter | Fiducial value | Prior |'
  prefs: []
  type: TYPE_TB
- en: '| Cosmological and baryonic parameters |'
  prefs: []
  type: TYPE_TB
- en: '| $\Omega_{\mathrm{m}}$ | $0.3$ | flat within the boundary of simulated cosmologies
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\sigma_{8}$ | $0.8$ | flat within the boundary of simulated cosmologies
    |'
  prefs: []
  type: TYPE_TB
- en: '| $A_{\mathrm{IA}}$ | $0$ | flat $[-3,3]$ |'
  prefs: []
  type: TYPE_TB
- en: '| $M_{\mathrm{c}}$ | $3.3\times 10^{13}h^{-1}\mathrm{M}_{\odot}$ | log-uniform
    $[10^{12}h^{-1}\mathrm{M}_{\odot},10^{16}h^{-1}\mathrm{M}_{\odot}]$ |'
  prefs: []
  type: TYPE_TB
- en: '| $M_{1,0}$ | $8.63\times 10^{11}h^{-1}\mathrm{M}_{\odot}$ | log-uniform $[10^{10}h^{-1}\mathrm{M}_{\odot},10^{13}h^{-1}\mathrm{M}_{\odot}]$
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\eta$ | $0.54$ | log-uniform $[10^{-0.7},10^{0.5}]$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\beta$ | $0.12$ | log-uniform $[10^{-1.0},10^{0.5}]$ |'
  prefs: []
  type: TYPE_TB
- en: '| Nuisance parameters |'
  prefs: []
  type: TYPE_TB
- en: '| $\Delta z_{1}$ | $-$ | Gaussian $\mathcal{N}(0,0.0285)$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\Delta z_{2}$ | $-$ | Gaussian $\mathcal{N}(0,0.0135)$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\Delta z_{3}$ | $-$ | Gaussian $\mathcal{N}(0,0.0383)$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\Delta z_{4}$ | $-$ | Gaussian $\mathcal{N}(0,0.0376)$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\Delta m$ | $-$ | Gaussian $\mathcal{N}(0,0.01)$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\alpha_{\mathrm{psf}}$ | $-$ | Gaussian $\mathcal{N}(0.030,0.015)$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\beta_{\mathrm{psf}}$ | $-$ | Gaussian $\mathcal{N}(-0.89,0.70)$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: The prior distributions of all parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We employ the baryonic correction model (BCM, Aricò et al., [2020](#bib.bib8),
    see also Schneider & Teyssier [2015](#bib.bib64)) to make modifications to the
    simulated density fields, mimicking the impact of cooling, star formation, and
    feedback during galaxy formation. Other than the baryon density parameter $\Omega_{\mathrm{b}}$,
    the BCM has four free parameters: two characteristic halo masses $M_{\mathrm{c}}$
    and $M_{1,0}$, the maximum distance $\eta$ of the gas ejected from halos, and
    the logarithmic slope $\beta$ of the gas fraction versus halo mass. With the total
    mass of each halo conserved, these four parameters control the difference between
    the density profile with and without baryons.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of the BCM in this work is identical to our previous works
    (see Lu & Haiman, [2021](#bib.bib49); Lu et al., [2022](#bib.bib50)). We briefly
    introduce the process here, and we refer the reader to Lu & Haiman ([2021](#bib.bib49))
    for a detailed description. In the analyses where the baryonic effects are included,
    the BCM is applied to the density planes prior to ray-tracing. In each halo, a
    fixed portion ($\Omega_{\mathrm{b}}/\Omega_{\mathrm{m}}$) of the mass is replaced
    by the density profile calculated with the halo mass, concentration parameter,
    and baryonic parameters. The fiducial values of the baryonic parameters are: $M_{\mathrm{c}}=3.3\times
    10^{13}h^{-1}\mathrm{M}_{\odot}$, $M_{1,0}=8.63\times 10^{11}h^{-1}\mathrm{M}_{\odot}$,
    $\eta=0.54$, $\beta=0.12$, and we adopt log-uniform priors for all four parameters
    with the ranges shown in Table [2](#S3.T2 "Table 2 ‣ 3.4 Baryonic model ‣ 3 Simulation
    pipeline ‣ Cosmological constraints from HSC survey first-year data using deep
    learning"). Note that the prior ranges in this work are different from those in
    Aricò et al. ([2020](#bib.bib8)), because we use the constraints by other observations
    (see e.g. Schneider & Teyssier, [2015](#bib.bib64); Lu & Haiman, [2021](#bib.bib49))
    as reference instead of using the best-fits from hydrodynamical simulations.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 Simulated ellipticity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A measured galaxy ellipticity presented in the real shear catalogue is the consequence
    of multiple factors, with the lensing shears calculated in § [3.2](#S3.SS2 "3.2
    Ray-tracing ‣ 3 Simulation pipeline ‣ Cosmological constraints from HSC survey
    first-year data using deep learning") being only one of them. In this section,
    we present our method of simulating ellipticities considering the other two major
    factors—shape noise and shear measurement biases, as part of the forward modelling
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Shape noise refers to part of the ellipticity that is contributed by the intrinsic
    shape of the galaxy, ignoring the correlation between the intrinsic shapes. In
    terms of generating shape noise to be added to the simulated shears, a simple
    empirical method is randomly rotating the measured ellipticity $\boldsymbol{e}\equiv(e_{1},e_{2})$.
    This ensures that (1) the level of shape noise is almost the same as that in the
    real catalogue (because $|\boldsymbol{\gamma}|\ll|\boldsymbol{e}|$ for a single
    galaxy) and (2) random rotations removes lensing signals from the ellipticities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Shear measurement biases, specifically the multiplicative bias $m$ and the
    additive bias $\boldsymbol{c}\equiv(c_{1},c_{2})$, describe the relation between
    the true shear $\boldsymbol{\gamma}^{\mathrm{(true)}}$ and the measured shear
    $\boldsymbol{\gamma}^{\mathrm{(mea)}}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\boldsymbol{\gamma}^{\mathrm{(mea)}}=(1+m)\boldsymbol{\gamma}^{\mathrm{(true)}}+\boldsymbol{c}.$
    |  | (10) |'
  prefs: []
  type: TYPE_TB
- en: There are multiple reasons for the existence of shear biases, such as the limitations
    of the PSF deconvolution algorithm, or the shape of the galaxy not being correctly
    described by the model. Mandelbaum et al. ([2018b](#bib.bib52)) have done thorough
    investigations into shear biases using image simulations, and they provide $m$
    and $\boldsymbol{c}$ estimations for each galaxy in the HSC shear catalogue. With
    all calibrated biases removed, Mandelbaum et al. ([2018b](#bib.bib52)) show that
    the uncertainty of the residual multiplicative bias $\Delta m$ is controlled at
    the 1 percent level.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our pipeline, the simulated ellipticity of a galaxy is calculated following
    Bernstein & Jarvis ([2002](#bib.bib11)) and Shirasaki et al. ([2019](#bib.bib65)),
    but we neglect the second order terms as we find virtually no difference in the
    produced maps:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\boldsymbol{e}^{\mathrm{(sim)}}=e^{i\phi}\boldsymbol{e}^{\mathrm{(mea)}}+(1+\Delta
    m)(1+m_{\mathrm{tot}})\frac{2\boldsymbol{\gamma}\mathcal{R}}{1-\kappa}+\boldsymbol{c},$
    |  | (11) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\mathcal{R}\equiv 1-{\frac{1}{2}\left&#124;\boldsymbol{e}^{\mathrm{(mea)}}\right&#124;}^{2}\frac{e_{\mathrm{RMS}}^{2}}{e_{\mathrm{RMS}}^{2}+\sigma_{\mathrm{e}}^{2}},$
    |  | (12) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle m_{\mathrm{tot}}\equiv m+m_{\mathrm{sel}}+m_{\mathcal{R}},$
    |  | (13) |'
  prefs: []
  type: TYPE_TB
- en: where $\boldsymbol{e}^{\mathrm{(mea)}}$ denotes the measured ellipticity in
    the catalogue, $e^{i\phi}\boldsymbol{e}^{\mathrm{(mea)}}$ the measured ellipticity
    with a random rotation, $m$ and $\boldsymbol{c}$ the estimated biases in the HSC
    catalogue, $e_{\mathrm{RMS}}$ the estimated intrinsic root mean square (RMS) ellipticity
    in the catalogue, and $\sigma_{\mathrm{e}}$ the estimated measurement error in
    the catalogue. Following Hikage et al. ([2019](#bib.bib26)), the multiplicative
    biases due to galaxy size selection $m_{\mathrm{sel}}$ are 0.0086, 0.0099, 0.0091,
    and 0.0091 in the four redshift bins respectively (low-$z$ to high-$z$), the multiplicative
    biases due to redshift-dependent responsivity corrections $m_{\mathcal{R}}$ are
    0.000, 0.000, 0.015, and 0.030 in the four bins respectively, and the nuisance
    parameter $\Delta m$ is randomly sampled from the normal distribution $\mathcal{N}(0,0.01)$,
    applied across all simulated ellipticities. A realisation of the simulated ellipticities
    can be viewed as a catalogue that have similar characteristics as the real catalogue,
    except for the underlying model parameters and a few systematics that need to
    be addressed after map conversion.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6 Shear maps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dd50e0cd62f970dd531056fc4669794a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: The field mask, shear map, and convergence map of an HSC sub-field
    in GAMA09H. The shear map and convergence map are generated with a smoothing scale
    of $\sigma_{\mathrm{G}}=2\,\mathrm{arcmin}$.'
  prefs: []
  type: TYPE_NORMAL
- en: With the ellipticities simulated for all galaxies in a sub-field and a redshift
    bin, we can generate a $3\times 3\,\mathrm{{deg}^{2}}$ shear map on a $104\times
    104$ square grid, and we add 12 pixels of padding on all four sides of the map
    to better maintain the lensing signal near the edge during smoothing (see below).
    The size of the full map is therefore $3.69\times 3.69\,\mathrm{{deg}^{2}}$ with
    a dimension of $128\times 128$, and the size of each pixel is $\Delta x=1.73\,\mathrm{arcmin}$.
  prefs: []
  type: TYPE_NORMAL
- en: In the HSC catalogue, there are regions without galaxies due to bright stars,
    and we need to find this *field mask* $\sigma_{\mathrm{mask}}(\boldsymbol{x})$
    for each sub-field, which will be used in the generation of shear maps. Note that
    the field mask does not depend on the redshift bin, thus the number density of
    the galaxies is high enough for us to calculate the mask at a resolution of $0.87\,\mathrm{arcmin}$,
    i.e. on a $208\times 208$ grid for a $3\times 3\,\mathrm{{deg}^{2}}$ sub-field.
    The sub-fields have 10 to 15 galaxies per pixel on average among all pixels with
    at least one galaxy, and based on that, we consider the pixels with fewer than
    four galaxies to be covered by the mask ($\sigma_{\mathrm{mask}}(\boldsymbol{x})=1$).
    Then, the field masks are down-sampled by a factor of two to the resolution of
    shear maps, an example of which is shown in Figure [6](#S3.F6 "Figure 6 ‣ 3.6
    Shear maps ‣ 3 Simulation pipeline ‣ Cosmological constraints from HSC survey
    first-year data using deep learning").
  prefs: []
  type: TYPE_NORMAL
- en: The calculation of the shear maps follows the shear estimation procedure as
    in Appendix 3 of Mandelbaum et al. ([2018a](#bib.bib51)). The value of the pixel
    centred at $\boldsymbol{x}\equiv(x,y)$ is
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\boldsymbol{\gamma}(\boldsymbol{x})=\frac{1}{1+m_{\mathrm{tot}}(\boldsymbol{x})}\left[\frac{\boldsymbol{e}(\boldsymbol{x})}{2(1-e_{\mathrm{RMS}}^{2}(\boldsymbol{x}))}-\boldsymbol{c}(\boldsymbol{x})\right].$
    |  | (14) |'
  prefs: []
  type: TYPE_TB
- en: The fields on the right-hand side are defined as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\phi(\boldsymbol{x})=\frac{\phi_{w}(\boldsymbol{x})}{w(\boldsymbol{x})},$
    |  | (15) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\phi_{w}(\boldsymbol{x})=\left(\sum_{\boldsymbol{x}_{i}\in
    A(\boldsymbol{x})}{w_{i}\phi_{i}}\right)+\sigma_{\mathrm{mask}}(\boldsymbol{x})\langle
    w\rangle\langle\phi\rangle,$ |  | (16) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle w(\boldsymbol{x})=\left(\sum_{\boldsymbol{x}_{i}\in A(\boldsymbol{x})}{w_{i}}\right)+\sigma_{\mathrm{mask}}(\boldsymbol{x})\langle
    w\rangle,$ |  | (17) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\langle w\rangle=\frac{1}{N}\sum_{i}{w_{i}},\;\langle\phi\rangle=\frac{1}{N}\sum_{i}{\phi_{i}},$
    |  | (18) |'
  prefs: []
  type: TYPE_TB
- en: where $\phi$ is one of $\{e_{\mathrm{RMS}}^{2},m_{\mathrm{tot}},\boldsymbol{c},\boldsymbol{e}\}$,
    $N$ the number of galaxies in the sub-field and the redshift bin, $w_{i}$ the
    lensing weight of the $i^{\text{th}}$ galaxy in the catalogue, and $\boldsymbol{x}_{i}\in
    A(\boldsymbol{x})$ means that the $i^{\text{th}}$ galaxy is located in the pixel
    centred at $\boldsymbol{x}$. We further simplify the calculation by assuming $\langle\boldsymbol{c}\rangle=\langle\boldsymbol{e}\rangle=0$.
    Note that due to the second terms in Equation ([16](#S3.E16 "In 3.6 Shear maps
    ‣ 3 Simulation pipeline ‣ Cosmological constraints from HSC survey first-year
    data using deep learning")) and ([17](#S3.E17 "In 3.6 Shear maps ‣ 3 Simulation
    pipeline ‣ Cosmological constraints from HSC survey first-year data using deep
    learning")), the average values (e.g. shears and biases) are assigned to the masked
    region of the map so that $\phi(\boldsymbol{x})$ and $\boldsymbol{\gamma}(\boldsymbol{x})$
    are well-defined on the entire map. When smoothing of the shear map is needed,
    a Gaussian kernel with standard deviation $\sigma_{\mathrm{G}}$ is applied to
    $\phi_{w}(\boldsymbol{x})$ and $w(\boldsymbol{x})$, e.g.
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $w(\boldsymbol{x}_{0})\rightarrow\iint\mathrm{d}\boldsymbol{x}\,\frac{\exp\left(-{&#124;\boldsymbol{x}&#124;}^{2}/2\sigma_{\mathrm{G}}^{2}\right)}{\sqrt{2\pi\sigma_{\mathrm{G}}}}w(\boldsymbol{x}_{0}+\boldsymbol{x}).$
    |  | (19) |'
  prefs: []
  type: TYPE_TB
- en: The process of shear map generation from the real HSC catalogue is identical
    to the that from the simulated catalogues. An example shear map from the real
    HSC data with smoothing is shown in Figure [6](#S3.F6 "Figure 6 ‣ 3.6 Shear maps
    ‣ 3 Simulation pipeline ‣ Cosmological constraints from HSC survey first-year
    data using deep learning").
  prefs: []
  type: TYPE_NORMAL
- en: 3.7 Convergence maps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We use the Kaiser–Squires method (Kaiser & Squires, [1993](#bib.bib34)) to convert
    the shear maps from the previous step to convergence maps $\kappa(\boldsymbol{x})$.
    In Fourier space, the shear $\hat{\boldsymbol{\gamma}}(\boldsymbol{\ell})$ and
    the convergence $\hat{\kappa}(\boldsymbol{\ell})$ are related by
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\kappa}(\boldsymbol{\ell})=\frac{\ell_{1}^{2}-\ell_{2}^{2}}{\ell_{1}^{2}+\ell_{2}^{2}}\hat{\gamma_{1}}(\boldsymbol{\ell})+\frac{2\ell_{1}\ell_{2}}{\ell_{1}^{2}+\ell_{2}^{2}}\hat{\gamma_{2}}(\boldsymbol{\ell}).$
    |  | (20) |'
  prefs: []
  type: TYPE_TB
- en: Again, the same conversion is applied to the real HSC shear maps. An example
    convergence map from the HSC data is shown in Figure [6](#S3.F6 "Figure 6 ‣ 3.6
    Shear maps ‣ 3 Simulation pipeline ‣ Cosmological constraints from HSC survey
    first-year data using deep learning"). All of our cosmological analyses will be
    done convergence maps.
  prefs: []
  type: TYPE_NORMAL
- en: 3.8 Intrinsic alignment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The lensing shear from the ray-tracing method in § [3.2](#S3.SS2 "3.2 Ray-tracing
    ‣ 3 Simulation pipeline ‣ Cosmological constraints from HSC survey first-year
    data using deep learning") reproduces the interaction between the light from the
    source galaxy and the foreground matter distribution and the intrinsic ellipticities
    of the galaxies are randomly assigned. But in the real Universe, there can be
    an intrinsic alignment (IA) between the galaxies through two mechanisms: (1) galaxies
    that are physically close to each other tend to have similar ellipticities (intrinsic-intrinsic,
    or II), and (2) a foreground galaxy is correlated with a local matter distribution
    that distorts a background galaxy in the orthogonal direction (gravitational-intrinsic,
    or GI). In this work, we adopt the non-linear alignment model (Hirata & Seljak,
    [2004](#bib.bib30); Bridle & King, [2007](#bib.bib12)) which predicts the power
    spectrum of the IA signal to be'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle P_{\mathrm{IA}}(k,z)$ | $\displaystyle=$ | $\displaystyle
    P_{\mathrm{II}}(k,z)+P_{\mathrm{GI}}(k,z)$ |  | (21) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle F^{2}(z)P_{\delta}(k,z)+F(z)P_{\delta}(k,z),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $F(z)=-A_{\mathrm{IA}}C_{1}\bar{\rho}(z)\frac{D(z)}{D(0)}\left(\frac{1+z}{1+z_{0}}\right)^{\eta}\left(\frac{\bar{L}}{L_{0}}\right)^{\beta}.$
    |  | (22) |'
  prefs: []
  type: TYPE_TB
- en: In Equation ([22](#S3.E22 "In 3.8 Intrinsic alignment ‣ 3 Simulation pipeline
    ‣ Cosmological constraints from HSC survey first-year data using deep learning")),
    $A_{\mathrm{IA}}$ denotes a free parameter that controls the amplitude of IA,
    $C_{1}=5\times 10^{-14}h^{-2}\mathrm{M}_{\odot}^{-1}\mathrm{Mpc}^{3}$ a normalising
    constant, $\bar{\rho}(z)$ the mean matter density of the universe at redshift
    $z$, $D(z)$ the linear growth factor, and $\bar{L}$ the weighted average luminosity
    of the source sample. Following Fluri et al. ([2019](#bib.bib17)) and Hildebrandt
    et al. ([2017](#bib.bib28)), we ignore the redshift and luminosity dependent terms
    by setting $\eta=\beta=0$.
  prefs: []
  type: TYPE_NORMAL
- en: A natural simple choice for the IA-induced convergence field is linked to the
    matter distribution. Specifically, we follow Fluri et al. ([2019](#bib.bib17))
    and adopt
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\kappa_{\mathrm{IA}}^{(b)}(\boldsymbol{x})=\int\mathrm{d}z\,F(z)n_{\mathrm{g}}^{(b)}(z)\delta(\boldsymbol{x},z),$
    |  | (23) |'
  prefs: []
  type: TYPE_TB
- en: where $n_{\mathrm{g}}^{(b)}(z)$ denotes the number of galaxies per redshift
    in the bin $b$ normalised with $\int\mathrm{d}z\,n_{\mathrm{g}}^{(b)}(z)=1$, and
    $\delta(\boldsymbol{x},\chi)$ the density contrast. This IA estimation yields
    the correct IA power spectrum by construction and can be easily incorporated into
    our ray-tracing subroutine. We can trace $\kappa_{\mathrm{IA}}(\boldsymbol{x})$
    along with $\boldsymbol{\gamma}_{\mathrm{IA}}(\boldsymbol{x})$ for each galaxy.
    We note that $\kappa_{\mathrm{IA}}$ and $\boldsymbol{\gamma}_{\mathrm{IA}}$ are
    linearly proportional to $A_{\mathrm{IA}}$, and thus we only need to trace them
    with $A_{\mathrm{IA}}=1$ to get $\tilde{\kappa}_{\mathrm{IA}}(\boldsymbol{x})$
    and $\tilde{\boldsymbol{\gamma}}_{\mathrm{IA}}(\boldsymbol{x})$—results for any
    other $A_{\mathrm{IA}}$ can be inferred via
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\kappa_{\mathrm{IA}}(\boldsymbol{x})=A_{\mathrm{IA}}\tilde{\kappa}_{\mathrm{IA}}(\boldsymbol{x}),\;\boldsymbol{\gamma}_{\mathrm{IA}}(\boldsymbol{x})=A_{\mathrm{IA}}\tilde{\boldsymbol{\gamma}}_{\mathrm{IA}}(\boldsymbol{x}).$
    |  | (24) |'
  prefs: []
  type: TYPE_TB
- en: 'In our analyses where IA is included in the model, we modify the calculation
    of the simulated ellipticity in Equation ([11](#S3.E11 "In 3.5 Simulated ellipticity
    ‣ 3 Simulation pipeline ‣ Cosmological constraints from HSC survey first-year
    data using deep learning")) by doing the following replacement:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\frac{2\boldsymbol{\gamma}\mathcal{R}}{1-\kappa}\rightarrow\frac{2(\boldsymbol{\gamma}+A_{\mathrm{IA}}\tilde{\boldsymbol{\gamma}}_{\mathrm{IA}})\mathcal{R}}{1-(\kappa+A_{\mathrm{IA}}\tilde{\kappa}_{\mathrm{IA}})}.$
    |  | (25) |'
  prefs: []
  type: TYPE_TB
- en: 3.9 PSF error
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f6829c98b9c1c7a1735517a1853bbc5e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: (a) The auto and cross-correlation functions and (b) the auto and
    cross power spectra of the PSF residual terms, where $\tilde{\alpha}_{\mathrm{psf}}=0.030$
    and $\tilde{\beta}_{\mathrm{psf}}=-0.89$. Dashed lines mean that the values are
    negative.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The shape of a galaxy when observed by a ground-based telescope is contaminated
    by effects like atmospheric disturbances and instrument characteristics. They
    can be modelled by a PSF, which modifies the shape of the source through convolution.
    A typical approach to remove the PSF from a galaxy shape involves two steps: (1)
    predict the shape of the PSF at the location of the galaxy using nearby stellar
    images, and (2) apply a PSF deconvolution algorithm, such as the re-Gaussianization
    method in the HSC pipeline. Nevertheless, both steps can still leave small residual
    PSF in the galaxy shapes: (1) the number density of stars is much smaller than
    that of galaxies, thus the variations of PSF on small angular scales can not be
    accurately predicted, and (2) the PSF deconvolution algorithm can have imperfections
    that leaks PSF shape into the deconvolved galaxy shape (Mandelbaum et al., [2018a](#bib.bib51)).
    We follow Hikage et al. ([2019](#bib.bib26)) and Hamana et al. ([2020](#bib.bib22))
    to model PSF residuals as a linear combination of these two effects:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\delta\boldsymbol{\gamma}=\alpha_{\mathrm{psf}}\boldsymbol{\gamma}^{\mathrm{p}}+\beta_{\mathrm{psf}}\boldsymbol{\gamma}^{\mathrm{q}},$
    |  | (26) |'
  prefs: []
  type: TYPE_TB
- en: where $\boldsymbol{\gamma}^{\mathrm{p}}=\boldsymbol{e}^{\mathrm{psf}}/2$ denotes
    the shear associated with the predicted PSF shape, and $\boldsymbol{\gamma}^{\mathrm{q}}=\boldsymbol{\gamma}^{\mathrm{p}}-\boldsymbol{\gamma}_{\mathrm{true}}^{\mathrm{p}}$
    the difference between the predicted PSF shear and the untraceable true PSF shear.
  prefs: []
  type: TYPE_NORMAL
- en: As the small scale variations of PSFs is not recoverable, it is not possible
    to reproduce $\boldsymbol{\gamma}^{\mathrm{q}}$ fields that have identical characteristics
    to the real data. We therefore adopt an alternative approach where we model the
    the PSF residuals as Gaussian random fields, and they can be generated based on
    the auto- and cross-correlation functions between $\boldsymbol{\gamma}^{\mathrm{p}}$
    and $\boldsymbol{\gamma}^{\mathrm{q}}$ measured by Hamana et al. ([2020](#bib.bib22)).
    We choose the correlation functions because they are measured at a higher angular
    scale resolution than the power spectra by Hikage et al. ([2019](#bib.bib26)).
    We fit analytical models to the correlation functions presented in Figure 20 of
    Hamana et al. ([2020](#bib.bib22)) and derive their power spectra counterparts
    ($C^{\mathrm{pp}}$, $C^{\mathrm{pq}}$, and $C^{\mathrm{qq}}$) by the Hankel transform
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $C^{ij}(\ell)=2\pi\int\mathrm{d}\theta\,\theta\,\xi_{+}^{ij}(\theta)J_{0}(\ell\theta).$
    |  | (27) |'
  prefs: []
  type: TYPE_TB
- en: 'Visualisations of the correlation functions and power spectra are shown in
    Figure [7](#S3.F7 "Figure 7 ‣ 3.9 PSF error ‣ 3 Simulation pipeline ‣ Cosmological
    constraints from HSC survey first-year data using deep learning"). The total PSF
    error power spectrum is a linear combination of the three components:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $C^{\mathrm{psf}}(\ell)=\alpha_{\mathrm{psf}}^{2}C^{\mathrm{pp}}(\ell)+2\alpha_{\mathrm{psf}}\beta_{\mathrm{psf}}C^{\mathrm{pq}}(\ell)+\beta_{\mathrm{psf}}^{2}C^{\mathrm{qq}}(\ell),$
    |  | (28) |'
  prefs: []
  type: TYPE_TB
- en: 'where the nuisance parameters $\alpha$ and $\beta$ have Gaussian priors derived
    from Figure 21 in Hamana et al. ([2020](#bib.bib22)) with all angular scales:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\alpha_{\mathrm{psf}}\sim\mathcal{N}(0.030,0.015),\;\beta_{\mathrm{psf}}\sim\mathcal{N}(-0.89,0.70).$
    |  | (29) |'
  prefs: []
  type: TYPE_TB
- en: After the convergence maps are generated for a realisation (see Section [3.7](#S3.SS7
    "3.7 Convergence maps ‣ 3 Simulation pipeline ‣ Cosmological constraints from
    HSC survey first-year data using deep learning")), we sample $\alpha_{\mathrm{psf}}$
    and $\beta_{\mathrm{psf}}$ from their prior distributions and generate one PSF
    convergence map for each sub-field, which is added to the convergence maps for
    all redshift bins.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Summary statistics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1 Convolutional neural network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 4.1.1 Overview
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Considering that our simulation pipeline is a function that generates maps
    from parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\textrm{pipeline: }(\boldsymbol{\theta},\boldsymbol{\nu},\boldsymbol{r})\rightarrow\kappa,$
    |  | (30) |'
  prefs: []
  type: TYPE_TB
- en: 'where $\boldsymbol{\theta}\equiv(p_{1},\cdots,p_{N})$ denotes the parameters
    of interest, $\boldsymbol{\nu}$ the nuisance parameters, and $\boldsymbol{r}$
    the random variables, we train a *summarising CNN* to be a function that predicts
    the parameters of interest given a map:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\textrm{CNN: }\kappa\rightarrow\boldsymbol{y},$ |  | (31) |'
  prefs: []
  type: TYPE_TB
- en: where the weights of the CNN are adjusted so that $\boldsymbol{y}$ is close
    to $\boldsymbol{\theta}$, or more rigorously, minimising a *loss function* $L(\boldsymbol{y},\boldsymbol{\theta})$.
    Here, we note that although the CNN is trained with the goal of reproducing the
    parameters of the input map by its outputs, those outputs usually come with large
    biases (see e.g. Gupta et al., [2018](#bib.bib20); Ribli et al., [2019](#bib.bib63);
    Lu et al., [2022](#bib.bib50)), so they should not be used as estimations of those
    parameters. Instead, we view the output of the CNN as another summary statistic,
    and we derive a likelihood function $\mathcal{L}(\boldsymbol{y}|\boldsymbol{\theta})$
    from the predictions regardless of the meaning of its outputs, effectively marginalising
    over the nuisance parameters and randomness. A neural network-based summary statistic
    works in a similar way to traditional statistics such as power spectra and peak
    counts in that they all take a convergence map (or maps) as the input and generate
    an array of numbers as the output. The difference is that a neural network has
    millions of free parameters (called “weights”) that need to be determined through
    a training process. Using the CNNs in this way has been investigated in multiple
    studies (see Gupta et al., [2018](#bib.bib20); Ribli et al., [2019](#bib.bib63);
    Fluri et al., [2019](#bib.bib17), [2022](#bib.bib18); Lu et al., [2022](#bib.bib50)).
  prefs: []
  type: TYPE_NORMAL
- en: The CNN is often trained on a data set with a finite number of maps for multiple
    rounds. It is possible that the network over-fits to the training set, i.e. learning
    some irrelevant features out of randomness which only work on the training set.
    So it is important that we use a different set of maps, which have never been
    seen by the network, for the derivation of the likelihood function.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.2 Map smoothing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The weak lensing signals on very small angular scales are often discarded for
    a few reasons: (1) the modelling of baryonic effects is not well-known, (2) the
    non-linear alignment model underestimates the IA signal on small scales, (3) the
    PSF modelling error becomes comparable to the lensing signal at low redshifts,
    and (4) very small scales are not very informative due to shape noise (Fang &
    Haiman, [2007](#bib.bib16); Singh et al., [2015](#bib.bib66); Hikage et al., [2019](#bib.bib26);
    Aricò et al., [2020](#bib.bib8)). For example, Hikage et al. ([2019](#bib.bib26))
    adopts $\ell_{\mathrm{max}}=1900$ in their fiducial analysis ($\theta_{\mathrm{min}}\sim
    6\,\mathrm{arcmin}$), and Hamana et al. ([2020](#bib.bib22)) adopts $\theta_{\mathrm{min}}=7\,\mathrm{arcmin}$
    for $\xi_{+}(\theta)$. To be consistent with these two studies, we apply smoothing
    with Gaussian filters to our simulated maps (see Section [3.6](#S3.SS6 "3.6 Shear
    maps ‣ 3 Simulation pipeline ‣ Cosmological constraints from HSC survey first-year
    data using deep learning")) so that the CNN will not learn from the fluctuations
    on small scales which are not well-understood. Our fiducial analysis uses a smoothing
    radius of $\sigma_{\mathrm{G}}=4\,\mathrm{arcmin}$, which suppress the power by
    90 percent (i.e. 10 percent of the power remaining) at $\ell=1400$ and by 99 percent
    at $\ell=2000$, comparable to the fiducial analysis in Hikage et al. ([2019](#bib.bib26)).
    We will also perform analysis with other smoothing scales $\sigma_{\mathrm{G}}=1\text{--}8\,\mathrm{arcmin}$
    (99 percent suppression at $\ell=8000\text{--}1000$) to see how the statistical
    errors change.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.3 Architecture
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Layer/ | Kernel | Stride | Output |'
  prefs: []
  type: TYPE_TB
- en: '| block | size |  | dimension |'
  prefs: []
  type: TYPE_TB
- en: '| (Input) |  |  | $4\times 104\times 104$ |'
  prefs: []
  type: TYPE_TB
- en: '| Convolution | $7\times 7$ | 2 | $n_{\mathrm{ch}}\times 52\times 52$ |'
  prefs: []
  type: TYPE_TB
- en: '| Residual block 1 | $-$ | $-$ | $n_{\mathrm{ch}}\times 52\times 52$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\vdots$ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Residual block $n_{\mathrm{block}}$ | $-$ | $-$ | $n_{\mathrm{ch}}\times
    52\times 52$ |'
  prefs: []
  type: TYPE_TB
- en: '| Pooling | $2\times 2$ | 2 | $n_{\mathrm{ch}}\times 26\times 26$ |'
  prefs: []
  type: TYPE_TB
- en: '| Convolution | $3\times 3$ | 1 | $(2\,n_{\mathrm{ch}})\times 24\times 24$
    |'
  prefs: []
  type: TYPE_TB
- en: '| Pooling | $2\times 2$ | 2 | $(2\,n_{\mathrm{ch}})\times 12\times 12$ |'
  prefs: []
  type: TYPE_TB
- en: '| Convolution | $3\times 3$ | 1 | $(4\,n_{\mathrm{ch}})\times 10\times 10$
    |'
  prefs: []
  type: TYPE_TB
- en: '| Pooling | $2\times 2$ | 2 | $(4\,n_{\mathrm{ch}})\times 5\times 5$ |'
  prefs: []
  type: TYPE_TB
- en: '| Convolution | $3\times 3$ | 1 | $(8\,n_{\mathrm{ch}})\times 3\times 3$ |'
  prefs: []
  type: TYPE_TB
- en: '| Pooling | $3\times 3$ | 2 | $(8\,n_{\mathrm{ch}})\times 1\times 1$ |'
  prefs: []
  type: TYPE_TB
- en: '| Linear | $-$ | $-$ | $256$ |'
  prefs: []
  type: TYPE_TB
- en: '| ReLU | $-$ | $-$ | $256$ |'
  prefs: []
  type: TYPE_TB
- en: '| Linear | $-$ | $-$ | $N_{\theta}$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: The architecture of the CNNs. Here $n_{\mathrm{ch}}$ (number of channels)
    and $n_{\mathrm{block}}$ (number of residual blocks) are hyper-parameters. Convolution
    layers, except those in the residual blocks, are implicitly followed by batch
    normalisation layers and then ReLU layers.'
  prefs: []
  type: TYPE_NORMAL
- en: Similar to our previous work (Lu et al., [2022](#bib.bib50)), we employ a CNN
    architecture with residual blocks (He et al., [2016](#bib.bib24)), as is shown
    in Table [3](#S4.T3 "Table 3 ‣ 4.1.3 Architecture ‣ 4.1 Convolutional neural network
    ‣ 4 Summary statistics ‣ Cosmological constraints from HSC survey first-year data
    using deep learning"). A residual block consists of a $3\times 3$ convolution
    layer, a batch normalisation layer, a rectified linear (ReLU) layer, another $3\times
    3$ convolution layer, a batch normalisation layer, and a ReLU layer in series,
    with a skip connection that add the residual block input to the intermediate result
    prior to the last ReLU layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The input to the CNN is the convergence maps of the four redshift bins with
    the padding removed, thus it is an array with dimension $4\times 104\times 104$,
    representing a sub-field with $3\times 3\,\mathrm{{deg}^{2}}$ in size. The output
    from the CNN is a list of $N_{\theta}$ numbers, where $N_{\theta}=3$ when we adopt
    a model with only cosmological parameters ($\Omega_{\mathrm{m}}$, $\sigma_{8}$,
    $A_{\mathrm{IA}}$) being free, or $N_{\theta}=7$ when we adopt a model with four
    additional free baryonic parameters ($M_{\mathrm{c}}$, $M_{1,0}$, $\eta$, $\beta$).
    The network has two hyper-parameters: the number of map channels in residual blocks
    $n_{\mathrm{ch}}$ and the number of residual blocks $n_{\mathrm{block}}$. Our
    main models as presented in Section [6](#S6 "6 Cosmological constraints ‣ Cosmological
    constraints from HSC survey first-year data using deep learning") and Section [7](#S7
    "7 Discussion ‣ Cosmological constraints from HSC survey first-year data using
    deep learning") uses $n_{\mathrm{ch}}=64$ and $n_{\mathrm{block}}=10$; models
    with other choices are discussed in Section [7.1](#S7.SS1 "7.1 CNN hyper-parameters
    ‣ 7 Discussion ‣ Cosmological constraints from HSC survey first-year data using
    deep learning").'
  prefs: []
  type: TYPE_NORMAL
- en: The loss function of the CNN is
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $L(\boldsymbol{y},\boldsymbol{\theta})=\frac{1}{N_{\theta}}\sum_{i=1}^{N_{\theta}}{\left(y_{i}-\theta_{i}\right)^{2}},$
    |  | (32) |'
  prefs: []
  type: TYPE_TB
- en: 'where $N_{\theta}$ denotes the number of parameters (3 or 7), $\theta_{i}$
    the value of the $i^{\text{th}}$ parameter with the following normalisation: (a)
    $\Omega_{\mathrm{m}}$ retain its original value, (b) $\sigma_{8}$ is replaced
    by $S_{8}$, (c) $A_{\mathrm{IA}}$ is divided by a factor of $10$, and (d) the
    baryonic parameters ($M_{\mathrm{c}}$, $M_{1,0}$, $\eta$, $\beta$) are scaled
    such that their prior ranges map to $[0.0,0.5]$ after taking their logarithm.
    With normalisation, the value ranges of all parameters are around 0.5, which helps
    the convergence of the network.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.4 Training
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For the analyses without baryonic effects or with a fixed baryonic model ($N_{\theta}=3$),
    we generate 800 ray-tracing realisations per cosmology ($1.2\times 10^{6}$ maps
    in total) for training. For the analyses with free baryonic parameters, we generate
    1600 ray-tracing realisations ($2.4\times 10^{6}$ maps in total), where the baryonic
    parameters are randomly chosen according to a Sobol sequence (Sobol’, [1967](#bib.bib67))
    in the 4-dimensional hypercube such that each parameter follows a log-uniform
    distribution across its prior range. The post processing steps, including the
    addition of shape noise, IA, $\Delta m$, and PSF error, are applied on the fly,
    meaning that different maps will be generated during each visit to the same ray-tracing
    realisation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The network is trained with the Adam optimiser (Kingma & Ba, [2014](#bib.bib37))
    with $\beta_{1}=0.9$ and $\beta_{2}=0.999$ for eight epochs: the first five epochs
    use a learning rate of $\alpha=10^{-3}$, then the learning rate is decreased by
    a factor 10 at the beginning of each of the rest three epochs. We have verified
    that for the networks used in this study, these numbers of training epochs are
    sufficient for the training losses to converge at each learning rate stage. In
    each training step, the network takes batches of 256 tomographic convergence maps
    distributed across four graphics processing units (GPUs). The training runs were
    performed on the TACC Frontera cluster using four Quadro RTX 5000 GPUs, with each
    run taking three to five hours depending on network hyper-parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Cross power spectra and tomographic peak counts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition to the CNN, we also perform analyses with cross power spectra and
    tomographic peak counts on the same set of convergence maps, so that we can fairly
    compare their qualities.
  prefs: []
  type: TYPE_NORMAL
- en: 'The cross power spectrum between the convergence maps of two redshift bins
    $j$ and $k$ ($1\leq j\leq k\leq 4$) is measured by:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $C^{jk}(i)=\frac{1}{N_{\mathrm{mode},i}}\sum_{\ell_{i}\leq&#124;\boldsymbol{\ell}&#124;<\ell_{i+1}}C^{jk}(\boldsymbol{\ell}),$
    |  | (33) |'
  prefs: []
  type: TYPE_TB
- en: where $i=1,\cdots,8$ denote the indices of the multipole bins, $\ell_{i}=10^{2.4+i/10}$
    the boundaries of the bins, $N_{\mathrm{mode},i}$ the number of multipole modes
    in the $i^{\mathrm{th}}$ bin, $C^{jk}(\boldsymbol{\ell})$ the cross power spectrum
    at multipole $\boldsymbol{\ell}$. The multipole range of the measured cross power
    spectra is $316<\ell<1995$, comparable to that in Hikage et al. ([2019](#bib.bib26)).
    Across all ten pairs of the redshift bins, the cross power spectra of a tomographic
    convergence map produces a data vector with 80 numbers.
  prefs: []
  type: TYPE_NORMAL
- en: The peak counts of a convergence map in a redshift bin is defined to be the
    histogram of all peak values in the map, where a pixel is a peak if and only if
    its $\kappa$ value is greater than all eight of its neighbours. We smooth the
    maps by a Gaussian kernel with radius $\sigma_{\mathrm{G}}=2\,\mathrm{arcmin}$
    to remove small scale fluctuations. By inspecting the convergence maps at the
    fiducial cosmology, we find the typical standard deviations of $\kappa$ across
    the maps are $\sigma_{\kappa}=0.015,0.016,0.019,0.025$ in the four redshift bins
    (low to high) respectively. Then number of peaks are counted in 20 equally-spaced
    $\kappa$ bins in the range of $-1\,\sigma_{\kappa}^{(b)}\leq\kappa\leq 4\,\sigma_{\kappa}^{(b)}$,
    with the width of each bin being $0.25\,\sigma_{\kappa}^{(b)}$ for the $b^{\text{th}}$
    redshift bin.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Parameter inference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will describe in detail the process of inferring the cosmological
    parameters and, in some analyses, the baryonic parameters using summary statistics.
    We infer the parameters by comparing the target data vector, which can come from
    the simulations or the real data, to the model from our simulation pipeline. Note
    that this procedure is different from Hikage et al. ([2019](#bib.bib26)) and Hamana
    et al. ([2020](#bib.bib22)), where they primarily rely on theoretical predictions
    to construct the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first generate 800 ray-tracing realisations per cosmology from our pipeline,
    for each variation of baryonic modelling (no baryon, fiducial parameters, and
    free parameters). We note that these set of realisations are different from those
    being used to train the CNN in Section [4.1.4](#S4.SS1.SSS4 "4.1.4 Training ‣
    4.1 Convolutional neural network ‣ 4 Summary statistics ‣ Cosmological constraints
    from HSC survey first-year data using deep learning"). Then, we apply a summary
    statistic to all of the simulated tomographic convergence maps and compute one
    data vector per realisation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\boldsymbol{y}_{r}(\boldsymbol{\theta})=\frac{1}{N_{\mathrm{field}}}\sum_{s=1}^{N_{\mathrm{field}}}f\left(\kappa_{r}^{(s)}(\boldsymbol{\theta},\boldsymbol{x})\right),$
    |  | (34) |'
  prefs: []
  type: TYPE_TB
- en: 'where $N_{\mathrm{field}}=19$ denotes the number of sub-fields, $f$ the summary
    statistic, and $\kappa_{r}^{(s)}(\boldsymbol{\theta},\boldsymbol{x})$ the tomographic
    convergence map for the $r^{\text{th}}$ realisation and $s^{\text{th}}$ sub-field
    in the model with parameters $\boldsymbol{\theta}$. We evaluate $\boldsymbol{y}_{r}(\boldsymbol{\theta})$
    at following discrete $\theta$ values:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: for all $r$, $(\Omega_{\mathrm{m}},\sigma_{8})$ is one of the simulated cosmologies
    in Section [3.1](#S3.SS1 "3.1 N-body simulation setup ‣ 3 Simulation pipeline
    ‣ Cosmological constraints from HSC survey first-year data using deep learning");
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: for all $r$, $A_{\mathrm{IA}}=-3.0,-2.5,-2.0,\cdots,3.0$;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: for a specific $r$, the four baryonic parameters take the values of the $r^{\text{th}}$
    term in the Sobol sequence as in Section [4.1.4](#S4.SS1.SSS4 "4.1.4 Training
    ‣ 4.1 Convolutional neural network ‣ 4 Summary statistics ‣ Cosmological constraints
    from HSC survey first-year data using deep learning").
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Additionally, the target data vector $\boldsymbol{y}$ is calculated in the same
    way.
  prefs: []
  type: TYPE_NORMAL
- en: 'We model the likelihood of observing the data vector $\boldsymbol{y}$ given
    the parameters $\boldsymbol{\theta}$ as a multi-dimensional normal distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle p(\boldsymbol{y}&#124;\boldsymbol{\theta})\propto\frac{1}{\sqrt{\det\boldsymbol{\mathsf{C}}(\boldsymbol{\theta})}}\exp\left(-\frac{1}{2}\Delta\boldsymbol{y}^{\mathrm{T}}\tilde{\boldsymbol{\mathsf{C}}}^{-1}\Delta\boldsymbol{y}\right),$
    |  | (35) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\Delta\boldsymbol{y}=\boldsymbol{y}-\langle\boldsymbol{y}_{r}\rangle(\boldsymbol{\theta}),$
    |  | (36) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\tilde{\boldsymbol{\mathsf{C}}}^{-1}\equiv\frac{N_{\mathrm{sim}}-N_{\mathrm{theta}}-2}{N_{\mathrm{sim}}-1}\boldsymbol{\mathsf{C}}(\boldsymbol{\theta})^{-1},$
    |  | (37) |'
  prefs: []
  type: TYPE_TB
- en: where $\boldsymbol{\mathsf{C}}(\boldsymbol{\theta})$ is the covariance of $\boldsymbol{y}_{r}(\boldsymbol{\theta})$,
    $N_{\mathrm{sim}}=800$ the number of simulated realisations, and $N_{\mathrm{theta}}$
    the number of dimensions in the data vector (3 or 7 for the CNN and 80 for power
    spectra and peak counts). The summary statistics of 800 realisations from a single
    $500h^{-1}\mathrm{Mpc}$ $N$-body simulation can be considered statistically independent
    (Petri et al., [2016](#bib.bib56)), and the pre-factor in Equation ([37](#S5.E37
    "In 5 Parameter inference ‣ Cosmological constraints from HSC survey first-year
    data using deep learning")) is the Anderson-Hartlap correction factor (Hartlap
    et al., [2007](#bib.bib23)) that makes the precision matrix $\tilde{\boldsymbol{\mathsf{C}}}^{-1}$
    unbiased. Previous studies (see e.g. Lin & Kilbinger, [2015](#bib.bib46); Gupta
    et al., [2018](#bib.bib20); Lu et al., [2022](#bib.bib50)) have shown that the
    data vectors following multi-dimensional normal distributions is a reasonable
    assumption for parameter inference from either the peaks counts or from the outputs
    of the CNNs.
  prefs: []
  type: TYPE_NORMAL
- en: Since $\boldsymbol{y}_{r}(\boldsymbol{\theta})$ are only available at discrete
    $\boldsymbol{\theta}$ values, we need to interpolate between them so that $\langle\boldsymbol{y}_{r}\rangle$
    and $\boldsymbol{\mathsf{C}}$ can cover the entire parameter space. To avoid numerical
    instability, we interpolate the elements in the Cholesky decomposition of the
    covariance matrix, and we can reconstruct the interpolated covariance matrix by
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\boldsymbol{\mathsf{C}}}(\boldsymbol{\theta})=\hat{\boldsymbol{\mathsf{L}}}(\boldsymbol{\theta})\hat{\boldsymbol{\mathsf{L}}}^{\mathrm{T}}(\boldsymbol{\theta}),$
    |  | (38) |'
  prefs: []
  type: TYPE_TB
- en: 'where $\hat{\boldsymbol{\mathsf{L}}}(\boldsymbol{\theta})$ is the interpolated
    Cholesky decomposition. For the model without free baryonic parameters, we find
    that a second-order polynomial fit to each element with respect to $A_{\mathrm{IA}}$
    at each cosmology is sufficient:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $v_{i}(A_{\mathrm{IA}})=a_{i}+b_{i}A_{\mathrm{IA}}+c_{i}A_{\mathrm{IA}}^{2}+\epsilon,$
    |  | (39) |'
  prefs: []
  type: TYPE_TB
- en: where $v_{i}$ is one of the interpolated values, $(a_{i},b_{i},c_{i})$ the polynomial
    coefficients, and $\epsilon$ a small unspecified error term. Then, $a_{i}$, $b_{i}$,
    and $c_{i}$ are interpolated linearly between the cosmologies with Delaunay triangulation
    (see Figure [4](#S3.F4 "Figure 4 ‣ 3.1 N-body simulation setup ‣ 3 Simulation
    pipeline ‣ Cosmological constraints from HSC survey first-year data using deep
    learning")). For the model with free baryonic parameters, additional linear terms
    with respect to the baryonic parameters are added to the polynomial to fit $\langle\boldsymbol{y}_{r}\rangle$
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle v_{i}(A_{\mathrm{IA}},M_{\mathrm{c}},M_{1,0},\eta,\beta)=a_{i}+b_{i}A_{\mathrm{IA}}+c_{i}A_{\mathrm{IA}}^{2}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle+d_{i}M_{\mathrm{c}}+e_{i}M_{1,0}+f_{i}\eta+g_{i}\beta+\epsilon,$
    |  | (40) |'
  prefs: []
  type: TYPE_TB
- en: where the polynomial coefficients are interpolated between the cosmologies.
    For the covariance matrices, we reuse the values interpolated from the fiducial
    baryonic model, which means that the covariance is constant with respect to the
    baryonic parameters.
  prefs: []
  type: TYPE_NORMAL
- en: With the calculation of the likelihood function $p(\boldsymbol{y}|\boldsymbol{\theta})$
    ready, we derive the posterior distribution with Bayes’ theorem
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $p(\boldsymbol{\theta}&#124;\boldsymbol{y})\propto p(\boldsymbol{y}&#124;\boldsymbol{\theta})\,p(\boldsymbol{\theta}),$
    |  | (41) |'
  prefs: []
  type: TYPE_TB
- en: where $p(\boldsymbol{\theta})$ is the prior distribution, as summarised in Table [2](#S3.T2
    "Table 2 ‣ 3.4 Baryonic model ‣ 3 Simulation pipeline ‣ Cosmological constraints
    from HSC survey first-year data using deep learning"). We sample the posterior
    distribution with a Monte Carlo Markov (MCMC) chain of $5\times 10^{6}$ steps,
    which is sufficient for the chains to converge.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Cosmological constraints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Name | Target data vector | Summary | Baryonic | IA | $\Delta z$,$\Delta
    m$, | Other | Section |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  | calculated with | Statistics | model |  | PSF | treatments |  |'
  prefs: []
  type: TYPE_TB
- en: '| mock | T17 mock catalogues | All | None |  |  |  | [6.1](#S6.SS1 "6.1 Constraints
    with T17 mock catalogues ‣ 6 Cosmological constraints ‣ Cosmological constraints
    from HSC survey first-year data using deep learning") |'
  prefs: []
  type: TYPE_TB
- en: '| no-systematics | Our fiducial catalogues | All | None |  |  |  | [6.1](#S6.SS1
    "6.1 Constraints with T17 mock catalogues ‣ 6 Cosmological constraints ‣ Cosmological
    constraints from HSC survey first-year data using deep learning") |'
  prefs: []
  type: TYPE_TB
- en: '| hsc-default | HSC catalogue | All | None | ✓ | ✓ |  | [6.2](#S6.SS2 "6.2
    Constraints with the HSC catalogue ‣ 6 Cosmological constraints ‣ Cosmological
    constraints from HSC survey first-year data using deep learning") |'
  prefs: []
  type: TYPE_TB
- en: '| hsc-no-ia | HSC catalogue | All | None |  | ✓ |  | [6.2](#S6.SS2 "6.2 Constraints
    with the HSC catalogue ‣ 6 Cosmological constraints ‣ Cosmological constraints
    from HSC survey first-year data using deep learning") |'
  prefs: []
  type: TYPE_TB
- en: '| hsc-fid-baryon | HSC catalogue | All | Fiducial | ✓ | ✓ |  | [6.2](#S6.SS2
    "6.2 Constraints with the HSC catalogue ‣ 6 Cosmological constraints ‣ Cosmological
    constraints from HSC survey first-year data using deep learning") |'
  prefs: []
  type: TYPE_TB
- en: '| hsc-free-baryon | HSC catalogue | All | Free | ✓ | ✓ |  | [6.2](#S6.SS2 "6.2
    Constraints with the HSC catalogue ‣ 6 Cosmological constraints ‣ Cosmological
    constraints from HSC survey first-year data using deep learning") |'
  prefs: []
  type: TYPE_TB
- en: '| bootstrap | Our fiducial catalogues | All | None | ✓ | ✓ |  | [7](#S7 "7
    Discussion ‣ Cosmological constraints from HSC survey first-year data using deep
    learning") |'
  prefs: []
  type: TYPE_TB
- en: '| gaussian | Our fiducial catalogues | CNN | None | ✓ | ✓ | Convert to GRFs
    | [7.3](#S7.SS3 "7.3 Non-Gaussian information ‣ 7 Discussion ‣ Cosmological constraints
    from HSC survey first-year data using deep learning") |'
  prefs: []
  type: TYPE_TB
- en: '| smoothing | Our fiducial catalogues | CNN | None | ✓ | ✓ | Various smoothing
    scales | [7.2](#S7.SS2 "7.2 Map smoothing scale ‣ 7 Discussion ‣ Cosmological
    constraints from HSC survey first-year data using deep learning") |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: The configurations of the MCMC sampling runs.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we present the cosmological and baryonic constraints using
    our pipeline in Section [3](#S3 "3 Simulation pipeline ‣ Cosmological constraints
    from HSC survey first-year data using deep learning") and the parameter inference
    method in Section [5](#S5 "5 Parameter inference ‣ Cosmological constraints from
    HSC survey first-year data using deep learning"). In addition to the real HSC
    catalogue, we will also use T17 mock catalogues (see Section [2.2](#S2.SS2 "2.2
    T17 mock shear catalogues ‣ 2 catalogue preparation ‣ Cosmological constraints
    from HSC survey first-year data using deep learning")) and our own simulated catalogues
    from the fiducial cosmology to construct the target data vector ($\boldsymbol{y}$
    in Equation ([36](#S5.E36 "In 5 Parameter inference ‣ Cosmological constraints
    from HSC survey first-year data using deep learning"))), so that we can validate
    our model and testing methods and effects. Hereafter, we will use the terms “with
    the HSC catalog”, “with T17 mock catalogues”, and “with our fiducial catalogues”
    to represent those target data vector choices respectively. The specification
    of all MCMC sampling runs are summarised in Table [4](#S6.T4 "Table 4 ‣ 6 Cosmological
    constraints ‣ Cosmological constraints from HSC survey first-year data using deep
    learning"). In this work, we characterise the constraint of a parameter by the
    $16^{\text{th}}$ percentile $a$, median $b$, and $84^{\text{th}}$ percentile $c$
    of the posterior distribution in the form of $b_{a-b}^{c-b}$, and the statistical
    error refers to the difference $c-a$, which corresponds to the difference between
    $-1\sigma$ and $+1\sigma$ in a normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Constraints with T17 mock catalogues
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9d82ba2412381bf8d9233f6fae8bcf58.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Posterior distributions with the target data vectors calculated from
    our own catalogues at the fiducial cosmology ($\Omega_{\mathrm{m}}=0.3$, $S_{8}=0.8$)
    and those from T17 mock catalogues ($\Omega_{\mathrm{m}}=0.279$, $S_{8}=0.791$).
    The solid and dashed lines shows the 68 percent and 95 percent credible contours.'
  prefs: []
  type: TYPE_NORMAL
- en: First, we compare our simulation pipeline to the T17 mock simulations by constraining
    the cosmological parameters with the T17 mock catalogues generated in Section [2.2](#S2.SS2
    "2.2 T17 mock shear catalogues ‣ 2 catalogue preparation ‣ Cosmological constraints
    from HSC survey first-year data using deep learning"). Specifically, we calculate
    the data vector for each mock catalogue realisation and use the average data vector
    as the target data vector in Equation ([36](#S5.E36 "In 5 Parameter inference
    ‣ Cosmological constraints from HSC survey first-year data using deep learning")).²²2A
    more rigorous comparison can be made by setting the target data vector to the
    data vector from each realisation and summarising the properties of the posterior
    distributions, instead of using a single averaged data vector. We show the posterior
    distributions in Figure [8](#S6.F8 "Figure 8 ‣ 6.1 Constraints with T17 mock catalogues
    ‣ 6 Cosmological constraints ‣ Cosmological constraints from HSC survey first-year
    data using deep learning"), together with the constraints where the data vector
    is calculated with our own simulated catalogues at the fiducial cosmology. Here,
    we use the configurations mock and no-systematics, where the IAs, baryons, and
    other systematics are not included, because non of these are added to T17 mock
    catalogues. To make the contours easier to read, we plot $S_{8}$ instead of $\sigma_{8}$
    in Figure [8](#S6.F8 "Figure 8 ‣ 6.1 Constraints with T17 mock catalogues ‣ 6
    Cosmological constraints ‣ Cosmological constraints from HSC survey first-year
    data using deep learning") and hereafter.
  prefs: []
  type: TYPE_NORMAL
- en: We find that the posterior distribution from our fiducial catalogues and that
    from T17 simulations are very similar other than small translations. In terms
    of the marginal distributions of $S_{8}$, the median $S_{8}$ values from the T17
    mock catalogues are lower than that from our fiducial cosmology by $3.5\times
    10^{-3}$, $6.4\times 10^{-3}$, and $3.7\times 10^{-3}$ for the power spectrum,
    peak counts, and CNN respectively. In comparison, the actual $S_{8}$ difference
    from cosmological parameters of the simulations is $\Delta S_{8}=9.2\times 10^{-3}$—the
    discrepancy is very small relative to the statistical error of $S_{8}$. We conclude
    that our model prediction and parameter inference pipelines passed this validation
    step.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we note that the contours from our fiducial catalogues (the solid
    contours in Figure [8](#S6.F8 "Figure 8 ‣ 6.1 Constraints with T17 mock catalogues
    ‣ 6 Cosmological constraints ‣ Cosmological constraints from HSC survey first-year
    data using deep learning")) are in general not centred around $\Omega_{\mathrm{m}}=0.3$
    and $S_{8}=0.8$. In particular for the power spectrum, the maximum likelihood
    is reached at $(\Omega_{\mathrm{m}}=0.290,S_{8}=0.786)$. The reason is that the
    determinant of the covariance matrix varies across the cosmological parameter
    space, which affects the posterior probability in the prefactor of Equation ([35](#S5.E35
    "In 5 Parameter inference ‣ Cosmological constraints from HSC survey first-year
    data using deep learning")). This phenomenon is especially significant for the
    power spectrum because the determinant decreases by a factor of two when $S_{8}$
    increases from 0.796 to 0.804 (a one percent increase).
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Constraints with the HSC catalogue
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/34432bbbc6c8c72251377a454a2c2f99.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Posterior distributions based on the HSC data in the model without
    baryons (top panel), and its conditional distribution with $A_{\mathrm{IA}}=0$
    (bottom panel).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2fbda0e80bdc51649a772c025c34ea37.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Posterior distributions based on the HSC data in the model with
    fiducial baryonic parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4c3fc7e585b975b004939acd8573a031.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Posterior distributions based on the HSC data in the model with
    free baryonic parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Summary statistic | $\Omega_{\mathrm{m}}$ | $S_{8}$ | $A_{\mathrm{IA}}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Default (no baryon) | Power spectrum | ${0.211}_{-0.072}^{+0.105}\;(1.00)$
    | ${0.787}_{-0.023}^{+0.023}\;(1.00)$ | ${-0.07}_{-0.99}^{+0.75}\;(1.00)$ |'
  prefs: []
  type: TYPE_TB
- en: '| Peak counts | ${0.254}_{-0.042}^{+0.072}\;(0.64)$ | ${0.800}_{-0.023}^{+0.025}\;(1.03)$
    | ${1.10}_{-1.31}^{+1.15}\;(1.41)$ |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | ${0.278}_{-0.035}^{+0.037}\;(0.41)$ | ${0.793}_{-0.017}^{+0.018}\;(0.76)$
    | ${0.20}_{-0.58}^{+0.55}\;(0.65)$ |'
  prefs: []
  type: TYPE_TB
- en: '| No IA ($A_{\mathrm{IA}}=0$) | Power spectrum | ${0.235}_{-0.063}^{+0.111}\;(1.00)$
    | ${0.794}_{-0.022}^{+0.022}\;(1.00)$ | – |'
  prefs: []
  type: TYPE_TB
- en: '| Peak counts | ${0.218}_{-0.039}^{+0.049}\;(0.51)$ | ${0.803}_{-0.024}^{+0.025}\;(1.12)$
    | – |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | ${0.281}_{-0.029}^{+0.031}\;(0.35)$ | ${0.793}_{-0.017}^{+0.018}\;(0.80)$
    | – |'
  prefs: []
  type: TYPE_TB
- en: '| Fiducial baryonic model | Power spectrum | ${0.290}_{-0.087}^{+0.115}\;(1.00)$
    | ${0.820}_{-0.026}^{+0.025}\;(1.00)$ | ${0.18}_{-0.82}^{+0.61}\;(1.00)$ |'
  prefs: []
  type: TYPE_TB
- en: '| Peak counts | ${0.278}_{-0.051}^{+0.063}\;(0.57)$ | ${0.819}_{-0.026}^{+0.029}\;(1.08)$
    | ${1.11}_{-1.28}^{+1.14}\;(1.70)$ |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | ${0.250}_{-0.031}^{+0.036}\;(0.33)$ | ${0.826}_{-0.019}^{+0.020}\;(0.77)$
    | ${-0.04}_{-0.61}^{+0.58}\;(0.83)$ |'
  prefs: []
  type: TYPE_TB
- en: '| Free baryonic model | Power spectrum | ${0.259}_{-0.083}^{+0.139}\;(1.00)$
    | ${0.816}_{-0.030}^{+0.031}\;(1.00)$ | ${0.08}_{-0.98}^{+0.68}\;(1.00)$ |'
  prefs: []
  type: TYPE_TB
- en: '| Peak counts | ${0.268}_{-0.047}^{+0.082}\;(0.58)$ | ${0.822}_{-0.029}^{+0.034}\;(1.04)$
    | ${1.07}_{-1.32}^{+1.19}\;(1.51)$ |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | ${0.268}_{-0.036}^{+0.040}\;(0.35)$ | ${0.819}_{-0.024}^{+0.034}\;(0.95)$
    | ${-0.16}_{-0.58}^{+0.59}\;(0.71)$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5: Cosmological constraints with the HSC catalogue in various models.
    The numbers in the parentheses show the statistical errors of the constraints
    relative to those by the power spectrum.'
  prefs: []
  type: TYPE_NORMAL
- en: In our fiducial analysis (hsc-default), we include the all of systematic effects
    except the baryonic effects, as in Hikage et al. ([2019](#bib.bib26)). The posterior
    distributions of $\Omega_{\mathrm{m}}$, $\sigma_{8}$, and $A_{\mathrm{IA}}$ for
    the three methods are shown in Figure [9](#S6.F9 "Figure 9 ‣ 6.2 Constraints with
    the HSC catalogue ‣ 6 Cosmological constraints ‣ Cosmological constraints from
    HSC survey first-year data using deep learning"). Note that we again replace $\sigma_{8}$
    by $S_{8}$ in the plots for the clarity of the contours. We find $S_{8}=0.787_{-0.023}^{+0.023}$
    from the power spectrum, $S_{8}=0.800_{-0.023}^{+0.025}$ from the peak counts,
    and $S_{8}=0.793_{-0.018}^{+0.017}$ from the CNN. These values fall between the
    results in previous HSC studies—$S_{8}(\alpha=0.5)=0.780_{-0.033}^{+0.030}$ (Hikage
    et al., [2019](#bib.bib26)) and $S_{8}=0.823_{-0.028}^{+0.032}$ (Hamana et al.,
    [2020](#bib.bib22)). But we find that the statistical uncertainty for the power
    spectrum method in this work is 20–30 percent smaller than that by Hikage et al.
    ([2019](#bib.bib26)). We suspect that this is because Hikage et al. ([2019](#bib.bib26))
    have modelled eight parameters compared to only three in our fiducial analysis.
    Although the additional parameters does not appear to be correlated with $S_{8}$,
    nor are they constrained better than their priors, they can contribute to the
    statistical error of $S_{8}$.
  prefs: []
  type: TYPE_NORMAL
- en: While the posterior distributions of the three methods are in very good agreement,
    the CNN achieves the smallest statistical error for each of the parameters. Specifically,
    the CNN gives $S_{8}=0.793_{-0.018}^{+0.017}$, $\Omega_{\mathrm{m}}=0.278_{-0.035}^{+0.037}$
    and $A_{\mathrm{IA}}=0.20_{-0.58}^{+0.55}$, which are better than the power spectrum
    by a factor of 1.3, 2.5, and 1.5 respectively. We notice a slight multimodality
    in the marginal distribution of $\Omega_{\mathrm{m}}$ for the power spectrum.
    We speculate that this is likely caused by the cosmology grid (in Figure [4](#S3.F4
    "Figure 4 ‣ 3.1 N-body simulation setup ‣ 3 Simulation pipeline ‣ Cosmological
    constraints from HSC survey first-year data using deep learning")) being relatively
    coarse along the $\Omega_{\mathrm{m}}$ direction, resulting in small inaccuracies
    from interpolation. This can be verified, and improved upon, by increasing the
    number of simulations in future works.
  prefs: []
  type: TYPE_NORMAL
- en: Figure [9](#S6.F9 "Figure 9 ‣ 6.2 Constraints with the HSC catalogue ‣ 6 Cosmological
    constraints ‣ Cosmological constraints from HSC survey first-year data using deep
    learning") also shows the conditional distributions with $A_{\mathrm{IA}}=0$ (hsc-no-ia).
    Compared to the fiducial analysis, the marginal distributions of $S_{8}$ almost
    remain the same—the median values only shift by less than $\sim 0.3\,\sigma$,
    but the constraints of $\Omega_{\mathrm{m}}$ have changed slightly due to the
    degeneracy between $\Omega_{\mathrm{m}}$ and $A_{\mathrm{IA}}$.
  prefs: []
  type: TYPE_NORMAL
- en: Figure [10](#S6.F10 "Figure 10 ‣ 6.2 Constraints with the HSC catalogue ‣ 6
    Cosmological constraints ‣ Cosmological constraints from HSC survey first-year
    data using deep learning") shows the posterior distributions in the fiducial baryonic
    model (hsc-fid-baryon). We find that the inclusion of baryons shifts the constraints
    on $S_{8}$ higher by 0.02–0.03\. Such differences are expected since the overall
    effect of baryons is to lower the matter fluctuation on small physical scales,
    which is negatively correlated with a higher value of $S_{8}$.
  prefs: []
  type: TYPE_NORMAL
- en: Figure [11](#S6.F11 "Figure 11 ‣ 6.2 Constraints with the HSC catalogue ‣ 6
    Cosmological constraints ‣ Cosmological constraints from HSC survey first-year
    data using deep learning") shows the posterior distributions in the model with
    free baryonic parameters (hsc-free-baryon), which has seven free parameters in
    total. The cosmological constraints by the CNN are $\Omega_{\mathrm{m}}=0.268_{-0.036}^{+0.040}$,
    $S_{8}=0.819_{-0.024}^{+0.034}$, and $A_{\mathrm{IA}}=-0.16_{-0.58}^{+0.59}$.
    Other than a slight degeneracy between $S_{8}$ and $M_{\mathrm{c}}$ and the power
    spectrum preferring the model with low $M_{\mathrm{c}}$, none of the methods can
    extract enough information from the maps to constrain the baryonic parameters.
    Lu et al. ([2022](#bib.bib50)) have shown that these methods should marginally
    constrain baryonic parameters only with the full HSC survey area according to
    their simulation-based forecast, so it is not surprising that we can not constrain
    baryonic parameters with the smaller first-year survey area. With the impact of
    free baryonic parameters, the statistical errors of $S_{8}$ increase by 15–30
    percent for the three methods relative to those in fiducial baryonic model, but
    the median $S_{8}$ values are almost unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: The credible intervals for the above HSC constraints are summarised in Table [5](#S6.T5
    "Table 5 ‣ 6.2 Constraints with the HSC catalogue ‣ 6 Cosmological constraints
    ‣ Cosmological constraints from HSC survey first-year data using deep learning").
  prefs: []
  type: TYPE_NORMAL
- en: 7 Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 7.1 CNN hyper-parameters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| $n_{\mathrm{block}}$ | $n_{\mathrm{ch}}$ | $\sigma_{\mathrm{G}}$ | Statistical
    error |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | $\Omega_{\mathrm{m}}$ | $S_{8}$ | $A_{\mathrm{IA}}$ |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 32 | $4^{\prime}$ | 0.0778 | 0.0351 | 1.15 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 32 | $4^{\prime}$ | 0.0769 | 0.0351 | 1.15 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 32 | $4^{\prime}$ | 0.0782 | 0.0354 | 1.15 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 64 | $4^{\prime}$ | 0.0776 | 0.0354 | 1.14 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 64 | $\mathbf{4^{\prime}}$ | 0.0767 | 0.0355 | 1.16 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 64 | $4^{\prime}$ | 0.0756 | 0.0351 | 1.16 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 96 | $4^{\prime}$ | 0.0779 | 0.0355 | 1.15 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 96 | $4^{\prime}$ | 0.0761 | 0.0349 | 1.15 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 96 | $4^{\prime}$ | 0.0765 | 0.0353 | 1.13 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 64 | $8^{\prime}$ | 0.0918 | 0.0389 | 1.20 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 64 | $\mathbf{4^{\prime}}$ | 0.0767 | 0.0355 | 1.16 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 64 | $2^{\prime}$ | 0.0696 | 0.0338 | 1.13 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 64 | $1^{\prime}$ | 0.0696 | 0.0338 | 1.13 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6: The statistical errors of the parameters using different CNN architectures
    and smoothing scales.'
  prefs: []
  type: TYPE_NORMAL
- en: In our fiducial analysis, we use the CNN architecture with $n_{\mathrm{block}}=10$
    and $n_{\mathrm{ch}}=64$, and in this section, we train eight additional CNNs
    with combinations of $n_{\mathrm{block}}=5,10,15$ and $n_{\mathrm{ch}}=32,64,96$.
    In Table [6](#S7.T6 "Table 6 ‣ 7.1 CNN hyper-parameters ‣ 7 Discussion ‣ Cosmological
    constraints from HSC survey first-year data using deep learning"), we show the
    statistical error on $\Omega_{\mathrm{m}}$, $S_{8}$, and $A_{\mathrm{IA}}$ for
    all CNNs with our fiducial catalogues (bootstrap). We find that all CNN architectures
    we tested performs similarly, which means that those architectures are all complex
    enough to extract the information from the maps.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Map smoothing scale
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a04b9f3e51d9a9201d4ffb516b6a04c8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: Comparison between the HSC or T17 mock peak counts and our simulated
    peak counts. Left panels show the tomographic peak counts in four redshift bins,
    and the right panels show the non-tomographic peak counts with two smoothing scales.
    The error bars are calculated assuming Poisson distributions. The boundaries of
    the $\kappa/\sigma_{\kappa}$ ranges used in Liu et al. ([2022](#bib.bib48)) and
    in our analyses are shown in black and green dashed lines respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our fiducial analysis, the convergence maps taken by the CNN are smoothed
    by a Gaussian kernel with $\sigma_{\mathrm{G}}=4\,\mathrm{arcmin}$. Here, we train
    a few more CNNs on the convergence maps smoothed on other smoothing scales (smoothing):
    $\sigma_{\mathrm{G}}=1,2,\text{and }8\,\mathrm{arcmin}$. The statistical errors
    of the three parameters with those CNNs are in listed in Table [6](#S7.T6 "Table
    6 ‣ 7.1 CNN hyper-parameters ‣ 7 Discussion ‣ Cosmological constraints from HSC
    survey first-year data using deep learning"). We find that decreasing the smoothing
    scale reduces statistical errors of the parameters, as the information on smaller
    scales becomes available. But when a certain smoothing scale is reached, the shape
    noise dominates the signal and decreasing the smoothing scale further will no
    longer improve the constraints. From our tests, this critical smoothing scale
    is $2\textrm{--}4\,\mathrm{arcmin}$ for CNNs: the reductions in statistical errors
    are small from $\sigma_{\mathrm{G}}=4\,\mathrm{arcmin}$ to $\sigma_{\mathrm{G}}=2\,\mathrm{arcmin}$
    (9 percent for $\Omega_{\mathrm{m}}$ and 5 percent for $S_{8}$), and they are
    negligible from $\sigma_{\mathrm{G}}=2\,\mathrm{arcmin}$ to $\sigma_{\mathrm{G}}=1\,\mathrm{arcmin}$.
    A similar result is also found by Hikage et al. ([2019](#bib.bib26)), where extending
    from $\ell_{\mathrm{max}}=1900$ to $\ell_{\mathrm{max}}=3500$ only yields a 10
    percent reduction on the error of $S_{8}$.'
  prefs: []
  type: TYPE_NORMAL
- en: Although a smaller smoothing scale gives us tighter constraints, it makes the
    results more vulnerable to the systematic effects that are not well-understood
    or not accounted for. Here, we present an example where we find a discrepancy
    between the number of high peaks in the HSC data and that in our simulation. In
    Figure [12](#S7.F12 "Figure 12 ‣ 7.2 Map smoothing scale ‣ 7 Discussion ‣ Cosmological
    constraints from HSC survey first-year data using deep learning"), we show the
    tomographic peak counts with $\sigma_{\mathrm{G}}=2\,\mathrm{arcmin}$ (used in
    our analyses) and the non-tomographic peak counts with $\sigma_{\mathrm{G}}=1\,\mathrm{arcmin}$
    and $2\,\mathrm{arcmin}$. The number of peaks in each bin is normalized by that
    from the simulation assuming the cosmology constrained in Section [6](#S6 "6 Cosmological
    constraints ‣ Cosmological constraints from HSC survey first-year data using deep
    learning") ($\Omega_{\mathrm{m}}=0.254,\sigma_{8}=0.800,A_{\mathrm{IA}}=1.10$
    for HSC; $\Omega_{\mathrm{m}}=0.313,\sigma_{8}=0.785,A_{\mathrm{IA}}=0$ for T17
    mock). The non-tomographic maps are calculated on a higher resolution grid of
    $208\times 208$ due to a higher galaxy number density on each map. We find that
    with $\sigma_{\mathrm{G}}=1\,\mathrm{arcmin}$ and $\kappa/\sigma_{\kappa}>4$,
    the non-tomographic peak counts from the HSC data are consistently lower than
    those from our simulations. This effect for $\sigma_{\mathrm{G}}=2\,\mathrm{arcmin}$,
    if there is any, has a much lower statistical significance. We speculate that
    this behaviour is caused by us ignoring the boost factor and dilution effect due
    to the clustering of the galaxies, which are two of main systematics for high
    peaks. According to Liu et al. ([2022](#bib.bib48)), taking the boost factor and
    dilution effect into account can decrease the number of high peaks ($\kappa/\sigma_{\kappa}>4.5$)
    by about 30–50 percent in non-tomographic maps with $\sigma_{\mathrm{G}}=1.5\,\mathrm{arcmin}$,
    which is comparable to our results in Figure [12](#S7.F12 "Figure 12 ‣ 7.2 Map
    smoothing scale ‣ 7 Discussion ‣ Cosmological constraints from HSC survey first-year
    data using deep learning"). While $\kappa$ cuts can be made to prevent those systematics
    from affecting our peak counts analyses, it is much harder to modify a $\sigma_{\mathrm{G}}=1\,\mathrm{arcmin}$
    map to prevent a CNN from learning high peak features.
  prefs: []
  type: TYPE_NORMAL
- en: Take both factors above into consideration, we find a similar conclusion to
    Hikage et al. ([2019](#bib.bib26)) that a smoothing scale of $\sigma_{\mathrm{G}}=4\,\mathrm{arcmin}$
    ($\ell\lesssim 2000$) is a conservative choice to give reliable constraints.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3 Non-Gaussian information
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0284119fec5baa700cfb308fdafd76e9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Posterior distributions based on the fiducial cosmology. The dashed
    contours shows the constraints by the CNN on the maps with non-Gaussian information
    removed.'
  prefs: []
  type: TYPE_NORMAL
- en: The results in Section [6](#S6 "6 Cosmological constraints ‣ Cosmological constraints
    from HSC survey first-year data using deep learning") show that the CNN can produce
    tighter constraints than the power spectrum, especially for $\Omega_{\mathrm{m}}$,
    which suggests that the CNN can effectively extract non-Gaussian information from
    the maps. But since it is hard to fully analyse the internal working of the CNN,
    we need to perform tests to make sure that it does not underestimate the statistical
    errors through over-fitting to the training maps.
  prefs: []
  type: TYPE_NORMAL
- en: In Section [5](#S5 "5 Parameter inference ‣ Cosmological constraints from HSC
    survey first-year data using deep learning"), we have mentioned that we can avoid
    over-fitting by using two separate sets of maps for training and for the construction
    of the likelihood function. Here, we perform a direct test to check the possibility
    of over-fitting using Gaussian random fields (GRFs), following a similar test
    by Gupta et al. ([2018](#bib.bib20)). In this test, we remove non-Gaussian information
    from each simulated tomographic convergence map by randomising the phase in the
    Fourier space; formally,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\kappa}^{(b)}(\boldsymbol{\ell})\rightarrow e^{i\varphi(\boldsymbol{\ell})}\hat{\kappa}^{(b)}(\boldsymbol{\ell}),$
    |  | (42) |'
  prefs: []
  type: TYPE_TB
- en: where $\hat{\kappa}^{(b)}$ is the convergence map of the $b^{\text{th}}$ redshift
    bin in the Fourier space, and $\varphi$ a random phase across all redshift bins
    following a uniform distribution $\mathcal{U}(-\pi,\pi)$ that satisfies $\varphi(-\boldsymbol{\ell})=-\varphi(\boldsymbol{\ell})$.
    With the assumption that the weak lensing field is isotropic, this operation preserves
    the power spectrum—furthermore, the generated GRFs have the exact same amount
    of information that can be extracted through the power spectrum. Therefore, no
    summary statistics, including the CNN, should perform better than the power spectrum
    on those maps.
  prefs: []
  type: TYPE_NORMAL
- en: Figure [13](#S7.F13 "Figure 13 ‣ 7.3 Non-Gaussian information ‣ 7 Discussion
    ‣ Cosmological constraints from HSC survey first-year data using deep learning")
    shows the posterior distribution from the CNN with the GRFs (gaussian) along with
    that from the power spectrum using our fiducial catalogues (bootstrap). Apart
    from a small shift along the $S_{8}$ direction due to the varying determinant,
    these two contours are almost identical. Figure [13](#S7.F13 "Figure 13 ‣ 7.3
    Non-Gaussian information ‣ 7 Discussion ‣ Cosmological constraints from HSC survey
    first-year data using deep learning") also shows the posterior distribution by
    the CNN on the original maps (bootstrap, with non-Gaussian information), where
    the contours are fully enclosed in the contours by the CNN on GRFs. These results
    suggest that this CNN architecture is working properly in extracting information—it
    does not underestimate the statistical errors on GRFs, and it can extract additional
    non-Gaussian information when available.
  prefs: []
  type: TYPE_NORMAL
- en: 7.4 Comparison with Planck 2018 results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f3e869d57b198493e420d8a9b13158fd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: The posterior distributions of $\Omega_{\mathrm{m}}$ and $S_{8}$
    marginalised over other parameters, constrained by the CNNs with various baryonic
    models and by Planck Collaboration et al. ([2020](#bib.bib58)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Many previous studies have found that the constraint on $S_{8}$ from WL is
    lower than that from the cosmic microwave background and have investigated the
    probable causes (Hikage et al., [2019](#bib.bib26); Troxel et al., [2018](#bib.bib73);
    Hildebrandt et al., [2017](#bib.bib28); Joudaki et al., [2016](#bib.bib33); Leauthaud
    et al., [2017](#bib.bib44)). Here, we show the constraints on $\Omega_{\mathrm{m}}$
    and $S_{8}$ by the CNNs with various baryonic models and that by Planck Collaboration
    et al. ([2020](#bib.bib58)) (TT,TE,EE+lowE+lensing) in Figure [14](#S7.F14 "Figure
    14 ‣ 7.4 Comparison with Planck 2018 results ‣ 7 Discussion ‣ Cosmological constraints
    from HSC survey first-year data using deep learning"). Contrary to the analysis
    in Hikage et al. ([2019](#bib.bib26)), where the baryonic effects are considered
    not important in constraining $S_{8}$, we find that they can be significant for
    the CNN (hsc-fid-baryon is higher by $\sim 1.7\,\sigma$), because the $S_{8}$
    shift measured in this work is higher than Hikage et al. ([2019](#bib.bib26))
    by $\sim 50\text{ percent}$ while the statistical error on $S_{8}$ is 23 percent
    smaller. When compared to Planck 2018, we find that our constraint on $S_{8}$
    without baryons is lower than Planck 2018 by $\sim 2.2\,\sigma$, but with baryons,
    the discrepancy is much smaller ($\sim 0.3\,\sigma$ for the fiducial baryonic
    model, $\sim 0.5\,\sigma$ for the fiducial baryonic model). If additional cosmological
    parameters had been included in our study, the statistical error of $S_{8}$ could
    have been slightly larger (see Section [6.2](#S6.SS2 "6.2 Constraints with the
    HSC catalogue ‣ 6 Cosmological constraints ‣ Cosmological constraints from HSC
    survey first-year data using deep learning")), and the tension can be less pronounced
    in all cases. We also note that since the first-year HSC data can not provide
    constraints on the baryonic parameters, better prior distributions of the baryonic
    parameters may be obtained with the help of external observations, but this is
    beyond the scope of this study. Nevertheless, it is clear that baryonic effects
    account for at least a part, and possibly all of the discrepancy with Planck 2018
    $S_{8}$ constraint. Similar results have been found by previous studies with other
    baryonic models: Troxel et al. ([2018](#bib.bib73)) have shown that $S_{8}$ increases
    from $0.782_{-0.027}^{+0.027}$ to $0.798_{-0.028}^{+0.026}$ by including baryons,
    and Hildebrandt et al. ([2017](#bib.bib28)) have shown that $S_{8}$ increases
    by $0.3\text{--}1.0\,\sigma$ by including baryons.'
  prefs: []
  type: TYPE_NORMAL
- en: 8 Conclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this study, we have presented cosmological constraints from the first-year
    HSC data (Mandelbaum et al., [2018a](#bib.bib51)) using CNNs as summary statistics,
    applied to lensing maps created from the public HSC shear catalogue. We have compared
    these to the constraints from the lensing convergence power spectrum and peak
    counts. The constraints come from our 4-bin tomographic analyses for the 8.4 million
    galaxies in the redshift range $0.3\leq z\leq 1.5$ and placed on 19 sub-fields
    with an area of $3\times 3\,\mathrm{{deg}^{2}}$ each.
  prefs: []
  type: TYPE_NORMAL
- en: We have developed a simulation pipeline to produce mock convergence maps and
    create forward models with properties as close as possible to those of the observed
    data. The pipeline starts with running 79 dark matter-only $N$-body simulations
    with varying $\Omega_{\mathrm{m}}$ and $\sigma_{8}$. The simulated galaxy shear
    is ray-traced through the simulations, and we add shape noise to them based on
    the real catalogue. Lastly, we convert the real and simulated shears to convergence
    maps. During this process, intrinsic alignments, baryonic effects, photometric
    redshift estimation uncertainties, shear measurement biases, and PSF modelling
    errors are added.
  prefs: []
  type: TYPE_NORMAL
- en: We have trained the CNNs to predict the underlying cosmological, intrinsic alignment,
    and baryonic parameters from the simulated convergence maps. The training maps
    are smoothed by a Gaussian kernel with $\sigma_{\mathrm{G}}=4\,\mathrm{arcmin}$
    so that the CNNs do not have access to the information on the smallest scales
    ($\ell\gtrsim 2000$), which is consistent with the $\ell$ range of the power spectrum.
    We then used the trained networks to derive likelihood functions in the same way
    as for other summary statistics, and they are also applied to the HSC convergence
    maps to derive parameter estimates, which are treated as any other statistic.
    We have performed Bayesian inference with MCMC to sample the posterior.
  prefs: []
  type: TYPE_NORMAL
- en: In the $\Lambda$CDM model with two free cosmological parameters $\Omega_{\mathrm{m}}$
    and $\sigma_{8}$, we find $\Omega_{\mathrm{m}}=0.278_{-0.035}^{+0.037}$, $S_{8}=0.793_{-0.018}^{+0.017}$,
    and the IA amplitude $A_{\mathrm{IA}}=0.20_{-0.58}^{+0.55}$. By adding the baryonic
    effects with the fiducial parameters, we find $\Omega_{\mathrm{m}}=0.250_{-0.031}^{+0.036}$,
    $S_{8}=0.826_{-0.019}^{+0.020}$, and $A_{\mathrm{IA}}=-0.04_{-0.61}^{+0.58}$.
    In a baryonic model with free parameters, we find the baryonic parameters to be
    poorly constrained, and $\Omega_{\mathrm{m}}=0.268_{-0.036}^{+0.040}$, $S_{8}=0.819_{-0.024}^{+0.034}$,
    and $A_{\mathrm{IA}}=-0.16_{-0.58}^{+0.59}$ when marginalising over baryonic parameters.
  prefs: []
  type: TYPE_NORMAL
- en: All statistical uncertainties of the constraints by the CNNs are smaller than
    those of the power spectrum and peak counts. Compared to the power spectrum, the
    statistical errors of $\Omega_{\mathrm{m}}$ by the CNNs is smaller by a factor
    of 2.5–3.0, and those of $S_{8}$ is smaller by 5–24 percent, showing the effectiveness
    of CNNs in extracting non-Gaussian information from the lensing signals. We note
    that if more cosmological parameters were included in our modelling, the statistical
    error of $S_{8}$ could have been larger, as suggested by a comparison between
    the power spectrum constraints in this study and by Hikage et al. ([2019](#bib.bib26)).
    We also find that the median value of $S_{8}$ is increased by 0.02–0.03 when we
    take baryons into consideration. With baryons, the $S_{8}$ discrepancy between
    our CNN constraints and Planck 2018 results is reduced from $\sim 2.2\,\sigma$
    to $0.3\text{--}0.5\,\sigma$.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We thank Jia Liu and José Zorrilla Matilla for useful discussions and Cyrille
    Doux for comments that helped us clarify our manuscript. We acknowledge support
    by NASA ATP grant 80NSSC18K1093, the use of the NSF XSEDE facility Stampede2,
    for the simulations and data analysis in this study.
  prefs: []
  type: TYPE_NORMAL
- en: The Hyper Suprime-Cam (HSC) collaboration includes the astronomical communities
    of Japan and Taiwan, and Princeton University. The HSC instrumentation and software
    were developed by the National Astronomical Observatory of Japan (NAOJ), the Kavli
    Institute for the Physics and Mathematics of the Universe (Kavli IPMU), the University
    of Tokyo, the High Energy Accelerator Research Organization (KEK), the Academia
    Sinica Institute for Astronomy and Astrophysics in Taiwan (ASIAA), and Princeton
    University. Funding was contributed by the FIRST program from Japanese Cabinet
    Office, the Ministry of Education, Culture, Sports, Science and Technology (MEXT),
    the Japan Society for the Promotion of Science (JSPS), Japan Science and Technology
    Agency (JST), the Toray Science Foundation, NAOJ, Kavli IPMU, KEK, ASIAA, and
    Princeton University.
  prefs: []
  type: TYPE_NORMAL
- en: This paper makes use of software developed for the Large Synoptic Survey Telescope.
    We thank the LSST Project for making their code available as free software at
    http://dm.lsst.org
  prefs: []
  type: TYPE_NORMAL
- en: The Pan-STARRS1 Surveys (PS1) have been made possible through contributions
    of the Institute for Astronomy, the University of Hawaii, the Pan-STARRS Project
    Office, the Max-Planck Society and its participating institutes, the Max Planck
    Institute for Astronomy, Heidelberg and the Max Planck Institute for Extraterrestrial
    Physics, Garching, The Johns Hopkins University, Durham University, the University
    of Edinburgh, Queen’s University Belfast, the Harvard-Smithsonian Center for Astrophysics,
    the Las Cumbres Observatory Global Telescope Network Incorporated, the National
    Central University of Taiwan, the Space Telescope Science Institute, the National
    Aeronautics and Space Administration under Grant No. NNX08AR22G issued through
    the Planetary Science Division of the NASA Science Mission Directorate, the National
    Science Foundation under Grant No. AST-1238877, the University of Maryland, and
    Eotvos Lorand University (ELTE) and the Los Alamos National Laboratory.
  prefs: []
  type: TYPE_NORMAL
- en: Based [in part] on data collected at the Subaru Telescope and retrieved from
    the HSC data archive system, which is operated by Subaru Telescope and Astronomy
    Data Center at National Astronomical Observatory of Japan.
  prefs: []
  type: TYPE_NORMAL
- en: Data availability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The data underlying this article were accessed from Stampede2\. The derived
    data generated in this research will be shared on reasonable request to the corresponding
    author.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Abbott et al. (2016) Abbott, T., Abdalla, F., Allam, S., et al. 2016, Physical
    Review D, 94, 022001
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abbott et al. (2022) Abbott, T., Aguena, M., Alarcon, A., et al. 2022, Physical
    Review D, 105, 023520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abruzzo & Haiman (2019) Abruzzo, M. W., & Haiman, Z. 2019, Monthly Notices of
    the Royal Astronomical Society, 486, 2730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aihara et al. (2018a) Aihara, H., Arimoto, N., Armstrong, R., et al. 2018a,
    Publications of the Astronomical Society of Japan, 70, S4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aihara et al. (2018b) Aihara, H., Armstrong, R., Bickerton, S., et al. 2018b,
    Publications of the Astronomical Society of Japan, 70, S8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alam et al. (2017) Alam, S., Ata, M., Bailey, S., et al. 2017, Monthly Notices
    of the Royal Astronomical Society, 470, 2617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anderson et al. (2014) Anderson, L., Aubourg, É., Bailey, S., et al. 2014, Monthly
    Notices of the Royal Astronomical Society, 441, 24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aricò et al. (2020) Aricò, G., Angulo, R. E., Hernández-Monteagudo, C., et al.
    2020, Monthly Notices of the Royal Astronomical Society, 495, 4800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asgari et al. (2021) Asgari, M., Lin, C.-A., Joachimi, B., et al. 2021, Astronomy
    & Astrophysics, 645, A104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bartelmann & Schneider (2001) Bartelmann, M., & Schneider, P. 2001, Physics
    Reports, 340, 291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bernstein & Jarvis (2002) Bernstein, G., & Jarvis, M. 2002, The Astronomical
    Journal, 123, 583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bridle & King (2007) Bridle, S., & King, L. 2007, New Journal of Physics, 9,
    444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coxeter & Coxeter (1989) Coxeter, H., & Coxeter, H. 1989, Introduction to Geometry,
    Wiley Classics Library (Wiley). [https://books.google.com/books?id=c0ld-crynsIC](https://books.google.com/books?id=c0ld-crynsIC)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dietrich & Hartlap (2010) Dietrich, J. P., & Hartlap, J. 2010, MNRAS, 402, 1049,
    doi: [10.1111/j.1365-2966.2009.15948.x](http://doi.org/10.1111/j.1365-2966.2009.15948.x)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dodelson & Zhang (2005) Dodelson, S., & Zhang, P. 2005, Physical Review D, 72,
    083001
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fang & Haiman (2007) Fang, W., & Haiman, Z. 2007, Physical Review D, 75, 043010
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fluri et al. (2019) Fluri, J., Kacprzak, T., Lucchi, A., et al. 2019, Physical
    Review D, 100, 063514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fluri et al. (2022) —. 2022, Physical Review D, 105, 083518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fu et al. (2014) Fu, L., Kilbinger, M., Erben, T., et al. 2014, Monthly Notices
    of the Royal Astronomical Society, 441, 2725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gupta et al. (2018) Gupta, A., Matilla, J. M. Z., Hsu, D., & Haiman, Z. 2018,
    Physical Review D, 97, 103515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hahn & Abel (2011) Hahn, O., & Abel, T. 2011, Monthly Notices of the Royal Astronomical
    Society, 415, 2101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hamana et al. (2020) Hamana, T., Shirasaki, M., Miyazaki, S., et al. 2020, Publications
    of the Astronomical Society of Japan, 72, 16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hartlap et al. (2007) Hartlap, J., Simon, P., & Schneider, P. 2007, Astronomy
    & Astrophysics, 464, 399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2016) He, K., Zhang, X., Ren, S., & Sun, J. 2016, in Proceedings
    of the IEEE conference on computer vision and pattern recognition, 770–778
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heymans et al. (2021) Heymans, C., Tröster, T., Asgari, M., et al. 2021, Astronomy
    & Astrophysics, 646, A140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hikage et al. (2019) Hikage, C., Oguri, M., Hamana, T., et al. 2019, Publications
    of the Astronomical Society of Japan, 71, 43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hilbert et al. (2009) Hilbert, S., Hartlap, J., White, S., & Schneider, P. 2009,
    Astronomy & Astrophysics, 499, 31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hildebrandt et al. (2017) Hildebrandt, H., Viola, M., Heymans, C., et al. 2017,
    Monthly Notices of the Royal Astronomical Society, 465, 1454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hinshaw et al. (2013) Hinshaw, G., Larson, D., Komatsu, E., et al. 2013, The
    Astrophysical Journal Supplement Series, 208, 19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hirata & Seljak (2004) Hirata, C. M., & Seljak, U. 2004, Physical Review D,
    70, 063526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jain et al. (2000) Jain, B., Seljak, U., & White, S. 2000, The Astrophysical
    Journal, 530, 547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jain & Van Waerbeke (2000) Jain, B., & Van Waerbeke, L. 2000, The Astrophysical
    Journal, 530, L1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Joudaki et al. (2016) Joudaki, S., Blake, C., Heymans, C., et al. 2016, Monthly
    Notices of the Royal Astronomical Society, stw2665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kaiser & Squires (1993) Kaiser, N., & Squires, G. 1993, The Astrophysical Journal,
    404, 441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kilbinger (2015) Kilbinger, M. 2015, Reports on Progress in Physics, 78, 086901,
    doi: [10.1088/0034-4885/78/8/086901](http://doi.org/10.1088/0034-4885/78/8/086901)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kilbinger et al. (2009) Kilbinger, M., Benabed, K., Guy, J., et al. 2009, Astronomy
    & Astrophysics, 497, 677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kingma & Ba (2014) Kingma, D. P., & Ba, J. 2014, arXiv preprint arXiv:1412.6980
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Köhlinger et al. (2016) Köhlinger, F., Viola, M., Valkenburg, W., et al. 2016,
    Monthly Notices of the Royal Astronomical Society, 456, 1508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kratochvil et al. (2010) Kratochvil, J. M., Haiman, Z., & May, M. 2010, Physical
    Review D, 81, 043519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kratochvil et al. (2012) Kratochvil, J. M., Lim, E. A., Wang, S., et al. 2012,
    Physical Review D, 85, 103513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky et al. (2012) Krizhevsky, A., Sutskever, I., & Hinton, G. E. 2012,
    Advances in neural information processing systems, 25, 1097
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kuijken et al. (2015) Kuijken, K., Heymans, C., Hildebrandt, H., et al. 2015,
    Monthly Notices of the Royal Astronomical Society, 454, 3500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Laigle et al. (2016) Laigle, C., McCracken, H. J., Ilbert, O., et al. 2016,
    The Astrophysical Journal Supplement Series, 224, 24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leauthaud et al. (2017) Leauthaud, A., Saito, S., Hilbert, S., et al. 2017,
    Monthly Notices of the Royal Astronomical Society, 467, 3024
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. (1998) LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. 1998, Proceedings
    of the IEEE, 86, 2278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin & Kilbinger (2015) Lin, C.-A., & Kilbinger, M. 2015, Astronomy & Astrophysics,
    583, A70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2015) Liu, J., Petri, A., Haiman, Z., et al. 2015, Physical Review
    D, 91, 063507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2022) Liu, X., Yuan, S., Pan, C., et al. 2022, Monthly Notices of
    the Royal Astronomical Society, doi: [10.1093/mnras/stac2971](http://doi.org/10.1093/mnras/stac2971)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu & Haiman (2021) Lu, T., & Haiman, Z. 2021, Monthly Notices of the Royal Astronomical
    Society, 506, 3406, doi: [10.1093/mnras/stab1978](http://doi.org/10.1093/mnras/stab1978)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu et al. (2022) Lu, T., Haiman, Z., & Zorrilla Matilla, J. M. 2022, Monthly
    Notices of the Royal Astronomical Society, 511, 1518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mandelbaum et al. (2018a) Mandelbaum, R., Miyatake, H., Hamana, T., et al. 2018a,
    Publications of the Astronomical Society of Japan, 70, S25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mandelbaum et al. (2018b) Mandelbaum, R., Lanusse, F., Leauthaud, A., et al.
    2018b, Monthly Notices of the Royal Astronomical Society, 481, 3170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Martinet et al. (2018) Martinet, N., Schneider, P., Hildebrandt, H., et al.
    2018, Monthly Notices of the Royal Astronomical Society, 474, 712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Munshi et al. (2011) Munshi, D., van Waerbeke, L., Smidt, J., & Coles, P. 2011,
    MNRAS, submitted, e-print arXiv:1103.1876. [https://arxiv.org/abs/1103.1876](https://arxiv.org/abs/1103.1876)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Petri et al. (2013) Petri, A., Haiman, Z., Hui, L., May, M., & Kratochvil, J. M.
    2013, Physical Review D, 88, 123002
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Petri et al. (2016) Petri, A., Haiman, Z., & May, M. 2016, Physical Review D,
    93, 063524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Petri et al. (2017) Petri, A., Haiman, Z., & May, M. 2017, Phys. Rev. D, 95,
    123503, doi: [10.1103/PhysRevD.95.123503](http://doi.org/10.1103/PhysRevD.95.123503)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Planck Collaboration et al. (2020) Planck Collaboration, Aghanim, N., Akrami,
    Y., et al. 2020, A&A, 641, A6, doi: [10.1051/0004-6361/201833910](http://doi.org/10.1051/0004-6361/201833910)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Potter et al. (2017) Potter, D., Stadel, J., & Teyssier, R. 2017, Computational
    Astrophysics and Cosmology, 4, 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Redmon et al. (2016) Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. 2016,
    in Proceedings of the IEEE conference on computer vision and pattern recognition,
    779–788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refregier (2003) Refregier, A. 2003, Annual Review of Astronomy and Astrophysics,
    41, 645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ren et al. (2015) Ren, S., He, K., Girshick, R., & Sun, J. 2015, Advances in
    neural information processing systems, 28, 91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ribli et al. (2019) Ribli, D., Pataki, B. Á., Zorrilla Matilla, J. M., et al.
    2019, Monthly Notices of the Royal Astronomical Society, 490, 1843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schneider & Teyssier (2015) Schneider, A., & Teyssier, R. 2015, Journal of Cosmology
    and Astroparticle Physics, 2015, 049
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shirasaki et al. (2019) Shirasaki, M., Hamana, T., Takada, M., Takahashi, R.,
    & Miyatake, H. 2019, Monthly Notices of the Royal Astronomical Society, 486, 52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh et al. (2015) Singh, S., Mandelbaum, R., & More, S. 2015, Monthly Notices
    of the Royal Astronomical Society, 450, 2195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sobol’ (1967) Sobol’, I. M. 1967, Zhurnal Vychislitel’noi Matematiki i Matematicheskoi
    Fiziki, 7, 784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Takada & Jain (2003) Takada, M., & Jain, B. 2003, Monthly Notices of the Royal
    Astronomical Society, 344, 857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Takada & Jain (2004) —. 2004, Monthly Notices of the Royal Astronomical Society,
    348, 897
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Takahashi et al. (2017) Takahashi, R., Hamana, T., Shirasaki, M., et al. 2017,
    The Astrophysical Journal, 850, 24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Takahashi et al. (2012) Takahashi, R., Sato, M., Nishimichi, T., Taruya, A.,
    & Oguri, M. 2012, The Astrophysical Journal, 761, 152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tanaka et al. (2018) Tanaka, M., Coupon, J., Hsieh, B.-C., et al. 2018, Publications
    of the Astronomical Society of Japan, 70, S9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troxel et al. (2018) Troxel, M. A., MacCrann, N., Zuntz, J., et al. 2018, Physical
    Review D, 98, 043528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vafaei et al. (2010) Vafaei, S., Lu, T., van Waerbeke, L., et al. 2010, Astroparticle
    Physics, 32, 340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
