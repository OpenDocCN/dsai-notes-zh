- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:48:22'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2201.05867] Transferability in Deep Learning: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2201.05867](https://ar5iv.labs.arxiv.org/html/2201.05867)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Transferability in Deep Learning: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: \nameJunguang Jiang \emailjiangjunguang1123@outlook.com
  prefs: []
  type: TYPE_NORMAL
- en: \addrSchool of Software, BNRist, Tsinghua University
  prefs: []
  type: TYPE_NORMAL
- en: Beijing 100084, China \AND\nameYang Shu \emailshu-y18@mails.tsinghua.edu.cn
  prefs: []
  type: TYPE_NORMAL
- en: \addrSchool of Software, BNRist, Tsinghua University
  prefs: []
  type: TYPE_NORMAL
- en: Beijing 100084, China \AND\nameJianmin Wang \emailjimwang@tsinghua.edu.cn
  prefs: []
  type: TYPE_NORMAL
- en: \addrSchool of Software, BNRist, Tsinghua University
  prefs: []
  type: TYPE_NORMAL
- en: Beijing 100084, China \AND\nameMingsheng Long \emailmingsheng@tsinghua.edu.cn
  prefs: []
  type: TYPE_NORMAL
- en: \addrSchool of Software, BNRist, Tsinghua University
  prefs: []
  type: TYPE_NORMAL
- en: 'Beijing 100084, China Equal contributionCorrespondence to: Mingsheng Long <mingsheng@tsinghua.edu.cn>.'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The success of deep learning algorithms generally depends on large-scale data,
    while humans appear to have inherent ability of knowledge transfer, by recognizing
    and applying relevant knowledge from previous learning experiences when encountering
    and solving unseen tasks. Such an ability to acquire and reuse knowledge is known
    as *transferability* in deep learning. It has formed the long-term quest towards
    making deep learning as *data-efficient* as human learning, and has been motivating
    fruitful design of more powerful deep learning algorithms. We present this survey
    to connect different isolated areas in deep learning with their relation to transferability,
    and to provide a unified and complete view to investigating transferability through
    the whole *lifecycle* of deep learning. The survey elaborates the fundamental
    goals and challenges in parallel with the core principles and methods, covering
    recent cornerstones in deep architectures, pre-training, task adaptation and domain
    adaptation. This highlights unanswered questions on the appropriate objectives
    for learning transferable knowledge and for adapting the knowledge to new tasks
    and domains, avoiding catastrophic forgetting and negative transfer. Finally,
    we implement a benchmark and an open-source library, enabling a fair evaluation
    of deep learning methods in terms of transferability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Keywords: Deep learning, transferability, pre-training, adaptation, library,
    benchmark'
  prefs: []
  type: TYPE_NORMAL
- en: Contents
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[1 Introduction](#S1 "In Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[1.1 Terminology](#S1.SS1 "In 1 Introduction ‣ Transferability in Deep Learning:
    A Survey")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[1.2 Overview](#S1.SS2 "In 1 Introduction ‣ Transferability in Deep Learning:
    A Survey")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[2 Pre-Training](#S2 "In Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[2.1 Pre-Training Model](#S2.SS1 "In 2 Pre-Training ‣ Transferability in Deep
    Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[2.2 Supervised Pre-Training](#S2.SS2 "In 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[2.2.1 Meta-Learning](#S2.SS2.SSS1 "In 2.2 Supervised Pre-Training ‣ 2 Pre-Training
    ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[2.2.2 Causal Learning](#S2.SS2.SSS2 "In 2.2 Supervised Pre-Training ‣ 2 Pre-Training
    ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[2.3 Unsupervised Pre-Training](#S2.SS3 "In 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[2.3.1 Generative Learning](#S2.SS3.SSS1 "In 2.3 Unsupervised Pre-Training
    ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[2.3.2 Contrastive Learning](#S2.SS3.SSS2 "In 2.3 Unsupervised Pre-Training
    ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[2.4 Remarks](#S2.SS4 "In 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3 Adaptation](#S3 "In Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.1 Task Adaptation](#S3.SS1 "In 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.1.1 Catastrophic Forgetting](#S3.SS1.SSS1 "In 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.1.2 Negative Transfer](#S3.SS1.SSS2 "In 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.1.3 Parameter Efficiency](#S3.SS1.SSS3 "In 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.1.4 Data Efficiency](#S3.SS1.SSS4 "In 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.1.5 Remarks](#S3.SS1.SSS5 "In 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.2 Domain Adaptation](#S3.SS2 "In 3 Adaptation ‣ Transferability in Deep
    Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.2.1 Statistics Matching](#S3.SS2.SSS1 "In 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.2.2 Domain Adversarial Learning](#S3.SS2.SSS2 "In 3.2 Domain Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.2.3 Hypothesis Adversarial Learning](#S3.SS2.SSS3 "In 3.2 Domain Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.2.4 Domain Translation](#S3.SS2.SSS4 "In 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.2.5 Semi-Supervised Learning](#S3.SS2.SSS5 "In 3.2 Domain Adaptation ‣ 3
    Adaptation ‣ Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3.2.6 Remarks](#S3.SS2.SSS6 "In 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[4 Evaluation](#S4 "In Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[4.1 Datasets](#S4.SS1 "In 4 Evaluation ‣ Transferability in Deep Learning:
    A Survey")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[4.2 Library](#S4.SS2 "In 4 Evaluation ‣ Transferability in Deep Learning:
    A Survey")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[4.3 Benchmark](#S4.SS3 "In 4 Evaluation ‣ Transferability in Deep Learning:
    A Survey")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[4.3.1 Pre-Training](#S4.SS3.SSS1 "In 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[4.3.2 Task Adaptation](#S4.SS3.SSS2 "In 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[4.3.3 Domain Adaptation](#S4.SS3.SSS3 "In 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[5 Conclusion](#S5 "In Transferability in Deep Learning: A Survey")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning (LeCun et al., [2015](#bib.bib94)) is a class of machine learning
    algorithms that utilize multiple processing layers to learn representations of
    data with multiple levels of abstraction. These multiple processing layers, also
    called deep neural networks (DNNs), are empowered with the ability to discover
    different explanatory factors of variation behind the intricate structured data (Bengio
    et al., [2013](#bib.bib13)). With essential advances in network architectures,
    training strategies and computation devices, deep learning has made breakthroughs
    or even revolutions in various areas, such as computer vision (Krizhevsky et al.,
    [2012](#bib.bib90); He et al., [2016](#bib.bib64)), natural language processing (Radford
    et al., [2018](#bib.bib134)), speech processing (Amodei et al., [2016](#bib.bib3)),
    computational biology (Senior et al., [2020](#bib.bib155)), games (Silver et al.,
    [2016](#bib.bib161); Vinyals et al., [2019](#bib.bib181)) and so forth. Despite
    its great success in these important areas, deep learning is still faced with
    the grand challenge of data efficiency. Most mainstream deep learning methods
    require big datasets in the order of millions or even trillions to achieve good
    performance, yet collecting and annotating such huge amount of data for each new
    task or domain are expensive and even prohibitive. This data efficiency challenge
    heavily impedes the adoption of deep learning to a wider spectrum of application
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 'An effective solution to this challenge is to explore the transferability in
    deep learning. Transferability is a foundational ability of human learning: human
    beings can gain relevant knowledge from other related problems and apply it to
    handle new problems with extremely few samples (Thrun and Pratt, [1998](#bib.bib170)).
    In deep learning, transferability refers to the ability of deep neural networks
    to extract transferable representations from some source tasks and then adapt
    the gained representations to improve learning in related target tasks (Bengio,
    [2012](#bib.bib11)). Recent advances in deep learning reveal that deep models
    trained via upstream tasks on large-scale data tend to yield good transferability
    to a variety of downstream tasks, such as visual object detection (Ren et al.,
    [2015](#bib.bib141)), natural language understanding (Devlin et al., [2019](#bib.bib39)),
    to name a few. Transferability has become the central property of deep learning
    for improving data efficiency. It is on par with generalizability, interpretability,
    and robustness for bridging the gap between machine learning and human learning.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7791c0a00ea88fce1ed63c91f1ea5e2a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The two-stage lifecycle of most deep learning applications. In the
    first stage, the deep model is *pre-trained* on an upstream task with large-scale
    data (labeled or unlabeled) for gaining transferable knowledge. In the second
    stage, the pre-trained model is *adapted* to a downstream task in the target domain
    with labeled data; If the downstream task only has unlabeled data, then additional
    labeled data from another source domain of identical learning task but different
    data distribution will be used to improve performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Towards gaining and applying knowledge with good transferability, the lifecycle
    of many deep learning applications is divided into two stages: pre-training and
    adaptation (Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Transferability in
    Deep Learning: A Survey")). The goal of the pre-training stage is to gain the
    transferable knowledge. The deep models are pre-trained on an upstream task with
    large-scale data (either labeled or unlabeled) to learn disentangled representations
    or reusable parameters that are transferable to a variety of downstream tasks.
    The goal of the adaptation stage is to reuse the transferable knowledge. The pre-trained
    models are adapted to a downstream task in the target domain with labeled data,
    and the previously learned knowledge enables better generalization with fewer
    labeled samples. When the downstream task only has unlabeled data, additional
    labeled data from another source domain of identical learning task but different
    data distribution will be used to improve the data efficiency of the adapted model
    (Ganin and Lempitsky, [2015](#bib.bib45)).'
  prefs: []
  type: TYPE_NORMAL
- en: It is helpful to highlight the difference underlying the transferability in
    the two stages. The pre-training stage focuses mainly on the *generic* transferability,
    i.e., obtaining a general transferable representation that can improve the performance
    of as many downstream tasks as possible. In contrast, the adaptation stage pays
    attention to the *specific* transferability, i.e., how to exploit the transferable
    knowledge in pre-trained models for a specific kind of downstream tasks, or how
    to improve the transferability between related domains of the same downstream
    task. The generic transferability is attractive since it may benefit many downstream
    tasks without additional cost or special design. Yet it may ignore the special
    structures of downstream tasks that are crucial for stronger transferability,
    thus the specific transferability is still necessary in many cases. Recently,
    the gap between the pre-training stage and the adaptation stage is getting closer.
    Several pre-training methods are designed to obtain fast model adaptation ability
    in the adaptation stage (Finn et al., [2017](#bib.bib43)), while some adaptation
    methods try to convert downstream tasks into pre-training tasks to make full use
    of the generic transferability of pre-trained models (Brown et al., [2020](#bib.bib18)).
  prefs: []
  type: TYPE_NORMAL
- en: Transferability lies at the core of the whole lifecycle of deep learning, yet
    different areas such as domain adaptation (Zhuang et al., [2021](#bib.bib211))
    and continual learning (Delange et al., [2021](#bib.bib37)), mainly explore transferability
    in a partial regime of the lifecycle. This is not enough to achieve a complete
    picture of transferability. Thereby, we present this survey to connect different
    isolated areas in deep learning with their relation to transferability, and to
    provide a unified and complete view to investigate transferability through the
    whole lifecycle of deep learning. Due to the broadness of the scope and the limitation
    of the space, we do not aim to cover all methods towards transferability. Instead,
    we elaborate on the core principles and methods and then give a brief review of
    the expanded literature. We further implement TLlib, a high-quality open library
    to provide a fair evaluation of typical methods. We hope this survey can highlight
    the grand picture of transferability in deep learning, and provide a useful navigation
    to researchers interested in improving the data efficiency of deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Notations and descriptions used in the survey.'
  prefs: []
  type: TYPE_NORMAL
- en: '| $\mathcal{X}$ | Input space |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{Y}$ | Output space |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{D}$ | A fixed but unknown distribution over $\mathcal{X}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{\widehat{D}}$ | Empirical distribution of a sample drawn i.i.d.
    from $\mathcal{D}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $P(\cdot)$ | Probability of an event |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbb{E}(\cdot)$ | Expectation of a random variable |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{U}$ | Upstream data |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{S}$ | Source domain in downstream data |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{T}$ | Target domain in downstream data |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{H}$ | Hypothesis space |'
  prefs: []
  type: TYPE_TB
- en: '| $h$ | A hypothesis in the hypothesis space $\mathcal{H}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\psi$ | Feature generator |'
  prefs: []
  type: TYPE_TB
- en: '| $\theta$ | Hypothesis parameter |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{x}$ | Model input |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{y}$ | Model output |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{z}$ | Hidden activation of the feature generator |'
  prefs: []
  type: TYPE_TB
- en: '| $D$ | A discriminator to distinguish different distributions |'
  prefs: []
  type: TYPE_TB
- en: 1.1 Terminology
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Foremost, we give several definitions related to transferability, and the summary
    of notations and their descriptions used in this survey can be found in Table
    [1](#S1.T1 "Table 1 ‣ 1 Introduction ‣ Transferability in Deep Learning: A Survey").
    Denote the input space as $\mathcal{X}$ and the output space as $\mathcal{Y}$,
    and assume that there exists an unknown labeling function $f:\mathcal{X}\mapsto\mathcal{Y}$.
    Formally, a task corresponds to learning an underlying labeling function $f$.
    To learn a task, we first collect a set of samples $\widehat{\mathcal{D}}=\{\mathbf{x}_{1},...,\mathbf{x}_{n}\}$,
    which are drawn independently and identically distributed (i.i.d.) from some fixed
    but unknown distribution $\mathcal{D}$. Formally, a domain is a marginal probability
    distribution $P(\mathbf{X})$ defined on a certain input space $\mathcal{X}$. Consider
    a set of hypotheses $\mathcal{H}$ and a specific loss function $\ell:\mathcal{Y}\times\mathcal{Y}\mapsto\mathbb{R}_{+}$,
    the objective of the learner is to select a hypothesis $h\in\mathcal{H}$ that
    yields the lowest generalization error, $\min_{h\in\mathcal{H}}\mathbb{E}_{\mathbf{x}\sim\mathcal{D}}\ell(h(\mathbf{x}),f(\mathbf{x}))$.'
  prefs: []
  type: TYPE_NORMAL
- en: Definition 1 (Transferability)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Given a source domain $\mathcal{S}$ with learning task $t_{\mathcal{S}}$ and
    a target domain $\mathcal{T}$ with learning task $t_{\mathcal{T}}$, transferability
    is the ability of gaining transferable knowledge from $t_{\mathcal{S}}$ on $\mathcal{S}$
    and reusing the knowledge to decrease the generalization error of $t_{\mathcal{T}}$
    on $\mathcal{T}$, under the distribution shift $\mathcal{S}\neq\mathcal{T}$ or
    the task discrepancy $t_{\mathcal{S}}\neq t_{\mathcal{T}}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the deep learning lifecycle (Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Transferability in Deep Learning: A Survey")), the pre-training stage aims to
    *gain* transferable knowledge via learning on upstream task with large-scale data,
    while the adaptation stage aims to *reuse* the pre-trained knowledge to improve
    the data efficiency in downstream tasks. The upstream and downstream are different
    in both learning tasks and data distributions. To conform with the literature,
    in the pre-training stage, we will replace the notions of source domain/task with
    the widely-used upstream data/task, denoted as $\mathcal{U}$ and $t_{\mathcal{U}}$
    respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/abcced6c694b3611ae3ef1cd52e0c3a4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Overview of this survey. The survey is organized around the lifecycle
    (pre-training, adaptation, and evaluation) of deep learning applications and focuses
    on the core problems and methods towards transferability. Besides, we briefly
    review related learning setups.'
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 Overview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The survey is organized around how to acquire and utilize the transferability
    in deep learning throughout its whole lifecycle, including pre-training, adaptation,
    and evaluation (Figure [2](#S1.F2 "Figure 2 ‣ 1.1 Terminology ‣ 1 Introduction
    ‣ Transferability in Deep Learning: A Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pre-Training. We first briefly discuss some important model architectures that
    make pre-trained representations transferable. Then we elaborate on supervised
    pre-training and unsupervised pre-training, which are distinguished by the availability
    of labeled or unlabeled data for pre-training. In supervised pre-training, we
    cover both standard practices commonly used in the industry and research advances
    in academia to acquire transferability on the labeled data. In unsupervised pre-training,
    we cover the latest designs of proper pre-training tasks on unlabeled data to
    gain transferability.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adaptation. We mainly elaborate on task adaptation and domain adaptation, which
    are divided by whether there exists another related source domain in addition
    to the pre-trained model for boosting the downstream task performance. In task
    adaptation, we first pinpoint several open problems caused by the discrepancy
    between upstream tasks and downstream tasks, then illustrate how different task
    adaptation paradigms (Yosinski et al., [2014](#bib.bib197); Brown et al., [2020](#bib.bib18))
    close the task discrepancy to better utilize the transferability. In domain adaptation,
    we first pinpoint the most influential theories for closing the distribution shift
    (Ben-David et al., [2006](#bib.bib9), [2010a](#bib.bib8)), then elaborate how
    to derive solid learning algorithms (Long et al., [2015](#bib.bib112); Ganin and
    Lempitsky, [2015](#bib.bib45)) from these theories to enhance the transferability
    of deep models across domains.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation. We mainly investigate the transferability gained and reused by different
    pre-training and adaptation methods on several large-scale datasets released recently
    in the literature. Note that we omit some small-scale and relatively obsolete
    datasets to make our benchmark concise and easy to report. To facilitate fair
    evaluation and full reproduction of existing algorithms, we open source TLlib,
    a high-quality library along with this survey at [https://github.com/thuml/Transfer-Learning-Library](https://github.com/thuml/Transfer-Learning-Library).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Pre-training and adaptation lie at the core methods towards transferability.
    In parallel with them, there are some fields that are also closely related to
    the transferability in deep learning, such as domain generalization (Gulrajani
    and Lopez-Paz, [2021](#bib.bib60)), out-of-distribution (OOD) generalization (Bengio
    et al., [2021](#bib.bib14)), few-shot learning (Chen et al., [2019a](#bib.bib24)),
    etc. Recent evaluation shows that these learning setups can largely benefit from
    the advancement in pre-training and adaptation and we will give a brief review
    to them in the related sections.
  prefs: []
  type: TYPE_NORMAL
- en: 2 Pre-Training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Despite yielding unprecedented performances on various machine learning tasks,
    the deep learning methods require large amounts of labeled data to generalize
    well. This *data hungry* nature limits their application to a wide variety of
    domains and tasks, especially to scenarios short of data and annotations. Pre-training,
    which obtains transferable representations or models from upstream tasks with
    large-scale data to boost the performance on downstream tasks, is one of the most
    common and practical solutions to the problem of data scarcity. In this section,
    we will first review some important model architectures that have a great impact
    on the transferability of pre-trained representations in Section [2.1](#S2.SS1
    "2.1 Pre-Training Model ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A
    Survey"). Then we elaborate on how to *gain knowledge* of improved transferability
    via supervised pre-training on large-scale labeled data in Section [2.2](#S2.SS2
    "2.2 Supervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey") and via unsupervised pre-training on much larger unlabeled data in
    Section [2.3](#S2.SS3 "2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey"). Figure [3](#S2.F3 "Figure 3 ‣ 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey") overviews the recent cornerstones of pre-training
    methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dabd6cc8ab25bab8c0cb5921176bb3ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Cornerstones of pre-training methods for *gaining* knowledge of transferability.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Pre-Training Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Pre-training has a big interplay with the model architecture. On the one hand,
    pre-training techniques, such as greedy layerwise unsupervised pre-training (Bengio
    et al., [2007](#bib.bib12)), have eased the training of many deep architectures.
    On the other hand, as neural networks evolve from shallow to deep, they have a
    larger capacity to capture knowledge by pre-training from large-scale data, which
    increases their transferability to downstream tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Model architecture has a great influence on the transferability of knowledge
    obtained via pre-training. Kornblith et al. ([2019](#bib.bib88)) find that the
    performance of the pre-trained models on the downstream tasks is highly correlated
    with the accuracy on the pre-training tasks, which suggests that improving the
    performance on the pre-training task serves as a direct way for improving transferability.
    The depth of the architecture, or more precisely, the *capacity* of the model,
    is deemed the most critical factor to its transferability. However, training very
    deep neural networks have remained a grand difficulty for decades. He et al. ([2016](#bib.bib64))
    observe a degradation of training accuracy by increasing the network depth, which
    implies that deeper models are more difficult to optimize. Instead of fitting
    a desired mapping $h(\mathbf{x})$ by a few stacked layers, they proposed Residual
    Network (ResNet) to explicitly fit a residual mapping $\delta(\mathbf{x}):=h(\mathbf{x})-\mathbf{x}$
    and then recast the original mapping into $\delta(\mathbf{x})+\mathbf{x}$. As
    a result, ResNet improves feature and gradient flows and enables end-to-end training
    of hundreds of and even thousands of layers, allowing the capacity of pre-trained
    models to scale up easily. Ioffe and Szegedy ([2015](#bib.bib77)) hypothesize
    that the optimization difficulty also comes from the internal covariate shift
    caused by layerwise transformation. To stabilize training very deep models, they
    proposed Batch Normalization (BatchNorm) (Ioffe and Szegedy, [2015](#bib.bib77)),
    which performs normalization for each training mini-batch within the architecture.
    This design is extensively used by ResNet. Kolesnikov et al. ([2020](#bib.bib87))
    find that BatchNorm is suboptimal for transfer due to the requirement of distribution-dependent
    moving averaged statistics. They proposed Big Transfer (BiT) to replace BatchNorm
    by GroupNorm (Wu and He, [2018](#bib.bib191)), which generates pre-trained models
    of strong performance on downstream tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5a4d009737791b030e1fad73959ed36a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Designed inductive bias (left) and learned inductive bias from pre-training
    (right).'
  prefs: []
  type: TYPE_NORMAL
- en: The pre-training paradigm also reshapes the design of model architectures. In
    classic supervised learning, models usually have strong *inductive bias* such
    as the local connectivity assumption in Convolutional Neural Network (CNN) and
    Recurrent Neural Network (RNN). A strong inductive bias makes pre-training of
    deep models more data-efficient and generalize better when training data is scarce,
    yet on the other hand, it also limits the expressiveness and transferability of
    the deep models when there is large-scale data for pre-training. Thus, Transformer (Vaswani
    et al., [2017](#bib.bib177)) removes the local connectivity assumption and models
    the global dependencies between every two tokens. The connection weights are dynamically
    computed by the self-attention mechanism and then the feature aggregation in Transformer
    depends on these attentions calculated from the input sequence, while the token
    positions in the sequence are encoded by positional embedding. Transformers are
    powerful for sequence modeling in natural language processing, and Vision Transformer
    (ViT) (Dosovitskiy et al., [2021](#bib.bib42)) extends them to computer vision.
    ViT splits an image into fixed-size patches, linearly embeds each of them, adds
    positional embeddings, and feeds the resulting sequence of vectors to a standard
    Transformer encoder. In summary, Transformer makes least assumptions on the structural
    information of data, which makes Transformer an *expressive* architecture for
    storing the transferable knowledge extracted by pre-training on large amounts
    of training data (Devlin et al., [2019](#bib.bib39); Radford et al., [2018](#bib.bib134)).
  prefs: []
  type: TYPE_NORMAL
- en: 'In some sense, pre-training provides a *learned* inductive bias for the downstream
    tasks (Torrey and Shavlik, [2010](#bib.bib172)). Many downstream tasks only have
    hundreds or thousands of labeled samples, yet the pre-trained Transformers with
    hundreds of millions of parameters can generalize well after fine-tuning on such
    small data. To explain this phenomenon, Aghajanyan et al. ([2021](#bib.bib2))
    empirically show that pre-training minimizes the intrinsic dimension (Li et al.,
    [2018](#bib.bib99)), which measures the number of parameters required to closely
    approximate the optimization problem. Further, an intrinsic-dimension generalization
    bound is given, indicating that the pre-trained parameters implicitly affect the
    inductive bias of models and a larger pre-trained model might correspond to a
    smaller allowed hypothesis space during fine-tuning (see Figure [4](#S2.F4 "Figure
    4 ‣ 2.1 Pre-Training Model ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey")). The success of Transformer reveals that as the amount of pre-training
    data increases, the learned inductive bias is able to outperform the manually
    designed inductive bias in terms of transferability.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Supervised Pre-Training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Supervised pre-training aims to obtain models on large-scale labeled data and
    then transfers these models to boost downstream tasks (see Figure [5](#S2.F5 "Figure
    5 ‣ 2.2 Supervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey")). Supervised pre-training is commonly employed in computer vision,
    where image classification on ImageNet (Deng et al., [2009](#bib.bib38); Russakovsky
    et al., [2015](#bib.bib144)) is often used as the pre-training task. The pre-trained
    models can be transferred to downstream tasks by reusing the representations from
    the feature generator (Sermanet et al., [2013](#bib.bib156)). Donahue et al. ([2014](#bib.bib41))
    find that the generic visual representations pre-trained on ImageNet outperforms
    many conventional feature descriptors on various object recognition tasks. Yosinski
    et al. ([2014](#bib.bib197)) find that transferring the pre-trained models by
    fine-tuning the whole models yields better generalization performance on new tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e6b96942b79834dbe02f2b35a4aca798.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Standard supervised pre-training. The model is composed of a feature
    generator and a task-specific head. The goal is to obtain a feature generator
    capturing transferable knowledge from large-scale labeled data. After pre-training,
    the feature generator is adapted to downstream tasks, while the task-specific
    head is usually discarded.'
  prefs: []
  type: TYPE_NORMAL
- en: Among the factors that influence the transferability of pre-trained models,
    the quantity and quality of the pre-training data might be the most important.
    BiT (Kolesnikov et al., [2020](#bib.bib87)) emphasizes that training on larger
    datasets is vital for better transferability. Yet the data labeling is labor-exhaustive
    and time-consuming, which limits the possible size of the annotation data. To
    break this limitation, Mahajan et al. ([2018](#bib.bib118)) explore Weakly Supervised
    Pre-training (WSP) on IG-1B-Targeted, a dataset of billions of images with social
    media hashtags. Yalniz et al. ([2019](#bib.bib194)) further explore web-scale
    Semi-Supervised Pre-training (SSP) on YFCC100M, a dataset of billions of unlabeled
    images along with a relatively smaller set of task-specific labeled data. These
    methods improve clearly against the counterpart trained with only clean labeled
    data and achieve stronger transfer performance. On the other hand, Domain Adaptive
    Transfer (DAT) (Ngiam et al., [2018](#bib.bib122)) studies the influence of data
    quality and finds that using more data does not necessarily lead to better transferability,
    especially when the dataset is extremely large. Thus, an importance weighting
    strategy is proposed to carefully choose the pre-training data that are most relevant
    to the target task. Cui et al. ([2018](#bib.bib35)) also find that pre-training
    on more similar upstream data improves transferability to fine-grained downstream
    tasks. They propose to estimate domain similarity via the Earth Mover’s Distance
    to choose proper pre-training data. Geirhos et al. ([2019](#bib.bib49)) find that
    models trained supervisedly on ImageNet are biased towards textures in images,
    and propose to pre-train with a Stylized ImageNet (SIN), which fixes the texture
    bias and encourages the models to learn shape-based representations of better
    transferability.
  prefs: []
  type: TYPE_NORMAL
- en: 'While standard supervised pre-training is powerful when there are enough labeled
    data, it still has drawbacks that may limit the transferability of the model.
    For instance, standard supervised pre-trained models are vulnerable to adversarial
    examples (Goodfellow et al., [2015](#bib.bib55)), and Salman et al. ([2020](#bib.bib148))
    enhance the adversarial robustness of the pre-trained models to achieve better
    transferability. In addition, there are alternative pre-training methods for improving
    the transferability of deep models. Section [2.2.1](#S2.SS2.SSS1 "2.2.1 Meta-Learning
    ‣ 2.2 Supervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey") will elaborate on meta-learning, which aims to obtain pre-trained models
    that adapt to downstream tasks with less training time and less training data.
    Section [2.2.2](#S2.SS2.SSS2 "2.2.2 Causal Learning ‣ 2.2 Supervised Pre-Training
    ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A Survey") will review causal
    learning, which aims to obtain distributionally robust and generalizable pre-trained
    models.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.1 Meta-Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Standard supervised pre-training gains transferable representations to boost
    the learning of new tasks. However, it still requires to fine-tune the pre-trained
    models with hundreds or thousands of labeled data and with many gradient updates
    when adapting to the new task. In contrast, people have the ability to quickly
    adapt to different related new tasks with few labeled data. Meta-learning, also
    known as learning to learn (Schmidhuber, [1987](#bib.bib152)), aims to pursue
    such kind of *efficient* transferability in the pre-training stage.
  prefs: []
  type: TYPE_NORMAL
- en: 'The core idea of meta-learning is to equip the model with some meta knowledge
    $\phi$ that captures intrinsic properties of different learning tasks, which is
    called meta-training. When facing a new task, the learned meta knowledge could
    help the target model $\theta$ adapt to the task faster, which is called meta-testing.
    Meta-learning is based on a simple machine learning principle that test and training
    conditions should be matched. As shown in Figure [6(a)](#S2.F6.sf1 "In Figure
    6 ‣ 2.2.1 Meta-Learning ‣ 2.2 Supervised Pre-Training ‣ 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey"), to simulate the fast adaptation condition during
    meta-testing, the meta-training data is constructed into a collection of $n$ learning
    tasks, and each task $i\in[n]$ contains a training set $\mathcal{D}^{\text{tr}}_{i}$
    for adaptation to this task and a test set $\mathcal{D}^{\text{ts}}_{i}$ for evaluation¹¹1$\mathcal{D}^{\text{ts}}$
    is a *surrogate* test set used during meta-training to simulate different tasks
    and improve the model. It is different from the true test set in the general setting
    in machine learning.. As shown in Figure [6(b)](#S2.F6.sf2 "In Figure 6 ‣ 2.2.1
    Meta-Learning ‣ 2.2 Supervised Pre-Training ‣ 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey"), the learning objective of meta-training is a bi-level
    optimization problem,'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\phi^{*}={\arg}\mathop{\max}_{\phi}\sum_{i=1}^{n}\log P(\theta_{i}(\phi)&#124;\mathcal{D}^{\text{ts}}_{i}),\quad\text{where}\
    \theta_{i}(\phi)={\arg}\mathop{\max}_{\theta}\log P(\theta&#124;\mathcal{D}^{\text{tr}}_{i},\phi).\\
    $ |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: Here the inner level optimization updates the model $\theta$ with the training
    set $\mathcal{D}^{\text{tr}}_{i}$ using meta knowledge $\phi$, and the outer level
    optimization evaluates the updated model with the test set $\mathcal{D}^{\text{ts}}_{i}$
    to find better meta knowledge of stronger transferability. The key to enhancing
    the transferability of meta-learning methods is to design a proper form of meta
    knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0fbbcc03cc77d3515e3da83470830f35.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Learning Setup
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2ead3339e35459a28217d5fffe75a9c6.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6: Learning setup and architecture for meta-learning. (a) Meta-learning
    consists of two phases, meta-training and meta-testing. Meta-training gains meta
    knowledge $\phi$ from training tasks to help the model $\theta$ adapt quickly
    to a new task in meta-testing, where each task consists of a training set and
    a test set. (b) In the inner level optimization, the model $\theta$ is updated
    with the training set $\mathcal{D}^{\text{tr}}_{i}$ using meta knowledge $\phi$.
    In the outer level optimization, the updated model is evaluated on the test set
    $\mathcal{D}^{\text{ts}}_{i}$ to find better meta knowledge $\phi$.'
  prefs: []
  type: TYPE_NORMAL
- en: Memory-Based Meta-Learning considers *memory mechanisms* as the meta knowledge.
    A controller writes knowledge extracted from training data $\mathcal{D}_{i}^{\text{tr}}$
    into the memory, and reads from the memory to adapt the base learner $\theta$
    to make predictions on test data $\mathcal{D}_{i}^{\text{ts}}$. The parameter
    of the controller is updated to find transferable knowledge. Memory-Augmented
    Neural Network (MANN) (Santoro et al., [2016](#bib.bib150)) stores bound sample
    representation-class label information in the external memory, which can then
    be retrieved as features for making predictions when a sample from the same class
    is presented. Meta Network (Munkhdalai and Yu, [2017](#bib.bib121)) designs another
    memory mechanism where a base learner provides information about the status of
    the current task while the meta learner interacts with the external memory to
    generate parameters for the base learner to quickly learn the new task. Memory-based
    meta-learning methods improve transferability in various downstream tasks, such
    as few-shot classification and reinforcement learning. However, they require a
    careful design of the black-box architecture to incorporate the memory mechanism,
    and it is unclearer what is stored and retrieved in the memory and why it helps
    adapt the model.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization-Based Meta-Learning considers a good *initialization* of the model
    as the meta knowledge. The motivation of Model-Agnostic Meta-Learning (MAML) (Finn
    et al., [2017](#bib.bib43)) is to explicitly seek for an initialization that is
    most transferable for fine-tuning, i.e., only a small amount of gradient steps
    and a few labeled data are needed for the model to generalize to a new task. To
    learn such an initialization, for each sampled task $i\in[n]$, the model $\phi$
    is first updated on its training data $\mathcal{D}_{i}^{\text{tr}}$ using one
    gradient step of size $\alpha$,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\theta_{i}=\phi-\alpha\nabla_{\phi}L(\phi,\mathcal{D}_{i}^{\text{tr}}).$
    |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: which mimics the situation of fine-tuning the model from the starting point
    of $\phi$. As meta knowledge, $\phi$ should have good transferablity, such that
    for all tasks $i\in[n]$, the fine-tuned parameters $\theta_{i}$ could perform
    well on the test set $\mathcal{D}_{i}^{\text{ts}}$,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\min_{\phi}\sum_{i=1}^{n}L(\theta_{i}(\phi),\mathcal{D}_{i}^{\text{ts}})=\sum_{i=1}^{n}L(\phi-\alpha\nabla_{\phi}L(\phi,\mathcal{D}_{i}^{\text{tr}}),\mathcal{D}_{i}^{\text{ts}}).$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: The meta knowledge of MAML is high-dimensional, hindering MAML from deeper models.
    To tackle it, Meta Transfer (Sun et al., [2019a](#bib.bib167)) uses standard pre-training
    for initialization and performs meta-training with light-weight neuron operations
    (e.g. scaling and shifting over tasks), which reduces the training tasks needed
    to acquire the meta knowledge.  Raghu et al. ([2020](#bib.bib137)) find that feature
    reuse of the backbone is the predominant reason for efficient learning on downstream
    tasks with MAML. They thus propose the Almost No Inner Loop algorithm, which performs
    inner loop updates and task adaptation only on the task-specific head layer. Another
    limitation of MAML is that the fixed meta knowledge is globally shared by all
    tasks. To break this, Latent Embedding Optimization (Rusu et al., [2019](#bib.bib145))
    performs gradient-based meta-learning in a low-dimensional latent space, and learns
    data-dependent latent embedding as meta knowledge to generate target model parameters.
    Yao et al. ([2019](#bib.bib196)) perform Hierarchically Structured Meta-Learning
    over hierarchical tasks based on clustering structures and learns to tailor transferable
    meta knowledge to different tasks.
  prefs: []
  type: TYPE_NORMAL
- en: While meta-learning methods enable fast model adaptation across tasks, they
    are weak in transferring to data from different domains, and some sophisticated
    methods even perform worse than standard pre-training baselines (Chen et al.,
    [2019a](#bib.bib24)). Thus, Omni-Training  (Shu et al., [2021a](#bib.bib159))
    incorporates both standard pre-training and meta-training in a framework with
    a tri-flow architecture to equip the pre-trained model with both domain transferability
    across different distributions and task transferability for fast adaptation across
    related tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.2 Causal Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It remains difficult for supervised pre-training to obtain a transferable representation
    that generalizes well to an out-of-distribution (OOD) domain (Bengio et al., [2021](#bib.bib14)).
    In contrast, humans have the ability to adapt to different domains or new environments.
    Causal learning aims to pursue such kind of *extrapolated* transferability in
    the pre-training stage.
  prefs: []
  type: TYPE_NORMAL
- en: 'The core idea of causal learning is to equip the model with some causal mechanisms
    that capture independent and disentangled aspects of the complex real-world distributions.
    When the distribution changes, only one or several causal mechanisms change, with
    others remaining invariant, which could result in better out-of-distribution (OOD)
    generalization. The causal mechanisms are described by Structural Causal Models.
    As shown in Figure [7](#S2.F7 "Figure 7 ‣ 2.2.2 Causal Learning ‣ 2.2 Supervised
    Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A Survey"),
    causal mechanisms consider a set of variables as the vertices of a directed acyclic
    graph, and each edge represents a mechanism of direct causation in that the parents
    directly affect the assignment of the child. This induces a canonical factorization
    of the joint distribution of these variables into the disentangled distribution
    of them conditioned on their parents. The independent causal mechanism principle
    states that given its mechanism, the conditional distribution of each variable
    does not inform or influence the other mechanisms (Schölkopf et al., [2012](#bib.bib153);
    Peters et al., [2017](#bib.bib130)). This implies that small distribution changes
    should only affect the causal mechanisms along with the disentangled factorization
    in a sparse and local way (Schölkopf et al., [2021](#bib.bib154)), thereby enabling
    transferability towards different distributions. The key problem of causal learning
    is to obtain the variables governed by independent causal mechanisms. One way
    is to explicitly introduce independence with the *modular* models. Another common
    practice is to leverage the *invariance* assumption that causal relationships
    remain invariant across distributions.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/72766ad5a9818623242e83d59ada27ff.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Causal mechanisms consider a set of observations or variables as
    the vertices of a directed acyclic graph, where each edge corresponds to a mechanism
    of direct causation. Causal learning seeks a model with variables governed by
    certain causal mechanisms, and if the environment or distribution changes, only
    part of the causal mechanisms will be affected.'
  prefs: []
  type: TYPE_NORMAL
- en: Modular Model. Recurrent Independent Mechanism (RIM) (Goyal et al., [2021](#bib.bib56))
    takes a modular model composed of several modules of different functions, where
    each module is a recurrent cell such as LSTM or GRU (Cho et al., [2014](#bib.bib31))
    and represents a causal mechanism. To obtain independence in distinct modules,
    RIM introduces attention between the hidden states of each module and the current
    inputs. For specific inputs, only the most relevant modules with larger attention
    are activated and updated, which forms competition between different modules and
    encourages their independence. RIM is shown to capture independent causal mechanisms
    and generalize well over different temporal patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Invariant Learning. The invariance assumption indicates that the conditional
    probability of the target output given its direct cause should be invariant across
    all environments or distributions. Invariant Causal Prediction (ICP) (Peters et al.,
    [2016](#bib.bib129)) uncovers independent causal mechanisms by performing a statistical
    test to find the subset of the variables satisfying the invariance assumption.
    Invariant Risk Minimization (IRM) (Arjovsky et al., [2019](#bib.bib4)) extends
    this idea to representation learning and learns a good representation such that
    the conditional probability of the target output given the representation should
    be invariant across training environments. Formally, given a data representation
    $\psi:\mathcal{X}\rightarrow\mathcal{Z}$ and training environments $\mathcal{E}^{\text{tr}}$,
    the conditional probability between the representation and the output is invariant
    if there is a classifier $h:\mathcal{Z}\rightarrow\mathcal{Y}$ simultaneously
    optimal for all the environments. This can be formalized as the following constrained
    optimization problem,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathop{\min}_{\psi:\mathcal{X}\rightarrow\mathcal{Z},{h}:\mathcal{Z}\rightarrow\mathcal{Y}}\
    \sum_{e\in\mathcal{E}^{\text{tr}}}\epsilon^{e}(h\circ\psi),\quad\text{subject
    to }h\in\mathop{\arg\min}_{\bar{h}:\mathcal{Z}\rightarrow\mathcal{Y}}\epsilon^{e}(\bar{h}\circ\psi),\
    \text{for all}\ e\in\mathcal{E}^{\text{tr}},$ |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: where $\epsilon^{e}(h\circ\psi)$ refers to the expected error of the predictor
    $h\circ\psi$ on the environment $e$. The transferability across environments relies
    on how the invariance across training environments implies invariance across all
    environments. Thus, the diversity of training environments is important for gaining
    transferability. IRM can be extended to complex situations where the causal relations
    are defined on some latent variables that need to be extracted from data.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Unsupervised Pre-Training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Being a canonical successful approach, supervised pre-training still requires
    a large amount of labeled data which are expensive to annotate and only available
    in certain fields. This hinders pre-training on huge-scale data and limits its
    transferability to particular tasks. To break this shackle, unsupervised learning (Bengio,
    [2012](#bib.bib11)), typically in the form of self-supervised learning, is used
    for pre-training on very large unlabeled data to acquire generally transferable
    knowledge. To improve the transferability on downstream tasks, it is crucial to
    design a proper self-supervised task for pre-training. According to the type of
    task, we can divide common unsupervised pre-training methods into generative learning
    and contrastive learning, which will be discussed in Sections [2.3.1](#S2.SS3.SSS1
    "2.3.1 Generative Learning ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣
    Transferability in Deep Learning: A Survey") and [2.3.2](#S2.SS3.SSS2 "2.3.2 Contrastive
    Learning ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in
    Deep Learning: A Survey") respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.1 Generative Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Generative learning is underpinned by the idea of learning to generate data
    distribution $P(\mathbf{X})$ for unsupervised pre-training. It aims to learn the
    intrinsic representation in data and has been commonly used for pre-training deep
    neural networks (Bengio et al., [2007](#bib.bib12)). As shown in Figure [8](#S2.F8
    "Figure 8 ‣ 2.3.1 Generative Learning ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training
    ‣ Transferability in Deep Learning: A Survey"), we employ an encoder $f_{\theta}$
    that maps the perturbed input $\tilde{\mathbf{x}}$ into a latent representation
    $\mathbf{z}=f_{\theta}(\tilde{\mathbf{x}})$ and a decoder $g_{\theta}$ that maps
    the representation back to derive a reconstructed version of the input $\widehat{\mathbf{x}}=g_{\theta}(\mathbf{z})$.
    The model is then optimized by minimizing the reconstruction error $L_{\text{gen}}(\widehat{\mathbf{x}},\mathbf{x})$.
    Most generative pre-training methods are based on two models: *Autoregressive*
    Model, which generates future inputs given only past inputs, and *Autoencoding*
    Model, which generates full inputs given partial inputs.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0732882422804ad47d492c4e5c973b30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Generative pre-training tries to reconstruct the original input $\mathbf{x}$
    from a perturbed input $\tilde{\mathbf{x}}$. The generative learning task shall
    encourage the learned representation $\mathbf{z}$ to capture the intrinsic and
    transferable explanatory factors from the data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Autoregressive Model approximates the distribution of a sequence by predicting
    each entry conditioned on its previous context, which is called Language Modeling
    (LM) task in NLP. As shown in Figure [9](#S2.F9 "Figure 9 ‣ 2.3.1 Generative Learning
    ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey"), given a text sequence $\mathbf{x}_{1:T}=[x_{1},x_{2},...,x_{T}]$,
    the learning objective of LM is to maximize the conditional probability of each
    entry $x_{t}$,'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\max_{\theta}\sum_{t=1}^{T}\log P_{\theta}(x_{t}&#124;x_{t-k},\cdots,x_{t-1}),$
    |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: where $k$ is the size of the context window and $\theta$ is the parameter of
    the neural network. Generative Pre-Training (GPT) (Radford et al., [2018](#bib.bib134))
    explores unsupervised pre-training of Transformer with LM on the BooksCorpus (Zhu
    et al., [2015](#bib.bib210)) dataset with over $7000$ unpublished books. This
    equips the model with great transferability to various NLP tasks, such as question
    answering, commonsense reasoning, and so on. The advantage of LM is that it models
    the context dependency while the drawback is that it only encodes contextual information
    from one direction, yet contextual representations encoded in both directions
    may be more suitable to many downstream tasks, such as natural language inference.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/14875a775be44e900a4b3b7ec575659c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Attention visibility in Transformer (Trm) for language models. (a)
    LM maximizes the probabilities of all words conditioned on their previous words.
    (b) MLM maximizes the probabilities of random masked words conditioned on all
    unmasked words. (c) PLM permutes the original sequence and then performs autoregression.
    (d) Seq2Seq MLM encodes the input masked sequence $x$ and then decodes the output
    masked tokens $y$ sequentially.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Autoencoding Model approximates the data distribution by generating original
    data from encoded representations. Vincent et al. ([2008](#bib.bib179)) hypothesize
    that a good representation should also be robust to partial corruption of the
    input. Thus Denoising Autoencoder (Vincent et al., [2008](#bib.bib179)) is trained
    to reconstruct the original input $\mathbf{x}$ with the corrupted input $\tilde{\mathbf{x}}$.
    Inspired from Denoising Autoencoder, BERT (Devlin et al., [2019](#bib.bib39))
    adopts the Masked Language Modeling (MLM) task as a pre-training task to overcome
    the drawback of the unidirectional LM. As shown in Figure [9](#S2.F9 "Figure 9
    ‣ 2.3.1 Generative Learning ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣
    Transferability in Deep Learning: A Survey"), MLM first randomly masks out some
    tokens $m(\mathbf{x})$ from the input sentences $\mathbf{x}$ with a special [MASK]
    token and then trains the models to predict the masked tokens by the rest of the
    tokens $\mathbf{x}_{\setminus m(\mathbf{x})}$,'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\max_{\theta}\sum_{x\in m(\mathbf{x})}\log P_{\theta}(x&#124;\mathbf{x}_{\setminus
    m(\mathbf{x})}).$ |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: Masked pre-training has also been used in many other areas. For instance, Masked
    Autoencoders (MAE) (He et al., [2021](#bib.bib68)) pre-trains vision transformers
    on large-scale unlabeled image datasets using the image generation task. The difficulty
    is that the signals are highly redundant in images, thus it is hard for generative
    tasks, such as filling a few missing pixels, to capture high-level knowledge from
    data. To tackle this issue, MAE randomly masks a very large portion of patches,
    forcing the model to go beyond low-level understanding and reconstruct the whole
    image based on a small subset of visible patches, which improves its transferability
    to semantic-level tasks. For another instance, to pre-train Graph Neural Network
    (GNN) (Garcia and Bruna, [2018](#bib.bib47)) for transferable representations,
    Attribute Masking (Hu et al., [2020](#bib.bib75)) conceals node or edge attributes
    and asks GNNs to predict those attributes based on neighboring structures, which
    can capture the regularities of attributes distribution over different graph structures,
    such as the chemistry rules in molecular graphs, and improve transferability on
    the downstream node or edge classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Combining Autoregressive and Autoencoding Models. In MLM, some special tokens,
    such as [MASK], are only used in pre-training while absent in the downstream tasks,
    leading to the mismatch between the pre-training phase and the fine-tuning phase.
    To mitigate this discrepancy, Permuted Language Modeling (PLM) (Yang et al., [2019](#bib.bib195))
    randomly samples a permutation of the sequence and then performs autoregression
    on the permuted sequence to predict the last few tokens. To explore the limits
    of transferability of knowledge gained in different generative pre-training methods,
    T5 (Raffel et al., [2020](#bib.bib136)) unifies all text-based language tasks
    into the text-to-text format and then adopts a Sequence-to-Sequence MLM (Seq2Seq
    MLM), where the encoder processes a masked sequence and the decoder sequentially
    generates the masked tokens in an autoregression manner.
  prefs: []
  type: TYPE_NORMAL
- en: The design of unsupervised pre-training tasks has a great influence on the transferability
    to the downstream tasks, thus many efforts have been made to optimize the pre-training
    tasks and exploit better training objectives. RoBERTa (Liu et al., [2019b](#bib.bib109))
    explores the under-training issue of BERT and highlights that training with more
    data, longer sequences, and dynamically changed masking patterns helps the model
    transfer better. Besides, MLM randomly masks out some independent words, which
    are the smallest semantic units in English but may not have complete semantics
    in other languages, such as Chinese. Thus, ERNIE (Baidu) (Sun et al., [2019b](#bib.bib168))
    introduces entity-level and phrase-level masking, where multiple words that represent
    the same semantic meaning are masked. This achieves good transferability on Chinese
    NLP tasks. To improve transferability to tasks where span selection is important,
    such as question answering and coreference resolution, SpanBERT (Joshi et al.,
    [2020](#bib.bib83)) masks a random variable length of span in the text and trains
    the span boundary representations to predict the entire content of the masked
    span. BART (Lewis et al., [2020](#bib.bib98)) introduces more perturbation functions
    such as sentence permutation, document rotation, token deletion, and text infilling
    for more transferable pre-trained models.
  prefs: []
  type: TYPE_NORMAL
- en: The generative pre-training on large-scale data greatly improves the transferability
    of models and even enables *few-shot* task transfer. By scaling up the model size
    to $175$B and pre-training on the corpus over $500$GB, GPT-3 (Brown et al., [2020](#bib.bib18))
    obtains impressive transferability. Using only task demonstrations and a few examples,
    GPT-3 achieves better performance than prior state-of-the-art fine-tuning approaches
    on some tasks. The success of GPT-3 comes from the fact that the web-scale corpus
    contains a vast amount of natural language sentences, which potentially demonstrate
    different tasks without explicit task symbols. A high-capacity language model
    trained on such data would perform unsupervised multi-task learning and absorb
    transferable knowledge to handle downstream tasks. The generative pre-training
    on large-scale data also improves the transferability across domains. Multilingual
    BERT (Pires et al., [2019](#bib.bib132)) is pre-trained with MLM on Wikipedia
    texts from $104$ languages and then achieves great cross-lingual transferability
    in the downstream tasks, where each language can be considered as a domain. Further,
    XLM (Lample and Conneau, [2019](#bib.bib91)) introduces the translation language
    modeling task, which extends MLM to parallel bilingual sentence pairs, encouraging
    more transferable representations across language.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.2 Contrastive Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Contrastive learning utilizes the idea of learning to compare for unsupervised
    pre-training. As shown in Figure [10](#S2.F10 "Figure 10 ‣ 2.3.2 Contrastive Learning
    ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey"), two different views, query $\mathbf{x}^{q}$ and key $\mathbf{x}^{k}$,
    are constructed from the original data $\mathbf{x}$. Encoders will map different
    views into latent representations and decoders will further map the representation
    to the metric space. The model is learned by minimizing the distance between query
    and key of the same instance. We will review three typical contrastive learning
    methods widely used in pre-training: Mutual Information Maximization (uses the
    global context and the local features as different views), Relative Position Prediction
    (uses different local components as different views), and Instance Discrimination
    (uses data augmentations to generate different views of the same instance). Different
    ways of generating and comparing different views encourage these methods to respectively
    capture the global-local relation, local-local relation and global-global relation
    of the training data.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5401b4143822ad8a944acaab0024de96.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Contrastive pre-training aims to minimize the similarity between
    the query $\mathbf{q}$ and the key $\mathbf{k}$ that are generated from different
    views of the same data input $\mathbf{x}$.'
  prefs: []
  type: TYPE_NORMAL
- en: Mutual Information Maximization.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Deep InfoMax (Hjelm et al., [2019](#bib.bib70)) aims to acquire transferable
    representations from the relation between the high-level global context and the
    low-level local features. Given input $\mathbf{x}$, Deep InfoMax learns an encoder
    $\psi$ to maximize the mutual information between its input and output of the
    same instance. The mutual information can be estimated and bounded by training
    a discriminator to distinguish between their joint distribution and the product
    of their marginals. Using Noise-Contrastive Estimation (NCE), the training objective
    of Deep InfoMax becomes,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\max_{\psi}\mathbb{E}_{\mathbf{x}\sim\mathcal{U}}\left[D(\mathbf{x},\psi(\mathbf{x}))-\mathbb{E}_{\mathbf{x}^{\prime}\sim\widetilde{\mathcal{U}}}\Big{(}\log\sum_{\mathbf{x}^{\prime}}e^{D(\mathbf{x}^{\prime},\psi(\mathbf{x}))}\Big{)}\right],$
    |  | (7) |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{x}$ is the input sampled from the training distribution $\mathcal{U}$
    of upstream task, $\mathbf{x}^{\prime}$ is another input sampled from $\widetilde{\mathcal{U}}=\mathcal{U}$,
    and $D$ is the discriminator to distinguish between the joint distribution and
    the product of marginals. A parallel work, Contrastive Predictive Coding (CPC) (Oord
    et al., [2019](#bib.bib124)), also maximizes the mutual information between pairs
    of global representation and local representation. Given a sequence input, CPC
    processes it with an encoder and summarizes the results into a context by an autoregression
    model. Then it maximizes the mutual information between the summarized context
    and the hidden representation of the future observation in the sequence, which
    guides the learned representations to capture information for predicting future
    samples.
  prefs: []
  type: TYPE_NORMAL
- en: Mutual information maximization has been used to obtain pre-trained models on
    many data formats, such as Deep InfoMax on image data and CPC on sequence data.
    On graph data, Deep Graph Infomax (Veličković et al., [2019](#bib.bib178)) maximizes
    the mutual information between a node’s local representations and the k-hop neighborhoods’
    context representations. On multimodal data, Contrastive Language-Image Pre-training
    (CLIP) (Radford et al., [2021](#bib.bib135)) maximizes the mutual information
    between the image and the corresponding text in a multimodal embedding space.
    After training with a large-scale dataset of image-text pairs from the Internet,
    it enables the *zero-shot* transfer of the model to downstream tasks, competitive
    with the prior task-specific supervised models.
  prefs: []
  type: TYPE_NORMAL
- en: Relative Position Prediction.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Next Sentence Prediction (NSP) (Devlin et al., [2019](#bib.bib39)), which is
    first introduced in BERT, acquires transferable representations from the relation
    between *local parts*. Specifically, NSP uses a binary classifier to predict whether
    two sentences are coherent from the training corpus, aiming to enhance the transferability
    to tasks with multiple sentences, such as question answering and natural language
    inference. However, subsequent work questions the necessity of NSP tasks (Yang
    et al., [2019](#bib.bib195); Liu et al., [2019c](#bib.bib110)) and Lan et al.
    ([2020](#bib.bib93)) conjecture that NSP only forces the model to learn topic
    prediction, rather than more difficult coherence prediction. Since inter-sentence
    coherence is important to many downstream tasks, ALBERT (Lan et al., [2020](#bib.bib93))
    introduces a sentence-order prediction task, where two consecutive segments from
    the same document are taken as positive examples, and the same segments with order
    swapped are taken as negative examples. Similar ideas are also explored in vision,
    where the pre-training task is to predict relative positions of two patches from
    an image (Doersch et al., [2015](#bib.bib40)).
  prefs: []
  type: TYPE_NORMAL
- en: Instance Discrimination.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: InstDisc (Wu et al., [2018](#bib.bib192)) aims to learn transferable representations
    from the relation between *instances*. Given $n$ instances, an encoder $\psi$
    is trained to distinguish each instance from others, i.e., minimize the distance
    between the query $\mathbf{q}$ and key $\mathbf{k}_{+}$ from the same instance
    (also called positive samples) and maximize the distance between that of different
    instances (also called negative samples),
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\min_{\psi}-\log\frac{\text{exp}(\mathbf{q}\cdot\mathbf{k}_{+}/\tau)}{\sum_{j=0}^{K}\text{exp}(\mathbf{q}\cdot\mathbf{k}_{j}/\tau)},$
    |  | (8) |'
  prefs: []
  type: TYPE_TB
- en: where $\tau$ is a temperature hyper-parameter and the sum is over one positive
    and $K$ negative samples. Note that the computation of the features of all samples
    and the non-parametric softmax is costly especially when the number of training
    instances $n$ is extremely large. To tackle this issue, negative sampling is used
    to approximate the softmax, i.e., $K<n$.
  prefs: []
  type: TYPE_NORMAL
- en: 'The discriminability of representations to contrast one instance from another
    instance is closely related to the transferability on downstream tasks. Thus,
    many efforts have been made to increase the number and improve the quality of
    keys. As shown in Figure [11](#S2.F11 "Figure 11 ‣ Instance Discrimination. ‣
    2.3.2 Contrastive Learning ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣
    Transferability in Deep Learning: A Survey"), InstDisc (Wu et al., [2018](#bib.bib192))
    uses a memory bank to store the latest updated representations for each key, which
    increases the number of negative samples, yet may result in less consistent representations.
    Momentum Contrast (MoCo) (He et al., [2020](#bib.bib67)) maintains a dynamic queue
    of encoded features to enlarge the size of negative samples and encodes the keys
    with a momentum-updated encoder, which increases encoding consistency between
    different samples in the queue and improves the quality of keys. The way how the
    positive samples and negative samples are constructed is also important for transferability.
    Contrastive Multiview Coding (CMC) (Tian et al., [2020](#bib.bib171)) takes multiple
    views, rather than multiple augmentations, of the same instance as positive samples
    and achieves better transferability. SimCLR (Chen et al., [2020](#bib.bib23))
    emphasizes that data augmentations play a crucial role in implicitly defining
    different pretext tasks, and the composition of stronger augmentations leads to
    better transferability even without the need for a memory bank or a queue. The
    introduction of negative samples is to avoid trivial solutions that all outputs
    collapse to a constant. However, BYOL (Grill et al., [2020](#bib.bib59)) finds
    that when maximizing the similarity between two augmentations of one image, negative
    sample pairs are not necessary. Further, SimSiam (Chen and He, [2021](#bib.bib25))
    finds that momentum encoder is also not necessary while a stop-gradient operation
    applied on one side is enough for learning transferable representations.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/65674a98b60ff0d7df2aa039730907ee.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Comparison of different contrastive learning mechanisms. (a) InstDisc
    samples the keys from a memory bank. (b) MoCo encodes the new keys on the fly
    by a momentum encoder and maintains a queue of keys. (c) SimCLR encodes the keys
    and queries in the same batch with the same encoder and adds a nonlinear predictor
    to improve the representation. (d) SimSiam applies an MLP predictor on one side
    and applies a stop-gradient operation on the other side, and maximizes the similarity
    in two views without using negative pairs.'
  prefs: []
  type: TYPE_NORMAL
- en: Compared with supervised pre-training, contrastive pre-training leads to competitive
    performance on downstream classification tasks and even better performance on
    various other downstream tasks, such as object detection and semantic segmentation.
    To explain the stronger transferability of contrastive pre-training,  Zhao et al.
    ([2021](#bib.bib206)) observe that standard supervised pre-training usually transfers
    high-level semantic knowledge, while contrastive pre-training usually transfers
    low-level and mid-level representations. When the target tasks are different from
    the supervised pre-trained tasks, the supervised pre-training methods have the
    risk of over-fitting the semantic discriminative parts of objects defined by the
    class labels, which hurts the transferability. On the contrary, the contrastive
    pre-training tasks lead to more holistic modeling of the objects, which relaxes
    the task misalignment issue and achieves better transferability for widespread
    downstream tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Remarks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While standard supervised pre-training is well established, its transferability
    also depends on the relationship between the pre-training task and the target
    task, and no pre-training task can dominate all downstream tasks. He et al. ([2019](#bib.bib66))
    show that compared with the random initialization, supervised pre-training on
    ImageNet only speeds up the convergence of object detection on the COCO dataset,
    but does not lead to better final accuracy. Raghu et al. ([2019](#bib.bib138))
    observe similar phenomena in medical imaging, where training lightweight models
    from scratch perform comparably with transferring from ImageNet pre-trained models.
    Abnar et al. ([2022](#bib.bib1)) explore the limits of large-scale supervised
    pre-training and find that as the pre-training accuracy increases by scaling up
    data, model size and training time, the performance of downstream tasks gradually
    saturates and there are even some extreme scenarios where performance on pre-training
    and downstream tasks are at odds with each other. These controversial results
    encourage us to *rethink* the common practice of supervised pre-training and design
    new supervised pre-training strategies for specific fields, especially when large
    gaps exist between the pre-training and target tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: Comparison between different pre-training methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Modality Scalability¹ | Task Scalability² | Data Efficiency³ | Labeling
    Cost⁴ |'
  prefs: []
  type: TYPE_TB
- en: '| Standard Pre-Training | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$ |
    $\bigstar\bigstar\bigstar$ | $\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '| Meta-Learning | $\bigstar\bigstar\bigstar$ | $\bigstar$ | $\bigstar$ | $\bigstar$
    |'
  prefs: []
  type: TYPE_TB
- en: '| Causal Learning | $\bigstar\bigstar$ | $\bigstar$ | $\bigstar$ | $\bigstar$
    |'
  prefs: []
  type: TYPE_TB
- en: '| Generative Learning | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '| Contrastive Learning | $\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Modality Scalability: whether models can be pre-trained on various modalities,
    such as text, graph.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Task Scalability: whether pre-trained models can be easily transferred to different
    downstream tasks.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data Efficiency: whether stronger transferability can be yielded from large-scale
    pre-training.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Labeling Cost: whether relies on manual data labeling.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Table [2](#S2.T2 "Table 2 ‣ 2.4 Remarks ‣ 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey") compares pre-training methods from four perspectives:
    modality scalability, task scalability, data efficiency, and labeling cost. Though
    meta-learning enables fast adaptation to new tasks, it mainly considers related
    tasks such as reinforcement learning under environments with small changing factors,
    while standard pre-training can transfer to broader task gaps such as from image
    classification to object detection. Besides, the existing meta-learning and causal
    learning methods are empirically verified only on small datasets, and it remains
    unclear whether they can acquire stronger transferability via pre-training on
    large-scale data. Despite the promising performance without manual labeling, unsupervised
    pre-trained models require a large number of gradient steps for fine-tuning to
    downstream tasks. Also, strong data augmentations are required by contrastive
    learning to gain transferability, but they are not easy to design in other modalities,
    such as text and graphs. Finally, the design of unsupervised pre-training tasks
    remains heuristic, lacking solid analysis on how the task shift is bridged and
    what enables the transferability of these models.'
  prefs: []
  type: TYPE_NORMAL
- en: Acquiring transferability only through the pre-training stage may limit our
    horizon. As the shift in tasks and domains naturally exists between the pre-training
    and adaptation stages, many pre-training methods are tailored to adaptation. Unsupervised
    pre-training aims to improve the transferability to downstream tasks by exploring
    different kinds of self-supervised tasks to reduce the task discrepancy between
    pre-training and adaptation, or by enlarging the size and diversity of the upstream
    data to reduce the upstream-downstream discrepancy. The distribution shift commonly
    tackled by domain adaptation (Ganin and Lempitsky, [2015](#bib.bib45)) also influences
    the transferability of the pre-trained model. For instance, the data distribution
    in a specific domain, such as biological and scientific literature, is quite different
    from that in the general pre-training domain and may degrade transferability,
    thus BioBert (Lee et al., [2020b](#bib.bib97)) and SciBERT (Beltagy et al., [2019](#bib.bib7))
    perform pre-training on domain-specific data to improve the transferability on
    domain-specific tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Adaptation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While pre-training on large-scale datasets can gain transferable knowledge
    in deep models, performing task adaptation with the target data is still necessary
    for most applications, as the target task is usually different from the pre-training
    task. When the labeled data for the target task is not enough, domain adaptation
    from a related source domain with labeled data to boost the performance on the
    target domain is also necessary in many applications. We will review task adaptation
    and domain adaptation in Sections [3.1](#S3.SS1 "3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey") and [3.2](#S3.SS2 "3.2 Domain Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey") respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Task Adaptation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In task adaptation, there exist a pre-trained model $h_{\theta^{0}}$ and a
    target domain $\widehat{\mathcal{T}}=\{\mathbf{x}_{i},\textbf{y}_{i}\}_{i=1}^{m}$
    of $m$ labeled samples. The goal is to find a hypothesis $h_{\theta}:\mathcal{X}\mapsto\mathcal{Y}$
    in the space $\mathcal{H}$ using the pre-trained model and target data to achieve
    a low generalization risk $\epsilon_{\mathcal{T}}(h_{\theta})$. In general, there
    are two simple ways to *adapt* a pre-trained model to the downstream tasks: feature
    transfer and fine-tuning. Feature transfer freezes the weights of the pre-trained
    models and trains a linear classifier on top of that. In contrast, fine-tuning
    uses the pre-trained models to initialize the target model parameters and update
    these parameters during training. Feature transfer is fast in training and efficient
    in parameter storage, yet fine-tuning yields better performance (Yosinski et al.,
    [2014](#bib.bib197)), and has become a common practice for task adaptation in
    both vision and NLP (Girshick et al., [2014](#bib.bib50); Devlin et al., [2019](#bib.bib39)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1ea880a2ddd9c61b25424b533e6db763.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: Cornerstones of task adaptation methods for *applying* transferable
    knowledge.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Vanilla fine-tuning, which tunes the pre-trained models by empirical risk minimization
    on the target data, has been widely used in various downstream tasks and scenarios.
    However, vanilla fine-tuning still suffers from several issues, including catastrophic
    forgetting and negative transfer. We will introduce how to alleviate these issues
    in Sections [3.1.1](#S3.SS1.SSS1 "3.1.1 Catastrophic Forgetting ‣ 3.1 Task Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey") and [3.1.2](#S3.SS1.SSS2
    "3.1.2 Negative Transfer ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey"). Besides, as the parameters of deep models keep increasing
    and some of them reach billions or trillions, parameter efficiency and data efficiency
    have become increasingly important in task adaptation. We will give an introduction
    on how to explore the transferability in the pre-trained models to solve these
    problems in Sections [3.1.3](#S3.SS1.SSS3 "3.1.3 Parameter Efficiency ‣ 3.1 Task
    Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey") and [3.1.4](#S3.SS1.SSS4
    "3.1.4 Data Efficiency ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey"). Overall, Figure [12](#S3.F12 "Figure 12 ‣ 3.1 Task
    Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey") shows
    the progress made by the task adaptation algorithms to solve different problems.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 Catastrophic Forgetting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Catastrophic forgetting, which was first studied in lifelong learning, refers
    to the tendency of neural networks to lose knowledge acquired from previous tasks
    when learning new tasks (Kirkpatrick et al., [2017](#bib.bib86)). In the fine-tuning
    scenario where labeled data is usually scarce, it will lead to the overfitting
    of models on the target data. This phenomenon is also called representational
    collapse, i.e., the degradation of generalizable representations during the fine-tuning
    stages (Aghajanyan et al., [2021](#bib.bib2)). The most simple way to avoid catastrophic
    forgetting might be selecting a small learning rate and adopting an early-stopping
    strategy, which avoids updating the parameters too much. However, this strategy
    may lead the model to falling into the local minimal, especially when there is
    a large gap between the pre-training parameters and the optimal parameters for
    the downstream task.
  prefs: []
  type: TYPE_NORMAL
- en: Yosinski et al. ([2014](#bib.bib197)) find that the transferability of different
    layers is not the same — the first layers learn general features, the middle layers
    learn semantic features and the last layers learn task-specific features. Thus,
    to make the model retain the knowledge acquired in the pre-training task and fit
    the target task well at the same time, different layers should not be treated
    the same. Specifically, the first layers should retain more pre-trained knowledge
    while the last layers should adapt more to the downstream tasks. Inspired by this
    finding, DAN (Long et al., [2015](#bib.bib112)) sets the learning rate of the
    task-specific head to be $10$ times larger than that of the lower layers, which
    is simple yet effective when the labeled data is scarce or the target domain is
    close with the pre-training domain. ULMFiT (Howard and Ruder, [2018](#bib.bib74))
    gradually unfreezes the model starting from the last layers to the first layers,
    which effectively retains general knowledge in the first layers. To automatically
    determine which layers should be fine-tuned or frozen for each sample, Spottune
    (Guo et al., [2019](#bib.bib62)) proposes a policy network that is deployed to
    output the routing decision based on the input of each sample and is jointly trained
    with the main model during fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Domain Adaptive Tuning reveals that an important source of catastrophic forgetting
    is the dataset shift between the pre-training and the target domain. To bridge
    such shift, ULMFiT (Howard and Ruder, [2018](#bib.bib74)) and DAPT (Gururangan
    et al., [2020](#bib.bib63)) first tune the pre-trained model on data related to
    the target domain, or simply data of the target task, with the pre-training task.
    Then they fine-tune the adaptive-tuned model on the target task (Figure [13](#S3.F13
    "Figure 13 ‣ 3.1.1 Catastrophic Forgetting ‣ 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")). Usually, the pre-training task
    is unsupervised, thus further pre-training with in-domain data can provide rich
    information about the target data distribution for better task adaptation with
    no additional labeling costs. The two stages, domain adaptive tuning and regular
    fine-tuning, in the above methods can also be done jointly via multi-task learning.
    SiATL (Chronopoulou et al., [2019](#bib.bib32)) adds an auxiliary language model
    loss to the task-specific optimization function, which alleviates catastrophic
    forgetting and learns task-specific features at the same time.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/46d555c188591d06a93ede911a305797.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Domain Adaptive Tuning often consists of two consecutive steps:
    first, adaptive-tune on an auxiliary domain $\mathcal{T}^{\prime}$ that is related
    to the target domain using the pre-training task; second, fine-tune on the target
    domain $\mathcal{T}$ using the target learning task.'
  prefs: []
  type: TYPE_NORMAL
- en: Regularization Tuning is another way to prevent the models from deviating far
    away from the pretrained ones. The optimization objective with a general regularization
    is
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\min_{\theta}\sum_{i=1}^{m}L(h_{\theta}(\mathbf{x}_{i}),\mathbf{y}_{i})+\lambda\cdot\Omega({\theta}),$
    |  | (9) |'
  prefs: []
  type: TYPE_TB
- en: 'where $L$ is the loss function, $\Omega$ is a general form of regularization,
    and $\lambda$ is the trade-off between them. A typical regularization in supervised
    learning is $L_{2}$ penalty, $\Omega(\theta)=\frac{1}{2}||\theta||_{2}^{2}$, which
    drives the weights $\theta$ to zero to control the model complexity. Different
    from typical supervised learning, in fine-tuning, there exists a pre-trained model
    $h_{\theta^{0}}$ setting a reference that can be used to define the hypothesis
    space (Figure [4](#S2.F4 "Figure 4 ‣ 2.1 Pre-Training Model ‣ 2 Pre-Training ‣
    Transferability in Deep Learning: A Survey")). Thus, Elastic Weight Consolidation
    (EWC) (Kirkpatrick et al., [2017](#bib.bib86)) constrains the distance between
    the weights of the pre-trained and fine-tuned networks (Figure [14](#S3.F14 "Figure
    14 ‣ 3.1.1 Catastrophic Forgetting ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")) to overcome catastrophic forgetting,'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\Omega(\theta)=\sum_{j}\frac{1}{2}F_{j}\left\&#124;\theta_{j}-\theta^{0}_{j}\right\&#124;_{2}^{2},$
    |  | (10) |'
  prefs: []
  type: TYPE_TB
- en: 'where $F$ is the estimated Fisher information matrix. EWC is based on the assumption
    that the networks with similar weights should produce similar outputs. However,
    due to the complex structures of deep networks, similar parameters do not necessarily
    produce the same output, and the same output may also come from completely different
    model parameters. Thus, DELTA (Li et al., [2019](#bib.bib101)) constraints the
    behavior, i.e., the feature maps of the model by selecting the discriminative
    features with a supervised attention mechanism and regularizing the distance of
    these features between pre-trained and fine-tuned networks. Learning Without Forgetting
    (LWF) (Li and Hoiem, [2018](#bib.bib103)) constrains the output prediction of
    the model by encouraging the model’s response for old tasks to keep the same throughout
    the fine-tuning process (Figure [14](#S3.F14 "Figure 14 ‣ 3.1.1 Catastrophic Forgetting
    ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")).
    Regularization on the output often performs better than regularization on the
    parameters or the features, yet the latter two have better scalability and versatility
    to more complex downstream tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d086645060ddc45fe783b868bea47fc4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: Regularization methods for task adaptation that avoids catastrophic
    forgetting. Blue: pre-trained parameters; Red: fine-tuned parameters. (a) EWC
    regularizes the parameters of the new models $\theta$ and that of the pre-trained
    models $\theta_{0}$ with weighted $L_{2}$-penalty. (b) DELTA regularizes the feature
    maps of the new models $\mathbf{z}$ and that of the pre-trained models $\mathbf{z}_{0}$.
    (c) LWF enforces the output of the old tasks $\widehat{\mathbf{y}}_{0}$ close
    to the initial response $\mathbf{y}_{0}$.'
  prefs: []
  type: TYPE_NORMAL
- en: An explanation for the effect of regularization is that it makes the hypothesis
    smoother. Therefore, TRADES (Zhang et al., [2019a](#bib.bib202)) and SMART (Jiang
    et al., [2020](#bib.bib79)) directly enforce the smoothness of the hypothesis
    by encouraging the output of the model to not change much when injecting a small
    perturbation to the input,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\Omega(\theta)=\sum_{i=1}^{m}\max_{&#124;&#124;{\widetilde{\mathbf{x}}_{i}}-\mathbf{x}_{i}&#124;&#124;_{p}\leq\epsilon}L_{s}(h_{\theta}({\widetilde{\mathbf{x}}_{i}}),h_{\theta}(\mathbf{x}_{i})),$
    |  | (11) |'
  prefs: []
  type: TYPE_TB
- en: where $\epsilon>0$ is a small positive, $L_{s}$ is the distance between two
    predictions, such as the symmetrized KL-divergence in classification and the squared
    loss in regression.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the training objective, an alternative regularization approach is
    through the parameter updating strategy. Stochastic Normalization (Kou et al.,
    [2020](#bib.bib89)) randomly replaces the target statistics in the batch-normalization
    layer (Ioffe and Szegedy, [2015](#bib.bib77)) with their pre-trained statistics,
    which serves as an implicit regularization by avoiding over-depending on the target
    statistics. Mixout (Lee et al., [2020a](#bib.bib96)) randomly replaces part of
    the model parameters with their pre-trained weights during fine-tuning to mitigate
    catastrophic forgetting. Child-Tuning (Xu et al., [2021](#bib.bib193)) selects
    a subset of parameters (child network) by some criterion and only updates them
    during fine-tuning. In some senses, the above methods decrease the hypothesis
    space to preserve the transferability in pre-trained models.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 Negative Transfer
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although the paradigm of pre-training and fine-tuning has been used in various
    downstream tasks, it does not necessarily produce a positive effect, which is
    known as negative transfer (Rosenstein, [2005](#bib.bib142)). Wang et al. ([2019d](#bib.bib187))
    propose to quantitatively measure the degree of negative transfer across different
    domains and we extend this idea to the paradigm of pre-training and fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: Definition 2 (Negative Transfer Gap)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let $h_{\theta}(\mathcal{U},\mathcal{T})$ be a hypothesis obtained by adapting
    the model pre-trained from the upstream data $\mathcal{U}$ to the target data
    $\mathcal{T}$, and $h_{\theta}(\emptyset,\mathcal{T})$ be a hypothesis obtained
    by training from scratch on $\mathcal{T}$, then negative transfer gap is defined
    as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $NTG=\epsilon_{\mathcal{T}}(h_{\theta}(\mathcal{U},\mathcal{T}))-\epsilon_{\mathcal{T}}(h_{\theta}(\emptyset,\mathcal{T})),$
    |  | (12) |'
  prefs: []
  type: TYPE_TB
- en: and negative transfer occurs if $NTG$ is positive and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/efc34ea98ae6f072b84d7a660820c337.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: Dilemma to promote positive transfer and avoid negative transfer:
    Aggressive strategies that promote larger positive transfer will suffer from severer
    negative transfer; Conservative strategies can decrease negative transfer, yet
    lead to smaller positive transfer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, negative transfer will happen when the relatedness between the upstream
    task and downstream task is not strong, e.g. Next Sentence Prediction pre-training
    task will hurt token-level classification tasks (Liu et al., [2019b](#bib.bib109)).
    Negative transfer will also happen when there is a large shift between the pre-training
    domain and the target domain, e.g. for legal documents classification, pre-training
    only on legal documents is better than pre-training on more diverse datasets (Zheng
    et al., [2021](#bib.bib207)). Second, negative transfer depends on the size of
    the labeled target dataset (Wang et al., [2019d](#bib.bib187)). For example, He
    et al. ([2019](#bib.bib66)) empirically show that on large-scale object detection
    datasets (e.g. COCO), ImageNet pre-training is not beneficial when training for
    enough iterations. Third, negative transfer depends on the task adaptation algorithms.
    An ideal adaptation algorithm should promote positive transfer between related
    tasks while avoiding negative transfer between unrelated tasks. In practice, however,
    these two goals are often contradictory and result in the *dilemma*: approaches
    that promote larger positive transfer will suffer from severer negative transfer
    (Figure [15](#S3.F15 "Figure 15 ‣ 3.1.2 Negative Transfer ‣ 3.1 Task Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing Safe Transfer.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: One way to avoid negative transfer is to recognize and reject harmful knowledge
    in the pre-trained model. Chen et al. ([2019b](#bib.bib27)) observe that with
    sufficient training data, the spectral components with small singular values vanish
    during fine-tuning, indicating that small singular values correspond to detrimental
    pre-trained knowledge and may cause negative transfer. Thus BSS penalizes smaller
    singular values to suppress untransferable spectral components for safe transfer.
    Jang et al. ([2019](#bib.bib78)) meta-learns the weights determining which pairs
    of layers should be matched and to what extent the knowledge should be transferred,
    which rejects irrelevant information during transfer. Zoo-tuning (Shu et al.,
    [2021b](#bib.bib160)) enables adaptive transfer from a zoo of models, which adaptively
    aggregates multiple pre-trained models to derive the target model using data-dependent
    gating mechanisms to highlight transferable parameters. Another way to mitigate
    negative transfer of the pre-trained model is to fully explore the target data.
    Self-Tuning (Wang et al., [2021](#bib.bib186)) proposes a pseudo group contrastive
    mechanism to explore the intrinsic structure of the target data in the process
    of fine-tuning with standard supervised objective.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing Pre-trained Models.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: With the fast development of deep learning, a large zoo of pre-trained models
    are available, thus a simpler way to avoid negative transfer is to select a model
    that is pre-trained on the upstream data/task relevant to the downstream data/task.
    The most common practice to choose pre-trained models is based on rich past experience
    or through heavy experiments. To facilitate faster selection, Taskonomy (Zamir
    et al., [2018](#bib.bib199)) proposes a fully computational approach for explicitly
    modeling the relationship between $26$ different visual tasks. Another more efficient
    strategy to select pre-trained models is to predict the transferability of pre-trained
    models. LEEP (Nguyen et al., [2020](#bib.bib123)) constructs an empirical predictor
    by estimating the joint distribution over pre-trained labels and the target labels,
    and then uses the log expectation of the empirical predictor to measure the transferability.
    LogME (You et al., [2021](#bib.bib198)) proposes to predict the fine-tuning performance
    from the compatibility of features $\{\mathbf{z}_{i}=\psi(\mathbf{x}_{i})\}_{i=1}^{m}$
    and labels $\{\mathbf{y}_{i}\}_{i=1}^{m}$. Still, these methods may underestimate
    strong but non-linear features. He et al. ([2021](#bib.bib68)) show that features
    from contrastive pre-training, such as MoCo v3 (Chen et al., [2021a](#bib.bib26)),
    have higher linear probing accuracy while worse fully fine-tuning results than
    generative pre-training, such as MAE (He et al., [2021](#bib.bib68)), indicating
    that the linear separability of the pre-trained features is not the sole metric
    for evaluating transferability.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e34c45d320b6765ea49be605dccaf3ac.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: Comparison on how different adaptation methods freeze (blue) and
    tune (red) pre-trained parameters. (a) Feature transfer freezes all the pre-trained
    parameters. (b) Fine-tuning re-trains all the pre-trained parameters. (c) Side-tuning
    trains a lightweight conditioned side network that is fused with the fixed pre-trained
    network using summation. (d) Adapter-Tuning inserts adapter modules for tuning
    into each frozen pre-trained layer.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.3 Parameter Efficiency
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Fine-tuning large pre-trained models yields strong performances on many downstream
    tasks (Radford et al., [2018](#bib.bib134); Devlin et al., [2019](#bib.bib39)),
    yet it is not parameter efficient since it generates a full set of model parameters
    for each downstream task, which will cause unacceptable storage cost as the number
    of tasks increases. The simplest solution is Multi-task Learning (Caruana, [1997](#bib.bib20)),
    i.e., fine-tuning a single model to solve multiple target tasks, which might be
    mutually beneficial to each other (He et al., [2017](#bib.bib65); Liu et al.,
    [2019a](#bib.bib108)). Yet when different target tasks are weakly related, multi-task
    learning will underperform fine-tuning for each task separately. Also, multi-task
    learning requires simultaneous access to all target tasks, which is not feasible
    in online scenarios where the target tasks arrive in sequence. Hereafter, we will
    introduce new tuning paradigms proposed to improve parameter efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Residual Tuning.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Inspired by the fact that approximation to a difference is easier than the original
    function (He et al., [2016](#bib.bib64)), Side-Tuning (Zhang et al., [2019b](#bib.bib203))
    adds a small side network $h_{\text{side}}$ to adapt the frozen pre-trained model
    $h_{\text{pretrained}}$ for the target task and obtain a combined model $h(x)=\alpha
    h_{\text{pretrained}}(x)+(1-\alpha)h_{\text{side}}(x)$, where $\alpha$ is a weight
    that changes during training. When there is a big gap between the pre-trained
    model and the downstream task, it may be difficult to learn the residuals of the
    entire model. Thus, Adapter Tuning (Houlsby et al., [2019](#bib.bib73)) inserts
    residual adapter modules into each frozen layer. Residual Adapter was first introduced
    for learning multiple visual domains (Rebuffi et al., [2017](#bib.bib139)) and
    consists of a skip connection, such that it is set as a near-identity function
    and will not impair the whole model when the training starts. By choosing a much
    smaller amount of parameters for the adapters, Adapter Tuning can extend pre-trained
    models to new tasks without increasing much storage cost. Houlsby et al. ([2019](#bib.bib73))
    find that Adapter Tuning with only $3.6\%$ tunable parameters can match the performance
    of the fully fine-tuned BERT on the GLUE benchmark (Wang et al., [2019a](#bib.bib183)),
    revealing the great potential of this method.
  prefs: []
  type: TYPE_NORMAL
- en: Parameter Difference Tuning.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: While residual adapter tuning changes the model activations by adding new modules,
    parameter difference tuning extends the pre-trained models through a task-specific
    parameter difference vector,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\theta_{\text{task}}=\theta_{\text{pretrained}}\oplus\delta_{\text{task}},$
    |  | (13) |'
  prefs: []
  type: TYPE_TB
- en: where $\oplus$ is the element-wise addition function, $\theta_{\text{pretrained}}$
    is the fixed pre-trained parameters and $\delta_{\text{task}}$ is the tuned task-specific
    difference vector. Instead of storing a copy of $\theta_{\text{task}}$ for every
    task, difference tuning only needs to store a single copy of $\theta_{\text{pretrained}}$
    and a copy of $\delta_{\text{task}}$ for every task. As long as the size of $\delta_{\text{task}}$
    can be reduced, we can achieve parameter efficient models. To this end, Diff Pruning
    (Guo et al., [2021](#bib.bib61)) utilizes $L_{0}$-norm penalty (Louizos et al.,
    [2018](#bib.bib117)) to encourage sparsity of the difference vector $\delta_{\text{task}}$.
    Aghajanyan et al. ([2021](#bib.bib2)) adopt FastFood transform $M$ (Li et al.,
    [2018](#bib.bib99)) to convert $\delta_{\text{task}}$ into a low-dimensional vector
    $\delta_{\text{low}}$, i.e., $\delta_{\text{task}}=\delta_{\text{low}}M$. The
    element-wise addition can also be replaced by element-wise multiplication. For
    instance, Piggyback (Mallya and Lazebnik, [2018](#bib.bib119)) multiplies real-valued
    mask weights to the pre-trained parameters, i.e., $\theta_{\text{task}}=\theta_{\text{pretrained}}\odot\delta_{\text{task}}$
    during training. After training, the mask weights $\delta_{\text{task}}$ are passed
    through a thresholding function to obtain binary-valued masks, further reducing
    the parameter storage of $\delta_{\text{task}}$ at inference.
  prefs: []
  type: TYPE_NORMAL
- en: 'The essential difference between the above two tuning methods lies in their
    different assumptions about the root of transferability. Residual tuning assumes
    that transferability is encoded in the *behaviors* of each module, i.e., the features
    output by each module. When adapting to the downstream tasks, we only need to
    add some task-specific behaviors by stacking the pre-trained modules with the
    residual adapter modules. In contrast, parameter difference tuning assumes that
    transferability lies in the pre-trained *parameters*. Most of the pre-trained
    parameters can be reused, and only a small part of them need to be adapted to
    the downstream tasks, thus we only need to store the increment. Another thing
    to mention is that when limiting the size of the residual adapters or the complexity
    of the difference vector, these methods naturally overcome the catastrophic forgetting
    issue in Section [3.1.1](#S3.SS1.SSS1 "3.1.1 Catastrophic Forgetting ‣ 3.1 Task
    Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.4 Data Efficiency
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Currently, when fine-tuning large pre-trained models, hundreds or even thousands
    of labeled samples are still required to achieve strong performance on a specific
    downstream task, which limits the application of the “pre-training and fine-tuning”
    paradigm to wider range of tasks where labeled data are expensive to collect.
    In contrast, people can adapt to a new task with extremely few labeled samples,
    which is known as few-shot learning, or even with no labeled samples, which is
    known as zero-shot learning. Considering the lifecycle of deep learning, we can
    tackle this problem in three ways. The first is to improve the cross-task transferability
    of the pre-trained models, such as by increasing the model capacity or the pre-training
    dataset size, which is mentioned in Section [2](#S2 "2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey"). The second is to transfer from another labeled source
    domain where labeled data is cheaper to collect, which will be discussed in Section
    [3.2](#S3.SS2 "3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep
    Learning: A Survey"). The last is to reformulate the target task to close its
    gap with the pre-trained models, which is the focus of this part.'
  prefs: []
  type: TYPE_NORMAL
- en: Metric Learning.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Fine-tuning in low data regimes will easily cause over-fitting as updating the
    model of large-scale parameters using few labeled samples is ill-posed. In contrast,
    many *non-parametric* methods, such as nearest neighbors, can deal with low-sample
    regimes without suffering from catastrophic forgetting. To combine the advantages
    of parametric and non-parametric methods, Matching Net (Vinyals et al., [2016](#bib.bib180))
    uses an attention mechanism over the learned representations to predict the classes
    for the query samples, which can be interpreted as weighted nearest neighbors.
    Since labeled data is severely limited, ProtoNet (Snell et al., [2017](#bib.bib162))
    adds a stronger inductive bias that there exists a single prototype representation
    for each class, where each prototype is the mean of the features of the labeled
    samples in each class, and classification boils down to finding the nearest prototype.
    Since no gradient update is performed on the feature representation, choosing
    a proper distance metric that has good transferability across tasks plays an important
    role. A common choice is the cosine distance, which explicitly reduces the intra-class
    variations and improves the cross-task transferability. Chen et al. ([2019a](#bib.bib24))
    find that by replacing the linear classifier with a cosine-distance based classifier,
    the naive feature transfer method without fine-tuning serves as a strong baseline
    in few-shot learning.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Learning.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Prompting, firstly proposed in GPT-3 (Brown et al., [2020](#bib.bib18)), is
    another way to reformulate the downstream task to make it similar to the solved
    pre-training task. In fine-tuning, models will take input $\mathbf{x}$ and predict
    an output $\mathbf{y}$ as $P(\mathbf{y}|\mathbf{x})$. In prompting, the original
    input $\mathbf{x}$ is modified by a prompt template into a new string $\tilde{\mathbf{x}}$
    that has unfilled slots, then the pre-trained language model will fill $\tilde{\mathbf{x}}$
    to obatin a final string $\widehat{\mathbf{x}}$ and derive the output $\mathbf{y}$
    from $\widehat{\mathbf{x}}$ (Liu et al., [2021b](#bib.bib107)). Table [3](#S3.T3
    "Table 3 ‣ Prompt Learning. ‣ 3.1.4 Data Efficiency ‣ 3.1 Task Adaptation ‣ 3
    Adaptation ‣ Transferability in Deep Learning: A Survey") provides an example
    of prompting methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: An example of prompting method from Liu et al. ([2021b](#bib.bib107)).'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Notation | Example |'
  prefs: []
  type: TYPE_TB
- en: '| Input | $\mathbf{x}$ | I love this film. |'
  prefs: []
  type: TYPE_TB
- en: '| Output | $\mathbf{y}$ | positive |'
  prefs: []
  type: TYPE_TB
- en: '| Prompt Template | ${f_{\text{prompt}}(\mathbf{x})}$ | [X] Overall, it was
    a [Z] film. |'
  prefs: []
  type: TYPE_TB
- en: '| Prompt | $\tilde{\mathbf{x}}$ | I love this film. Overall, it was a [Z] film.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Filled Prompt | $\mathbf{\widehat{x}}$ | I love this movie. Overall, it was
    a good movie. |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/e272b27c4fa3d7c80739da24598a843c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17: (a) Fine-tuning generates a new set of parameters for each downstream
    task. (b) Prompting fixes the pre-trained parameters and finds task-specific prompts
    to solve each downstream task. (c) Instruction Tuning tunes the pre-trained models
    on instruction-format dataset and uses the obtained model to do inference with
    multiple downstream tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of prompting is that it enables few-shot or even zero-shot task
    adaptation. The strong cross-task transferability stems from the implicit multiple
    tasks such as question-answering that language models are forced to learn on the
    large-scale pre-training corpus. However, this transferability requires a large
    model capacity to deal with potential implicit tasks and is also very sensitive
    to the choice of prompts. Thus, the disadvantage is that it introduces the necessity
    for prompt engineering, i.e., finding the best prompts to solve each downstream
    task, which is work-heavy and time-consuming especially on large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Combining prompting and fine-tuning may tackle this problem (Figure [17](#S3.F17
    "Figure 17 ‣ Prompt Learning. ‣ 3.1.4 Data Efficiency ‣ 3.1 Task Adaptation ‣
    3 Adaptation ‣ Transferability in Deep Learning: A Survey")). PET-TC (Schick and
    Schütze, [2020](#bib.bib151)) tunes the parameters of pre-trained language models
    in prompt learning while Prefix-Tuning (Li and Liang, [2021](#bib.bib100)) adds
    additional prompt-related parameters and tunes these parameters. Instruction Tuning
    (Wei et al., [2022](#bib.bib188)) explicitly fine-tunes the pre-trained models
    on a mixture of datasets expressed through natural language instructions (similar
    to the filled prompt) and obtain Fine-tuned LAnguage Model (FLAN), which largely
    increases the models’ transferability to unseen tasks. In summary, prompt learning
    has provided a revolutionary way on how to utilize the transferability of pre-trained
    models.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.5 Remarks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Table [4](#S3.T4 "Table 4 ‣ 3.1.5 Remarks ‣ 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey") gives a comparison of different
    task adaptation methods. Fine-tuning (including vanilla fine-tuning, domain adaptive
    tuning, and regularization tuning) has better performance when there are enough
    labeled data in the downstream tasks. In contrast, prompt learning requires much
    fewer labeled data to achieve decent performance, yet its applications are still
    limited to NLP and it is still non-trivial to extend it to vision or other areas.
    Fine-tuning is the most parameter-inefficient since it generates a full set of
    model parameters for each downstream task, while residual tuning, difference tuning,
    and prompt learning are all parameter efficient. Also, these latter methods naturally
    mitigate the catastrophic forgetting problem, but *negative transfer* is still
    a hard problem to be resolved.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: Comparison between different task adaptation methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Adaptation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Performance¹ &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Efficiency² &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Parameter &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Efficiency³ &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Modality &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Scalability⁴ &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Task &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Scalability⁵ &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Feature Transfer | $\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '| Vanilla Fine-tuning | $\bigstar\bigstar\bigstar$ | $\bigstar$ | $\bigstar$
    | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '| Domain Adaptive Tuning | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$
    | $\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '| Regularization Tuning | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$ |
    $\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '| Residual Tuning | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar$
    | $\bigstar\bigstar$ | $\bigstar\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '| Parameter Difference Tuning | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '| Metric Learning | $\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ | $\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '| Prompt Learning | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar$ | $\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Adaptation Performance: performance when there are large-scale labeled data
    in downstream tasks.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data Efficiency: performance when there are only small-scale labeled data in
    downstream tasks.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Parameter Efficiency: whether can control parameters when the number of downstream
    tasks increases.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Modality Scalability: whether can adapt pre-trained models to various modalities,
    such as text, graph.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Task Scalability: whether can adapt pre-trained models to different downstream
    tasks, such as detection.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The motivation of many task adaptation methods can be understood from the perspective
    of *transferability*. For instance, domain adaptive tuning aims to bridge the
    domain discrepancy between the pre-training task and the downstream task by further
    obtaining a pre-trained model on the target data distribution. Prompt learning
    aims to bridge the task discrepancy between the pre-training task and the downstream
    task by reformulating all the tasks to the same format. In this scenario, when
    all tasks can be expressed in the same form, the difference between the pre-training
    task and the downstream task is only the shift in data distributions, i.e., task
    adaptation becomes the domain adaptation problem.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Domain Adaptation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The pre-training and fine-tuning paradigm has greatly improved the state-of-the-arts
    for diverse machine learning problems and applications, and the pre-trained deep
    networks can be easily adapted to the tasks at hand even with a small amount of
    labeled data. However, in many practical scenarios, there is no labeled training
    data and thus there is the demand to transfer a deep network from a source domain
    where labeled training data is available to a target domain where only unlabeled
    data exists (Chen et al., [2012](#bib.bib22); Glorot et al., [2011](#bib.bib51)).
    In this situation, the deep models still suffer from performance degradations
    due to *distribution shift* (Quionero-Candela et al., [2009](#bib.bib133)). Thus,
    domain adaptation is proposed to reduce the distribution shift between training
    and testing domains (Pan and Yang, [2010](#bib.bib125)).
  prefs: []
  type: TYPE_NORMAL
- en: Many methods have been proposed for domain adaptation in the shallow regime,
    either by re-weighting or selecting samples from the source domain (Sugiyama et al.,
    [2008](#bib.bib165)) or seeking an explicit feature space transformation from
    the source distribution into the target distribution (Gong et al., [2013](#bib.bib53)).
    As seminal methods, Huang et al. ([2007](#bib.bib76)); Pan et al. ([2011](#bib.bib126));
    Long et al. ([2013](#bib.bib111)) explicitly match the distributions in the kernel-reproducing
    Hilbert space, while Gong et al. ([2012](#bib.bib52)) map the principal axes associated
    with each of the distributions. This survey will focus on deep domain adaptation,
    where adaptation modules are embedded in deep architectures to match data distributions
    across domains.
  prefs: []
  type: TYPE_NORMAL
- en: In unsupervised domain adaptation (UDA), there is a source domain $\widehat{\mathcal{S}}=\{(\mathbf{x}_{i}^{s},\mathbf{y}_{i}^{s})\}_{i=1}^{n}$
    of $n$ labeled samples and a target domain $\widehat{\mathcal{T}}=\{\mathbf{x}_{i}^{t}\}_{i=1}^{m}$
    of $m$ unlabeled samples. The goal of a learning algorithm is to find a hypothesis
    $h:\mathcal{X}\mapsto\mathcal{Y}$ in the hypothesis space $\mathcal{H}$ with a
    low target risk $\epsilon_{\mathcal{T}}(h)=\mathbb{E}_{(\mathbf{x}^{t},\mathbf{y}^{t})\sim\mathcal{T}}[\ell(h(\mathbf{x}^{t}),\mathbf{y}^{t})]$
    with no access to the labels of $\mathcal{T}$, where $\ell:\mathcal{Y}\times\mathcal{Y}\rightarrow\mathbb{R}_{+}$
    is a loss function. Several seminal theories have been proposed to tackle this
    problem and the the main idea of them is to bound the target risk $\epsilon_{\mathcal{T}}(h)$
    by the source risk $\epsilon_{\mathcal{S}}(h)$ and a distribution distance. In
    this survey, we will focus on the theory of $\mathcal{H}\Delta\mathcal{H}$-Divergence
    (Ben-David et al., [2006](#bib.bib9), [2010a](#bib.bib8); Mansour et al., [2009](#bib.bib120))
    and Disparity Discrepancy (Zhang et al., [2019c](#bib.bib204)) and illustrate
    how to derive different algorithms from these theories. First, using triangle
    inequalities, we can relate the target risk to the source risk as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Theorem 3 (Bound with Disparity)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Assume that the loss function $\ell$ is symmetric and obeys the triangle inequality.
    Define the *disparity* between any two hypotheses $h$ and $h^{\prime}$ on distribution
    $\mathcal{D}$ as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\epsilon_{\mathcal{D}}(h,h^{\prime})=\mathbb{E}_{(\mathbf{x},\mathbf{y})\sim\mathcal{D}}[\ell(h(\mathbf{x}),h^{\prime}(\mathbf{x}))].$
    |  | (14) |'
  prefs: []
  type: TYPE_TB
- en: Then the target risk $\epsilon_{\mathcal{T}}(h)$ can be bounded by
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{\epsilon_{\mathcal{T}}}\left(h\right)$ | $\displaystyle\leqslant{\epsilon_{\mathcal{S}}}\left(h\right)+\left[{{\epsilon_{\mathcal{S}}}\left({{h^{*}}}\right)+{\epsilon_{\mathcal{T}}}\left({{h^{*}}}\right)}\right]+\left&#124;{{\epsilon_{\mathcal{S}}}\left({h,{h^{*}}}\right)-{\epsilon_{\mathcal{T}}}\left({h,{h^{*}}}\right)}\right&#124;,$
    |  | (15) |'
  prefs: []
  type: TYPE_TB
- en: where $h^{*}={\arg\min}_{h\in\mathcal{H}}\left[{{\epsilon_{\mathcal{S}}}\left({{h}}\right)+{\epsilon_{\mathcal{T}}}\left({{h}}\right)}\right]$
    is the ideal joint hypothesis, $\epsilon_{ideal}={{\epsilon_{\mathcal{S}}}\left({{h^{*}}}\right)+{\epsilon_{\mathcal{T}}}\left({{h^{*}}}\right)}$
    is the ideal joint error, $\left|{{\epsilon_{\mathcal{S}}}\left({h,{h^{*}}}\right)-{\epsilon_{\mathcal{T}}}\left({h,{h^{*}}}\right)}\right|$
    is the *disparity difference* between $\mathcal{S}$ and $\mathcal{T}$.
  prefs: []
  type: TYPE_NORMAL
- en: It is a common *assumption* in domain adaptation that the ideal joint error
    ${\epsilon_{ideal}}$ shall be sufficiently small, otherwise domain adaptation
    will be infeasible, the *impossibility* theorem (Ben-David et al., [2010b](#bib.bib10)).
    The goal is reduced to bound the disparity difference. However, since the ideal
    hypothesis $h^{*}$ is unknown due to the unavailability of labeled target data,
    the disparity difference cannot be estimated directly. To this end, $\mathcal{H}\Delta\mathcal{H}$-Divergence
    (Ben-David et al., [2006](#bib.bib9), [2010a](#bib.bib8)) is proposed to measure
    the upper bound of the disparity difference.
  prefs: []
  type: TYPE_NORMAL
- en: Definition 4 ($\mathcal{H}\Delta\mathcal{H}$-Divergence)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Define $\mathcal{H}\Delta\mathcal{H}\triangleq\{h|h=h_{1}\otimes h_{2},h_{1},h_{2}\in\mathcal{H}\}$
    as the *symmetric difference hypothesis space* of $\mathcal{H}$, where $\otimes$
    stands for the XOR operator. Then the *$\mathcal{H}\Delta\mathcal{H}$-Divergence*
    between $\mathcal{S}$ and $\mathcal{T}$ is
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle d_{\mathcal{H}\Delta\mathcal{H}}(\mathcal{S},\mathcal{T})$
    | $\displaystyle\triangleq\sup_{h,h^{\prime}\in\mathcal{H}}\left&#124;{{\epsilon_{\mathcal{S}}}\left({h,{h^{\prime}}}\right)-{\epsilon_{\mathcal{T}}}\left({h,{h^{\prime}}}\right)}\right&#124;.$
    |  |'
  prefs: []
  type: TYPE_TB
- en: For binary classification problem with the $01$-loss, $\ell(y,y^{\prime})=\mathds{1}(y\neq
    y^{\prime})$, we have
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle d_{\mathcal{H}\Delta\mathcal{H}}(\mathcal{S},\mathcal{T})$
    | $\displaystyle={\sup_{\delta\in\mathcal{H}\Delta\mathcal{H}}}\left&#124;{{\mathbb{E}_{{\mathcal{S}}}}\left[{\delta{\left({\mathbf{x}}\right)}\neq
    0}\right]-{\mathbb{E}_{{\mathcal{T}}}}\left[{\delta\left({{\mathbf{x}}}\right)\neq
    0}\right]}\right&#124;.$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'The main advantage of the $\mathcal{H}\Delta\mathcal{H}$-Divergence is that
    it can be estimated from *finite* unlabeled samples of source and target domains.
    However, it is generally hard to compute and optimize. Thus, it is approximated
    by training a domain discriminator $D$ that separates the source and target samples
    (Ben-David et al., [2006](#bib.bib9); Ganin and Lempitsky, [2015](#bib.bib45)).
    Assume that the family of the discriminators is rich enough, such as the multilayer
    perceptrons (MLP) that is universal approximator to any functions, to contain
    $\mathcal{H}\Delta\mathcal{H}$, i.e., $\mathcal{H}\Delta\mathcal{H}\subset\mathcal{H}_{D}$.
    The $\mathcal{H}\Delta\mathcal{H}$-Divergence can be further bounded by ${\sup_{D\in{\mathcal{H}_{D}}}}\left|{{\mathbb{E}_{{\mathcal{S}}}}\left[{D{\left({\mathbf{x}}\right)}=1}\right]+{\mathbb{E}_{{\mathcal{T}}}}\left[{D\left({{\mathbf{x}}}\right)=0}\right]}\right|$,
    which gives rise to the *domain adversarial* methods in Section [3.2.2](#S3.SS2.SSS2
    "3.2.2 Domain Adversarial Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey"). The $\mathcal{H}\Delta\mathcal{H}$-Divergence can
    also be estimated in a nonparametric way by replacing $\mathcal{H}\Delta\mathcal{H}$
    with a proper function space $\mathcal{F}$, which induces the *statistics matching*
    methods in Section [3.2.1](#S3.SS2.SSS1 "3.2.1 Statistics Matching ‣ 3.2 Domain
    Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: The following theorem is the earliest theory in domain adaptation, which establishes
    the generalization bound based on the $\mathcal{H}\Delta\mathcal{H}$-Divergence
    for binary classification problems.
  prefs: []
  type: TYPE_NORMAL
- en: Theorem 5 (Ben-David et al. ([2010a](#bib.bib8)))
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let $\mathcal{H}$ be a binary hypothesis space of VC dimension $d$. If $\widehat{\mathcal{S}}$
    and $\widehat{\mathcal{T}}$ are samples of size $m$ each, then for any $\delta\in(0,1)$,
    with probability at least $1-\delta$, for every $h\in\mathcal{H}$,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\epsilon_{\mathcal{T}}(h)\leq\epsilon_{{\mathcal{S}}}(h)+d_{\mathcal{H}\Delta\mathcal{H}}({\mathcal{\widehat{\mathcal{S}}}},{\mathcal{\widehat{T}}})+\epsilon_{ideal}+4\sqrt{\frac{2d\log(2m)+\log(\frac{2}{\delta})}{m}}.$
    |  | (16) |'
  prefs: []
  type: TYPE_TB
- en: This bound sheds key insights into algorithm designs. However, it has the limit
    of being based on the particular $01$-loss. Thus, Mansour et al. ([2009](#bib.bib120))
    extend the domain adaptation theory to a general class of loss functions satisfying
    the symmetry and subadditivity.
  prefs: []
  type: TYPE_NORMAL
- en: Theorem 6 (Mansour et al. ([2009](#bib.bib120)))
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Assume that the loss function $\ell$ is symmetric and obeys the triangle inequality,
    and define $h_{\mathcal{S}}^{*}=\arg\min_{h\in\mathcal{H}}\epsilon_{\mathcal{S}}(h)$
    and $h_{\mathcal{T}}^{*}=\arg\min_{h\in\mathcal{H}}\epsilon_{\mathcal{T}}(h)$
    as the ideal hypotheses for the source and target domains, then for every $h\in\mathcal{H}$,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\epsilon_{\mathcal{T}}(h)\leq\epsilon_{{\mathcal{S}}}(h,h_{\mathcal{S}}^{*})+d_{\mathcal{H}\Delta\mathcal{H}}({\mathcal{S}},{\mathcal{T}})+\epsilon,$
    |  | (17) |'
  prefs: []
  type: TYPE_TB
- en: where $\epsilon_{{\mathcal{S}}}(h,h_{\mathcal{S}}^{*})$ stands for the source
    risk and $\epsilon=\epsilon_{{\mathcal{T}}}(h_{\mathcal{T}}^{*})+\epsilon_{{\mathcal{S}}}(h_{\mathcal{T}}^{*},h_{\mathcal{S}}^{*})$
    for the capacity to adapt. Further, let $\ell$ be bounded, $\forall(y,y^{\prime})\in\mathcal{Y}^{2},\ell(y,y^{\prime})\leq
    M$ for some $M>0$, and defined as $\ell(y,y^{\prime})=|y-y^{\prime}|^{q}$ for
    some $q$. If $\widehat{\mathcal{S}}$ and $\widehat{\mathcal{T}}$ are samples of
    size $n$ and $m$ each, with probability at least $1-\delta$, we have
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $d_{\mathcal{H}\Delta\mathcal{H}}({\mathcal{S}},{\mathcal{T}})\leq d_{\mathcal{H}\Delta\mathcal{H}}(\widehat{\mathcal{S}},\widehat{\mathcal{T}})+4q(\mathfrak{R}_{n,\mathcal{S}}(\mathcal{H})+\mathfrak{R}_{m,\mathcal{T}}(\mathcal{H}))+3M\Bigg{(}\sqrt{\frac{\log\frac{4}{\delta}}{2n}}+\sqrt{\frac{\log\frac{4}{\delta}}{2m}}\Bigg{)},$
    |  | (18) |'
  prefs: []
  type: TYPE_TB
- en: where $\mathfrak{R}_{n,\mathcal{D}}$ is the expected Rademacher Complexity (Bartlett
    and Mendelson, [2002](#bib.bib6)) with respect to distribution $\mathcal{D}$ and
    sample size $n$.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the $\mathcal{H}\Delta\mathcal{H}$-Divergence bounds are still *loose*
    since the supremum is taken over both $h^{\prime}\in\mathcal{H}$ and $h\in\mathcal{H}$.
    Observing that $h$ is known as the source classifier, the Disparity Discrepancy
    (Zhang et al., [2019c](#bib.bib204)) provides a tighter bound by computing directly
    on $\mathcal{H}$.
  prefs: []
  type: TYPE_NORMAL
- en: Definition 7 (Disparity Discrepancy)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Given a binary hypothesis space $\mathcal{H}$ and a *specific hypothesis* $h\!\in\!\mathcal{H}$,
    the *Disparity Discrepancy* induced by $h^{\prime}\in\mathcal{H}$ is defined by
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $d_{h,\mathcal{H}}(\mathcal{S},\mathcal{T})=\sup_{h^{\prime}\in\mathcal{H}}\left(\mathbb{E}_{\mathcal{T}}\mathds{1}[h^{\prime}\neq
    h]-\mathbb{E}_{\mathcal{S}}\mathds{1}[h^{\prime}\neq h]\right)$ |  | (19) |'
  prefs: []
  type: TYPE_TB
- en: Since the supremum is only take over $h^{\prime}\in\mathcal{H}$, estimating
    and minimizing the disparity discrepancy jointly through a minimax game can be
    done much more easily. The disparity discrepancy can well measure the distribution
    shift and yields a tighter generalization bound.
  prefs: []
  type: TYPE_NORMAL
- en: Theorem 8 (Zhang et al. ([2019c](#bib.bib204)))
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let $\widehat{\mathcal{S}}$ and $\widehat{\mathcal{T}}$ be samples of size $n$
    and $m$ each. For any $\delta>0$ and every binary classifier $h\in\mathcal{H}$,
    with probability at least $1-3\delta$, we have
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\epsilon_{\mathcal{T}}(h)$ | $\displaystyle\leq\epsilon_{\widehat{\mathcal{S}}}(h)+d_{h,\mathcal{H}}(\widehat{\mathcal{S}},\widehat{\mathcal{T}})+\epsilon_{ideal}+2\mathfrak{R}_{n,\mathcal{S}}(\mathcal{H})$
    |  | (20) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle+2\mathfrak{R}_{n,\mathcal{S}}(\mathcal{H}\Delta\mathcal{H})+2\sqrt{\frac{\log\frac{2}{\delta}}{2n}}+2\mathfrak{R}_{m,\mathcal{T}}(\mathcal{H}\Delta\mathcal{H})+\sqrt{\frac{\log\frac{2}{\delta}}{2m}}.$
    |  |'
  prefs: []
  type: TYPE_TB
- en: The disparity discrepancy can be further extended to the *multiclass* classification
    problem with hypothesis space $\mathcal{F}$ of scoring functions $f:\mathcal{X}\times\mathcal{Y}\rightarrow\mathbb{R}$
    and margin loss, which is going beyond existing bounds and closer to the choices
    for real tasks (Zhang et al., [2019c](#bib.bib204)).
  prefs: []
  type: TYPE_NORMAL
- en: Definition 9 (Margin Disparity Discrepancy)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Given a scoring hypothesis space $\mathcal{F}$, denote the margin of a real
    hypothesis $f$ at a labeled example $(x,y)$ as $\rho_{f}(x,y)\triangleq\frac{1}{2}(f(x,y)-\max_{y^{\prime}\neq
    y}f(x,y^{\prime}))$, the labeling function induced by $f$ as $h_{f}:x\mapsto\arg\max_{y\in\mathcal{Y}}f(x,y)$,
    and the margin loss as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | <math   alttext="\Phi_{\rho}(x)\triangleq\begin{cases}0&amp;\rho\leq{x}\\
    1-x/\rho&amp;0\leq{x}\leq\rho\\'
  prefs: []
  type: TYPE_NORMAL
- en: 1&amp;{x}\leq 0\\
  prefs: []
  type: TYPE_NORMAL
- en: \end{cases}," display="block"><semantics ><mrow 
    ><mrow  ><mrow
     ><msub 
    ><mi mathvariant="normal" 
    >Φ</mi><mi  >ρ</mi></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
     ><mo stretchy="false"
     >(</mo><mi 
    >x</mi><mo stretchy="false" 
    >)</mo></mrow></mrow><mo 
    >≜</mo><mrow  ><mo
     >{</mo><mtable columnspacing="5pt"
    displaystyle="true" rowspacing="0pt"  ><mtr
     ><mtd 
    columnalign="left"  ><mn
     >0</mn></mtd><mtd
     columnalign="left"  ><mrow
     ><mi 
    >ρ</mi><mo  >≤</mo><mi
     >x</mi></mrow></mtd></mtr><mtr
     ><mtd 
    columnalign="left"  ><mrow
     ><mn 
    >1</mn><mo  >−</mo><mrow
     ><mi 
    >x</mi><mo 
    >/</mo><mi 
    >ρ</mi></mrow></mrow></mtd><mtd 
    columnalign="left"  ><mrow
     ><mn 
    >0</mn><mo  >≤</mo><mi
     >x</mi><mo 
    >≤</mo><mi  >ρ</mi></mrow></mtd></mtr><mtr
     ><mtd 
    columnalign="left"  ><mn
     >1</mn></mtd><mtd
     columnalign="left"  ><mrow
     ><mi 
    >x</mi><mo  >≤</mo><mn
     >0</mn></mrow></mtd></mtr></mtable></mrow></mrow><mo
     >,</mo></mrow><annotation-xml
    encoding="MathML-Content" ><apply 
    ><ci  >≜</ci><apply
     ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >Φ</ci><ci  >𝜌</ci></apply><ci
     >𝑥</ci></apply><apply 
    ><csymbol cd="latexml"  >cases</csymbol><cn
    type="integer"  >0</cn><apply
     ><ci 
    >𝜌</ci><ci  >𝑥</ci></apply><apply
     ><cn type="integer"
     >1</cn><apply
     ><ci 
    >𝑥</ci><ci 
    >𝜌</ci></apply></apply><apply 
    ><apply  ><cn
    type="integer"  >0</cn><ci
     >𝑥</ci></apply><apply
     ><ci 
    >𝜌</ci></apply></apply><cn type="integer" 
    >1</cn><apply  ><ci
     >𝑥</ci><cn type="integer"
     >0</cn></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\Phi_{\rho}(x)\triangleq\begin{cases}0&\rho\leq{x}\\
    1-x/\rho&0\leq{x}\leq\rho\\ 1&{x}\leq 0\\ \end{cases},</annotation></semantics></math>
    |  | (21) |
  prefs: []
  type: TYPE_NORMAL
- en: then the *margin disparity* between $f$ and $f^{\prime}$ on distribution $\mathcal{D}$
    is
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\epsilon_{\mathcal{D}}^{(\rho)}(f^{\prime},f)=\mathbb{E}_{(x,y)\sim\mathcal{D}}[\Phi_{\rho}(\rho_{f^{\prime}}(x,h_{f}(x))].$
    |  | (22) |'
  prefs: []
  type: TYPE_TB
- en: Given a *specific hypothesis* $f\!\in\!\mathcal{F}$, the *Margin Disparity Discrepancy*
    is defined by
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $d_{f,\mathcal{F}}^{(\rho)}(\mathcal{S},\mathcal{T})=\sup_{f^{\prime}\in\mathcal{F}}[\epsilon_{\mathcal{T}}^{(\rho)}(f^{\prime},f)-\epsilon_{\mathcal{S}}^{(\rho)}(f^{\prime},f)].$
    |  | (23) |'
  prefs: []
  type: TYPE_TB
- en: 'Note that the margin disparity satisfies the nonnegativity and subadditivity,
    but not the symmetry. Thus Theorem [6](#Thmtheorem6 "Theorem 6 (Mansour et al.
    (2009)) ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey") cannot apply here and a new generalization bound is derived.'
  prefs: []
  type: TYPE_NORMAL
- en: Theorem 10 (Zhang et al. ([2019c](#bib.bib204)))
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Given the same settings with Definition [9](#Thmtheorem9 "Definition 9 (Margin
    Disparity Discrepancy) ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey"), for any $\delta>0$, with probability at least $1-3\delta$,
    the following *margin bound* holds for all scoring functions $f\in\mathcal{F}$,'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\epsilon_{\mathcal{T}}(f)\leq$ | $\displaystyle\ \epsilon_{\widehat{\mathcal{S}}}^{(\rho)}(f)+d_{f,\mathcal{F}}^{(\rho)}(\mathcal{\widehat{\mathcal{S}}},\mathcal{\widehat{T}})+\epsilon_{ideal}+\frac{2k^{2}}{\rho}{\mathfrak{R}_{n,\mathcal{S}}}(\Pi_{1}\mathcal{F})$
    |  | (24) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle+$ | $\displaystyle\ \frac{k}{\rho}{\mathfrak{R}_{n,\mathcal{S}}}(\Pi_{\mathcal{H}}\mathcal{F})+2\sqrt{\frac{\log\frac{2}{\delta}}{2n}}+\frac{k}{\rho}{\mathfrak{R}_{m,\mathcal{T}}}(\Pi_{\mathcal{H}}\mathcal{F})+\sqrt{\frac{\log\frac{2}{\delta}}{2m}},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\Pi_{\mathcal{H}}\mathcal{F}\triangleq\{x\mapsto f(x,h(x))|h\in\mathcal{H},f\in\mathcal{F}\}$
    is the scoring version of the symmetric hypothesis space $\mathcal{H}\Delta\mathcal{H}$,
    $\Pi_{1}\mathcal{F}\triangleq\{x\mapsto f(x,y)|y\in\mathcal{Y},f\in\mathcal{F}\}$
    and $\epsilon_{ideal}=\min_{f^{*}\in\mathcal{F}}\{\mathrm{err}_{\mathcal{S}}^{(\rho)}(f^{*})+\mathrm{err}_{\mathcal{T}}^{(\rho)}(f^{*})\}$
    is the ideal joint error in terms of margin loss, $k$ is the number of classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This margin bound suggests that a proper margin $\rho$ could yield better generalization
    on the target domain. Theorems [8](#Thmtheorem8 "Theorem 8 (Zhang et al. (2019c))
    ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")
    and [10](#Thmtheorem10 "Theorem 10 (Zhang et al. (2019c)) ‣ 3.2 Domain Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey") together form the
    theoretical basis of the *hypothesis adversarial* methods in Section [3.2.3](#S3.SS2.SSS3
    "3.2.3 Hypothesis Adversarial Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey"). Note that the supremum in both
    the $\mathcal{H}\Delta\mathcal{H}$-Divergence and Disparity Discrepancy will become
    meaningless, when the allowed hypothesis space $\mathcal{H}$ is too large, which
    is common in deep neural networks. Thus, pre-training the deep neural networks
    on large-scale upstream data to decrease the allowed hypotheses is still necessary
    for the domain adversarial methods and hypothesis adversarial methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A final important note is that while there are no theoretical guarantees for
    some well-established methods, they have also achieved quite strong performance
    in practice, such as the *domain translation* methods in Section [3.2.4](#S3.SS2.SSS4
    "3.2.4 Domain Translation ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey") and the *semi-supervised learning* methods in Section
    [3.2.5](#S3.SS2.SSS5 "3.2.5 Semi-Supervised Learning ‣ 3.2 Domain Adaptation ‣
    3 Adaptation ‣ Transferability in Deep Learning: A Survey"). Figure [18](#S3.F18
    "Figure 18 ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey") highlights the cornerstones of domain adaptation methods in deep learning,
    which rely on the reuse of transferability gained in pre-trained deep models.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9c80fa5d148b1d29830a1ffb659e24e0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18: The cornerstones of domain adaptation methods in deep learning.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.1 Statistics Matching
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We have introduced several seminal theories on the generalization bounds for
    domain adaptation, which are all based on the *hypothesis-induced* distribution
    distances. These distances are less intuitive because they rely on unknown hypotheses
    and cannot be computed before learning the hypotheses. In this section, we first
    introduce another family of metrics on the space of *probability measures* well-studied
    in probability theory, which provide interpretable and complementary properties
    to the hypothesis-induced distribution distances and relate closely to a large
    set of domain adaptation algorithms (Long et al., [2015](#bib.bib112), [2017](#bib.bib114)).
  prefs: []
  type: TYPE_NORMAL
- en: Definition 11 (Maximum Mean Discrepancy)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Given two probability distributions $\mathcal{S}$ and $\mathcal{T}$ on a measurable
    space $\mathbf{X}$, the *integral probability metric* (Redko et al., [2020](#bib.bib140))
    is defined as $d_{\mathcal{F}}(\mathcal{S},\mathcal{T})\triangleq\sup_{f\in\mathcal{F}}\big{|}\mathbb{E}_{\mathbf{x}\sim\mathcal{S}}[f(\mathbf{x})]-\mathbb{E}_{\mathbf{x}\sim\mathcal{T}}[f(\mathbf{x})]\big{|}$,
    where $\mathcal{F}$ is a class of bounded functions on $\mathbf{X}$. Sriperumbudur
    et al. ([2010](#bib.bib163)) further restrict $\mathcal{F}$ as the unit ball in
    Reproducing Kernel Hilbert Space (RKHS) $\mathcal{H}_{k}$ endowed with a *characteristic*
    kernel $k$, $\mathcal{F}=\{f\in\mathcal{H}_{k}:||f||_{\mathcal{H}_{k}}\leq 1\}$,
    leading to the *maximum mean discrepancy (MMD)* (Gretton et al., [2012a](#bib.bib57)),
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $d_{\emph{MMD}}^{2}(\mathcal{S},\mathcal{T})=\big{\&#124;}\mathbb{E}_{\mathbf{x}\sim\mathcal{S}}[\phi(\mathbf{x})]-\mathbb{E}_{\mathbf{x}\sim\mathcal{T}}[\phi(\mathbf{x})]\big{\&#124;}_{\mathcal{H}_{k}}^{2},$
    |  | (25) |'
  prefs: []
  type: TYPE_TB
- en: where $\phi(x)$ is a feature map associated with kernel $k$ such that $k(\mathbf{x},\mathbf{x}^{\prime})=\left\langle\phi(\mathbf{x}),\phi(\mathbf{x}^{\prime})\right\rangle$.
    It can be proved from probability theory that $\mathcal{S}=\mathcal{T}$ if and
    only if $d_{\mathcal{F}}(\mathcal{S},\mathcal{T})=0$ or $d_{\emph{MMD}}^{2}(\mathcal{S},\mathcal{T})=0$.
  prefs: []
  type: TYPE_NORMAL
- en: Theorem 12 (Redko et al. ([2020](#bib.bib140)))
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Given the same settings with Definition [11](#Thmtheorem11 "Definition 11 (Maximum
    Mean Discrepancy) ‣ 3.2.1 Statistics Matching ‣ 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey"), let $\ell$ be a convex loss function
    with a parametric form $\ell(y,y^{\prime})=|y-y^{\prime}|^{q}$ for some $q$. Then
    for any $\delta>0$, with probability at least $1-\delta$, the following bound
    holds for all $h\in\mathcal{F}$,'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\epsilon_{\mathcal{T}}(h)$ | $\displaystyle\leq\epsilon_{\mathcal{S}}(h)+d_{\emph{MMD}}(\mathcal{\widehat{\mathcal{S}}},\mathcal{\widehat{T}})+\epsilon_{ideal}$
    |  | (26) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle+\frac{2}{n}\mathbb{E}_{\mathbf{x}\sim\mathcal{S}}[\sqrt{\mathrm{tr}(\mathbf{K}_{\mathcal{S}})}]+\frac{2}{m}\mathbb{E}_{\mathbf{x}\sim\mathcal{T}}[\sqrt{\mathrm{tr}(\mathbf{K}_{\mathcal{T}})}]+\sqrt{\frac{\log\frac{2}{\delta}}{2n}}+\sqrt{\frac{\log\frac{2}{\delta}}{2m}},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{K}_{\mathcal{S}}$ and $\mathbf{K}_{\mathcal{T}}$ are the kernel
    matrices computed on samples from $\mathcal{S}$ and $\mathcal{T}$, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: This bound has several advantages compared to previous theories. First, it is
    *hypothesis-free* and does not require estimating hypotheses to measure the distribution
    distance. Second, the complexity term does not depend on the Vapnik-Chervonenkis
    dimension. Third, the unbiased estimate of MMD can be computed in linear time.
    Fourth, minimizing MMD has a nice interpretation of *statistics matching* in the
    probability space. These advantages make the bound particularly useful to underpin
    several seminal algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep Domain Confusion (DDC) (Tzeng et al., [2014](#bib.bib174)) applies MMD
    with a linear kernel to a single feature layer of the deep network, yet it has
    limited power for closing the domain gap since linear kernel is not characteristic
    and cannot ensure MMD to be a probability metric. Thereby, Deep Adaptation Network
    (DAN) (Long et al., [2015](#bib.bib112), [2019](#bib.bib116)) introduces the multiple-kernel
    variant of MMD (MK-MMD) (Gretton et al., [2012b](#bib.bib58), [a](#bib.bib57))
    to measure the domain relatedness, employing a convex combination of multiple
    characteristic kernels such as Gaussian kernel to make the function space $\mathcal{F}$
    rich enough and enhance the distinguishing power of MK-MMD. Besides, as shown
    in Figure [19](#S3.F19 "Figure 19 ‣ 3.2.1 Statistics Matching ‣ 3.2 Domain Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"), multiple domain-specific
    layers are adapted by MK-MMD, which enables learning transferable features for
    domain adaptation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/76edbd0ec585a41eaeb5f900c6fc3c61.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19: The cornerstone methods of statistics matching: (a) DAN adapts the
    *marginal* distributions of activations in multiple task-specific layers with
    MK-MMD. (b) JAN adapts the *joint* distributions of the feature activations and
    classification predictions with JMMD.'
  prefs: []
  type: TYPE_NORMAL
- en: DAN mainly reduces the shift in the feature distribution and ignores that in
    the label distribution. Take AlexNet as example, the feature distribution shift
    mainly exists in layers $fc6$ and $fc7$ while the label distribution shift mainly
    exists in layer $fc8$. Joint Adaptation Network (JAN) (Long et al., [2017](#bib.bib114))
    proposes Joint Maximum Mean Discrepancy (JMMD) to measure the shift in joint distributions
    $P(\mathbf{X}^{s},\mathbf{Y}^{s})$ and $Q(\mathbf{X}^{t},\mathbf{Y}^{t})$. Denoting
    the activations of adapted layers $\mathcal{L}$ as $\{(\mathbf{z}_{i}^{s1},\dots,\mathbf{z}_{i}^{s|\mathcal{L}|})\}_{i=1}^{n}$
    and $\{(\mathbf{z}_{j}^{t1},\dots,\mathbf{z}_{j}^{t|\mathcal{L}|})\}_{j=1}^{m}$,
    JMMD is defined as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $d_{\text{JMMD}}^{2}(\widehat{\mathcal{S}},\widehat{\mathcal{T}})=\Big{\&#124;}\mathbb{E}_{i\in[n]}\otimes_{l\in\mathcal{L}}\phi^{l}(\mathbf{z}_{i}^{sl})-\mathbb{E}_{j\in[m]}\otimes_{l\in\mathcal{L}}\phi^{l}(\mathbf{z}_{j}^{tl})\Big{\&#124;}_{\mathcal{H}_{k}}^{2}$
    |  | (27) |'
  prefs: []
  type: TYPE_TB
- en: where $\phi^{l}$ is the feature map associated with kernel $k^{l}$ for layer
    $l$ and $\otimes$ is the outer product.
  prefs: []
  type: TYPE_NORMAL
- en: A characteristic kernel widely used in MMD is the Gaussian kernel, or $k(\mathbf{x}_{1},\mathbf{x}_{2})=\exp(-||\mathbf{x}_{1}-\mathbf{x}_{1}||^{2}/{2\sigma^{2}})$.
    After Taylor expansion, MMD can be considered as a weighted sum of distances between
    all orders of statistic moments. Thus, the statistic moments can be directly used
    to measure the distribution distance. For instance, deep CORAL (Sun and Saenko,
    [2016](#bib.bib166)) uses the second-order statistics (covariance) to measure
    distribution distance, which is frustratingly easy yet useful. Center moment discrepancy
    (CMD) (Zellinger et al., [2017](#bib.bib200)) further considers an explicit order-wise
    matching of higher-order moments.
  prefs: []
  type: TYPE_NORMAL
- en: One disadvantage of MMD is that it cannot take into account the geometry of
    the data distribution when estimating the discrepancy between two domains. Thus,
    Joint Distribution Optimal Transport (JDOT) (Courty et al., [2017](#bib.bib34))
    is introduced into domain adaptation, and Deep JDOT (Damodaran et al., [2018](#bib.bib36))
    further extends it to deep networks. Another disadvantage is that minimizing MMD
    on the instance representation has the risk of changing the feature scale, while
    regression tasks are fragile to feature scaling. Thus, Representation Subspace
    Distance (RSD) (Chen et al., [2021b](#bib.bib29)) closes the domain shift through
    orthogonal bases of the representation spaces, which are free from feature scaling.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of explicitly matching the statistics moments of feature distributions,
    Adaptive Batch Normalization (AdaBN) (Li et al., [2017](#bib.bib102)) implicitly
    minimizes domain discrepancy by aligning BatchNorm Ioffe and Szegedy ([2015](#bib.bib77))
    statistics. The hypothesis is that task-related knowledge is stored in the weight
    matrix while domain-related knowledge is represented by BatchNorm statistics.
    Thus AdaBN replaces the mean and variance of all BatchNorm layers with those estimated
    on the target domain at inference to reduce the domain shift. However, it is risky
    that AdaBN excludes the statistics on the target domain from training. Thus, Transferable
    Normalization (TransNorm) (Wang et al., [2019c](#bib.bib185)) applies domain-specific
    mean and variance at both training and inference to capture sufficient statistics
    of both domains.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, both MMD and JMMD may misalign samples from different classes due to
    a suboptimal modeling of the discriminative structure. To alleviate this problem,
    Contrastive Adaptation Network (CAN) (Kang et al., [2019](#bib.bib84)) alternatively
    estimates the labels of target samples through clustering, and adapts the feature
    representations in a class-wise manner. Besides, CAN uses class-aware sampling
    for both domains to improve adaptation efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/561bfb3236019edb72cf3bf9869aa161.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20: Both DANN and CDAN have a feature generator network $\psi$, a classifier
    $h$, and a domain discriminator $D$ connected to $\psi$ via a gradient reversal
    layer. (a) In DANN, the discriminator $D$ is trained to distinguish between domains
    while the generator $\psi$ tries to make the feature distributions indistinguishable
    for the discriminator. (b) In CDAN, the discriminator $D$ is conditioned on the
    classifier prediction $\widehat{\mathbf{y}}$ via a multilinear map $\mathbf{z}\otimes\widehat{\mathbf{y}}$.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2 Domain Adversarial Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Domain Adversarial Neural Network.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'An important milestone for modeling distributions is the Generative Adversarial
    Net (GAN) (Goodfellow et al., [2014](#bib.bib54)). Inspired by GAN, Domain Adversarial
    Neural Network (DANN) (Ganin and Lempitsky, [2015](#bib.bib45); Ganin et al.,
    [2016](#bib.bib46)) integrates a two-player game into domain adaptation (Figure
    [20](#S3.F20 "Figure 20 ‣ 3.2.1 Statistics Matching ‣ 3.2 Domain Adaptation ‣
    3 Adaptation ‣ Transferability in Deep Learning: A Survey")). The first player
    is the domain discriminator $D$ trained to distinguish the source features from
    the target features and the second player is the feature generator $\psi$ trained
    simultaneously to confuse the domain discriminator. As mentioned in Section [3.2](#S3.SS2
    "3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"),
    the upper bound of $\mathcal{H}\Delta\mathcal{H}$-Divergence between feature distributions
    can be estimated by training the domain discriminator $D$,'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $L_{\text{DANN}}(\psi)=\max_{D}\mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}\log[D(\mathbf{z}^{s})]+\mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}\log[1-D(\mathbf{z}^{t})],$
    |  | (28) |'
  prefs: []
  type: TYPE_TB
- en: 'where $\mathbf{z}=\psi(\mathbf{x})$ is the feature representation for $\mathbf{x}$.
    The objective of the feature generator $\psi$ is to minimize the source error
    as well as the $\mathcal{H}\Delta\mathcal{H}$-Divergence bounded by Equation [28](#S3.E28
    "In Domain Adversarial Neural Network. ‣ 3.2.2 Domain Adversarial Learning ‣ 3.2
    Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"),'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\min_{\psi,h}\mathbb{E}_{(\mathbf{x}^{s},\mathbf{y}^{s})\sim\widehat{\mathcal{S}}}L_{\text{CE}}(h(\mathbf{z}^{s}),\mathbf{y}^{s})+\lambda
    L_{\text{DANN}}(\psi),$ |  | (29) |'
  prefs: []
  type: TYPE_TB
- en: where $L_{\text{CE}}$ is the cross-entropy loss, $\lambda$ is a hyper-parameter
    that trades off source error and domain adversary. Minimizing the cross-entropy
    loss will lead to discriminative representations while decreasing the domain adversarial
    loss will result in transferable representations.
  prefs: []
  type: TYPE_NORMAL
- en: 'DANN aligns the marginal feature distributions through adversarial training.
    However, this may be insufficient when the feature-label joint distributions change
    between domains. Besides, the feature distribution is usually multimodal in multi-class
    classification, thus even if the discriminator is fully confused, there is no
    guarantee that the two feature distributions are similar (Arora et al., [2017](#bib.bib5)).
    To tackle these two issues, Conditional Domain Adversarial Network (CDAN) (Long
    et al., [2018](#bib.bib115)) conditions features $\mathbf{z}$ on classifier predictions
    $\widehat{\mathbf{y}}=h(\mathbf{z})$ and introduces multilinear map $\mathbf{z}\otimes\widehat{\mathbf{y}}$
    instead of $\mathbf{z}$ as the input to domain discriminator $D$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $L_{\text{CDAN}}(\psi)=\max_{D}\mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}\log[D(\mathbf{z}^{s}\otimes\widehat{\mathbf{y}}^{s})]+\mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}\log[1-D(\mathbf{z}^{t}\otimes\widehat{\mathbf{y}}^{t})].$
    |  | (30) |'
  prefs: []
  type: TYPE_TB
- en: Conditioning on $\widehat{\mathbf{y}}$, CDAN fully captures cross-variance between
    the feature representation and classifier prediction, resulting in better alignment
    of the joint distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Tzeng et al. ([2015](#bib.bib175)) align the class distributions explicitly
    by transferring the similarity structure in classes from the source domain to
    the target domain. Specifically, the average output probability of data from each
    class is computed over the source samples as soft labels. Then the model is optimized
    to match the distribution over classes to the soft labels.
  prefs: []
  type: TYPE_NORMAL
- en: Improvements.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: DANN integrates a gradient reverse layer (GRL) into the standard architecture
    to implement the minimax between the feature generator and domain classifier.
    However, this optimizing strategy might not work well in practice due to gradient
    vanishing, which is also a major problem in training GANs. For instance, when
    the generated target features $\mathbf{z}^{t}$ are very distinguishable from source
    features such that $D(\mathbf{z}^{t})=0$, the gradient for the feature generator
    is small and vice versa. This makes the optimization of the feature generator
    difficult. Thus, Adversarial Discriminative Domain Adaptation (ADDA) (Tzeng et al.,
    [2017](#bib.bib176)) splits the optimization of feature generator $\psi$ and domain
    classifier $D$ into two independent objectives, where the maximization of $D$
    remains unchanged, but the objective of $\psi$ becomes
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\min_{\psi}\mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}-\log[D(\mathbf{z}^{t})].$
    |  | (31) |'
  prefs: []
  type: TYPE_TB
- en: This assigns small gradients for source-like target samples and larger gradients
    for the other target samples. It has the same fixed-point properties as GRL while
    making the optimization easier for the feature generator. Although adversarial
    domain adaptation enhances the feature *transferability*, i.e. the ability of
    feature representations to bridge the discrepancy across domains, studies (Chen
    et al., [2019c](#bib.bib28)) reveal that it is at the expense of deteriorating
    the *discriminability*, i.e. the easiness of separating categories over the fixed
    feature representations of both domains. Spectral analysis shows that only the
    eigenvectors corresponding to the largest singular values tend to carry transferable
    knowledge, while other eigenvectors may reflect domain variations and thus be
    overly penalized in domain adversarial training. However, these eigenvectors may
    convey crucial discriminative information, and thus the discriminability is weakened.
    To tackle this transferability-discriminability dilemma, Batch Spectral Penalization
    (BSP) (Chen et al., [2019c](#bib.bib28)) penalizes the largest singular values
    so that the other eigenvectors can be relatively strengthened to boost the feature
    discriminability. Domain Separation Network (DSN) (Bousmalis et al., [2016](#bib.bib15))
    introduces a private subspace for each domain, which preserves domain-specific
    information, such as background and low-level image statistics. Then domain alignment
    is performed safely in the shared subspace, which is orthogonal to the private
    subspace responsible for the discriminative tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Domain Adversarial Leanring in Real-World Scenarios.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Domain adversarial learning has largely improved the performance on unlabeled
    target domain and has been widely adopted in many applications (Hoffman et al.,
    [2016](#bib.bib71); Chen et al., [2018](#bib.bib30)). However, real-world scenarios
    are much more complex. Here we list several situations that are often encountered
    yet not well resolved, and review some existing solutions to them.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/706624197a5526daa980a3d256897cf9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21: Where to adapt in different methods. (a) DANN performs alignment
    on global features. (b) DA-Faster performs alignment on both image-level and instance-level
    features. (c) SWDA performs alignment on local features. (d) Adapt-SegMap performs
    alignment on local outputs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Which part to adapt is unknown. In image recognition, we only need to classify
    the input. Yet in applications such as object detection, we need to locate the
    Region of Interests (RoIs) first and then classify them. Due to the distribution
    shift across domains, the localization of RoIs on the target domain is not reliable,
    thus which part to adapt in the adversarial training is unknown. To alleviate
    this problem, as shown in Figure [21](#S3.F21 "Figure 21 ‣ Domain Adversarial
    Leanring in Real-World Scenarios. ‣ 3.2.2 Domain Adversarial Learning ‣ 3.2 Domain
    Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"), DA-Faster
    (Chen et al., [2018](#bib.bib30)) performs domain alignment at both image level
    and instance level, where the image-level alignment is believed to improve the
    localization of RoIs on the target domain. SWDA (Saito et al., [2019](#bib.bib147))
    argues that alignment of the local features is more effective than that of the
    global features for better localization. Although the above adversarial training
    methods have improved the transferability of object detectors, the discriminability
    might get lost in the adversarial adaptation process as mentioned by BSP (Chen
    et al., [2019c](#bib.bib28)). Since discriminability is crucial for the localization
    of RoIs, D-adapt (Jiang et al., [2022](#bib.bib81)) introduces parameter-independent
    category adaptor and bounding box adaptor to decouple adversarial adaptation from
    detector training, which yields sharp improvement.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are structural dependencies between labels of each sample. In low-level
    classification tasks, such as semantic segmentation or token classification (Named
    Entity Recognition, Parts-of-speech tagging, etc.), adaptation on *features* (Hoffman
    et al., [2016](#bib.bib71)) may not be a good option, because the feature of each
    pixel or each token is high-dimensional and there exist many pixels or tokens
    in a single sample. Every coin has two sides. Compared to the high-level classification
    tasks, the *output space* of these low-level tasks contains much richer information
    of the distribution, e.g., scene layout and context, and thus adaptation on the
    output space can reduce the domain shift. As shown in Figure [21](#S3.F21 "Figure
    21 ‣ Domain Adversarial Leanring in Real-World Scenarios. ‣ 3.2.2 Domain Adversarial
    Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey"), Adapt-SegMap (Tsai et al., [2018](#bib.bib173)) trains a discriminator
    to distinguish whether the segmentation output is from the source or the target,
    while the feature generator is encouraged to generate similar segmentation outputs
    across domains. It explicitly aligns the output distributions of target and source
    domains, and implicitly adapts the feature distributions. Further, ADVENT (Vu
    et al., [2019](#bib.bib182)) minimizes the distribution distance on the self-information
    distributions, where the entropy of segmentation outputs is fed to the discriminator.
    In this way, the conditional information is neglected while more attention is
    paid to the structural dependencies between local semantics.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.3 Hypothesis Adversarial Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Inevitably, there is still a gap between the proxy distance used in previous
    methods and the hypothesis-induced discrepancies in the theories. To close this
    gap, Maximum Classifier Discrepancy (MCD) (Saito et al., [2018](#bib.bib146))
    starts to estimate and optimize $\mathcal{H}\Delta\mathcal{H}$-Divergence in a
    fully parameterized way. As shown in Figure [22](#S3.F22 "Figure 22 ‣ 3.2.3 Hypothesis
    Adversarial Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey"), MCD maximizes the discrepancy between two classifiers’
    outputs to detect target samples far from the support of source distribution,
    i.e. estimate $\mathcal{H}\Delta\mathcal{H}$-Divergence. A feature generator then
    learns to generate target features near the support to minimize the discrepancy,
    i.e. minimize the domain discrepancy. MCD uses the $L_{1}$ distance to calculate
    the discrepancy, while Sliced Wasserstein Discrepancy (SWD) (Lee et al., [2019](#bib.bib95))
    adopts the Wasserstein metric, which is the natural geometry for probability measures
    induced by the optimal transport theory. In theory MCD is closer to $\mathcal{H}\Delta\mathcal{H}$-Divergence,
    yet in experiments it is slow in convergence and very sensitive to hyper-parameters.
    The reason is that there exist two classifiers $h$ and $h^{\prime}$ in MCD that
    maximize the discrepancy, which makes the minimax optimization hard to reach equilibrium.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Disparity Discrepancy (DD) (Zhang et al., [2019c](#bib.bib204)) provides a
    tighter bound by taking supremum in hypothesis space $\mathcal{H}$ rather than
    $\mathcal{H}\Delta\mathcal{H}$. This will significantly ease the minimax optimization.
    As shown in Figure [22](#S3.F22 "Figure 22 ‣ 3.2.3 Hypothesis Adversarial Learning
    ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"),
    DD introduces an adversarial classifier $h^{\prime}$ sharing the same hypothesis
    space with $h$. The supremum in $d_{h,\mathcal{H}}(\mathcal{S},\mathcal{T})$ is
    approximated by'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | <math   alttext="\begin{split}L_{\text{DD}}(h,\psi)=\max_{h^{\prime}}&amp;\
    \mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}L^{s}\left[h^{\prime}(\psi(\mathbf{x}^{s})),h(\psi(\mathbf{x}^{s}))\right]\\
    -&amp;\ \mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}L^{t}\left[h^{\prime}(\psi(\mathbf{x}^{t})),h(\psi(\mathbf{x}^{t}))\right],\\'
  prefs: []
  type: TYPE_NORMAL
- en: \end{split}" display="block"><semantics ><mtable columnspacing="0pt"
    displaystyle="true" rowspacing="0pt" ><mtr ><mtd
     columnalign="right" ><mrow ><mrow
    ><msub ><mi
     >L</mi><mtext 
    >DD</mtext></msub><mo lspace="0em" rspace="0em"
     >​</mo><mrow
    ><mo stretchy="false" 
    >(</mo><mi  >h</mi><mo
     >,</mo><mi 
    >ψ</mi><mo stretchy="false" 
    >)</mo></mrow></mrow><mo 
    >=</mo><munder ><mi
     >max</mi><msup 
    ><mi 
    >h</mi><mo 
    >′</mo></msup></munder></mrow></mtd><mtd
     columnalign="left" ><mrow ><msub
    ><mi  >𝔼</mi><mrow
     ><msup
     ><mi
     >𝐱</mi><mi
     >s</mi></msup><mo
     >∼</mo><mover
    accent="true"  ><mi
      >𝒮</mi><mo
     >^</mo></mover></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><msup
    ><mi  >L</mi><mi
     >s</mi></msup><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo  >[</mo><mrow
    ><msup ><mi
     >h</mi><mo
     >′</mo></msup><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" 
    >(</mo><mrow ><mi
     >ψ</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" 
    >(</mo><msup ><mi
     >𝐱</mi><mi
     >s</mi></msup><mo
    stretchy="false"  >)</mo></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow><mo
     >,</mo><mrow
    ><mi  >h</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" 
    >(</mo><mrow ><mi
     >ψ</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" 
    >(</mo><msup ><mi
     >𝐱</mi><mi
     >s</mi></msup><mo
    stretchy="false"  >)</mo></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow><mo
     >]</mo></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><mo
     >−</mo></mtd><mtd
     columnalign="left" ><mrow ><mrow
    ><msub ><mi
     >𝔼</mi><mrow
     ><msup 
    ><mi 
    >𝐱</mi><mi 
    >t</mi></msup><mo 
    >∼</mo><mover accent="true" 
    ><mi 
     >𝒯</mi><mo
     >^</mo></mover></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><msup
    ><mi  >L</mi><mi
     >t</mi></msup><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo  >[</mo><mrow
    ><msup ><mi
     >h</mi><mo 
    >′</mo></msup><mo lspace="0em" rspace="0em"
     >​</mo><mrow
    ><mo stretchy="false" 
    >(</mo><mrow ><mi
     >ψ</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" 
    >(</mo><msup ><mi
     >𝐱</mi><mi
     >t</mi></msup><mo
    stretchy="false"  >)</mo></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow><mo
     >,</mo><mrow
    ><mi 
    >h</mi><mo lspace="0em" rspace="0em" 
    >​</mo><mrow ><mo
    stretchy="false"  >(</mo><mrow
    ><mi 
    >ψ</mi><mo lspace="0em" rspace="0em" 
    >​</mo><mrow ><mo
    stretchy="false"  >(</mo><msup
    ><mi 
    >𝐱</mi><mi 
    >t</mi></msup><mo stretchy="false" 
    >)</mo></mrow></mrow><mo stretchy="false" 
    >)</mo></mrow></mrow><mo 
    >]</mo></mrow></mrow><mo 
    >,</mo></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply 
    ><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝐿</ci><ci  ><mtext
    mathsize="70%"  >DD</mtext></ci></apply><interval
    closure="open"  ><ci
     >ℎ</ci><ci 
    >𝜓</ci></interval></apply><apply 
    ><apply 
    ><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >ℎ</ci><ci 
    >′</ci></apply></apply><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝔼</ci><apply 
    ><csymbol cd="latexml" 
    >similar-to</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >𝐱</ci><ci 
    >𝑠</ci></apply><apply 
    ><ci 
    >^</ci><ci 
    >𝒮</ci></apply></apply></apply><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >𝐿</ci><ci 
    >𝑠</ci></apply></apply></apply><interval closure="closed"
     ><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >ℎ</ci><ci
     >′</ci></apply><apply
     ><ci
     >𝜓</ci><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >𝐱</ci><ci
     >𝑠</ci></apply></apply></apply><apply
     ><ci
     >ℎ</ci><apply
     ><ci
     >𝜓</ci><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >𝐱</ci><ci
     >𝑠</ci></apply></apply></apply></interval></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝔼</ci><apply
     ><csymbol
    cd="latexml"  >similar-to</csymbol><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >𝐱</ci><ci
     >𝑡</ci></apply><apply
     ><ci
     >^</ci><ci
     >𝒯</ci></apply></apply></apply><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >𝐿</ci><ci 
    >𝑡</ci></apply><interval closure="closed" 
    ><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >ℎ</ci><ci 
    >′</ci></apply><apply 
    ><ci  >𝜓</ci><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >𝐱</ci><ci
     >𝑡</ci></apply></apply></apply><apply
     ><ci
     >ℎ</ci><apply
     ><ci
     >𝜓</ci><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >𝐱</ci><ci
     >𝑡</ci></apply></apply></apply></interval></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}L_{\text{DD}}(h,\psi)=\max_{h^{\prime}}&\
    \mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}L^{s}\left[h^{\prime}(\psi(\mathbf{x}^{s})),h(\psi(\mathbf{x}^{s}))\right]\\
    -&\ \mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}L^{t}\left[h^{\prime}(\psi(\mathbf{x}^{t})),h(\psi(\mathbf{x}^{t}))\right],\\
    \end{split}</annotation></semantics></math> |  | (32) |
  prefs: []
  type: TYPE_NORMAL
- en: where $L^{s}$ and $L^{t}$ are specific loss functions defined on the source
    domain and target domain respectively. Based on the theory (Zhang et al., [2019c](#bib.bib204)),
    when the adversarial classifier $h^{\prime}$ is close to the supremum, minimizing
    the following terms will decrease the target error $\epsilon_{\mathcal{T}}$,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\min_{\psi,h}\ \mathbb{E}_{(\mathbf{x}^{s},\mathbf{y}^{s})\sim\widehat{\mathcal{S}}}L_{\text{CE}}(h(\psi(\mathbf{x}^{s})),\mathbf{y}^{s})+\lambda
    L_{\text{DD}}(h,\psi),$ |  | (33) |'
  prefs: []
  type: TYPE_TB
- en: where $\lambda$ is a tradeoff hyper-parameter. An intuitive explanation is that
    DD is looking for an adversarial classifier $h^{\prime}$ that predicts correctly
    on the source domain while making different predictions from $h$ on the target
    domain. And then the feature generator $\psi$ is encouraged to generate features
    near the decision boundary to avoid such situations.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6e88626d3639be2911eb67ccbdfe7068.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22: (a) The training of MCD has three steps. Step A: Both the classifiers
    and the feature generator are trained to classify the source samples correctly.
    Step B: The classifiers $h_{1}$ and $h_{2}$ learn to maximize the discrepancy
    on the target samples. (b) Step C: The feature generator $\psi$ learns to minimize
    the discrepancy on the target samples. (c) DD and MDD introduce an adversarial
    classifier $h^{\prime}$ to maximize the discrepancy and trains the feature generator
    $\psi$ to minimize the source error as well as the discrepancy.'
  prefs: []
  type: TYPE_NORMAL
- en: However, DD is still limited to the $01$ loss in the classification setting.
    Based on scoring functions and margin loss, Margin Disparity Discrepancy (MDD)
    (Zhang et al., [2019c](#bib.bib204)) goes a crucial step forward and provides
    a *margin* theory for the multi-class classification setting. The margin $\rho$
    is attained by introducing parameter $\gamma\triangleq\exp\rho$ in the disparity
    discrepancy,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | <math   alttext="\begin{split}L_{\text{MDD}}(h,\psi)=\max_{h^{\prime}}\
    \gamma&amp;\ \mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}\log\left[\sigma_{h(\psi(\mathbf{x}^{s}))}(h^{\prime}(\psi(\mathbf{x}^{s})))\right]\\
    +&amp;\ \mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}\log\left[1-\sigma_{h(\psi(\mathbf{x}^{t}))}(h^{\prime}(\psi(\mathbf{x}^{t})))\right],\\'
  prefs: []
  type: TYPE_NORMAL
- en: \end{split}" display="block"><semantics ><mtable columnspacing="0pt"
    displaystyle="true" rowspacing="0pt" ><mtr ><mtd
     columnalign="right" ><mrow ><mrow
    ><msub ><mi
     >L</mi><mtext 
    >MDD</mtext></msub><mo lspace="0em" rspace="0em"
     >​</mo><mrow
    ><mo stretchy="false" 
    >(</mo><mi  >h</mi><mo
     >,</mo><mi 
    >ψ</mi><mo stretchy="false" 
    >)</mo></mrow></mrow><mo 
    >=</mo><mrow ><munder
    ><mi  >max</mi><msup
     ><mi
     >h</mi><mo
     >′</mo></msup></munder><mo
    lspace="0.167em"  >⁡</mo><mi
     >γ</mi></mrow></mrow></mtd><mtd
     columnalign="left" ><mrow ><msub
    ><mi  >𝔼</mi><mrow
     ><msup
     ><mi
     >𝐱</mi><mi
     >s</mi></msup><mo
     >∼</mo><mover
    accent="true"  ><mi
      >𝒮</mi><mo
     >^</mo></mover></mrow></msub><mo
    lspace="0.167em" rspace="0em"  >​</mo><mrow
    ><mi  >log</mi><mo
     >⁡</mo><mrow
    ><mo  >[</mo><mrow
    ><msub ><mi
     >σ</mi><mrow
     ><mi 
    >h</mi><mo lspace="0em" rspace="0em"
     >​</mo><mrow
     ><mo
    stretchy="false"  >(</mo><mrow
     ><mi
     >ψ</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
     ><mo
    stretchy="false"  >(</mo><msup
     ><mi
     >𝐱</mi><mi
     >s</mi></msup><mo
    stretchy="false"  >)</mo></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" 
    >(</mo><mrow ><msup
    ><mi 
    >h</mi><mo 
    >′</mo></msup><mo lspace="0em" rspace="0em"
     >​</mo><mrow
    ><mo stretchy="false" 
    >(</mo><mrow ><mi
     >ψ</mi><mo
    lspace="0em" rspace="0em" 
    >​</mo><mrow ><mo
    stretchy="false"  >(</mo><msup
    ><mi 
    >𝐱</mi><mi 
    >s</mi></msup><mo stretchy="false" 
    >)</mo></mrow></mrow><mo stretchy="false" 
    >)</mo></mrow></mrow><mo stretchy="false" 
    >)</mo></mrow></mrow><mo 
    >]</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><mo
     >+</mo></mtd><mtd
     columnalign="left" ><mrow ><mrow
    ><msub ><mi
     >𝔼</mi><mrow
     ><msup 
    ><mi 
    >𝐱</mi><mi 
    >t</mi></msup><mo 
    >∼</mo><mover accent="true" 
    ><mi 
     >𝒯</mi><mo
     >^</mo></mover></mrow></msub><mo
    lspace="0.167em" rspace="0em"  >​</mo><mrow
    ><mi  >log</mi><mo
     >⁡</mo><mrow
    ><mo  >[</mo><mrow
    ><mn 
    >1</mn><mo  >−</mo><mrow
    ><msub ><mi
     >σ</mi><mrow
     ><mi 
    >h</mi><mo lspace="0em" rspace="0em" 
    >​</mo><mrow 
    ><mo stretchy="false" 
    >(</mo><mrow 
    ><mi 
    >ψ</mi><mo lspace="0em" rspace="0em"
     >​</mo><mrow
     ><mo
    stretchy="false"  >(</mo><msup
     ><mi
     >𝐱</mi><mi
     >t</mi></msup><mo
    stretchy="false"  >)</mo></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" 
    >(</mo><mrow ><msup
    ><mi 
    >h</mi><mo 
    >′</mo></msup><mo lspace="0em" rspace="0em"
     >​</mo><mrow
    ><mo stretchy="false"
     >(</mo><mrow
    ><mi 
    >ψ</mi><mo lspace="0em" rspace="0em" 
    >​</mo><mrow ><mo
    stretchy="false"  >(</mo><msup
    ><mi 
    >𝐱</mi><mi 
    >t</mi></msup><mo stretchy="false" 
    >)</mo></mrow></mrow><mo stretchy="false" 
    >)</mo></mrow></mrow><mo stretchy="false" 
    >)</mo></mrow></mrow></mrow><mo 
    >]</mo></mrow></mrow></mrow><mo 
    >,</mo></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply 
    ><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝐿</ci><ci  ><mtext
    mathsize="70%"  >MDD</mtext></ci></apply><interval
    closure="open"  ><ci
     >ℎ</ci><ci 
    >𝜓</ci></interval></apply><apply 
    ><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >ℎ</ci><ci 
    >′</ci></apply></apply><apply 
    ><ci 
    >𝛾</ci><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝔼</ci><apply 
    ><csymbol cd="latexml" 
    >similar-to</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >𝐱</ci><ci 
    >𝑠</ci></apply><apply 
    ><ci 
    >^</ci><ci 
    >𝒮</ci></apply></apply></apply><apply 
    ><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝜎</ci><apply 
    ><ci 
    >ℎ</ci><apply 
    ><ci 
    >𝜓</ci><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >𝐱</ci><ci 
    >𝑠</ci></apply></apply></apply></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >ℎ</ci><ci
     >′</ci></apply><apply
     ><ci
     >𝜓</ci><apply
     ><csymbol
    cd="ambiguous" 
    >superscript</csymbol><ci 
    >𝐱</ci><ci 
    >𝑠</ci></apply></apply></apply></apply></apply></apply></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝔼</ci><apply
     ><csymbol
    cd="latexml"  >similar-to</csymbol><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >𝐱</ci><ci
     >𝑡</ci></apply><apply
     ><ci
     >^</ci><ci
     >𝒯</ci></apply></apply></apply><apply
     ><apply
     ><cn
    type="integer"  >1</cn><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝜎</ci><apply
     ><ci 
    >ℎ</ci><apply 
    ><ci 
    >𝜓</ci><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >𝐱</ci><ci 
    >𝑡</ci></apply></apply></apply></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >ℎ</ci><ci
     >′</ci></apply><apply
     ><ci
     >𝜓</ci><apply
     ><csymbol
    cd="ambiguous" 
    >superscript</csymbol><ci 
    >𝐱</ci><ci 
    >𝑡</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}L_{\text{MDD}}(h,\psi)=\max_{h^{\prime}}\
    \gamma&\ \mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}\log\left[\sigma_{h(\psi(\mathbf{x}^{s}))}(h^{\prime}(\psi(\mathbf{x}^{s})))\right]\\
    +&\ \mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}\log\left[1-\sigma_{h(\psi(\mathbf{x}^{t}))}(h^{\prime}(\psi(\mathbf{x}^{t})))\right],\\
    \end{split}</annotation></semantics></math> |  | (34) |
  prefs: []
  type: TYPE_NORMAL
- en: 'where $\sigma$ is the softmax function. A proper $\gamma$ can constrain $h^{\prime}$
    in a hypothesis space of proper size to avoid overestimation of the generalization
    bound. Note that in Equation [34](#S3.E34 "In 3.2.3 Hypothesis Adversarial Learning
    ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"),
    the loss on the source domain is the standard cross-entropy, while that on the
    target domain is a modified cross-entropy to avoid gradient vanishing and ease
    the optimization of $h^{\prime}$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In principle, DD can be easily extended to regression problems by replacing
    the classifiers in Figure [22](#S3.F22 "Figure 22 ‣ 3.2.3 Hypothesis Adversarial
    Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey") with regressors and choosing $L^{s}$ and $L^{t}$ as the $L_{1}$ or
    $L_{2}$ loss commonly used in regression. It has been extended to both keypoint
    detection (Jiang et al., [2021](#bib.bib80)) and bounding box localization task
    (Jiang et al., [2022](#bib.bib81)). To tackle the challenge caused by the high-dimensional
    output space in the keypoint detection, Regressive Domain Adaptation (RegDA) (Jiang
    et al., [2021](#bib.bib80)) introduces a spatial probability distribution to describe
    the sparse density of the output space and uses it to guide the optimization of
    the adversarial regressor $h^{\prime}$. In an expectation sense, this reduces
    the size of the hypothesis space of $h^{\prime}$ and avoids overestimation of
    the generalization bound in Zhang et al. ([2019c](#bib.bib204)).'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.4 Domain Translation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Domain translation is the task of mapping *raw data* of text, image, audio,
    and other data modality from the source distribution $\mathcal{S}$ to the target
    distribution $\mathcal{T}$. In domain adaptation problems, we can use translation
    models, usually based on Generate Adversarial Networks (GAN) (Goodfellow et al.,
    [2014](#bib.bib54)), to obtain labeled source domain in the target style, i.e.
    translated into the target distribution. Training on such stylized source domain
    can yield better transferability than models trained on the original source domain.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e3ca12b264f23573a911cf2a886a0d1c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 23: (a) The architecture for PixelDA includes a generator network $G$,
    an adversarial discriminator $D$ and a task-specific classifier $h$ on feature
    extractor $\psi$. (b) Cycle-consistency loss: after we translate from source domain
    to target domain, we should recover the source data if translating back again.
    (c) Semantic-consistency loss: translating between domains should not change the
    semantic labels of the samples, where $f$ is the labeling function.'
  prefs: []
  type: TYPE_NORMAL
- en: GANs reason about the marginal distribution, i.e., from a random vector, the
    generator network should synthesize data that resembles one that is drawn from
    the true distribution. However, marginal distribution is not enough for domain
    adaptation, thus Coupled Generative Adversarial Networks (CoGAN) (Liu and Tuzel,
    [2016](#bib.bib106)) learns a joint distribution of multi-domain images from data,
    i.e., from a random vector, multiple generators should generate paired data that
    are from different distributions and share the same labels. By enforcing a weight-sharing
    constraint between different generators, CoGAN learns a joint distribution without
    the existence of corresponding images in different domains. Then the shared labels
    of the target samples are used to train the target model.
  prefs: []
  type: TYPE_NORMAL
- en: 'A more common objective of domain translation is to learn a mapping $G:\mathcal{S}\rightarrow\mathcal{T}$
    such that the generated sample $G(\mathbf{x})$ is indistinguishable from the training
    samples of the target domain. As shown in Figure [23](#S3.F23 "Figure 23 ‣ 3.2.4
    Domain Translation ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in
    Deep Learning: A Survey"), PixelDA (Bousmalis et al., [2017](#bib.bib16)) introduces
    an adversarial discriminator $D$ to distinguish between translated samples and
    target samples,'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle L_{\mathrm{GAN}}(G)$ | $\displaystyle=\max_{D}\mathbb{E}_{\mathbf{x}\sim\widehat{\mathcal{S}}}\log\left[1-D(G(\mathbf{x}))\right]+\mathbb{E}_{\mathbf{x}\sim\widehat{\mathcal{T}}}\log\left[D(\mathbf{x})\right].$
    |  | (35) |'
  prefs: []
  type: TYPE_TB
- en: The generator $G$ tries to synthesize samples $G(\mathbf{x})$ that look similar
    to images from the target domain by $\min_{G}L_{\mathrm{GAN}}(G)$. The task-specific
    classifier $h$ and feature extractor $\psi$ are trained supervisedly on the target-style
    generated data by $\min_{\psi,h}\mathbb{E}_{(\mathbf{x},\mathbf{y})\sim\widehat{\mathcal{S}}}L_{\text{sup}}(h\circ\psi(G(\mathbf{x})),\mathbf{y})$.
  prefs: []
  type: TYPE_NORMAL
- en: Cycle Consistency.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'While GAN can learn a mapping between two datasets, the desired mapping may
    not be obtained. The source sample may be projected to an irrelevant target sample,
    destroying the structure or content of the original samples. Besides, multiple
    source samples may be mapped to the same target sample, leading to the well-known
    problem of *mode collapse* (Goodfellow et al., [2014](#bib.bib54)). Therefore,
    CycleGAN (Zhu et al., [2017](#bib.bib209)) introduces an additional mapping $F:\mathcal{T}\rightarrow\mathcal{S}$
    from target to source and adds a constraint of cycle consistency to reduce the
    space of possible mapping functions (Figure [23](#S3.F23 "Figure 23 ‣ 3.2.4 Domain
    Translation ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey")). Mathematically, cycle consistency requires $F$ and $G$ to be bijections
    and inverse of each other. In practice, CycleGAN constrains $F(G(\mathbf{x}))\approx\mathbf{x}$
    and $G(F(\mathbf{x}))\approx\mathbf{x}$, which preserves the structure or content
    of samples to obtain more meaningful mappings. CycleGAN has been widely used in
    domain adaptation problems, such as image classification (Hoffman et al., [2018](#bib.bib72)),
    semantic segmentation (Hoffman et al., [2018](#bib.bib72)), person re-identification
    (Wei et al., [2018](#bib.bib189)), robotic grasping (Bousmalis et al., [2018](#bib.bib17)),
    object detection (Kim et al., [2019](#bib.bib85)), etc. The idea goes beyond the
    field of image translation and is widely used in other fields, such as unsupervised
    machine translation (Lample et al., [2017](#bib.bib92)), where the cycle consistency
    is also called back-translation. Unsupervised machine translation can further
    be used for cross-lingual domain adaptation tasks (Conneau et al., [2018](#bib.bib33)),
    where a language is a domain.'
  prefs: []
  type: TYPE_NORMAL
- en: Semantic Consistency.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'CycleGAN is a general-purpose translation model for vision tasks and is apt
    at style transfer between datasets. However, it is difficult for CycleGAN to maintain
    the semantic information. It has been experimentally shown that when mapping from
    source to target, the problem of label flipping will easily occur (Bousmalis et al.,
    [2017](#bib.bib16); Hoffman et al., [2018](#bib.bib72)). As a result, there will
    exist a lot of noisy labels in the translated dataset, hurting the performance
    of the target model. Thus, ensuring semantic consistency is important for translation-based
    domain adaptation. Formally, given the labeling function $f$, the labels assigned
    to sample $\mathbf{x}$ should be consistent with that of the translated sample,
    i.e., $f(\mathbf{x})=f(G(\mathbf{x}))$ (Figure [23](#S3.F23 "Figure 23 ‣ 3.2.4
    Domain Translation ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in
    Deep Learning: A Survey")). Since function $f$ is not accessible, several proxy
    functions have been proposed to approximate the semantic consistency (Taigman
    et al., [2017](#bib.bib169); Hoffman et al., [2018](#bib.bib72); Bousmalis et al.,
    [2018](#bib.bib17)). Given a proxy function $h_{\mathrm{p}}$ and a distance measure
    $d$, the objective is to reduce the semantic inconsistency,'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\min_{G}L_{\mathrm{sc}}(G,h_{\mathrm{p}})=d(h_{\mathrm{p}}(\mathbf{x}),h_{\mathrm{p}}(G(\mathbf{x}))).$
    |  | (36) |'
  prefs: []
  type: TYPE_TB
- en: DTN (Taigman et al., [2017](#bib.bib169)) and SimGAN (Shrivastava et al., [2017](#bib.bib157))
    use the feature extractor as a proxy function and the goal is to translate the
    low-level style while keeping the high-level features invariant. PersonGAN (Wei
    et al., [2018](#bib.bib189)) uses the foreground crop of the person image as the
    proxy function of the person’s identity, which ensures that a person’s identity
    remains the same before and after translation. However, the constraint on feature
    or pixel space might be too strong, making it difficult to change the low-level
    style. Therefore, Cycle-consistent Adversarial Adaptation (CyCADA) (Hoffman et al.,
    [2018](#bib.bib72)) utilizes a pre-trained source model as a proxy function to
    encourage generating samples that have consistent predictions under the function.
    This proxy function effectively avoids label flipping during the translation of
    handwritten digit images, yet it is still not perfect. When faced with the dataset
    shift of real-world problems, the predictions on the generated samples are not
    reliable and may provide incorrect guidance to $G$.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the domain difference is primarily low-level, such as textures, illumination,
    and color, translation can effectively close the domain gap. But when the domain
    is different at the high level, such as from different camera angles, translation
    may fail to adapt domains. Therefore, translation methods at the low-level and
    adaptation methods at the high-level mentioned in Section [3.2.1](#S3.SS2.SSS1
    "3.2.1 Statistics Matching ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")-[3.2.3](#S3.SS2.SSS3 "3.2.3 Hypothesis Adversarial
    Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey") are complementary and can be combined in practical applications (Hoffman
    et al., [2018](#bib.bib72)). For example, Generate to Adapt (Sankaranarayanan
    et al., [2018](#bib.bib149)) directly uses the generative task as an auxiliary
    task to align features across domains.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.5 Semi-Supervised Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Unsupervised Domain Adaptation (UDA) is closely related to Semi-Supervised
    Learning (SSL) since both of them aim at generalizing from the labeled samples
    to the unlabeled samples. The difference is that in SSL, both the labeled and
    unlabeled samples come from the same distribution while in UDA, the source and
    target distributions differ. Thus, SSL tasks can be considered as a special case
    of UDA tasks and some SSL methods can be applied in UDA tasks. Since there is
    still no theoretical guarantee for SSL methods in the UDA scenario, the first
    question to answer is, under what assumptions can we use SSL in UDA? There are
    mainly three assumptions in SSL (Chapelle et al., [2006](#bib.bib21)). (1) Smoothness
    Assumption: if two samples $\mathbf{x}_{1}$, $\mathbf{x}_{2}$ residing in a high-density
    region are close, then so should be their corresponding outputs $\mathbf{y}_{1}$,
    $\mathbf{y}_{2}$ . (2) Cluster Assumption: if points are in the same cluster,
    they are likely to be of the same class. It can also be interpreted as the Low-density
    Separation Assumption, where the decision boundary should lie in the low-density
    regions. (3) Manifold Assumption: the high-dimensional data shall lie roughly
    on a low-dimensional manifold. Both smoothness assumption and cluster assumption
    are helpful for classification, but not for regression problems. Thus SSL is used
    more commonly in classifier adaptation. Here we review several SSL methods applied
    to the UDA problems.'
  prefs: []
  type: TYPE_NORMAL
- en: Consistency Regularization encourages consistent predictions for similar data
    points. Similar data points are generated by performing different data augmentations
    on the same data point. While many augmentation techniques are proposed for images,
    few are available for other data formats, such as texts and time series. Thus
    this type of method is limited to certain data modalities. Self-Ensemble (French
    et al., [2018](#bib.bib44)) applies mean-teacher, a typical consistency regularization
    method, to image domain adaptation. The teacher model, which is an Exponential
    Moving Average (EMA) of the student model, will generate predictions to train
    the student model on the target domain. Due to the domain shift, the predictions
    are noisy, thus Mutual Mean-Teaching (MMT) (Ge et al., [2020](#bib.bib48)) uses
    two collaborative networks jointly optimized under the supervision of mutual teacher
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Entropy Minimization encourages the model to make confident (i.e., low-entropy)
    predictions on unlabeled data. It serves as an auxiliary term in many domain adaptation
    methods (Long et al., [2016](#bib.bib113), [2018](#bib.bib115); Saito et al.,
    [2018](#bib.bib146); Shu et al., [2018](#bib.bib158); Vu et al., [2019](#bib.bib182)).
    The risk is that the predictions on the target domain are not reliable, and entropy
    minimization may hurt the performance of the model. Thus, Minimum Class Confusion
    (MCC) (Jin et al., [2020](#bib.bib82)) introduces a weight for each instance,
    where uncertain samples have smaller weights to avoid minimizing entropy on the
    incorrectly classified samples. MCC further minimizes the instance-weighted confusion
    between different classes, which is simple yet frustratingly effective. Source
    Hypothesis Transfer (Liang et al., [2020](#bib.bib104)) adopts an information
    maximization loss with a fair diversity-promoting objective, which circumvents
    the trivial solutions in entropy minimization that all unlabeled data have the
    same one-hot encoding.
  prefs: []
  type: TYPE_NORMAL
- en: Pseudo-Labeling produces proxy labels on unlabeled data and uses these noisy
    labels together with the labeled data to train the model. In self-training, a
    confidence threshold is used to filter out unreliable proxy labels, which may
    fail in UDA since the model is likely to be biased towards well-transferred classes
    while ignoring other hard classes. Thus, Class-Balanced Self-Training (CBST) (Zou
    et al., [2018](#bib.bib212)) uses a class-wise confidence threshold. Still, large
    noise exists in the generated pseudo labels on the target domain, and the standard
    Cross-Entropy (CE) loss has been shown to be sensitive to label noise (Zhang et al.,
    [2017](#bib.bib201)). Towards this problem, Zhang and Sabuncu ([2018](#bib.bib205))
    propose the Generalized Cross-Entropy (GCE) loss as an effective solution (Rusak
    et al., [2021](#bib.bib143); Liu et al., [2021a](#bib.bib105)),
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $L_{\text{GCE}}(\mathbf{x},\tilde{y})=1/q\cdot(1-h_{\tilde{y}}(\mathbf{x})^{q}),$
    |  | (37) |'
  prefs: []
  type: TYPE_TB
- en: where $q\in(0,1]$ is a hyper-parameter to trade-off between the CE loss and
    the MAE loss.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.6 Remarks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Different domain adaptation methods are compared from several perspectives
    in Table [5](#S3.T5 "Table 5 ‣ 3.2.6 Remarks ‣ 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey"). First, statistics matching, domain
    adversarial learning, and hypothesis adversarial learning methods are derived
    from theory, enjoying theoretical guarantees while domain translation and semi-supervised
    learning methods are still in the empirical regime. Second, the former three categories
    of methods work in the feature space or the output space and are highly related
    to specific tasks, and some are tightly integrated to specific architectures.
    In contrast, translation methods work in the input space and are relatively independent
    of specific tasks. However, translation models and semi-supervised learning are
    dependent on specific data format, and are hard to scale to different modalities.
    Finally, statistics matching methods are based on nonparametric distances, which
    are data-efficient but weak in expressiveness, thereby more suitable for low-data
    regimes. In contrast, domain adversarial learning and hypothesis adversarial learning
    methods are based on parametric distances, which can only be measured throughout
    learning, but are more performant when scaling up data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: Comparison between different domain adaptation methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Adaptation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Performance¹ &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Efficiency² &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Modality &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Scalability³ &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Task &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Scalability⁴ &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Theory &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Guarantee⁵ &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Statistics Matching | $\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '| Domain Adversarial Learning | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '| Hypothesis Adversarial Learning | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    |'
  prefs: []
  type: TYPE_TB
- en: '| Domain Translation | $\bigstar\bigstar$ | $\bigstar$ | $\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '| Semi-Supervised Learning | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar$
    | $\bigstar$ | $\bigstar$ |'
  prefs: []
  type: TYPE_TB
- en: '1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Performance: performance when there are large-scale data in source and target
    domains.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data Efficiency: performance when there are only small-scale data in source
    and target domains.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Modality Scalability: whether can adapt the model to various modalities, such
    as text, time series.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Task Scalability: whether can adapt the model to different tasks, such as regression,
    detection.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Theory Guarantee: whether the generalization error of target domain can be
    bounded in adaptation.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Domain adaptation is closely related to pre-training and task adaptation. First,
    pre-training can boost the *transferability* in domain adaptation, since pre-training
    will reduce the allowed hypothesis space and decrease the generalization bound
    on the target domain, as mentioned in Section [3.2](#S3.SS2 "3.2 Domain Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"). Thus pre-training
    on the source domain also serves as the first step in many domain adaptation methods,
    such as RegDA (Jiang et al., [2021](#bib.bib80)). Pre-training also provides some
    new solutions for domain adaptation. When there exists a large unlabeled target
    domain, a feasible solution is to first perform unsupervised pre-training on the
    target domain, and then fine-tune with the labeled data on the source domain.
    This is widely adopted in cross-lingual adaptation (Lample and Conneau, [2019](#bib.bib91)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'When using pre-trained models for domain adaptation, we will also encounter
    the problems in task adaptation, such as the *catastrophic forgetting* mentioned
    in [3.1.1](#S3.SS1.SSS1 "3.1.1 Catastrophic Forgetting ‣ 3.1 Task Adaptation ‣
    3 Adaptation ‣ Transferability in Deep Learning: A Survey"). Thus, many domain
    adaptation methods babysit the learning rates to avoid catastrophic forgetting
    (Long et al., [2015](#bib.bib112); Ganin and Lempitsky, [2015](#bib.bib45)). Compared
    with task adaptation, domain adaptation increases the restriction on the task
    space, where the task of the source domain and that of the target domain must
    be the same. Due to this restriction, domain adaptation has a strict theoretical
    guarantee. But this restriction is sometimes hard to satisfy in practice since
    we cannot ensure whether the category on the unlabeled target domain is exactly
    the same as the source domain (Busto and Gall, [2017](#bib.bib19)). Therefore,
    real-world adaptation is often a mix of task adaptation and domain adaptation.
    How to explore the transferability in such a practical *open-domain* scenario
    is a problem to be solved.'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Evaluation serves as a means for (1) measuring the performance of different
    architectures, different pre-training and adaptation methods, and (2) understanding
    the strengths and limitations of different methods. This section will elaborate
    on the evaluation of *transferability*, which is defined by the performance on
    the target task or domain. We believe that the evaluation of different methods
    should be performed on large-scale datasets for a practical and meaningful comparison.
    Thus, in Section [4.1](#S4.SS1 "4.1 Datasets ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey") we list some large-scale datasets that are suitable
    for evaluating transferability in deep learning. Since different methods are often
    based on different codebases, a fair comparison between them is rather difficult.
    To fill this blank, in Section [4.2](#S4.SS2 "4.2 Library ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey") we propose an open-source library, TLlib, to better
    evaluate transferability of different methods in a unified framework. Finally,
    Section [4.3](#S4.SS3 "4.3 Benchmark ‣ 4 Evaluation ‣ Transferability in Deep
    Learning: A Survey") provides several benchmarks for evaluating both the cross-task
    transferability and cross-domain transferability.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To evaluate the transferability in deep learning, we list several datasets that
    are large-scale in the number of samples and categories, the richness of tasks,
    and the diversity of domains.
  prefs: []
  type: TYPE_NORMAL
- en: 'The General Language Understanding Evaluation (GLUE) (Wang et al., [2019a](#bib.bib183))
    is one of the most famous benchmarks in NLP. As shown in Table [6](#S4.T6 "Table
    6 ‣ 4.1 Datasets ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey"),
    it consists of nine sentence or sentence-pair language understanding tasks, covering
    a diverse range of dataset sizes, text genres, and degrees of difficulty. It is
    widely used to evaluate the *cross-task* transferability of different pre-training
    and task adaptation methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6: Descriptions and statistics of the GLUE datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Corpus | #Train | #Test | Metrics | Task | Domain |'
  prefs: []
  type: TYPE_TB
- en: '| CoLA | 8.5k | 1k | Matthews corr | acceptability | misc. |'
  prefs: []
  type: TYPE_TB
- en: '| SST-2 | 67k | 1.8k | acc. | sentiment | movie reviews |'
  prefs: []
  type: TYPE_TB
- en: '| MRPC | 3.7k | 1.7k | acc./F1 | paraphrase | news |'
  prefs: []
  type: TYPE_TB
- en: '| STS-B | 7k | 1.4k | Pearson/Spearman corr | sentence similarity | misc. |'
  prefs: []
  type: TYPE_TB
- en: '| QQP | 364k | 391k | acc./F1 | paraphrase | social QA questions |'
  prefs: []
  type: TYPE_TB
- en: '| MNLI | 393k | 20k | matched acc./mismatched acc. | NLI | misc. |'
  prefs: []
  type: TYPE_TB
- en: '| QNLI | 105k | 5.4k | acc | QA/NLI | Wikipedia |'
  prefs: []
  type: TYPE_TB
- en: '| RTE | 2.5k | 3k | acc | NLI | news, Wikipedia |'
  prefs: []
  type: TYPE_TB
- en: '| WNLI | 634 | 146 | acc | coreference/NLI | fiction books |'
  prefs: []
  type: TYPE_TB
- en: 'In contrast, there is no common benchmark to evaluate the transferability of
    different methods in computer vision. Table [7](#S4.T7 "Table 7 ‣ 4.1 Datasets
    ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey") lists some of the
    widely used vision datasets. Food-101, CIFAR-10, CIFAR-100, SUN397, Stanford Cars,
    FGVC Aircraft, DTD, Oxford-III Pets, Caltech-101, Oxford 102 Flowers are used
    to evaluate the transferability of different architectures under task discrepancy
    (Kornblith et al., [2019](#bib.bib88)). ImageNet-R(endition) (Hendrycks et al.,
    [2021](#bib.bib69)) and ImageNet-Sketch (Wang et al., [2019b](#bib.bib184)) are
    two variants of the ImageNet, mainly used to evaluate the *cross-domain* transferablity
    of different architectures and pre-training methods. DomainNet (Peng et al., [2019](#bib.bib128))
    has multiple domains sharing the same category space, and is used to evaluate
    the *cross-domain* transferablity of different domain adaptation methods under
    large domain shift.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7: Descriptions and statistics of typical vision datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | #Train | #Test | #Classes | Metric | Domain |'
  prefs: []
  type: TYPE_TB
- en: '| Food-101 | 75,750 | 25,250 | 101 | top-1 | photos and real world images |'
  prefs: []
  type: TYPE_TB
- en: '| CIFAR-10 | 50,000 | 10,000 | 10 | top-1 | photos and real world images |'
  prefs: []
  type: TYPE_TB
- en: '| CIFAR-100 | 50,000 | 10,000 | 100 | top-1 | photos and real world images
    |'
  prefs: []
  type: TYPE_TB
- en: '| SUN397 | 19,850 | 19,850 | 397 | top-1 | photos and real world images |'
  prefs: []
  type: TYPE_TB
- en: '| Stanford Cars | 8,144 | 8,041 | 196 | top-1 | photos and real world images
    |'
  prefs: []
  type: TYPE_TB
- en: '| FGVC Aircraft | 6,667 | 3,333 | 100 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; mean &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; per-class &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| photos and real world images |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Describable &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Textures (DTD) &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 3,760 | 1,880 | 47 | top-1 | photos and real world images |'
  prefs: []
  type: TYPE_TB
- en: '| Oxford-III Pets | 3,680 | 3,369 | 37 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; mean &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; per-class &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| photos and real world images |'
  prefs: []
  type: TYPE_TB
- en: '| Caltech-101 | 3,060 | 6,084 | 102 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; mean &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; per-class &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| photos and real world images |'
  prefs: []
  type: TYPE_TB
- en: '| Oxford 102 Flowers | 2,040 | 6,149 | 102 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; mean &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; per-class &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| photos and real world images |'
  prefs: []
  type: TYPE_TB
- en: '| ImageNet-R | - | 30k | 200 | top-1 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; art, cartoons, deviantart, graffiti, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; embroidery, graphics, origami, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; paintings, patterns, plastic objects, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; plush objects, sculptures, sketches, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; tattoos, toys, and video games &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| ImageNet-Sketch | - | 50k | 1000 | top-1 | sketch |'
  prefs: []
  type: TYPE_TB
- en: '| DomainNet-c | 33,525 | 14,604 | 365 | top-1 | clipart images |'
  prefs: []
  type: TYPE_TB
- en: '| DomainNet-p | 50,416 | 21,850 | 365 | top-1 | artistic paintings |'
  prefs: []
  type: TYPE_TB
- en: '| DomainNet-r | 120,906 | 52,041 | 365 | top-1 | photos and real world images
    |'
  prefs: []
  type: TYPE_TB
- en: '| DomainNet-s | 48,212 | 20,916 | 365 | top-1 | sketch |'
  prefs: []
  type: TYPE_TB
- en: 4.2 Library
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To make up for the lack of a unified codebase in some areas, we propose an open
    and ongoing library, TLlib. This library implements many representative adaptation
    algorithms in a unified way, allowing quantitative, fair, reproducible comparisons
    between different algorithms and promoting seamless integration of different pre-training
    or adaptation methods.
  prefs: []
  type: TYPE_NORMAL
- en: Library Usage.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: First, we give a short description of how to use TLlib using DANN as an instance.
    In the original implementation of DANN, the domain adversarial loss, domain discriminator,
    feature generator, and classifier are tightly coupled together in one nn.Module,
    which causes the difficulty of reuse, e.g., the entire algorithm needs re-implementation
    when the input data is changed from image to text. Yet in this case, the domain
    adversarial loss and the domain discriminator remain unchanged and shall be reused.
    Therefore, in TLlib, models and loss functions are decoupled. When using DANN
    for any case, users need only to initialize a domain discriminator and pass it
    to the domain adversarial loss module, and then use this module in the same way
    as the cross-entropy loss module defined in PyTorch (example code below). TLlib
    provides friendly and coherent APIs for supported algorithms. Detailed usages
    of these algorithms can be found at the [documentation](http://tllib.thuml.ai/).
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,Pj4+ICMgZGVmaW5lIHRoZSBkb21haW4gZGlzY3JpbWluYXRvcgo+Pj4gZnJvbSBkYWxpYi5tb2R1bGVzLmRvbWFpbl9kaXNjcmltaW5hdG9yIGltcG9ydCBEb21haW5EaXNjcmltaW5hdG9yCj4+PiBkaXNjcmltaW5hdG9yID0gRG9tYWluRGlzY3JpbWluYXRvcihpbl9mZWF0dXJlPTEwMjQsIGhpZGRlbl9zaXplPTEwMjQpCj4+PiAjIGRlZmluZSB0aGUgZG9tYWluIGFkdmVyc2FyaWFsIGxvc3MgbW9kdWxlCj4+PiBmcm9tIGRhbGliLmFkcHRhdGlvbi5kYW5uIGltcG9ydCBEb21haW5BZHZlcnNhcmlhbExvc3MKPj4+IGRhbm4gPSBEb21haW5BZHZlcnNhcmlhbExvc3MoZGlzY3JpbWluYXRvciwgcmVkdWN0aW9uPSdtZWFuJykKPj4+ICMgZmVhdHVyZXMgZnJvbSB0aGUgc291cmNlIGFuZCB0YXJnZXQgZG9tYWluCj4+PiBmX3MsIGZfdCA9IHRvcmNoLnJhbmRuKDIwLCAxMDI0KSwgdG9yY2gucmFuZG4oMjAsIDEwMjQpCj4+PiAjIGNhbGN1bGF0ZSB0aGUgZmluYWwgbG9zcwo+Pj4gbG9zcyA9IGRhbm4oZl9zLCBmX3Qp)>>>  #  define  the  domain  discriminator>>>  from  dalib.modules.domain_discriminator  import  DomainDiscriminator>>>  discriminator  =  DomainDiscriminator(in_feature=1024,  hidden_size=1024)>>>  #  define  the  domain  adversarial  loss  module>>>  from  dalib.adptation.dann  import  DomainAdversarialLoss>>>  dann  =  DomainAdversarialLoss(discriminator,  reduction=’mean’)>>>  #  features  from  the  source  and  target  domain>>>  f_s,  f_t  =  torch.randn(20,  1024),  torch.randn(20,  1024)>>>  #  calculate  the  final  loss>>>  loss  =  dann(f_s,  f_t)'
  prefs: []
  type: TYPE_NORMAL
- en: Design Philosophy.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: TLlib is designed to be extendible by researchers and simple for practitioners.
    Currently, there are mainly two types of algorithm implementations. One is to
    encapsulate each algorithm in a Trainer, whose typical representative is PyTorch-Lighting.
    Users only need to feed the training data to it and do not need to care about
    the specific training process. Another strategy is to encapsulate the core loss
    function in each algorithm, and users need to implement the complete training
    process by themselves. A typical representative is PyTorch (Paszke et al., [2019](#bib.bib127)).
    Although the former method is easier to use, it is less extendible. Since it is
    often necessary to adjust the training process in different transfer learning
    scenarios, TLlib adopts the latter method for better extendibility. We try our
    best to make TLlib easy to start with, e.g., we support the automatic download
    of most common transfer learning datasets so that users do not need to spend time
    on data preparation. Our code is in *PyTorch-style* and we provide training examples
    of different transfer algorithms in different scenarios, which allows users to
    quickly adapt to TLlib as long as they have learned PyTorch before. For more convenient
    algorithm selection, we provide a comprehensive benchmark among all those libraries.
    For faster algorithm reproduction, we provide training scripts for all the results
    in the benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: TLlib is released under the MIT License and available at [https://github.com/thuml/Transfer-Learning-Library](https://github.com/thuml/Transfer-Learning-Library).
    Documentation and tutorials are available on its [website](http://tllib.thuml.ai/).
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Benchmark
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This section will present a benchmark of typical pre-training and adaptation
    methods on the large-scale datasets described in Section [4.1](#S4.SS1 "4.1 Datasets
    ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey"). Since such a benchmark
    is missing in the literature, we produce the results using the open library TLlib
    implemented in Section [4.2](#S4.SS2 "4.2 Library ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.1 Pre-Training
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Protocols.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The transferability of pre-training methods is evaluated on the target task,
    where the adaptation process and data augmentations are kept the same for fair
    comparison. Hyper-parameters in adaptation are selected by the performance of
    target validation data.
  prefs: []
  type: TYPE_NORMAL
- en: Results.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'For the pre-training methods, the transferability cross different tasks and
    across different domains should be evaluated. Tables [8](#S4.T8 "Table 8 ‣ Results.
    ‣ 4.3.1 Pre-Training ‣ 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability in Deep
    Learning: A Survey") and [9](#S4.T9 "Table 9 ‣ Results. ‣ 4.3.1 Pre-Training ‣
    4.3 Benchmark ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey") list
    the performance on various downstream tasks with different architectures and pre-training
    tasks. It can be concluded that architectures and pre-training methods have a
    great impact on the *cross-task* transferability of deep networks. Table [10](#S4.T10
    "Table 10 ‣ Results. ‣ 4.3.1 Pre-Training ‣ 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey") lists the performance on ImageNet-Sketch and ImageNet-R
    with different architectures and pre-training tasks. Architectures and pre-training
    strategies also greatly influence the *cross-domain* transferability in deep learning.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 8: Cross-task transferability benchmark. Results of different architectures
    and pre-training methods are reported from the [GLUE leaderboard](https://gluebenchmark.com).
    BiLSTM+ELMo (Peters et al., [2018](#bib.bib131)) serves as the baseline. GPT (Radford
    et al., [2018](#bib.bib134)), $\text{BERT}_{\text{Large}}$ (Devlin et al., [2019](#bib.bib39)),
    T5 (Raffel et al., [2020](#bib.bib136)), and ERNIE (Sun et al., [2019b](#bib.bib168))
    have different architectures. RoBERTa (Liu et al., [2019c](#bib.bib110)), XLM
    (Lample and Conneau, [2019](#bib.bib91)), and SpanBERT (Joshi et al., [2020](#bib.bib83))
    share the same architecture as $\text{BERT}_{\text{Large}}$ but employ different
    pre-training methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | CoLA | SST-2 | MRPC | STS-B | QQP | $\text{MNLI}_{m}$ | $\text{MNLI}_{mm}$
    | QNLI | RTE | Avg |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Human &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Baselines &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 66.4 | 97.8 | 86.3 | 92.7 | 80.4 | 92 | 92.8 | 91.2 | 93.6 | 88.1 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; BiLSTM &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; +ELMo &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 36.0 | 90.4 | 84.9 | 73.3 | 64.8 | 76.4 | 76.1 | 79.9 | 56.8 | 71.0 |'
  prefs: []
  type: TYPE_TB
- en: '| GPT | 45.4 | 91.3 | 82.3 | 80.0 | 70.3 | 82.1 | 81.4 | 88.1 | 56.0 | 75.2
    |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; $\text{BERT}_{\text{Large}}$ &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 60.5 | 94.9 | 89.3 | 86.5 | 72.1 | 86.7 | 85.9 | 92.7 | 70.1 | 82.1 |'
  prefs: []
  type: TYPE_TB
- en: '| T5 | 71.6 | 97.5 | 92.8 | 93.1 | 90.6 | 92.2 | 91.9 | 96.9 | 92.8 | 91.0
    |'
  prefs: []
  type: TYPE_TB
- en: '| ERNIE | 75.5 | 97.8 | 93.9 | 93.0 | 90.9 | 92.3 | 91.7 | 97.3 | 92.6 | 91.7
    |'
  prefs: []
  type: TYPE_TB
- en: '| RoBERTa | 67.8 | 96.7 | 92.3 | 92.2 | 90.2 | 90.8 | 90.2 | 95.4 | 88.2 |
    89.3 |'
  prefs: []
  type: TYPE_TB
- en: '| XLM | 62.9 | 95.6 | 90.7 | 88.8 | 89.8 | 89.1 | 88.5 | 94.0 | 76.0 | 86.2
    |'
  prefs: []
  type: TYPE_TB
- en: '| SpanBERT | 64.3 | 94.8 | 90.9 | 89.9 | 89.5 | 88.1 | 87.7 | 94.3 | 79.0 |
    86.5 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 9: Cross-task transferability benchmark. Results on image recognition
    using different pre-training methods, including SimCLR (Chen et al., [2020](#bib.bib23))
    and BYOL (Grill et al., [2020](#bib.bib59)).'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Pre-Training | Food | CIFAR10 | CIFAR100 | SUN397 | Cars | Aircraft
    | DTD | Pets | Caltech101 | Flowers | Avg |'
  prefs: []
  type: TYPE_TB
- en: '| ResNet50 | Random Init | 86.9 | 95.9 | 80.2 | 53.6 | 91.4 | 85.9 | 64.8 |
    81.5 | 72.6 | 92.0 | 80.5 |'
  prefs: []
  type: TYPE_TB
- en: '| SimCLR | 88.2 | 97.7 | 85.9 | 63.5 | 91.3 | 88.1 | 73.2 | 89.2 | 92.1 | 97.0
    | 86.6 |'
  prefs: []
  type: TYPE_TB
- en: '| BYOL | 88.5 | 97.8 | 86.1 | 63.7 | 91.6 | 88.1 | 76.2 | 91.7 | 93.8 | 97.0
    | 87.5 |'
  prefs: []
  type: TYPE_TB
- en: '| ResNet50 | Supervised Pre-Trained on ImageNet | 87.8 | 96.8 | 84.5 | 64.7
    | 91.7 | 86.6 | 75.2 | 92.5 | 91.8 | 97.5 | 86.9 |'
  prefs: []
  type: TYPE_TB
- en: '| ResNet101 | 87.6 | 97.7 | 87.0 | 64.8 | 91.7 | 85.6 | 75.4 | 94.0 | 93.1
    | 97.9 | 87.5 |'
  prefs: []
  type: TYPE_TB
- en: '| ResNet152 | 87.6 | 97.9 | 87.6 | 66.0 | 92.0 | 85.3 | 74.9 | 94.5 | 93.2
    | 97.4 | 87.6 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 10: Cross-domain transferability benchmark. Results are reported from
    the PyTorch-Image-Models (Wightman, [2019](#bib.bib190)) on ImageNet using different
    architectures and pre-training methods. SSP refers to semi-supervised pre-training
    on YFCC100M (Yalniz et al., [2019](#bib.bib194)). WSP refers to weakly supervised
    pre-training on IG-1B-Targeted (Mahajan et al., [2018](#bib.bib118)).'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Pre-Training | Param Count | ImageNet-Sketch | ImageNetR |'
  prefs: []
  type: TYPE_TB
- en: '| top-1 | top-5 | top-1 | top-5 |'
  prefs: []
  type: TYPE_TB
- en: '| ResNet50 | Standard Pre-Trained on ImageNet | 25.6 | 29.6 | 46.8 | 40.4 |
    54.7 |'
  prefs: []
  type: TYPE_TB
- en: '| ResNet152d | 60.2 | 37.9 | 58.4 | 49.3 | 64.4 |'
  prefs: []
  type: TYPE_TB
- en: '| $\text{ViT}_{\text{large, patch16}}$ | 304.3 | 51.8 | 73.7 | 64.3 | 76.2
    |'
  prefs: []
  type: TYPE_TB
- en: '| ResNext101_32x8d | Standard | 88.8 | 29.4 | 48.5 | 42.6 | 58.3 |'
  prefs: []
  type: TYPE_TB
- en: '| SSP | 34.1 | 55.6 | 49.2 | 65.5 |'
  prefs: []
  type: TYPE_TB
- en: '| WSP | 54.9 | 77.5 | 75.9 | 86.2 |'
  prefs: []
  type: TYPE_TB
- en: '| SSP+WSP | 56.4 | 78.9 | 75.6 | 87.1 |'
  prefs: []
  type: TYPE_TB
- en: 4.3.2 Task Adaptation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Protocols.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We follow the common practice in the community as described in Kornblith et al.
    ([2019](#bib.bib88)). Training iterations and data augmentations are kept the
    same for different task adaptation methods for a fair comparison. Hyper-parameters,
    such as learning rate and weight decay, of each method are selected by the performance
    on target validation data.
  prefs: []
  type: TYPE_NORMAL
- en: Results.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We mainly investigate the *cross-task* transferability between different task
    adaptation methods. Tables [11](#S4.T11 "Table 11 ‣ Results. ‣ 4.3.2 Task Adaptation
    ‣ 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey")
    and [12](#S4.T12 "Table 12 ‣ Results. ‣ 4.3.2 Task Adaptation ‣ 4.3 Benchmark
    ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey") compare the performance
    of downstream tasks with different task adaptation methods. Note that previous
    methods usually only report results on individual datasets, such as Aircraft and
    Stanford Cars, where regularization tuning performs better than vanilla fine-tuning
    by a large margin. But the average improvements brought by different task adaptation
    methods on a large number of datasets are still limited. Thus, we can conclude
    that the effectiveness of different task adaptation algorithms largely depends
    on the relatedness between the target task and the pre-training task.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 11: Cross-task transferability benchmark. GLUE performance with different
    task adaptation methods, including SMART (Jiang et al., [2020](#bib.bib79)), Adapter-Tuning
    (Houlsby et al., [2019](#bib.bib73)) and Diff Pruning (Guo et al., [2021](#bib.bib61)).
    Results are reported from their original papers.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Task &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Adaptation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; New Params &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Per Task &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| CoLA | SST-2 | MRPC | STS-B | QQP | $\text{MNLI}_{m}$ | $\text{MNLI}_{mm}$
    | QNLI | RTE | Avg |'
  prefs: []
  type: TYPE_TB
- en: '| RoBERTa | vanilla | 100% | 67.8 | 96.7 | 92.3 | 92.2 | 90.2 | 90.8 | 90.2
    | 95.4 | 88.2 | 89.3 |'
  prefs: []
  type: TYPE_TB
- en: '| SMART | 100% | 65.1 | 97.5 | 93.7 | 92.9 | 90.1 | 91.0 | 90.8 | 95.4 | 87.9
    | 89.4 |'
  prefs: []
  type: TYPE_TB
- en: '| BERT${}_{\text{Large}}$ | vanilla | 100% | 60.5 | 94.9 | 89.3 | 86.5 | 72.1
    | 86.7 | 85.9 | 92.7 | 70.1 | 82.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Adapter | 2.10% | 59.2 | 94.3 | 88.7 | 87.3 | 89.4 | 85.4 | 85.0 | 92.4 |
    71.6 | 83.7 |'
  prefs: []
  type: TYPE_TB
- en: '| Diff Pruning | 0.50% | 61.1 | 94.1 | 89.7 | 86.0 | - | 86.4 | 86.0 | 93.3
    | 70.6 | - |'
  prefs: []
  type: TYPE_TB
- en: 'Table 12: Cross-task transferability benchmark. Accuracy (%) on image classification
    with different task adaptation methods: LWF (Li and Hoiem, [2018](#bib.bib103)),
    DELTA (Li et al., [2019](#bib.bib101)), BSS (Chen et al., [2019b](#bib.bib27)),
    Bi-Tuning (Zhong et al., [2020](#bib.bib208)). Results are reproduced by TLlib.'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Task &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Adaptation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Food | CIFAR10 | CIFAR100 | SUN397 | Cars | Aircraft | DTD | Pets | Caltech101
    | Flowers | Avg |'
  prefs: []
  type: TYPE_TB
- en: '| ResNet50 | 85.1 | 96.9 | 84.1 | 80.7 | 87.8 | 80.1 | 74.4 | 93.2 | 92.9 |
    96.5 | 87.2 |'
  prefs: []
  type: TYPE_TB
- en: '| LWF | 83.9 | 96.5 | 83.6 | 79.5 | 87.4 | 82.2 | 76.3 | 94.0 | 91.7 | 97.1
    | 87.2 |'
  prefs: []
  type: TYPE_TB
- en: '| DELTA | 83.8 | 95.9 | 83.7 | 73.6 | 88.1 | 82.3 | 75.6 | 94.2 | 92.5 | 97.0
    | 86.7 |'
  prefs: []
  type: TYPE_TB
- en: '| BSS | 85.0 | 96.6 | 84.2 | 80.4 | 88.4 | 81.8 | 74.3 | 93.3 | 93.0 | 96.6
    | 87.4 |'
  prefs: []
  type: TYPE_TB
- en: '| Bi-Tuning | 85.7 | 97.1 | 84.3 | 80.7 | 90.3 | 84.8 | 74.6 | 93.5 | 93.4
    | 97.5 | 88.2 |'
  prefs: []
  type: TYPE_TB
- en: 4.3.3 Domain Adaptation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Protocols.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We follow the standard protocols for unsupervised domain adaptation (Long et al.,
    [2015](#bib.bib112); Ganin and Lempitsky, [2015](#bib.bib45)). Training iterations
    and data augmentations are kept the same for different methods for a fair comparison.
    For each method, hyper-parameters are selected on one task and then kept the same
    for all other tasks, requiring the hyper-parameters of each method to transfer
    across tasks. This selection strategy is more executable than the importance-weighted
    cross-validation (Sugiyama et al., [2007](#bib.bib164)) and can be applied to
    various practical applications, thus it is widely adopted by many competitions.
  prefs: []
  type: TYPE_NORMAL
- en: Results.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Tables [13](#S4.T13 "Table 13 ‣ Results. ‣ 4.3.3 Domain Adaptation ‣ 4.3 Benchmark
    ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey") and [14](#S4.T14
    "Table 14 ‣ Results. ‣ 4.3.3 Domain Adaptation ‣ 4.3 Benchmark ‣ 4 Evaluation
    ‣ Transferability in Deep Learning: A Survey") give the classification performance
    of different domain adaptation methods on DomainNet and ImageNet. We find that
    many state-of-the-art methods on small datasets do not perform well on large-scale
    datasets. This field shall pay more attention to improving the *cross-domain*
    transferability of deep models on large-scale datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 13: Cross-domain transferability benchmark. Accuracy (%) for unsupervised
    domain adaptation on DomainNet. Results are reproduced from TLlib.'
  prefs: []
  type: TYPE_NORMAL
- en: '| DomainNet | c$\shortrightarrow$p | c$\shortrightarrow$r | c$\shortrightarrow$s
    | p$\shortrightarrow$c | p$\shortrightarrow$r | p$\shortrightarrow$s | r$\shortrightarrow$c
    | r$\shortrightarrow$p | r$\shortrightarrow$s | s$\shortrightarrow$c | s$\shortrightarrow$p
    | s$\shortrightarrow$r | Avg |'
  prefs: []
  type: TYPE_TB
- en: '| ResNet101 | 32.7 | 50.6 | 39.4 | 41.1 | 56.8 | 35.0 | 48.6 | 48.8 | 36.1
    | 49.0 | 34.8 | 46.1 | 43.3 |'
  prefs: []
  type: TYPE_TB
- en: '| DAN ([2015](#bib.bib112)) | 38.8 | 55.2 | 43.9 | 45.9 | 59.0 | 40.8 | 50.8
    | 49.8 | 38.9 | 56.1 | 45.9 | 55.5 | 48.4 |'
  prefs: []
  type: TYPE_TB
- en: '| DANN ([2016](#bib.bib46)) | 37.9 | 54.3 | 44.4 | 41.7 | 55.6 | 36.8 | 50.7
    | 50.8 | 40.1 | 55.0 | 45.0 | 54.5 | 47.2 |'
  prefs: []
  type: TYPE_TB
- en: '| ADDA ([2017](#bib.bib176)) | 38.4 | 54.1 | 44.1 | 43.5 | 56.7 | 39.2 | 52.8
    | 51.3 | 40.9 | 55.0 | 45.4 | 54.5 | 48.0 |'
  prefs: []
  type: TYPE_TB
- en: '| JAN ([2017](#bib.bib114)) | 40.5 | 56.7 | 45.1 | 47.2 | 59.9 | 43.0 | 54.2
    | 52.6 | 41.9 | 56.6 | 46.2 | 55.5 | 50.0 |'
  prefs: []
  type: TYPE_TB
- en: '| CDAN ([2018](#bib.bib115)) | 40.4 | 56.8 | 46.1 | 45.1 | 58.4 | 40.5 | 55.6
    | 53.6 | 43.0 | 57.2 | 46.4 | 55.7 | 49.9 |'
  prefs: []
  type: TYPE_TB
- en: '| MCD ([2018](#bib.bib146)) | 37.5 | 52.9 | 44.0 | 44.6 | 54.5 | 41.6 | 52.0
    | 51.5 | 39.7 | 55.5 | 44.6 | 52.0 | 47.5 |'
  prefs: []
  type: TYPE_TB
- en: '| MDD ([2019c](#bib.bib204)) | 42.9 | 59.5 | 47.5 | 48.6 | 59.4 | 42.6 | 58.3
    | 53.7 | 46.2 | 58.7 | 46.5 | 57.7 | 51.8 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 14: Cross-domain transferability benchmark. Accuracy (%) for unsupervised
    domain adaptation on ImageNet-scale datasets. Results are reproduced from TLlib.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Task | ImageNet$\shortrightarrow$ImageNet-R | ImageNet$\shortrightarrow$ImageNet-Sketch
    |'
  prefs: []
  type: TYPE_TB
- en: '| Model | ResNet50 | ig_resnext101_32x8d |'
  prefs: []
  type: TYPE_TB
- en: '| Source Only | 35.6 | 54.9 |'
  prefs: []
  type: TYPE_TB
- en: '| DAN (Long et al., [2015](#bib.bib112)) | 39.8 | 55.7 |'
  prefs: []
  type: TYPE_TB
- en: '| DANN (Ganin et al., [2016](#bib.bib46)) | 52.7 | 56.5 |'
  prefs: []
  type: TYPE_TB
- en: '| JAN (Long et al., [2017](#bib.bib114)) | 41.7 | 55.7 |'
  prefs: []
  type: TYPE_TB
- en: '| CDAN (Long et al., [2018](#bib.bib115)) | 53.9 | 58.2 |'
  prefs: []
  type: TYPE_TB
- en: '| MCD (Saito et al., [2018](#bib.bib146)) | 46.7 | 55.0 |'
  prefs: []
  type: TYPE_TB
- en: '| MDD (Zhang et al., [2019c](#bib.bib204)) | 56.2 | 62.4 |'
  prefs: []
  type: TYPE_TB
- en: 5 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we investigate how to acquire and apply transferability in the
    whole lifecycle of deep learning. In the pre-training section, we focus on how
    to improve the transferability of the pre-trained models by designing architecture,
    pre-training task, and training strategy. In the task adaptation section, we discuss
    how to better preserve and utilize the transferable knowledge to improve the performance
    of target tasks. In the domain adaptation section, we illustrate how to bridge
    the domain gap to increase the transferability for real applications. This survey
    connects many isolated areas with their relation to transferability and provides
    a unified perspective to explore transferability in deep learning. We expect this
    study will attract the community’s attention to the fundamental role of transferability
    in deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs: []
  type: TYPE_NORMAL
- en: This work was supported by the NSFC Grants (62022050 and 62021002), the Beijing
    Nova Program (Z201100006820041), and the BNRist Innovation Fund (BNR2021RC01002).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Abnar et al. (2022) Samira Abnar, Mostafa Dehghani, Behnam Neyshabur, and Hanie
    Sedghi. Exploring the limits of large scale pre-training. In *ICLR*, 2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aghajanyan et al. (2021) Armen Aghajanyan, Luke Zettlemoyer, and Sonal Gupta.
    Intrinsic dimensionality explains the effectiveness of language model fine-tuning.
    In *ACL*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Amodei et al. (2016) Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai,
    Jingliang Bai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Qiang
    Cheng, Guoliang Chen, et al. Deep speech 2: End-to-end speech recognition in english
    and mandarin. In *ICML*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arjovsky et al. (2019) Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David
    Lopez-Paz. Invariant risk minimization. *arXiv preprint arXiv:1907.02893*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arora et al. (2017) Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang.
    Generalization and equilibrium in generative adversarial nets (GANs). In *ICML*,
    2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bartlett and Mendelson (2002) Peter L. Bartlett and Shahar Mendelson. Rademacher
    and gaussian complexities: Risk bounds and structural results. In *JMLR*, 2002.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Beltagy et al. (2019) Iz Beltagy, Kyle Lo, and Arman Cohan. Scibert: Pretrained
    language model for scientific text. In *EMNLP*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ben-David et al. (2010a) S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza, F. Pereira,
    and J. W. Vaughan. A theory of learning from different domains. *Machine Learning,
    79*, page 151–175, 2010a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ben-David et al. (2006) Shai Ben-David, John Blitzer, Koby Crammer, and Fernando
    Pereira. Analysis of representations for domain adaptation. In *NeurIPS*, 2006.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ben-David et al. (2010b) Shai Ben-David, Tyler Lu, Teresa Luu, and David Pal.
    Impossibility theorems for domain adaptation. In *AISTATS*, pages 129–136, 2010b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bengio (2012) Yoshua Bengio. Deep learning of representations for unsupervised
    and transfer learning. In *ICML workshop*, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bengio et al. (2007) Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle.
    Greedy layer-wise training of deep networks. In *NeurIPS*, 2007.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bengio et al. (2013) Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation
    learning: A review and new perspectives. *TPAMI*, 35(8):1798–1828, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bengio et al. (2021) Yoshua Bengio, Yann Lecun, and Geoffrey Hinton. Deep learning
    for ai. *Communications of the ACM*, 64(7):58–65, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bousmalis et al. (2016) Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman,
    Dilip Krishnan, and Dumitru Erhan. Domain separation networks. In *NeurIPS*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bousmalis et al. (2017) Konstantinos Bousmalis, Nathan Silberman, David Dohan,
    Dumitru Erhan, and Dilip Krishnan. Unsupervised pixel-level domain adaptation
    with generative adversarial networks. In *CVPR*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bousmalis et al. (2018) Konstantinos Bousmalis, Alex Irpan, Paul Wohlhart, Yunfei
    Bai, Matthew Kelcey, Mrinal Kalakrishnan, Laura Downs, Julian Ibarz, Peter Pastor,
    Kurt Konolige, Sergey Levine, and Vincent Vanhoucke. Using simulation and domain
    adaptation to improve efficiency of deep robotic grasping. In *ICRA*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020) Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, et al. Language models are few-shot learners. In *NeurIPS*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Busto and Gall (2017) Pau Panareda Busto and Juergen Gall. Open set domain adaptation.
    In *ICCV*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caruana (1997) Rich Caruana. Multitask learning. Technical report, 1997.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapelle et al. (2006) Olivier Chapelle, Bernhard Schölkopf, and Alexander Zien.
    *Semi-Supervised Learning (Adaptive Computation and Machine Learning)*. The MIT
    Press, 2006. ISBN 0262033585.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2012) Minmin Chen, Zhixiang Xu, Kilian Q. Weinberger, and Fei Sha.
    Marginalized denoising autoencoders for domain adaptation. In *ICML*, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2020) Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey
    Hinton. A simple framework for contrastive learning of visual representations.
    In *ICML*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2019a) Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang Frank
    Wang, and Jia-Bin Huang. A closer look at few-shot classification. In *ICLR*,
    2019a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen and He (2021) Xinlei Chen and Kaiming He. Exploring simple siamese representation
    learning. In *CVPR*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2021a) Xinlei Chen, Saining Xie, and Kaiming He. An empirical study
    of training self-supervised vision transformers. *arXiv preprint arXiv:2104.02057*,
    2021a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2019b) Xinyang Chen, Sinan Wang, Bo Fu, Mingsheng Long, and Jianmin
    Wang. Catastrophic forgetting meets negative transfer: Batch spectral shrinkage
    for safe transfer learning. In *NeurIPS*, 2019b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2019c) Xinyang Chen, Sinan Wang, Mingsheng Long, and Jianmin Wang.
    Transferability vs. discriminability: Batch spectral penalization for adversarial
    domain adaptation. In *ICML*, 2019c.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2021b) Xinyang Chen, Sinan Wang, Jianmin Wang, and Mingsheng Long.
    Representation subspace distance for domain adaptation regression. In *ICML*,
    2021b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2018) Yuhua Chen, Wen Li, Christos Sakaridis, Dengxin Dai, and
    Luc Van Gool. Domain adaptive faster R-CNN for object detection in the wild. In
    *CVPR*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cho et al. (2014) Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry
    Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations
    using RNN encoder–decoder for statistical machine translation. In *EMNLP*, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chronopoulou et al. (2019) Alexandra Chronopoulou, Christos Baziotis, and Alexandros
    Potamianos. An embarrassingly simple approach for transfer learning from pretrained
    language models. In *NAACL*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Conneau et al. (2018) Alexis Conneau, Guillaume Lample, Ruty Rinott, Adina
    Williams, Samuel R. Bowman, Holger Schwenk, and Veselin Stoyanov. XNLI: evaluating
    cross-lingual sentence representations. In *EMNLP*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Courty et al. (2017) Nicolas Courty, Rémi Flamary, Amaury Habrard, and Alain
    Rakotomamonjy. Joint distribution optimal transportation for domain adaptation.
    In *NeurIPS*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cui et al. (2018) Yin Cui, Yang Song, Chen Sun, Andrew Howard, and Serge Belongie.
    Large scale fine-grained categorization and domain-specific transfer learning.
    In *CVPR*, pages 4109–4118, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Damodaran et al. (2018) Bharath Bhushan Damodaran, Benjamin Kellenberger, Rémi
    Flamary, Devis Tuia, and Nicolas Courty. Deepjdot: Deep joint distribution optimal
    transport for unsupervised domain adaptation. In *ECCV*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Delange et al. (2021) Matthias Delange, Rahaf Aljundi, Marc Masana, Sarah Parisot,
    Xu Jia, Ales Leonardis, Greg Slabaugh, and Tinne Tuytelaars. A continual learning
    survey: Defying forgetting in classification tasks. *TPAMI*, page 1–20, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deng et al. (2009) Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and
    Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In *CVPR*, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. Bert: Pre-training of deep bidirectional transformers for language
    understanding. In *NAACL*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doersch et al. (2015) Carl Doersch, Abhinav Gupta, and Alexei A. Efros. Unsupervised
    visual representation learning by context prediction. In *ICCV*, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Donahue et al. (2014) Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman,
    Ning Zhang, Eric Tzeng, and Trevor Darrell. Decaf: A deep convolutional activation
    feature for generic visual recognition. In *ICML*, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dosovitskiy et al. (2021) Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
    Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias
    Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An
    Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. In *ICLR*,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finn et al. (2017) Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic
    meta-learning for fast adaptation of deep networks. In *ICML*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: French et al. (2018) Geoffrey French, Michal Mackiewicz, and Mark H. Fisher.
    Self-ensembling for domain adaptation. In *ICLR*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ganin and Lempitsky (2015) Yaroslav Ganin and Victor Lempitsky. Unsupervised
    domain adaptation by backpropagation. In *ICML*, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ganin et al. (2016) Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain,
    Hugo Larochelle, François Laviolette, Mario March, and Victor Lempitsky. Domain-adversarial
    training of neural networks. *JMLR*, 17(59):1–35, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Garcia and Bruna (2018) Victor Garcia and Joan Bruna. Few-shot learning with
    graph neural networks. In *ICLR*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ge et al. (2020) Yixiao Ge, Dapeng Chen, and Hongsheng Li. Mutual mean-teaching:
    Pseudo label refinery for unsupervised domain adaptation on person re-identification.
    In *ICLR*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geirhos et al. (2019) Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias
    Bethge, Felix A Wichmann, and Wieland Brendel. Imagenet-trained cnns are biased
    towards texture; increasing shape bias improves accuracy and robustness. In *ICLR*,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Girshick et al. (2014) Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra
    Malik. Rich feature hierarchies for accurate object detection and semantic segmentation.
    In *CVPR*, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Glorot et al. (2011) Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Domain
    adaptation for large-scale sentiment classification: A deep learning approach.
    In *ICML*, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gong et al. (2012) Boqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman. Geodesic
    flow kernel for unsupervised domain adaptation. In *CVPR*, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gong et al. (2013) Boqing Gong, Kristen Grauman, and Fei Sha. Connecting the
    dots with landmarks: Discriminatively learning domain-invariant features for unsupervised
    domain adaptation. In *ICML*, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2014) Ian J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
    Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
    Generative adversarial networks. In *NeurIPS*, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2015) Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.
    Explaining and harnessing adversarial examples. 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goyal et al. (2021) Anirudh Goyal, Alex Lamb, Jordan Hoffmann, Shagun Sodhani,
    Sergey Levine, Yoshua Bengio, and Bernhard Schölkopf. Recurrent independent mechanisms.
    In *ICLR*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gretton et al. (2012a) Arthur Gretton, Karsten M. Borgwardt, Malte J. Rasch,
    Bernhard Schölkopf, and Alexander Smola. A kernel two-sample test. *JMLR*, 13(25):723–773,
    2012a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gretton et al. (2012b) Arthur Gretton, Dino Sejdinovic, Heiko Strathmann, Sivaraman
    Balakrishnan, Massimiliano Pontil, Kenji Fukumizu, and Bharath K Sriperumbudur.
    Optimal kernel choice for large-scale two-sample tests. In *NeurIPS*, 2012b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grill et al. (2020) Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin
    Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires,
    Zhaohan Guo, Mohammad Gheshlaghi Azar, Bilal Piot, koray kavukcuoglu, Remi Munos,
    and Michal Valko. Bootstrap your own latent - a new approach to self-supervised
    learning. In *NeurIPS*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gulrajani and Lopez-Paz (2021) Ishaan Gulrajani and David Lopez-Paz. In search
    of lost domain generalization. In *ICLR*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. (2021) Demi Guo, Alexander Rush, and Yoon Kim. Parameter-efficient
    transfer learning with diff pruning. In *ACL*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guo et al. (2019) Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman,
    Tajana Rosing, and Rogerio Feris. Spottune: transfer learning through adaptive
    fine-tuning. In *CVPR*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gururangan et al. (2020) Suchin Gururangan, Ana Marasović, Swabha Swayamdipta,
    Kyle Lo, Iz Beltagy, Doug Downey, and Noah A. Smith. Don’t stop pretraining: Adapt
    language models to domains and tasks. In *ACL*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2016) Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep
    residual learning for image recognition. In *CVPR*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2017) Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick.
    Mask r-cnn. In *ICCV*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2019) Kaiming He, Ross Girshick, and Piotr Dollár. Rethinking imagenet
    pre-training. In *ICCV*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2020) Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
    Momentum contrast for unsupervised visual representation learning. In *CVPR*,
    2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2021) Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár,
    and Ross Girshick. Masked autoencoders are scalable vision learners. *arXiv preprint
    arXiv:2111.06377*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hendrycks et al. (2021) Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath,
    Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn
    Song, Jacob Steinhardt, and Justin Gilmer. The many faces of robustness: A critical
    analysis of out-of-distribution generalization. *ICCV*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hjelm et al. (2019) R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan
    Grewal, Phil Bachman, Adam Trischler, and Yoshua Bengio. Learning deep representations
    by mutual information estimation and maximization. In *ICLR*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hoffman et al. (2016) Judy Hoffman, Dequan Wang, Fisher Yu, and Trevor Darrell.
    Fcns in the wild: Pixel-level adversarial and constraint-based adaptation. 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hoffman et al. (2018) Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu,
    Phillip Isola, Kate Saenko, Alexei Efros, and Trevor Darrell. Cycada: Cycle-consistent
    adversarial domain adaptation. In *ICML*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Houlsby et al. (2019) Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna
    Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain
    Gelly. Parameter-efficient transfer learning for NLP. In *ICML*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Howard and Ruder (2018) Jeremy Howard and Sebastian Ruder. Universal language
    model fine-tuning for text classification. In *ACL*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. (2020) Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang,
    Vijay S. Pande, and Jure Leskovec. Pre-training graph neural networks. In *ICLR*,
    2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2007) Jiayuan Huang, Arthur Gretton, Karsten Borgwardt, Bernhard
    Schölkopf, and Alex Smola. Correcting sample selection bias by unlabeled data.
    In *NeurIPS*, 2007.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ioffe and Szegedy (2015) Sergey Ioffe and Christian Szegedy. Batch normalization:
    Accelerating deep network training by reducing internal covariate shift. In *ICML*,
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jang et al. (2019) Yunhun Jang, Hankook Lee, Sung Ju Hwang, and Jinwoo Shin.
    Learning what and where to transfer. In *ICML*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jiang et al. (2020) Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu,
    Jianfeng Gao, and Tuo Zhao. SMART: robust and efficient fine-tuning for pre-trained
    natural language models through principled regularized optimization. In *ACL*,
    2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2021) Junguang Jiang, Yifei Ji, Ximei Wang, Yufeng Liu, Jianmin
    Wang, and Mingsheng Long. Regressive domain adaptation for unsupervised keypoint
    detection. In *CVPR*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2022) Junguang Jiang, Baixu Chen, Jianmin Wang, and Mingsheng
    Long. Decoupled adaptation for cross-domain object detection. In *ICLR*, 2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jin et al. (2020) Ying Jin, Ximei Wang, Mingsheng Long, and Jianmin Wang. Minimum
    class confusion for versatile domain adaptation. In *ECCV*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Joshi et al. (2020) Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke
    Zettlemoyer, and Omer Levy. SpanBERT: Improving pre-training by representing and
    predicting spans. In *TACL*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kang et al. (2019) Guoliang Kang, Lu Jiang, Yi Yang, and Alexander G Hauptmann.
    Contrastive adaptation network for unsupervised domain adaptation. In *CVPR*,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2019) Taekyung Kim, Minki Jeong, Seunghyeon Kim, Seokeon Choi,
    and Changick Kim. Diversify and match: A domain adaptive representation learning
    paradigm for object detection. In *CVPR*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kirkpatrick et al. (2017) James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz,
    Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago
    Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting
    in neural networks. *PNAS*, 114(13):3521–3526, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kolesnikov et al. (2020) Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan
    Puigcerver, Jessica Yung, Sylvain Gelly, and Neil Houlsby. Big transfer (bit):
    General visual representation learning. In *ECCV*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kornblith et al. (2019) Simon Kornblith, Jonathon Shlens, and Quoc V Le. Do
    better imagenet models transfer better? In *CVPR*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kou et al. (2020) Zhi Kou, Kaichao You, Mingsheng Long, and Jianmin Wang. Stochastic
    normalization. In *NeurIPS*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky et al. (2012) Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton.
    Imagenet classification with deep convolutional neural networks. In *NeurIPS*,
    2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lample and Conneau (2019) Guillaume Lample and Alexis Conneau. Cross-lingual
    language model pretraining. In *NeurIPS*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lample et al. (2017) Guillaume Lample, Ludovic Denoyer, and Marc’Aurelio Ranzato.
    Unsupervised machine translation using monolingual corpora only. In *ICLR*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lan et al. (2020) Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel,
    Piyush Sharma, and Radu Soricut. Albert: A lite bert for self-supervised learning
    of language representations. In *ICLR*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. (2015) Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning.
    *Nature*, 521(7553):436–444, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee et al. (2019) Chen-Yu Lee, Tanmay Batra, Mohammad Haris Baig, and Daniel
    Ulbricht. Sliced wasserstein discrepancy for unsupervised domain adaptation. In
    *CVPR*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2020a) Cheolhyoung Lee, Kyunghyun Cho, and Wanmo Kang. Mixout:
    Effective regularization to finetune large-scale pretrained language models. In
    *ICLR*, 2020a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2020b) Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu
    Kim, Chan Ho So, and Jaewoo Kang. Biobert: a pre-trained biomedical language representation
    model for biomedical text mining. *Bioinformatics*, 36(4):1234–1240, 2020b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lewis et al. (2020) Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad,
    Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART:
    Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation,
    and Comprehension. In *ACL*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2018) Chunyuan Li, Heerad Farkhoor, Rosanne Liu, and Jason Yosinski.
    Measuring the intrinsic dimension of objective landscapes. In *ICLR*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li and Liang (2021) Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing
    continuous prompts for generation. In *ACL*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2019) Xingjian Li, Haoyi Xiong, Hanchao Wang, Yuxuan Rao, Liping
    Liu, Zeyu Chen, and Jun Huan. Delta: Deep learning transfer using feature map
    with attention for convolutional networks. In *ICLR*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2017) Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi
    Hou. Revisiting batch normalization for practical domain adaptation. In *ICLR
    Workshop*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li and Hoiem (2018) Zhizhong Li and Derek Hoiem. Learning without forgetting.
    *TPAMI*, 40(12):2935–2947, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. (2020) Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need
    to access the source data? source hypothesis transfer for unsupervised domain
    adaptation. In *ICML*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2021a) Hong Liu, Jianmin Wang, and Mingsheng Long. Cycle self-training
    for domain adaptation. In *NeurIPS*, 2021a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu and Tuzel (2016) Ming-Yu Liu and Oncel Tuzel. Coupled generative adversarial
    networks. In *NeurIPS*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2021b) Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki
    Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey
    of prompting methods in natural language processing, 2021b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2019a) Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao.
    Multi-task deep neural networks for natural language understanding. In *ACL*,
    2019a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019b) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta:
    A robustly optimized bert pretraining approach. *arXiv preprint arXiv:1907.11692*,
    2019b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019c) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta:
    A robustly optimized BERT pretraining approach. 2019c.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2013) Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun,
    and Philip S. Yu. Transfer feature learning with joint distribution adaptation.
    In *ICCV*, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2015) Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I. Jordan.
    Learning transferable features with deep adaptation networks. In *ICML*, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2016) Mingsheng Long, Jianmin Wang, and Michael I. Jordan. Unsupervised
    domain adaptation with residual transfer networks. In *NeurIPS*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2017) Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan.
    Deep transfer learning with joint adaptation networks. In *ICML*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2018) Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I.
    Jordan. Conditional adversarial domain adaptation. In *NeurIPS*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2019) Mingsheng Long, Yue Cao, Zhangjie Cao, Jianmin Wang, and
    Michael I. Jordan. Transferable representation learning with deep adaptation networks.
    *TPAMI*, 41(12):3071–3085, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Louizos et al. (2018) Christos Louizos, Max Welling, and Diederik P. Kingma.
    Learning sparse neural networks through l_0 regularization. In *ICLR*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mahajan et al. (2018) Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming
    He, Manohar Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. Exploring
    the limits of weakly supervised pretraining. In *ECCV*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mallya and Lazebnik (2018) Arun Mallya and Svetlana Lazebnik. Piggyback: Adding
    multiple tasks to a single, fixed network by learning to mask. In *ECCV*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mansour et al. (2009) Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh.
    Domain adaptation: Learning bounds and algorithms. In *COLT*, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Munkhdalai and Yu (2017) Tsendsuren Munkhdalai and Hong Yu. Meta networks. In
    *ICML*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ngiam et al. (2018) Jiquan Ngiam, Daiyi Peng, Vijay Vasudevan, Simon Kornblith,
    Quoc V Le, and Ruoming Pang. Domain adaptive transfer learning with specialist
    models. *arXiv preprint arXiv:1811.07056*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nguyen et al. (2020) Cuong Nguyen, Tal Hassner, Matthias Seeger, and Cedric
    Archambeau. Leep: A new measure to evaluate transferability of learned representations.
    In *ICML*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oord et al. (2019) Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation
    learning with contrastive predictive coding. *NeurIPS*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pan and Yang (2010) Sinno Jialin Pan and Qiang Yang. A survey on transfer learning.
    *TKDE*, pages 1345–1359, 2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pan et al. (2011) Sinno Jialin Pan, Ivor W. Tsang, James T. Kwok, and Qiang
    Yang. Domain adaptation via transfer component analysis. *TNNLS*, pages 199–210,
    2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Paszke et al. (2019) Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James
    Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca
    Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison,
    Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and
    Soumith Chintala. Pytorch: An imperative style, high-performance deep learning
    library. In *NeurIPS*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peng et al. (2019) Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko,
    and Bo Wang. Moment matching for multi-source domain adaptation. In *ICCV*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peters et al. (2016) Jonas Peters, Peter Bühlmann, and Nicolai Meinshausen.
    Causal inference by using invariant prediction: identification and confidence
    intervals. *Journal of the Royal Statistical Society. Series B (Statistical Methodology)*,
    pages 947–1012, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peters et al. (2017) Jonas Peters, Dominik Janzing, and Bernhard Schölkopf.
    *Elements of causal inference: foundations and learning algorithms*. The MIT Press,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peters et al. (2018) Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner,
    Christopher Clark, Kenton Lee, and Luke Zettlemoyer. Deep contextualized word
    representations. In *NAACL*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pires et al. (2019) Telmo Pires, Eva Schlinger, and Dan Garrette. How multilingual
    is multilingual bert? In *ACL*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quionero-Candela et al. (2009) J. Quionero-Candela, M. Sugiyama, A. Schwaighofer,
    and N. D. Lawrence. *Dataset shift in machine learning*. The MIT Press, 2009.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2018) Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya
    Sutskever. Improving language understanding by generative pre-training. *Technical
    report, OpenAI*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2021) Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh,
    Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack
    Clark, et al. Learning transferable visual models from natural language supervision.
    In *ICML*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
    Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring
    the limits of transfer learning with a unified text-to-text transformer. *JMLR*,
    21(140):1–67, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raghu et al. (2020) Aniruddh Raghu, Maithra Raghu, Samy Bengio, and Oriol Vinyals.
    Rapid learning or feature reuse? towards understanding the effectiveness of maml.
    In *ICLR*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Raghu et al. (2019) Maithra Raghu, Chiyuan Zhang, Jon Kleinberg, and Samy Bengio.
    Transfusion: Understanding transfer learning for medical imaging. In *NeurIPS*,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rebuffi et al. (2017) S-A Rebuffi, H. Bilen, and A. Vedaldi. Learning multiple
    visual domains with residual adapters. In *NeurIPS*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Redko et al. (2020) Ievgen Redko, Emilie Morvant, Amaury Habrard, Marc Sebban,
    and Younès Bennani. A survey on domain adaptation theory: learning bounds and
    theoretical guarantees, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren et al. (2015) Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster
    r-cnn: Towards real-time object detection with region proposal networks. In *NeurIPS*,
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rosenstein (2005) Michael T. Rosenstein. To transfer or not to transfer. In
    *NeurIPS*, 2005.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rusak et al. (2021) Evgenia. Rusak, Steffen Schneider, Peter Gehler, Oliver
    Bringmann, Wieland Brendel, and Matthias Bethge. Adapting imagenet-scale models
    to complex distribution shifts with self-learning. *arXiv preprint arXiv:2104.12928*,
    2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Russakovsky et al. (2015) Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause,
    Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael
    Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition
    Challenge. *IJCV*, 115(3):211–252, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rusu et al. (2019) Andrei A Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals,
    Razvan Pascanu, Simon Osindero, and Raia Hadsell. Meta-learning with latent embedding
    optimization. In *ICLR*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saito et al. (2018) Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya
    Harada. Maximum classifier discrepancy for unsupervised domain adaptation. In
    *CVPR*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saito et al. (2019) Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada, and Kate
    Saenko. Strong-weak distribution alignment for adaptive object detection. In *CVPR*,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Salman et al. (2020) Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor,
    and Aleksander Madry. Do adversarially robust imagenet models transfer better?
    In *NeurIPS*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sankaranarayanan et al. (2018) Swami Sankaranarayanan, Yogesh Balaji, Carlos D.
    Castillo, and Rama Chellappa. Generate to adapt: Aligning domains using generative
    adversarial networks. In *CVPR*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Santoro et al. (2016) Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan
    Wierstra, and Timothy Lillicrap. Meta-learning with memory-augmented neural networks.
    In *ICML*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schick and Schütze (2020) Timo Schick and Hinrich Schütze. Exploiting cloze
    questions for few-shot text classification and natural language inference. In
    *EACL*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schmidhuber (1987) Jürgen Schmidhuber. *Evolutionary principles in self-referential
    learning*. PhD thesis, Technische Universität München, 1987.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schölkopf et al. (2012) Bernhard Schölkopf, Dominik Janzing, Jonas Peters, Eleni
    Sgouritsa, Kun Zhang, and Joris Mooij. On causal and anticausal learning. In *ICML*,
    2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schölkopf et al. (2021) Bernhard Schölkopf, Francesco Locatello, Stefan Bauer,
    Nan Rosemary Ke, Nal Kalchbrenner, Anirudh Goyal, and Yoshua Bengio. Toward causal
    representation learning. *Proceedings of the IEEE*, 109(5):612–634, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Senior et al. (2020) Andrew W Senior, Richard Evans, John Jumper, James Kirkpatrick,
    Laurent Sifre, Tim Green, Chongli Qin, Augustin Žídek, Alexander WR Nelson, Alex
    Bridgland, et al. Improved protein structure prediction using potentials from
    deep learning. *Nature*, 577(7792):706–710, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sermanet et al. (2013) Pierre Sermanet, David Eigen, Xiang Zhang, Michaël Mathieu,
    Rob Fergus, and Yann LeCun. Overfeat: Integrated recognition, localization and
    detection using convolutional networks. *arXiv preprint arXiv:1312.6229*, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shrivastava et al. (2017) Ashish Shrivastava, Tomas Pfister, Oncel Tuzel, Josh
    Susskind, Wenda Wang, and Russell Webb. Learning from simulated and unsupervised
    images through adversarial training. In *CVPR*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shu et al. (2018) Rui Shu, Hung H. Bui, Hirokazu Narui, and Stefano Ermon. A
    dirt-t approach to unsupervised domain adaptation. In *ICLR*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shu et al. (2021a) Yang Shu, Zhangjie Cao, Jinghan Gao, Jianmin Wang, and Mingsheng
    Long. Omni-training for data-efficient deep learning. *arXiv preprint arXiv:2110.07510*,
    2021a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shu et al. (2021b) Yang Shu, Zhi Kou, Zhangjie Cao, Jianmin Wang, and Mingsheng
    Long. Zoo-tuning: Adaptive transfer from a zoo of models. In *ICML*, 2021b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Silver et al. (2016) David Silver, Aja Huang, Chris J Maddison, Arthur Guez,
    Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou,
    Veda Panneershelvam, Marc Lanctot, et al. Mastering the game of go with deep neural
    networks and tree search. *Nature*, 529(7587):484–489, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snell et al. (2017) Jake Snell, Kevin Swersky, and Richard S. Zemel. Prototypical
    networks for few-shot learning. In *NeurIPS*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sriperumbudur et al. (2010) Bharath K. Sriperumbudur, Arthur Gretton, Kenji
    Fukumizu, Bernhard Schölkopf, and Gert R. G. Lanckriet. Hilbert space embeddings
    and metrics on probability measures. *JMLR*, 2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sugiyama et al. (2007) Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert
    Müller. Covariate shift adaptation by importance weighted cross validation. *JMLR*,
    8(35):985–1005, 2007.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sugiyama et al. (2008) Masashi Sugiyama, Shinichi Nakajima, Hisashi Kashima,
    Paul Buenau, and Motoaki Kawanabe. Direct importance estimation with model selection
    and its application to covariate shift adaptation. In *NeurIPS*, 2008.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun and Saenko (2016) Baochen Sun and Kate Saenko. Deep coral: Correlation
    alignment for deep domain adaptation. In *ECCV*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2019a) Qianru Sun, Yaoyao Liu, Tat-Seng Chua, and Bernt Schiele.
    Meta-transfer learning for few-shot learning. In *CVPR*, 2019a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2019b) Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen,
    Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, and Hua Wu. Ernie: Enhanced representation
    through knowledge integration. *arXiv preprint arXiv:1904.09223*, 2019b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taigman et al. (2017) Yaniv Taigman, Adam Polyak, and Lior Wolf. Unsupervised
    cross-domain image generation. In *ICLR*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thrun and Pratt (1998) Sebastian Thrun and Lorien Pratt. *Learning to learn*.
    Springer Science & Business Media, 1998.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tian et al. (2020) Yonglong Tian, Dilip Krishnan, and Phillip Isola. Contrastive
    multiview coding. In *ECCV*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Torrey and Shavlik (2010) Lisa Torrey and Jude Shavlik. Transfer learning. 2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tsai et al. (2018) Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn,
    Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output
    space for semantic segmentation. In *CVPR*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tzeng et al. (2014) Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and
    Trevor Darrell. Deep domain confusion: Maximizing for domain invariance. 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tzeng et al. (2015) Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko.
    Simultaneous deep transfer across domains and tasks. In *ICCV*, pages 4068–4076,
    2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tzeng et al. (2017) Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.
    Adversarial discriminative domain adaptation. In *CVPR*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is
    all you need. In *NeurIPS*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Veličković et al. (2019) Petar Veličković, William Fedus, William L Hamilton,
    Pietro Liò, Yoshua Bengio, and R Devon Hjelm. Deep graph infomax. In *ICLR*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vincent et al. (2008) Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine
    Manzagol. Extracting and composing robust features with denoising autoencoders.
    In *ICML*, 2008.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vinyals et al. (2016) Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan
    Wierstra, et al. Matching networks for one shot learning. In *NeurIPS*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vinyals et al. (2019) Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki,
    Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H Choi, Richard Powell,
    Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using multi-agent
    reinforcement learning. *Nature*, 575(7782):350–354, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vu et al. (2019) Tuan-Hung Vu, Himalaya Jain, Maxime Bucher, Matthieu Cord,
    and Patrick Perez. Advent: Adversarial entropy minimization for domain adaptation
    in semantic segmentation. In *CVPR*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2019a) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill,
    Omer Levy, and Samuel R. Bowman. GLUE: A multi-task benchmark and analysis platform
    for natural language understanding. In *ICLR*, 2019a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019b) Haohan Wang, Songwei Ge, Zachary Lipton, and Eric P Xing.
    Learning robust global representations by penalizing local predictive power. In
    *NeurIPS*, 2019b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2019c) Ximei Wang, Ying Jin, Mingsheng Long, Jianmin Wang, and
    Michael I Jordan. Transferable normalization: Towards improving transferability
    of deep neural networks. In *NeurIPS*, 2019c.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2021) Ximei Wang, Jinghan Gao, Mingsheng Long, and Jianmin Wang.
    Self-tuning for data-efficient deep learning. In *ICML*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019d) Zirui Wang, Zihang Dai, Barnabás Póczos, and Jaime G. Carbonell.
    Characterizing and avoiding negative transfer. In *CVPR*, 2019d.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2022) Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei
    Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. Finetuned language models
    are zero-shot learners. In *ICLR*, 2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2018) Longhui Wei, Shiliang Zhang, Wen Gao, and Qi Tian. Person
    transfer gan to bridge domain gap for person re-identification. In *CVPR*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wightman (2019) Ross Wightman. Pytorch image models. [https://github.com/rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models),
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu and He (2018) Yuxin Wu and Kaiming He. Group normalization. In *ECCV*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2018) Zhirong Wu, Yuanjun Xiong, X Yu Stella, and Dahua Lin. Unsupervised
    feature learning via non-parametric instance discrimination. In *CVPR*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2021) Runxin Xu, Fuli Luo, Zhiyuan Zhang, Chuanqi Tan, Baobao Chang,
    Songfang Huang, and Fei Huang. Raise a child in large language model: Towards
    effective and generalizable fine-tuning. In *EMNLP*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yalniz et al. (2019) I Zeki Yalniz, Hervé Jégou, Kan Chen, Manohar Paluri, and
    Dhruv Mahajan. Billion-scale semi-supervised learning for image classification.
    *arXiv preprint arXiv:1905.00546*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2019) Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R
    Salakhutdinov, and Quoc V Le. Xlnet: Generalized autoregressive pretraining for
    language understanding. In *NeurIPS*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yao et al. (2019) Huaxiu Yao, Ying Wei, Junzhou Huang, and Zhenhui Li. Hierarchically
    structured meta-learning. In *ICML*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yosinski et al. (2014) Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson.
    How transferable are features in deep neural networks? In *NeurIPS*, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You et al. (2021) Kaichao You, Yong Liu, Jianmin Wang, and Mingsheng Long.
    Logme: Practical assessment of pre-trained models for transfer learning. In *ICML*,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zamir et al. (2018) Amir Roshan Zamir, Alexander Sax, William B. Shen, Leonidas J.
    Guibas, Jitendra Malik, and Silvio Savarese. Taskonomy: Disentangling task transfer
    learning. In *CVPR*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zellinger et al. (2017) Werner Zellinger, Thomas Grubinger, Edwin Lughofer,
    Thomas Natschläger, and Susanne Saminger-Platz. Central moment discrepancy (cmd)
    for domain-invariant representation learning. In *ICLR*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2017) Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht,
    and Oriol Vinyals. Understanding deep learning requires rethinking generalization.
    In *ICLR*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2019a) Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P. Xing,
    Laurent El Ghaoui, and Michael I. Jordan. Theoretically principled trade-off between
    robustness and accuracy. In *ICML*, 2019a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2019b) Jeffrey O. Zhang, Alexander Sax, Amir Zamir, Leonidas J.
    Guibas, and Jitendra Malik. Side-tuning: Network adaptation via additive side
    networks. 2019b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2019c) Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan.
    Bridging theory and algorithm for domain adaptation. In *ICML*, 2019c.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang and Sabuncu (2018) Zhilu Zhang and Mert R. Sabuncu. Generalized cross
    entropy loss for training deep neural networks with noisy labels. In *NeurIPS*,
    2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2021) Nanxuan Zhao, Zhirong Wu, Rynson W. H. Lau, and Stephen Lin.
    What makes instance discrimination good for transfer learning? In *ICLR*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zheng et al. (2021) Lucia Zheng, Neel Guha, Brandon R. Anderson, Peter Henderson,
    and Daniel E. Ho. When does pretraining help? assessing self-supervised learning
    for law and the casehold dataset. In *ICAIL*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhong et al. (2020) Jincheng Zhong, Ximei Wang, Zhi Kou, Jianmin Wang, and Mingsheng
    Long. Bi-tuning of pre-trained representations. *arXiv preprint arXiv:2011.06182*,
    2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. (2017) Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros.
    Unpaired image-to-image translation using cycle-consistent adversarial networks.
    In *ICCV*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2015) Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov,
    Raquel Urtasun, Antonio Torralba, and Sanja Fidler. Aligning books and movies:
    Towards story-like visual explanations by watching movies and reading books. In
    *ICCV*, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhuang et al. (2021) Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun
    Zhu, Hengshu Zhu, Hui Xiong, and Qing He. A comprehensive survey on transfer learning.
    *Proceedings of the IEEE*, 109(1):43–76, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zou et al. (2018) Yang Zou, Zhiding Yu, B. V. K. Vijaya Kumar, and Jinsong Wang.
    Unsupervised domain adaptation for semantic segmentation via class-balanced self-training.
    In *ECCV*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
