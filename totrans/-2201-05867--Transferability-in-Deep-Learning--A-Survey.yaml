- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 19:48:22'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:48:22
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2201.05867] Transferability in Deep Learning: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2201.05867] 深度学习中的迁移性：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2201.05867](https://ar5iv.labs.arxiv.org/html/2201.05867)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2201.05867](https://ar5iv.labs.arxiv.org/html/2201.05867)
- en: 'Transferability in Deep Learning: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习中的迁移性：综述
- en: \nameJunguang Jiang \emailjiangjunguang1123@outlook.com
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: \name姜俊光 \emailjiangjunguang1123@outlook.com
- en: \addrSchool of Software, BNRist, Tsinghua University
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: \addr软件学院，北京师范大学，北京 100084，中国
- en: Beijing 100084, China \AND\nameYang Shu \emailshu-y18@mails.tsinghua.edu.cn
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 北京 100084，中国 \AND\name杨舒 \emailshu-y18@mails.tsinghua.edu.cn
- en: \addrSchool of Software, BNRist, Tsinghua University
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: \addr软件学院，北京师范大学，北京 100084，中国
- en: Beijing 100084, China \AND\nameJianmin Wang \emailjimwang@tsinghua.edu.cn
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 北京 100084，中国 \AND\name杨舒 \emailshu-y18@mails.tsinghua.edu.cn
- en: \addrSchool of Software, BNRist, Tsinghua University
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: \addr软件学院，北京师范大学，北京 100084，中国 \AND\name王建民 \emailjimwang@tsinghua.edu.cn
- en: Beijing 100084, China \AND\nameMingsheng Long \emailmingsheng@tsinghua.edu.cn
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 北京 100084，中国 \AND\name龙名生 \emailmingsheng@tsinghua.edu.cn
- en: \addrSchool of Software, BNRist, Tsinghua University
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: \addr软件学院，北京师范大学，北京 100084，中国
- en: 'Beijing 100084, China Equal contributionCorrespondence to: Mingsheng Long <mingsheng@tsinghua.edu.cn>.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 北京 100084，中国 平等贡献 通信作者：龙名生 <mingsheng@tsinghua.edu.cn>。
- en: Abstract
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The success of deep learning algorithms generally depends on large-scale data,
    while humans appear to have inherent ability of knowledge transfer, by recognizing
    and applying relevant knowledge from previous learning experiences when encountering
    and solving unseen tasks. Such an ability to acquire and reuse knowledge is known
    as *transferability* in deep learning. It has formed the long-term quest towards
    making deep learning as *data-efficient* as human learning, and has been motivating
    fruitful design of more powerful deep learning algorithms. We present this survey
    to connect different isolated areas in deep learning with their relation to transferability,
    and to provide a unified and complete view to investigating transferability through
    the whole *lifecycle* of deep learning. The survey elaborates the fundamental
    goals and challenges in parallel with the core principles and methods, covering
    recent cornerstones in deep architectures, pre-training, task adaptation and domain
    adaptation. This highlights unanswered questions on the appropriate objectives
    for learning transferable knowledge and for adapting the knowledge to new tasks
    and domains, avoiding catastrophic forgetting and negative transfer. Finally,
    we implement a benchmark and an open-source library, enabling a fair evaluation
    of deep learning methods in terms of transferability.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习算法的成功通常依赖于大规模数据，而人类似乎具备固有的知识迁移能力，即在遇到和解决未见任务时，通过识别和应用先前学习经验中的相关知识。这种获取和重用知识的能力被称为深度学习中的*迁移性*。这形成了将深度学习变得与人类学习一样*数据高效*的长期追求，并激发了更强大深度学习算法的设计。我们提出这项综述，以连接深度学习中不同的孤立领域及其与迁移性的关系，并提供一个统一而完整的视角，探讨深度学习的整个*lifecycle*中的迁移性。这项综述详细阐述了基本目标和挑战，同时涵盖了核心原理和方法，包括深度架构、预训练、任务适应和领域适应中的最新基石。这突出了有关学习可迁移知识的适当目标以及将知识适应于新任务和领域的问题，避免灾难性遗忘和负迁移。最后，我们实现了一个基准测试和一个开源库，能够公平评估深度学习方法的迁移性。
- en: 'Keywords: Deep learning, transferability, pre-training, adaptation, library,
    benchmark'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 关键词：深度学习，迁移性，预训练，适应，库，基准
- en: Contents
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 内容
- en: '[1 Introduction](#S1 "In Transferability in Deep Learning: A Survey")'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[1 引言](#S1 "在《深度学习中的迁移性：综述》中")'
- en: '[1.1 Terminology](#S1.SS1 "In 1 Introduction ‣ Transferability in Deep Learning:
    A Survey")'
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[1.1 术语](#S1.SS1 "在 1 引言 ‣ 深度学习中的迁移性：综述 中")'
- en: '[1.2 Overview](#S1.SS2 "In 1 Introduction ‣ Transferability in Deep Learning:
    A Survey")'
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[1.2 概述](#S1.SS2 "在 1 引言 ‣ 深度学习中的迁移性：综述 中")'
- en: '[2 Pre-Training](#S2 "In Transferability in Deep Learning: A Survey")'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2 预训练](#S2 "在《深度学习中的迁移性：综述》中")'
- en: '[2.1 Pre-Training Model](#S2.SS1 "In 2 Pre-Training ‣ Transferability in Deep
    Learning: A Survey")'
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.1 预训练模型](#S2.SS1 "在 2 预训练 ‣ 深度学习中的迁移性：综述 中")'
- en: '[2.2 Supervised Pre-Training](#S2.SS2 "In 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey")'
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.2 监督预训练](#S2.SS2 "在 2 预训练 ‣ 深度学习中的迁移性：综述 中")'
- en: '[2.2.1 Meta-Learning](#S2.SS2.SSS1 "In 2.2 Supervised Pre-Training ‣ 2 Pre-Training
    ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.2.1 元学习](#S2.SS2.SSS1 "在 2.2 监督预训练 ‣ 2 预训练 ‣ 深度学习中的迁移性：综述 中")'
- en: '[2.2.2 Causal Learning](#S2.SS2.SSS2 "In 2.2 Supervised Pre-Training ‣ 2 Pre-Training
    ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.2.2 因果学习](#S2.SS2.SSS2 "在《深度学习中的迁移性：一项调查》中的2.2 监督预训练 ‣ 2 预训练")'
- en: '[2.3 Unsupervised Pre-Training](#S2.SS3 "In 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey")'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.3 无监督预训练](#S2.SS3 "在《深度学习中的迁移性：一项调查》中的2 预训练")'
- en: '[2.3.1 Generative Learning](#S2.SS3.SSS1 "In 2.3 Unsupervised Pre-Training
    ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.3.1 生成学习](#S2.SS3.SSS1 "在《深度学习中的迁移性：一项调查》中的2.3 无监督预训练 ‣ 2 预训练")'
- en: '[2.3.2 Contrastive Learning](#S2.SS3.SSS2 "In 2.3 Unsupervised Pre-Training
    ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.3.2 对比学习](#S2.SS3.SSS2 "在《深度学习中的迁移性：一项调查》中的2.3 无监督预训练 ‣ 2 预训练")'
- en: '[2.4 Remarks](#S2.SS4 "In 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey")'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.4 备注](#S2.SS4 "在《深度学习中的迁移性：一项调查》中的2 预训练 ‣ 备注")'
- en: '[3 Adaptation](#S3 "In Transferability in Deep Learning: A Survey")'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3 适应](#S3 "在《深度学习中的迁移性：一项调查》中的3 适应")'
- en: '[3.1 Task Adaptation](#S3.SS1 "In 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey")'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.1 任务适应](#S3.SS1 "在《深度学习中的迁移性：一项调查》中的3 适应")'
- en: '[3.1.1 Catastrophic Forgetting](#S3.SS1.SSS1 "In 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.1.1 灾难性遗忘](#S3.SS1.SSS1 "在《深度学习中的迁移性：一项调查》中的3.1 任务适应 ‣ 3 适应")'
- en: '[3.1.2 Negative Transfer](#S3.SS1.SSS2 "In 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.1.2 负迁移](#S3.SS1.SSS2 "在《深度学习中的迁移性：一项调查》中的3.1 任务适应 ‣ 3 适应")'
- en: '[3.1.3 Parameter Efficiency](#S3.SS1.SSS3 "In 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.1.3 参数效率](#S3.SS1.SSS3 "在《深度学习中的迁移性：一项调查》中的3.1 任务适应 ‣ 3 适应")'
- en: '[3.1.4 Data Efficiency](#S3.SS1.SSS4 "In 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.1.4 数据效率](#S3.SS1.SSS4 "在《深度学习中的迁移性：一项调查》中的3.1 任务适应 ‣ 3 适应")'
- en: '[3.1.5 Remarks](#S3.SS1.SSS5 "In 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")'
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.1.5 备注](#S3.SS1.SSS5 "在《深度学习中的迁移性：一项调查》中的3.1 任务适应 ‣ 3 适应")'
- en: '[3.2 Domain Adaptation](#S3.SS2 "In 3 Adaptation ‣ Transferability in Deep
    Learning: A Survey")'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.2 领域适应](#S3.SS2 "在《深度学习中的迁移性：一项调查》中的3 适应 ‣ 领域适应")'
- en: '[3.2.1 Statistics Matching](#S3.SS2.SSS1 "In 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.2.1 统计匹配](#S3.SS2.SSS1 "在《深度学习中的迁移性：一项调查》中的3.2 领域适应 ‣ 3 适应")'
- en: '[3.2.2 Domain Adversarial Learning](#S3.SS2.SSS2 "In 3.2 Domain Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.2.2 领域对抗学习](#S3.SS2.SSS2 "在《深度学习中的迁移性：一项调查》中的3.2 领域适应 ‣ 3 适应")'
- en: '[3.2.3 Hypothesis Adversarial Learning](#S3.SS2.SSS3 "In 3.2 Domain Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.2.3 假设对抗学习](#S3.SS2.SSS3 "在《深度学习中的迁移性：一项调查》中的3.2 领域适应 ‣ 3 适应")'
- en: '[3.2.4 Domain Translation](#S3.SS2.SSS4 "In 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.2.4 领域翻译](#S3.SS2.SSS4 "在《深度学习中的迁移性：一项调查》中的3.2 领域适应 ‣ 3 适应")'
- en: '[3.2.5 Semi-Supervised Learning](#S3.SS2.SSS5 "In 3.2 Domain Adaptation ‣ 3
    Adaptation ‣ Transferability in Deep Learning: A Survey")'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.2.5 半监督学习](#S3.SS2.SSS5 "在《深度学习中的迁移性：一项调查》中的3.2 领域适应 ‣ 3 适应")'
- en: '[3.2.6 Remarks](#S3.SS2.SSS6 "In 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.2.6 备注](#S3.SS2.SSS6 "在《深度学习中的迁移性：一项调查》中的3.2 领域适应 ‣ 3 适应")'
- en: '[4 Evaluation](#S4 "In Transferability in Deep Learning: A Survey")'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4 评估](#S4 "在《深度学习中的迁移性：一项调查》中的4 评估")'
- en: '[4.1 Datasets](#S4.SS1 "In 4 Evaluation ‣ Transferability in Deep Learning:
    A Survey")'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4.1 数据集](#S4.SS1 "在《深度学习中的迁移性：一项调查》中的4 评估")'
- en: '[4.2 Library](#S4.SS2 "In 4 Evaluation ‣ Transferability in Deep Learning:
    A Survey")'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4.2 库](#S4.SS2 "在《深度学习中的迁移性：一项调查》中的4 评估")'
- en: '[4.3 Benchmark](#S4.SS3 "In 4 Evaluation ‣ Transferability in Deep Learning:
    A Survey")'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4.3 基准](#S4.SS3 "在《深度学习中的迁移性：一项调查》中的4 评估 ‣ 基准")'
- en: '[4.3.1 Pre-Training](#S4.SS3.SSS1 "In 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey")'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4.3.1 预训练](#S4.SS3.SSS1 "在《深度学习中的迁移性：一项调查》中的4.3 基准 ‣ 4 评估")'
- en: '[4.3.2 Task Adaptation](#S4.SS3.SSS2 "In 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey")'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4.3.2 任务适应](#S4.SS3.SSS2 "在《深度学习中的迁移性：一项调查》中的4.3 基准 ‣ 4 评估 ‣ 任务适应")'
- en: '[4.3.3 Domain Adaptation](#S4.SS3.SSS3 "In 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey")'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4.3.3 领域适应](#S4.SS3.SSS3 "在《深度学习中的迁移性：一项调查》中的4.3 基准 ‣ 4 评估")'
- en: '[5 Conclusion](#S5 "In Transferability in Deep Learning: A Survey")'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5 结论](#S5 "在深度学习中的迁移能力：综述")'
- en: 1 Introduction
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Deep learning (LeCun et al., [2015](#bib.bib94)) is a class of machine learning
    algorithms that utilize multiple processing layers to learn representations of
    data with multiple levels of abstraction. These multiple processing layers, also
    called deep neural networks (DNNs), are empowered with the ability to discover
    different explanatory factors of variation behind the intricate structured data (Bengio
    et al., [2013](#bib.bib13)). With essential advances in network architectures,
    training strategies and computation devices, deep learning has made breakthroughs
    or even revolutions in various areas, such as computer vision (Krizhevsky et al.,
    [2012](#bib.bib90); He et al., [2016](#bib.bib64)), natural language processing (Radford
    et al., [2018](#bib.bib134)), speech processing (Amodei et al., [2016](#bib.bib3)),
    computational biology (Senior et al., [2020](#bib.bib155)), games (Silver et al.,
    [2016](#bib.bib161); Vinyals et al., [2019](#bib.bib181)) and so forth. Despite
    its great success in these important areas, deep learning is still faced with
    the grand challenge of data efficiency. Most mainstream deep learning methods
    require big datasets in the order of millions or even trillions to achieve good
    performance, yet collecting and annotating such huge amount of data for each new
    task or domain are expensive and even prohibitive. This data efficiency challenge
    heavily impedes the adoption of deep learning to a wider spectrum of application
    scenarios.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（LeCun 等，[2015](#bib.bib94)）是一类利用多个处理层来学习具有多个抽象层次的数据表示的机器学习算法。这些多个处理层，也称为深度神经网络（DNNs），具备发现复杂结构数据背后不同解释因素的能力（Bengio
    等，[2013](#bib.bib13)）。随着网络架构、训练策略和计算设备的重大进展，深度学习在计算机视觉（Krizhevsky 等，[2012](#bib.bib90)；He
    等，[2016](#bib.bib64)），自然语言处理（Radford 等，[2018](#bib.bib134)），语音处理（Amodei 等，[2016](#bib.bib3)），计算生物学（Senior
    等，[2020](#bib.bib155)），游戏（Silver 等，[2016](#bib.bib161)；Vinyals 等，[2019](#bib.bib181)）等多个领域取得了突破性甚至革命性的进展。尽管在这些重要领域取得了巨大成功，深度学习仍面临数据效率的重大挑战。大多数主流深度学习方法需要数百万甚至数十亿的数据集才能实现良好的性能，但为每个新任务或领域收集和标注如此大量的数据既昂贵又难以接受。这一数据效率挑战严重阻碍了深度学习在更广泛应用场景中的采用。
- en: 'An effective solution to this challenge is to explore the transferability in
    deep learning. Transferability is a foundational ability of human learning: human
    beings can gain relevant knowledge from other related problems and apply it to
    handle new problems with extremely few samples (Thrun and Pratt, [1998](#bib.bib170)).
    In deep learning, transferability refers to the ability of deep neural networks
    to extract transferable representations from some source tasks and then adapt
    the gained representations to improve learning in related target tasks (Bengio,
    [2012](#bib.bib11)). Recent advances in deep learning reveal that deep models
    trained via upstream tasks on large-scale data tend to yield good transferability
    to a variety of downstream tasks, such as visual object detection (Ren et al.,
    [2015](#bib.bib141)), natural language understanding (Devlin et al., [2019](#bib.bib39)),
    to name a few. Transferability has become the central property of deep learning
    for improving data efficiency. It is on par with generalizability, interpretability,
    and robustness for bridging the gap between machine learning and human learning.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这一挑战的有效方案是深入探索深度学习中的迁移能力。迁移能力是人类学习的基础能力：人类可以从其他相关问题中获得相关知识，并应用于处理新问题，仅需极少的样本（Thrun
    和 Pratt，[1998](#bib.bib170)）。在深度学习中，迁移能力指的是深度神经网络从某些源任务中提取可迁移表示的能力，然后将获得的表示调整以改善相关目标任务的学习（Bengio，[2012](#bib.bib11)）。深度学习的最新进展表明，通过大规模数据上的上游任务训练的深度模型往往能在各种下游任务中表现出良好的迁移能力，例如视觉目标检测（Ren
    等，[2015](#bib.bib141)），自然语言理解（Devlin 等，[2019](#bib.bib39)），仅举几例。迁移能力已成为深度学习提高数据效率的核心属性。它与可泛化性、可解释性和鲁棒性等效，用于弥合机器学习和人类学习之间的差距。
- en: '![Refer to caption](img/7791c0a00ea88fce1ed63c91f1ea5e2a.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7791c0a00ea88fce1ed63c91f1ea5e2a.png)'
- en: 'Figure 1: The two-stage lifecycle of most deep learning applications. In the
    first stage, the deep model is *pre-trained* on an upstream task with large-scale
    data (labeled or unlabeled) for gaining transferable knowledge. In the second
    stage, the pre-trained model is *adapted* to a downstream task in the target domain
    with labeled data; If the downstream task only has unlabeled data, then additional
    labeled data from another source domain of identical learning task but different
    data distribution will be used to improve performance.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：大多数深度学习应用的两阶段生命周期。在第一阶段，深度模型在上游任务上进行*预训练*，使用大规模数据（有标注或无标注）来获得可转移知识。在第二阶段，预训练模型在目标领域的下游任务中进行*适应*，使用有标注数据；如果下游任务只有无标注数据，则会使用来自另一个源领域的相同学习任务但数据分布不同的附加标注数据来提高性能。
- en: 'Towards gaining and applying knowledge with good transferability, the lifecycle
    of many deep learning applications is divided into two stages: pre-training and
    adaptation (Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Transferability in
    Deep Learning: A Survey")). The goal of the pre-training stage is to gain the
    transferable knowledge. The deep models are pre-trained on an upstream task with
    large-scale data (either labeled or unlabeled) to learn disentangled representations
    or reusable parameters that are transferable to a variety of downstream tasks.
    The goal of the adaptation stage is to reuse the transferable knowledge. The pre-trained
    models are adapted to a downstream task in the target domain with labeled data,
    and the previously learned knowledge enables better generalization with fewer
    labeled samples. When the downstream task only has unlabeled data, additional
    labeled data from another source domain of identical learning task but different
    data distribution will be used to improve the data efficiency of the adapted model
    (Ganin and Lempitsky, [2015](#bib.bib45)).'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '为了获得并应用具有良好转移性的知识，许多深度学习应用的生命周期被划分为两个阶段：预训练和适应（图 [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Transferability in Deep Learning: A Survey")）。预训练阶段的目标是获得可转移的知识。深度模型在上游任务上使用大规模数据（有标注或无标注）进行预训练，以学习可以转移到多种下游任务的解耦表示或可重复使用的参数。适应阶段的目标是重用这些可转移的知识。预训练模型在目标领域的下游任务中使用有标注数据进行适应，先前学习的知识使得模型在较少的标注样本下能够更好地泛化。当下游任务只有无标注数据时，将使用来自另一个源领域的相同学习任务但数据分布不同的附加标注数据来提高适应模型的数据效率（Ganin
    和 Lempitsky, [2015](#bib.bib45)）。'
- en: It is helpful to highlight the difference underlying the transferability in
    the two stages. The pre-training stage focuses mainly on the *generic* transferability,
    i.e., obtaining a general transferable representation that can improve the performance
    of as many downstream tasks as possible. In contrast, the adaptation stage pays
    attention to the *specific* transferability, i.e., how to exploit the transferable
    knowledge in pre-trained models for a specific kind of downstream tasks, or how
    to improve the transferability between related domains of the same downstream
    task. The generic transferability is attractive since it may benefit many downstream
    tasks without additional cost or special design. Yet it may ignore the special
    structures of downstream tasks that are crucial for stronger transferability,
    thus the specific transferability is still necessary in many cases. Recently,
    the gap between the pre-training stage and the adaptation stage is getting closer.
    Several pre-training methods are designed to obtain fast model adaptation ability
    in the adaptation stage (Finn et al., [2017](#bib.bib43)), while some adaptation
    methods try to convert downstream tasks into pre-training tasks to make full use
    of the generic transferability of pre-trained models (Brown et al., [2020](#bib.bib18)).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 突出两个阶段间转移性差异是有帮助的。预训练阶段主要关注于*通用*转移性，即获取一个可以提高尽可能多下游任务性能的一般可转移表示。相比之下，适应阶段关注于*特定*转移性，即如何利用预训练模型中的可转移知识来处理特定类型的下游任务，或者如何提高相同下游任务相关领域间的转移性。通用转移性很有吸引力，因为它可以在没有额外成本或特殊设计的情况下使许多下游任务受益。然而，它可能忽视了对更强转移性至关重要的下游任务的特殊结构，因此在许多情况下，特定转移性仍然是必要的。最近，预训练阶段和适应阶段之间的差距越来越小。几种预训练方法被设计用来在适应阶段获得快速模型适应能力（Finn
    et al., [2017](#bib.bib43)），同时一些适应方法尝试将下游任务转化为预训练任务，以充分利用预训练模型的通用转移性（Brown et
    al., [2020](#bib.bib18)）。
- en: Transferability lies at the core of the whole lifecycle of deep learning, yet
    different areas such as domain adaptation (Zhuang et al., [2021](#bib.bib211))
    and continual learning (Delange et al., [2021](#bib.bib37)), mainly explore transferability
    in a partial regime of the lifecycle. This is not enough to achieve a complete
    picture of transferability. Thereby, we present this survey to connect different
    isolated areas in deep learning with their relation to transferability, and to
    provide a unified and complete view to investigate transferability through the
    whole lifecycle of deep learning. Due to the broadness of the scope and the limitation
    of the space, we do not aim to cover all methods towards transferability. Instead,
    we elaborate on the core principles and methods and then give a brief review of
    the expanded literature. We further implement TLlib, a high-quality open library
    to provide a fair evaluation of typical methods. We hope this survey can highlight
    the grand picture of transferability in deep learning, and provide a useful navigation
    to researchers interested in improving the data efficiency of deep learning.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 转移性是深度学习整个生命周期的核心，但不同领域如领域适应（Zhuang等，[2021](#bib.bib211)）和持续学习（Delange等，[2021](#bib.bib37)）主要在生命周期的部分阶段探索转移性。这不足以全面了解转移性。因此，我们提出了这项调查，以将深度学习中不同的孤立领域与其转移性关系连接起来，并提供一个统一和完整的视角，通过深度学习的整个生命周期研究转移性。由于范围广泛和空间限制，我们并不打算涵盖所有针对转移性的方法。相反，我们详细阐述核心原理和方法，然后简要回顾扩展文献。我们进一步实现了TLlib，一个高质量的开源库，以提供对典型方法的公平评估。我们希望这项调查能够突出深度学习中转移性的宏伟图景，并为有兴趣提高深度学习数据效率的研究人员提供有用的导航。
- en: 'Table 1: Notations and descriptions used in the survey.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：调查中使用的符号和描述。
- en: '| $\mathcal{X}$ | Input space |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{X}$ | 输入空间 |'
- en: '| $\mathcal{Y}$ | Output space |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{Y}$ | 输出空间 |'
- en: '| $\mathcal{D}$ | A fixed but unknown distribution over $\mathcal{X}$ |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{D}$ | 在$\mathcal{X}$上的一个固定但未知的分布 |'
- en: '| $\mathcal{\widehat{D}}$ | Empirical distribution of a sample drawn i.i.d.
    from $\mathcal{D}$ |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{\widehat{D}}$ | 从$\mathcal{D}$中独立同分布抽取样本的经验分布 |'
- en: '| $P(\cdot)$ | Probability of an event |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| $P(\cdot)$ | 事件的概率 |'
- en: '| $\mathbb{E}(\cdot)$ | Expectation of a random variable |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbb{E}(\cdot)$ | 随机变量的期望 |'
- en: '| $\mathcal{U}$ | Upstream data |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{U}$ | 上游数据 |'
- en: '| $\mathcal{S}$ | Source domain in downstream data |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{S}$ | 下游数据中的源领域 |'
- en: '| $\mathcal{T}$ | Target domain in downstream data |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{T}$ | 下游数据中的目标领域 |'
- en: '| $\mathcal{H}$ | Hypothesis space |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{H}$ | 假设空间 |'
- en: '| $h$ | A hypothesis in the hypothesis space $\mathcal{H}$ |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| $h$ | 假设空间$\mathcal{H}$中的一个假设 |'
- en: '| $\psi$ | Feature generator |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| $\psi$ | 特征生成器 |'
- en: '| $\theta$ | Hypothesis parameter |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| $\theta$ | 假设参数 |'
- en: '| $\mathbf{x}$ | Model input |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{x}$ | 模型输入 |'
- en: '| $\mathbf{y}$ | Model output |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{y}$ | 模型输出 |'
- en: '| $\mathbf{z}$ | Hidden activation of the feature generator |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| $\mathbf{z}$ | 特征生成器的隐藏激活 |'
- en: '| $D$ | A discriminator to distinguish different distributions |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| $D$ | 区分不同分布的判别器 |'
- en: 1.1 Terminology
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 术语
- en: 'Foremost, we give several definitions related to transferability, and the summary
    of notations and their descriptions used in this survey can be found in Table
    [1](#S1.T1 "Table 1 ‣ 1 Introduction ‣ Transferability in Deep Learning: A Survey").
    Denote the input space as $\mathcal{X}$ and the output space as $\mathcal{Y}$,
    and assume that there exists an unknown labeling function $f:\mathcal{X}\mapsto\mathcal{Y}$.
    Formally, a task corresponds to learning an underlying labeling function $f$.
    To learn a task, we first collect a set of samples $\widehat{\mathcal{D}}=\{\mathbf{x}_{1},...,\mathbf{x}_{n}\}$,
    which are drawn independently and identically distributed (i.i.d.) from some fixed
    but unknown distribution $\mathcal{D}$. Formally, a domain is a marginal probability
    distribution $P(\mathbf{X})$ defined on a certain input space $\mathcal{X}$. Consider
    a set of hypotheses $\mathcal{H}$ and a specific loss function $\ell:\mathcal{Y}\times\mathcal{Y}\mapsto\mathbb{R}_{+}$,
    the objective of the learner is to select a hypothesis $h\in\mathcal{H}$ that
    yields the lowest generalization error, $\min_{h\in\mathcal{H}}\mathbb{E}_{\mathbf{x}\sim\mathcal{D}}\ell(h(\mathbf{x}),f(\mathbf{x}))$.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们给出与可迁移性相关的几个定义，并且在本综述中使用的符号及其描述的总结见表 [1](#S1.T1 "表 1 ‣ 1 引言 ‣ 深度学习中的可迁移性：综述")。设输入空间为
    $\mathcal{X}$，输出空间为 $\mathcal{Y}$，并假设存在一个未知的标记函数 $f:\mathcal{X}\mapsto\mathcal{Y}$。形式上，一个任务对应于学习一个潜在的标记函数
    $f$。为了学习一个任务，我们首先收集一组样本 $\widehat{\mathcal{D}}=\{\mathbf{x}_{1},...,\mathbf{x}_{n}\}$，这些样本是从某个固定但未知的分布
    $\mathcal{D}$ 中独立同分布（i.i.d.）抽取的。形式上，领域是定义在某个输入空间 $\mathcal{X}$ 上的边际概率分布 $P(\mathbf{X})$。考虑一组假设
    $\mathcal{H}$ 和一个特定的损失函数 $\ell:\mathcal{Y}\times\mathcal{Y}\mapsto\mathbb{R}_{+}$，学习者的目标是选择一个假设
    $h\in\mathcal{H}$ 以获得最低的泛化误差，即 $\min_{h\in\mathcal{H}}\mathbb{E}_{\mathbf{x}\sim\mathcal{D}}\ell(h(\mathbf{x}),f(\mathbf{x}))$。
- en: Definition 1 (Transferability)
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 1（可迁移性）
- en: Given a source domain $\mathcal{S}$ with learning task $t_{\mathcal{S}}$ and
    a target domain $\mathcal{T}$ with learning task $t_{\mathcal{T}}$, transferability
    is the ability of gaining transferable knowledge from $t_{\mathcal{S}}$ on $\mathcal{S}$
    and reusing the knowledge to decrease the generalization error of $t_{\mathcal{T}}$
    on $\mathcal{T}$, under the distribution shift $\mathcal{S}\neq\mathcal{T}$ or
    the task discrepancy $t_{\mathcal{S}}\neq t_{\mathcal{T}}$.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个源领域 $\mathcal{S}$ 及其学习任务 $t_{\mathcal{S}}$，以及一个目标领域 $\mathcal{T}$ 及其学习任务
    $t_{\mathcal{T}}$，可迁移性是指从 $\mathcal{S}$ 上的 $t_{\mathcal{S}}$ 获取可迁移知识的能力，并利用这些知识减少
    $\mathcal{T}$ 上 $t_{\mathcal{T}}$ 的泛化误差，这里存在分布变化 $\mathcal{S}\neq\mathcal{T}$
    或任务差异 $t_{\mathcal{S}}\neq t_{\mathcal{T}}$。
- en: 'In the deep learning lifecycle (Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Transferability in Deep Learning: A Survey")), the pre-training stage aims to
    *gain* transferable knowledge via learning on upstream task with large-scale data,
    while the adaptation stage aims to *reuse* the pre-trained knowledge to improve
    the data efficiency in downstream tasks. The upstream and downstream are different
    in both learning tasks and data distributions. To conform with the literature,
    in the pre-training stage, we will replace the notions of source domain/task with
    the widely-used upstream data/task, denoted as $\mathcal{U}$ and $t_{\mathcal{U}}$
    respectively.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习生命周期中（图 [1](#S1.F1 "图 1 ‣ 1 引言 ‣ 深度学习中的可迁移性：综述")），预训练阶段旨在通过在大规模数据上的上游任务学习来*获得*可迁移知识，而适应阶段则旨在*重用*预训练知识以提高下游任务中的数据效率。上游和下游在学习任务和数据分布上都存在差异。为了符合文献中的惯例，在预训练阶段，我们将用广泛使用的上游数据/任务替代源领域/任务，分别表示为
    $\mathcal{U}$ 和 $t_{\mathcal{U}}$。
- en: '![Refer to caption](img/abcced6c694b3611ae3ef1cd52e0c3a4.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/abcced6c694b3611ae3ef1cd52e0c3a4.png)'
- en: 'Figure 2: Overview of this survey. The survey is organized around the lifecycle
    (pre-training, adaptation, and evaluation) of deep learning applications and focuses
    on the core problems and methods towards transferability. Besides, we briefly
    review related learning setups.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：本综述的概述。综述围绕深度学习应用的生命周期（预训练、适应和评估）进行组织，重点关注可迁移性的核心问题和方法。此外，我们简要回顾了相关的学习设置。
- en: 1.2 Overview
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2 概述
- en: 'The survey is organized around how to acquire and utilize the transferability
    in deep learning throughout its whole lifecycle, including pre-training, adaptation,
    and evaluation (Figure [2](#S1.F2 "Figure 2 ‣ 1.1 Terminology ‣ 1 Introduction
    ‣ Transferability in Deep Learning: A Survey")).'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这项调查围绕如何在深度学习的整个生命周期中获取和利用迁移性进行组织，包括预训练、适应和评估（图 [2](#S1.F2 "图 2 ‣ 1.1 术语 ‣ 1
    介绍 ‣ 深度学习中的迁移性：调查")）。
- en: •
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Pre-Training. We first briefly discuss some important model architectures that
    make pre-trained representations transferable. Then we elaborate on supervised
    pre-training and unsupervised pre-training, which are distinguished by the availability
    of labeled or unlabeled data for pre-training. In supervised pre-training, we
    cover both standard practices commonly used in the industry and research advances
    in academia to acquire transferability on the labeled data. In unsupervised pre-training,
    we cover the latest designs of proper pre-training tasks on unlabeled data to
    gain transferability.
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预训练。我们首先简要讨论一些重要的模型架构，这些架构使预训练表示具有迁移性。然后我们详细阐述了有监督的预训练和无监督的预训练，这两者通过预训练数据是标注数据还是未标注数据来区分。在有监督的预训练中，我们涵盖了业界常用的标准实践以及学术界的研究进展，以在标注数据上获取迁移性。在无监督的预训练中，我们涵盖了最新的适当预训练任务设计，以在未标注数据上获得迁移性。
- en: •
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Adaptation. We mainly elaborate on task adaptation and domain adaptation, which
    are divided by whether there exists another related source domain in addition
    to the pre-trained model for boosting the downstream task performance. In task
    adaptation, we first pinpoint several open problems caused by the discrepancy
    between upstream tasks and downstream tasks, then illustrate how different task
    adaptation paradigms (Yosinski et al., [2014](#bib.bib197); Brown et al., [2020](#bib.bib18))
    close the task discrepancy to better utilize the transferability. In domain adaptation,
    we first pinpoint the most influential theories for closing the distribution shift
    (Ben-David et al., [2006](#bib.bib9), [2010a](#bib.bib8)), then elaborate how
    to derive solid learning algorithms (Long et al., [2015](#bib.bib112); Ganin and
    Lempitsky, [2015](#bib.bib45)) from these theories to enhance the transferability
    of deep models across domains.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 适应。我们主要阐述了任务适应和领域适应，这两者通过是否存在另一个相关的源领域来提升下游任务性能。在任务适应中，我们首先指出了上游任务和下游任务之间差异所造成的若干开放问题，然后说明了不同的任务适应范式（Yosinski
    等, [2014](#bib.bib197); Brown 等, [2020](#bib.bib18)）如何缩小任务差距，以更好地利用迁移性。在领域适应中，我们首先指出了最有影响力的理论，以弥合分布偏移（Ben-David
    等, [2006](#bib.bib9), [2010a](#bib.bib8)），然后详细阐述了如何从这些理论中推导出稳健的学习算法（Long 等, [2015](#bib.bib112);
    Ganin 和 Lempitsky, [2015](#bib.bib45)），以增强深度模型在不同领域间的迁移性。
- en: •
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Evaluation. We mainly investigate the transferability gained and reused by different
    pre-training and adaptation methods on several large-scale datasets released recently
    in the literature. Note that we omit some small-scale and relatively obsolete
    datasets to make our benchmark concise and easy to report. To facilitate fair
    evaluation and full reproduction of existing algorithms, we open source TLlib,
    a high-quality library along with this survey at [https://github.com/thuml/Transfer-Learning-Library](https://github.com/thuml/Transfer-Learning-Library).
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评估。我们主要调查了不同预训练和适应方法在最近文献中发布的几个大规模数据集上获得和重用的迁移性。请注意，我们省略了一些小规模和相对过时的数据集，以使我们的基准更加简洁易报告。为了便于公平评估和完全重现现有算法，我们开源了
    TLlib，这是一个高质量的库，随这项调查一起发布，网址为 [https://github.com/thuml/Transfer-Learning-Library](https://github.com/thuml/Transfer-Learning-Library)。
- en: Pre-training and adaptation lie at the core methods towards transferability.
    In parallel with them, there are some fields that are also closely related to
    the transferability in deep learning, such as domain generalization (Gulrajani
    and Lopez-Paz, [2021](#bib.bib60)), out-of-distribution (OOD) generalization (Bengio
    et al., [2021](#bib.bib14)), few-shot learning (Chen et al., [2019a](#bib.bib24)),
    etc. Recent evaluation shows that these learning setups can largely benefit from
    the advancement in pre-training and adaptation and we will give a brief review
    to them in the related sections.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练和适应是实现迁移性的核心方法。与之并行的，还有一些领域也与深度学习中的迁移性密切相关，如领域泛化（Gulrajani 和 Lopez-Paz, [2021](#bib.bib60)）、分布外（OOD）泛化（Bengio
    等, [2021](#bib.bib14)）、少样本学习（Chen 等, [2019a](#bib.bib24)）等。最近的评估显示，这些学习设置可以从预训练和适应的进展中大大受益，我们将在相关部分中对其进行简要回顾。
- en: 2 Pre-Training
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 预训练
- en: 'Despite yielding unprecedented performances on various machine learning tasks,
    the deep learning methods require large amounts of labeled data to generalize
    well. This *data hungry* nature limits their application to a wide variety of
    domains and tasks, especially to scenarios short of data and annotations. Pre-training,
    which obtains transferable representations or models from upstream tasks with
    large-scale data to boost the performance on downstream tasks, is one of the most
    common and practical solutions to the problem of data scarcity. In this section,
    we will first review some important model architectures that have a great impact
    on the transferability of pre-trained representations in Section [2.1](#S2.SS1
    "2.1 Pre-Training Model ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A
    Survey"). Then we elaborate on how to *gain knowledge* of improved transferability
    via supervised pre-training on large-scale labeled data in Section [2.2](#S2.SS2
    "2.2 Supervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey") and via unsupervised pre-training on much larger unlabeled data in
    Section [2.3](#S2.SS3 "2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey"). Figure [3](#S2.F3 "Figure 3 ‣ 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey") overviews the recent cornerstones of pre-training
    methods.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管在各种机器学习任务上表现出前所未有的性能，深度学习方法仍然需要大量的标注数据才能很好地泛化。这种*数据饥渴*的特性限制了它们在各种领域和任务中的应用，尤其是在数据和注释稀缺的情况下。预训练通过从上游任务中获得可迁移的表示或模型，并利用大规模数据来提升下游任务的性能，是解决数据稀缺问题的最常见且实际的解决方案之一。在这一部分，我们将首先回顾一些对预训练表示的迁移性影响深远的重要模型架构，详见[2.1节](#S2.SS1
    "2.1 Pre-Training Model ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A
    Survey")。然后，我们详细讲解如何通过在大规模标注数据上进行监督预训练，在[2.2节](#S2.SS2 "2.2 Supervised Pre-Training
    ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A Survey")提高迁移性，以及通过在更大规模的未标注数据上进行无监督预训练，在[2.3节](#S2.SS3
    "2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey")提高迁移性。图[3](#S2.F3 "Figure 3 ‣ 2 Pre-Training ‣ Transferability in Deep
    Learning: A Survey")概述了预训练方法的最新基石。'
- en: '![Refer to caption](img/dabd6cc8ab25bab8c0cb5921176bb3ca.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/dabd6cc8ab25bab8c0cb5921176bb3ca.png)'
- en: 'Figure 3: Cornerstones of pre-training methods for *gaining* knowledge of transferability.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：*获得*知识迁移性的预训练方法的基石。
- en: 2.1 Pre-Training Model
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 预训练模型
- en: Pre-training has a big interplay with the model architecture. On the one hand,
    pre-training techniques, such as greedy layerwise unsupervised pre-training (Bengio
    et al., [2007](#bib.bib12)), have eased the training of many deep architectures.
    On the other hand, as neural networks evolve from shallow to deep, they have a
    larger capacity to capture knowledge by pre-training from large-scale data, which
    increases their transferability to downstream tasks.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练与模型架构有着密切的相互作用。一方面，预训练技术，如贪婪逐层无监督预训练（Bengio等，[2007](#bib.bib12)），已经简化了许多深度架构的训练。另一方面，随着神经网络从浅层到深层的发展，它们能够通过从大规模数据中进行预训练来捕获更多的知识，从而提高了它们对下游任务的迁移性。
- en: Model architecture has a great influence on the transferability of knowledge
    obtained via pre-training. Kornblith et al. ([2019](#bib.bib88)) find that the
    performance of the pre-trained models on the downstream tasks is highly correlated
    with the accuracy on the pre-training tasks, which suggests that improving the
    performance on the pre-training task serves as a direct way for improving transferability.
    The depth of the architecture, or more precisely, the *capacity* of the model,
    is deemed the most critical factor to its transferability. However, training very
    deep neural networks have remained a grand difficulty for decades. He et al. ([2016](#bib.bib64))
    observe a degradation of training accuracy by increasing the network depth, which
    implies that deeper models are more difficult to optimize. Instead of fitting
    a desired mapping $h(\mathbf{x})$ by a few stacked layers, they proposed Residual
    Network (ResNet) to explicitly fit a residual mapping $\delta(\mathbf{x}):=h(\mathbf{x})-\mathbf{x}$
    and then recast the original mapping into $\delta(\mathbf{x})+\mathbf{x}$. As
    a result, ResNet improves feature and gradient flows and enables end-to-end training
    of hundreds of and even thousands of layers, allowing the capacity of pre-trained
    models to scale up easily. Ioffe and Szegedy ([2015](#bib.bib77)) hypothesize
    that the optimization difficulty also comes from the internal covariate shift
    caused by layerwise transformation. To stabilize training very deep models, they
    proposed Batch Normalization (BatchNorm) (Ioffe and Szegedy, [2015](#bib.bib77)),
    which performs normalization for each training mini-batch within the architecture.
    This design is extensively used by ResNet. Kolesnikov et al. ([2020](#bib.bib87))
    find that BatchNorm is suboptimal for transfer due to the requirement of distribution-dependent
    moving averaged statistics. They proposed Big Transfer (BiT) to replace BatchNorm
    by GroupNorm (Wu and He, [2018](#bib.bib191)), which generates pre-trained models
    of strong performance on downstream tasks.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 模型架构对通过预训练获得的知识的迁移能力有很大影响。Kornblith 等人 ([2019](#bib.bib88)) 发现预训练模型在下游任务上的表现与预训练任务上的准确率高度相关，这表明提高预训练任务上的表现是提高迁移能力的直接途径。架构的深度，或更准确地说，模型的*容量*，被认为是其迁移能力最关键的因素。然而，训练非常深的神经网络数十年来一直是一个重大难题。He
    等人 ([2016](#bib.bib64)) 观察到通过增加网络深度会导致训练准确率下降，这意味着更深的模型更难以优化。他们提出了残差网络（ResNet），通过显式地拟合残差映射
    $\delta(\mathbf{x}):=h(\mathbf{x})-\mathbf{x}$，然后将原始映射重构为 $\delta(\mathbf{x})+\mathbf{x}$，而不是通过几个堆叠的层来拟合期望的映射
    $h(\mathbf{x})$。结果，ResNet 改善了特征和梯度流，并使得数百层甚至上千层的端到端训练成为可能，使得预训练模型的*容量*可以轻松扩展。Ioffe
    和 Szegedy ([2015](#bib.bib77)) 假设优化困难也来自于由逐层变换引起的内部协方差偏移。为了稳定非常深模型的训练，他们提出了批量归一化（BatchNorm）
    (Ioffe 和 Szegedy, [2015](#bib.bib77))，该方法对架构中的每个训练小批次进行归一化。这一设计被 ResNet 广泛使用。Kolesnikov
    等人 ([2020](#bib.bib87)) 发现 BatchNorm 在迁移上表现不佳，因为它需要依赖于分布的移动平均统计量。他们提出了大迁移（BiT）来用
    GroupNorm (Wu 和 He, [2018](#bib.bib191)) 替代 BatchNorm，从而生成在下游任务上表现优异的预训练模型。
- en: '![Refer to caption](img/5a4d009737791b030e1fad73959ed36a.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5a4d009737791b030e1fad73959ed36a.png)'
- en: 'Figure 4: Designed inductive bias (left) and learned inductive bias from pre-training
    (right).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：设计的归纳偏置（左）和从预训练中学习到的归纳偏置（右）。
- en: The pre-training paradigm also reshapes the design of model architectures. In
    classic supervised learning, models usually have strong *inductive bias* such
    as the local connectivity assumption in Convolutional Neural Network (CNN) and
    Recurrent Neural Network (RNN). A strong inductive bias makes pre-training of
    deep models more data-efficient and generalize better when training data is scarce,
    yet on the other hand, it also limits the expressiveness and transferability of
    the deep models when there is large-scale data for pre-training. Thus, Transformer (Vaswani
    et al., [2017](#bib.bib177)) removes the local connectivity assumption and models
    the global dependencies between every two tokens. The connection weights are dynamically
    computed by the self-attention mechanism and then the feature aggregation in Transformer
    depends on these attentions calculated from the input sequence, while the token
    positions in the sequence are encoded by positional embedding. Transformers are
    powerful for sequence modeling in natural language processing, and Vision Transformer
    (ViT) (Dosovitskiy et al., [2021](#bib.bib42)) extends them to computer vision.
    ViT splits an image into fixed-size patches, linearly embeds each of them, adds
    positional embeddings, and feeds the resulting sequence of vectors to a standard
    Transformer encoder. In summary, Transformer makes least assumptions on the structural
    information of data, which makes Transformer an *expressive* architecture for
    storing the transferable knowledge extracted by pre-training on large amounts
    of training data (Devlin et al., [2019](#bib.bib39); Radford et al., [2018](#bib.bib134)).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练范式还重塑了模型架构的设计。在经典的监督学习中，模型通常具有强*归纳偏差*，例如卷积神经网络（CNN）和递归神经网络（RNN）中的局部连接假设。强归纳偏差使得深度模型的预训练在数据稀缺时更加数据高效，并且更好地泛化，然而另一方面，当有大规模数据进行预训练时，它也限制了深度模型的表达能力和迁移能力。因此，变换器（Vaswani等人，[2017](#bib.bib177)）去除了局部连接假设，并建模了每两个标记之间的全局依赖关系。连接权重由自注意力机制动态计算，然后变换器中的特征聚合依赖于从输入序列计算出的这些注意力，而序列中的标记位置通过位置嵌入进行编码。变换器在自然语言处理中的序列建模中表现强大，而视觉变换器（ViT）（Dosovitskiy等人，[2021](#bib.bib42)）将其扩展到计算机视觉。ViT将图像分割成固定大小的块，对每个块进行线性嵌入，添加位置嵌入，并将结果向量序列输入到标准变换器编码器中。总之，变换器对数据的结构信息做了最少的假设，这使得变换器成为一个*富有表现力*的架构，能够存储通过在大量训练数据上进行预训练提取的可迁移知识（Devlin等人，[2019](#bib.bib39)；Radford等人，[2018](#bib.bib134)）。
- en: 'In some sense, pre-training provides a *learned* inductive bias for the downstream
    tasks (Torrey and Shavlik, [2010](#bib.bib172)). Many downstream tasks only have
    hundreds or thousands of labeled samples, yet the pre-trained Transformers with
    hundreds of millions of parameters can generalize well after fine-tuning on such
    small data. To explain this phenomenon, Aghajanyan et al. ([2021](#bib.bib2))
    empirically show that pre-training minimizes the intrinsic dimension (Li et al.,
    [2018](#bib.bib99)), which measures the number of parameters required to closely
    approximate the optimization problem. Further, an intrinsic-dimension generalization
    bound is given, indicating that the pre-trained parameters implicitly affect the
    inductive bias of models and a larger pre-trained model might correspond to a
    smaller allowed hypothesis space during fine-tuning (see Figure [4](#S2.F4 "Figure
    4 ‣ 2.1 Pre-Training Model ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey")). The success of Transformer reveals that as the amount of pre-training
    data increases, the learned inductive bias is able to outperform the manually
    designed inductive bias in terms of transferability.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '从某种意义上说，预训练为下游任务提供了*学习到的*归纳偏差（Torrey和Shavlik，[2010](#bib.bib172)）。许多下游任务只有数百或数千个标记样本，但经过数亿参数的预训练变换器在这样的小数据上进行微调后，能够很好地泛化。为了解释这种现象，Aghajanyan等人（[2021](#bib.bib2)）通过实验证明，预训练最小化了内在维度（Li等人，[2018](#bib.bib99)），内在维度测量了接近优化问题所需的参数数量。此外，还给出了一个内在维度泛化界限，表明预训练的参数会隐式影响模型的归纳偏差，较大的预训练模型在微调时可能对应较小的允许假设空间（见图
    [4](#S2.F4 "Figure 4 ‣ 2.1 Pre-Training Model ‣ 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey)）。变换器的成功表明，随着预训练数据量的增加，学习到的归纳偏差能够在迁移能力方面超越人工设计的归纳偏差。'
- en: 2.2 Supervised Pre-Training
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 监督式预训练
- en: 'Supervised pre-training aims to obtain models on large-scale labeled data and
    then transfers these models to boost downstream tasks (see Figure [5](#S2.F5 "Figure
    5 ‣ 2.2 Supervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey")). Supervised pre-training is commonly employed in computer vision,
    where image classification on ImageNet (Deng et al., [2009](#bib.bib38); Russakovsky
    et al., [2015](#bib.bib144)) is often used as the pre-training task. The pre-trained
    models can be transferred to downstream tasks by reusing the representations from
    the feature generator (Sermanet et al., [2013](#bib.bib156)). Donahue et al. ([2014](#bib.bib41))
    find that the generic visual representations pre-trained on ImageNet outperforms
    many conventional feature descriptors on various object recognition tasks. Yosinski
    et al. ([2014](#bib.bib197)) find that transferring the pre-trained models by
    fine-tuning the whole models yields better generalization performance on new tasks.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 监督预训练旨在获得在大规模标注数据上的模型，然后将这些模型迁移以提升下游任务（见图 [5](#S2.F5 "图 5 ‣ 2.2 监督预训练 ‣ 2 预训练
    ‣ 深度学习中的迁移性：综述")）。监督预训练通常用于计算机视觉领域，其中在 ImageNet 上的图像分类（Deng et al., [2009](#bib.bib38);
    Russakovsky et al., [2015](#bib.bib144)）常作为预训练任务。预训练的模型可以通过重用特征生成器中的表示来迁移到下游任务（Sermanet
    et al., [2013](#bib.bib156)）。Donahue et al. ([2014](#bib.bib41)) 发现，在 ImageNet
    上预训练的通用视觉表示在各种物体识别任务上优于许多传统的特征描述符。Yosinski et al. ([2014](#bib.bib197)) 发现，通过微调整个模型来迁移预训练模型，在新任务上能获得更好的泛化性能。
- en: '![Refer to caption](img/e6b96942b79834dbe02f2b35a4aca798.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/e6b96942b79834dbe02f2b35a4aca798.png)'
- en: 'Figure 5: Standard supervised pre-training. The model is composed of a feature
    generator and a task-specific head. The goal is to obtain a feature generator
    capturing transferable knowledge from large-scale labeled data. After pre-training,
    the feature generator is adapted to downstream tasks, while the task-specific
    head is usually discarded.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：标准的监督预训练。模型由一个特征生成器和一个任务特定的头部组成。目标是获得一个从大规模标注数据中捕获可迁移知识的特征生成器。预训练后，特征生成器会被适配到下游任务中，而任务特定的头部通常会被丢弃。
- en: Among the factors that influence the transferability of pre-trained models,
    the quantity and quality of the pre-training data might be the most important.
    BiT (Kolesnikov et al., [2020](#bib.bib87)) emphasizes that training on larger
    datasets is vital for better transferability. Yet the data labeling is labor-exhaustive
    and time-consuming, which limits the possible size of the annotation data. To
    break this limitation, Mahajan et al. ([2018](#bib.bib118)) explore Weakly Supervised
    Pre-training (WSP) on IG-1B-Targeted, a dataset of billions of images with social
    media hashtags. Yalniz et al. ([2019](#bib.bib194)) further explore web-scale
    Semi-Supervised Pre-training (SSP) on YFCC100M, a dataset of billions of unlabeled
    images along with a relatively smaller set of task-specific labeled data. These
    methods improve clearly against the counterpart trained with only clean labeled
    data and achieve stronger transfer performance. On the other hand, Domain Adaptive
    Transfer (DAT) (Ngiam et al., [2018](#bib.bib122)) studies the influence of data
    quality and finds that using more data does not necessarily lead to better transferability,
    especially when the dataset is extremely large. Thus, an importance weighting
    strategy is proposed to carefully choose the pre-training data that are most relevant
    to the target task. Cui et al. ([2018](#bib.bib35)) also find that pre-training
    on more similar upstream data improves transferability to fine-grained downstream
    tasks. They propose to estimate domain similarity via the Earth Mover’s Distance
    to choose proper pre-training data. Geirhos et al. ([2019](#bib.bib49)) find that
    models trained supervisedly on ImageNet are biased towards textures in images,
    and propose to pre-train with a Stylized ImageNet (SIN), which fixes the texture
    bias and encourages the models to learn shape-based representations of better
    transferability.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在影响预训练模型迁移能力的因素中，预训练数据的数量和质量可能是最重要的。BiT (Kolesnikov et al., [2020](#bib.bib87))
    强调，使用更大的数据集进行训练对更好的迁移能力至关重要。然而，数据标注是劳动密集型和耗时的，这限制了标注数据的可能规模。为了打破这一限制，Mahajan et al.
    ([2018](#bib.bib118)) 探索了在 IG-1B-Targeted 上进行弱监督预训练 (WSP)，这是一个包含社交媒体标签的数十亿张图像的数据集。Yalniz
    et al. ([2019](#bib.bib194)) 进一步探索了在 YFCC100M 上进行的大规模半监督预训练 (SSP)，这是一个包含数十亿张未标注图像及相对较小的任务特定标注数据的数据集。这些方法相比于仅用干净标注数据训练的对照组，明显提升了迁移性能。另一方面，Domain
    Adaptive Transfer (DAT) (Ngiam et al., [2018](#bib.bib122)) 研究了数据质量的影响，发现使用更多的数据并不一定能带来更好的迁移能力，尤其是当数据集极其庞大时。因此，提出了一种重要性加权策略，以仔细选择与目标任务最相关的预训练数据。Cui
    et al. ([2018](#bib.bib35)) 也发现，对更相似的上游数据进行预训练能提高对细粒度下游任务的迁移能力。他们建议通过地球搬运工距离 (Earth
    Mover’s Distance) 来估计领域相似性，以选择合适的预训练数据。Geirhos et al. ([2019](#bib.bib49)) 发现，使用
    ImageNet 进行监督训练的模型对图像中的纹理有偏见，并建议使用 Stylized ImageNet (SIN) 进行预训练，以修正纹理偏见，并鼓励模型学习基于形状的更具迁移性的表示。
- en: 'While standard supervised pre-training is powerful when there are enough labeled
    data, it still has drawbacks that may limit the transferability of the model.
    For instance, standard supervised pre-trained models are vulnerable to adversarial
    examples (Goodfellow et al., [2015](#bib.bib55)), and Salman et al. ([2020](#bib.bib148))
    enhance the adversarial robustness of the pre-trained models to achieve better
    transferability. In addition, there are alternative pre-training methods for improving
    the transferability of deep models. Section [2.2.1](#S2.SS2.SSS1 "2.2.1 Meta-Learning
    ‣ 2.2 Supervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey") will elaborate on meta-learning, which aims to obtain pre-trained models
    that adapt to downstream tasks with less training time and less training data.
    Section [2.2.2](#S2.SS2.SSS2 "2.2.2 Causal Learning ‣ 2.2 Supervised Pre-Training
    ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A Survey") will review causal
    learning, which aims to obtain distributionally robust and generalizable pre-trained
    models.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管标准的监督预训练在有足够标注数据的情况下很强大，但它仍然存在一些可能限制模型迁移能力的缺陷。例如，标准的监督预训练模型容易受到对抗样本的影响 (Goodfellow
    et al., [2015](#bib.bib55))，Salman et al. ([2020](#bib.bib148)) 通过增强预训练模型的对抗鲁棒性来实现更好的迁移能力。此外，还有一些替代的预训练方法可以提高深度模型的迁移能力。第[2.2.1](#S2.SS2.SSS1
    "2.2.1 元学习 ‣ 2.2 监督预训练 ‣ 2 预训练 ‣ 深度学习中的迁移能力：综述")节将详细介绍元学习，它旨在获得能够适应下游任务的预训练模型，从而减少训练时间和训练数据。第[2.2.2](#S2.SS2.SSS2
    "2.2.2 因果学习 ‣ 2.2 监督预训练 ‣ 2 预训练 ‣ 深度学习中的迁移能力：综述")节将回顾因果学习，它旨在获得具有分布鲁棒性和泛化能力的预训练模型。
- en: 2.2.1 Meta-Learning
  id: totrans-113
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1 元学习
- en: Standard supervised pre-training gains transferable representations to boost
    the learning of new tasks. However, it still requires to fine-tune the pre-trained
    models with hundreds or thousands of labeled data and with many gradient updates
    when adapting to the new task. In contrast, people have the ability to quickly
    adapt to different related new tasks with few labeled data. Meta-learning, also
    known as learning to learn (Schmidhuber, [1987](#bib.bib152)), aims to pursue
    such kind of *efficient* transferability in the pre-training stage.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的有监督预训练获得了可转移的表征，以促进新任务的学习。然而，它仍然需要对预训练模型进行微调，需要大量的标记数据和许多梯度更新，以适应新任务。相比之下，人们能够用少量标记数据快速适应不同的相关新任务。元学习，也被称为学习如何学习（Schmidhuber，[1987](#bib.bib152)），旨在追求这种*高效*的可转移性。
- en: 'The core idea of meta-learning is to equip the model with some meta knowledge
    $\phi$ that captures intrinsic properties of different learning tasks, which is
    called meta-training. When facing a new task, the learned meta knowledge could
    help the target model $\theta$ adapt to the task faster, which is called meta-testing.
    Meta-learning is based on a simple machine learning principle that test and training
    conditions should be matched. As shown in Figure [6(a)](#S2.F6.sf1 "In Figure
    6 ‣ 2.2.1 Meta-Learning ‣ 2.2 Supervised Pre-Training ‣ 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey"), to simulate the fast adaptation condition during
    meta-testing, the meta-training data is constructed into a collection of $n$ learning
    tasks, and each task $i\in[n]$ contains a training set $\mathcal{D}^{\text{tr}}_{i}$
    for adaptation to this task and a test set $\mathcal{D}^{\text{ts}}_{i}$ for evaluation¹¹1$\mathcal{D}^{\text{ts}}$
    is a *surrogate* test set used during meta-training to simulate different tasks
    and improve the model. It is different from the true test set in the general setting
    in machine learning.. As shown in Figure [6(b)](#S2.F6.sf2 "In Figure 6 ‣ 2.2.1
    Meta-Learning ‣ 2.2 Supervised Pre-Training ‣ 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey"), the learning objective of meta-training is a bi-level
    optimization problem,'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 元学习的核心思想是为模型提供一些能够捕捉不同学习任务内在特性的元知识$\phi$，这被称为元训练。当面对新任务时，学到的元知识可以帮助目标模型$\theta$更快地适应任务，这被称为元测试。元学习基于一个简单的机器学习原则，即测试和训练条件应匹配。如图[6(a)](#S2.F6.sf1
    "在图6 ‣ 2.2.1 元学习 ‣ 2.2 有监督的预训练 ‣ 2 预训练 ‣ 深度学习中的可转移性：综述")所示，为了模拟元测试期间的快速适应条件，元训练数据被构造为$n$个学习任务的集合，每个任务$i\in[n]$包含一个用于适应此任务的训练集$\mathcal{D}^{\text{tr}}_{i}$和一个用于评估的测试集$\mathcal{D}^{\text{ts}}_{i}$¹¹1$\mathcal{D}^{\text{ts}}$是一个*替代*测试集，用于元训练期间模拟不同任务并改进模型。它与机器学习中的真实测试集不同。如图[6(b)](#S2.F6.sf2
    "在图6 ‣ 2.2.1 元学习 ‣ 2.2 有监督的预训练 ‣ 2 预训练 ‣ 深度学习中的可转移性：综述")所示，元训练的学习目标是一个双层优化问题，
- en: '|  | $\phi^{*}={\arg}\mathop{\max}_{\phi}\sum_{i=1}^{n}\log P(\theta_{i}(\phi)&#124;\mathcal{D}^{\text{ts}}_{i}),\quad\text{where}\
    \theta_{i}(\phi)={\arg}\mathop{\max}_{\theta}\log P(\theta&#124;\mathcal{D}^{\text{tr}}_{i},\phi).\\
    $ |  | (1) |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '|  | $\phi^{*}={\arg}\mathop{\max}_{\phi}\sum_{i=1}^{n}\log P(\theta_{i}(\phi)&#124;\mathcal{D}^{\text{ts}}_{i}),\quad\text{where}\
    \theta_{i}(\phi)={\arg}\mathop{\max}_{\theta}\log P(\theta&#124;\mathcal{D}^{\text{tr}}_{i},\phi).\\
    $ |  | (1) |'
- en: Here the inner level optimization updates the model $\theta$ with the training
    set $\mathcal{D}^{\text{tr}}_{i}$ using meta knowledge $\phi$, and the outer level
    optimization evaluates the updated model with the test set $\mathcal{D}^{\text{ts}}_{i}$
    to find better meta knowledge of stronger transferability. The key to enhancing
    the transferability of meta-learning methods is to design a proper form of meta
    knowledge.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，内层优化使用元知识$\phi$和训练集$\mathcal{D}^{\text{tr}}_{i}$来更新模型$\theta$，外层优化则用测试集$\mathcal{D}^{\text{ts}}_{i}$来评估更新后的模型，以寻找更强的可转移性元知识。提升元学习方法的可转移性的关键在于设计合适形式的元知识。
- en: '![Refer to caption](img/0fbbcc03cc77d3515e3da83470830f35.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0fbbcc03cc77d3515e3da83470830f35.png)'
- en: (a) Learning Setup
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 学习设置
- en: '![Refer to caption](img/2ead3339e35459a28217d5fffe75a9c6.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2ead3339e35459a28217d5fffe75a9c6.png)'
- en: (b) Architecture
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 体系结构
- en: 'Figure 6: Learning setup and architecture for meta-learning. (a) Meta-learning
    consists of two phases, meta-training and meta-testing. Meta-training gains meta
    knowledge $\phi$ from training tasks to help the model $\theta$ adapt quickly
    to a new task in meta-testing, where each task consists of a training set and
    a test set. (b) In the inner level optimization, the model $\theta$ is updated
    with the training set $\mathcal{D}^{\text{tr}}_{i}$ using meta knowledge $\phi$.
    In the outer level optimization, the updated model is evaluated on the test set
    $\mathcal{D}^{\text{ts}}_{i}$ to find better meta knowledge $\phi$.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：元学习的学习设置和架构。 (a) 元学习包括两个阶段，元训练和元测试。元训练从训练任务中获得元知识 $\phi$，以帮助模型 $\theta$ 快速适应元测试中的新任务，其中每个任务由一个训练集和一个测试集组成。
    (b) 在内部优化层次中，模型 $\theta$ 使用元知识 $\phi$ 在训练集 $\mathcal{D}^{\text{tr}}_{i}$ 上进行更新。在外部优化层次中，更新后的模型在测试集
    $\mathcal{D}^{\text{ts}}_{i}$ 上进行评估，以寻找更好的元知识 $\phi$。
- en: Memory-Based Meta-Learning considers *memory mechanisms* as the meta knowledge.
    A controller writes knowledge extracted from training data $\mathcal{D}_{i}^{\text{tr}}$
    into the memory, and reads from the memory to adapt the base learner $\theta$
    to make predictions on test data $\mathcal{D}_{i}^{\text{ts}}$. The parameter
    of the controller is updated to find transferable knowledge. Memory-Augmented
    Neural Network (MANN) (Santoro et al., [2016](#bib.bib150)) stores bound sample
    representation-class label information in the external memory, which can then
    be retrieved as features for making predictions when a sample from the same class
    is presented. Meta Network (Munkhdalai and Yu, [2017](#bib.bib121)) designs another
    memory mechanism where a base learner provides information about the status of
    the current task while the meta learner interacts with the external memory to
    generate parameters for the base learner to quickly learn the new task. Memory-based
    meta-learning methods improve transferability in various downstream tasks, such
    as few-shot classification and reinforcement learning. However, they require a
    careful design of the black-box architecture to incorporate the memory mechanism,
    and it is unclearer what is stored and retrieved in the memory and why it helps
    adapt the model.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 基于记忆的元学习将*记忆机制*视为元知识。控制器将从训练数据 $\mathcal{D}_{i}^{\text{tr}}$ 中提取的知识写入内存，并从内存中读取以适应基本学习器
    $\theta$ 以对测试数据 $\mathcal{D}_{i}^{\text{ts}}$ 进行预测。控制器的参数被更新以寻找可迁移的知识。Memory-Augmented
    Neural Network (MANN) (Santoro et al., [2016](#bib.bib150)) 将样本表示-类别标签信息存储在外部记忆中，当出现来自同一类别的样本时，这些信息可以被检索作为特征进行预测。Meta
    Network (Munkhdalai and Yu, [2017](#bib.bib121)) 设计了另一种记忆机制，其中基本学习器提供当前任务的状态信息，而元学习器与外部记忆交互以生成基本学习器的参数，以便快速学习新任务。基于记忆的元学习方法在各种下游任务中提高了迁移性，如少样本分类和强化学习。然而，它们需要仔细设计黑箱架构以纳入记忆机制，并且不清楚在记忆中存储和检索的内容以及为何这些内容有助于适应模型。
- en: Optimization-Based Meta-Learning considers a good *initialization* of the model
    as the meta knowledge. The motivation of Model-Agnostic Meta-Learning (MAML) (Finn
    et al., [2017](#bib.bib43)) is to explicitly seek for an initialization that is
    most transferable for fine-tuning, i.e., only a small amount of gradient steps
    and a few labeled data are needed for the model to generalize to a new task. To
    learn such an initialization, for each sampled task $i\in[n]$, the model $\phi$
    is first updated on its training data $\mathcal{D}_{i}^{\text{tr}}$ using one
    gradient step of size $\alpha$,
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 基于优化的元学习将模型的良好*初始化*视为元知识。Model-Agnostic Meta-Learning (MAML) (Finn et al., [2017](#bib.bib43))
    的动机是明确寻找一种最具可迁移性的初始化，即模型仅需少量梯度步骤和少量标记数据就能泛化到新任务。为了学习这样的初始化，对于每个抽样任务 $i\in[n]$，模型
    $\phi$ 首先在其训练数据 $\mathcal{D}_{i}^{\text{tr}}$ 上使用大小为 $\alpha$ 的一次梯度步骤进行更新，
- en: '|  | $\theta_{i}=\phi-\alpha\nabla_{\phi}L(\phi,\mathcal{D}_{i}^{\text{tr}}).$
    |  | (2) |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|  | $\theta_{i}=\phi-\alpha\nabla_{\phi}L(\phi,\mathcal{D}_{i}^{\text{tr}}).$
    |  | (2) |'
- en: which mimics the situation of fine-tuning the model from the starting point
    of $\phi$. As meta knowledge, $\phi$ should have good transferablity, such that
    for all tasks $i\in[n]$, the fine-tuned parameters $\theta_{i}$ could perform
    well on the test set $\mathcal{D}_{i}^{\text{ts}}$,
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这模仿了从 $\phi$ 的起始点对模型进行微调的情况。作为元知识，$\phi$ 应具有良好的可迁移性，以便对于所有任务 $i\in[n]$，微调后的参数
    $\theta_{i}$ 可以在测试集 $\mathcal{D}_{i}^{\text{ts}}$ 上表现良好。
- en: '|  | $\min_{\phi}\sum_{i=1}^{n}L(\theta_{i}(\phi),\mathcal{D}_{i}^{\text{ts}})=\sum_{i=1}^{n}L(\phi-\alpha\nabla_{\phi}L(\phi,\mathcal{D}_{i}^{\text{tr}}),\mathcal{D}_{i}^{\text{ts}}).$
    |  | (3) |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{\phi}\sum_{i=1}^{n}L(\theta_{i}(\phi),\mathcal{D}_{i}^{\text{ts}})=\sum_{i=1}^{n}L(\phi-\alpha\nabla_{\phi}L(\phi,\mathcal{D}_{i}^{\text{tr}}),\mathcal{D}_{i}^{\text{ts}}).$
    |  | (3) |'
- en: The meta knowledge of MAML is high-dimensional, hindering MAML from deeper models.
    To tackle it, Meta Transfer (Sun et al., [2019a](#bib.bib167)) uses standard pre-training
    for initialization and performs meta-training with light-weight neuron operations
    (e.g. scaling and shifting over tasks), which reduces the training tasks needed
    to acquire the meta knowledge.  Raghu et al. ([2020](#bib.bib137)) find that feature
    reuse of the backbone is the predominant reason for efficient learning on downstream
    tasks with MAML. They thus propose the Almost No Inner Loop algorithm, which performs
    inner loop updates and task adaptation only on the task-specific head layer. Another
    limitation of MAML is that the fixed meta knowledge is globally shared by all
    tasks. To break this, Latent Embedding Optimization (Rusu et al., [2019](#bib.bib145))
    performs gradient-based meta-learning in a low-dimensional latent space, and learns
    data-dependent latent embedding as meta knowledge to generate target model parameters.
    Yao et al. ([2019](#bib.bib196)) perform Hierarchically Structured Meta-Learning
    over hierarchical tasks based on clustering structures and learns to tailor transferable
    meta knowledge to different tasks.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: MAML的元知识是高维的，这阻碍了MAML在更深模型中的应用。为了解决这个问题，Meta Transfer（Sun et al., [2019a](#bib.bib167)）使用标准预训练进行初始化，并通过轻量级神经操作（例如在任务间的缩放和偏移）进行元训练，从而减少了获得元知识所需的训练任务。Raghu
    et al. ([2020](#bib.bib137))发现骨干网络的特征重用是MAML在下游任务中高效学习的主要原因。因此，他们提出了几乎无内部循环算法，该算法仅在特定任务的头层上进行内部循环更新和任务适应。MAML的另一个限制是固定的元知识被所有任务全局共享。为了解决这个问题，Latent
    Embedding Optimization（Rusu et al., [2019](#bib.bib145)）在低维潜在空间中执行基于梯度的元学习，并学习数据依赖的潜在嵌入作为元知识，以生成目标模型参数。Yao
    et al. ([2019](#bib.bib196))在基于聚类结构的层级任务上执行层级结构元学习，并学习将可迁移的元知识量身定制到不同任务中。
- en: While meta-learning methods enable fast model adaptation across tasks, they
    are weak in transferring to data from different domains, and some sophisticated
    methods even perform worse than standard pre-training baselines (Chen et al.,
    [2019a](#bib.bib24)). Thus, Omni-Training  (Shu et al., [2021a](#bib.bib159))
    incorporates both standard pre-training and meta-training in a framework with
    a tri-flow architecture to equip the pre-trained model with both domain transferability
    across different distributions and task transferability for fast adaptation across
    related tasks.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管元学习方法可以在任务间实现快速模型适应，但它们在不同领域的数据迁移上表现较弱，一些复杂的方法甚至表现不如标准的预训练基线（Chen et al.,
    [2019a](#bib.bib24)）。因此，Omni-Training（Shu et al., [2021a](#bib.bib159)）在一个三流架构的框架中融合了标准预训练和元训练，以使预训练模型具备在不同分布间的领域迁移能力和在相关任务间的快速适应能力。
- en: 2.2.2 Causal Learning
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2 因果学习
- en: It remains difficult for supervised pre-training to obtain a transferable representation
    that generalizes well to an out-of-distribution (OOD) domain (Bengio et al., [2021](#bib.bib14)).
    In contrast, humans have the ability to adapt to different domains or new environments.
    Causal learning aims to pursue such kind of *extrapolated* transferability in
    the pre-training stage.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于监督式预训练而言，获得能够良好泛化到分布外（OOD）领域的可迁移表示仍然很困难（Bengio et al., [2021](#bib.bib14)）。相比之下，人类具有适应不同领域或新环境的能力。因果学习旨在在预训练阶段追求这种*外推*的迁移能力。
- en: 'The core idea of causal learning is to equip the model with some causal mechanisms
    that capture independent and disentangled aspects of the complex real-world distributions.
    When the distribution changes, only one or several causal mechanisms change, with
    others remaining invariant, which could result in better out-of-distribution (OOD)
    generalization. The causal mechanisms are described by Structural Causal Models.
    As shown in Figure [7](#S2.F7 "Figure 7 ‣ 2.2.2 Causal Learning ‣ 2.2 Supervised
    Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A Survey"),
    causal mechanisms consider a set of variables as the vertices of a directed acyclic
    graph, and each edge represents a mechanism of direct causation in that the parents
    directly affect the assignment of the child. This induces a canonical factorization
    of the joint distribution of these variables into the disentangled distribution
    of them conditioned on their parents. The independent causal mechanism principle
    states that given its mechanism, the conditional distribution of each variable
    does not inform or influence the other mechanisms (Schölkopf et al., [2012](#bib.bib153);
    Peters et al., [2017](#bib.bib130)). This implies that small distribution changes
    should only affect the causal mechanisms along with the disentangled factorization
    in a sparse and local way (Schölkopf et al., [2021](#bib.bib154)), thereby enabling
    transferability towards different distributions. The key problem of causal learning
    is to obtain the variables governed by independent causal mechanisms. One way
    is to explicitly introduce independence with the *modular* models. Another common
    practice is to leverage the *invariance* assumption that causal relationships
    remain invariant across distributions.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '因果学习的核心思想是为模型配备一些因果机制，这些机制捕捉复杂真实世界分布的独立和解耦方面。当分布发生变化时，只有一个或几个因果机制发生变化，其它机制保持不变，这可能会导致更好的分布外（OOD）泛化。因果机制由结构性因果模型描述。如图[7](#S2.F7
    "Figure 7 ‣ 2.2.2 Causal Learning ‣ 2.2 Supervised Pre-Training ‣ 2 Pre-Training
    ‣ Transferability in Deep Learning: A Survey")所示，因果机制将一组变量视为有向无环图的顶点，每条边表示直接因果机制，即父节点直接影响子节点的赋值。这引出了这些变量的联合分布的标准化因解耦分布，即在父节点条件下的分布。独立因果机制原理指出，给定其机制，每个变量的条件分布不会通知或影响其他机制（Schölkopf
    et al., [2012](#bib.bib153); Peters et al., [2017](#bib.bib130)）。这意味着小的分布变化只应以稀疏和局部的方式影响因果机制及其解耦分解（Schölkopf
    et al., [2021](#bib.bib154)），从而实现对不同分布的可迁移性。因果学习的关键问题是获取由独立因果机制支配的变量。一个方法是通过*模块化*模型显式引入独立性。另一种常见做法是利用*不变性*假设，即因果关系在分布之间保持不变。'
- en: '![Refer to caption](img/72766ad5a9818623242e83d59ada27ff.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/72766ad5a9818623242e83d59ada27ff.png)'
- en: 'Figure 7: Causal mechanisms consider a set of observations or variables as
    the vertices of a directed acyclic graph, where each edge corresponds to a mechanism
    of direct causation. Causal learning seeks a model with variables governed by
    certain causal mechanisms, and if the environment or distribution changes, only
    part of the causal mechanisms will be affected.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7: 因果机制将一组观察或变量视为有向无环图的顶点，其中每条边对应一个直接因果机制。因果学习寻求一个由特定因果机制支配的变量模型，如果环境或分布发生变化，只有部分因果机制会受到影响。'
- en: Modular Model. Recurrent Independent Mechanism (RIM) (Goyal et al., [2021](#bib.bib56))
    takes a modular model composed of several modules of different functions, where
    each module is a recurrent cell such as LSTM or GRU (Cho et al., [2014](#bib.bib31))
    and represents a causal mechanism. To obtain independence in distinct modules,
    RIM introduces attention between the hidden states of each module and the current
    inputs. For specific inputs, only the most relevant modules with larger attention
    are activated and updated, which forms competition between different modules and
    encourages their independence. RIM is shown to capture independent causal mechanisms
    and generalize well over different temporal patterns.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 模块化模型。递归独立机制（RIM）（Goyal et al., [2021](#bib.bib56)）采用一个由多个不同功能模块组成的模块化模型，其中每个模块是一个递归单元，例如LSTM或GRU（Cho
    et al., [2014](#bib.bib31)），并表示一个因果机制。为了在不同模块中获得独立性，RIM在每个模块的隐藏状态与当前输入之间引入了注意力机制。对于特定输入，仅激活和更新最相关的注意力较大的模块，这在不同模块之间形成了竞争，促进了它们的独立性。RIM已被证明能够捕捉独立的因果机制，并在不同的时间模式上良好地泛化。
- en: Invariant Learning. The invariance assumption indicates that the conditional
    probability of the target output given its direct cause should be invariant across
    all environments or distributions. Invariant Causal Prediction (ICP) (Peters et al.,
    [2016](#bib.bib129)) uncovers independent causal mechanisms by performing a statistical
    test to find the subset of the variables satisfying the invariance assumption.
    Invariant Risk Minimization (IRM) (Arjovsky et al., [2019](#bib.bib4)) extends
    this idea to representation learning and learns a good representation such that
    the conditional probability of the target output given the representation should
    be invariant across training environments. Formally, given a data representation
    $\psi:\mathcal{X}\rightarrow\mathcal{Z}$ and training environments $\mathcal{E}^{\text{tr}}$,
    the conditional probability between the representation and the output is invariant
    if there is a classifier $h:\mathcal{Z}\rightarrow\mathcal{Y}$ simultaneously
    optimal for all the environments. This can be formalized as the following constrained
    optimization problem,
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 不变学习。不可变性假设表明，目标输出给定其直接原因的条件概率应该在所有环境或分布中保持不变。不变因果预测（ICP）(Peters et al., [2016](#bib.bib129))
    通过执行统计测试来发现满足不可变性假设的变量子集，从而揭示独立的因果机制。不变风险最小化（IRM）(Arjovsky et al., [2019](#bib.bib4))
    将这一思想扩展到表示学习中，学习一个良好的表示，使得目标输出给定表示的条件概率在训练环境中保持不变。形式上，给定数据表示 $\psi:\mathcal{X}\rightarrow\mathcal{Z}$
    和训练环境 $\mathcal{E}^{\text{tr}}$，如果存在一个分类器 $h:\mathcal{Z}\rightarrow\mathcal{Y}$
    对所有环境同时最优，则表示和输出之间的条件概率是不变的。这可以形式化为以下约束优化问题，
- en: '|  | $\mathop{\min}_{\psi:\mathcal{X}\rightarrow\mathcal{Z},{h}:\mathcal{Z}\rightarrow\mathcal{Y}}\
    \sum_{e\in\mathcal{E}^{\text{tr}}}\epsilon^{e}(h\circ\psi),\quad\text{subject
    to }h\in\mathop{\arg\min}_{\bar{h}:\mathcal{Z}\rightarrow\mathcal{Y}}\epsilon^{e}(\bar{h}\circ\psi),\
    \text{for all}\ e\in\mathcal{E}^{\text{tr}},$ |  | (4) |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathop{\min}_{\psi:\mathcal{X}\rightarrow\mathcal{Z},{h}:\mathcal{Z}\rightarrow\mathcal{Y}}\
    \sum_{e\in\mathcal{E}^{\text{tr}}}\epsilon^{e}(h\circ\psi),\quad\text{subject
    to }h\in\mathop{\arg\min}_{\bar{h}:\mathcal{Z}\rightarrow\mathcal{Y}}\epsilon^{e}(\bar{h}\circ\psi),\
    \text{for all}\ e\in\mathcal{E}^{\text{tr}},$ |  | (4) |'
- en: where $\epsilon^{e}(h\circ\psi)$ refers to the expected error of the predictor
    $h\circ\psi$ on the environment $e$. The transferability across environments relies
    on how the invariance across training environments implies invariance across all
    environments. Thus, the diversity of training environments is important for gaining
    transferability. IRM can be extended to complex situations where the causal relations
    are defined on some latent variables that need to be extracted from data.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\epsilon^{e}(h\circ\psi)$ 指的是预测器 $h\circ\psi$ 在环境 $e$ 上的期望误差。跨环境的可迁移性依赖于训练环境的不可变性是否暗示了所有环境中的不可变性。因此，训练环境的多样性对于获得可迁移性至关重要。IRM
    可以扩展到复杂情况，其中因果关系定义在一些需要从数据中提取的潜在变量上。
- en: 2.3 Unsupervised Pre-Training
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 无监督预训练
- en: 'Being a canonical successful approach, supervised pre-training still requires
    a large amount of labeled data which are expensive to annotate and only available
    in certain fields. This hinders pre-training on huge-scale data and limits its
    transferability to particular tasks. To break this shackle, unsupervised learning (Bengio,
    [2012](#bib.bib11)), typically in the form of self-supervised learning, is used
    for pre-training on very large unlabeled data to acquire generally transferable
    knowledge. To improve the transferability on downstream tasks, it is crucial to
    design a proper self-supervised task for pre-training. According to the type of
    task, we can divide common unsupervised pre-training methods into generative learning
    and contrastive learning, which will be discussed in Sections [2.3.1](#S2.SS3.SSS1
    "2.3.1 Generative Learning ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣
    Transferability in Deep Learning: A Survey") and [2.3.2](#S2.SS3.SSS2 "2.3.2 Contrastive
    Learning ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in
    Deep Learning: A Survey") respectively.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种经典的成功方法，监督预训练仍然需要大量标注数据，这些数据标注成本高且仅在某些领域可用。这阻碍了大规模数据的预训练，并限制了其在特定任务中的迁移性。为打破这一桎梏，通常采用无监督学习（Bengio，[2012](#bib.bib11)），特别是自监督学习形式，在非常大规模的未标注数据上进行预训练，以获得一般可转移的知识。为了提高下游任务的迁移性，设计合适的自监督任务用于预训练至关重要。根据任务类型，我们可以将常见的无监督预训练方法分为生成学习和对比学习，这将在第
    [2.3.1](#S2.SS3.SSS1 "2.3.1 生成学习 ‣ 2.3 无监督预训练 ‣ 2 预训练 ‣ 深度学习中的迁移性：综述") 和 [2.3.2](#S2.SS3.SSS2
    "2.3.2 对比学习 ‣ 2.3 无监督预训练 ‣ 2 预训练 ‣ 深度学习中的迁移性：综述") 节中分别讨论。
- en: 2.3.1 Generative Learning
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1 生成学习
- en: 'Generative learning is underpinned by the idea of learning to generate data
    distribution $P(\mathbf{X})$ for unsupervised pre-training. It aims to learn the
    intrinsic representation in data and has been commonly used for pre-training deep
    neural networks (Bengio et al., [2007](#bib.bib12)). As shown in Figure [8](#S2.F8
    "Figure 8 ‣ 2.3.1 Generative Learning ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training
    ‣ Transferability in Deep Learning: A Survey"), we employ an encoder $f_{\theta}$
    that maps the perturbed input $\tilde{\mathbf{x}}$ into a latent representation
    $\mathbf{z}=f_{\theta}(\tilde{\mathbf{x}})$ and a decoder $g_{\theta}$ that maps
    the representation back to derive a reconstructed version of the input $\widehat{\mathbf{x}}=g_{\theta}(\mathbf{z})$.
    The model is then optimized by minimizing the reconstruction error $L_{\text{gen}}(\widehat{\mathbf{x}},\mathbf{x})$.
    Most generative pre-training methods are based on two models: *Autoregressive*
    Model, which generates future inputs given only past inputs, and *Autoencoding*
    Model, which generates full inputs given partial inputs.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 生成学习基于为无监督预训练生成数据分布 $P(\mathbf{X})$ 的思想。它旨在学习数据中的内在表示，并且已被广泛用于深度神经网络的预训练（Bengio
    等，[2007](#bib.bib12)）。如图 [8](#S2.F8 "图 8 ‣ 2.3.1 生成学习 ‣ 2.3 无监督预训练 ‣ 2 预训练 ‣ 深度学习中的迁移性：综述")
    所示，我们使用一个编码器 $f_{\theta}$ 将扰动输入 $\tilde{\mathbf{x}}$ 映射到潜在表示 $\mathbf{z}=f_{\theta}(\tilde{\mathbf{x}})$，以及一个解码器
    $g_{\theta}$ 将表示映射回去以生成重建的输入版本 $\widehat{\mathbf{x}}=g_{\theta}(\mathbf{z})$。然后，通过最小化重建误差
    $L_{\text{gen}}(\widehat{\mathbf{x}},\mathbf{x})$ 来优化模型。大多数生成预训练方法基于两个模型：*自回归*
    模型，它仅根据过去的输入生成未来的输入；和 *自编码* 模型，它根据部分输入生成完整的输入。
- en: '![Refer to caption](img/0732882422804ad47d492c4e5c973b30.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/0732882422804ad47d492c4e5c973b30.png)'
- en: 'Figure 8: Generative pre-training tries to reconstruct the original input $\mathbf{x}$
    from a perturbed input $\tilde{\mathbf{x}}$. The generative learning task shall
    encourage the learned representation $\mathbf{z}$ to capture the intrinsic and
    transferable explanatory factors from the data.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：生成预训练试图从扰动输入 $\tilde{\mathbf{x}}$ 重建原始输入 $\mathbf{x}$。生成学习任务应鼓励学习到的表示 $\mathbf{z}$
    捕捉数据中的内在和可转移的解释性因素。
- en: 'Autoregressive Model approximates the distribution of a sequence by predicting
    each entry conditioned on its previous context, which is called Language Modeling
    (LM) task in NLP. As shown in Figure [9](#S2.F9 "Figure 9 ‣ 2.3.1 Generative Learning
    ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey"), given a text sequence $\mathbf{x}_{1:T}=[x_{1},x_{2},...,x_{T}]$,
    the learning objective of LM is to maximize the conditional probability of each
    entry $x_{t}$,'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '自回归模型通过预测每个条目的前置上下文来逼近序列的分布，这在自然语言处理（NLP）中被称为语言建模（LM）任务。如图[9](#S2.F9 "Figure
    9 ‣ 2.3.1 Generative Learning ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training
    ‣ Transferability in Deep Learning: A Survey")所示，给定一个文本序列$\mathbf{x}_{1:T}=[x_{1},x_{2},...,x_{T}]$，LM的学习目标是最大化每个条目$x_{t}$的条件概率，'
- en: '|  | $\max_{\theta}\sum_{t=1}^{T}\log P_{\theta}(x_{t}&#124;x_{t-k},\cdots,x_{t-1}),$
    |  | (5) |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|  | $\max_{\theta}\sum_{t=1}^{T}\log P_{\theta}(x_{t}\mid x_{t-k},\cdots,x_{t-1}),$
    |  | (5) |'
- en: where $k$ is the size of the context window and $\theta$ is the parameter of
    the neural network. Generative Pre-Training (GPT) (Radford et al., [2018](#bib.bib134))
    explores unsupervised pre-training of Transformer with LM on the BooksCorpus (Zhu
    et al., [2015](#bib.bib210)) dataset with over $7000$ unpublished books. This
    equips the model with great transferability to various NLP tasks, such as question
    answering, commonsense reasoning, and so on. The advantage of LM is that it models
    the context dependency while the drawback is that it only encodes contextual information
    from one direction, yet contextual representations encoded in both directions
    may be more suitable to many downstream tasks, such as natural language inference.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$k$是上下文窗口的大小，$\theta$是神经网络的参数。生成预训练（GPT）（Radford et al., [2018](#bib.bib134)）探索了使用LM对BooksCorpus（Zhu
    et al., [2015](#bib.bib210)）数据集（包含超过$7000$本未出版书籍）进行的Transformer的无监督预训练。这使得模型具备了很好的迁移能力，可以应用于各种NLP任务，例如问答、常识推理等。LM的优点在于它建模了上下文依赖性，而缺点在于它仅从一个方向编码上下文信息，然而双向编码的上下文表示可能更适合许多下游任务，如自然语言推理。
- en: '![Refer to caption](img/14875a775be44e900a4b3b7ec575659c.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/14875a775be44e900a4b3b7ec575659c.png)'
- en: 'Figure 9: Attention visibility in Transformer (Trm) for language models. (a)
    LM maximizes the probabilities of all words conditioned on their previous words.
    (b) MLM maximizes the probabilities of random masked words conditioned on all
    unmasked words. (c) PLM permutes the original sequence and then performs autoregression.
    (d) Seq2Seq MLM encodes the input masked sequence $x$ and then decodes the output
    masked tokens $y$ sequentially.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '图 9: Transformer（Trm）在语言模型中的注意力可见性。（a）LM最大化所有单词的概率，条件是它们之前的单词。（b）MLM最大化随机掩蔽单词的概率，条件是所有未掩蔽的单词。（c）PLM对原始序列进行排列，然后执行自回归。（d）Seq2Seq
    MLM对输入掩蔽序列$x$进行编码，然后依次解码输出掩蔽标记$y$。'
- en: 'Autoencoding Model approximates the data distribution by generating original
    data from encoded representations. Vincent et al. ([2008](#bib.bib179)) hypothesize
    that a good representation should also be robust to partial corruption of the
    input. Thus Denoising Autoencoder (Vincent et al., [2008](#bib.bib179)) is trained
    to reconstruct the original input $\mathbf{x}$ with the corrupted input $\tilde{\mathbf{x}}$.
    Inspired from Denoising Autoencoder, BERT (Devlin et al., [2019](#bib.bib39))
    adopts the Masked Language Modeling (MLM) task as a pre-training task to overcome
    the drawback of the unidirectional LM. As shown in Figure [9](#S2.F9 "Figure 9
    ‣ 2.3.1 Generative Learning ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣
    Transferability in Deep Learning: A Survey"), MLM first randomly masks out some
    tokens $m(\mathbf{x})$ from the input sentences $\mathbf{x}$ with a special [MASK]
    token and then trains the models to predict the masked tokens by the rest of the
    tokens $\mathbf{x}_{\setminus m(\mathbf{x})}$,'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '自编码模型通过从编码表示生成原始数据来逼近数据分布。Vincent et al. ([2008](#bib.bib179))假设一个好的表示也应该对输入的部分损坏具有鲁棒性。因此，去噪自编码器（Vincent
    et al., [2008](#bib.bib179)）被训练来用损坏的输入$\tilde{\mathbf{x}}$重建原始输入$\mathbf{x}$。受到去噪自编码器的启发，BERT（Devlin
    et al., [2019](#bib.bib39)）采用了掩蔽语言建模（MLM）任务作为预训练任务，以克服单向LM的缺点。如图[9](#S2.F9 "Figure
    9 ‣ 2.3.1 Generative Learning ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training
    ‣ Transferability in Deep Learning: A Survey")所示，MLM首先用一个特殊的[MASK]标记随机掩蔽输入句子$\mathbf{x}$中的一些标记$m(\mathbf{x})$，然后训练模型通过其余的标记$\mathbf{x}_{\setminus
    m(\mathbf{x})}$来预测被掩蔽的标记，'
- en: '|  | $\max_{\theta}\sum_{x\in m(\mathbf{x})}\log P_{\theta}(x&#124;\mathbf{x}_{\setminus
    m(\mathbf{x})}).$ |  | (6) |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '|  | $\max_{\theta}\sum_{x\in m(\mathbf{x})}\log P_{\theta}(x\mid\mathbf{x}_{\setminus
    m(\mathbf{x})}).$ |  | (6) |'
- en: Masked pre-training has also been used in many other areas. For instance, Masked
    Autoencoders (MAE) (He et al., [2021](#bib.bib68)) pre-trains vision transformers
    on large-scale unlabeled image datasets using the image generation task. The difficulty
    is that the signals are highly redundant in images, thus it is hard for generative
    tasks, such as filling a few missing pixels, to capture high-level knowledge from
    data. To tackle this issue, MAE randomly masks a very large portion of patches,
    forcing the model to go beyond low-level understanding and reconstruct the whole
    image based on a small subset of visible patches, which improves its transferability
    to semantic-level tasks. For another instance, to pre-train Graph Neural Network
    (GNN) (Garcia and Bruna, [2018](#bib.bib47)) for transferable representations,
    Attribute Masking (Hu et al., [2020](#bib.bib75)) conceals node or edge attributes
    and asks GNNs to predict those attributes based on neighboring structures, which
    can capture the regularities of attributes distribution over different graph structures,
    such as the chemistry rules in molecular graphs, and improve transferability on
    the downstream node or edge classification tasks.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 掩码预训练也已应用于许多其他领域。例如，掩码自编码器（MAE）（He 等，[2021](#bib.bib68)）在大规模未标记图像数据集上使用图像生成任务对视觉变换器进行预训练。困难在于图像中的信号高度冗余，因此像填补几个缺失像素这样的生成任务很难从数据中捕获高级知识。为了解决这个问题，MAE
    随机掩盖大量补丁，迫使模型超越低级理解，并根据少量可见补丁重建整个图像，从而提高其在语义级任务中的迁移性。另一个例子是，为了对图形神经网络（GNN）（Garcia
    和 Bruna，[2018](#bib.bib47)）进行可迁移表示的预训练，属性掩码（Hu 等，[2020](#bib.bib75)）隐藏节点或边属性，并要求
    GNN 根据邻近结构预测这些属性，这可以捕捉不同图结构中属性分布的规律性，如分子图中的化学规则，并提高在下游节点或边分类任务中的迁移性。
- en: Combining Autoregressive and Autoencoding Models. In MLM, some special tokens,
    such as [MASK], are only used in pre-training while absent in the downstream tasks,
    leading to the mismatch between the pre-training phase and the fine-tuning phase.
    To mitigate this discrepancy, Permuted Language Modeling (PLM) (Yang et al., [2019](#bib.bib195))
    randomly samples a permutation of the sequence and then performs autoregression
    on the permuted sequence to predict the last few tokens. To explore the limits
    of transferability of knowledge gained in different generative pre-training methods,
    T5 (Raffel et al., [2020](#bib.bib136)) unifies all text-based language tasks
    into the text-to-text format and then adopts a Sequence-to-Sequence MLM (Seq2Seq
    MLM), where the encoder processes a masked sequence and the decoder sequentially
    generates the masked tokens in an autoregression manner.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 结合自回归和自编码模型。在 MLM 中，一些特殊的标记，如[MASK]，仅在预训练中使用，而在下游任务中缺失，导致预训练阶段和微调阶段之间的不匹配。为了减轻这种差异，排列语言建模（PLM）（Yang
    等，[2019](#bib.bib195)）随机抽样序列的排列，然后对排列的序列执行自回归，以预测最后几个标记。为了探索在不同生成预训练方法中获得知识的迁移极限，T5（Raffel
    等，[2020](#bib.bib136)）将所有基于文本的语言任务统一为文本到文本格式，然后采用序列到序列 MLM（Seq2Seq MLM），其中编码器处理掩码序列，解码器以自回归方式顺序生成掩码标记。
- en: The design of unsupervised pre-training tasks has a great influence on the transferability
    to the downstream tasks, thus many efforts have been made to optimize the pre-training
    tasks and exploit better training objectives. RoBERTa (Liu et al., [2019b](#bib.bib109))
    explores the under-training issue of BERT and highlights that training with more
    data, longer sequences, and dynamically changed masking patterns helps the model
    transfer better. Besides, MLM randomly masks out some independent words, which
    are the smallest semantic units in English but may not have complete semantics
    in other languages, such as Chinese. Thus, ERNIE (Baidu) (Sun et al., [2019b](#bib.bib168))
    introduces entity-level and phrase-level masking, where multiple words that represent
    the same semantic meaning are masked. This achieves good transferability on Chinese
    NLP tasks. To improve transferability to tasks where span selection is important,
    such as question answering and coreference resolution, SpanBERT (Joshi et al.,
    [2020](#bib.bib83)) masks a random variable length of span in the text and trains
    the span boundary representations to predict the entire content of the masked
    span. BART (Lewis et al., [2020](#bib.bib98)) introduces more perturbation functions
    such as sentence permutation, document rotation, token deletion, and text infilling
    for more transferable pre-trained models.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督预训练任务的设计对下游任务的迁移性有着重大影响，因此，许多努力致力于优化预训练任务并探索更好的训练目标。RoBERTa (Liu et al.,
    [2019b](#bib.bib109)) 探讨了 BERT 的欠训练问题，并强调使用更多数据、更长序列和动态变化的掩码模式有助于模型的更好迁移。此外，MLM
    随机掩盖了一些独立的词，这些词是英语中最小的语义单元，但在其他语言（如中文）中可能没有完整的语义。因此，ERNIE (百度) (Sun et al., [2019b](#bib.bib168))
    引入了实体级别和短语级别的掩盖，其中掩盖了表示相同语义的多个词。这在中文 NLP 任务中实现了良好的迁移性。为了提高对跨度选择重要任务（如问答和共指消解）的迁移性，SpanBERT
    (Joshi et al., [2020](#bib.bib83)) 在文本中掩盖了随机长度的跨度，并训练跨度边界表示以预测被掩盖跨度的全部内容。BART
    (Lewis et al., [2020](#bib.bib98)) 引入了更多的扰动函数，如句子排列、文档旋转、标记删除和文本填充，以实现更具迁移性的预训练模型。
- en: The generative pre-training on large-scale data greatly improves the transferability
    of models and even enables *few-shot* task transfer. By scaling up the model size
    to $175$B and pre-training on the corpus over $500$GB, GPT-3 (Brown et al., [2020](#bib.bib18))
    obtains impressive transferability. Using only task demonstrations and a few examples,
    GPT-3 achieves better performance than prior state-of-the-art fine-tuning approaches
    on some tasks. The success of GPT-3 comes from the fact that the web-scale corpus
    contains a vast amount of natural language sentences, which potentially demonstrate
    different tasks without explicit task symbols. A high-capacity language model
    trained on such data would perform unsupervised multi-task learning and absorb
    transferable knowledge to handle downstream tasks. The generative pre-training
    on large-scale data also improves the transferability across domains. Multilingual
    BERT (Pires et al., [2019](#bib.bib132)) is pre-trained with MLM on Wikipedia
    texts from $104$ languages and then achieves great cross-lingual transferability
    in the downstream tasks, where each language can be considered as a domain. Further,
    XLM (Lample and Conneau, [2019](#bib.bib91)) introduces the translation language
    modeling task, which extends MLM to parallel bilingual sentence pairs, encouraging
    more transferable representations across language.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模数据上的生成预训练显著提高了模型的迁移性，甚至实现了*少样本*任务迁移。通过将模型规模扩大到 $175$B 并在 $500$GB 的语料库上进行预训练，GPT-3
    (Brown et al., [2020](#bib.bib18)) 获得了令人印象深刻的迁移性。仅使用任务演示和少量示例，GPT-3 在某些任务上比以前的最先进微调方法表现更好。GPT-3
    的成功源于网络规模的语料库包含大量自然语言句子，这些句子潜在地展示了不同的任务，而没有明确的任务符号。在这种数据上训练的高容量语言模型可以进行无监督的多任务学习，并吸收可迁移的知识以处理下游任务。大规模数据上的生成预训练也改善了跨领域的迁移性。Multilingual
    BERT (Pires et al., [2019](#bib.bib132)) 在来自 $104$ 种语言的维基百科文本上进行 MLM 预训练，然后在下游任务中实现了出色的跨语言迁移性，其中每种语言都可以被视为一个领域。此外，XLM
    (Lample 和 Conneau, [2019](#bib.bib91)) 引入了翻译语言建模任务，将 MLM 扩展到平行的双语句子对，鼓励跨语言更具迁移性的表示。
- en: 2.3.2 Contrastive Learning
  id: totrans-156
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.2 对比学习
- en: 'Contrastive learning utilizes the idea of learning to compare for unsupervised
    pre-training. As shown in Figure [10](#S2.F10 "Figure 10 ‣ 2.3.2 Contrastive Learning
    ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning:
    A Survey"), two different views, query $\mathbf{x}^{q}$ and key $\mathbf{x}^{k}$,
    are constructed from the original data $\mathbf{x}$. Encoders will map different
    views into latent representations and decoders will further map the representation
    to the metric space. The model is learned by minimizing the distance between query
    and key of the same instance. We will review three typical contrastive learning
    methods widely used in pre-training: Mutual Information Maximization (uses the
    global context and the local features as different views), Relative Position Prediction
    (uses different local components as different views), and Instance Discrimination
    (uses data augmentations to generate different views of the same instance). Different
    ways of generating and comparing different views encourage these methods to respectively
    capture the global-local relation, local-local relation and global-global relation
    of the training data.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 对比学习利用学习比较的思想进行无监督预训练。如图 [10](#S2.F10 "图 10 ‣ 2.3.2 对比学习 ‣ 2.3 无监督预训练 ‣ 2 预训练
    ‣ 深度学习中的可迁移性：综述") 所示，从原始数据 $\mathbf{x}$ 构造出两个不同的视图，即查询 $\mathbf{x}^{q}$ 和键 $\mathbf{x}^{k}$。编码器将不同的视图映射到潜在表示中，解码器进一步将表示映射到度量空间中。通过最小化同一实例的查询和键之间的距离来学习模型。我们将回顾三种在预训练中广泛使用的典型对比学习方法：互信息最大化（使用全局上下文和局部特征作为不同视图）、相对位置预测（使用不同的局部组件作为不同视图）和实例区分（使用数据增强生成同一实例的不同视图）。生成和比较不同视图的不同方式使这些方法分别捕捉训练数据的全局-局部关系、局部-局部关系和全局-全局关系。
- en: '![Refer to caption](img/5401b4143822ad8a944acaab0024de96.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5401b4143822ad8a944acaab0024de96.png)'
- en: 'Figure 10: Contrastive pre-training aims to minimize the similarity between
    the query $\mathbf{q}$ and the key $\mathbf{k}$ that are generated from different
    views of the same data input $\mathbf{x}$.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：对比预训练旨在最小化从同一数据输入 $\mathbf{x}$ 的不同视图生成的查询 $\mathbf{q}$ 和键 $\mathbf{k}$
    之间的相似度。
- en: Mutual Information Maximization.
  id: totrans-160
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 互信息最大化。
- en: Deep InfoMax (Hjelm et al., [2019](#bib.bib70)) aims to acquire transferable
    representations from the relation between the high-level global context and the
    low-level local features. Given input $\mathbf{x}$, Deep InfoMax learns an encoder
    $\psi$ to maximize the mutual information between its input and output of the
    same instance. The mutual information can be estimated and bounded by training
    a discriminator to distinguish between their joint distribution and the product
    of their marginals. Using Noise-Contrastive Estimation (NCE), the training objective
    of Deep InfoMax becomes,
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Deep InfoMax (Hjelm 等，[2019](#bib.bib70)) 旨在从高层次的全局上下文和低层次的局部特征之间的关系中获取可迁移的表示。给定输入
    $\mathbf{x}$，Deep InfoMax 学习一个编码器 $\psi$ 来最大化其输入和相同实例的输出之间的互信息。互信息可以通过训练一个鉴别器来估计和界定，该鉴别器区分它们的联合分布和边际分布的乘积。使用噪声对比估计（NCE），Deep
    InfoMax 的训练目标变为，
- en: '|  | $\max_{\psi}\mathbb{E}_{\mathbf{x}\sim\mathcal{U}}\left[D(\mathbf{x},\psi(\mathbf{x}))-\mathbb{E}_{\mathbf{x}^{\prime}\sim\widetilde{\mathcal{U}}}\Big{(}\log\sum_{\mathbf{x}^{\prime}}e^{D(\mathbf{x}^{\prime},\psi(\mathbf{x}))}\Big{)}\right],$
    |  | (7) |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '|  | $\max_{\psi}\mathbb{E}_{\mathbf{x}\sim\mathcal{U}}\left[D(\mathbf{x},\psi(\mathbf{x}))-\mathbb{E}_{\mathbf{x}^{\prime}\sim\widetilde{\mathcal{U}}}\Big{(}\log\sum_{\mathbf{x}^{\prime}}e^{D(\mathbf{x}^{\prime},\psi(\mathbf{x}))}\Big{)}\right],$
    |  | (7) |'
- en: where $\mathbf{x}$ is the input sampled from the training distribution $\mathcal{U}$
    of upstream task, $\mathbf{x}^{\prime}$ is another input sampled from $\widetilde{\mathcal{U}}=\mathcal{U}$,
    and $D$ is the discriminator to distinguish between the joint distribution and
    the product of marginals. A parallel work, Contrastive Predictive Coding (CPC) (Oord
    et al., [2019](#bib.bib124)), also maximizes the mutual information between pairs
    of global representation and local representation. Given a sequence input, CPC
    processes it with an encoder and summarizes the results into a context by an autoregression
    model. Then it maximizes the mutual information between the summarized context
    and the hidden representation of the future observation in the sequence, which
    guides the learned representations to capture information for predicting future
    samples.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathbf{x}$ 是从上游任务的训练分布 $\mathcal{U}$ 中采样的输入，$\mathbf{x}^{\prime}$ 是从 $\widetilde{\mathcal{U}}=\mathcal{U}$
    中采样的另一个输入，$D$ 是区分联合分布和边际分布乘积的判别器。一个相关的工作，对比预测编码（CPC）（Oord 等，[2019](#bib.bib124)）也最大化全球表示和局部表示之间的互信息。给定一个序列输入，CPC
    用编码器处理该输入，并通过自回归模型将结果总结成一个上下文。然后，它最大化总结的上下文与序列中未来观察的隐藏表示之间的互信息，这引导学习到的表示捕捉用于预测未来样本的信息。
- en: Mutual information maximization has been used to obtain pre-trained models on
    many data formats, such as Deep InfoMax on image data and CPC on sequence data.
    On graph data, Deep Graph Infomax (Veličković et al., [2019](#bib.bib178)) maximizes
    the mutual information between a node’s local representations and the k-hop neighborhoods’
    context representations. On multimodal data, Contrastive Language-Image Pre-training
    (CLIP) (Radford et al., [2021](#bib.bib135)) maximizes the mutual information
    between the image and the corresponding text in a multimodal embedding space.
    After training with a large-scale dataset of image-text pairs from the Internet,
    it enables the *zero-shot* transfer of the model to downstream tasks, competitive
    with the prior task-specific supervised models.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 互信息最大化已被用于获取许多数据格式上的预训练模型，例如图像数据上的 Deep InfoMax 和序列数据上的 CPC。在图形数据上，Deep Graph
    Infomax（Veličković 等，[2019](#bib.bib178)）最大化节点的局部表示与 k-hop 邻域的上下文表示之间的互信息。在多模态数据上，对比语言-图像预训练（CLIP）（Radford
    等，[2021](#bib.bib135)）最大化图像与对应文本在多模态嵌入空间中的互信息。在使用来自互联网的大规模图像-文本对数据集进行训练后，它实现了模型的*零样本*迁移，并且与之前的任务特定监督模型具有竞争力。
- en: Relative Position Prediction.
  id: totrans-165
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 相对位置预测。
- en: Next Sentence Prediction (NSP) (Devlin et al., [2019](#bib.bib39)), which is
    first introduced in BERT, acquires transferable representations from the relation
    between *local parts*. Specifically, NSP uses a binary classifier to predict whether
    two sentences are coherent from the training corpus, aiming to enhance the transferability
    to tasks with multiple sentences, such as question answering and natural language
    inference. However, subsequent work questions the necessity of NSP tasks (Yang
    et al., [2019](#bib.bib195); Liu et al., [2019c](#bib.bib110)) and Lan et al.
    ([2020](#bib.bib93)) conjecture that NSP only forces the model to learn topic
    prediction, rather than more difficult coherence prediction. Since inter-sentence
    coherence is important to many downstream tasks, ALBERT (Lan et al., [2020](#bib.bib93))
    introduces a sentence-order prediction task, where two consecutive segments from
    the same document are taken as positive examples, and the same segments with order
    swapped are taken as negative examples. Similar ideas are also explored in vision,
    where the pre-training task is to predict relative positions of two patches from
    an image (Doersch et al., [2015](#bib.bib40)).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 下一句预测（NSP）（Devlin 等，[2019](#bib.bib39)），首次引入 BERT，通过*局部部分*之间的关系获取可迁移的表示。具体而言，NSP
    使用二分类器预测训练语料库中的两个句子是否连贯，旨在增强对多句子任务的迁移能力，例如问答和自然语言推理。然而，后续工作质疑了 NSP 任务的必要性（Yang
    等，[2019](#bib.bib195)；Liu 等，[2019c](#bib.bib110)），Lan 等人（[2020](#bib.bib93)）猜测
    NSP 仅迫使模型学习主题预测，而非更难的连贯性预测。由于句间连贯性对许多下游任务至关重要，ALBERT（Lan 等，[2020](#bib.bib93)）引入了句子顺序预测任务，其中两个来自同一文档的连续段落作为正例，顺序调换的相同段落作为负例。类似的想法也在视觉领域中得到探索，其中预训练任务是预测图像中两个区域的相对位置（Doersch
    等，[2015](#bib.bib40)）。
- en: Instance Discrimination.
  id: totrans-167
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 实例区分。
- en: InstDisc (Wu et al., [2018](#bib.bib192)) aims to learn transferable representations
    from the relation between *instances*. Given $n$ instances, an encoder $\psi$
    is trained to distinguish each instance from others, i.e., minimize the distance
    between the query $\mathbf{q}$ and key $\mathbf{k}_{+}$ from the same instance
    (also called positive samples) and maximize the distance between that of different
    instances (also called negative samples),
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: InstDisc（Wu et al., [2018](#bib.bib192)）旨在通过*实例*之间的关系学习可转移的表示。给定$n$个实例，训练一个编码器$\psi$以区分每个实例，即最小化查询$\mathbf{q}$和来自同一实例的键$\mathbf{k}_{+}$（也称为正样本）之间的距离，并最大化不同实例（也称为负样本）之间的距离，
- en: '|  | $\min_{\psi}-\log\frac{\text{exp}(\mathbf{q}\cdot\mathbf{k}_{+}/\tau)}{\sum_{j=0}^{K}\text{exp}(\mathbf{q}\cdot\mathbf{k}_{j}/\tau)},$
    |  | (8) |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{\psi}-\log\frac{\text{exp}(\mathbf{q}\cdot\mathbf{k}_{+}/\tau)}{\sum_{j=0}^{K}\text{exp}(\mathbf{q}\cdot\mathbf{k}_{j}/\tau)},$
    |  | (8) |'
- en: where $\tau$ is a temperature hyper-parameter and the sum is over one positive
    and $K$ negative samples. Note that the computation of the features of all samples
    and the non-parametric softmax is costly especially when the number of training
    instances $n$ is extremely large. To tackle this issue, negative sampling is used
    to approximate the softmax, i.e., $K<n$.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\tau$是一个温度超参数，求和是在一个正样本和$K$个负样本上进行的。请注意，所有样本特征的计算和非参数softmax计算代价较高，尤其是当训练实例数$n$极大时。为解决这一问题，使用负采样来近似softmax，即$K<n$。
- en: 'The discriminability of representations to contrast one instance from another
    instance is closely related to the transferability on downstream tasks. Thus,
    many efforts have been made to increase the number and improve the quality of
    keys. As shown in Figure [11](#S2.F11 "Figure 11 ‣ Instance Discrimination. ‣
    2.3.2 Contrastive Learning ‣ 2.3 Unsupervised Pre-Training ‣ 2 Pre-Training ‣
    Transferability in Deep Learning: A Survey"), InstDisc (Wu et al., [2018](#bib.bib192))
    uses a memory bank to store the latest updated representations for each key, which
    increases the number of negative samples, yet may result in less consistent representations.
    Momentum Contrast (MoCo) (He et al., [2020](#bib.bib67)) maintains a dynamic queue
    of encoded features to enlarge the size of negative samples and encodes the keys
    with a momentum-updated encoder, which increases encoding consistency between
    different samples in the queue and improves the quality of keys. The way how the
    positive samples and negative samples are constructed is also important for transferability.
    Contrastive Multiview Coding (CMC) (Tian et al., [2020](#bib.bib171)) takes multiple
    views, rather than multiple augmentations, of the same instance as positive samples
    and achieves better transferability. SimCLR (Chen et al., [2020](#bib.bib23))
    emphasizes that data augmentations play a crucial role in implicitly defining
    different pretext tasks, and the composition of stronger augmentations leads to
    better transferability even without the need for a memory bank or a queue. The
    introduction of negative samples is to avoid trivial solutions that all outputs
    collapse to a constant. However, BYOL (Grill et al., [2020](#bib.bib59)) finds
    that when maximizing the similarity between two augmentations of one image, negative
    sample pairs are not necessary. Further, SimSiam (Chen and He, [2021](#bib.bib25))
    finds that momentum encoder is also not necessary while a stop-gradient operation
    applied on one side is enough for learning transferable representations.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '表示对比一个实例与另一个实例的可区分性与下游任务中的可转移性密切相关。因此，许多工作致力于增加键的数量和提高其质量。如图[11](#S2.F11 "Figure
    11 ‣ Instance Discrimination. ‣ 2.3.2 Contrastive Learning ‣ 2.3 Unsupervised
    Pre-Training ‣ 2 Pre-Training ‣ Transferability in Deep Learning: A Survey")所示，InstDisc（Wu
    et al., [2018](#bib.bib192)）使用内存库存储每个键的最新更新表示，这增加了负样本的数量，但可能导致表示的一致性降低。Momentum
    Contrast（MoCo）（He et al., [2020](#bib.bib67)）维持一个动态的编码特征队列，以扩大负样本的数量，并使用动量更新的编码器对键进行编码，这增加了队列中不同样本之间的编码一致性，提高了键的质量。正样本和负样本的构建方式对于转移性也很重要。Contrastive
    Multiview Coding（CMC）（Tian et al., [2020](#bib.bib171)）将同一实例的多个视角（而非多个增强）作为正样本，从而实现更好的转移性。SimCLR（Chen
    et al., [2020](#bib.bib23)）强调数据增强在隐式定义不同前任务中发挥了关键作用，强大的增强组合即使在没有内存库或队列的情况下也能实现更好的转移性。引入负样本是为了避免所有输出收敛为一个常数的平凡解。然而，BYOL（Grill
    et al., [2020](#bib.bib59)）发现，当最大化图像的两个增强之间的相似性时，负样本对并非必要。此外，SimSiam（Chen and
    He, [2021](#bib.bib25)）发现动量编码器也不是必要的，而在一侧应用的停止梯度操作足以学习可转移的表示。'
- en: '![Refer to caption](img/65674a98b60ff0d7df2aa039730907ee.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/65674a98b60ff0d7df2aa039730907ee.png)'
- en: 'Figure 11: Comparison of different contrastive learning mechanisms. (a) InstDisc
    samples the keys from a memory bank. (b) MoCo encodes the new keys on the fly
    by a momentum encoder and maintains a queue of keys. (c) SimCLR encodes the keys
    and queries in the same batch with the same encoder and adds a nonlinear predictor
    to improve the representation. (d) SimSiam applies an MLP predictor on one side
    and applies a stop-gradient operation on the other side, and maximizes the similarity
    in two views without using negative pairs.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：不同对比学习机制的比较。 (a) InstDisc 从记忆库中抽取键。 (b) MoCo 通过动量编码器实时编码新键，并维护一个键的队列。 (c)
    SimCLR 使用相同的编码器在同一批次中编码键和查询，并添加一个非线性预测器以改进表示。 (d) SimSiam 在一侧应用 MLP 预测器，在另一侧应用停止梯度操作，并在不使用负对的情况下最大化两个视图之间的相似性。
- en: Compared with supervised pre-training, contrastive pre-training leads to competitive
    performance on downstream classification tasks and even better performance on
    various other downstream tasks, such as object detection and semantic segmentation.
    To explain the stronger transferability of contrastive pre-training,  Zhao et al.
    ([2021](#bib.bib206)) observe that standard supervised pre-training usually transfers
    high-level semantic knowledge, while contrastive pre-training usually transfers
    low-level and mid-level representations. When the target tasks are different from
    the supervised pre-trained tasks, the supervised pre-training methods have the
    risk of over-fitting the semantic discriminative parts of objects defined by the
    class labels, which hurts the transferability. On the contrary, the contrastive
    pre-training tasks lead to more holistic modeling of the objects, which relaxes
    the task misalignment issue and achieves better transferability for widespread
    downstream tasks.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 与监督式预训练相比，对比式预训练在下游分类任务上表现出竞争力，甚至在物体检测和语义分割等其他各种下游任务上表现更好。为了解释对比式预训练更强的迁移能力，赵等人（[2021](#bib.bib206)）观察到，标准监督式预训练通常转移高级语义知识，而对比式预训练通常转移低级和中级表示。当目标任务与监督式预训练任务不同时，监督式预训练方法有过拟合由类别标签定义的物体语义特征的风险，这会损害迁移能力。相反，对比式预训练任务导致对物体的更全面建模，缓解了任务错位问题，并为广泛的下游任务实现了更好的迁移能力。
- en: 2.4 Remarks
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 备注
- en: While standard supervised pre-training is well established, its transferability
    also depends on the relationship between the pre-training task and the target
    task, and no pre-training task can dominate all downstream tasks. He et al. ([2019](#bib.bib66))
    show that compared with the random initialization, supervised pre-training on
    ImageNet only speeds up the convergence of object detection on the COCO dataset,
    but does not lead to better final accuracy. Raghu et al. ([2019](#bib.bib138))
    observe similar phenomena in medical imaging, where training lightweight models
    from scratch perform comparably with transferring from ImageNet pre-trained models.
    Abnar et al. ([2022](#bib.bib1)) explore the limits of large-scale supervised
    pre-training and find that as the pre-training accuracy increases by scaling up
    data, model size and training time, the performance of downstream tasks gradually
    saturates and there are even some extreme scenarios where performance on pre-training
    and downstream tasks are at odds with each other. These controversial results
    encourage us to *rethink* the common practice of supervised pre-training and design
    new supervised pre-training strategies for specific fields, especially when large
    gaps exist between the pre-training and target tasks.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然标准监督式预训练已相当成熟，但其迁移能力也依赖于预训练任务与目标任务之间的关系，没有任何预训练任务可以主导所有下游任务。他等人（[2019](#bib.bib66)）显示，与随机初始化相比，在ImageNet上的监督式预训练仅加快了COCO数据集上物体检测的收敛速度，但没有带来更好的最终准确性。Raghu等人（[2019](#bib.bib138)）在医学影像中观察到类似现象，从头训练轻量级模型与从ImageNet预训练模型迁移的表现相当。Abnar等人（[2022](#bib.bib1)）探索了大规模监督式预训练的限制，并发现随着数据、模型规模和训练时间的增加，预训练准确性提高，下游任务的性能逐渐饱和，甚至存在一些极端情况下预训练任务和下游任务的性能相互矛盾。这些有争议的结果促使我们*重新思考*监督式预训练的常见做法，并为特定领域设计新的监督式预训练策略，特别是在预训练任务与目标任务之间存在较大差距时。
- en: 'Table 2: Comparison between different pre-training methods.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：不同预训练方法的比较。
- en: '| Method | Modality Scalability¹ | Task Scalability² | Data Efficiency³ | Labeling
    Cost⁴ |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 模态扩展性¹ | 任务可扩展性² | 数据效率³ | 标注成本⁴ |'
- en: '| Standard Pre-Training | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$ |
    $\bigstar\bigstar\bigstar$ | $\bigstar$ |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 标准预训练 | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar$ |'
- en: '| Meta-Learning | $\bigstar\bigstar\bigstar$ | $\bigstar$ | $\bigstar$ | $\bigstar$
    |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 元学习 | $\bigstar\bigstar\bigstar$ | $\bigstar$ | $\bigstar$ | $\bigstar$ |'
- en: '| Causal Learning | $\bigstar\bigstar$ | $\bigstar$ | $\bigstar$ | $\bigstar$
    |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 因果学习 | $\bigstar\bigstar$ | $\bigstar$ | $\bigstar$ | $\bigstar$ |'
- en: '| Generative Learning | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 生成学习 | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ |'
- en: '| Contrastive Learning | $\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 对比学习 | $\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ |'
- en: '1'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1'
- en: 'Modality Scalability: whether models can be pre-trained on various modalities,
    such as text, graph.'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模态扩展性：模型是否可以在各种模态上进行预训练，如文本、图形。
- en: '2'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2'
- en: 'Task Scalability: whether pre-trained models can be easily transferred to different
    downstream tasks.'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任务可扩展性：预训练模型是否可以轻松转移到不同的下游任务。
- en: '3'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '3'
- en: 'Data Efficiency: whether stronger transferability can be yielded from large-scale
    pre-training.'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据效率：是否可以通过大规模预训练获得更强的迁移性。
- en: '4'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '4'
- en: 'Labeling Cost: whether relies on manual data labeling.'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 标注成本：是否依赖人工数据标注。
- en: 'Table [2](#S2.T2 "Table 2 ‣ 2.4 Remarks ‣ 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey") compares pre-training methods from four perspectives:
    modality scalability, task scalability, data efficiency, and labeling cost. Though
    meta-learning enables fast adaptation to new tasks, it mainly considers related
    tasks such as reinforcement learning under environments with small changing factors,
    while standard pre-training can transfer to broader task gaps such as from image
    classification to object detection. Besides, the existing meta-learning and causal
    learning methods are empirically verified only on small datasets, and it remains
    unclear whether they can acquire stronger transferability via pre-training on
    large-scale data. Despite the promising performance without manual labeling, unsupervised
    pre-trained models require a large number of gradient steps for fine-tuning to
    downstream tasks. Also, strong data augmentations are required by contrastive
    learning to gain transferability, but they are not easy to design in other modalities,
    such as text and graphs. Finally, the design of unsupervised pre-training tasks
    remains heuristic, lacking solid analysis on how the task shift is bridged and
    what enables the transferability of these models.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 表[2](#S2.T2 "表 2 ‣ 2.4 备注 ‣ 2 预训练 ‣ 深度学习中的迁移性：综述")从四个角度比较了预训练方法：模态扩展性、任务可扩展性、数据效率和标注成本。尽管元学习能够快速适应新任务，但它主要考虑与之相关的任务，如在小变化因素环境下的强化学习，而标准预训练则可以转移到更广泛的任务差距，例如从图像分类到目标检测。此外，现有的元学习和因果学习方法仅在小数据集上进行实证验证，目前尚不清楚它们是否能够通过在大规模数据上进行预训练来获得更强的迁移性。尽管没有人工标注的前景看好，无监督预训练模型在对下游任务进行微调时需要大量的梯度步骤。此外，对比学习需要强大的数据增强来获得迁移性，但在其他模态（如文本和图形）中设计这些增强并不容易。最后，无监督预训练任务的设计仍然是启发式的，缺乏对任务转移如何实现以及这些模型迁移性的有效分析。
- en: Acquiring transferability only through the pre-training stage may limit our
    horizon. As the shift in tasks and domains naturally exists between the pre-training
    and adaptation stages, many pre-training methods are tailored to adaptation. Unsupervised
    pre-training aims to improve the transferability to downstream tasks by exploring
    different kinds of self-supervised tasks to reduce the task discrepancy between
    pre-training and adaptation, or by enlarging the size and diversity of the upstream
    data to reduce the upstream-downstream discrepancy. The distribution shift commonly
    tackled by domain adaptation (Ganin and Lempitsky, [2015](#bib.bib45)) also influences
    the transferability of the pre-trained model. For instance, the data distribution
    in a specific domain, such as biological and scientific literature, is quite different
    from that in the general pre-training domain and may degrade transferability,
    thus BioBert (Lee et al., [2020b](#bib.bib97)) and SciBERT (Beltagy et al., [2019](#bib.bib7))
    perform pre-training on domain-specific data to improve the transferability on
    domain-specific tasks.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 仅通过预训练阶段获得的迁移能力可能会限制我们的视野。由于在预训练阶段和适应阶段之间自然存在任务和领域的变化，许多预训练方法都专门针对适应性进行调整。无监督预训练的目标是通过探索不同种类的自监督任务来减少预训练和适应之间的任务差异，或者通过扩大上游数据的规模和多样性来减少上游-下游的差异，从而提高对下游任务的迁移能力。领域适应（Ganin
    和 Lempitsky, [2015](#bib.bib45)）常常解决的分布转移问题也会影响预训练模型的迁移能力。例如，特定领域的数据分布，如生物和科学文献，与一般的预训练领域有很大不同，这可能会降低迁移能力，因此
    BioBert（Lee 等, [2020b](#bib.bib97)）和 SciBERT（Beltagy 等, [2019](#bib.bib7)）在领域特定的数据上进行预训练，以提高在领域特定任务上的迁移能力。
- en: 3 Adaptation
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 适应性
- en: 'While pre-training on large-scale datasets can gain transferable knowledge
    in deep models, performing task adaptation with the target data is still necessary
    for most applications, as the target task is usually different from the pre-training
    task. When the labeled data for the target task is not enough, domain adaptation
    from a related source domain with labeled data to boost the performance on the
    target domain is also necessary in many applications. We will review task adaptation
    and domain adaptation in Sections [3.1](#S3.SS1 "3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey") and [3.2](#S3.SS2 "3.2 Domain Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey") respectively.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在大规模数据集上进行预训练可以在深度模型中获得可迁移的知识，但对于大多数应用而言，仍然需要使用目标数据进行任务适应，因为目标任务通常与预训练任务不同。当目标任务的标记数据不足时，从具有标记数据的相关源领域进行领域适应，以提升目标领域的表现也是许多应用中必要的。我们将在第
    [3.1](#S3.SS1 "3.1 任务适应 ‣ 3 适应性 ‣ 深度学习中的迁移能力：综述") 和第 [3.2](#S3.SS2 "3.2 领域适应 ‣
    3 适应性 ‣ 深度学习中的迁移能力：综述") 节中分别回顾任务适应和领域适应。
- en: 3.1 Task Adaptation
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 任务适应
- en: 'In task adaptation, there exist a pre-trained model $h_{\theta^{0}}$ and a
    target domain $\widehat{\mathcal{T}}=\{\mathbf{x}_{i},\textbf{y}_{i}\}_{i=1}^{m}$
    of $m$ labeled samples. The goal is to find a hypothesis $h_{\theta}:\mathcal{X}\mapsto\mathcal{Y}$
    in the space $\mathcal{H}$ using the pre-trained model and target data to achieve
    a low generalization risk $\epsilon_{\mathcal{T}}(h_{\theta})$. In general, there
    are two simple ways to *adapt* a pre-trained model to the downstream tasks: feature
    transfer and fine-tuning. Feature transfer freezes the weights of the pre-trained
    models and trains a linear classifier on top of that. In contrast, fine-tuning
    uses the pre-trained models to initialize the target model parameters and update
    these parameters during training. Feature transfer is fast in training and efficient
    in parameter storage, yet fine-tuning yields better performance (Yosinski et al.,
    [2014](#bib.bib197)), and has become a common practice for task adaptation in
    both vision and NLP (Girshick et al., [2014](#bib.bib50); Devlin et al., [2019](#bib.bib39)).'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在任务适应中，存在一个预训练模型 $h_{\theta^{0}}$ 和一个目标领域 $\widehat{\mathcal{T}}=\{\mathbf{x}_{i},\textbf{y}_{i}\}_{i=1}^{m}$，其中包含
    $m$ 个标记样本。目标是使用预训练模型和目标数据在空间 $\mathcal{H}$ 中找到一个假设 $h_{\theta}:\mathcal{X}\mapsto\mathcal{Y}$，以实现低的泛化风险
    $\epsilon_{\mathcal{T}}(h_{\theta})$。一般来说，有两种简单的方法可以将预训练模型 *适应* 到下游任务：特征迁移和微调。特征迁移冻结预训练模型的权重，并在其上训练一个线性分类器。相比之下，微调使用预训练模型初始化目标模型参数，并在训练过程中更新这些参数。特征迁移在训练中速度较快且参数存储高效，但微调表现更佳（Yosinski
    等, [2014](#bib.bib197)），已成为视觉和自然语言处理（Girshick 等, [2014](#bib.bib50); Devlin 等,
    [2019](#bib.bib39)）任务适应的常见做法。
- en: '![Refer to caption](img/1ea880a2ddd9c61b25424b533e6db763.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/1ea880a2ddd9c61b25424b533e6db763.png)'
- en: 'Figure 12: Cornerstones of task adaptation methods for *applying* transferable
    knowledge.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：用于*应用*可迁移知识的任务适应方法的基石。
- en: 'Vanilla fine-tuning, which tunes the pre-trained models by empirical risk minimization
    on the target data, has been widely used in various downstream tasks and scenarios.
    However, vanilla fine-tuning still suffers from several issues, including catastrophic
    forgetting and negative transfer. We will introduce how to alleviate these issues
    in Sections [3.1.1](#S3.SS1.SSS1 "3.1.1 Catastrophic Forgetting ‣ 3.1 Task Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey") and [3.1.2](#S3.SS1.SSS2
    "3.1.2 Negative Transfer ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey"). Besides, as the parameters of deep models keep increasing
    and some of them reach billions or trillions, parameter efficiency and data efficiency
    have become increasingly important in task adaptation. We will give an introduction
    on how to explore the transferability in the pre-trained models to solve these
    problems in Sections [3.1.3](#S3.SS1.SSS3 "3.1.3 Parameter Efficiency ‣ 3.1 Task
    Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey") and [3.1.4](#S3.SS1.SSS4
    "3.1.4 Data Efficiency ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey"). Overall, Figure [12](#S3.F12 "Figure 12 ‣ 3.1 Task
    Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey") shows
    the progress made by the task adaptation algorithms to solve different problems.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '传统的微调，通过在目标数据上进行经验风险最小化来调整预训练模型，已广泛应用于各种下游任务和场景。然而，传统微调仍然存在几个问题，包括灾难性遗忘和负迁移。我们将在[3.1.1](#S3.SS1.SSS1
    "3.1.1 Catastrophic Forgetting ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")和[3.1.2](#S3.SS1.SSS2 "3.1.2 Negative Transfer ‣ 3.1
    Task Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")部分介绍如何缓解这些问题。此外，随着深度模型参数的不断增加，有些达到了数十亿甚至数万亿，参数效率和数据效率在任务适应中变得越来越重要。我们将在[3.1.3](#S3.SS1.SSS3
    "3.1.3 Parameter Efficiency ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")和[3.1.4](#S3.SS1.SSS4 "3.1.4 Data Efficiency ‣ 3.1
    Task Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")部分介绍如何探索预训练模型的迁移能力来解决这些问题。总体而言，图[12](#S3.F12
    "Figure 12 ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey")展示了任务适应算法在解决不同问题上的进展。'
- en: 3.1.1 Catastrophic Forgetting
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 灾难性遗忘
- en: Catastrophic forgetting, which was first studied in lifelong learning, refers
    to the tendency of neural networks to lose knowledge acquired from previous tasks
    when learning new tasks (Kirkpatrick et al., [2017](#bib.bib86)). In the fine-tuning
    scenario where labeled data is usually scarce, it will lead to the overfitting
    of models on the target data. This phenomenon is also called representational
    collapse, i.e., the degradation of generalizable representations during the fine-tuning
    stages (Aghajanyan et al., [2021](#bib.bib2)). The most simple way to avoid catastrophic
    forgetting might be selecting a small learning rate and adopting an early-stopping
    strategy, which avoids updating the parameters too much. However, this strategy
    may lead the model to falling into the local minimal, especially when there is
    a large gap between the pre-training parameters and the optimal parameters for
    the downstream task.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 灾难性遗忘，最早在终身学习中被研究，指的是神经网络在学习新任务时倾向于丧失从之前任务中获得的知识（Kirkpatrick et al., [2017](#bib.bib86)）。在标记数据通常稀缺的微调场景中，这会导致模型在目标数据上的过拟合。这一现象也被称为表征崩溃，即在微调阶段的可泛化表征的退化（Aghajanyan
    et al., [2021](#bib.bib2)）。避免灾难性遗忘的最简单方法可能是选择较小的学习率和采用早停策略，这样可以避免过多更新参数。然而，这种策略可能导致模型陷入局部最小值，特别是在预训练参数与下游任务的最佳参数之间存在较大差距时。
- en: Yosinski et al. ([2014](#bib.bib197)) find that the transferability of different
    layers is not the same — the first layers learn general features, the middle layers
    learn semantic features and the last layers learn task-specific features. Thus,
    to make the model retain the knowledge acquired in the pre-training task and fit
    the target task well at the same time, different layers should not be treated
    the same. Specifically, the first layers should retain more pre-trained knowledge
    while the last layers should adapt more to the downstream tasks. Inspired by this
    finding, DAN (Long et al., [2015](#bib.bib112)) sets the learning rate of the
    task-specific head to be $10$ times larger than that of the lower layers, which
    is simple yet effective when the labeled data is scarce or the target domain is
    close with the pre-training domain. ULMFiT (Howard and Ruder, [2018](#bib.bib74))
    gradually unfreezes the model starting from the last layers to the first layers,
    which effectively retains general knowledge in the first layers. To automatically
    determine which layers should be fine-tuned or frozen for each sample, Spottune
    (Guo et al., [2019](#bib.bib62)) proposes a policy network that is deployed to
    output the routing decision based on the input of each sample and is jointly trained
    with the main model during fine-tuning.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Yosinski 等人 ([2014](#bib.bib197)) 发现不同层的迁移性并不相同——第一层学习通用特征，中间层学习语义特征，而最后一层学习任务特定的特征。因此，为了使模型既能保留在预训练任务中获得的知识，又能很好地适应目标任务，不同的层不应被同等对待。具体来说，第一层应该保留更多的预训练知识，而最后一层则应该更多地适应下游任务。受此发现启发，DAN
    (Long et al., [2015](#bib.bib112)) 将任务特定头的学习率设置为低层的$10$倍，这在标记数据稀缺或目标领域与预训练领域接近时效果简单而有效。ULMFiT
    (Howard 和 Ruder, [2018](#bib.bib74)) 从最后一层逐渐解冻模型，直到第一层，这有效地保留了第一层的通用知识。为了自动确定每个样本应微调或冻结哪些层，Spottune
    (Guo et al., [2019](#bib.bib62)) 提出了一个策略网络，该网络基于每个样本的输入输出路由决策，并在微调过程中与主模型共同训练。
- en: 'Domain Adaptive Tuning reveals that an important source of catastrophic forgetting
    is the dataset shift between the pre-training and the target domain. To bridge
    such shift, ULMFiT (Howard and Ruder, [2018](#bib.bib74)) and DAPT (Gururangan
    et al., [2020](#bib.bib63)) first tune the pre-trained model on data related to
    the target domain, or simply data of the target task, with the pre-training task.
    Then they fine-tune the adaptive-tuned model on the target task (Figure [13](#S3.F13
    "Figure 13 ‣ 3.1.1 Catastrophic Forgetting ‣ 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")). Usually, the pre-training task
    is unsupervised, thus further pre-training with in-domain data can provide rich
    information about the target data distribution for better task adaptation with
    no additional labeling costs. The two stages, domain adaptive tuning and regular
    fine-tuning, in the above methods can also be done jointly via multi-task learning.
    SiATL (Chronopoulou et al., [2019](#bib.bib32)) adds an auxiliary language model
    loss to the task-specific optimization function, which alleviates catastrophic
    forgetting and learns task-specific features at the same time.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 域自适应微调揭示了一个重要的灾难性遗忘来源是预训练和目标领域之间的数据集转移。为了弥合这种转移，ULMFiT (Howard 和 Ruder, [2018](#bib.bib74))
    和 DAPT (Gururangan et al., [2020](#bib.bib63)) 首先在与目标领域相关的数据，或简单的目标任务数据上调整预训练模型。然后，他们在目标任务上微调自适应调整的模型（图
    [13](#S3.F13 "图 13 ‣ 3.1.1 灾难性遗忘 ‣ 3.1 任务适应 ‣ 3 适应 ‣ 深度学习中的迁移性：综述")）。通常，预训练任务是无监督的，因此使用领域内数据进行进一步预训练可以提供关于目标数据分布的丰富信息，从而更好地适应任务，而无需额外的标记成本。上述方法中的两个阶段，领域自适应微调和常规微调，也可以通过多任务学习联合完成。SiATL
    (Chronopoulou et al., [2019](#bib.bib32)) 在任务特定优化函数中添加了一个辅助语言模型损失，这既缓解了灾难性遗忘，又同时学习了任务特定特征。
- en: '![Refer to caption](img/46d555c188591d06a93ede911a305797.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/46d555c188591d06a93ede911a305797.png)'
- en: 'Figure 13: Domain Adaptive Tuning often consists of two consecutive steps:
    first, adaptive-tune on an auxiliary domain $\mathcal{T}^{\prime}$ that is related
    to the target domain using the pre-training task; second, fine-tune on the target
    domain $\mathcal{T}$ using the target learning task.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13：领域自适应微调通常包括两个连续步骤：首先，在与目标领域相关的辅助领域 $\mathcal{T}^{\prime}$ 上使用预训练任务进行自适应微调；其次，在目标领域
    $\mathcal{T}$ 上使用目标学习任务进行微调。
- en: Regularization Tuning is another way to prevent the models from deviating far
    away from the pretrained ones. The optimization objective with a general regularization
    is
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化调整是另一种防止模型偏离预训练模型的方法。具有一般正则化的优化目标是
- en: '|  | $\min_{\theta}\sum_{i=1}^{m}L(h_{\theta}(\mathbf{x}_{i}),\mathbf{y}_{i})+\lambda\cdot\Omega({\theta}),$
    |  | (9) |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{\theta}\sum_{i=1}^{m}L(h_{\theta}(\mathbf{x}_{i}),\mathbf{y}_{i})+\lambda\cdot\Omega({\theta}),$
    |  | (9) |'
- en: 'where $L$ is the loss function, $\Omega$ is a general form of regularization,
    and $\lambda$ is the trade-off between them. A typical regularization in supervised
    learning is $L_{2}$ penalty, $\Omega(\theta)=\frac{1}{2}||\theta||_{2}^{2}$, which
    drives the weights $\theta$ to zero to control the model complexity. Different
    from typical supervised learning, in fine-tuning, there exists a pre-trained model
    $h_{\theta^{0}}$ setting a reference that can be used to define the hypothesis
    space (Figure [4](#S2.F4 "Figure 4 ‣ 2.1 Pre-Training Model ‣ 2 Pre-Training ‣
    Transferability in Deep Learning: A Survey")). Thus, Elastic Weight Consolidation
    (EWC) (Kirkpatrick et al., [2017](#bib.bib86)) constrains the distance between
    the weights of the pre-trained and fine-tuned networks (Figure [14](#S3.F14 "Figure
    14 ‣ 3.1.1 Catastrophic Forgetting ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")) to overcome catastrophic forgetting,'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $L$ 是损失函数，$\Omega$ 是正则化的一般形式，$\lambda$ 是它们之间的折衷。监督学习中的典型正则化是 $L_{2}$ 惩罚，$\Omega(\theta)=\frac{1}{2}||\theta||_{2}^{2}$，它将权重
    $\theta$ 推向零，以控制模型复杂度。不同于典型的监督学习，在微调中，存在一个预训练模型 $h_{\theta^{0}}$ 作为参考，可以用来定义假设空间
    (图 [4](#S2.F4 "Figure 4 ‣ 2.1 Pre-Training Model ‣ 2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey"))。因此，弹性权重整合 (EWC) (Kirkpatrick 等, [2017](#bib.bib86))
    约束预训练和微调网络之间权重的距离 (图 [14](#S3.F14 "Figure 14 ‣ 3.1.1 Catastrophic Forgetting ‣
    3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"))
    以克服灾难性遗忘，'
- en: '|  | $\Omega(\theta)=\sum_{j}\frac{1}{2}F_{j}\left\&#124;\theta_{j}-\theta^{0}_{j}\right\&#124;_{2}^{2},$
    |  | (10) |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '|  | $\Omega(\theta)=\sum_{j}\frac{1}{2}F_{j}\left\&#124;\theta_{j}-\theta^{0}_{j}\right\&#124;_{2}^{2},$
    |  | (10) |'
- en: 'where $F$ is the estimated Fisher information matrix. EWC is based on the assumption
    that the networks with similar weights should produce similar outputs. However,
    due to the complex structures of deep networks, similar parameters do not necessarily
    produce the same output, and the same output may also come from completely different
    model parameters. Thus, DELTA (Li et al., [2019](#bib.bib101)) constraints the
    behavior, i.e., the feature maps of the model by selecting the discriminative
    features with a supervised attention mechanism and regularizing the distance of
    these features between pre-trained and fine-tuned networks. Learning Without Forgetting
    (LWF) (Li and Hoiem, [2018](#bib.bib103)) constrains the output prediction of
    the model by encouraging the model’s response for old tasks to keep the same throughout
    the fine-tuning process (Figure [14](#S3.F14 "Figure 14 ‣ 3.1.1 Catastrophic Forgetting
    ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")).
    Regularization on the output often performs better than regularization on the
    parameters or the features, yet the latter two have better scalability and versatility
    to more complex downstream tasks.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $F$ 是估计的费舍尔信息矩阵。EWC 基于这样的假设：具有相似权重的网络应该产生相似的输出。然而，由于深度网络的复杂结构，相似的参数不一定会产生相同的输出，相同的输出也可能来自完全不同的模型参数。因此，DELTA
    (Li 等, [2019](#bib.bib101)) 通过选择具有监督注意机制的区分特征并正则化这些特征在预训练和微调网络之间的距离来约束模型的行为，即特征图。学习无遗忘
    (LWF) (Li 和 Hoiem, [2018](#bib.bib103)) 通过鼓励模型对旧任务的响应在整个微调过程中保持一致来约束模型的输出预测 (图
    [14](#S3.F14 "Figure 14 ‣ 3.1.1 Catastrophic Forgetting ‣ 3.1 Task Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"))。对输出的正则化通常比对参数或特征的正则化效果更好，但后两者在更复杂的下游任务中具有更好的可扩展性和多样性。'
- en: '![Refer to caption](img/d086645060ddc45fe783b868bea47fc4.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d086645060ddc45fe783b868bea47fc4.png)'
- en: 'Figure 14: Regularization methods for task adaptation that avoids catastrophic
    forgetting. Blue: pre-trained parameters; Red: fine-tuned parameters. (a) EWC
    regularizes the parameters of the new models $\theta$ and that of the pre-trained
    models $\theta_{0}$ with weighted $L_{2}$-penalty. (b) DELTA regularizes the feature
    maps of the new models $\mathbf{z}$ and that of the pre-trained models $\mathbf{z}_{0}$.
    (c) LWF enforces the output of the old tasks $\widehat{\mathbf{y}}_{0}$ close
    to the initial response $\mathbf{y}_{0}$.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14：用于任务适应的正则化方法，避免灾难性遗忘。蓝色：预训练参数；红色：微调参数。 (a) EWC 用加权 $L_{2}$-惩罚对新模型的参数 $\theta$
    和预训练模型的参数 $\theta_{0}$ 进行正则化。 (b) DELTA 对新模型的特征图 $\mathbf{z}$ 和预训练模型的特征图 $\mathbf{z}_{0}$
    进行正则化。 (c) LWF 强制旧任务的输出 $\widehat{\mathbf{y}}_{0}$ 接近初始响应 $\mathbf{y}_{0}$。
- en: An explanation for the effect of regularization is that it makes the hypothesis
    smoother. Therefore, TRADES (Zhang et al., [2019a](#bib.bib202)) and SMART (Jiang
    et al., [2020](#bib.bib79)) directly enforce the smoothness of the hypothesis
    by encouraging the output of the model to not change much when injecting a small
    perturbation to the input,
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化效果的一个解释是它使得假设更加平滑。因此，TRADES（Zhang et al., [2019a](#bib.bib202)）和SMART（Jiang
    et al., [2020](#bib.bib79)）通过鼓励模型输出在对输入施加小扰动时变化不大，直接强制假设的平滑性。
- en: '|  | $\Omega(\theta)=\sum_{i=1}^{m}\max_{&#124;&#124;{\widetilde{\mathbf{x}}_{i}}-\mathbf{x}_{i}&#124;&#124;_{p}\leq\epsilon}L_{s}(h_{\theta}({\widetilde{\mathbf{x}}_{i}}),h_{\theta}(\mathbf{x}_{i})),$
    |  | (11) |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|  | $\Omega(\theta)=\sum_{i=1}^{m}\max_{&#124;&#124;{\widetilde{\mathbf{x}}_{i}}-\mathbf{x}_{i}&#124;&#124;_{p}\leq\epsilon}L_{s}(h_{\theta}({\widetilde{\mathbf{x}}_{i}}),h_{\theta}(\mathbf{x}_{i})),$
    |  | (11) |'
- en: where $\epsilon>0$ is a small positive, $L_{s}$ is the distance between two
    predictions, such as the symmetrized KL-divergence in classification and the squared
    loss in regression.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\epsilon>0$ 是一个小的正数，$L_{s}$ 是两个预测之间的距离，例如分类中的对称KL散度和回归中的平方损失。
- en: Apart from the training objective, an alternative regularization approach is
    through the parameter updating strategy. Stochastic Normalization (Kou et al.,
    [2020](#bib.bib89)) randomly replaces the target statistics in the batch-normalization
    layer (Ioffe and Szegedy, [2015](#bib.bib77)) with their pre-trained statistics,
    which serves as an implicit regularization by avoiding over-depending on the target
    statistics. Mixout (Lee et al., [2020a](#bib.bib96)) randomly replaces part of
    the model parameters with their pre-trained weights during fine-tuning to mitigate
    catastrophic forgetting. Child-Tuning (Xu et al., [2021](#bib.bib193)) selects
    a subset of parameters (child network) by some criterion and only updates them
    during fine-tuning. In some senses, the above methods decrease the hypothesis
    space to preserve the transferability in pre-trained models.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 除了训练目标之外，另一种正则化方法是通过参数更新策略。随机归一化（Kou et al., [2020](#bib.bib89)）随机用预训练统计量替代批量归一化层中的目标统计量（Ioffe
    和 Szegedy, [2015](#bib.bib77)），这通过避免过度依赖目标统计量来实现隐式正则化。Mixout（Lee et al., [2020a](#bib.bib96)）在微调过程中随机用预训练权重替换模型参数的一部分，以减轻灾难性遗忘。Child-Tuning（Xu
    et al., [2021](#bib.bib193)）通过某些标准选择一部分参数（子网络），并在微调过程中只更新这些参数。在某些方面，以上方法通过减少假设空间来保持预训练模型的迁移能力。
- en: 3.1.2 Negative Transfer
  id: totrans-218
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 负迁移
- en: Although the paradigm of pre-training and fine-tuning has been used in various
    downstream tasks, it does not necessarily produce a positive effect, which is
    known as negative transfer (Rosenstein, [2005](#bib.bib142)). Wang et al. ([2019d](#bib.bib187))
    propose to quantitatively measure the degree of negative transfer across different
    domains and we extend this idea to the paradigm of pre-training and fine-tuning.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管预训练和微调的范式已被用于各种下游任务，但它并不一定产生积极的效果，这被称为负迁移（Rosenstein, [2005](#bib.bib142)）。Wang
    et al. ([2019d](#bib.bib187)) 提出了定量测量不同领域之间负迁移程度的方法，我们将这一思想扩展到预训练和微调的范式中。
- en: Definition 2 (Negative Transfer Gap)
  id: totrans-220
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 2（负迁移差距）
- en: Let $h_{\theta}(\mathcal{U},\mathcal{T})$ be a hypothesis obtained by adapting
    the model pre-trained from the upstream data $\mathcal{U}$ to the target data
    $\mathcal{T}$, and $h_{\theta}(\emptyset,\mathcal{T})$ be a hypothesis obtained
    by training from scratch on $\mathcal{T}$, then negative transfer gap is defined
    as
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 设 $h_{\theta}(\mathcal{U},\mathcal{T})$ 为通过将从上游数据 $\mathcal{U}$ 预训练的模型调整到目标数据
    $\mathcal{T}$ 获得的假设，$h_{\theta}(\emptyset,\mathcal{T})$ 为通过在 $\mathcal{T}$ 上从头训练获得的假设，则负迁移差距定义为
- en: '|  | $NTG=\epsilon_{\mathcal{T}}(h_{\theta}(\mathcal{U},\mathcal{T}))-\epsilon_{\mathcal{T}}(h_{\theta}(\emptyset,\mathcal{T})),$
    |  | (12) |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '|  | $NTG=\epsilon_{\mathcal{T}}(h_{\theta}(\mathcal{U},\mathcal{T}))-\epsilon_{\mathcal{T}}(h_{\theta}(\emptyset,\mathcal{T})),$
    |  | (12) |'
- en: and negative transfer occurs if $NTG$ is positive and vice versa.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 如果$NTG$为正，则发生负面转移，反之亦然。
- en: '![Refer to caption](img/efc34ea98ae6f072b84d7a660820c337.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/efc34ea98ae6f072b84d7a660820c337.png)'
- en: 'Figure 15: Dilemma to promote positive transfer and avoid negative transfer:
    Aggressive strategies that promote larger positive transfer will suffer from severer
    negative transfer; Conservative strategies can decrease negative transfer, yet
    lead to smaller positive transfer.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图15：促进正面转移与避免负面转移的困境：激进策略会促进更大正面转移，但会遭受更严重的负面转移；保守策略可以减少负面转移，但会导致较小的正面转移。
- en: 'First, negative transfer will happen when the relatedness between the upstream
    task and downstream task is not strong, e.g. Next Sentence Prediction pre-training
    task will hurt token-level classification tasks (Liu et al., [2019b](#bib.bib109)).
    Negative transfer will also happen when there is a large shift between the pre-training
    domain and the target domain, e.g. for legal documents classification, pre-training
    only on legal documents is better than pre-training on more diverse datasets (Zheng
    et al., [2021](#bib.bib207)). Second, negative transfer depends on the size of
    the labeled target dataset (Wang et al., [2019d](#bib.bib187)). For example, He
    et al. ([2019](#bib.bib66)) empirically show that on large-scale object detection
    datasets (e.g. COCO), ImageNet pre-training is not beneficial when training for
    enough iterations. Third, negative transfer depends on the task adaptation algorithms.
    An ideal adaptation algorithm should promote positive transfer between related
    tasks while avoiding negative transfer between unrelated tasks. In practice, however,
    these two goals are often contradictory and result in the *dilemma*: approaches
    that promote larger positive transfer will suffer from severer negative transfer
    (Figure [15](#S3.F15 "Figure 15 ‣ 3.1.2 Negative Transfer ‣ 3.1 Task Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")).'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，当上游任务与下游任务之间的相关性不强时，例如，下一句预测预训练任务会对令牌级分类任务造成负面影响（Liu等，[2019b](#bib.bib109)）。当预训练领域与目标领域之间存在较大差异时，也会发生负面转移，例如，对于法律文档分类，仅在法律文档上进行预训练优于在更多样化的数据集上进行预训练（Zheng等，[2021](#bib.bib207)）。其次，负面转移还取决于标记目标数据集的大小（Wang等，[2019d](#bib.bib187)）。例如，He等人（[2019](#bib.bib66)）实证显示，在大规模目标检测数据集（例如COCO）上，ImageNet预训练在进行足够迭代训练时并没有显著好处。第三，负面转移还取决于任务适配算法。理想的适配算法应促进相关任务之间的正面转移，同时避免无关任务之间的负面转移。然而，在实践中，这两个目标往往是矛盾的，导致*困境*：那些促进更大正面转移的方法将遭受更严重的负面转移（图
    [15](#S3.F15 "Figure 15 ‣ 3.1.2 Negative Transfer ‣ 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")）。'
- en: Enhancing Safe Transfer.
  id: totrans-227
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 提升安全转移。
- en: One way to avoid negative transfer is to recognize and reject harmful knowledge
    in the pre-trained model. Chen et al. ([2019b](#bib.bib27)) observe that with
    sufficient training data, the spectral components with small singular values vanish
    during fine-tuning, indicating that small singular values correspond to detrimental
    pre-trained knowledge and may cause negative transfer. Thus BSS penalizes smaller
    singular values to suppress untransferable spectral components for safe transfer.
    Jang et al. ([2019](#bib.bib78)) meta-learns the weights determining which pairs
    of layers should be matched and to what extent the knowledge should be transferred,
    which rejects irrelevant information during transfer. Zoo-tuning (Shu et al.,
    [2021b](#bib.bib160)) enables adaptive transfer from a zoo of models, which adaptively
    aggregates multiple pre-trained models to derive the target model using data-dependent
    gating mechanisms to highlight transferable parameters. Another way to mitigate
    negative transfer of the pre-trained model is to fully explore the target data.
    Self-Tuning (Wang et al., [2021](#bib.bib186)) proposes a pseudo group contrastive
    mechanism to explore the intrinsic structure of the target data in the process
    of fine-tuning with standard supervised objective.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 避免负迁移的一种方法是识别并排除预训练模型中的有害知识。Chen et al. ([2019b](#bib.bib27)) 观察到，随着训练数据的增加，具有小奇异值的谱分量在微调过程中消失，表明小奇异值对应于有害的预训练知识，可能导致负迁移。因此，BSS
    通过惩罚较小的奇异值来抑制不可迁移的谱分量，从而实现安全迁移。Jang et al. ([2019](#bib.bib78)) 通过元学习确定哪些层对应该匹配，以及知识应迁移的程度，从而在迁移过程中排除不相关的信息。Zoo-tuning
    (Shu et al., [2021b](#bib.bib160)) 允许从大量模型中进行自适应迁移，它通过数据依赖的门控机制自适应地聚合多个预训练模型，以突出可迁移的参数。另一种减轻预训练模型负迁移的方法是充分探索目标数据。Self-Tuning
    (Wang et al., [2021](#bib.bib186)) 提出了伪组对比机制，以在具有标准监督目标的微调过程中探索目标数据的内在结构。
- en: Choosing Pre-trained Models.
  id: totrans-229
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 选择预训练模型。
- en: With the fast development of deep learning, a large zoo of pre-trained models
    are available, thus a simpler way to avoid negative transfer is to select a model
    that is pre-trained on the upstream data/task relevant to the downstream data/task.
    The most common practice to choose pre-trained models is based on rich past experience
    or through heavy experiments. To facilitate faster selection, Taskonomy (Zamir
    et al., [2018](#bib.bib199)) proposes a fully computational approach for explicitly
    modeling the relationship between $26$ different visual tasks. Another more efficient
    strategy to select pre-trained models is to predict the transferability of pre-trained
    models. LEEP (Nguyen et al., [2020](#bib.bib123)) constructs an empirical predictor
    by estimating the joint distribution over pre-trained labels and the target labels,
    and then uses the log expectation of the empirical predictor to measure the transferability.
    LogME (You et al., [2021](#bib.bib198)) proposes to predict the fine-tuning performance
    from the compatibility of features $\{\mathbf{z}_{i}=\psi(\mathbf{x}_{i})\}_{i=1}^{m}$
    and labels $\{\mathbf{y}_{i}\}_{i=1}^{m}$. Still, these methods may underestimate
    strong but non-linear features. He et al. ([2021](#bib.bib68)) show that features
    from contrastive pre-training, such as MoCo v3 (Chen et al., [2021a](#bib.bib26)),
    have higher linear probing accuracy while worse fully fine-tuning results than
    generative pre-training, such as MAE (He et al., [2021](#bib.bib68)), indicating
    that the linear separability of the pre-trained features is not the sole metric
    for evaluating transferability.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习的快速发展，现有大量的预训练模型，因此避免负迁移的一个更简单方法是选择一个在上游数据/任务上预训练的模型，这些数据/任务与下游数据/任务相关。选择预训练模型的最常见做法是基于丰富的过去经验或通过大量实验。为了加快选择速度，Taskonomy
    (Zamir et al., [2018](#bib.bib199)) 提出了一个完全计算的方法，用于明确建模 $26$ 种不同视觉任务之间的关系。另一种更有效的选择预训练模型的策略是预测预训练模型的迁移能力。LEEP
    (Nguyen et al., [2020](#bib.bib123)) 通过估计预训练标签和目标标签的联合分布来构建一个经验预测器，然后使用经验预测器的对数期望来衡量迁移能力。LogME
    (You et al., [2021](#bib.bib198)) 提出了通过特征 $\{\mathbf{z}_{i}=\psi(\mathbf{x}_{i})\}_{i=1}^{m}$
    和标签 $\{\mathbf{y}_{i}\}_{i=1}^{m}$ 的兼容性来预测微调性能。然而，这些方法可能会低估强但非线性的特征。He et al.
    ([2021](#bib.bib68)) 表明，来自对比预训练的特征，如 MoCo v3 (Chen et al., [2021a](#bib.bib26))，在完全微调结果上表现较差，而在线性探测准确度上更高，表明预训练特征的线性可分性并不是评估迁移能力的唯一指标。
- en: '![Refer to caption](img/e34c45d320b6765ea49be605dccaf3ac.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e34c45d320b6765ea49be605dccaf3ac.png)'
- en: 'Figure 16: Comparison on how different adaptation methods freeze (blue) and
    tune (red) pre-trained parameters. (a) Feature transfer freezes all the pre-trained
    parameters. (b) Fine-tuning re-trains all the pre-trained parameters. (c) Side-tuning
    trains a lightweight conditioned side network that is fused with the fixed pre-trained
    network using summation. (d) Adapter-Tuning inserts adapter modules for tuning
    into each frozen pre-trained layer.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图16：不同适应方法冻结（蓝色）和调整（红色）预训练参数的比较。（a）特征迁移冻结所有预训练参数。（b）微调重新训练所有预训练参数。（c）Side-tuning训练一个轻量级条件侧网络，并通过求和将其与固定的预训练网络融合。（d）Adapter-Tuning在每个冻结的预训练层中插入适配器模块以进行调整。
- en: 3.1.3 Parameter Efficiency
  id: totrans-233
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.3 参数效率
- en: Fine-tuning large pre-trained models yields strong performances on many downstream
    tasks (Radford et al., [2018](#bib.bib134); Devlin et al., [2019](#bib.bib39)),
    yet it is not parameter efficient since it generates a full set of model parameters
    for each downstream task, which will cause unacceptable storage cost as the number
    of tasks increases. The simplest solution is Multi-task Learning (Caruana, [1997](#bib.bib20)),
    i.e., fine-tuning a single model to solve multiple target tasks, which might be
    mutually beneficial to each other (He et al., [2017](#bib.bib65); Liu et al.,
    [2019a](#bib.bib108)). Yet when different target tasks are weakly related, multi-task
    learning will underperform fine-tuning for each task separately. Also, multi-task
    learning requires simultaneous access to all target tasks, which is not feasible
    in online scenarios where the target tasks arrive in sequence. Hereafter, we will
    introduce new tuning paradigms proposed to improve parameter efficiency.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 微调大型预训练模型在许多下游任务上表现出色（Radford等，[2018](#bib.bib134)；Devlin等，[2019](#bib.bib39)），但由于每个下游任务都会生成一整套模型参数，因此参数效率较低，随着任务数量的增加，存储成本也会变得不可接受。最简单的解决方案是多任务学习（Caruana，[1997](#bib.bib20)），即微调一个模型以解决多个目标任务，这些任务之间可能互相有利（He等，[2017](#bib.bib65)；Liu等，[2019a](#bib.bib108)）。然而，当不同的目标任务关联较弱时，多任务学习的表现会逊色于对每个任务单独进行微调。此外，多任务学习需要同时访问所有目标任务，这在目标任务按顺序到达的在线场景中不可行。接下来，我们将介绍为提高参数效率而提出的新调整范式。
- en: Residual Tuning.
  id: totrans-235
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 残差调整。
- en: Inspired by the fact that approximation to a difference is easier than the original
    function (He et al., [2016](#bib.bib64)), Side-Tuning (Zhang et al., [2019b](#bib.bib203))
    adds a small side network $h_{\text{side}}$ to adapt the frozen pre-trained model
    $h_{\text{pretrained}}$ for the target task and obtain a combined model $h(x)=\alpha
    h_{\text{pretrained}}(x)+(1-\alpha)h_{\text{side}}(x)$, where $\alpha$ is a weight
    that changes during training. When there is a big gap between the pre-trained
    model and the downstream task, it may be difficult to learn the residuals of the
    entire model. Thus, Adapter Tuning (Houlsby et al., [2019](#bib.bib73)) inserts
    residual adapter modules into each frozen layer. Residual Adapter was first introduced
    for learning multiple visual domains (Rebuffi et al., [2017](#bib.bib139)) and
    consists of a skip connection, such that it is set as a near-identity function
    and will not impair the whole model when the training starts. By choosing a much
    smaller amount of parameters for the adapters, Adapter Tuning can extend pre-trained
    models to new tasks without increasing much storage cost. Houlsby et al. ([2019](#bib.bib73))
    find that Adapter Tuning with only $3.6\%$ tunable parameters can match the performance
    of the fully fine-tuned BERT on the GLUE benchmark (Wang et al., [2019a](#bib.bib183)),
    revealing the great potential of this method.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 受以下事实启发：对差异的近似比原始函数更容易（He等，[2016](#bib.bib64)），Side-Tuning（Zhang等，[2019b](#bib.bib203)）添加了一个小的侧网络$h_{\text{side}}$来调整冻结的预训练模型$h_{\text{pretrained}}$以适应目标任务，并获得一个组合模型$h(x)=\alpha
    h_{\text{pretrained}}(x)+(1-\alpha)h_{\text{side}}(x)$，其中$\alpha$是训练过程中变化的权重。当预训练模型和下游任务之间存在较大差距时，可能很难学习整个模型的残差。因此，Adapter
    Tuning（Houlsby等，[2019](#bib.bib73)）在每个冻结层中插入残差适配器模块。Residual Adapter首次用于学习多个视觉领域（Rebuffi等，[2017](#bib.bib139)），由一个跳过连接组成，使其设置为近似恒等函数，训练开始时不会损害整个模型。通过选择更少量的参数用于适配器，Adapter
    Tuning可以在不增加太多存储成本的情况下，将预训练模型扩展到新任务。Houlsby等人（[2019](#bib.bib73)）发现，仅使用$3.6\%$的可调参数的Adapter
    Tuning可以在GLUE基准（Wang等，[2019a](#bib.bib183)）上匹配完全微调的BERT的性能，揭示了这一方法的巨大潜力。
- en: Parameter Difference Tuning.
  id: totrans-237
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 参数差异调整。
- en: While residual adapter tuning changes the model activations by adding new modules,
    parameter difference tuning extends the pre-trained models through a task-specific
    parameter difference vector,
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然残差适配器调整通过添加新模块来改变模型激活，参数差异调整通过任务特定的参数差异向量扩展预训练模型，
- en: '|  | $\theta_{\text{task}}=\theta_{\text{pretrained}}\oplus\delta_{\text{task}},$
    |  | (13) |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '|  | $\theta_{\text{task}}=\theta_{\text{pretrained}}\oplus\delta_{\text{task}},$
    |  | (13) |'
- en: where $\oplus$ is the element-wise addition function, $\theta_{\text{pretrained}}$
    is the fixed pre-trained parameters and $\delta_{\text{task}}$ is the tuned task-specific
    difference vector. Instead of storing a copy of $\theta_{\text{task}}$ for every
    task, difference tuning only needs to store a single copy of $\theta_{\text{pretrained}}$
    and a copy of $\delta_{\text{task}}$ for every task. As long as the size of $\delta_{\text{task}}$
    can be reduced, we can achieve parameter efficient models. To this end, Diff Pruning
    (Guo et al., [2021](#bib.bib61)) utilizes $L_{0}$-norm penalty (Louizos et al.,
    [2018](#bib.bib117)) to encourage sparsity of the difference vector $\delta_{\text{task}}$.
    Aghajanyan et al. ([2021](#bib.bib2)) adopt FastFood transform $M$ (Li et al.,
    [2018](#bib.bib99)) to convert $\delta_{\text{task}}$ into a low-dimensional vector
    $\delta_{\text{low}}$, i.e., $\delta_{\text{task}}=\delta_{\text{low}}M$. The
    element-wise addition can also be replaced by element-wise multiplication. For
    instance, Piggyback (Mallya and Lazebnik, [2018](#bib.bib119)) multiplies real-valued
    mask weights to the pre-trained parameters, i.e., $\theta_{\text{task}}=\theta_{\text{pretrained}}\odot\delta_{\text{task}}$
    during training. After training, the mask weights $\delta_{\text{task}}$ are passed
    through a thresholding function to obtain binary-valued masks, further reducing
    the parameter storage of $\delta_{\text{task}}$ at inference.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\oplus$ 是逐元素加法函数，$\theta_{\text{pretrained}}$ 是固定的预训练参数，$\delta_{\text{task}}$
    是调整后的任务特定差异向量。差异调整方法不需要为每个任务存储一份$\theta_{\text{task}}$的副本，只需为每个任务存储一份$\theta_{\text{pretrained}}$的副本和一份$\delta_{\text{task}}$的副本。只要$\delta_{\text{task}}$的大小可以减少，我们就可以实现参数高效的模型。为此，Diff
    Pruning (Guo et al., [2021](#bib.bib61)) 利用 $L_{0}$-范数惩罚 (Louizos et al., [2018](#bib.bib117))
    来鼓励差异向量$\delta_{\text{task}}$的稀疏性。Aghajanyan et al. ([2021](#bib.bib2)) 采用 FastFood
    变换 $M$ (Li et al., [2018](#bib.bib99)) 将$\delta_{\text{task}}$ 转换为低维向量 $\delta_{\text{low}}$，即
    $\delta_{\text{task}}=\delta_{\text{low}}M$。逐元素加法也可以被逐元素乘法替代。例如，Piggyback (Mallya
    和 Lazebnik, [2018](#bib.bib119)) 在训练期间将实值掩码权重乘到预训练参数上，即 $\theta_{\text{task}}=\theta_{\text{pretrained}}\odot\delta_{\text{task}}$。训练后，掩码权重$\delta_{\text{task}}$
    经过阈值函数处理以获得二值掩码，进一步减少了推理时$\delta_{\text{task}}$的参数存储。
- en: 'The essential difference between the above two tuning methods lies in their
    different assumptions about the root of transferability. Residual tuning assumes
    that transferability is encoded in the *behaviors* of each module, i.e., the features
    output by each module. When adapting to the downstream tasks, we only need to
    add some task-specific behaviors by stacking the pre-trained modules with the
    residual adapter modules. In contrast, parameter difference tuning assumes that
    transferability lies in the pre-trained *parameters*. Most of the pre-trained
    parameters can be reused, and only a small part of them need to be adapted to
    the downstream tasks, thus we only need to store the increment. Another thing
    to mention is that when limiting the size of the residual adapters or the complexity
    of the difference vector, these methods naturally overcome the catastrophic forgetting
    issue in Section [3.1.1](#S3.SS1.SSS1 "3.1.1 Catastrophic Forgetting ‣ 3.1 Task
    Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey").'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '上述两种调整方法的根本区别在于它们对可迁移性的根源的不同假设。残差调整假设可迁移性编码在每个模块的*行为*中，即每个模块输出的特征。当适应下游任务时，我们只需通过将预训练模块与残差适配器模块堆叠在一起，来添加一些任务特定的行为。相反，参数差异调整假设可迁移性存在于预训练的*参数*中。大部分预训练参数可以重复使用，只有一小部分需要调整到下游任务中，因此我们只需存储增量。另一个需要提到的事情是，当限制残差适配器的大小或差异向量的复杂度时，这些方法自然克服了[3.1.1](#S3.SS1.SSS1
    "3.1.1 Catastrophic Forgetting ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")节中的灾难性遗忘问题。'
- en: 3.1.4 Data Efficiency
  id: totrans-242
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.4 数据效率
- en: 'Currently, when fine-tuning large pre-trained models, hundreds or even thousands
    of labeled samples are still required to achieve strong performance on a specific
    downstream task, which limits the application of the “pre-training and fine-tuning”
    paradigm to wider range of tasks where labeled data are expensive to collect.
    In contrast, people can adapt to a new task with extremely few labeled samples,
    which is known as few-shot learning, or even with no labeled samples, which is
    known as zero-shot learning. Considering the lifecycle of deep learning, we can
    tackle this problem in three ways. The first is to improve the cross-task transferability
    of the pre-trained models, such as by increasing the model capacity or the pre-training
    dataset size, which is mentioned in Section [2](#S2 "2 Pre-Training ‣ Transferability
    in Deep Learning: A Survey"). The second is to transfer from another labeled source
    domain where labeled data is cheaper to collect, which will be discussed in Section
    [3.2](#S3.SS2 "3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep
    Learning: A Survey"). The last is to reformulate the target task to close its
    gap with the pre-trained models, which is the focus of this part.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '当前，在微调大型预训练模型时，仍然需要数百甚至数千个标记样本才能在特定下游任务上取得良好表现，这限制了“预训练和微调”范式在标记数据昂贵的任务中的应用。相反，人们可以通过极少的标记样本适应新任务，这被称为少样本学习，甚至可以在没有标记样本的情况下进行学习，这被称为零样本学习。考虑到深度学习的生命周期，我们可以通过三种方式来解决这个问题。第一种是提高预训练模型的跨任务迁移能力，比如通过增加模型容量或预训练数据集的规模，这在[2](#S2
    "2 Pre-Training ‣ Transferability in Deep Learning: A Survey")节中提到。第二种是从另一个标记源领域进行迁移，在那里标记数据的收集成本较低，这将在[3.2](#S3.SS2
    "3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")节中讨论。最后一种是重新定义目标任务，以缩小其与预训练模型的差距，这是本部分的重点。'
- en: Metric Learning.
  id: totrans-244
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 衡量学习。
- en: Fine-tuning in low data regimes will easily cause over-fitting as updating the
    model of large-scale parameters using few labeled samples is ill-posed. In contrast,
    many *non-parametric* methods, such as nearest neighbors, can deal with low-sample
    regimes without suffering from catastrophic forgetting. To combine the advantages
    of parametric and non-parametric methods, Matching Net (Vinyals et al., [2016](#bib.bib180))
    uses an attention mechanism over the learned representations to predict the classes
    for the query samples, which can be interpreted as weighted nearest neighbors.
    Since labeled data is severely limited, ProtoNet (Snell et al., [2017](#bib.bib162))
    adds a stronger inductive bias that there exists a single prototype representation
    for each class, where each prototype is the mean of the features of the labeled
    samples in each class, and classification boils down to finding the nearest prototype.
    Since no gradient update is performed on the feature representation, choosing
    a proper distance metric that has good transferability across tasks plays an important
    role. A common choice is the cosine distance, which explicitly reduces the intra-class
    variations and improves the cross-task transferability. Chen et al. ([2019a](#bib.bib24))
    find that by replacing the linear classifier with a cosine-distance based classifier,
    the naive feature transfer method without fine-tuning serves as a strong baseline
    in few-shot learning.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据稀缺的情况下进行微调容易导致过拟合，因为使用少量标记样本更新大规模参数的模型是不适定的。相比之下，许多*非参数*方法，如最近邻，可以在低样本情况下处理而不会遭受灾难性遗忘。为了结合参数方法和非参数方法的优点，Matching
    Net（Vinyals 等，[2016](#bib.bib180)）使用了对学习表示的注意机制来预测查询样本的类别，这可以解释为加权的最近邻。由于标记数据严重受限，ProtoNet（Snell
    等，[2017](#bib.bib162)）增加了一个更强的归纳偏置，即每个类别存在一个单一的原型表示，其中每个原型是每个类别中标记样本特征的均值，分类归结为找到最接近的原型。由于在特征表示上没有进行梯度更新，因此选择一个在任务之间具有良好迁移性的距离度量起着重要作用。一个常见的选择是余弦距离，它明确减少了类内变异并改善了跨任务迁移性。Chen
    等（[2019a](#bib.bib24)）发现，通过用基于余弦距离的分类器替代线性分类器，未经微调的原始特征迁移方法在少样本学习中作为强基线。
- en: Prompt Learning.
  id: totrans-246
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 提示学习。
- en: 'Prompting, firstly proposed in GPT-3 (Brown et al., [2020](#bib.bib18)), is
    another way to reformulate the downstream task to make it similar to the solved
    pre-training task. In fine-tuning, models will take input $\mathbf{x}$ and predict
    an output $\mathbf{y}$ as $P(\mathbf{y}|\mathbf{x})$. In prompting, the original
    input $\mathbf{x}$ is modified by a prompt template into a new string $\tilde{\mathbf{x}}$
    that has unfilled slots, then the pre-trained language model will fill $\tilde{\mathbf{x}}$
    to obatin a final string $\widehat{\mathbf{x}}$ and derive the output $\mathbf{y}$
    from $\widehat{\mathbf{x}}$ (Liu et al., [2021b](#bib.bib107)). Table [3](#S3.T3
    "Table 3 ‣ Prompt Learning. ‣ 3.1.4 Data Efficiency ‣ 3.1 Task Adaptation ‣ 3
    Adaptation ‣ Transferability in Deep Learning: A Survey") provides an example
    of prompting methods.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 提示，最初在GPT-3中提出（Brown等，[2020](#bib.bib18)），是一种将下游任务重新表述为类似于解决的预训练任务的方式。在微调中，模型将输入$\mathbf{x}$并预测输出$\mathbf{y}$为$P(\mathbf{y}|\mathbf{x})$。在提示中，原始输入$\mathbf{x}$通过提示模板修改为一个新的字符串$\tilde{\mathbf{x}}$，该字符串具有未填充的槽，然后预训练的语言模型将填充$\tilde{\mathbf{x}}$以获得最终字符串$\widehat{\mathbf{x}}$，并从$\widehat{\mathbf{x}}$中推导出输出$\mathbf{y}$（Liu等，[2021b](#bib.bib107)）。表[3](#S3.T3
    "表 3 ‣ 提示学习。 ‣ 3.1.4 数据效率 ‣ 3.1 任务适应 ‣ 3 适应 ‣ 深度学习中的迁移性：调查")提供了提示方法的示例。
- en: 'Table 3: An example of prompting method from Liu et al. ([2021b](#bib.bib107)).'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：来自Liu等（[2021b](#bib.bib107)）的提示方法示例。
- en: '| Name | Notation | Example |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 符号 | 示例 |'
- en: '| Input | $\mathbf{x}$ | I love this film. |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 输入 | $\mathbf{x}$ | 我喜欢这部电影。 |'
- en: '| Output | $\mathbf{y}$ | positive |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 输出 | $\mathbf{y}$ | 正面 |'
- en: '| Prompt Template | ${f_{\text{prompt}}(\mathbf{x})}$ | [X] Overall, it was
    a [Z] film. |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 提示模板 | ${f_{\text{prompt}}(\mathbf{x})}$ | [X] 总体而言，这是一部[Z]电影。 |'
- en: '| Prompt | $\tilde{\mathbf{x}}$ | I love this film. Overall, it was a [Z] film.
    |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| 提示 | $\tilde{\mathbf{x}}$ | 我喜欢这部电影。总体而言，这是一部[Z]电影。 |'
- en: '| Filled Prompt | $\mathbf{\widehat{x}}$ | I love this movie. Overall, it was
    a good movie. |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| 填充提示 | $\mathbf{\widehat{x}}$ | 我喜欢这部电影。总体而言，这是一部好电影。 |'
- en: '![Refer to caption](img/e272b27c4fa3d7c80739da24598a843c.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e272b27c4fa3d7c80739da24598a843c.png)'
- en: 'Figure 17: (a) Fine-tuning generates a new set of parameters for each downstream
    task. (b) Prompting fixes the pre-trained parameters and finds task-specific prompts
    to solve each downstream task. (c) Instruction Tuning tunes the pre-trained models
    on instruction-format dataset and uses the obtained model to do inference with
    multiple downstream tasks.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图17：（a）微调为每个下游任务生成一组新的参数。（b）提示固定了预训练参数，并找到任务特定的提示来解决每个下游任务。（c）指令调优在指令格式数据集上调整预训练模型，并使用获得的模型对多个下游任务进行推理。
- en: The advantage of prompting is that it enables few-shot or even zero-shot task
    adaptation. The strong cross-task transferability stems from the implicit multiple
    tasks such as question-answering that language models are forced to learn on the
    large-scale pre-training corpus. However, this transferability requires a large
    model capacity to deal with potential implicit tasks and is also very sensitive
    to the choice of prompts. Thus, the disadvantage is that it introduces the necessity
    for prompt engineering, i.e., finding the best prompts to solve each downstream
    task, which is work-heavy and time-consuming especially on large datasets.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 提示的优点在于它使得少样本甚至零样本任务适应成为可能。强大的跨任务迁移能力源于语言模型在大规模预训练语料库上被迫学习的隐式多任务（如问答）。然而，这种迁移能力需要较大的模型容量来处理潜在的隐式任务，同时对提示的选择也非常敏感。因此，其缺点在于引入了提示工程的必要性，即找到最佳提示以解决每个下游任务，这在大数据集上尤其工作繁重且耗时。
- en: 'Combining prompting and fine-tuning may tackle this problem (Figure [17](#S3.F17
    "Figure 17 ‣ Prompt Learning. ‣ 3.1.4 Data Efficiency ‣ 3.1 Task Adaptation ‣
    3 Adaptation ‣ Transferability in Deep Learning: A Survey")). PET-TC (Schick and
    Schütze, [2020](#bib.bib151)) tunes the parameters of pre-trained language models
    in prompt learning while Prefix-Tuning (Li and Liang, [2021](#bib.bib100)) adds
    additional prompt-related parameters and tunes these parameters. Instruction Tuning
    (Wei et al., [2022](#bib.bib188)) explicitly fine-tunes the pre-trained models
    on a mixture of datasets expressed through natural language instructions (similar
    to the filled prompt) and obtain Fine-tuned LAnguage Model (FLAN), which largely
    increases the models’ transferability to unseen tasks. In summary, prompt learning
    has provided a revolutionary way on how to utilize the transferability of pre-trained
    models.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 结合提示和微调可能解决这个问题（图[17](#S3.F17 "图17 ‣ 提示学习。 ‣ 3.1.4 数据效率 ‣ 3.1 任务适应 ‣ 3 适应 ‣
    深度学习中的可迁移性：综述")）。PET-TC（Schick 和 Schütze，[2020](#bib.bib151)）在提示学习中调整预训练语言模型的参数，而
    Prefix-Tuning（Li 和 Liang，[2021](#bib.bib100)）增加了额外的提示相关参数并对这些参数进行调优。Instruction
    Tuning（Wei 等，[2022](#bib.bib188)）明确地在通过自然语言指令（类似于填充提示）表达的混合数据集上微调预训练模型，并获得 Fine-tuned
    LAnguage Model（FLAN），这大大提高了模型对未见任务的可迁移性。总之，提示学习提供了一种革命性的方式来利用预训练模型的迁移能力。
- en: 3.1.5 Remarks
  id: totrans-259
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.5 备注
- en: 'Table [4](#S3.T4 "Table 4 ‣ 3.1.5 Remarks ‣ 3.1 Task Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey") gives a comparison of different
    task adaptation methods. Fine-tuning (including vanilla fine-tuning, domain adaptive
    tuning, and regularization tuning) has better performance when there are enough
    labeled data in the downstream tasks. In contrast, prompt learning requires much
    fewer labeled data to achieve decent performance, yet its applications are still
    limited to NLP and it is still non-trivial to extend it to vision or other areas.
    Fine-tuning is the most parameter-inefficient since it generates a full set of
    model parameters for each downstream task, while residual tuning, difference tuning,
    and prompt learning are all parameter efficient. Also, these latter methods naturally
    mitigate the catastrophic forgetting problem, but *negative transfer* is still
    a hard problem to be resolved.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 表[4](#S3.T4 "表4 ‣ 3.1.5 备注 ‣ 3.1 任务适应 ‣ 3 适应 ‣ 深度学习中的可迁移性：综述")展示了不同任务适应方法的比较。当下游任务中有足够标注数据时，微调（包括原始微调、领域自适应调优和正则化调优）表现更好。相对而言，提示学习需要的标注数据少得多以实现良好的性能，但其应用仍限于自然语言处理，且将其扩展到视觉或其他领域仍然困难。微调最为参数低效，因为每个下游任务都生成一整套模型参数，而残差调优、差异调优和提示学习都是参数高效的。这些方法自然地缓解了灾难性遗忘问题，但*负迁移*仍然是一个难以解决的问题。
- en: 'Table 4: Comparison between different task adaptation methods.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：不同任务适应方法的比较。
- en: '|  |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '&#124; Adaptation &#124;'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 适应 &#124;'
- en: '&#124; Performance¹ &#124;'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 性能¹ &#124;'
- en: '|'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Data &#124;'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 数据 &#124;'
- en: '&#124; Efficiency² &#124;'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 效率² &#124;'
- en: '|'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Parameter &#124;'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 参数 &#124;'
- en: '&#124; Efficiency³ &#124;'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 效率³ &#124;'
- en: '|'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Modality &#124;'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模态 &#124;'
- en: '&#124; Scalability⁴ &#124;'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可扩展性⁴ &#124;'
- en: '|'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Task &#124;'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 任务 &#124;'
- en: '&#124; Scalability⁵ &#124;'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可扩展性⁵ &#124;'
- en: '|'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Feature Transfer | $\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 特征迁移 | $\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ |'
- en: '| Vanilla Fine-tuning | $\bigstar\bigstar\bigstar$ | $\bigstar$ | $\bigstar$
    | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 原始微调 | $\bigstar\bigstar\bigstar$ | $\bigstar$ | $\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ |'
- en: '| Domain Adaptive Tuning | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$
    | $\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 领域自适应调优 | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar$ |
    $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
- en: '| Regularization Tuning | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$ |
    $\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar$ |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 正则化调优 | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar$ |'
- en: '| Residual Tuning | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar$
    | $\bigstar\bigstar$ | $\bigstar\bigstar$ |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 残差调优 | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar$
    | $\bigstar\bigstar$ |'
- en: '| Parameter Difference Tuning | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 参数差异调优 | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ |'
- en: '| Metric Learning | $\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ | $\bigstar$ |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 度量学习 | $\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ | $\bigstar$ |'
- en: '| Prompt Learning | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar$ | $\bigstar$ |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 提示学习 | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar$ | $\bigstar$ |'
- en: '1'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1'
- en: 'Adaptation Performance: performance when there are large-scale labeled data
    in downstream tasks.'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 适应性能：当下游任务中有大规模标注数据时的性能。
- en: '2'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2'
- en: 'Data Efficiency: performance when there are only small-scale labeled data in
    downstream tasks.'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据效率：当下游任务中仅有小规模标注数据时的性能。
- en: '3'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '3'
- en: 'Parameter Efficiency: whether can control parameters when the number of downstream
    tasks increases.'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参数效率：当下游任务数量增加时，是否能够控制参数。
- en: '4'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '4'
- en: 'Modality Scalability: whether can adapt pre-trained models to various modalities,
    such as text, graph.'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模态可扩展性：是否能将预训练模型适应到各种模态，如文本、图。
- en: '5'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '5'
- en: 'Task Scalability: whether can adapt pre-trained models to different downstream
    tasks, such as detection.'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任务可扩展性：是否能将预训练模型适应到不同的下游任务，如检测。
- en: The motivation of many task adaptation methods can be understood from the perspective
    of *transferability*. For instance, domain adaptive tuning aims to bridge the
    domain discrepancy between the pre-training task and the downstream task by further
    obtaining a pre-trained model on the target data distribution. Prompt learning
    aims to bridge the task discrepancy between the pre-training task and the downstream
    task by reformulating all the tasks to the same format. In this scenario, when
    all tasks can be expressed in the same form, the difference between the pre-training
    task and the downstream task is only the shift in data distributions, i.e., task
    adaptation becomes the domain adaptation problem.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 许多任务适应方法的动机可以从*可迁移性*的角度来理解。例如，领域自适应调优旨在通过进一步在目标数据分布上获取预训练模型，来弥合预训练任务和下游任务之间的领域差异。提示学习旨在通过将所有任务重新表述为相同的格式，来弥合预训练任务和下游任务之间的任务差异。在这种情况下，当所有任务都可以用相同的形式表示时，预训练任务和下游任务之间的区别仅仅是数据分布的变化，即任务适应变成了领域适应问题。
- en: 3.2 Domain Adaptation
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 领域适应
- en: The pre-training and fine-tuning paradigm has greatly improved the state-of-the-arts
    for diverse machine learning problems and applications, and the pre-trained deep
    networks can be easily adapted to the tasks at hand even with a small amount of
    labeled data. However, in many practical scenarios, there is no labeled training
    data and thus there is the demand to transfer a deep network from a source domain
    where labeled training data is available to a target domain where only unlabeled
    data exists (Chen et al., [2012](#bib.bib22); Glorot et al., [2011](#bib.bib51)).
    In this situation, the deep models still suffer from performance degradations
    due to *distribution shift* (Quionero-Candela et al., [2009](#bib.bib133)). Thus,
    domain adaptation is proposed to reduce the distribution shift between training
    and testing domains (Pan and Yang, [2010](#bib.bib125)).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练和微调范式大大提高了多种机器学习问题和应用的最先进技术，并且预训练的深度网络即使在标注数据较少的情况下也可以很容易地适应当前任务。然而，在许多实际场景中，没有标注训练数据，因此需要将深度网络从源领域（有标注训练数据）转移到目标领域（仅有未标注数据）（Chen
    et al., [2012](#bib.bib22); Glorot et al., [2011](#bib.bib51)）。在这种情况下，由于*分布变化*，深度模型仍然会遭遇性能下降（Quionero-Candela
    et al., [2009](#bib.bib133)）。因此，提出了领域适应来减少训练和测试领域之间的分布变化（Pan and Yang, [2010](#bib.bib125)）。
- en: Many methods have been proposed for domain adaptation in the shallow regime,
    either by re-weighting or selecting samples from the source domain (Sugiyama et al.,
    [2008](#bib.bib165)) or seeking an explicit feature space transformation from
    the source distribution into the target distribution (Gong et al., [2013](#bib.bib53)).
    As seminal methods, Huang et al. ([2007](#bib.bib76)); Pan et al. ([2011](#bib.bib126));
    Long et al. ([2013](#bib.bib111)) explicitly match the distributions in the kernel-reproducing
    Hilbert space, while Gong et al. ([2012](#bib.bib52)) map the principal axes associated
    with each of the distributions. This survey will focus on deep domain adaptation,
    where adaptation modules are embedded in deep architectures to match data distributions
    across domains.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 许多方法已被提出用于浅层领域适应，方法包括通过重新加权或从源领域选择样本（Sugiyama 等，[2008](#bib.bib165)），或寻求从源分布到目标分布的显式特征空间转换（Gong
    等，[2013](#bib.bib53)）。作为开创性的方法，Huang 等（[2007](#bib.bib76)）；Pan 等（[2011](#bib.bib126)）；Long
    等（[2013](#bib.bib111)）明确匹配了在核再生希尔伯特空间中的分布，而 Gong 等（[2012](#bib.bib52)）则映射了与每个分布相关的主轴。本文综述将重点关注深度领域适应，其中适应模块嵌入在深度架构中，以匹配跨领域的数据分布。
- en: In unsupervised domain adaptation (UDA), there is a source domain $\widehat{\mathcal{S}}=\{(\mathbf{x}_{i}^{s},\mathbf{y}_{i}^{s})\}_{i=1}^{n}$
    of $n$ labeled samples and a target domain $\widehat{\mathcal{T}}=\{\mathbf{x}_{i}^{t}\}_{i=1}^{m}$
    of $m$ unlabeled samples. The goal of a learning algorithm is to find a hypothesis
    $h:\mathcal{X}\mapsto\mathcal{Y}$ in the hypothesis space $\mathcal{H}$ with a
    low target risk $\epsilon_{\mathcal{T}}(h)=\mathbb{E}_{(\mathbf{x}^{t},\mathbf{y}^{t})\sim\mathcal{T}}[\ell(h(\mathbf{x}^{t}),\mathbf{y}^{t})]$
    with no access to the labels of $\mathcal{T}$, where $\ell:\mathcal{Y}\times\mathcal{Y}\rightarrow\mathbb{R}_{+}$
    is a loss function. Several seminal theories have been proposed to tackle this
    problem and the the main idea of them is to bound the target risk $\epsilon_{\mathcal{T}}(h)$
    by the source risk $\epsilon_{\mathcal{S}}(h)$ and a distribution distance. In
    this survey, we will focus on the theory of $\mathcal{H}\Delta\mathcal{H}$-Divergence
    (Ben-David et al., [2006](#bib.bib9), [2010a](#bib.bib8); Mansour et al., [2009](#bib.bib120))
    and Disparity Discrepancy (Zhang et al., [2019c](#bib.bib204)) and illustrate
    how to derive different algorithms from these theories. First, using triangle
    inequalities, we can relate the target risk to the source risk as follows.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督领域适应（UDA）中，有一个源领域 $\widehat{\mathcal{S}}=\{(\mathbf{x}_{i}^{s},\mathbf{y}_{i}^{s})\}_{i=1}^{n}$
    由 $n$ 个标记样本组成，以及一个目标领域 $\widehat{\mathcal{T}}=\{\mathbf{x}_{i}^{t}\}_{i=1}^{m}$
    由 $m$ 个未标记样本组成。学习算法的目标是找到一个假设 $h:\mathcal{X}\mapsto\mathcal{Y}$ 在假设空间 $\mathcal{H}$
    中，其目标风险 $\epsilon_{\mathcal{T}}(h)=\mathbb{E}_{(\mathbf{x}^{t},\mathbf{y}^{t})\sim\mathcal{T}}[\ell(h(\mathbf{x}^{t}),\mathbf{y}^{t})]$
    低，并且没有访问 $\mathcal{T}$ 的标签，其中 $\ell:\mathcal{Y}\times\mathcal{Y}\rightarrow\mathbb{R}_{+}$
    是一个损失函数。一些开创性理论已经提出以解决这个问题，它们的主要思想是通过源风险 $\epsilon_{\mathcal{S}}(h)$ 和一个分布距离来界限目标风险
    $\epsilon_{\mathcal{T}}(h)$。在这篇综述中，我们将重点关注 $\mathcal{H}\Delta\mathcal{H}$-发散（Ben-David
    等，[2006](#bib.bib9)，[2010a](#bib.bib8)；Mansour 等，[2009](#bib.bib120)）和差异性不一致（Zhang
    等，[2019c](#bib.bib204)）的理论，并说明如何从这些理论中推导出不同的算法。首先，利用三角不等式，我们可以将目标风险与源风险相关联，如下所示。
- en: Theorem 3 (Bound with Disparity)
  id: totrans-301
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 3（带有差异的界限）
- en: Assume that the loss function $\ell$ is symmetric and obeys the triangle inequality.
    Define the *disparity* between any two hypotheses $h$ and $h^{\prime}$ on distribution
    $\mathcal{D}$ as
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 假设损失函数 $\ell$ 是对称的，并且满足三角不等式。定义分布 $\mathcal{D}$ 上任何两个假设 $h$ 和 $h^{\prime}$ 之间的*差异*为
- en: '|  | $\epsilon_{\mathcal{D}}(h,h^{\prime})=\mathbb{E}_{(\mathbf{x},\mathbf{y})\sim\mathcal{D}}[\ell(h(\mathbf{x}),h^{\prime}(\mathbf{x}))].$
    |  | (14) |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '|  | $\epsilon_{\mathcal{D}}(h,h^{\prime})=\mathbb{E}_{(\mathbf{x},\mathbf{y})\sim\mathcal{D}}[\ell(h(\mathbf{x}),h^{\prime}(\mathbf{x}))].$
    |  | (14) |'
- en: Then the target risk $\epsilon_{\mathcal{T}}(h)$ can be bounded by
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，目标风险 $\epsilon_{\mathcal{T}}(h)$ 可以被界限为
- en: '|  | $\displaystyle{\epsilon_{\mathcal{T}}}\left(h\right)$ | $\displaystyle\leqslant{\epsilon_{\mathcal{S}}}\left(h\right)+\left[{{\epsilon_{\mathcal{S}}}\left({{h^{*}}}\right)+{\epsilon_{\mathcal{T}}}\left({{h^{*}}}\right)}\right]+\left&#124;{{\epsilon_{\mathcal{S}}}\left({h,{h^{*}}}\right)-{\epsilon_{\mathcal{T}}}\left({h,{h^{*}}}\right)}\right&#124;,$
    |  | (15) |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle{\epsilon_{\mathcal{T}}}\left(h\right)$ | $\displaystyle\leqslant{\epsilon_{\mathcal{S}}}\left(h\right)+\left[{{\epsilon_{\mathcal{S}}}\left({{h^{*}}}\right)+{\epsilon_{\mathcal{T}}}\left({{h^{*}}}\right)}\right]+\left&#124;{{\epsilon_{\mathcal{S}}}\left({h,{h^{*}}}\right)-{\epsilon_{\mathcal{T}}}\left({h,{h^{*}}}\right)}\right&#124;,$
    |  | (15) |'
- en: where $h^{*}={\arg\min}_{h\in\mathcal{H}}\left[{{\epsilon_{\mathcal{S}}}\left({{h}}\right)+{\epsilon_{\mathcal{T}}}\left({{h}}\right)}\right]$
    is the ideal joint hypothesis, $\epsilon_{ideal}={{\epsilon_{\mathcal{S}}}\left({{h^{*}}}\right)+{\epsilon_{\mathcal{T}}}\left({{h^{*}}}\right)}$
    is the ideal joint error, $\left|{{\epsilon_{\mathcal{S}}}\left({h,{h^{*}}}\right)-{\epsilon_{\mathcal{T}}}\left({h,{h^{*}}}\right)}\right|$
    is the *disparity difference* between $\mathcal{S}$ and $\mathcal{T}$.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $h^{*}={\arg\min}_{h\in\mathcal{H}}\left[{{\epsilon_{\mathcal{S}}}\left({{h}}\right)+{\epsilon_{\mathcal{T}}}\left({{h}}\right)}\right]$
    是理想的联合假设，$\epsilon_{ideal}={{\epsilon_{\mathcal{S}}}\left({{h^{*}}}\right)+{\epsilon_{\mathcal{T}}}\left({{h^{*}}}\right)}$
    是理想的联合误差，$\left|{{\epsilon_{\mathcal{S}}}\left({h,{h^{*}}}\right)-{\epsilon_{\mathcal{T}}}\left({h,{h^{*}}}\right)}\right|$
    是$\mathcal{S}$和$\mathcal{T}$之间的*差异差异*。
- en: It is a common *assumption* in domain adaptation that the ideal joint error
    ${\epsilon_{ideal}}$ shall be sufficiently small, otherwise domain adaptation
    will be infeasible, the *impossibility* theorem (Ben-David et al., [2010b](#bib.bib10)).
    The goal is reduced to bound the disparity difference. However, since the ideal
    hypothesis $h^{*}$ is unknown due to the unavailability of labeled target data,
    the disparity difference cannot be estimated directly. To this end, $\mathcal{H}\Delta\mathcal{H}$-Divergence
    (Ben-David et al., [2006](#bib.bib9), [2010a](#bib.bib8)) is proposed to measure
    the upper bound of the disparity difference.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在领域适应中，一个常见的*假设*是理想的联合误差 ${\epsilon_{ideal}}$ 应足够小，否则领域适应将不可行，这称为*不可能性*定理 (Ben-David
    等人，[2010b](#bib.bib10))。目标被简化为界定差异差异。然而，由于缺乏标记的目标数据，理想的假设 $h^{*}$ 是未知的，因此差异差异无法直接估计。为此，提出了$\mathcal{H}\Delta\mathcal{H}$-散度
    (Ben-David 等人，[2006](#bib.bib9)，[2010a](#bib.bib8)) 来衡量差异差异的上界。
- en: Definition 4 ($\mathcal{H}\Delta\mathcal{H}$-Divergence)
  id: totrans-308
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 4 ($\mathcal{H}\Delta\mathcal{H}$-散度)
- en: Define $\mathcal{H}\Delta\mathcal{H}\triangleq\{h|h=h_{1}\otimes h_{2},h_{1},h_{2}\in\mathcal{H}\}$
    as the *symmetric difference hypothesis space* of $\mathcal{H}$, where $\otimes$
    stands for the XOR operator. Then the *$\mathcal{H}\Delta\mathcal{H}$-Divergence*
    between $\mathcal{S}$ and $\mathcal{T}$ is
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 $\mathcal{H}\Delta\mathcal{H}\triangleq\{h|h=h_{1}\otimes h_{2},h_{1},h_{2}\in\mathcal{H}\}$
    为$\mathcal{H}$的*对称差假设空间*，其中 $\otimes$ 表示 XOR 操作符。那么，$\mathcal{H}\Delta\mathcal{H}$-散度在$\mathcal{S}$和$\mathcal{T}$之间为
- en: '|  | $\displaystyle d_{\mathcal{H}\Delta\mathcal{H}}(\mathcal{S},\mathcal{T})$
    | $\displaystyle\triangleq\sup_{h,h^{\prime}\in\mathcal{H}}\left&#124;{{\epsilon_{\mathcal{S}}}\left({h,{h^{\prime}}}\right)-{\epsilon_{\mathcal{T}}}\left({h,{h^{\prime}}}\right)}\right&#124;.$
    |  |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle d_{\mathcal{H}\Delta\mathcal{H}}(\mathcal{S},\mathcal{T})$
    | $\displaystyle\triangleq\sup_{h,h^{\prime}\in\mathcal{H}}\left&#124;{{\epsilon_{\mathcal{S}}}\left({h,{h^{\prime}}}\right)-{\epsilon_{\mathcal{T}}}\left({h,{h^{\prime}}}\right)}\right&#124;.$
    |  |'
- en: For binary classification problem with the $01$-loss, $\ell(y,y^{\prime})=\mathds{1}(y\neq
    y^{\prime})$, we have
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有 $01$-损失的二分类问题，$\ell(y,y^{\prime})=\mathds{1}(y\neq y^{\prime})$，我们有
- en: '|  | $\displaystyle d_{\mathcal{H}\Delta\mathcal{H}}(\mathcal{S},\mathcal{T})$
    | $\displaystyle={\sup_{\delta\in\mathcal{H}\Delta\mathcal{H}}}\left&#124;{{\mathbb{E}_{{\mathcal{S}}}}\left[{\delta{\left({\mathbf{x}}\right)}\neq
    0}\right]-{\mathbb{E}_{{\mathcal{T}}}}\left[{\delta\left({{\mathbf{x}}}\right)\neq
    0}\right]}\right&#124;.$ |  |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle d_{\mathcal{H}\Delta\mathcal{H}}(\mathcal{S},\mathcal{T})$
    | $\displaystyle={\sup_{\delta\in\mathcal{H}\Delta\mathcal{H}}}\left&#124;{{\mathbb{E}_{{\mathcal{S}}}}\left[{\delta{\left({\mathbf{x}}\right)}\neq
    0}\right]-{\mathbb{E}_{{\mathcal{T}}}}\left[{\delta\left({{\mathbf{x}}}\right)\neq
    0}\right]}\right&#124;.$ |  |'
- en: 'The main advantage of the $\mathcal{H}\Delta\mathcal{H}$-Divergence is that
    it can be estimated from *finite* unlabeled samples of source and target domains.
    However, it is generally hard to compute and optimize. Thus, it is approximated
    by training a domain discriminator $D$ that separates the source and target samples
    (Ben-David et al., [2006](#bib.bib9); Ganin and Lempitsky, [2015](#bib.bib45)).
    Assume that the family of the discriminators is rich enough, such as the multilayer
    perceptrons (MLP) that is universal approximator to any functions, to contain
    $\mathcal{H}\Delta\mathcal{H}$, i.e., $\mathcal{H}\Delta\mathcal{H}\subset\mathcal{H}_{D}$.
    The $\mathcal{H}\Delta\mathcal{H}$-Divergence can be further bounded by ${\sup_{D\in{\mathcal{H}_{D}}}}\left|{{\mathbb{E}_{{\mathcal{S}}}}\left[{D{\left({\mathbf{x}}\right)}=1}\right]+{\mathbb{E}_{{\mathcal{T}}}}\left[{D\left({{\mathbf{x}}}\right)=0}\right]}\right|$,
    which gives rise to the *domain adversarial* methods in Section [3.2.2](#S3.SS2.SSS2
    "3.2.2 Domain Adversarial Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey"). The $\mathcal{H}\Delta\mathcal{H}$-Divergence can
    also be estimated in a nonparametric way by replacing $\mathcal{H}\Delta\mathcal{H}$
    with a proper function space $\mathcal{F}$, which induces the *statistics matching*
    methods in Section [3.2.1](#S3.SS2.SSS1 "3.2.1 Statistics Matching ‣ 3.2 Domain
    Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey").'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '$\mathcal{H}\Delta\mathcal{H}$-散度的主要优点在于它可以从*有限*的源域和目标域无标签样本中估计。然而，它通常难以计算和优化。因此，通过训练一个领域判别器$D$来近似，它能够区分源域和目标样本（Ben-David等人，[2006](#bib.bib9)；Ganin和Lempitsky，[2015](#bib.bib45)）。假设判别器家族足够丰富，例如能够通用逼近任何函数的多层感知器（MLP），以包含$\mathcal{H}\Delta\mathcal{H}$，即$\mathcal{H}\Delta\mathcal{H}\subset\mathcal{H}_{D}$。$\mathcal{H}\Delta\mathcal{H}$-散度可以进一步界限为${\sup_{D\in{\mathcal{H}_{D}}}}\left|{{\mathbb{E}_{{\mathcal{S}}}}\left[{D{\left({\mathbf{x}}\right)}=1}\right]+{\mathbb{E}_{{\mathcal{T}}}}\left[{D\left({{\mathbf{x}}}\right)=0}\right]}\right|，这引出了第[3.2.2节](#S3.SS2.SSS2
    "3.2.2 Domain Adversarial Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")中的*领域对抗*方法。$\mathcal{H}\Delta\mathcal{H}$-散度还可以通过用适当的函数空间$\mathcal{F}$替换$\mathcal{H}\Delta\mathcal{H}$以非参数方式估计，这引出了第[3.2.1节](#S3.SS2.SSS1
    "3.2.1 Statistics Matching ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")中的*统计匹配*方法。'
- en: The following theorem is the earliest theory in domain adaptation, which establishes
    the generalization bound based on the $\mathcal{H}\Delta\mathcal{H}$-Divergence
    for binary classification problems.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 以下定理是领域适应中最早的理论，它基于$\mathcal{H}\Delta\mathcal{H}$-散度为二分类问题建立了泛化界限。
- en: Theorem 5 (Ben-David et al. ([2010a](#bib.bib8)))
  id: totrans-315
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理5（Ben-David等人（[2010a](#bib.bib8)））
- en: Let $\mathcal{H}$ be a binary hypothesis space of VC dimension $d$. If $\widehat{\mathcal{S}}$
    and $\widehat{\mathcal{T}}$ are samples of size $m$ each, then for any $\delta\in(0,1)$,
    with probability at least $1-\delta$, for every $h\in\mathcal{H}$,
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 设$\mathcal{H}$为VC维度为$d$的二进制假设空间。如果$\widehat{\mathcal{S}}$和$\widehat{\mathcal{T}}$是各自大小为$m$的样本，则对于任何$\delta\in(0,1)$，以至少$1-\delta$的概率，对于每个$h\in\mathcal{H}$，
- en: '|  | $\epsilon_{\mathcal{T}}(h)\leq\epsilon_{{\mathcal{S}}}(h)+d_{\mathcal{H}\Delta\mathcal{H}}({\mathcal{\widehat{\mathcal{S}}}},{\mathcal{\widehat{T}}})+\epsilon_{ideal}+4\sqrt{\frac{2d\log(2m)+\log(\frac{2}{\delta})}{m}}.$
    |  | (16) |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '|  | $\epsilon_{\mathcal{T}}(h)\leq\epsilon_{{\mathcal{S}}}(h)+d_{\mathcal{H}\Delta\mathcal{H}}({\mathcal{\widehat{\mathcal{S}}}},{\mathcal{\widehat{T}}})+\epsilon_{ideal}+4\sqrt{\frac{2d\log(2m)+\log(\frac{2}{\delta})}{m}}.$
    |  | (16) |'
- en: This bound sheds key insights into algorithm designs. However, it has the limit
    of being based on the particular $01$-loss. Thus, Mansour et al. ([2009](#bib.bib120))
    extend the domain adaptation theory to a general class of loss functions satisfying
    the symmetry and subadditivity.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 这个界限为算法设计提供了关键见解。然而，它的限制在于基于特定的$01$-损失。因此，Mansour等人（[2009](#bib.bib120)）将领域适应理论扩展到满足对称性和次加性的一般损失函数类。
- en: Theorem 6 (Mansour et al. ([2009](#bib.bib120)))
  id: totrans-319
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理6（Mansour等人（[2009](#bib.bib120)））
- en: Assume that the loss function $\ell$ is symmetric and obeys the triangle inequality,
    and define $h_{\mathcal{S}}^{*}=\arg\min_{h\in\mathcal{H}}\epsilon_{\mathcal{S}}(h)$
    and $h_{\mathcal{T}}^{*}=\arg\min_{h\in\mathcal{H}}\epsilon_{\mathcal{T}}(h)$
    as the ideal hypotheses for the source and target domains, then for every $h\in\mathcal{H}$,
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 假设损失函数$\ell$是对称的并且满足三角不等式，并定义$h_{\mathcal{S}}^{*}=\arg\min_{h\in\mathcal{H}}\epsilon_{\mathcal{S}}(h)$和$h_{\mathcal{T}}^{*}=\arg\min_{h\in\mathcal{H}}\epsilon_{\mathcal{T}}(h)$为源域和目标域的理想假设，则对于每个$h\in\mathcal{H}$，
- en: '|  | $\epsilon_{\mathcal{T}}(h)\leq\epsilon_{{\mathcal{S}}}(h,h_{\mathcal{S}}^{*})+d_{\mathcal{H}\Delta\mathcal{H}}({\mathcal{S}},{\mathcal{T}})+\epsilon,$
    |  | (17) |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '|  | $\epsilon_{\mathcal{T}}(h)\leq\epsilon_{{\mathcal{S}}}(h,h_{\mathcal{S}}^{*})+d_{\mathcal{H}\Delta\mathcal{H}}({\mathcal{S}},{\mathcal{T}})+\epsilon,$
    |  | (17) |'
- en: where $\epsilon_{{\mathcal{S}}}(h,h_{\mathcal{S}}^{*})$ stands for the source
    risk and $\epsilon=\epsilon_{{\mathcal{T}}}(h_{\mathcal{T}}^{*})+\epsilon_{{\mathcal{S}}}(h_{\mathcal{T}}^{*},h_{\mathcal{S}}^{*})$
    for the capacity to adapt. Further, let $\ell$ be bounded, $\forall(y,y^{\prime})\in\mathcal{Y}^{2},\ell(y,y^{\prime})\leq
    M$ for some $M>0$, and defined as $\ell(y,y^{\prime})=|y-y^{\prime}|^{q}$ for
    some $q$. If $\widehat{\mathcal{S}}$ and $\widehat{\mathcal{T}}$ are samples of
    size $n$ and $m$ each, with probability at least $1-\delta$, we have
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\epsilon_{{\mathcal{S}}}(h,h_{\mathcal{S}}^{*})$ 代表源风险，$\epsilon=\epsilon_{{\mathcal{T}}}(h_{\mathcal{T}}^{*})+\epsilon_{{\mathcal{S}}}(h_{\mathcal{T}}^{*},h_{\mathcal{S}}^{*})$
    代表适应能力。此外，令 $\ell$ 有界，对于任意 $(y,y^{\prime})\in\mathcal{Y}^{2}$，$\ell(y,y^{\prime})\leq
    M$ 对于某些 $M>0$，并定义为 $\ell(y,y^{\prime})=|y-y^{\prime}|^{q}$ 对于某些 $q$。如果 $\widehat{\mathcal{S}}$
    和 $\widehat{\mathcal{T}}$ 是每个大小为 $n$ 和 $m$ 的样本，以至少 $1-\delta$ 的概率，我们有
- en: '|  | $d_{\mathcal{H}\Delta\mathcal{H}}({\mathcal{S}},{\mathcal{T}})\leq d_{\mathcal{H}\Delta\mathcal{H}}(\widehat{\mathcal{S}},\widehat{\mathcal{T}})+4q(\mathfrak{R}_{n,\mathcal{S}}(\mathcal{H})+\mathfrak{R}_{m,\mathcal{T}}(\mathcal{H}))+3M\Bigg{(}\sqrt{\frac{\log\frac{4}{\delta}}{2n}}+\sqrt{\frac{\log\frac{4}{\delta}}{2m}}\Bigg{)},$
    |  | (18) |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '|  | $d_{\mathcal{H}\Delta\mathcal{H}}({\mathcal{S}},{\mathcal{T}})\leq d_{\mathcal{H}\Delta\mathcal{H}}(\widehat{\mathcal{S}},\widehat{\mathcal{T}})+4q(\mathfrak{R}_{n,\mathcal{S}}(\mathcal{H})+\mathfrak{R}_{m,\mathcal{T}}(\mathcal{H}))+3M\Bigg{(}\sqrt{\frac{\log\frac{4}{\delta}}{2n}}+\sqrt{\frac{\log\frac{4}{\delta}}{2m}}\Bigg{)},$
    |  | (18) |'
- en: where $\mathfrak{R}_{n,\mathcal{D}}$ is the expected Rademacher Complexity (Bartlett
    and Mendelson, [2002](#bib.bib6)) with respect to distribution $\mathcal{D}$ and
    sample size $n$.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathfrak{R}_{n,\mathcal{D}}$ 是相对于分布 $\mathcal{D}$ 和样本大小 $n$ 的期望 Rademacher
    复杂度（Bartlett 和 Mendelson，[2002](#bib.bib6)）。
- en: Note that the $\mathcal{H}\Delta\mathcal{H}$-Divergence bounds are still *loose*
    since the supremum is taken over both $h^{\prime}\in\mathcal{H}$ and $h\in\mathcal{H}$.
    Observing that $h$ is known as the source classifier, the Disparity Discrepancy
    (Zhang et al., [2019c](#bib.bib204)) provides a tighter bound by computing directly
    on $\mathcal{H}$.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于上确界是针对 $h^{\prime}\in\mathcal{H}$ 和 $h\in\mathcal{H}$ 取的，所以 $\mathcal{H}\Delta\mathcal{H}$-散度界限仍然是*松弛*的。观察到
    $h$ 被称为源分类器，差异错配（Zhang 等人，[2019c](#bib.bib204)）通过直接在 $\mathcal{H}$ 上计算提供了一个更紧的界限。
- en: Definition 7 (Disparity Discrepancy)
  id: totrans-326
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 7（差异错配）
- en: Given a binary hypothesis space $\mathcal{H}$ and a *specific hypothesis* $h\!\in\!\mathcal{H}$,
    the *Disparity Discrepancy* induced by $h^{\prime}\in\mathcal{H}$ is defined by
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个二分类假设空间 $\mathcal{H}$ 和一个*特定假设* $h\!\in\!\mathcal{H}$，由 $h^{\prime}\in\mathcal{H}$
    引起的*差异错配* 定义为
- en: '|  | $d_{h,\mathcal{H}}(\mathcal{S},\mathcal{T})=\sup_{h^{\prime}\in\mathcal{H}}\left(\mathbb{E}_{\mathcal{T}}\mathds{1}[h^{\prime}\neq
    h]-\mathbb{E}_{\mathcal{S}}\mathds{1}[h^{\prime}\neq h]\right)$ |  | (19) |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '|  | $d_{h,\mathcal{H}}(\mathcal{S},\mathcal{T})=\sup_{h^{\prime}\in\mathcal{H}}\left(\mathbb{E}_{\mathcal{T}}\mathds{1}[h^{\prime}\neq
    h]-\mathbb{E}_{\mathcal{S}}\mathds{1}[h^{\prime}\neq h]\right)$ |  | (19) |'
- en: Since the supremum is only take over $h^{\prime}\in\mathcal{H}$, estimating
    and minimizing the disparity discrepancy jointly through a minimax game can be
    done much more easily. The disparity discrepancy can well measure the distribution
    shift and yields a tighter generalization bound.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 由于上确界仅针对 $h^{\prime}\in\mathcal{H}$ 进行，因此通过极小极大博弈联合估计和最小化差异错配要容易得多。差异错配可以很好地衡量分布变化，并提供更紧的泛化界限。
- en: Theorem 8 (Zhang et al. ([2019c](#bib.bib204)))
  id: totrans-330
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 8（Zhang 等人（[2019c](#bib.bib204)））
- en: Let $\widehat{\mathcal{S}}$ and $\widehat{\mathcal{T}}$ be samples of size $n$
    and $m$ each. For any $\delta>0$ and every binary classifier $h\in\mathcal{H}$,
    with probability at least $1-3\delta$, we have
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 让 $\widehat{\mathcal{S}}$ 和 $\widehat{\mathcal{T}}$ 为每个大小为 $n$ 和 $m$ 的样本。对于任意
    $\delta>0$ 和每个二分类器 $h\in\mathcal{H}$，以至少 $1-3\delta$ 的概率，我们有
- en: '|  | $\displaystyle\epsilon_{\mathcal{T}}(h)$ | $\displaystyle\leq\epsilon_{\widehat{\mathcal{S}}}(h)+d_{h,\mathcal{H}}(\widehat{\mathcal{S}},\widehat{\mathcal{T}})+\epsilon_{ideal}+2\mathfrak{R}_{n,\mathcal{S}}(\mathcal{H})$
    |  | (20) |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\epsilon_{\mathcal{T}}(h)$ | $\displaystyle\leq\epsilon_{\widehat{\mathcal{S}}}(h)+d_{h,\mathcal{H}}(\widehat{\mathcal{S}},\widehat{\mathcal{T}})+\epsilon_{ideal}+2\mathfrak{R}_{n,\mathcal{S}}(\mathcal{H})$
    |  | (20) |'
- en: '|  |  | $\displaystyle+2\mathfrak{R}_{n,\mathcal{S}}(\mathcal{H}\Delta\mathcal{H})+2\sqrt{\frac{\log\frac{2}{\delta}}{2n}}+2\mathfrak{R}_{m,\mathcal{T}}(\mathcal{H}\Delta\mathcal{H})+\sqrt{\frac{\log\frac{2}{\delta}}{2m}}.$
    |  |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle+2\mathfrak{R}_{n,\mathcal{S}}(\mathcal{H}\Delta\mathcal{H})+2\sqrt{\frac{\log\frac{2}{\delta}}{2n}}+2\mathfrak{R}_{m,\mathcal{T}}(\mathcal{H}\Delta\mathcal{H})+\sqrt{\frac{\log\frac{2}{\delta}}{2m}}.$
    |  |'
- en: The disparity discrepancy can be further extended to the *multiclass* classification
    problem with hypothesis space $\mathcal{F}$ of scoring functions $f:\mathcal{X}\times\mathcal{Y}\rightarrow\mathbb{R}$
    and margin loss, which is going beyond existing bounds and closer to the choices
    for real tasks (Zhang et al., [2019c](#bib.bib204)).
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 这种差异不一致性可以进一步扩展到具有假设空间 $\mathcal{F}$ 的 *多类别* 分类问题，其中 $f:\mathcal{X}\times\mathcal{Y}\rightarrow\mathbb{R}$
    是评分函数，边际损失超出了现有的界限，更接近真实任务的选择（Zhang 等，[2019c](#bib.bib204)）。
- en: Definition 9 (Margin Disparity Discrepancy)
  id: totrans-335
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 9（边际差异不一致性）
- en: Given a scoring hypothesis space $\mathcal{F}$, denote the margin of a real
    hypothesis $f$ at a labeled example $(x,y)$ as $\rho_{f}(x,y)\triangleq\frac{1}{2}(f(x,y)-\max_{y^{\prime}\neq
    y}f(x,y^{\prime}))$, the labeling function induced by $f$ as $h_{f}:x\mapsto\arg\max_{y\in\mathcal{Y}}f(x,y)$,
    and the margin loss as
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个评分假设空间 $\mathcal{F}$，将真实假设 $f$ 在标记示例 $(x,y)$ 处的边际定义为 $\rho_{f}(x,y)\triangleq\frac{1}{2}(f(x,y)-\max_{y^{\prime}\neq
    y}f(x,y^{\prime}))$，由 $f$ 引起的标记函数为 $h_{f}:x\mapsto\arg\max_{y\in\mathcal{Y}}f(x,y)$，边际损失为
- en: '|  | <math   alttext="\Phi_{\rho}(x)\triangleq\begin{cases}0&amp;\rho\leq{x}\\
    1-x/\rho&amp;0\leq{x}\leq\rho\\'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\Phi_{\rho}(x)\triangleq\begin{cases}0&amp;\rho\leq{x}\\
    1-x/\rho&amp;0\leq{x}\leq\rho\\'
- en: 1&amp;{x}\leq 0\\
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 1&amp;{x}\leq 0\\
- en: \end{cases}," display="block"><semantics ><mrow ><mrow  ><mrow ><msub ><mi mathvariant="normal"
    >Φ</mi><mi  >ρ</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"
    >(</mo><mi >x</mi><mo stretchy="false" >)</mo></mrow></mrow><mo >≜</mo><mrow  ><mo
    >{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"  ><mtr
    ><mtd columnalign="left"  ><mn >0</mn></mtd><mtd columnalign="left"  ><mrow ><mi
    >ρ</mi><mo  >≤</mo><mi >x</mi></mrow></mtd></mtr><mtr ><mtd columnalign="left"  ><mrow
    ><mn >1</mn><mo  >−</mo><mrow ><mi >x</mi><mo >/</mo><mi >ρ</mi></mrow></mrow></mtd><mtd
    columnalign="left"  ><mrow ><mn >0</mn><mo  >≤</mo><mi >x</mi><mo >≤</mo><mi  >ρ</mi></mrow></mtd></mtr><mtr
    ><mtd columnalign="left"  ><mn >1</mn></mtd><mtd columnalign="left"  ><mrow ><mi
    >x</mi><mo  >≤</mo><mn >0</mn></mrow></mtd></mtr></mtable></mrow></mrow><mo >,</mo></mrow><annotation-xml
    encoding="MathML-Content" ><apply ><ci  >≜</ci><apply ><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >Φ</ci><ci  >𝜌</ci></apply><ci >𝑥</ci></apply><apply ><csymbol
    cd="latexml"  >cases</csymbol><cn type="integer"  >0</cn><apply ><ci >𝜌</ci><ci  >𝑥</ci></apply><apply
    ><cn type="integer" >1</cn><apply ><ci >𝑥</ci><ci >𝜌</ci></apply></apply><apply
    ><apply  ><cn type="integer"  >0</cn><ci >𝑥</ci></apply><apply ><ci >𝜌</ci></apply></apply><cn
    type="integer" >1</cn><apply  ><ci >𝑥</ci><cn type="integer" >0</cn></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\Phi_{\rho}(x)\triangleq\begin{cases}0&\rho\leq{x}\\
    1-x/\rho&0\leq{x}\leq\rho\\ 1&{x}\leq 0\\ \end{cases},</annotation></semantics></math>
    |  | (21) |
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: \end{cases}," display="block"><semantics ><mrow ><mrow  ><mrow ><msub ><mi mathvariant="normal"
    >Φ</mi><mi  >ρ</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"
    >(</mo><mi >x</mi><mo stretchy="false" >)</mo></mrow></mrow><mo >≜</mo><mrow  ><mo
    >{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"  ><mtr
    ><mtd columnalign="left"  ><mn >0</mn></mtd><mtd columnalign="left"  ><mrow ><mi
    >ρ</mi><mo  >≤</mo><mi >x</mi></mrow></mtd></mtr><mtr ><mtd columnalign="left"  ><mrow
    ><mn >1</mn><mo  >−</mo><mrow ><mi >x</mi><mo >/</mo><mi >ρ</mi></mrow></mrow></mtd><mtd
    columnalign="left"  ><mrow ><mn >0</mn><mo  >≤</mo><mi >x</mi><mo >≤</mo><mi  >ρ</mi></mrow></mtd></mtr><mtr
    ><mtd columnalign="left"  ><mn >1</mn></mtd><mtd columnalign="left"  ><mrow ><mi
    >x</mi><mo  >≤</mo><mn >0</mn></mrow></mtd></mtr></mtable></mrow></mrow><mo >,</mo></mrow><annotation-xml
    encoding="MathML-Content" ><apply ><ci  >≜</ci><apply ><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >Φ</ci><ci  >𝜌</ci></apply><ci >𝑥</ci></apply><apply ><csymbol
    cd="latexml"  >cases</csymbol><cn type="integer"  >0</cn><apply ><ci >𝜌</ci><ci  >𝑥</ci></apply><apply
    ><cn type="integer" >1</cn><apply ><ci >𝑥</ci><ci >𝜌</ci></apply></apply><apply
    ><apply  ><cn type="integer"  >0</cn><ci >𝑥</ci></apply><apply ><ci >𝜌</ci></apply></apply><cn
    type="integer" >1</cn><apply  ><ci >𝑥</ci><cn type="integer" >0</cn></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\Phi_{\rho}(x)\triangleq\begin{cases}0&\rho\leq{x}\\
    1-x/\rho&0\leq{x}\leq\rho\\ 1&{x}\leq 0\\ \end{cases},</annotation></semantics></math>
    |  | (21) |
- en: then the *margin disparity* between $f$ and $f^{\prime}$ on distribution $\mathcal{D}$
    is
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 那么在分布 $\mathcal{D}$ 上，$f$ 和 $f^{\prime}$ 之间的 *边际差异* 为
- en: '|  | $\epsilon_{\mathcal{D}}^{(\rho)}(f^{\prime},f)=\mathbb{E}_{(x,y)\sim\mathcal{D}}[\Phi_{\rho}(\rho_{f^{\prime}}(x,h_{f}(x))].$
    |  | (22) |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '|  | $\epsilon_{\mathcal{D}}^{(\rho)}(f^{\prime},f)=\mathbb{E}_{(x,y)\sim\mathcal{D}}[\Phi_{\rho}(\rho_{f^{\prime}}(x,h_{f}(x))].$
    |  | (22) |'
- en: Given a *specific hypothesis* $f\!\in\!\mathcal{F}$, the *Margin Disparity Discrepancy*
    is defined by
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个 *特定假设* $f\!\in\!\mathcal{F}$，*边际差异失配* 定义为
- en: '|  | $d_{f,\mathcal{F}}^{(\rho)}(\mathcal{S},\mathcal{T})=\sup_{f^{\prime}\in\mathcal{F}}[\epsilon_{\mathcal{T}}^{(\rho)}(f^{\prime},f)-\epsilon_{\mathcal{S}}^{(\rho)}(f^{\prime},f)].$
    |  | (23) |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '|  | $d_{f,\mathcal{F}}^{(\rho)}(\mathcal{S},\mathcal{T})=\sup_{f^{\prime}\in\mathcal{F}}[\epsilon_{\mathcal{T}}^{(\rho)}(f^{\prime},f)-\epsilon_{\mathcal{S}}^{(\rho)}(f^{\prime},f)].$
    |  | (23) |'
- en: 'Note that the margin disparity satisfies the nonnegativity and subadditivity,
    but not the symmetry. Thus Theorem [6](#Thmtheorem6 "Theorem 6 (Mansour et al.
    (2009)) ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey") cannot apply here and a new generalization bound is derived.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，边际差异满足非负性和子加性，但不满足对称性。因此定理 [6](#Thmtheorem6 "定理 6 (Mansour et al. (2009))
    ‣ 3.2 域适应 ‣ 3 适应 ‣ 深度学习中的可迁移性：综述") 不能在这里应用，需推导出一个新的泛化界限。
- en: Theorem 10 (Zhang et al. ([2019c](#bib.bib204)))
  id: totrans-345
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 10 (Zhang et al. ([2019c](#bib.bib204)))
- en: 'Given the same settings with Definition [9](#Thmtheorem9 "Definition 9 (Margin
    Disparity Discrepancy) ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey"), for any $\delta>0$, with probability at least $1-3\delta$,
    the following *margin bound* holds for all scoring functions $f\in\mathcal{F}$,'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在与定义 [9](#Thmtheorem9 "定义 9 (边际差异失配) ‣ 3.2 域适应 ‣ 3 适应 ‣ 深度学习中的可迁移性：综述") 相同的设置下，对于任意
    $\delta>0$，以至少 $1-3\delta$ 的概率，以下 *边际界限* 对所有评分函数 $f\in\mathcal{F}$ 成立，
- en: '|  | $\displaystyle\epsilon_{\mathcal{T}}(f)\leq$ | $\displaystyle\ \epsilon_{\widehat{\mathcal{S}}}^{(\rho)}(f)+d_{f,\mathcal{F}}^{(\rho)}(\mathcal{\widehat{\mathcal{S}}},\mathcal{\widehat{T}})+\epsilon_{ideal}+\frac{2k^{2}}{\rho}{\mathfrak{R}_{n,\mathcal{S}}}(\Pi_{1}\mathcal{F})$
    |  | (24) |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\epsilon_{\mathcal{T}}(f)\leq$ | $\displaystyle\ \epsilon_{\widehat{\mathcal{S}}}^{(\rho)}(f)+d_{f,\mathcal{F}}^{(\rho)}(\mathcal{\widehat{\mathcal{S}}},\mathcal{\widehat{T}})+\epsilon_{ideal}+\frac{2k^{2}}{\rho}{\mathfrak{R}_{n,\mathcal{S}}}(\Pi_{1}\mathcal{F})$
    |  | (24) |'
- en: '|  | $\displaystyle+$ | $\displaystyle\ \frac{k}{\rho}{\mathfrak{R}_{n,\mathcal{S}}}(\Pi_{\mathcal{H}}\mathcal{F})+2\sqrt{\frac{\log\frac{2}{\delta}}{2n}}+\frac{k}{\rho}{\mathfrak{R}_{m,\mathcal{T}}}(\Pi_{\mathcal{H}}\mathcal{F})+\sqrt{\frac{\log\frac{2}{\delta}}{2m}},$
    |  |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle+$ | $\displaystyle\ \frac{k}{\rho}{\mathfrak{R}_{n,\mathcal{S}}}(\Pi_{\mathcal{H}}\mathcal{F})+2\sqrt{\frac{\log\frac{2}{\delta}}{2n}}+\frac{k}{\rho}{\mathfrak{R}_{m,\mathcal{T}}}(\Pi_{\mathcal{H}}\mathcal{F})+\sqrt{\frac{\log\frac{2}{\delta}}{2m}},$
    |  |'
- en: where $\Pi_{\mathcal{H}}\mathcal{F}\triangleq\{x\mapsto f(x,h(x))|h\in\mathcal{H},f\in\mathcal{F}\}$
    is the scoring version of the symmetric hypothesis space $\mathcal{H}\Delta\mathcal{H}$,
    $\Pi_{1}\mathcal{F}\triangleq\{x\mapsto f(x,y)|y\in\mathcal{Y},f\in\mathcal{F}\}$
    and $\epsilon_{ideal}=\min_{f^{*}\in\mathcal{F}}\{\mathrm{err}_{\mathcal{S}}^{(\rho)}(f^{*})+\mathrm{err}_{\mathcal{T}}^{(\rho)}(f^{*})\}$
    is the ideal joint error in terms of margin loss, $k$ is the number of classes.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\Pi_{\mathcal{H}}\mathcal{F}\triangleq\{x\mapsto f(x,h(x))|h\in\mathcal{H},f\in\mathcal{F}\}$
    是对称假设空间 $\mathcal{H}\Delta\mathcal{H}$ 的评分版本，$\Pi_{1}\mathcal{F}\triangleq\{x\mapsto
    f(x,y)|y\in\mathcal{Y},f\in\mathcal{F}\}$，以及 $\epsilon_{ideal}=\min_{f^{*}\in\mathcal{F}}\{\mathrm{err}_{\mathcal{S}}^{(\rho)}(f^{*})+\mathrm{err}_{\mathcal{T}}^{(\rho)}(f^{*})\}$
    是以边际损失为标准的理想联合误差，$k$ 是类别数。
- en: 'This margin bound suggests that a proper margin $\rho$ could yield better generalization
    on the target domain. Theorems [8](#Thmtheorem8 "Theorem 8 (Zhang et al. (2019c))
    ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")
    and [10](#Thmtheorem10 "Theorem 10 (Zhang et al. (2019c)) ‣ 3.2 Domain Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey") together form the
    theoretical basis of the *hypothesis adversarial* methods in Section [3.2.3](#S3.SS2.SSS3
    "3.2.3 Hypothesis Adversarial Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey"). Note that the supremum in both
    the $\mathcal{H}\Delta\mathcal{H}$-Divergence and Disparity Discrepancy will become
    meaningless, when the allowed hypothesis space $\mathcal{H}$ is too large, which
    is common in deep neural networks. Thus, pre-training the deep neural networks
    on large-scale upstream data to decrease the allowed hypotheses is still necessary
    for the domain adversarial methods and hypothesis adversarial methods.'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 这一边际界限表明，适当的边际$\rho$可能会在目标领域上带来更好的推广。定理[8](#Thmtheorem8 "定理 8 (Zhang等人 (2019c))
    ‣ 3.2 领域适应 ‣ 3 适应 ‣ 深度学习中的迁移性调查")和[10](#Thmtheorem10 "定理 10 (Zhang等人 (2019c))
    ‣ 3.2 领域适应 ‣ 3 适应 ‣ 深度学习中的迁移性调查")共同构成了[3.2.3](#S3.SS2.SSS3 "3.2.3 假设对抗学习 ‣ 3.2
    领域适应 ‣ 3 适应 ‣ 深度学习中的迁移性调查")节中*假设对抗*方法的理论基础。请注意，当允许的假设空间$\mathcal{H}$过大时，$\mathcal{H}\Delta\mathcal{H}$-散度和差异差距中的上确界将变得毫无意义，这在深度神经网络中很常见。因此，在大规模上游数据上预训练深度神经网络，以减少允许的假设，对于领域对抗方法和假设对抗方法仍然是必要的。
- en: 'A final important note is that while there are no theoretical guarantees for
    some well-established methods, they have also achieved quite strong performance
    in practice, such as the *domain translation* methods in Section [3.2.4](#S3.SS2.SSS4
    "3.2.4 Domain Translation ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey") and the *semi-supervised learning* methods in Section
    [3.2.5](#S3.SS2.SSS5 "3.2.5 Semi-Supervised Learning ‣ 3.2 Domain Adaptation ‣
    3 Adaptation ‣ Transferability in Deep Learning: A Survey"). Figure [18](#S3.F18
    "Figure 18 ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey") highlights the cornerstones of domain adaptation methods in deep learning,
    which rely on the reuse of transferability gained in pre-trained deep models.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的补充说明是，尽管某些已建立的方法没有理论上的保证，但它们在实践中也表现出相当强的性能，比如[3.2.4](#S3.SS2.SSS4 "3.2.4
    领域翻译 ‣ 3.2 领域适应 ‣ 3 适应 ‣ 深度学习中的迁移性调查")节中的*领域翻译*方法和[3.2.5](#S3.SS2.SSS5 "3.2.5
    半监督学习 ‣ 3.2 领域适应 ‣ 3 适应 ‣ 深度学习中的迁移性调查")节中的*半监督学习*方法。图[18](#S3.F18 "图 18 ‣ 3.2
    领域适应 ‣ 3 适应 ‣ 深度学习中的迁移性调查")突出了深度学习中领域适应方法的基石，这些方法依赖于在预训练深度模型中获得的迁移性。
- en: '![Refer to caption](img/9c80fa5d148b1d29830a1ffb659e24e0.png)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/9c80fa5d148b1d29830a1ffb659e24e0.png)'
- en: 'Figure 18: The cornerstones of domain adaptation methods in deep learning.'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18：深度学习中领域适应方法的基石。
- en: 3.2.1 Statistics Matching
  id: totrans-354
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 统计匹配
- en: We have introduced several seminal theories on the generalization bounds for
    domain adaptation, which are all based on the *hypothesis-induced* distribution
    distances. These distances are less intuitive because they rely on unknown hypotheses
    and cannot be computed before learning the hypotheses. In this section, we first
    introduce another family of metrics on the space of *probability measures* well-studied
    in probability theory, which provide interpretable and complementary properties
    to the hypothesis-induced distribution distances and relate closely to a large
    set of domain adaptation algorithms (Long et al., [2015](#bib.bib112), [2017](#bib.bib114)).
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了几种关于领域适应的推广界限的开创性理论，这些理论都基于*假设诱导*的分布距离。这些距离不够直观，因为它们依赖于未知的假设，并且在学习假设之前无法计算。在本节中，我们首先介绍另一类在概率论中研究较多的*概率测度*空间上的度量，这些度量提供了对假设诱导分布距离的可解释和互补的性质，并与大量领域适应算法（Long等人，[2015](#bib.bib112)，[2017](#bib.bib114)）密切相关。
- en: Definition 11 (Maximum Mean Discrepancy)
  id: totrans-356
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 11（最大均值差异）
- en: Given two probability distributions $\mathcal{S}$ and $\mathcal{T}$ on a measurable
    space $\mathbf{X}$, the *integral probability metric* (Redko et al., [2020](#bib.bib140))
    is defined as $d_{\mathcal{F}}(\mathcal{S},\mathcal{T})\triangleq\sup_{f\in\mathcal{F}}\big{|}\mathbb{E}_{\mathbf{x}\sim\mathcal{S}}[f(\mathbf{x})]-\mathbb{E}_{\mathbf{x}\sim\mathcal{T}}[f(\mathbf{x})]\big{|}$,
    where $\mathcal{F}$ is a class of bounded functions on $\mathbf{X}$. Sriperumbudur
    et al. ([2010](#bib.bib163)) further restrict $\mathcal{F}$ as the unit ball in
    Reproducing Kernel Hilbert Space (RKHS) $\mathcal{H}_{k}$ endowed with a *characteristic*
    kernel $k$, $\mathcal{F}=\{f\in\mathcal{H}_{k}:||f||_{\mathcal{H}_{k}}\leq 1\}$,
    leading to the *maximum mean discrepancy (MMD)* (Gretton et al., [2012a](#bib.bib57)),
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 给定两个在可测空间$\mathbf{X}$上的概率分布$\mathcal{S}$和$\mathcal{T}$，*积分概率度量*（Redko 等人，[2020](#bib.bib140)）定义为$d_{\mathcal{F}}(\mathcal{S},\mathcal{T})\triangleq\sup_{f\in\mathcal{F}}\big{|}\mathbb{E}_{\mathbf{x}\sim\mathcal{S}}[f(\mathbf{x})]-\mathbb{E}_{\mathbf{x}\sim\mathcal{T}}[f(\mathbf{x})]\big{|}$，其中$\mathcal{F}$是$\mathbf{X}$上的有界函数类。Sriperumbudur
    等人 ([2010](#bib.bib163)) 进一步将$\mathcal{F}$限制为赋予*特征*核$k$的再生核希尔伯特空间（RKHS）$\mathcal{H}_{k}$中的单位球体，$\mathcal{F}=\{f\in\mathcal{H}_{k}:||f||_{\mathcal{H}_{k}}\leq
    1\}$，从而得到*最大均值差异（MMD）*（Gretton 等人，[2012a](#bib.bib57)），
- en: '|  | $d_{\emph{MMD}}^{2}(\mathcal{S},\mathcal{T})=\big{\&#124;}\mathbb{E}_{\mathbf{x}\sim\mathcal{S}}[\phi(\mathbf{x})]-\mathbb{E}_{\mathbf{x}\sim\mathcal{T}}[\phi(\mathbf{x})]\big{\&#124;}_{\mathcal{H}_{k}}^{2},$
    |  | (25) |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '|  | $d_{\emph{MMD}}^{2}(\mathcal{S},\mathcal{T})=\big{\|}\mathbb{E}_{\mathbf{x}\sim\mathcal{S}}[\phi(\mathbf{x})]-\mathbb{E}_{\mathbf{x}\sim\mathcal{T}}[\phi(\mathbf{x})]\big{\|}_{\mathcal{H}_{k}}^{2},$
    |  | (25) |'
- en: where $\phi(x)$ is a feature map associated with kernel $k$ such that $k(\mathbf{x},\mathbf{x}^{\prime})=\left\langle\phi(\mathbf{x}),\phi(\mathbf{x}^{\prime})\right\rangle$.
    It can be proved from probability theory that $\mathcal{S}=\mathcal{T}$ if and
    only if $d_{\mathcal{F}}(\mathcal{S},\mathcal{T})=0$ or $d_{\emph{MMD}}^{2}(\mathcal{S},\mathcal{T})=0$.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\phi(x)$是与核$k$相关的特征映射，使得$k(\mathbf{x},\mathbf{x}^{\prime})=\left\langle\phi(\mathbf{x}),\phi(\mathbf{x}^{\prime})\right\rangle$。从概率理论中可以证明，当且仅当$d_{\mathcal{F}}(\mathcal{S},\mathcal{T})=0$或$d_{\emph{MMD}}^{2}(\mathcal{S},\mathcal{T})=0$时，$\mathcal{S}=\mathcal{T}$。
- en: Theorem 12 (Redko et al. ([2020](#bib.bib140)))
  id: totrans-360
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 12 (Redko 等人 ([2020](#bib.bib140)))
- en: 'Given the same settings with Definition [11](#Thmtheorem11 "Definition 11 (Maximum
    Mean Discrepancy) ‣ 3.2.1 Statistics Matching ‣ 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey"), let $\ell$ be a convex loss function
    with a parametric form $\ell(y,y^{\prime})=|y-y^{\prime}|^{q}$ for some $q$. Then
    for any $\delta>0$, with probability at least $1-\delta$, the following bound
    holds for all $h\in\mathcal{F}$,'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 在与定义[11](#Thmtheorem11 "定义 11 (最大均值差异) ‣ 3.2.1 统计匹配 ‣ 3.2 域适应 ‣ 3 适应 ‣ 深度学习中的可迁移性：综述")相同的设置下，设$\ell$为一个具有参数形式$\ell(y,y^{\prime})=|y-y^{\prime}|^{q}$的凸损失函数，其中$q$为某个值。则对于任何$\delta>0$，以至少$1-\delta$的概率，以下界限对所有$h\in\mathcal{F}$成立，
- en: '|  | $\displaystyle\epsilon_{\mathcal{T}}(h)$ | $\displaystyle\leq\epsilon_{\mathcal{S}}(h)+d_{\emph{MMD}}(\mathcal{\widehat{\mathcal{S}}},\mathcal{\widehat{T}})+\epsilon_{ideal}$
    |  | (26) |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\epsilon_{\mathcal{T}}(h)$ | $\displaystyle\leq\epsilon_{\mathcal{S}}(h)+d_{\emph{MMD}}(\mathcal{\widehat{\mathcal{S}}},\mathcal{\widehat{T}})+\epsilon_{ideal}$
    |  | (26) |'
- en: '|  |  | $\displaystyle+\frac{2}{n}\mathbb{E}_{\mathbf{x}\sim\mathcal{S}}[\sqrt{\mathrm{tr}(\mathbf{K}_{\mathcal{S}})}]+\frac{2}{m}\mathbb{E}_{\mathbf{x}\sim\mathcal{T}}[\sqrt{\mathrm{tr}(\mathbf{K}_{\mathcal{T}})}]+\sqrt{\frac{\log\frac{2}{\delta}}{2n}}+\sqrt{\frac{\log\frac{2}{\delta}}{2m}},$
    |  |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle+\frac{2}{n}\mathbb{E}_{\mathbf{x}\sim\mathcal{S}}[\sqrt{\mathrm{tr}(\mathbf{K}_{\mathcal{S}})}]+\frac{2}{m}\mathbb{E}_{\mathbf{x}\sim\mathcal{T}}[\sqrt{\mathrm{tr}(\mathbf{K}_{\mathcal{T}})}]+\sqrt{\frac{\log\frac{2}{\delta}}{2n}}+\sqrt{\frac{\log\frac{2}{\delta}}{2m}},$
    |  |'
- en: where $\mathbf{K}_{\mathcal{S}}$ and $\mathbf{K}_{\mathcal{T}}$ are the kernel
    matrices computed on samples from $\mathcal{S}$ and $\mathcal{T}$, respectively.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathbf{K}_{\mathcal{S}}$和$\mathbf{K}_{\mathcal{T}}$是分别在样本$\mathcal{S}$和$\mathcal{T}$上计算的核矩阵。
- en: This bound has several advantages compared to previous theories. First, it is
    *hypothesis-free* and does not require estimating hypotheses to measure the distribution
    distance. Second, the complexity term does not depend on the Vapnik-Chervonenkis
    dimension. Third, the unbiased estimate of MMD can be computed in linear time.
    Fourth, minimizing MMD has a nice interpretation of *statistics matching* in the
    probability space. These advantages make the bound particularly useful to underpin
    several seminal algorithms.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 与先前理论相比，这个界限具有几个优点。首先，它是*无假设*的，不需要估计假设来测量分布距离。其次，复杂性项不依赖于 Vapnik-Chervonenkis
    维度。第三，MMD 的无偏估计可以在线性时间内计算。第四，最小化 MMD 在概率空间中有一个很好的*统计匹配*解释。这些优点使得该界限特别有用，可以支持几个开创性的算法。
- en: 'Deep Domain Confusion (DDC) (Tzeng et al., [2014](#bib.bib174)) applies MMD
    with a linear kernel to a single feature layer of the deep network, yet it has
    limited power for closing the domain gap since linear kernel is not characteristic
    and cannot ensure MMD to be a probability metric. Thereby, Deep Adaptation Network
    (DAN) (Long et al., [2015](#bib.bib112), [2019](#bib.bib116)) introduces the multiple-kernel
    variant of MMD (MK-MMD) (Gretton et al., [2012b](#bib.bib58), [a](#bib.bib57))
    to measure the domain relatedness, employing a convex combination of multiple
    characteristic kernels such as Gaussian kernel to make the function space $\mathcal{F}$
    rich enough and enhance the distinguishing power of MK-MMD. Besides, as shown
    in Figure [19](#S3.F19 "Figure 19 ‣ 3.2.1 Statistics Matching ‣ 3.2 Domain Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"), multiple domain-specific
    layers are adapted by MK-MMD, which enables learning transferable features for
    domain adaptation.'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: Deep Domain Confusion (DDC) (Tzeng et al., [2014](#bib.bib174)) 在深度网络的单个特征层上应用
    MMD 及线性核，但由于线性核缺乏特征性，无法确保 MMD 是一个概率度量，因此其缩小领域差距的能力有限。因此，Deep Adaptation Network
    (DAN) (Long et al., [2015](#bib.bib112), [2019](#bib.bib116)) 引入了 MMD 的多核变体 (MK-MMD)
    (Gretton et al., [2012b](#bib.bib58), [a](#bib.bib57)) 来测量领域相关性，采用多种特征核的凸组合，如高斯核，以丰富函数空间
    $\mathcal{F}$ 并增强 MK-MMD 的区分能力。此外，如图 [19](#S3.F19 "图 19 ‣ 3.2.1 统计匹配 ‣ 3.2 域适应
    ‣ 3 适应 ‣ 深度学习中的可迁移性：综述") 所示，通过 MK-MMD 调整多个领域特定层，从而使学习到的特征可以用于领域适应。
- en: '![Refer to caption](img/76edbd0ec585a41eaeb5f900c6fc3c61.png)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/76edbd0ec585a41eaeb5f900c6fc3c61.png)'
- en: 'Figure 19: The cornerstone methods of statistics matching: (a) DAN adapts the
    *marginal* distributions of activations in multiple task-specific layers with
    MK-MMD. (b) JAN adapts the *joint* distributions of the feature activations and
    classification predictions with JMMD.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '图 19: 统计匹配的核心方法：（a）DAN 使用 MK-MMD 调整多个任务特定层的*边际*激活分布。（b）JAN 使用 JMMD 调整特征激活和分类预测的*联合*分布。'
- en: DAN mainly reduces the shift in the feature distribution and ignores that in
    the label distribution. Take AlexNet as example, the feature distribution shift
    mainly exists in layers $fc6$ and $fc7$ while the label distribution shift mainly
    exists in layer $fc8$. Joint Adaptation Network (JAN) (Long et al., [2017](#bib.bib114))
    proposes Joint Maximum Mean Discrepancy (JMMD) to measure the shift in joint distributions
    $P(\mathbf{X}^{s},\mathbf{Y}^{s})$ and $Q(\mathbf{X}^{t},\mathbf{Y}^{t})$. Denoting
    the activations of adapted layers $\mathcal{L}$ as $\{(\mathbf{z}_{i}^{s1},\dots,\mathbf{z}_{i}^{s|\mathcal{L}|})\}_{i=1}^{n}$
    and $\{(\mathbf{z}_{j}^{t1},\dots,\mathbf{z}_{j}^{t|\mathcal{L}|})\}_{j=1}^{m}$,
    JMMD is defined as
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: DAN 主要减少特征分布的变化，而忽略了标签分布的变化。以 AlexNet 为例，特征分布变化主要存在于 $fc6$ 和 $fc7$ 层，而标签分布变化主要存在于
    $fc8$ 层。Joint Adaptation Network (JAN) (Long et al., [2017](#bib.bib114)) 提出了
    Joint Maximum Mean Discrepancy (JMMD) 来测量联合分布 $P(\mathbf{X}^{s},\mathbf{Y}^{s})$
    和 $Q(\mathbf{X}^{t},\mathbf{Y}^{t})$ 的变化。将适应后的层 $\mathcal{L}$ 的激活表示为 $\{(\mathbf{z}_{i}^{s1},\dots,\mathbf{z}_{i}^{s|\mathcal{L}|})\}_{i=1}^{n}$
    和 $\{(\mathbf{z}_{j}^{t1},\dots,\mathbf{z}_{j}^{t|\mathcal{L}|})\}_{j=1}^{m}$，JMMD
    定义为
- en: '|  | $d_{\text{JMMD}}^{2}(\widehat{\mathcal{S}},\widehat{\mathcal{T}})=\Big{\&#124;}\mathbb{E}_{i\in[n]}\otimes_{l\in\mathcal{L}}\phi^{l}(\mathbf{z}_{i}^{sl})-\mathbb{E}_{j\in[m]}\otimes_{l\in\mathcal{L}}\phi^{l}(\mathbf{z}_{j}^{tl})\Big{\&#124;}_{\mathcal{H}_{k}}^{2}$
    |  | (27) |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '|  | $d_{\text{JMMD}}^{2}(\widehat{\mathcal{S}},\widehat{\mathcal{T}})=\Big{\&#124;}\mathbb{E}_{i\in[n]}\otimes_{l\in\mathcal{L}}\phi^{l}(\mathbf{z}_{i}^{sl})-\mathbb{E}_{j\in[m]}\otimes_{l\in\mathcal{L}}\phi^{l}(\mathbf{z}_{j}^{tl})\Big{\&#124;}_{\mathcal{H}_{k}}^{2}$
    |  | (27) |'
- en: where $\phi^{l}$ is the feature map associated with kernel $k^{l}$ for layer
    $l$ and $\otimes$ is the outer product.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\phi^{l}$ 是与层 $l$ 的核 $k^{l}$ 相关的特征映射，$\otimes$ 是外积。
- en: A characteristic kernel widely used in MMD is the Gaussian kernel, or $k(\mathbf{x}_{1},\mathbf{x}_{2})=\exp(-||\mathbf{x}_{1}-\mathbf{x}_{1}||^{2}/{2\sigma^{2}})$.
    After Taylor expansion, MMD can be considered as a weighted sum of distances between
    all orders of statistic moments. Thus, the statistic moments can be directly used
    to measure the distribution distance. For instance, deep CORAL (Sun and Saenko,
    [2016](#bib.bib166)) uses the second-order statistics (covariance) to measure
    distribution distance, which is frustratingly easy yet useful. Center moment discrepancy
    (CMD) (Zellinger et al., [2017](#bib.bib200)) further considers an explicit order-wise
    matching of higher-order moments.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 在最大均值差异（MMD）中广泛使用的一个特征核是高斯核，或者 $k(\mathbf{x}_{1},\mathbf{x}_{2})=\exp(-||\mathbf{x}_{1}-\mathbf{x}_{1}||^{2}/{2\sigma^{2}})$。经过泰勒展开，MMD
    可以被视为各阶统计矩之间距离的加权和。因此，统计矩可以直接用于度量分布距离。例如，深度CORAL（Sun and Saenko, [2016](#bib.bib166)）使用二阶统计量（协方差）来测量分布距离，这既简单又实用。中心矩差异（CMD）(Zellinger
    et al., [2017](#bib.bib200)) 进一步考虑了高阶矩的显式阶次匹配。
- en: One disadvantage of MMD is that it cannot take into account the geometry of
    the data distribution when estimating the discrepancy between two domains. Thus,
    Joint Distribution Optimal Transport (JDOT) (Courty et al., [2017](#bib.bib34))
    is introduced into domain adaptation, and Deep JDOT (Damodaran et al., [2018](#bib.bib36))
    further extends it to deep networks. Another disadvantage is that minimizing MMD
    on the instance representation has the risk of changing the feature scale, while
    regression tasks are fragile to feature scaling. Thus, Representation Subspace
    Distance (RSD) (Chen et al., [2021b](#bib.bib29)) closes the domain shift through
    orthogonal bases of the representation spaces, which are free from feature scaling.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: MMD 的一个缺点是它在估计两个领域之间的差异时无法考虑数据分布的几何形状。因此，引入了联合分布最优传输（JDOT）(Courty et al., [2017](#bib.bib34))
    以进行领域适应，深度 JDOT (Damodaran et al., [2018](#bib.bib36)) 进一步将其扩展到深度网络。另一个缺点是，最小化
    MMD 对实例表示的风险在于改变特征尺度，而回归任务对特征缩放非常敏感。因此，表示子空间距离（RSD）(Chen et al., [2021b](#bib.bib29))
    通过表示空间的正交基来缩小领域偏移，这些基不受特征缩放的影响。
- en: Instead of explicitly matching the statistics moments of feature distributions,
    Adaptive Batch Normalization (AdaBN) (Li et al., [2017](#bib.bib102)) implicitly
    minimizes domain discrepancy by aligning BatchNorm Ioffe and Szegedy ([2015](#bib.bib77))
    statistics. The hypothesis is that task-related knowledge is stored in the weight
    matrix while domain-related knowledge is represented by BatchNorm statistics.
    Thus AdaBN replaces the mean and variance of all BatchNorm layers with those estimated
    on the target domain at inference to reduce the domain shift. However, it is risky
    that AdaBN excludes the statistics on the target domain from training. Thus, Transferable
    Normalization (TransNorm) (Wang et al., [2019c](#bib.bib185)) applies domain-specific
    mean and variance at both training and inference to capture sufficient statistics
    of both domains.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 自适应批量归一化（AdaBN）(Li et al., [2017](#bib.bib102)) 不通过显式匹配特征分布的统计矩，而是通过对齐批量归一化（BatchNorm
    Ioffe and Szegedy ([2015](#bib.bib77))）统计来隐式最小化领域差异。假设是任务相关的知识存储在权重矩阵中，而领域相关的知识由批量归一化统计表示。因此，AdaBN
    在推断时用目标领域上估计的均值和方差替换所有批量归一化层的均值和方差，以减少领域偏移。然而，AdaBN 排除了目标领域的统计数据从训练中，这具有一定风险。因此，可迁移归一化（TransNorm）(Wang
    et al., [2019c](#bib.bib185)) 在训练和推断时都应用领域特定的均值和方差，以捕获两个领域的充分统计数据。
- en: Finally, both MMD and JMMD may misalign samples from different classes due to
    a suboptimal modeling of the discriminative structure. To alleviate this problem,
    Contrastive Adaptation Network (CAN) (Kang et al., [2019](#bib.bib84)) alternatively
    estimates the labels of target samples through clustering, and adapts the feature
    representations in a class-wise manner. Besides, CAN uses class-aware sampling
    for both domains to improve adaptation efficiency.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，MMD 和 JMMD 都可能由于对判别结构的建模不佳而使不同类别的样本不对齐。为了缓解这个问题，对比适应网络（CAN）(Kang et al.,
    [2019](#bib.bib84)) 通过聚类交替估计目标样本的标签，并以类别为基础适应特征表示。此外，CAN 使用类别感知采样来提高适应效率。
- en: '![Refer to caption](img/561bfb3236019edb72cf3bf9869aa161.png)'
  id: totrans-376
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/561bfb3236019edb72cf3bf9869aa161.png)'
- en: 'Figure 20: Both DANN and CDAN have a feature generator network $\psi$, a classifier
    $h$, and a domain discriminator $D$ connected to $\psi$ via a gradient reversal
    layer. (a) In DANN, the discriminator $D$ is trained to distinguish between domains
    while the generator $\psi$ tries to make the feature distributions indistinguishable
    for the discriminator. (b) In CDAN, the discriminator $D$ is conditioned on the
    classifier prediction $\widehat{\mathbf{y}}$ via a multilinear map $\mathbf{z}\otimes\widehat{\mathbf{y}}$.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 图 20：DANN 和 CDAN 都具有一个特征生成网络 $\psi$、一个分类器 $h$ 和一个通过梯度反转层与 $\psi$ 连接的领域判别器 $D$。
    (a) 在 DANN 中，判别器 $D$ 被训练来区分不同领域，而生成器 $\psi$ 尝试使特征分布对判别器而言难以区分。 (b) 在 CDAN 中，判别器
    $D$ 根据分类器预测 $\widehat{\mathbf{y}}$ 通过一个多线性映射 $\mathbf{z}\otimes\widehat{\mathbf{y}}$
    进行条件化。
- en: 3.2.2 Domain Adversarial Learning
  id: totrans-378
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 领域对抗学习
- en: Domain Adversarial Neural Network.
  id: totrans-379
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 领域对抗神经网络。
- en: 'An important milestone for modeling distributions is the Generative Adversarial
    Net (GAN) (Goodfellow et al., [2014](#bib.bib54)). Inspired by GAN, Domain Adversarial
    Neural Network (DANN) (Ganin and Lempitsky, [2015](#bib.bib45); Ganin et al.,
    [2016](#bib.bib46)) integrates a two-player game into domain adaptation (Figure
    [20](#S3.F20 "Figure 20 ‣ 3.2.1 Statistics Matching ‣ 3.2 Domain Adaptation ‣
    3 Adaptation ‣ Transferability in Deep Learning: A Survey")). The first player
    is the domain discriminator $D$ trained to distinguish the source features from
    the target features and the second player is the feature generator $\psi$ trained
    simultaneously to confuse the domain discriminator. As mentioned in Section [3.2](#S3.SS2
    "3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"),
    the upper bound of $\mathcal{H}\Delta\mathcal{H}$-Divergence between feature distributions
    can be estimated by training the domain discriminator $D$,'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '模型分布的重要里程碑是生成对抗网络（GAN）（Goodfellow 等， [2014](#bib.bib54)）。受到 GAN 启发，领域对抗神经网络（DANN）（Ganin
    和 Lempitsky，[2015](#bib.bib45)；Ganin 等，[2016](#bib.bib46)）将一个双玩家游戏整合到领域适应中（图 [20](#S3.F20
    "Figure 20 ‣ 3.2.1 Statistics Matching ‣ 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")）。第一个玩家是领域判别器 $D$，其训练目的是区分源特征和目标特征，第二个玩家是特征生成器
    $\psi$，其训练目标是迷惑领域判别器。如在第 [3.2](#S3.SS2 "3.2 Domain Adaptation ‣ 3 Adaptation ‣
    Transferability in Deep Learning: A Survey") 节中提到的，通过训练领域判别器 $D$ 可以估计特征分布之间的 $\mathcal{H}\Delta\mathcal{H}$-散度的上界，'
- en: '|  | $L_{\text{DANN}}(\psi)=\max_{D}\mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}\log[D(\mathbf{z}^{s})]+\mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}\log[1-D(\mathbf{z}^{t})],$
    |  | (28) |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '|  | $L_{\text{DANN}}(\psi)=\max_{D}\mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}\log[D(\mathbf{z}^{s})]+\mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}\log[1-D(\mathbf{z}^{t})],$
    |  | (28) |'
- en: 'where $\mathbf{z}=\psi(\mathbf{x})$ is the feature representation for $\mathbf{x}$.
    The objective of the feature generator $\psi$ is to minimize the source error
    as well as the $\mathcal{H}\Delta\mathcal{H}$-Divergence bounded by Equation [28](#S3.E28
    "In Domain Adversarial Neural Network. ‣ 3.2.2 Domain Adversarial Learning ‣ 3.2
    Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"),'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $\mathbf{z}=\psi(\mathbf{x})$ 是 $\mathbf{x}$ 的特征表示。特征生成器 $\psi$ 的目标是最小化源错误以及由方程
    [28](#S3.E28 "In Domain Adversarial Neural Network. ‣ 3.2.2 Domain Adversarial
    Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey") 约束的 $\mathcal{H}\Delta\mathcal{H}$-散度，'
- en: '|  | $\min_{\psi,h}\mathbb{E}_{(\mathbf{x}^{s},\mathbf{y}^{s})\sim\widehat{\mathcal{S}}}L_{\text{CE}}(h(\mathbf{z}^{s}),\mathbf{y}^{s})+\lambda
    L_{\text{DANN}}(\psi),$ |  | (29) |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{\psi,h}\mathbb{E}_{(\mathbf{x}^{s},\mathbf{y}^{s})\sim\widehat{\mathcal{S}}}L_{\text{CE}}(h(\mathbf{z}^{s}),\mathbf{y}^{s})+\lambda
    L_{\text{DANN}}(\psi),$ |  | (29) |'
- en: where $L_{\text{CE}}$ is the cross-entropy loss, $\lambda$ is a hyper-parameter
    that trades off source error and domain adversary. Minimizing the cross-entropy
    loss will lead to discriminative representations while decreasing the domain adversarial
    loss will result in transferable representations.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $L_{\text{CE}}$ 是交叉熵损失，$\lambda$ 是一个超参数，用于平衡源错误和领域对抗。最小化交叉熵损失将导致具有判别性的表示，而减少领域对抗损失将导致可迁移的表示。
- en: 'DANN aligns the marginal feature distributions through adversarial training.
    However, this may be insufficient when the feature-label joint distributions change
    between domains. Besides, the feature distribution is usually multimodal in multi-class
    classification, thus even if the discriminator is fully confused, there is no
    guarantee that the two feature distributions are similar (Arora et al., [2017](#bib.bib5)).
    To tackle these two issues, Conditional Domain Adversarial Network (CDAN) (Long
    et al., [2018](#bib.bib115)) conditions features $\mathbf{z}$ on classifier predictions
    $\widehat{\mathbf{y}}=h(\mathbf{z})$ and introduces multilinear map $\mathbf{z}\otimes\widehat{\mathbf{y}}$
    instead of $\mathbf{z}$ as the input to domain discriminator $D$:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: DANN通过对抗训练来对齐边际特征分布。然而，当特征-标签联合分布在领域间发生变化时，这可能不足够。此外，特征分布在多分类任务中通常是多模态的，因此即使判别器完全混淆，也不能保证两个特征分布相似（Arora
    et al., [2017](#bib.bib5)）。为了解决这两个问题，条件领域对抗网络（CDAN）(Long et al., [2018](#bib.bib115))
    将特征 $\mathbf{z}$ 条件化在分类器预测 $\widehat{\mathbf{y}}=h(\mathbf{z})$ 上，并引入多线性映射 $\mathbf{z}\otimes\widehat{\mathbf{y}}$
    代替 $\mathbf{z}$ 作为领域判别器 $D$ 的输入：
- en: '|  | $L_{\text{CDAN}}(\psi)=\max_{D}\mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}\log[D(\mathbf{z}^{s}\otimes\widehat{\mathbf{y}}^{s})]+\mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}\log[1-D(\mathbf{z}^{t}\otimes\widehat{\mathbf{y}}^{t})].$
    |  | (30) |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '|  | $L_{\text{CDAN}}(\psi)=\max_{D}\mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}\log[D(\mathbf{z}^{s}\otimes\widehat{\mathbf{y}}^{s})]+\mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}\log[1-D(\mathbf{z}^{t}\otimes\widehat{\mathbf{y}}^{t})].$
    |  | (30) |'
- en: Conditioning on $\widehat{\mathbf{y}}$, CDAN fully captures cross-variance between
    the feature representation and classifier prediction, resulting in better alignment
    of the joint distributions.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在 $\widehat{\mathbf{y}}$ 的条件下，CDAN 完全捕捉了特征表示和分类器预测之间的交叉方差，从而更好地对齐了联合分布。
- en: Tzeng et al. ([2015](#bib.bib175)) align the class distributions explicitly
    by transferring the similarity structure in classes from the source domain to
    the target domain. Specifically, the average output probability of data from each
    class is computed over the source samples as soft labels. Then the model is optimized
    to match the distribution over classes to the soft labels.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: Tzeng et al. ([2015](#bib.bib175)) 通过将源领域中的类的相似结构转移到目标领域，明确对齐类分布。具体而言，计算每个类的数据在源样本中的平均输出概率作为软标签。然后，模型被优化以使类分布匹配这些软标签。
- en: Improvements.
  id: totrans-389
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 改进。
- en: DANN integrates a gradient reverse layer (GRL) into the standard architecture
    to implement the minimax between the feature generator and domain classifier.
    However, this optimizing strategy might not work well in practice due to gradient
    vanishing, which is also a major problem in training GANs. For instance, when
    the generated target features $\mathbf{z}^{t}$ are very distinguishable from source
    features such that $D(\mathbf{z}^{t})=0$, the gradient for the feature generator
    is small and vice versa. This makes the optimization of the feature generator
    difficult. Thus, Adversarial Discriminative Domain Adaptation (ADDA) (Tzeng et al.,
    [2017](#bib.bib176)) splits the optimization of feature generator $\psi$ and domain
    classifier $D$ into two independent objectives, where the maximization of $D$
    remains unchanged, but the objective of $\psi$ becomes
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: DANN在标准架构中集成了一个梯度反转层（GRL），以实现特征生成器和领域分类器之间的最小最大化。然而，由于梯度消失，这种优化策略在实际中可能效果不佳，这也是训练GAN的一个主要问题。例如，当生成的目标特征
    $\mathbf{z}^{t}$ 与源特征非常不同，以至于 $D(\mathbf{z}^{t})=0$ 时，特征生成器的梯度很小，反之亦然。这使得特征生成器的优化变得困难。因此，对抗性区分领域适应（ADDA）(Tzeng
    et al., [2017](#bib.bib176)) 将特征生成器 $\psi$ 和领域分类器 $D$ 的优化分为两个独立的目标，其中 $D$ 的最大化保持不变，但
    $\psi$ 的目标变为
- en: '|  | $\min_{\psi}\mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}-\log[D(\mathbf{z}^{t})].$
    |  | (31) |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{\psi}\mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}-\log[D(\mathbf{z}^{t})].$
    |  | (31) |'
- en: This assigns small gradients for source-like target samples and larger gradients
    for the other target samples. It has the same fixed-point properties as GRL while
    making the optimization easier for the feature generator. Although adversarial
    domain adaptation enhances the feature *transferability*, i.e. the ability of
    feature representations to bridge the discrepancy across domains, studies (Chen
    et al., [2019c](#bib.bib28)) reveal that it is at the expense of deteriorating
    the *discriminability*, i.e. the easiness of separating categories over the fixed
    feature representations of both domains. Spectral analysis shows that only the
    eigenvectors corresponding to the largest singular values tend to carry transferable
    knowledge, while other eigenvectors may reflect domain variations and thus be
    overly penalized in domain adversarial training. However, these eigenvectors may
    convey crucial discriminative information, and thus the discriminability is weakened.
    To tackle this transferability-discriminability dilemma, Batch Spectral Penalization
    (BSP) (Chen et al., [2019c](#bib.bib28)) penalizes the largest singular values
    so that the other eigenvectors can be relatively strengthened to boost the feature
    discriminability. Domain Separation Network (DSN) (Bousmalis et al., [2016](#bib.bib15))
    introduces a private subspace for each domain, which preserves domain-specific
    information, such as background and low-level image statistics. Then domain alignment
    is performed safely in the shared subspace, which is orthogonal to the private
    subspace responsible for the discriminative tasks.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 这会为类似源领域的目标样本分配较小的梯度，而为其他目标样本分配较大的梯度。它具有与 GRL 相同的固定点特性，同时使特征生成器的优化更为容易。尽管对抗性领域适应增强了特征的*可迁移性*，即特征表示跨领域桥接差异的能力，但研究（Chen
    et al., [2019c](#bib.bib28)）表明，这以牺牲*可区分性*为代价，即在两个领域的固定特征表示上区分类别的难易程度。光谱分析显示，只有对应于最大奇异值的特征向量倾向于携带可迁移的知识，而其他特征向量可能反映领域变化，从而在领域对抗训练中受到过度惩罚。然而，这些特征向量可能传达了重要的区分信息，从而削弱了可区分性。为了应对这种可迁移性与可区分性的矛盾，Batch
    Spectral Penalization (BSP)（Chen et al., [2019c](#bib.bib28)）惩罚最大的奇异值，以便其他特征向量能够相对增强，从而提高特征的可区分性。Domain
    Separation Network (DSN)（Bousmalis et al., [2016](#bib.bib15)）为每个领域引入了一个私有子空间，该子空间保留了领域特定的信息，如背景和低级图像统计信息。然后在与负责区分任务的私有子空间正交的共享子空间中安全地执行领域对齐。
- en: Domain Adversarial Leanring in Real-World Scenarios.
  id: totrans-393
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 现实世界场景中的领域对抗学习。
- en: Domain adversarial learning has largely improved the performance on unlabeled
    target domain and has been widely adopted in many applications (Hoffman et al.,
    [2016](#bib.bib71); Chen et al., [2018](#bib.bib30)). However, real-world scenarios
    are much more complex. Here we list several situations that are often encountered
    yet not well resolved, and review some existing solutions to them.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 域对抗学习在无标签目标领域上的性能有了显著提升，并已被广泛应用于许多领域（Hoffman et al., [2016](#bib.bib71); Chen
    et al., [2018](#bib.bib30)）。然而，现实世界的场景要复杂得多。这里列出了一些经常遇到但尚未很好解决的情况，并回顾了一些现有的解决方案。
- en: '![Refer to caption](img/706624197a5526daa980a3d256897cf9.png)'
  id: totrans-395
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/706624197a5526daa980a3d256897cf9.png)'
- en: 'Figure 21: Where to adapt in different methods. (a) DANN performs alignment
    on global features. (b) DA-Faster performs alignment on both image-level and instance-level
    features. (c) SWDA performs alignment on local features. (d) Adapt-SegMap performs
    alignment on local outputs.'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 图21：在不同方法中的适应位置。（a）DANN 在全局特征上执行对齐。（b）DA-Faster 在图像级别和实例级别特征上执行对齐。（c）SWDA 在局部特征上执行对齐。（d）Adapt-SegMap
    在局部输出上执行对齐。
- en: 'Which part to adapt is unknown. In image recognition, we only need to classify
    the input. Yet in applications such as object detection, we need to locate the
    Region of Interests (RoIs) first and then classify them. Due to the distribution
    shift across domains, the localization of RoIs on the target domain is not reliable,
    thus which part to adapt in the adversarial training is unknown. To alleviate
    this problem, as shown in Figure [21](#S3.F21 "Figure 21 ‣ Domain Adversarial
    Leanring in Real-World Scenarios. ‣ 3.2.2 Domain Adversarial Learning ‣ 3.2 Domain
    Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"), DA-Faster
    (Chen et al., [2018](#bib.bib30)) performs domain alignment at both image level
    and instance level, where the image-level alignment is believed to improve the
    localization of RoIs on the target domain. SWDA (Saito et al., [2019](#bib.bib147))
    argues that alignment of the local features is more effective than that of the
    global features for better localization. Although the above adversarial training
    methods have improved the transferability of object detectors, the discriminability
    might get lost in the adversarial adaptation process as mentioned by BSP (Chen
    et al., [2019c](#bib.bib28)). Since discriminability is crucial for the localization
    of RoIs, D-adapt (Jiang et al., [2022](#bib.bib81)) introduces parameter-independent
    category adaptor and bounding box adaptor to decouple adversarial adaptation from
    detector training, which yields sharp improvement.'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '适应哪个部分尚不清楚。在图像识别中，我们只需要对输入进行分类。然而在物体检测等应用中，我们需要首先定位兴趣区域（RoIs），然后再对其进行分类。由于领域间的分布变化，目标领域中RoIs的定位不可靠，因此在对抗训练中需要适应哪个部分尚不清楚。为了解决这个问题，如图[21](#S3.F21
    "Figure 21 ‣ Domain Adversarial Leanring in Real-World Scenarios. ‣ 3.2.2 Domain
    Adversarial Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")所示，DA-Faster（Chen等，[2018](#bib.bib30)）在图像级和实例级都进行领域对齐，其中图像级对齐被认为可以改善目标领域中RoIs的定位。SWDA（Saito等，[2019](#bib.bib147)）认为，本地特征的对齐比全局特征的对齐更有效，从而实现更好的定位。尽管上述对抗训练方法提高了物体检测器的迁移能力，但如BSP（Chen等，[2019c](#bib.bib28)）所提到的，对抗适应过程可能会丧失可分辨性。由于可分辨性对于RoIs的定位至关重要，D-adapt（Jiang等，[2022](#bib.bib81)）引入了参数无关的类别适配器和边界框适配器，将对抗适应与检测器训练解耦，从而带来了显著的改进。'
- en: 'There are structural dependencies between labels of each sample. In low-level
    classification tasks, such as semantic segmentation or token classification (Named
    Entity Recognition, Parts-of-speech tagging, etc.), adaptation on *features* (Hoffman
    et al., [2016](#bib.bib71)) may not be a good option, because the feature of each
    pixel or each token is high-dimensional and there exist many pixels or tokens
    in a single sample. Every coin has two sides. Compared to the high-level classification
    tasks, the *output space* of these low-level tasks contains much richer information
    of the distribution, e.g., scene layout and context, and thus adaptation on the
    output space can reduce the domain shift. As shown in Figure [21](#S3.F21 "Figure
    21 ‣ Domain Adversarial Leanring in Real-World Scenarios. ‣ 3.2.2 Domain Adversarial
    Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey"), Adapt-SegMap (Tsai et al., [2018](#bib.bib173)) trains a discriminator
    to distinguish whether the segmentation output is from the source or the target,
    while the feature generator is encouraged to generate similar segmentation outputs
    across domains. It explicitly aligns the output distributions of target and source
    domains, and implicitly adapts the feature distributions. Further, ADVENT (Vu
    et al., [2019](#bib.bib182)) minimizes the distribution distance on the self-information
    distributions, where the entropy of segmentation outputs is fed to the discriminator.
    In this way, the conditional information is neglected while more attention is
    paid to the structural dependencies between local semantics.'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 样本标签之间存在结构性依赖。在低级分类任务中，如语义分割或标记分类（命名实体识别、词性标注等），对*特征*的适应可能不是一个好的选择，因为每个像素或每个标记的特征都是高维的，并且单个样本中存在许多像素或标记。每个硬币都有两面。与高级分类任务相比，这些低级任务的*输出空间*包含了更丰富的分布信息，例如场景布局和上下文，因此对输出空间的适应可以减少领域偏移。如图[21](#S3.F21
    "图 21 ‣ 现实世界场景中的领域对抗学习 ‣ 3.2.2 领域对抗学习 ‣ 3.2 领域适应 ‣ 3 适应 ‣ 深度学习中的迁移性：综述")所示，Adapt-SegMap
    (Tsai et al., [2018](#bib.bib173)) 训练一个鉴别器来区分分割输出是来自源领域还是目标领域，同时鼓励特征生成器在不同领域之间生成相似的分割输出。它明确地对齐了目标领域和源领域的输出分布，并隐式地适应了特征分布。此外，ADVENT
    (Vu et al., [2019](#bib.bib182)) 最小化自信息分布上的分布距离，其中分割输出的熵被输入到鉴别器中。这样，条件信息被忽略，而更多关注于局部语义之间的结构依赖。
- en: 3.2.3 Hypothesis Adversarial Learning
  id: totrans-399
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 假设对抗学习
- en: 'Inevitably, there is still a gap between the proxy distance used in previous
    methods and the hypothesis-induced discrepancies in the theories. To close this
    gap, Maximum Classifier Discrepancy (MCD) (Saito et al., [2018](#bib.bib146))
    starts to estimate and optimize $\mathcal{H}\Delta\mathcal{H}$-Divergence in a
    fully parameterized way. As shown in Figure [22](#S3.F22 "Figure 22 ‣ 3.2.3 Hypothesis
    Adversarial Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey"), MCD maximizes the discrepancy between two classifiers’
    outputs to detect target samples far from the support of source distribution,
    i.e. estimate $\mathcal{H}\Delta\mathcal{H}$-Divergence. A feature generator then
    learns to generate target features near the support to minimize the discrepancy,
    i.e. minimize the domain discrepancy. MCD uses the $L_{1}$ distance to calculate
    the discrepancy, while Sliced Wasserstein Discrepancy (SWD) (Lee et al., [2019](#bib.bib95))
    adopts the Wasserstein metric, which is the natural geometry for probability measures
    induced by the optimal transport theory. In theory MCD is closer to $\mathcal{H}\Delta\mathcal{H}$-Divergence,
    yet in experiments it is slow in convergence and very sensitive to hyper-parameters.
    The reason is that there exist two classifiers $h$ and $h^{\prime}$ in MCD that
    maximize the discrepancy, which makes the minimax optimization hard to reach equilibrium.'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 不可避免的是，之前方法中使用的代理距离与理论中的假设诱导不一致性之间仍存在差距。为了弥合这一差距，最大分类器差异（MCD）（Saito 等，[2018](#bib.bib146)）开始以完全参数化的方式估计和优化
    $\mathcal{H}\Delta\mathcal{H}$-散度。如图 [22](#S3.F22 "图 22 ‣ 3.2.3 假设对抗学习 ‣ 3.2 领域适应
    ‣ 3 适应 ‣ 深度学习中的可迁移性：综述") 所示，MCD 通过最大化两个分类器输出之间的差异来检测远离源分布支持的目标样本，即估计 $\mathcal{H}\Delta\mathcal{H}$-散度。特征生成器然后学习生成接近支持的目标特征以最小化差异，即最小化领域差异。MCD
    使用 $L_{1}$ 距离来计算差异，而切片 Wasserstein 差异（SWD）（Lee 等，[2019](#bib.bib95)）则采用 Wasserstein
    度量，这是由最优传输理论引发的概率度量的自然几何。在理论上，MCD 更接近 $\mathcal{H}\Delta\mathcal{H}$-散度，但在实验中，它在收敛速度上较慢，并且对超参数非常敏感。原因是
    MCD 中存在两个分类器 $h$ 和 $h^{\prime}$ 使差异最大化，这使得最小最大优化难以达到平衡。
- en: 'Disparity Discrepancy (DD) (Zhang et al., [2019c](#bib.bib204)) provides a
    tighter bound by taking supremum in hypothesis space $\mathcal{H}$ rather than
    $\mathcal{H}\Delta\mathcal{H}$. This will significantly ease the minimax optimization.
    As shown in Figure [22](#S3.F22 "Figure 22 ‣ 3.2.3 Hypothesis Adversarial Learning
    ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"),
    DD introduces an adversarial classifier $h^{\prime}$ sharing the same hypothesis
    space with $h$. The supremum in $d_{h,\mathcal{H}}(\mathcal{S},\mathcal{T})$ is
    approximated by'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 差异不一致性（DD）（Zhang 等，[2019c](#bib.bib204)）通过在假设空间 $\mathcal{H}$ 中取上确界而不是 $\mathcal{H}\Delta\mathcal{H}$
    提供了一个更紧的界限。这将显著简化最小最大优化。如图 [22](#S3.F22 "图 22 ‣ 3.2.3 假设对抗学习 ‣ 3.2 领域适应 ‣ 3 适应
    ‣ 深度学习中的可迁移性：综述") 所示，DD 引入了一个与 $h$ 共享相同假设空间的对抗分类器 $h^{\prime}$。$d_{h,\mathcal{H}}(\mathcal{S},\mathcal{T})$
    中的上确界通过以下方式近似
- en: '|  | <math   alttext="\begin{split}L_{\text{DD}}(h,\psi)=\max_{h^{\prime}}&amp;\
    \mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}L^{s}\left[h^{\prime}(\psi(\mathbf{x}^{s})),h(\psi(\mathbf{x}^{s}))\right]\\
    -&amp;\ \mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}L^{t}\left[h^{\prime}(\psi(\mathbf{x}^{t})),h(\psi(\mathbf{x}^{t}))\right],\\'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math alttext="\begin{split}L_{\text{DD}}(h,\psi)=\max_{h^{\prime}}&amp;\
    \mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}L^{s}\left[h^{\prime}(\psi(\mathbf{x}^{s})),h(\psi(\mathbf{x}^{s}))\right]\\
    -&amp;\ \mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}L^{t}\left[h^{\prime}(\psi(\mathbf{x}^{t})),h(\psi(\mathbf{x}^{t}))\right],\\'
- en: \end{split}" display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt" ><mtr ><mtd columnalign="right" ><mrow ><mrow ><msub ><mi >L</mi><mtext
    >DD</mtext></msub><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo stretchy="false"
    >(</mo><mi  >h</mi><mo >,</mo><mi >ψ</mi><mo stretchy="false" >)</mo></mrow></mrow><mo
    >=</mo><munder ><mi >max</mi><msup ><mi >h</mi><mo >′</mo></msup></munder></mrow></mtd><mtd
    columnalign="left" ><mrow ><msub ><mi  >𝔼</mi><mrow ><msup ><mi >𝐱</mi><mi >s</mi></msup><mo
    >∼</mo><mover accent="true"  ><mi >𝒮</mi><mo >^</mo></mover></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><msup ><mi  >L</mi><mi >s</mi></msup><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo  >[</mo><mrow ><msup ><mi >h</mi><mo >′</mo></msup><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >(</mo><mrow ><mi
    >ψ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >(</mo><msup
    ><mi >𝐱</mi><mi >s</mi></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo stretchy="false"  >)</mo></mrow></mrow><mo
    >,</mo><mrow ><mi  >h</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"
    >(</mo><mrow ><mi >ψ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"
    >(</mo><msup ><mi >𝐱</mi><mi >s</mi></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow><mo >]</mo></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><mo >−</mo></mtd><mtd columnalign="left" ><mrow ><mrow
    ><msub ><mi >𝔼</mi><mrow ><msup ><mi >𝐱</mi><mi >t</mi></msup><mo >∼</mo><mover
    accent="true" ><mi >𝒯</mi><mo >^</mo></mover></mrow></msub><mo lspace="0em" rspace="0em"  >​</mo><msup
    ><mi  >L</mi><mi >t</mi></msup><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo  >[</mo><mrow
    ><msup ><mi >h</mi><mo >′</mo></msup><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo stretchy="false" >(</mo><mrow ><mi >ψ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" >(</mo><msup ><mi >𝐱</mi><mi >t</mi></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow><mo >,</mo><mrow ><mi >h</mi><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo stretchy="false"  >(</mo><mrow ><mi >ψ</mi><mo
    lspace="0em" rspace="0em" >​</mo><mrow ><mo stretchy="false"  >(</mo><msup ><mi
    >𝐱</mi><mi >t</mi></msup><mo stretchy="false" >)</mo></mrow></mrow><mo stretchy="false"
    >)</mo></mrow></mrow><mo >]</mo></mrow></mrow><mo >,</mo></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐿</ci><ci  ><mtext mathsize="70%"  >DD</mtext></ci></apply><interval closure="open"  ><ci
    >ℎ</ci><ci >𝜓</ci></interval></apply><apply ><apply ><apply ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ℎ</ci><ci >′</ci></apply></apply><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝔼</ci><apply ><csymbol cd="latexml" >similar-to</csymbol><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >𝐱</ci><ci >𝑠</ci></apply><apply ><ci >^</ci><ci >𝒮</ci></apply></apply></apply><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝐿</ci><ci >𝑠</ci></apply></apply></apply><interval
    closure="closed" ><apply ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >ℎ</ci><ci >′</ci></apply><apply ><ci >𝜓</ci><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >𝐱</ci><ci >𝑠</ci></apply></apply></apply><apply ><ci >ℎ</ci><apply ><ci >𝜓</ci><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><ci >𝐱</ci><ci >𝑠</ci></apply></apply></apply></interval></apply><apply
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝔼</ci><apply ><csymbol
    cd="latexml"  >similar-to</csymbol><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >𝐱</ci><ci >𝑡</ci></apply><apply ><ci >^</ci><ci >𝒯</ci></apply></apply></apply><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><ci >𝐿</ci><ci >𝑡</ci></apply><interval
    closure="closed" ><apply ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ℎ</ci><ci >′</ci></apply><apply ><ci  >𝜓</ci><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >𝐱</ci><ci >𝑡</ci></apply></apply></apply><apply ><ci >ℎ</ci><apply ><ci >𝜓</ci><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><ci >𝐱</ci><ci >𝑡</ci></apply></apply></apply></interval></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}L_{\text{DD}}(h,\psi)=\max_{h^{\prime}}&\
    \mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}L^{s}\left[h^{\prime}(\psi(\mathbf{x}^{s})),h(\psi(\mathbf{x}^{s}))\right]\\
    -&\ \mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}L^{t}\left[h^{\prime}(\psi(\mathbf{x}^{t})),h(\psi(\mathbf{x}^{t}))\right],\\
    \end{split}</annotation></semantics></math> |  | (32) |
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: \end{split}" display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt" ><mtr ><mtd columnalign="right" ><mrow ><mrow ><msub ><mi >L</mi><mtext
    >DD</mtext></msub><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo stretchy="false"
    >(</mo><mi >h</mi><mo >,</mo><mi >ψ</mi><mo stretchy="false" >)</mo></mrow></mrow><mo
    >=</mo><munder ><mi >max</mi><msup ><mi >h</mi><mo >′</mo></msup></munder></mrow></mtd><mtd
    columnalign="left" ><mrow ><msub ><mi  >𝔼</mi><mrow ><msup ><mi >𝐱</mi><mi >s</mi></msup><mo
    >∼</mo><mover accent="true"  ><mi >𝒮</mi><mo >^</mo></mover></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><msup ><mi  >L</mi><mi >s</mi></msup><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo  >[</mo><mrow ><msup ><mi >h</mi><mo >′</mo></msup><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >(</mo><mrow ><mi
    >ψ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >(</mo><msup
    ><mi >𝐱</mi><mi >s</mi></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo stretchy="false"  >)</mo></mrow></mrow><mo
    >,</mo><mrow ><mi  >h</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"
    >(</mo><mrow ><mi >ψ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"
    >(</mo><msup ><mi >𝐱</mi><mi >s</mi></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow><mo >]</mo></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><mo >−</mo></mtd><mtd columnalign="left" ><mrow ><mrow
    ><msub ><mi >𝔼</mi><mrow ><msup ><mi >𝐱</mi><mi >t</mi></msup><mo >∼</mo><mover
    accent="true" ><mi >𝒯</mi><mo >^</mo></mover></mrow></msub><mo lspace="0em" rspace="0em"  >​</mo><msup
    ><mi  >L</mi><mi >t</mi></msup><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo  >[</mo><mrow
    ><msup ><mi >h</mi><mo >′</mo></msup><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo stretchy="false" >(</mo><mrow ><mi >ψ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" >(</mo><msup ><mi >𝐱</mi><mi >t</mi></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow><mo >,</mo><mrow ><mi >h</mi><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo stretchy="false"  >(</mo><mrow ><mi >ψ</mi><mo
    lspace="0em" rspace="0em" >​</mo><mrow ><mo stretchy="false"  >(</mo><msup ><mi
    >𝐱</mi><mi >t</mi></msup><mo stretchy="false" >)</mo></mrow></mrow><mo stretchy="false"
    >)</mo></mrow></mrow><mo >]</mo></mrow></mrow><mo >,</mo></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐿</ci><ci  ><mtext mathsize="70%"  >DD</mtext></ci></apply><interval closure="open"  ><ci
    >ℎ</ci><ci >𝜓</ci></interval></apply><apply ><apply ><apply ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ℎ</ci><ci >′</ci></apply></apply><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝔼</ci><apply ><csymbol cd="latexml" >similar-to</csymbol><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><ci >𝐱</ci><ci >𝑠</ci></apply><apply ><ci >^</ci><ci >𝒮</ci></apply></apply></apply><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝐿</ci><ci >𝑠</ci></apply></apply></apply><interval
    closure="closed" ><apply ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >ℎ</ci><ci >′</ci></apply><apply ><ci >𝜓</ci><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >𝐱</ci><ci >𝑠</ci></apply></apply></apply><apply ><ci >ℎ</ci><apply ><ci >𝜓</ci><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><ci >𝐱</ci><ci >𝑠</ci></apply></apply></apply></interval></apply><apply
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝔼</ci><apply ><csymbol
    cd="latexml"  >similar-to</csymbol><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >𝐱</ci><ci >𝑡</ci></apply><apply ><ci >^</ci><ci >𝒯</ci></apply></apply></apply><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><ci >𝐿</ci><ci >𝑡</ci></apply><interval
    closure="closed" ><apply ><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ℎ</ci><ci >′</ci></apply><apply ><ci  >𝜓</ci><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >𝐱</ci><ci >𝑡</ci></apply></apply></apply><apply ><ci >ℎ</ci><apply ><ci >𝜓</ci><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><ci >𝐱</ci><ci >𝑡</ci></apply></apply></apply></interval></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}L_{\text{DD}}(h,\psi)=\max_{h^{\prime}}&\
    \mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}L^{s}\left[h^{\prime}(\psi(\mathbf{x}^{s})),h(\psi(\mathbf{x}^{s}))\right]\\
    -&\ \mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}L^{t}\left[h^{\prime}(\psi(\mathbf{x}^{t})),h(\psi(\mathbf{x}^{t}))\right],\\
    \end{split}</annotation></semantics></math> |  | (32) |
- en: where $L^{s}$ and $L^{t}$ are specific loss functions defined on the source
    domain and target domain respectively. Based on the theory (Zhang et al., [2019c](#bib.bib204)),
    when the adversarial classifier $h^{\prime}$ is close to the supremum, minimizing
    the following terms will decrease the target error $\epsilon_{\mathcal{T}}$,
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $L^{s}$ 和 $L^{t}$ 是在源领域和目标领域上分别定义的特定损失函数。根据理论 (Zhang et al., [2019c](#bib.bib204))，当对抗分类器
    $h^{\prime}$ 接近上确界时，最小化以下项将减少目标误差 $\epsilon_{\mathcal{T}}$，
- en: '|  | $\min_{\psi,h}\ \mathbb{E}_{(\mathbf{x}^{s},\mathbf{y}^{s})\sim\widehat{\mathcal{S}}}L_{\text{CE}}(h(\psi(\mathbf{x}^{s})),\mathbf{y}^{s})+\lambda
    L_{\text{DD}}(h,\psi),$ |  | (33) |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{\psi,h}\ \mathbb{E}_{(\mathbf{x}^{s},\mathbf{y}^{s})\sim\widehat{\mathcal{S}}}L_{\text{CE}}(h(\psi(\mathbf{x}^{s})),\mathbf{y}^{s})+\lambda
    L_{\text{DD}}(h,\psi),$ |  | (33) |'
- en: where $\lambda$ is a tradeoff hyper-parameter. An intuitive explanation is that
    DD is looking for an adversarial classifier $h^{\prime}$ that predicts correctly
    on the source domain while making different predictions from $h$ on the target
    domain. And then the feature generator $\psi$ is encouraged to generate features
    near the decision boundary to avoid such situations.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\lambda$ 是一个权衡超参数。直观的解释是，DD 寻找一个对抗分类器 $h^{\prime}$，该分类器在源领域上预测正确，同时在目标领域上与
    $h$ 做出不同的预测。然后，特征生成器 $\psi$ 被鼓励生成接近决策边界的特征，以避免这种情况。
- en: '![Refer to caption](img/6e88626d3639be2911eb67ccbdfe7068.png)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6e88626d3639be2911eb67ccbdfe7068.png)'
- en: 'Figure 22: (a) The training of MCD has three steps. Step A: Both the classifiers
    and the feature generator are trained to classify the source samples correctly.
    Step B: The classifiers $h_{1}$ and $h_{2}$ learn to maximize the discrepancy
    on the target samples. (b) Step C: The feature generator $\psi$ learns to minimize
    the discrepancy on the target samples. (c) DD and MDD introduce an adversarial
    classifier $h^{\prime}$ to maximize the discrepancy and trains the feature generator
    $\psi$ to minimize the source error as well as the discrepancy.'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: '图 22: (a) MCD 的训练分为三个步骤。步骤 A: 分类器和特征生成器都被训练以正确分类源样本。步骤 B: 分类器 $h_{1}$ 和 $h_{2}$
    学习最大化目标样本上的差异。 (b) 步骤 C: 特征生成器 $\psi$ 学习最小化目标样本上的差异。 (c) DD 和 MDD 引入了对抗分类器 $h^{\prime}$
    来最大化差异，并训练特征生成器 $\psi$ 以最小化源误差和差异。'
- en: However, DD is still limited to the $01$ loss in the classification setting.
    Based on scoring functions and margin loss, Margin Disparity Discrepancy (MDD)
    (Zhang et al., [2019c](#bib.bib204)) goes a crucial step forward and provides
    a *margin* theory for the multi-class classification setting. The margin $\rho$
    is attained by introducing parameter $\gamma\triangleq\exp\rho$ in the disparity
    discrepancy,
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，DD 仍然局限于分类设置中的 $01$ 损失。基于评分函数和边际损失，Margin Disparity Discrepancy (MDD) (Zhang
    et al., [2019c](#bib.bib204)) 向前迈出了重要的一步，并为多类分类设置提供了*边际*理论。通过在差异差距中引入参数 $\gamma\triangleq\exp\rho$
    来获得边际 $\rho$，
- en: '|  | <math   alttext="\begin{split}L_{\text{MDD}}(h,\psi)=\max_{h^{\prime}}\
    \gamma&amp;\ \mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}\log\left[\sigma_{h(\psi(\mathbf{x}^{s}))}(h^{\prime}(\psi(\mathbf{x}^{s})))\right]\\
    +&amp;\ \mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}\log\left[1-\sigma_{h(\psi(\mathbf{x}^{t}))}(h^{\prime}(\psi(\mathbf{x}^{t})))\right],\\'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math alttext="\begin{split}L_{\text{MDD}}(h,\psi)=\max_{h^{\prime}}\
    \gamma&amp;\ \mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}\log\left[\sigma_{h(\psi(\mathbf{x}^{s}))}(h^{\prime}(\psi(\mathbf{x}^{s})))\right]\\
    +&amp;\ \mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}\log\left[1-\sigma_{h(\psi(\mathbf{x}^{t}))}(h^{\prime}(\psi(\mathbf{x}^{t})))\right],\\'
- en: \end{split}" display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt" ><mtr ><mtd columnalign="right" ><mrow ><mrow ><msub ><mi >L</mi><mtext
    >MDD</mtext></msub><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo stretchy="false"
    >(</mo><mi  >h</mi><mo >,</mo><mi >ψ</mi><mo stretchy="false" >)</mo></mrow></mrow><mo
    >=</mo><mrow ><munder ><mi  >max</mi><msup ><mi >h</mi><mo >′</mo></msup></munder><mo
    lspace="0.167em"  >⁡</mo><mi >γ</mi></mrow></mrow></mtd><mtd columnalign="left"
    ><mrow ><msub ><mi  >𝔼</mi><mrow ><msup ><mi >𝐱</mi><mi >s</mi></msup><mo >∼</mo><mover
    accent="true"  ><mi >𝒮</mi><mo >^</mo></mover></mrow></msub><mo lspace="0.167em"
    rspace="0em"  >​</mo><mrow ><mi  >log</mi><mo >⁡</mo><mrow ><mo  >[</mo><mrow
    ><msub ><mi >σ</mi><mrow ><mi >h</mi><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo stretchy="false"  >(</mo><mrow ><mi >ψ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false"  >(</mo><msup ><mi >𝐱</mi><mi >s</mi></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" >(</mo><mrow ><msup ><mi >h</mi><mo >′</mo></msup><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo stretchy="false" >(</mo><mrow ><mi >ψ</mi><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo stretchy="false"  >(</mo><msup ><mi >𝐱</mi><mi
    >s</mi></msup><mo stretchy="false" >)</mo></mrow></mrow><mo stretchy="false" >)</mo></mrow></mrow><mo
    stretchy="false" >)</mo></mrow></mrow><mo >]</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><mo >+</mo></mtd><mtd columnalign="left" ><mrow ><mrow
    ><msub ><mi >𝔼</mi><mrow ><msup ><mi >𝐱</mi><mi >t</mi></msup><mo >∼</mo><mover
    accent="true" ><mi >𝒯</mi><mo >^</mo></mover></mrow></msub><mo lspace="0.167em"
    rspace="0em"  >​</mo><mrow ><mi  >log</mi><mo >⁡</mo><mrow ><mo  >[</mo><mrow
    ><mn >1</mn><mo  >−</mo><mrow ><msub ><mi >σ</mi><mrow ><mi >h</mi><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo stretchy="false" >(</mo><mrow ><mi >ψ</mi><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo stretchy="false"  >(</mo><msup ><mi >𝐱</mi><mi
    >t</mi></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo stretchy="false"  >)</mo></mrow></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >(</mo><mrow ><msup
    ><mi >h</mi><mo >′</mo></msup><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo
    stretchy="false" >(</mo><mrow ><mi >ψ</mi><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo stretchy="false"  >(</mo><msup ><mi >𝐱</mi><mi >t</mi></msup><mo stretchy="false"
    >)</mo></mrow></mrow><mo stretchy="false" >)</mo></mrow></mrow><mo stretchy="false"
    >)</mo></mrow></mrow></mrow><mo >]</mo></mrow></mrow></mrow><mo >,</mo></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐿</ci><ci  ><mtext mathsize="70%"  >MDD</mtext></ci></apply><interval closure="open"  ><ci
    >ℎ</ci><ci >𝜓</ci></interval></apply><apply ><apply ><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ℎ</ci><ci >′</ci></apply></apply><apply ><ci >𝛾</ci><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝔼</ci><apply ><csymbol cd="latexml" >similar-to</csymbol><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝐱</ci><ci >𝑠</ci></apply><apply
    ><ci >^</ci><ci >𝒮</ci></apply></apply></apply><apply ><apply ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝜎</ci><apply ><ci >ℎ</ci><apply ><ci >𝜓</ci><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝐱</ci><ci >𝑠</ci></apply></apply></apply></apply><apply
    ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci >ℎ</ci><ci >′</ci></apply><apply
    ><ci >𝜓</ci><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝐱</ci><ci
    >𝑠</ci></apply></apply></apply></apply></apply></apply></apply><apply ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝔼</ci><apply ><csymbol cd="latexml"  >similar-to</csymbol><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><ci >𝐱</ci><ci >𝑡</ci></apply><apply
    ><ci >^</ci><ci >𝒯</ci></apply></apply></apply><apply ><apply ><cn type="integer"  >1</cn><apply
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝜎</ci><apply ><ci >ℎ</ci><apply
    ><ci >𝜓</ci><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝐱</ci><ci
    >𝑡</ci></apply></apply></apply></apply><apply ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >ℎ</ci><ci >′</ci></apply><apply ><ci >𝜓</ci><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >𝐱</ci><ci >𝑡</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}L_{\text{MDD}}(h,\psi)=\max_{h^{\prime}}\
    \gamma&\ \mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}\log\left[\sigma_{h(\psi(\mathbf{x}^{s}))}(h^{\prime}(\psi(\mathbf{x}^{s})))\right]\\
    +&\ \mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}\log\left[1-\sigma_{h(\psi(\mathbf{x}^{t}))}(h^{\prime}(\psi(\mathbf{x}^{t})))\right],\\
    \end{split}</annotation></semantics></math> |  | (34) |
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: \end{split}" display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt" ><mtr ><mtd columnalign="right" ><mrow ><mrow ><msub ><mi >L</mi><mtext
    >MDD</mtext></msub><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo stretchy="false"
    >(</mo><mi  >h</mi><mo >,</mo><mi >ψ</mi><mo stretchy="false" >)</mo></mrow></mrow><mo
    >=</mo><mrow ><munder ><mi  >max</mi><msup ><mi >h</mi><mo >′</mo></msup></munder><mo
    lspace="0.167em"  >⁡</mo><mi >γ</mi></mrow></mrow></mtd><mtd columnalign="left"
    ><mrow ><msub ><mi  >𝔼</mi><mrow ><msup ><mi >𝐱</mi><mi >s</mi></msup><mo >∼</mo><mover
    accent="true"  ><mi >𝒮</mi><mo >^</mo></mover></mrow></msub><mo lspace="0.167em"
    rspace="0em"  >​</mo><mrow ><mi  >log</mi><mo >⁡</mo><mrow ><mo  >[</mo><mrow
    ><msub ><mi >σ</mi><mrow ><mi >h</mi><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo stretchy="false"  >(</mo><mrow ><mi >ψ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false"  >(</mo><msup ><mi >𝐱</mi><mi >s</mi></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" >(</mo><mrow ><msup ><mi >h</mi><mo >′</mo></msup><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo stretchy="false" >(</mo><mrow ><mi >ψ</mi><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo stretchy="false"  >(</mo><msup ><mi >𝐱</mi><mi
    >s</mi></msup><mo stretchy="false" >)</mo></mrow></mrow><mo stretchy="false" >)</mo></mrow></mrow><mo
    stretchy="false" >)</mo></mrow></mrow><mo >]</mo></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="right" ><mo >+</mo></mtd><mtd columnalign="left" ><mrow ><mrow
    ><msub ><mi >𝔼</mi><mrow ><msup ><mi >𝐱</mi><mi >t</mi></msup><mo >∼</mo><mover
    accent="true" ><mi >𝒯</mi><mo >^</mo></mover></mrow></msub><mo lspace="0.167em"
    rspace="0em"  >​</mo><mrow ><mi  >log</mi><mo >⁡</mo><mrow ><mo  >[</mo><mrow
    ><mn >1</mn><mo  >−</mo><mrow ><msub ><mi >σ</mi><mrow ><mi >h</mi><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo stretchy="false" >(</mo><mrow ><mi >ψ</mi><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo stretchy="false"  >(</mo><msup ><mi >𝐱</mi><mi
    >t</mi></msup><mo stretchy="false"  >)</mo></mrow></mrow><mo stretchy="false"  >)</mo></mrow></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >(</mo><mrow ><msup
    ><mi >h</mi><mo >′</mo></msup><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo
    stretchy="false" >(</mo><mrow ><mi >ψ</mi><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo stretchy="false"  >(</mo><msup ><mi >𝐱</mi><mi >t</mi></msup><mo stretchy="false"
    >)</mo></mrow></mrow><mo stretchy="false" >)</mo></mrow></mrow><mo stretchy="false"
    >)</mo></mrow></mrow></mrow><mo >]</mo></mrow></mrow></mrow><mo >,</mo></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝐿</ci><ci  ><mtext mathsize="70%"  >MDD</mtext></ci></apply><interval closure="open"  ><ci
    >ℎ</ci><ci >𝜓</ci></interval></apply><apply ><apply ><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ℎ</ci><ci >′</ci></apply></apply><apply ><ci >𝛾</ci><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝔼</ci><apply ><csymbol cd="latexml" >similar-to</csymbol><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝐱</ci><ci >𝑠</ci></apply><apply
    ><ci >^</ci><ci >𝒮</ci></apply></apply></apply><apply ><apply ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝜎</ci><apply ><ci >ℎ</ci><apply ><ci >𝜓</ci><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝐱</ci><ci >𝑠</ci></apply></apply></apply></apply><apply
    ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci >ℎ</ci><ci >′</ci></apply><apply
    ><ci >𝜓</ci><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝐱</ci><ci
    >𝑠</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}L_{\text{MDD}}(h,\psi)=\max_{h^{\prime}}\
    \gamma&\ \mathbb{E}_{\mathbf{x}^{s}\sim\widehat{\mathcal{S}}}\log\left[\sigma_{h(\psi(\mathbf{x}^{s}))}(h^{\prime}(\psi(\mathbf{x}^{s})))\right]\\
    +&\ \mathbb{E}_{\mathbf{x}^{t}\sim\widehat{\mathcal{T}}}\log\left[1-\sigma_{h(\psi(\mathbf{x}^{t}))}(h^{\prime}(\psi(\mathbf{x}^{t})))\right],\\
    \end{split}</annotation></semantics></math> |  | (34) |
- en: 'where $\sigma$ is the softmax function. A proper $\gamma$ can constrain $h^{\prime}$
    in a hypothesis space of proper size to avoid overestimation of the generalization
    bound. Note that in Equation [34](#S3.E34 "In 3.2.3 Hypothesis Adversarial Learning
    ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"),
    the loss on the source domain is the standard cross-entropy, while that on the
    target domain is a modified cross-entropy to avoid gradient vanishing and ease
    the optimization of $h^{\prime}$.'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '其中$\sigma$是softmax函数。适当的$\gamma$可以将$h^{\prime}$约束在适当大小的假设空间中，以避免对泛化界限的过度估计。注意在方程[34](#S3.E34
    "In 3.2.3 Hypothesis Adversarial Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")中，源领域上的损失是标准交叉熵，而目标领域上的损失是修改过的交叉熵，以避免梯度消失并简化$h^{\prime}$的优化。'
- en: 'In principle, DD can be easily extended to regression problems by replacing
    the classifiers in Figure [22](#S3.F22 "Figure 22 ‣ 3.2.3 Hypothesis Adversarial
    Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey") with regressors and choosing $L^{s}$ and $L^{t}$ as the $L_{1}$ or
    $L_{2}$ loss commonly used in regression. It has been extended to both keypoint
    detection (Jiang et al., [2021](#bib.bib80)) and bounding box localization task
    (Jiang et al., [2022](#bib.bib81)). To tackle the challenge caused by the high-dimensional
    output space in the keypoint detection, Regressive Domain Adaptation (RegDA) (Jiang
    et al., [2021](#bib.bib80)) introduces a spatial probability distribution to describe
    the sparse density of the output space and uses it to guide the optimization of
    the adversarial regressor $h^{\prime}$. In an expectation sense, this reduces
    the size of the hypothesis space of $h^{\prime}$ and avoids overestimation of
    the generalization bound in Zhang et al. ([2019c](#bib.bib204)).'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '原则上，通过将图中的分类器[22](#S3.F22 "Figure 22 ‣ 3.2.3 Hypothesis Adversarial Learning
    ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")替换为回归器，并选择$L^{s}$和$L^{t}$作为回归中常用的$L_{1}$或$L_{2}$损失，DD可以很容易地扩展到回归问题。它已经扩展到关键点检测（Jiang等，[2021](#bib.bib80)）和边界框定位任务（Jiang等，[2022](#bib.bib81)）。为了应对关键点检测中高维输出空间带来的挑战，回归领域适应（RegDA）（Jiang等，[2021](#bib.bib80)）引入了一种空间概率分布来描述输出空间的稀疏密度，并用它来指导对抗回归器$h^{\prime}$的优化。在期望意义上，这减少了$h^{\prime}$的假设空间的大小，并避免了Zhang等（[2019c](#bib.bib204)）中过度估计泛化界限的问题。'
- en: 3.2.4 Domain Translation
  id: totrans-414
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.4 领域翻译
- en: Domain translation is the task of mapping *raw data* of text, image, audio,
    and other data modality from the source distribution $\mathcal{S}$ to the target
    distribution $\mathcal{T}$. In domain adaptation problems, we can use translation
    models, usually based on Generate Adversarial Networks (GAN) (Goodfellow et al.,
    [2014](#bib.bib54)), to obtain labeled source domain in the target style, i.e.
    translated into the target distribution. Training on such stylized source domain
    can yield better transferability than models trained on the original source domain.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 领域翻译是将来自源分布$\mathcal{S}$的文本、图像、音频和其他数据模态的*原始数据*映射到目标分布$\mathcal{T}$的任务。在领域适应问题中，我们可以使用翻译模型，通常基于生成对抗网络（GAN）（Goodfellow等，[2014](#bib.bib54)），以获得目标风格的标注源领域，即翻译成目标分布。对这种风格化源领域的训练可以比对原始源领域训练的模型获得更好的迁移能力。
- en: '![Refer to caption](img/e3ca12b264f23573a911cf2a886a0d1c.png)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/e3ca12b264f23573a911cf2a886a0d1c.png)'
- en: 'Figure 23: (a) The architecture for PixelDA includes a generator network $G$,
    an adversarial discriminator $D$ and a task-specific classifier $h$ on feature
    extractor $\psi$. (b) Cycle-consistency loss: after we translate from source domain
    to target domain, we should recover the source data if translating back again.
    (c) Semantic-consistency loss: translating between domains should not change the
    semantic labels of the samples, where $f$ is the labeling function.'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 图23：（a）PixelDA的架构包括一个生成器网络$G$、一个对抗判别器$D$和一个任务特定的分类器$h$，位于特征提取器$\psi$上。（b）循环一致性损失：在从源领域翻译到目标领域后，如果再翻译回源领域，我们应该恢复源数据。（c）语义一致性损失：领域间的翻译不应改变样本的语义标签，其中$f$是标注函数。
- en: GANs reason about the marginal distribution, i.e., from a random vector, the
    generator network should synthesize data that resembles one that is drawn from
    the true distribution. However, marginal distribution is not enough for domain
    adaptation, thus Coupled Generative Adversarial Networks (CoGAN) (Liu and Tuzel,
    [2016](#bib.bib106)) learns a joint distribution of multi-domain images from data,
    i.e., from a random vector, multiple generators should generate paired data that
    are from different distributions and share the same labels. By enforcing a weight-sharing
    constraint between different generators, CoGAN learns a joint distribution without
    the existence of corresponding images in different domains. Then the shared labels
    of the target samples are used to train the target model.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 关注于边际分布，即从一个随机向量，生成器网络应合成与从真实分布中抽取的数据相似的数据。然而，边际分布对于领域适应来说还不够，因此耦合生成对抗网络（CoGAN）
    (Liu and Tuzel, [2016](#bib.bib106)) 从数据中学习多领域图像的联合分布，即从一个随机向量，多个生成器应生成配对的数据，这些数据来自不同的分布并且共享相同的标签。通过在不同生成器之间强制共享权重约束，CoGAN
    学习了一个联合分布，而不需要不同领域中存在对应的图像。然后，目标样本的共享标签被用来训练目标模型。
- en: 'A more common objective of domain translation is to learn a mapping $G:\mathcal{S}\rightarrow\mathcal{T}$
    such that the generated sample $G(\mathbf{x})$ is indistinguishable from the training
    samples of the target domain. As shown in Figure [23](#S3.F23 "Figure 23 ‣ 3.2.4
    Domain Translation ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in
    Deep Learning: A Survey"), PixelDA (Bousmalis et al., [2017](#bib.bib16)) introduces
    an adversarial discriminator $D$ to distinguish between translated samples and
    target samples,'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 域翻译的一个更常见的目标是学习一个映射 $G:\mathcal{S}\rightarrow\mathcal{T}$，使得生成的样本 $G(\mathbf{x})$
    与目标领域的训练样本不可区分。如图 [23](#S3.F23 "图 23 ‣ 3.2.4 域翻译 ‣ 3.2 域适应 ‣ 3 适应 ‣ 深度学习中的可转移性：调查")
    所示，PixelDA (Bousmalis et al., [2017](#bib.bib16)) 引入了一个对抗判别器 $D$ 来区分翻译样本和目标样本，
- en: '|  | $\displaystyle L_{\mathrm{GAN}}(G)$ | $\displaystyle=\max_{D}\mathbb{E}_{\mathbf{x}\sim\widehat{\mathcal{S}}}\log\left[1-D(G(\mathbf{x}))\right]+\mathbb{E}_{\mathbf{x}\sim\widehat{\mathcal{T}}}\log\left[D(\mathbf{x})\right].$
    |  | (35) |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle L_{\mathrm{GAN}}(G)$ | $\displaystyle=\max_{D}\mathbb{E}_{\mathbf{x}\sim\widehat{\mathcal{S}}}\log\left[1-D(G(\mathbf{x}))\right]+\mathbb{E}_{\mathbf{x}\sim\widehat{\mathcal{T}}}\log\left[D(\mathbf{x})\right].$
    |  | (35) |'
- en: The generator $G$ tries to synthesize samples $G(\mathbf{x})$ that look similar
    to images from the target domain by $\min_{G}L_{\mathrm{GAN}}(G)$. The task-specific
    classifier $h$ and feature extractor $\psi$ are trained supervisedly on the target-style
    generated data by $\min_{\psi,h}\mathbb{E}_{(\mathbf{x},\mathbf{y})\sim\widehat{\mathcal{S}}}L_{\text{sup}}(h\circ\psi(G(\mathbf{x})),\mathbf{y})$.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器 $G$ 通过 $\min_{G}L_{\mathrm{GAN}}(G)$ 尝试合成看起来与目标领域图像相似的样本 $G(\mathbf{x})$。任务特定的分类器
    $h$ 和特征提取器 $\psi$ 通过 $\min_{\psi,h}\mathbb{E}_{(\mathbf{x},\mathbf{y})\sim\widehat{\mathcal{S}}}L_{\text{sup}}(h\circ\psi(G(\mathbf{x})),\mathbf{y})$
    在目标风格生成数据上进行监督训练。
- en: Cycle Consistency.
  id: totrans-422
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 循环一致性。
- en: 'While GAN can learn a mapping between two datasets, the desired mapping may
    not be obtained. The source sample may be projected to an irrelevant target sample,
    destroying the structure or content of the original samples. Besides, multiple
    source samples may be mapped to the same target sample, leading to the well-known
    problem of *mode collapse* (Goodfellow et al., [2014](#bib.bib54)). Therefore,
    CycleGAN (Zhu et al., [2017](#bib.bib209)) introduces an additional mapping $F:\mathcal{T}\rightarrow\mathcal{S}$
    from target to source and adds a constraint of cycle consistency to reduce the
    space of possible mapping functions (Figure [23](#S3.F23 "Figure 23 ‣ 3.2.4 Domain
    Translation ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey")). Mathematically, cycle consistency requires $F$ and $G$ to be bijections
    and inverse of each other. In practice, CycleGAN constrains $F(G(\mathbf{x}))\approx\mathbf{x}$
    and $G(F(\mathbf{x}))\approx\mathbf{x}$, which preserves the structure or content
    of samples to obtain more meaningful mappings. CycleGAN has been widely used in
    domain adaptation problems, such as image classification (Hoffman et al., [2018](#bib.bib72)),
    semantic segmentation (Hoffman et al., [2018](#bib.bib72)), person re-identification
    (Wei et al., [2018](#bib.bib189)), robotic grasping (Bousmalis et al., [2018](#bib.bib17)),
    object detection (Kim et al., [2019](#bib.bib85)), etc. The idea goes beyond the
    field of image translation and is widely used in other fields, such as unsupervised
    machine translation (Lample et al., [2017](#bib.bib92)), where the cycle consistency
    is also called back-translation. Unsupervised machine translation can further
    be used for cross-lingual domain adaptation tasks (Conneau et al., [2018](#bib.bib33)),
    where a language is a domain.'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管GAN可以学习两个数据集之间的映射，但可能无法获得期望的映射。源样本可能会被投影到一个不相关的目标样本中，从而破坏原始样本的结构或内容。此外，多个源样本可能被映射到相同的目标样本，这导致了著名的*模式崩溃*问题（Goodfellow等，[2014](#bib.bib54)）。因此，CycleGAN（Zhu等，[2017](#bib.bib209)）引入了一个从目标到源的额外映射$F:\mathcal{T}\rightarrow\mathcal{S}$，并添加了一个循环一致性的约束，以减少可能的映射函数空间（图
    [23](#S3.F23 "Figure 23 ‣ 3.2.4 Domain Translation ‣ 3.2 Domain Adaptation ‣ 3
    Adaptation ‣ Transferability in Deep Learning: A Survey")）。在数学上，循环一致性要求$F$和$G$是双射且互为逆。在实践中，CycleGAN约束$F(G(\mathbf{x}))\approx\mathbf{x}$和$G(F(\mathbf{x}))\approx\mathbf{x}$，这保留了样本的结构或内容，从而获得更有意义的映射。CycleGAN已被广泛应用于领域适应问题，如图像分类（Hoffman等，[2018](#bib.bib72)）、语义分割（Hoffman等，[2018](#bib.bib72)）、人员重新识别（Wei等，[2018](#bib.bib189)）、机器人抓取（Bousmalis等，[2018](#bib.bib17)）、物体检测（Kim等，[2019](#bib.bib85)）等。这个理念不仅限于图像翻译领域，还广泛应用于其他领域，如无监督机器翻译（Lample等，[2017](#bib.bib92)），其中循环一致性也称为回译。无监督机器翻译还可以进一步用于跨语言领域适应任务（Conneau等，[2018](#bib.bib33)），在这些任务中，一种语言即是一个领域。'
- en: Semantic Consistency.
  id: totrans-424
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 语义一致性。
- en: 'CycleGAN is a general-purpose translation model for vision tasks and is apt
    at style transfer between datasets. However, it is difficult for CycleGAN to maintain
    the semantic information. It has been experimentally shown that when mapping from
    source to target, the problem of label flipping will easily occur (Bousmalis et al.,
    [2017](#bib.bib16); Hoffman et al., [2018](#bib.bib72)). As a result, there will
    exist a lot of noisy labels in the translated dataset, hurting the performance
    of the target model. Thus, ensuring semantic consistency is important for translation-based
    domain adaptation. Formally, given the labeling function $f$, the labels assigned
    to sample $\mathbf{x}$ should be consistent with that of the translated sample,
    i.e., $f(\mathbf{x})=f(G(\mathbf{x}))$ (Figure [23](#S3.F23 "Figure 23 ‣ 3.2.4
    Domain Translation ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in
    Deep Learning: A Survey")). Since function $f$ is not accessible, several proxy
    functions have been proposed to approximate the semantic consistency (Taigman
    et al., [2017](#bib.bib169); Hoffman et al., [2018](#bib.bib72); Bousmalis et al.,
    [2018](#bib.bib17)). Given a proxy function $h_{\mathrm{p}}$ and a distance measure
    $d$, the objective is to reduce the semantic inconsistency,'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 'CycleGAN 是一个通用的视觉任务翻译模型，擅长数据集之间的风格迁移。然而，CycleGAN 难以保持语义信息。实验表明，从源到目标的映射过程中，标签翻转问题很容易发生（Bousmalis
    等，[2017](#bib.bib16); Hoffman 等，[2018](#bib.bib72)）。因此，翻译数据集中会存在大量噪声标签，影响目标模型的性能。因此，确保语义一致性对于基于翻译的领域适应非常重要。形式上，给定标记函数
    $f$，分配给样本 $\mathbf{x}$ 的标签应该与翻译样本的一致，即 $f(\mathbf{x})=f(G(\mathbf{x}))$（图 [23](#S3.F23
    "Figure 23 ‣ 3.2.4 Domain Translation ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣
    Transferability in Deep Learning: A Survey")）。由于函数 $f$ 不可访问，已经提出了几种代理函数来近似语义一致性（Taigman
    等，[2017](#bib.bib169); Hoffman 等，[2018](#bib.bib72); Bousmalis 等，[2018](#bib.bib17)）。给定代理函数
    $h_{\mathrm{p}}$ 和距离度量 $d$，目标是减少语义不一致。'
- en: '|  | $\min_{G}L_{\mathrm{sc}}(G,h_{\mathrm{p}})=d(h_{\mathrm{p}}(\mathbf{x}),h_{\mathrm{p}}(G(\mathbf{x}))).$
    |  | (36) |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{G}L_{\mathrm{sc}}(G,h_{\mathrm{p}})=d(h_{\mathrm{p}}(\mathbf{x}),h_{\mathrm{p}}(G(\mathbf{x}))).$
    |  | (36) |'
- en: DTN (Taigman et al., [2017](#bib.bib169)) and SimGAN (Shrivastava et al., [2017](#bib.bib157))
    use the feature extractor as a proxy function and the goal is to translate the
    low-level style while keeping the high-level features invariant. PersonGAN (Wei
    et al., [2018](#bib.bib189)) uses the foreground crop of the person image as the
    proxy function of the person’s identity, which ensures that a person’s identity
    remains the same before and after translation. However, the constraint on feature
    or pixel space might be too strong, making it difficult to change the low-level
    style. Therefore, Cycle-consistent Adversarial Adaptation (CyCADA) (Hoffman et al.,
    [2018](#bib.bib72)) utilizes a pre-trained source model as a proxy function to
    encourage generating samples that have consistent predictions under the function.
    This proxy function effectively avoids label flipping during the translation of
    handwritten digit images, yet it is still not perfect. When faced with the dataset
    shift of real-world problems, the predictions on the generated samples are not
    reliable and may provide incorrect guidance to $G$.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: DTN（Taigman 等，[2017](#bib.bib169)）和 SimGAN（Shrivastava 等，[2017](#bib.bib157)）使用特征提取器作为代理函数，目标是在保持高层次特征不变的情况下，转换低层次的风格。PersonGAN（Wei
    等，[2018](#bib.bib189)）将人物图像的前景裁剪作为人物身份的代理函数，这确保了翻译前后人物身份保持一致。然而，特征或像素空间的约束可能过强，使得改变低层次风格变得困难。因此，Cycle-consistent
    Adversarial Adaptation（CyCADA）（Hoffman 等，[2018](#bib.bib72)）利用预训练的源模型作为代理函数，鼓励生成在该函数下具有一致预测的样本。该代理函数有效地避免了在手写数字图像翻译过程中标签翻转，但仍然不完美。当面临现实世界问题的数据集转移时，对生成样本的预测不可靠，可能会对$G$提供错误的指导。
- en: 'When the domain difference is primarily low-level, such as textures, illumination,
    and color, translation can effectively close the domain gap. But when the domain
    is different at the high level, such as from different camera angles, translation
    may fail to adapt domains. Therefore, translation methods at the low-level and
    adaptation methods at the high-level mentioned in Section [3.2.1](#S3.SS2.SSS1
    "3.2.1 Statistics Matching ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability
    in Deep Learning: A Survey")-[3.2.3](#S3.SS2.SSS3 "3.2.3 Hypothesis Adversarial
    Learning ‣ 3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning:
    A Survey") are complementary and can be combined in practical applications (Hoffman
    et al., [2018](#bib.bib72)). For example, Generate to Adapt (Sankaranarayanan
    et al., [2018](#bib.bib149)) directly uses the generative task as an auxiliary
    task to align features across domains.'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 当领域差异主要是低层次的，例如纹理、照明和颜色时，翻译可以有效地缩小领域差距。但是，当领域在高层次上不同，例如来自不同的相机角度时，翻译可能无法适应领域。因此，第[3.2.1](#S3.SS2.SSS1
    "3.2.1 统计匹配 ‣ 3.2 领域适应 ‣ 3 适应 ‣ 深度学习中的可迁移性：一项调查")节和[3.2.3](#S3.SS2.SSS3 "3.2.3
    假设对抗学习 ‣ 3.2 领域适应 ‣ 3 适应 ‣ 深度学习中的可迁移性：一项调查")节中提到的低层次的翻译方法和高层次的适应方法是互补的，可以在实际应用中结合使用（Hoffman
    等，[2018](#bib.bib72)）。例如，Generate to Adapt（Sankaranarayanan 等，[2018](#bib.bib149)）直接将生成任务作为辅助任务来对齐跨领域的特征。
- en: 3.2.5 Semi-Supervised Learning
  id: totrans-429
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.5 半监督学习
- en: 'Unsupervised Domain Adaptation (UDA) is closely related to Semi-Supervised
    Learning (SSL) since both of them aim at generalizing from the labeled samples
    to the unlabeled samples. The difference is that in SSL, both the labeled and
    unlabeled samples come from the same distribution while in UDA, the source and
    target distributions differ. Thus, SSL tasks can be considered as a special case
    of UDA tasks and some SSL methods can be applied in UDA tasks. Since there is
    still no theoretical guarantee for SSL methods in the UDA scenario, the first
    question to answer is, under what assumptions can we use SSL in UDA? There are
    mainly three assumptions in SSL (Chapelle et al., [2006](#bib.bib21)). (1) Smoothness
    Assumption: if two samples $\mathbf{x}_{1}$, $\mathbf{x}_{2}$ residing in a high-density
    region are close, then so should be their corresponding outputs $\mathbf{y}_{1}$,
    $\mathbf{y}_{2}$ . (2) Cluster Assumption: if points are in the same cluster,
    they are likely to be of the same class. It can also be interpreted as the Low-density
    Separation Assumption, where the decision boundary should lie in the low-density
    regions. (3) Manifold Assumption: the high-dimensional data shall lie roughly
    on a low-dimensional manifold. Both smoothness assumption and cluster assumption
    are helpful for classification, but not for regression problems. Thus SSL is used
    more commonly in classifier adaptation. Here we review several SSL methods applied
    to the UDA problems.'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督领域适应（UDA）与半监督学习（SSL）密切相关，因为它们的目标都是从标记样本推广到未标记样本。不同之处在于，SSL 中，标记和未标记样本来自相同的分布，而在
    UDA 中，源分布和目标分布不同。因此，SSL 任务可以视为 UDA 任务的特例，某些 SSL 方法可以应用于 UDA 任务。由于在 UDA 场景中仍然没有
    SSL 方法的理论保证，第一个需要回答的问题是，在什么假设下我们可以在 UDA 中使用 SSL？SSL 主要有三种假设（Chapelle 等，[2006](#bib.bib21)）。(1)
    平滑性假设：如果两个样本 $\mathbf{x}_{1}$，$\mathbf{x}_{2}$ 位于高密度区域并且接近，那么它们对应的输出 $\mathbf{y}_{1}$，$\mathbf{y}_{2}$
    也应该接近。(2) 聚类假设：如果点在同一个簇中，它们很可能属于同一类别。这也可以解释为低密度分离假设，其中决策边界应位于低密度区域。(3) 流形假设：高维数据应大致位于低维流形上。平滑性假设和聚类假设对分类有帮助，但对回归问题则不然。因此，SSL
    在分类器适应中更常用。这里我们回顾几种应用于 UDA 问题的 SSL 方法。
- en: Consistency Regularization encourages consistent predictions for similar data
    points. Similar data points are generated by performing different data augmentations
    on the same data point. While many augmentation techniques are proposed for images,
    few are available for other data formats, such as texts and time series. Thus
    this type of method is limited to certain data modalities. Self-Ensemble (French
    et al., [2018](#bib.bib44)) applies mean-teacher, a typical consistency regularization
    method, to image domain adaptation. The teacher model, which is an Exponential
    Moving Average (EMA) of the student model, will generate predictions to train
    the student model on the target domain. Due to the domain shift, the predictions
    are noisy, thus Mutual Mean-Teaching (MMT) (Ge et al., [2020](#bib.bib48)) uses
    two collaborative networks jointly optimized under the supervision of mutual teacher
    models.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性正则化鼓励对相似数据点做出一致的预测。相似的数据点是通过对同一数据点进行不同的数据增强生成的。虽然已经提出了许多用于图像的增强技术，但对于文本和时间序列等其他数据格式的技术很少。因此，这种方法仅限于特定的数据模态。自集成（French
    等人，[2018](#bib.bib44)）将均值教师法，一种典型的一致性正则化方法，应用于图像领域的适应。教师模型是学生模型的指数移动平均（EMA），它将生成预测以训练学生模型在目标领域。由于领域偏移，预测噪声较多，因此互均值教学（MMT）（Ge
    等人，[2020](#bib.bib48)）使用两个协作网络，在相互教师模型的监督下联合优化。
- en: Entropy Minimization encourages the model to make confident (i.e., low-entropy)
    predictions on unlabeled data. It serves as an auxiliary term in many domain adaptation
    methods (Long et al., [2016](#bib.bib113), [2018](#bib.bib115); Saito et al.,
    [2018](#bib.bib146); Shu et al., [2018](#bib.bib158); Vu et al., [2019](#bib.bib182)).
    The risk is that the predictions on the target domain are not reliable, and entropy
    minimization may hurt the performance of the model. Thus, Minimum Class Confusion
    (MCC) (Jin et al., [2020](#bib.bib82)) introduces a weight for each instance,
    where uncertain samples have smaller weights to avoid minimizing entropy on the
    incorrectly classified samples. MCC further minimizes the instance-weighted confusion
    between different classes, which is simple yet frustratingly effective. Source
    Hypothesis Transfer (Liang et al., [2020](#bib.bib104)) adopts an information
    maximization loss with a fair diversity-promoting objective, which circumvents
    the trivial solutions in entropy minimization that all unlabeled data have the
    same one-hot encoding.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 熵最小化鼓励模型在未标记数据上做出自信的（即低熵）预测。它作为许多领域适应方法中的辅助项（Long 等人，[2016](#bib.bib113)，[2018](#bib.bib115)；Saito
    等人，[2018](#bib.bib146)；Shu 等人，[2018](#bib.bib158)；Vu 等人，[2019](#bib.bib182)）。风险在于目标领域的预测不可靠，熵最小化可能会损害模型的性能。因此，最小类别混淆（MCC）（Jin
    等人，[2020](#bib.bib82)）为每个实例引入了一个权重，其中不确定样本的权重较小，以避免在错误分类的样本上最小化熵。MCC 进一步最小化了不同类别之间的实例加权混淆，这种方法简单却有效。源假设转移（Liang
    等人，[2020](#bib.bib104)）采用了信息最大化损失，具有公平的多样性促进目标，这避免了熵最小化中所有未标记数据具有相同独热编码的平庸解决方案。
- en: Pseudo-Labeling produces proxy labels on unlabeled data and uses these noisy
    labels together with the labeled data to train the model. In self-training, a
    confidence threshold is used to filter out unreliable proxy labels, which may
    fail in UDA since the model is likely to be biased towards well-transferred classes
    while ignoring other hard classes. Thus, Class-Balanced Self-Training (CBST) (Zou
    et al., [2018](#bib.bib212)) uses a class-wise confidence threshold. Still, large
    noise exists in the generated pseudo labels on the target domain, and the standard
    Cross-Entropy (CE) loss has been shown to be sensitive to label noise (Zhang et al.,
    [2017](#bib.bib201)). Towards this problem, Zhang and Sabuncu ([2018](#bib.bib205))
    propose the Generalized Cross-Entropy (GCE) loss as an effective solution (Rusak
    et al., [2021](#bib.bib143); Liu et al., [2021a](#bib.bib105)),
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 伪标签生成在未标记数据上生成代理标签，并将这些噪声标签与已标记数据一起用于训练模型。在自训练中，使用置信度阈值来过滤掉不可靠的代理标签，这在UDA中可能会失败，因为模型可能会偏向于已良好转移的类别，同时忽略其他困难的类别。因此，类别平衡自训练（CBST）（Zou
    等人，[2018](#bib.bib212)）使用了类别级置信度阈值。尽管如此，目标领域生成的伪标签中仍存在较大噪声，而标准交叉熵（CE）损失已被证明对标签噪声敏感（Zhang
    等人，[2017](#bib.bib201)）。针对这一问题，Zhang 和 Sabuncu ([2018](#bib.bib205)) 提出了广义交叉熵（GCE）损失作为一种有效的解决方案（Rusak
    等人，[2021](#bib.bib143)；Liu 等人，[2021a](#bib.bib105)）。
- en: '|  | $L_{\text{GCE}}(\mathbf{x},\tilde{y})=1/q\cdot(1-h_{\tilde{y}}(\mathbf{x})^{q}),$
    |  | (37) |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '|  | $L_{\text{GCE}}(\mathbf{x},\tilde{y})=1/q\cdot(1-h_{\tilde{y}}(\mathbf{x})^{q}),$
    |  | (37) |'
- en: where $q\in(0,1]$ is a hyper-parameter to trade-off between the CE loss and
    the MAE loss.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $q\in(0,1]$ 是一个超参数，用于在CE损失和MAE损失之间进行权衡。
- en: 3.2.6 Remarks
  id: totrans-436
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.6 备注
- en: 'Different domain adaptation methods are compared from several perspectives
    in Table [5](#S3.T5 "Table 5 ‣ 3.2.6 Remarks ‣ 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey"). First, statistics matching, domain
    adversarial learning, and hypothesis adversarial learning methods are derived
    from theory, enjoying theoretical guarantees while domain translation and semi-supervised
    learning methods are still in the empirical regime. Second, the former three categories
    of methods work in the feature space or the output space and are highly related
    to specific tasks, and some are tightly integrated to specific architectures.
    In contrast, translation methods work in the input space and are relatively independent
    of specific tasks. However, translation models and semi-supervised learning are
    dependent on specific data format, and are hard to scale to different modalities.
    Finally, statistics matching methods are based on nonparametric distances, which
    are data-efficient but weak in expressiveness, thereby more suitable for low-data
    regimes. In contrast, domain adversarial learning and hypothesis adversarial learning
    methods are based on parametric distances, which can only be measured throughout
    learning, but are more performant when scaling up data.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: '在表格[5](#S3.T5 "Table 5 ‣ 3.2.6 Remarks ‣ 3.2 Domain Adaptation ‣ 3 Adaptation
    ‣ Transferability in Deep Learning: A Survey")中，从多个角度比较了不同的领域适应方法。首先，统计匹配、领域对抗学习和假设对抗学习方法源于理论，享有理论保障，而领域翻译和半监督学习方法仍处于经验阶段。其次，前面三类方法在特征空间或输出空间中工作，与特定任务高度相关，其中一些方法与特定架构紧密集成。相比之下，翻译方法在输入空间中工作，与特定任务相对独立。然而，翻译模型和半监督学习依赖于特定的数据格式，并且难以扩展到不同的模态。最后，统计匹配方法基于非参数距离，这些方法数据效率高但表现力弱，因此更适合低数据情况。相比之下，领域对抗学习和假设对抗学习方法基于参数距离，这些距离只能在学习过程中测量，但在扩展数据时性能更好。'
- en: 'Table 5: Comparison between different domain adaptation methods.'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：不同领域适应方法的比较。
- en: '|  |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '&#124; Adaptation &#124;'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 适应性 &#124;'
- en: '&#124; Performance¹ &#124;'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 性能¹ &#124;'
- en: '|'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Data &#124;'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 数据 &#124;'
- en: '&#124; Efficiency² &#124;'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 效率² &#124;'
- en: '|'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Modality &#124;'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模态 &#124;'
- en: '&#124; Scalability³ &#124;'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可扩展性³ &#124;'
- en: '|'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Task &#124;'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 任务 &#124;'
- en: '&#124; Scalability⁴ &#124;'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可扩展性⁴ &#124;'
- en: '|'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Theory &#124;'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 理论 &#124;'
- en: '&#124; Guarantee⁵ &#124;'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 保证⁵ &#124;'
- en: '|'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Statistics Matching | $\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| 统计匹配 | $\bigstar$ | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
- en: '| Domain Adversarial Learning | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '| 领域对抗学习 | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
- en: '| Hypothesis Adversarial Learning | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$
    | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| 假设对抗学习 | $\bigstar\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar\bigstar$ | $\bigstar\bigstar\bigstar$ |'
- en: '| Domain Translation | $\bigstar\bigstar$ | $\bigstar$ | $\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar$ |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| 领域翻译 | $\bigstar\bigstar$ | $\bigstar$ | $\bigstar$ | $\bigstar\bigstar\bigstar$
    | $\bigstar$ |'
- en: '| Semi-Supervised Learning | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar$
    | $\bigstar$ | $\bigstar$ |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| 半监督学习 | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar\bigstar$ | $\bigstar$
    | $\bigstar$ |'
- en: '1'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1'
- en: 'Performance: performance when there are large-scale data in source and target
    domains.'
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 性能：在源域和目标域有大规模数据时的性能。
- en: '2'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2'
- en: 'Data Efficiency: performance when there are only small-scale data in source
    and target domains.'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据效率：在源域和目标域仅有小规模数据时的性能。
- en: '3'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '3'
- en: 'Modality Scalability: whether can adapt the model to various modalities, such
    as text, time series.'
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模态可扩展性：是否可以将模型适应于各种模态，例如文本、时间序列。
- en: '4'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '4'
- en: 'Task Scalability: whether can adapt the model to different tasks, such as regression,
    detection.'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任务可扩展性：是否可以将模型适应于不同任务，例如回归、检测。
- en: '5'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '5'
- en: 'Theory Guarantee: whether the generalization error of target domain can be
    bounded in adaptation.'
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 理论保证：在适应过程中目标域的泛化误差是否可以被界定。
- en: 'Domain adaptation is closely related to pre-training and task adaptation. First,
    pre-training can boost the *transferability* in domain adaptation, since pre-training
    will reduce the allowed hypothesis space and decrease the generalization bound
    on the target domain, as mentioned in Section [3.2](#S3.SS2 "3.2 Domain Adaptation
    ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey"). Thus pre-training
    on the source domain also serves as the first step in many domain adaptation methods,
    such as RegDA (Jiang et al., [2021](#bib.bib80)). Pre-training also provides some
    new solutions for domain adaptation. When there exists a large unlabeled target
    domain, a feasible solution is to first perform unsupervised pre-training on the
    target domain, and then fine-tune with the labeled data on the source domain.
    This is widely adopted in cross-lingual adaptation (Lample and Conneau, [2019](#bib.bib91)).'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '领域适应与预训练和任务适应密切相关。首先，预训练可以提升领域适应中的*迁移性*，因为预训练会减少允许的假设空间并降低目标领域的泛化界限，如[3.2](#S3.SS2
    "3.2 Domain Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")节所述。因此，在许多领域适应方法中，预训练也是第一步，例如RegDA（Jiang
    et al., [2021](#bib.bib80)）。预训练还为领域适应提供了一些新的解决方案。当存在大量未标记的目标领域时，一种可行的解决方案是首先在目标领域进行无监督预训练，然后在源领域用标记数据进行微调。这在跨语言适应中得到了广泛应用（Lample
    和 Conneau, [2019](#bib.bib91)）。'
- en: 'When using pre-trained models for domain adaptation, we will also encounter
    the problems in task adaptation, such as the *catastrophic forgetting* mentioned
    in [3.1.1](#S3.SS1.SSS1 "3.1.1 Catastrophic Forgetting ‣ 3.1 Task Adaptation ‣
    3 Adaptation ‣ Transferability in Deep Learning: A Survey"). Thus, many domain
    adaptation methods babysit the learning rates to avoid catastrophic forgetting
    (Long et al., [2015](#bib.bib112); Ganin and Lempitsky, [2015](#bib.bib45)). Compared
    with task adaptation, domain adaptation increases the restriction on the task
    space, where the task of the source domain and that of the target domain must
    be the same. Due to this restriction, domain adaptation has a strict theoretical
    guarantee. But this restriction is sometimes hard to satisfy in practice since
    we cannot ensure whether the category on the unlabeled target domain is exactly
    the same as the source domain (Busto and Gall, [2017](#bib.bib19)). Therefore,
    real-world adaptation is often a mix of task adaptation and domain adaptation.
    How to explore the transferability in such a practical *open-domain* scenario
    is a problem to be solved.'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: '当使用预训练模型进行领域适应时，我们还会遇到任务适应中的问题，比如[3.1.1](#S3.SS1.SSS1 "3.1.1 Catastrophic Forgetting
    ‣ 3.1 Task Adaptation ‣ 3 Adaptation ‣ Transferability in Deep Learning: A Survey")中提到的*灾难性遗忘*。因此，许多领域适应方法会细心调整学习率以避免灾难性遗忘（Long
    et al., [2015](#bib.bib112)；Ganin 和 Lempitsky, [2015](#bib.bib45)）。与任务适应相比，领域适应对任务空间的限制更大，其中源领域和目标领域的任务必须相同。由于这一限制，领域适应具有严格的理论保证。但在实际操作中，这一限制有时难以满足，因为我们不能确保未标记目标领域的类别与源领域完全一致（Busto
    和 Gall, [2017](#bib.bib19)）。因此，现实世界的适应通常是任务适应和领域适应的混合。在这样的实际*开放领域*场景中，如何探索迁移性是一个待解决的问题。'
- en: 4 Evaluation
  id: totrans-472
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 评估
- en: 'Evaluation serves as a means for (1) measuring the performance of different
    architectures, different pre-training and adaptation methods, and (2) understanding
    the strengths and limitations of different methods. This section will elaborate
    on the evaluation of *transferability*, which is defined by the performance on
    the target task or domain. We believe that the evaluation of different methods
    should be performed on large-scale datasets for a practical and meaningful comparison.
    Thus, in Section [4.1](#S4.SS1 "4.1 Datasets ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey") we list some large-scale datasets that are suitable
    for evaluating transferability in deep learning. Since different methods are often
    based on different codebases, a fair comparison between them is rather difficult.
    To fill this blank, in Section [4.2](#S4.SS2 "4.2 Library ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey") we propose an open-source library, TLlib, to better
    evaluate transferability of different methods in a unified framework. Finally,
    Section [4.3](#S4.SS3 "4.3 Benchmark ‣ 4 Evaluation ‣ Transferability in Deep
    Learning: A Survey") provides several benchmarks for evaluating both the cross-task
    transferability and cross-domain transferability.'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 评估作为（1）衡量不同架构、不同预训练和适配方法的性能的手段，以及（2）理解不同方法的优缺点的手段。本节将详细阐述*可迁移性*的评估，该可迁移性由在目标任务或领域上的表现来定义。我们认为，不同方法的评估应在大规模数据集上进行，以便进行实际而有意义的比较。因此，在第
    [4.1](#S4.SS1 "4.1 数据集 ‣ 4 评估 ‣ 深度学习中的可迁移性：一项调查") 节中，我们列出了一些适合评估深度学习中可迁移性的大规模数据集。由于不同方法通常基于不同的代码库，它们之间的公平比较相当困难。为填补这一空白，在第
    [4.2](#S4.SS2 "4.2 库 ‣ 4 评估 ‣ 深度学习中的可迁移性：一项调查") 节中，我们提出了一个开源库 TLlib，以更好地在统一框架下评估不同方法的可迁移性。最后，第
    [4.3](#S4.SS3 "4.3 基准 ‣ 4 评估 ‣ 深度学习中的可迁移性：一项调查") 节提供了若干评估跨任务可迁移性和跨领域可迁移性的基准。
- en: 4.1 Datasets
  id: totrans-474
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 数据集
- en: To evaluate the transferability in deep learning, we list several datasets that
    are large-scale in the number of samples and categories, the richness of tasks,
    and the diversity of domains.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估深度学习中的可迁移性，我们列出了一些在样本和类别数量、任务的丰富性以及领域的多样性方面规模较大的数据集。
- en: 'The General Language Understanding Evaluation (GLUE) (Wang et al., [2019a](#bib.bib183))
    is one of the most famous benchmarks in NLP. As shown in Table [6](#S4.T6 "Table
    6 ‣ 4.1 Datasets ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey"),
    it consists of nine sentence or sentence-pair language understanding tasks, covering
    a diverse range of dataset sizes, text genres, and degrees of difficulty. It is
    widely used to evaluate the *cross-task* transferability of different pre-training
    and task adaptation methods.'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 通用语言理解评估（GLUE）（Wang et al., [2019a](#bib.bib183)）是自然语言处理领域最著名的基准之一。如表 [6](#S4.T6
    "表 6 ‣ 4.1 数据集 ‣ 4 评估 ‣ 深度学习中的可迁移性：一项调查") 所示，它包括九个句子或句子对语言理解任务，覆盖了不同的数据集规模、文本类型和难度等级。它广泛用于评估不同预训练和任务适配方法的*跨任务*可迁移性。
- en: 'Table 6: Descriptions and statistics of the GLUE datasets.'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：GLUE 数据集的描述和统计信息。
- en: '| Corpus | #Train | #Test | Metrics | Task | Domain |'
  id: totrans-478
  prefs: []
  type: TYPE_TB
  zh: '| 语料库 | #训练 | #测试 | 评估指标 | 任务 | 领域 |'
- en: '| CoLA | 8.5k | 1k | Matthews corr | acceptability | misc. |'
  id: totrans-479
  prefs: []
  type: TYPE_TB
  zh: '| CoLA | 8.5k | 1k | Matthews corr | 可接受性 | 其他 |'
- en: '| SST-2 | 67k | 1.8k | acc. | sentiment | movie reviews |'
  id: totrans-480
  prefs: []
  type: TYPE_TB
  zh: '| SST-2 | 67k | 1.8k | acc. | 情感分析 | 电影评论 |'
- en: '| MRPC | 3.7k | 1.7k | acc./F1 | paraphrase | news |'
  id: totrans-481
  prefs: []
  type: TYPE_TB
  zh: '| MRPC | 3.7k | 1.7k | acc./F1 | 意义重复 | 新闻 |'
- en: '| STS-B | 7k | 1.4k | Pearson/Spearman corr | sentence similarity | misc. |'
  id: totrans-482
  prefs: []
  type: TYPE_TB
  zh: '| STS-B | 7k | 1.4k | Pearson/Spearman corr | 句子相似性 | 其他 |'
- en: '| QQP | 364k | 391k | acc./F1 | paraphrase | social QA questions |'
  id: totrans-483
  prefs: []
  type: TYPE_TB
  zh: '| QQP | 364k | 391k | acc./F1 | 意义重复 | 社会问答问题 |'
- en: '| MNLI | 393k | 20k | matched acc./mismatched acc. | NLI | misc. |'
  id: totrans-484
  prefs: []
  type: TYPE_TB
  zh: '| MNLI | 393k | 20k | 匹配 acc./不匹配 acc. | NLI | 其他 |'
- en: '| QNLI | 105k | 5.4k | acc | QA/NLI | Wikipedia |'
  id: totrans-485
  prefs: []
  type: TYPE_TB
  zh: '| QNLI | 105k | 5.4k | acc | 问答/NLI | 维基百科 |'
- en: '| RTE | 2.5k | 3k | acc | NLI | news, Wikipedia |'
  id: totrans-486
  prefs: []
  type: TYPE_TB
  zh: '| RTE | 2.5k | 3k | acc | NLI | 新闻，维基百科 |'
- en: '| WNLI | 634 | 146 | acc | coreference/NLI | fiction books |'
  id: totrans-487
  prefs: []
  type: TYPE_TB
  zh: '| WNLI | 634 | 146 | acc | 共指/NLI | 小说 |'
- en: 'In contrast, there is no common benchmark to evaluate the transferability of
    different methods in computer vision. Table [7](#S4.T7 "Table 7 ‣ 4.1 Datasets
    ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey") lists some of the
    widely used vision datasets. Food-101, CIFAR-10, CIFAR-100, SUN397, Stanford Cars,
    FGVC Aircraft, DTD, Oxford-III Pets, Caltech-101, Oxford 102 Flowers are used
    to evaluate the transferability of different architectures under task discrepancy
    (Kornblith et al., [2019](#bib.bib88)). ImageNet-R(endition) (Hendrycks et al.,
    [2021](#bib.bib69)) and ImageNet-Sketch (Wang et al., [2019b](#bib.bib184)) are
    two variants of the ImageNet, mainly used to evaluate the *cross-domain* transferablity
    of different architectures and pre-training methods. DomainNet (Peng et al., [2019](#bib.bib128))
    has multiple domains sharing the same category space, and is used to evaluate
    the *cross-domain* transferablity of different domain adaptation methods under
    large domain shift.'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: '相比之下，没有通用的基准来评估计算机视觉中不同方法的可转移性。表 [7](#S4.T7 "Table 7 ‣ 4.1 Datasets ‣ 4 Evaluation
    ‣ Transferability in Deep Learning: A Survey") 列出了部分广泛使用的视觉数据集。Food-101、CIFAR-10、CIFAR-100、SUN397、Stanford
    Cars、FGVC Aircraft、DTD、Oxford-III Pets、Caltech-101、Oxford 102 Flowers 用于评估不同架构在任务差异下的可转移性（Kornblith
    et al., [2019](#bib.bib88)）。ImageNet-R（rendition）（Hendrycks et al., [2021](#bib.bib69)）和
    ImageNet-Sketch（Wang et al., [2019b](#bib.bib184)）是 ImageNet 的两个变体，主要用于评估不同架构和预训练方法的*跨领域*可转移性。DomainNet（Peng
    et al., [2019](#bib.bib128)）具有多个共享相同类别空间的领域，用于评估在大领域转移下不同领域适应方法的*跨领域*可转移性。'
- en: 'Table 7: Descriptions and statistics of typical vision datasets.'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：典型视觉数据集的描述和统计。
- en: '| Dataset | #Train | #Test | #Classes | Metric | Domain |'
  id: totrans-490
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | #训练 | #测试 | #类别 | 指标 | 领域 |'
- en: '| Food-101 | 75,750 | 25,250 | 101 | top-1 | photos and real world images |'
  id: totrans-491
  prefs: []
  type: TYPE_TB
  zh: '| Food-101 | 75,750 | 25,250 | 101 | top-1 | 照片和现实世界图像 |'
- en: '| CIFAR-10 | 50,000 | 10,000 | 10 | top-1 | photos and real world images |'
  id: totrans-492
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR-10 | 50,000 | 10,000 | 10 | top-1 | 照片和现实世界图像 |'
- en: '| CIFAR-100 | 50,000 | 10,000 | 100 | top-1 | photos and real world images
    |'
  id: totrans-493
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR-100 | 50,000 | 10,000 | 100 | top-1 | 照片和现实世界图像 |'
- en: '| SUN397 | 19,850 | 19,850 | 397 | top-1 | photos and real world images |'
  id: totrans-494
  prefs: []
  type: TYPE_TB
  zh: '| SUN397 | 19,850 | 19,850 | 397 | top-1 | 照片和现实世界图像 |'
- en: '| Stanford Cars | 8,144 | 8,041 | 196 | top-1 | photos and real world images
    |'
  id: totrans-495
  prefs: []
  type: TYPE_TB
  zh: '| Stanford Cars | 8,144 | 8,041 | 196 | top-1 | 照片和现实世界图像 |'
- en: '| FGVC Aircraft | 6,667 | 3,333 | 100 |'
  id: totrans-496
  prefs: []
  type: TYPE_TB
  zh: '| FGVC Aircraft | 6,667 | 3,333 | 100 |'
- en: '&#124; mean &#124;'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均值 &#124;'
- en: '&#124; per-class &#124;'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 每类 &#124;'
- en: '| photos and real world images |'
  id: totrans-499
  prefs: []
  type: TYPE_TB
  zh: '| 照片和现实世界图像 |'
- en: '|'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Describable &#124;'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可描述的 &#124;'
- en: '&#124; Textures (DTD) &#124;'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 纹理（DTD） &#124;'
- en: '| 3,760 | 1,880 | 47 | top-1 | photos and real world images |'
  id: totrans-503
  prefs: []
  type: TYPE_TB
  zh: '| 3,760 | 1,880 | 47 | top-1 | 照片和现实世界图像 |'
- en: '| Oxford-III Pets | 3,680 | 3,369 | 37 |'
  id: totrans-504
  prefs: []
  type: TYPE_TB
  zh: '| Oxford-III Pets | 3,680 | 3,369 | 37 |'
- en: '&#124; mean &#124;'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均值 &#124;'
- en: '&#124; per-class &#124;'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 每类 &#124;'
- en: '| photos and real world images |'
  id: totrans-507
  prefs: []
  type: TYPE_TB
  zh: '| 照片和现实世界图像 |'
- en: '| Caltech-101 | 3,060 | 6,084 | 102 |'
  id: totrans-508
  prefs: []
  type: TYPE_TB
  zh: '| Caltech-101 | 3,060 | 6,084 | 102 |'
- en: '&#124; mean &#124;'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均值 &#124;'
- en: '&#124; per-class &#124;'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 每类 &#124;'
- en: '| photos and real world images |'
  id: totrans-511
  prefs: []
  type: TYPE_TB
  zh: '| 照片和现实世界图像 |'
- en: '| Oxford 102 Flowers | 2,040 | 6,149 | 102 |'
  id: totrans-512
  prefs: []
  type: TYPE_TB
  zh: '| Oxford 102 Flowers | 2,040 | 6,149 | 102 |'
- en: '&#124; mean &#124;'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均值 &#124;'
- en: '&#124; per-class &#124;'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 每类 &#124;'
- en: '| photos and real world images |'
  id: totrans-515
  prefs: []
  type: TYPE_TB
  zh: '| 照片和现实世界图像 |'
- en: '| ImageNet-R | - | 30k | 200 | top-1 |'
  id: totrans-516
  prefs: []
  type: TYPE_TB
  zh: '| ImageNet-R | - | 30k | 200 | top-1 |'
- en: '&#124; art, cartoons, deviantart, graffiti, &#124;'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 艺术、卡通、deviantart、涂鸦、 &#124;'
- en: '&#124; embroidery, graphics, origami, &#124;'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 刺绣、图形、折纸、 &#124;'
- en: '&#124; paintings, patterns, plastic objects, &#124;'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 绘画、图案、塑料物品、 &#124;'
- en: '&#124; plush objects, sculptures, sketches, &#124;'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 毛绒玩具、雕塑、素描、 &#124;'
- en: '&#124; tattoos, toys, and video games &#124;'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 纹身、玩具和视频游戏 &#124;'
- en: '|'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| ImageNet-Sketch | - | 50k | 1000 | top-1 | sketch |'
  id: totrans-523
  prefs: []
  type: TYPE_TB
  zh: '| ImageNet-Sketch | - | 50k | 1000 | top-1 | 素描 |'
- en: '| DomainNet-c | 33,525 | 14,604 | 365 | top-1 | clipart images |'
  id: totrans-524
  prefs: []
  type: TYPE_TB
  zh: '| DomainNet-c | 33,525 | 14,604 | 365 | top-1 | 剪贴画图像 |'
- en: '| DomainNet-p | 50,416 | 21,850 | 365 | top-1 | artistic paintings |'
  id: totrans-525
  prefs: []
  type: TYPE_TB
  zh: '| DomainNet-p | 50,416 | 21,850 | 365 | top-1 | 艺术绘画 |'
- en: '| DomainNet-r | 120,906 | 52,041 | 365 | top-1 | photos and real world images
    |'
  id: totrans-526
  prefs: []
  type: TYPE_TB
  zh: '| DomainNet-r | 120,906 | 52,041 | 365 | top-1 | 照片和现实世界图像 |'
- en: '| DomainNet-s | 48,212 | 20,916 | 365 | top-1 | sketch |'
  id: totrans-527
  prefs: []
  type: TYPE_TB
  zh: '| DomainNet-s | 48,212 | 20,916 | 365 | top-1 | 素描 |'
- en: 4.2 Library
  id: totrans-528
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 图书馆
- en: To make up for the lack of a unified codebase in some areas, we propose an open
    and ongoing library, TLlib. This library implements many representative adaptation
    algorithms in a unified way, allowing quantitative, fair, reproducible comparisons
    between different algorithms and promoting seamless integration of different pre-training
    or adaptation methods.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
- en: Library Usage.
  id: totrans-530
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: First, we give a short description of how to use TLlib using DANN as an instance.
    In the original implementation of DANN, the domain adversarial loss, domain discriminator,
    feature generator, and classifier are tightly coupled together in one nn.Module,
    which causes the difficulty of reuse, e.g., the entire algorithm needs re-implementation
    when the input data is changed from image to text. Yet in this case, the domain
    adversarial loss and the domain discriminator remain unchanged and shall be reused.
    Therefore, in TLlib, models and loss functions are decoupled. When using DANN
    for any case, users need only to initialize a domain discriminator and pass it
    to the domain adversarial loss module, and then use this module in the same way
    as the cross-entropy loss module defined in PyTorch (example code below). TLlib
    provides friendly and coherent APIs for supported algorithms. Detailed usages
    of these algorithms can be found at the [documentation](http://tllib.thuml.ai/).
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,Pj4+ICMgZGVmaW5lIHRoZSBkb21haW4gZGlzY3JpbWluYXRvcgo+Pj4gZnJvbSBkYWxpYi5tb2R1bGVzLmRvbWFpbl9kaXNjcmltaW5hdG9yIGltcG9ydCBEb21haW5EaXNjcmltaW5hdG9yCj4+PiBkaXNjcmltaW5hdG9yID0gRG9tYWluRGlzY3JpbWluYXRvcihpbl9mZWF0dXJlPTEwMjQsIGhpZGRlbl9zaXplPTEwMjQpCj4+PiAjIGRlZmluZSB0aGUgZG9tYWluIGFkdmVyc2FyaWFsIGxvc3MgbW9kdWxlCj4+PiBmcm9tIGRhbGliLmFkcHRhdGlvbi5kYW5uIGltcG9ydCBEb21haW5BZHZlcnNhcmlhbExvc3MKPj4+IGRhbm4gPSBEb21haW5BZHZlcnNhcmlhbExvc3MoZGlzY3JpbWluYXRvciwgcmVkdWN0aW9uPSdtZWFuJykKPj4+ICMgZmVhdHVyZXMgZnJvbSB0aGUgc291cmNlIGFuZCB0YXJnZXQgZG9tYWluCj4+PiBmX3MsIGZfdCA9IHRvcmNoLnJhbmRuKDIwLCAxMDI0KSwgdG9yY2gucmFuZG4oMjAsIDEwMjQpCj4+PiAjIGNhbGN1bGF0ZSB0aGUgZmluYWwgbG9zcwo+Pj4gbG9zcyA9IGRhbm4oZl9zLCBmX3Qp)>>>  #  define  the  domain  discriminator>>>  from  dalib.modules.domain_discriminator  import  DomainDiscriminator>>>  discriminator  =  DomainDiscriminator(in_feature=1024,  hidden_size=1024)>>>  #  define  the  domain  adversarial  loss  module>>>  from  dalib.adptation.dann  import  DomainAdversarialLoss>>>  dann  =  DomainAdversarialLoss(discriminator,  reduction=’mean’)>>>  #  features  from  the  source  and  target  domain>>>  f_s,  f_t  =  torch.randn(20,  1024),  torch.randn(20,  1024)>>>  #  calculate  the  final  loss>>>  loss  =  dann(f_s,  f_t)'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
- en: Design Philosophy.
  id: totrans-533
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: TLlib is designed to be extendible by researchers and simple for practitioners.
    Currently, there are mainly two types of algorithm implementations. One is to
    encapsulate each algorithm in a Trainer, whose typical representative is PyTorch-Lighting.
    Users only need to feed the training data to it and do not need to care about
    the specific training process. Another strategy is to encapsulate the core loss
    function in each algorithm, and users need to implement the complete training
    process by themselves. A typical representative is PyTorch (Paszke et al., [2019](#bib.bib127)).
    Although the former method is easier to use, it is less extendible. Since it is
    often necessary to adjust the training process in different transfer learning
    scenarios, TLlib adopts the latter method for better extendibility. We try our
    best to make TLlib easy to start with, e.g., we support the automatic download
    of most common transfer learning datasets so that users do not need to spend time
    on data preparation. Our code is in *PyTorch-style* and we provide training examples
    of different transfer algorithms in different scenarios, which allows users to
    quickly adapt to TLlib as long as they have learned PyTorch before. For more convenient
    algorithm selection, we provide a comprehensive benchmark among all those libraries.
    For faster algorithm reproduction, we provide training scripts for all the results
    in the benchmark.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: TLlib旨在为研究人员提供可扩展性，并为从业者提供简便性。目前，主要有两种算法实现方式。一种是将每个算法封装在一个Trainer中，其典型代表是PyTorch-Lighting。用户只需将训练数据提供给它，无需关注具体的训练过程。另一种策略是将核心损失函数封装在每个算法中，用户需要自行实现完整的训练过程。一个典型代表是PyTorch
    (Paszke et al., [2019](#bib.bib127))。尽管前一种方法更易于使用，但扩展性较差。由于在不同的迁移学习场景中通常需要调整训练过程，TLlib采用了后一种方法以获得更好的扩展性。我们尽力使TLlib易于上手，例如，我们支持自动下载大多数常见的迁移学习数据集，用户无需花费时间准备数据。我们的代码是*PyTorch风格*的，并且我们提供了不同场景下不同迁移算法的训练示例，使用户只要在学习过PyTorch后就能快速适应TLlib。为了更方便的算法选择，我们提供了所有这些库的全面基准。为了更快地复现算法，我们提供了基准中所有结果的训练脚本。
- en: TLlib is released under the MIT License and available at [https://github.com/thuml/Transfer-Learning-Library](https://github.com/thuml/Transfer-Learning-Library).
    Documentation and tutorials are available on its [website](http://tllib.thuml.ai/).
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: TLlib以MIT许可证发布，可在[https://github.com/thuml/Transfer-Learning-Library](https://github.com/thuml/Transfer-Learning-Library)获取。文档和教程可在其[网站](http://tllib.thuml.ai/)上找到。
- en: 4.3 Benchmark
  id: totrans-536
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 基准
- en: 'This section will present a benchmark of typical pre-training and adaptation
    methods on the large-scale datasets described in Section [4.1](#S4.SS1 "4.1 Datasets
    ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey"). Since such a benchmark
    is missing in the literature, we produce the results using the open library TLlib
    implemented in Section [4.2](#S4.SS2 "4.2 Library ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey").'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将展示在第[4.1节](#S4.SS1 "4.1 数据集 ‣ 4 评估 ‣ 深度学习中的迁移性：综述")中描述的大规模数据集上，典型预训练和适应方法的基准。由于文献中缺乏这样的基准，我们使用第[4.2节](#S4.SS2
    "4.2 库 ‣ 4 评估 ‣ 深度学习中的迁移性：综述")中实现的开源库TLlib生成结果。
- en: 4.3.1 Pre-Training
  id: totrans-538
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1 预训练
- en: Protocols.
  id: totrans-539
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 协议。
- en: The transferability of pre-training methods is evaluated on the target task,
    where the adaptation process and data augmentations are kept the same for fair
    comparison. Hyper-parameters in adaptation are selected by the performance of
    target validation data.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练方法的迁移性在目标任务上进行评估，其中适应过程和数据增强保持不变以便公平比较。适应中的超参数通过目标验证数据的性能进行选择。
- en: Results.
  id: totrans-541
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 结果。
- en: 'For the pre-training methods, the transferability cross different tasks and
    across different domains should be evaluated. Tables [8](#S4.T8 "Table 8 ‣ Results.
    ‣ 4.3.1 Pre-Training ‣ 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability in Deep
    Learning: A Survey") and [9](#S4.T9 "Table 9 ‣ Results. ‣ 4.3.1 Pre-Training ‣
    4.3 Benchmark ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey") list
    the performance on various downstream tasks with different architectures and pre-training
    tasks. It can be concluded that architectures and pre-training methods have a
    great impact on the *cross-task* transferability of deep networks. Table [10](#S4.T10
    "Table 10 ‣ Results. ‣ 4.3.1 Pre-Training ‣ 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey") lists the performance on ImageNet-Sketch and ImageNet-R
    with different architectures and pre-training tasks. Architectures and pre-training
    strategies also greatly influence the *cross-domain* transferability in deep learning.'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: '对于预训练方法，应评估其在不同任务和领域中的迁移能力。表[8](#S4.T8 "Table 8 ‣ Results. ‣ 4.3.1 Pre-Training
    ‣ 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey")和[9](#S4.T9
    "Table 9 ‣ Results. ‣ 4.3.1 Pre-Training ‣ 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey")列出了不同架构和预训练任务下的各种下游任务表现。可以得出结论，架构和预训练方法对深度网络的*跨任务*迁移能力有很大影响。表[10](#S4.T10
    "Table 10 ‣ Results. ‣ 4.3.1 Pre-Training ‣ 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability
    in Deep Learning: A Survey")列出了不同架构和预训练任务下在ImageNet-Sketch和ImageNet-R上的表现。架构和预训练策略也极大地影响了深度学习中的*跨领域*迁移能力。'
- en: 'Table 8: Cross-task transferability benchmark. Results of different architectures
    and pre-training methods are reported from the [GLUE leaderboard](https://gluebenchmark.com).
    BiLSTM+ELMo (Peters et al., [2018](#bib.bib131)) serves as the baseline. GPT (Radford
    et al., [2018](#bib.bib134)), $\text{BERT}_{\text{Large}}$ (Devlin et al., [2019](#bib.bib39)),
    T5 (Raffel et al., [2020](#bib.bib136)), and ERNIE (Sun et al., [2019b](#bib.bib168))
    have different architectures. RoBERTa (Liu et al., [2019c](#bib.bib110)), XLM
    (Lample and Conneau, [2019](#bib.bib91)), and SpanBERT (Joshi et al., [2020](#bib.bib83))
    share the same architecture as $\text{BERT}_{\text{Large}}$ but employ different
    pre-training methods.'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 表8：跨任务迁移能力基准。报告了不同架构和预训练方法的结果，数据来源于[GLUE排行榜](https://gluebenchmark.com)。BiLSTM+ELMo（Peters等，[2018](#bib.bib131)）作为基线。GPT（Radford等，[2018](#bib.bib134)），$\text{BERT}_{\text{Large}}$（Devlin等，[2019](#bib.bib39)），T5（Raffel等，[2020](#bib.bib136)）和ERNIE（Sun等，[2019b](#bib.bib168)）有不同的架构。RoBERTa（Liu等，[2019c](#bib.bib110)），XLM（Lample和Conneau，[2019](#bib.bib91)）以及SpanBERT（Joshi等，[2020](#bib.bib83)）与$\text{BERT}_{\text{Large}}$共享相同架构，但使用不同的预训练方法。
- en: '| Model | CoLA | SST-2 | MRPC | STS-B | QQP | $\text{MNLI}_{m}$ | $\text{MNLI}_{mm}$
    | QNLI | RTE | Avg |'
  id: totrans-544
  prefs: []
  type: TYPE_TB
  zh: '| Model | CoLA | SST-2 | MRPC | STS-B | QQP | $\text{MNLI}_{m}$ | $\text{MNLI}_{mm}$
    | QNLI | RTE | Avg |'
- en: '|'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Human &#124;'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Human &#124;'
- en: '&#124; Baselines &#124;'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Baselines &#124;'
- en: '| 66.4 | 97.8 | 86.3 | 92.7 | 80.4 | 92 | 92.8 | 91.2 | 93.6 | 88.1 |'
  id: totrans-548
  prefs: []
  type: TYPE_TB
  zh: '| 66.4 | 97.8 | 86.3 | 92.7 | 80.4 | 92 | 92.8 | 91.2 | 93.6 | 88.1 |'
- en: '|'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; BiLSTM &#124;'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BiLSTM &#124;'
- en: '&#124; +ELMo &#124;'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; +ELMo &#124;'
- en: '| 36.0 | 90.4 | 84.9 | 73.3 | 64.8 | 76.4 | 76.1 | 79.9 | 56.8 | 71.0 |'
  id: totrans-552
  prefs: []
  type: TYPE_TB
  zh: '| 36.0 | 90.4 | 84.9 | 73.3 | 64.8 | 76.4 | 76.1 | 79.9 | 56.8 | 71.0 |'
- en: '| GPT | 45.4 | 91.3 | 82.3 | 80.0 | 70.3 | 82.1 | 81.4 | 88.1 | 56.0 | 75.2
    |'
  id: totrans-553
  prefs: []
  type: TYPE_TB
  zh: '| GPT | 45.4 | 91.3 | 82.3 | 80.0 | 70.3 | 82.1 | 81.4 | 88.1 | 56.0 | 75.2
    |'
- en: '|'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; $\text{BERT}_{\text{Large}}$ &#124;'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; $\text{BERT}_{\text{Large}}$ &#124;'
- en: '| 60.5 | 94.9 | 89.3 | 86.5 | 72.1 | 86.7 | 85.9 | 92.7 | 70.1 | 82.1 |'
  id: totrans-556
  prefs: []
  type: TYPE_TB
  zh: '| 60.5 | 94.9 | 89.3 | 86.5 | 72.1 | 86.7 | 85.9 | 92.7 | 70.1 | 82.1 |'
- en: '| T5 | 71.6 | 97.5 | 92.8 | 93.1 | 90.6 | 92.2 | 91.9 | 96.9 | 92.8 | 91.0
    |'
  id: totrans-557
  prefs: []
  type: TYPE_TB
  zh: '| T5 | 71.6 | 97.5 | 92.8 | 93.1 | 90.6 | 92.2 | 91.9 | 96.9 | 92.8 | 91.0
    |'
- en: '| ERNIE | 75.5 | 97.8 | 93.9 | 93.0 | 90.9 | 92.3 | 91.7 | 97.3 | 92.6 | 91.7
    |'
  id: totrans-558
  prefs: []
  type: TYPE_TB
  zh: '| ERNIE | 75.5 | 97.8 | 93.9 | 93.0 | 90.9 | 92.3 | 91.7 | 97.3 | 92.6 | 91.7
    |'
- en: '| RoBERTa | 67.8 | 96.7 | 92.3 | 92.2 | 90.2 | 90.8 | 90.2 | 95.4 | 88.2 |
    89.3 |'
  id: totrans-559
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa | 67.8 | 96.7 | 92.3 | 92.2 | 90.2 | 90.8 | 90.2 | 95.4 | 88.2 |
    89.3 |'
- en: '| XLM | 62.9 | 95.6 | 90.7 | 88.8 | 89.8 | 89.1 | 88.5 | 94.0 | 76.0 | 86.2
    |'
  id: totrans-560
  prefs: []
  type: TYPE_TB
  zh: '| XLM | 62.9 | 95.6 | 90.7 | 88.8 | 89.8 | 89.1 | 88.5 | 94.0 | 76.0 | 86.2
    |'
- en: '| SpanBERT | 64.3 | 94.8 | 90.9 | 89.9 | 89.5 | 88.1 | 87.7 | 94.3 | 79.0 |
    86.5 |'
  id: totrans-561
  prefs: []
  type: TYPE_TB
  zh: '| SpanBERT | 64.3 | 94.8 | 90.9 | 89.9 | 89.5 | 88.1 | 87.7 | 94.3 | 79.0 |
    86.5 |'
- en: 'Table 9: Cross-task transferability benchmark. Results on image recognition
    using different pre-training methods, including SimCLR (Chen et al., [2020](#bib.bib23))
    and BYOL (Grill et al., [2020](#bib.bib59)).'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 表9：跨任务迁移能力基准。展示了使用不同预训练方法在图像识别上的结果，包括SimCLR（Chen等，[2020](#bib.bib23)）和BYOL（Grill等，[2020](#bib.bib59)）。
- en: '| Model | Pre-Training | Food | CIFAR10 | CIFAR100 | SUN397 | Cars | Aircraft
    | DTD | Pets | Caltech101 | Flowers | Avg |'
  id: totrans-563
  prefs: []
  type: TYPE_TB
  zh: '| Model | Pre-Training | Food | CIFAR10 | CIFAR100 | SUN397 | Cars | Aircraft
    | DTD | Pets | Caltech101 | Flowers | Avg |'
- en: '| ResNet50 | Random Init | 86.9 | 95.9 | 80.2 | 53.6 | 91.4 | 85.9 | 64.8 |
    81.5 | 72.6 | 92.0 | 80.5 |'
  id: totrans-564
  prefs: []
  type: TYPE_TB
  zh: '| ResNet50 | 随机初始化 | 86.9 | 95.9 | 80.2 | 53.6 | 91.4 | 85.9 | 64.8 | 81.5
    | 72.6 | 92.0 | 80.5 |'
- en: '| SimCLR | 88.2 | 97.7 | 85.9 | 63.5 | 91.3 | 88.1 | 73.2 | 89.2 | 92.1 | 97.0
    | 86.6 |'
  id: totrans-565
  prefs: []
  type: TYPE_TB
  zh: '| SimCLR | 88.2 | 97.7 | 85.9 | 63.5 | 91.3 | 88.1 | 73.2 | 89.2 | 92.1 | 97.0
    | 86.6 |'
- en: '| BYOL | 88.5 | 97.8 | 86.1 | 63.7 | 91.6 | 88.1 | 76.2 | 91.7 | 93.8 | 97.0
    | 87.5 |'
  id: totrans-566
  prefs: []
  type: TYPE_TB
  zh: '| BYOL | 88.5 | 97.8 | 86.1 | 63.7 | 91.6 | 88.1 | 76.2 | 91.7 | 93.8 | 97.0
    | 87.5 |'
- en: '| ResNet50 | Supervised Pre-Trained on ImageNet | 87.8 | 96.8 | 84.5 | 64.7
    | 91.7 | 86.6 | 75.2 | 92.5 | 91.8 | 97.5 | 86.9 |'
  id: totrans-567
  prefs: []
  type: TYPE_TB
  zh: '| ResNet50 | 在 ImageNet 上监督预训练 | 87.8 | 96.8 | 84.5 | 64.7 | 91.7 | 86.6 |
    75.2 | 92.5 | 91.8 | 97.5 | 86.9 |'
- en: '| ResNet101 | 87.6 | 97.7 | 87.0 | 64.8 | 91.7 | 85.6 | 75.4 | 94.0 | 93.1
    | 97.9 | 87.5 |'
  id: totrans-568
  prefs: []
  type: TYPE_TB
  zh: '| ResNet101 | 87.6 | 97.7 | 87.0 | 64.8 | 91.7 | 85.6 | 75.4 | 94.0 | 93.1
    | 97.9 | 87.5 |'
- en: '| ResNet152 | 87.6 | 97.9 | 87.6 | 66.0 | 92.0 | 85.3 | 74.9 | 94.5 | 93.2
    | 97.4 | 87.6 |'
  id: totrans-569
  prefs: []
  type: TYPE_TB
  zh: '| ResNet152 | 87.6 | 97.9 | 87.6 | 66.0 | 92.0 | 85.3 | 74.9 | 94.5 | 93.2
    | 97.4 | 87.6 |'
- en: 'Table 10: Cross-domain transferability benchmark. Results are reported from
    the PyTorch-Image-Models (Wightman, [2019](#bib.bib190)) on ImageNet using different
    architectures and pre-training methods. SSP refers to semi-supervised pre-training
    on YFCC100M (Yalniz et al., [2019](#bib.bib194)). WSP refers to weakly supervised
    pre-training on IG-1B-Targeted (Mahajan et al., [2018](#bib.bib118)).'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: '表 10: 跨领域迁移能力基准。结果来自 PyTorch-Image-Models (Wightman, [2019](#bib.bib190))，使用不同的架构和预训练方法在
    ImageNet 上进行测试。SSP 指在 YFCC100M (Yalniz et al., [2019](#bib.bib194)) 上的半监督预训练。WSP
    指在 IG-1B-Targeted (Mahajan et al., [2018](#bib.bib118)) 上的弱监督预训练。'
- en: '| Model | Pre-Training | Param Count | ImageNet-Sketch | ImageNetR |'
  id: totrans-571
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 预训练 | 参数数量 | ImageNet-Sketch | ImageNetR |'
- en: '| top-1 | top-5 | top-1 | top-5 |'
  id: totrans-572
  prefs: []
  type: TYPE_TB
  zh: '| top-1 | top-5 | top-1 | top-5 |'
- en: '| ResNet50 | Standard Pre-Trained on ImageNet | 25.6 | 29.6 | 46.8 | 40.4 |
    54.7 |'
  id: totrans-573
  prefs: []
  type: TYPE_TB
  zh: '| ResNet50 | 在 ImageNet 上标准预训练 | 25.6 | 29.6 | 46.8 | 40.4 | 54.7 |'
- en: '| ResNet152d | 60.2 | 37.9 | 58.4 | 49.3 | 64.4 |'
  id: totrans-574
  prefs: []
  type: TYPE_TB
  zh: '| ResNet152d | 60.2 | 37.9 | 58.4 | 49.3 | 64.4 |'
- en: '| $\text{ViT}_{\text{large, patch16}}$ | 304.3 | 51.8 | 73.7 | 64.3 | 76.2
    |'
  id: totrans-575
  prefs: []
  type: TYPE_TB
  zh: '| $\text{ViT}_{\text{large, patch16}}$ | 304.3 | 51.8 | 73.7 | 64.3 | 76.2
    |'
- en: '| ResNext101_32x8d | Standard | 88.8 | 29.4 | 48.5 | 42.6 | 58.3 |'
  id: totrans-576
  prefs: []
  type: TYPE_TB
  zh: '| ResNext101_32x8d | 标准 | 88.8 | 29.4 | 48.5 | 42.6 | 58.3 |'
- en: '| SSP | 34.1 | 55.6 | 49.2 | 65.5 |'
  id: totrans-577
  prefs: []
  type: TYPE_TB
  zh: '| SSP | 34.1 | 55.6 | 49.2 | 65.5 |'
- en: '| WSP | 54.9 | 77.5 | 75.9 | 86.2 |'
  id: totrans-578
  prefs: []
  type: TYPE_TB
  zh: '| WSP | 54.9 | 77.5 | 75.9 | 86.2 |'
- en: '| SSP+WSP | 56.4 | 78.9 | 75.6 | 87.1 |'
  id: totrans-579
  prefs: []
  type: TYPE_TB
  zh: '| SSP+WSP | 56.4 | 78.9 | 75.6 | 87.1 |'
- en: 4.3.2 Task Adaptation
  id: totrans-580
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.2 任务适应
- en: Protocols.
  id: totrans-581
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 协议。
- en: We follow the common practice in the community as described in Kornblith et al.
    ([2019](#bib.bib88)). Training iterations and data augmentations are kept the
    same for different task adaptation methods for a fair comparison. Hyper-parameters,
    such as learning rate and weight decay, of each method are selected by the performance
    on target validation data.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遵循了 Kornblith 等人 ([2019](#bib.bib88)) 中描述的社区常规做法。为了公平比较，不同任务适应方法的训练迭代次数和数据增强保持一致。每种方法的超参数，如学习率和权重衰减，是根据目标验证数据的性能选择的。
- en: Results.
  id: totrans-583
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 结果。
- en: 'We mainly investigate the *cross-task* transferability between different task
    adaptation methods. Tables [11](#S4.T11 "Table 11 ‣ Results. ‣ 4.3.2 Task Adaptation
    ‣ 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey")
    and [12](#S4.T12 "Table 12 ‣ Results. ‣ 4.3.2 Task Adaptation ‣ 4.3 Benchmark
    ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey") compare the performance
    of downstream tasks with different task adaptation methods. Note that previous
    methods usually only report results on individual datasets, such as Aircraft and
    Stanford Cars, where regularization tuning performs better than vanilla fine-tuning
    by a large margin. But the average improvements brought by different task adaptation
    methods on a large number of datasets are still limited. Thus, we can conclude
    that the effectiveness of different task adaptation algorithms largely depends
    on the relatedness between the target task and the pre-training task.'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: '我们主要研究不同任务适应方法之间的*跨任务*迁移能力。表 [11](#S4.T11 "Table 11 ‣ Results. ‣ 4.3.2 Task
    Adaptation ‣ 4.3 Benchmark ‣ 4 Evaluation ‣ Transferability in Deep Learning:
    A Survey") 和 [12](#S4.T12 "Table 12 ‣ Results. ‣ 4.3.2 Task Adaptation ‣ 4.3 Benchmark
    ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey") 比较了不同任务适应方法在下游任务中的表现。注意，之前的方法通常只报告个别数据集的结果，例如
    Aircraft 和 Stanford Cars，在这些数据集中，正则化调优比普通微调表现更好。但不同任务适应方法在大量数据集上的平均改进仍然有限。因此，我们可以得出结论，不同任务适应算法的有效性在很大程度上依赖于目标任务和预训练任务之间的相关性。'
- en: 'Table 11: Cross-task transferability benchmark. GLUE performance with different
    task adaptation methods, including SMART (Jiang et al., [2020](#bib.bib79)), Adapter-Tuning
    (Houlsby et al., [2019](#bib.bib73)) and Diff Pruning (Guo et al., [2021](#bib.bib61)).
    Results are reported from their original papers.'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
- en: '| Model |'
  id: totrans-586
  prefs: []
  type: TYPE_TB
- en: '&#124; Task &#124;'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Adaptation &#124;'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; New Params &#124;'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Per Task &#124;'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
- en: '| CoLA | SST-2 | MRPC | STS-B | QQP | $\text{MNLI}_{m}$ | $\text{MNLI}_{mm}$
    | QNLI | RTE | Avg |'
  id: totrans-592
  prefs: []
  type: TYPE_TB
- en: '| RoBERTa | vanilla | 100% | 67.8 | 96.7 | 92.3 | 92.2 | 90.2 | 90.8 | 90.2
    | 95.4 | 88.2 | 89.3 |'
  id: totrans-593
  prefs: []
  type: TYPE_TB
- en: '| SMART | 100% | 65.1 | 97.5 | 93.7 | 92.9 | 90.1 | 91.0 | 90.8 | 95.4 | 87.9
    | 89.4 |'
  id: totrans-594
  prefs: []
  type: TYPE_TB
- en: '| BERT${}_{\text{Large}}$ | vanilla | 100% | 60.5 | 94.9 | 89.3 | 86.5 | 72.1
    | 86.7 | 85.9 | 92.7 | 70.1 | 82.1 |'
  id: totrans-595
  prefs: []
  type: TYPE_TB
- en: '| Adapter | 2.10% | 59.2 | 94.3 | 88.7 | 87.3 | 89.4 | 85.4 | 85.0 | 92.4 |
    71.6 | 83.7 |'
  id: totrans-596
  prefs: []
  type: TYPE_TB
- en: '| Diff Pruning | 0.50% | 61.1 | 94.1 | 89.7 | 86.0 | - | 86.4 | 86.0 | 93.3
    | 70.6 | - |'
  id: totrans-597
  prefs: []
  type: TYPE_TB
- en: 'Table 12: Cross-task transferability benchmark. Accuracy (%) on image classification
    with different task adaptation methods: LWF (Li and Hoiem, [2018](#bib.bib103)),
    DELTA (Li et al., [2019](#bib.bib101)), BSS (Chen et al., [2019b](#bib.bib27)),
    Bi-Tuning (Zhong et al., [2020](#bib.bib208)). Results are reproduced by TLlib.'
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Task &#124;'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Adaptation &#124;'
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
- en: '| Food | CIFAR10 | CIFAR100 | SUN397 | Cars | Aircraft | DTD | Pets | Caltech101
    | Flowers | Avg |'
  id: totrans-602
  prefs: []
  type: TYPE_TB
- en: '| ResNet50 | 85.1 | 96.9 | 84.1 | 80.7 | 87.8 | 80.1 | 74.4 | 93.2 | 92.9 |
    96.5 | 87.2 |'
  id: totrans-603
  prefs: []
  type: TYPE_TB
- en: '| LWF | 83.9 | 96.5 | 83.6 | 79.5 | 87.4 | 82.2 | 76.3 | 94.0 | 91.7 | 97.1
    | 87.2 |'
  id: totrans-604
  prefs: []
  type: TYPE_TB
- en: '| DELTA | 83.8 | 95.9 | 83.7 | 73.6 | 88.1 | 82.3 | 75.6 | 94.2 | 92.5 | 97.0
    | 86.7 |'
  id: totrans-605
  prefs: []
  type: TYPE_TB
- en: '| BSS | 85.0 | 96.6 | 84.2 | 80.4 | 88.4 | 81.8 | 74.3 | 93.3 | 93.0 | 96.6
    | 87.4 |'
  id: totrans-606
  prefs: []
  type: TYPE_TB
- en: '| Bi-Tuning | 85.7 | 97.1 | 84.3 | 80.7 | 90.3 | 84.8 | 74.6 | 93.5 | 93.4
    | 97.5 | 88.2 |'
  id: totrans-607
  prefs: []
  type: TYPE_TB
- en: 4.3.3 Domain Adaptation
  id: totrans-608
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Protocols.
  id: totrans-609
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We follow the standard protocols for unsupervised domain adaptation (Long et al.,
    [2015](#bib.bib112); Ganin and Lempitsky, [2015](#bib.bib45)). Training iterations
    and data augmentations are kept the same for different methods for a fair comparison.
    For each method, hyper-parameters are selected on one task and then kept the same
    for all other tasks, requiring the hyper-parameters of each method to transfer
    across tasks. This selection strategy is more executable than the importance-weighted
    cross-validation (Sugiyama et al., [2007](#bib.bib164)) and can be applied to
    various practical applications, thus it is widely adopted by many competitions.
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
- en: Results.
  id: totrans-611
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Tables [13](#S4.T13 "Table 13 ‣ Results. ‣ 4.3.3 Domain Adaptation ‣ 4.3 Benchmark
    ‣ 4 Evaluation ‣ Transferability in Deep Learning: A Survey") and [14](#S4.T14
    "Table 14 ‣ Results. ‣ 4.3.3 Domain Adaptation ‣ 4.3 Benchmark ‣ 4 Evaluation
    ‣ Transferability in Deep Learning: A Survey") give the classification performance
    of different domain adaptation methods on DomainNet and ImageNet. We find that
    many state-of-the-art methods on small datasets do not perform well on large-scale
    datasets. This field shall pay more attention to improving the *cross-domain*
    transferability of deep models on large-scale datasets.'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [13](#S4.T13 "表 13 ‣ 结果 ‣ 4.3.3 领域适应 ‣ 4.3 基准 ‣ 4 评估 ‣ 深度学习中的迁移能力：综述") 和 [14](#S4.T14
    "表 14 ‣ 结果 ‣ 4.3.3 领域适应 ‣ 4.3 基准 ‣ 4 评估 ‣ 深度学习中的迁移能力：综述") 给出了不同领域适应方法在 DomainNet
    和 ImageNet 上的分类性能。我们发现许多在小数据集上表现出色的最先进方法在大规模数据集上表现不佳。该领域应更加关注提高深度模型在大规模数据集上的*跨领域*迁移能力。
- en: 'Table 13: Cross-domain transferability benchmark. Accuracy (%) for unsupervised
    domain adaptation on DomainNet. Results are reproduced from TLlib.'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: '表 13: 跨领域迁移能力基准。在 DomainNet 上进行无监督领域适应的准确率（%）。结果来自 TLlib。'
- en: '| DomainNet | c$\shortrightarrow$p | c$\shortrightarrow$r | c$\shortrightarrow$s
    | p$\shortrightarrow$c | p$\shortrightarrow$r | p$\shortrightarrow$s | r$\shortrightarrow$c
    | r$\shortrightarrow$p | r$\shortrightarrow$s | s$\shortrightarrow$c | s$\shortrightarrow$p
    | s$\shortrightarrow$r | Avg |'
  id: totrans-614
  prefs: []
  type: TYPE_TB
  zh: '| DomainNet | c$\shortrightarrow$p | c$\shortrightarrow$r | c$\shortrightarrow$s
    | p$\shortrightarrow$c | p$\shortrightarrow$r | p$\shortrightarrow$s | r$\shortrightarrow$c
    | r$\shortrightarrow$p | r$\shortrightarrow$s | s$\shortrightarrow$c | s$\shortrightarrow$p
    | s$\shortrightarrow$r | 平均 |'
- en: '| ResNet101 | 32.7 | 50.6 | 39.4 | 41.1 | 56.8 | 35.0 | 48.6 | 48.8 | 36.1
    | 49.0 | 34.8 | 46.1 | 43.3 |'
  id: totrans-615
  prefs: []
  type: TYPE_TB
  zh: '| ResNet101 | 32.7 | 50.6 | 39.4 | 41.1 | 56.8 | 35.0 | 48.6 | 48.8 | 36.1
    | 49.0 | 34.8 | 46.1 | 43.3 |'
- en: '| DAN ([2015](#bib.bib112)) | 38.8 | 55.2 | 43.9 | 45.9 | 59.0 | 40.8 | 50.8
    | 49.8 | 38.9 | 56.1 | 45.9 | 55.5 | 48.4 |'
  id: totrans-616
  prefs: []
  type: TYPE_TB
  zh: '| DAN ([2015](#bib.bib112)) | 38.8 | 55.2 | 43.9 | 45.9 | 59.0 | 40.8 | 50.8
    | 49.8 | 38.9 | 56.1 | 45.9 | 55.5 | 48.4 |'
- en: '| DANN ([2016](#bib.bib46)) | 37.9 | 54.3 | 44.4 | 41.7 | 55.6 | 36.8 | 50.7
    | 50.8 | 40.1 | 55.0 | 45.0 | 54.5 | 47.2 |'
  id: totrans-617
  prefs: []
  type: TYPE_TB
  zh: '| DANN ([2016](#bib.bib46)) | 37.9 | 54.3 | 44.4 | 41.7 | 55.6 | 36.8 | 50.7
    | 50.8 | 40.1 | 55.0 | 45.0 | 54.5 | 47.2 |'
- en: '| ADDA ([2017](#bib.bib176)) | 38.4 | 54.1 | 44.1 | 43.5 | 56.7 | 39.2 | 52.8
    | 51.3 | 40.9 | 55.0 | 45.4 | 54.5 | 48.0 |'
  id: totrans-618
  prefs: []
  type: TYPE_TB
  zh: '| ADDA ([2017](#bib.bib176)) | 38.4 | 54.1 | 44.1 | 43.5 | 56.7 | 39.2 | 52.8
    | 51.3 | 40.9 | 55.0 | 45.4 | 54.5 | 48.0 |'
- en: '| JAN ([2017](#bib.bib114)) | 40.5 | 56.7 | 45.1 | 47.2 | 59.9 | 43.0 | 54.2
    | 52.6 | 41.9 | 56.6 | 46.2 | 55.5 | 50.0 |'
  id: totrans-619
  prefs: []
  type: TYPE_TB
  zh: '| JAN ([2017](#bib.bib114)) | 40.5 | 56.7 | 45.1 | 47.2 | 59.9 | 43.0 | 54.2
    | 52.6 | 41.9 | 56.6 | 46.2 | 55.5 | 50.0 |'
- en: '| CDAN ([2018](#bib.bib115)) | 40.4 | 56.8 | 46.1 | 45.1 | 58.4 | 40.5 | 55.6
    | 53.6 | 43.0 | 57.2 | 46.4 | 55.7 | 49.9 |'
  id: totrans-620
  prefs: []
  type: TYPE_TB
  zh: '| CDAN ([2018](#bib.bib115)) | 40.4 | 56.8 | 46.1 | 45.1 | 58.4 | 40.5 | 55.6
    | 53.6 | 43.0 | 57.2 | 46.4 | 55.7 | 49.9 |'
- en: '| MCD ([2018](#bib.bib146)) | 37.5 | 52.9 | 44.0 | 44.6 | 54.5 | 41.6 | 52.0
    | 51.5 | 39.7 | 55.5 | 44.6 | 52.0 | 47.5 |'
  id: totrans-621
  prefs: []
  type: TYPE_TB
  zh: '| MCD ([2018](#bib.bib146)) | 37.5 | 52.9 | 44.0 | 44.6 | 54.5 | 41.6 | 52.0
    | 51.5 | 39.7 | 55.5 | 44.6 | 52.0 | 47.5 |'
- en: '| MDD ([2019c](#bib.bib204)) | 42.9 | 59.5 | 47.5 | 48.6 | 59.4 | 42.6 | 58.3
    | 53.7 | 46.2 | 58.7 | 46.5 | 57.7 | 51.8 |'
  id: totrans-622
  prefs: []
  type: TYPE_TB
  zh: '| MDD ([2019c](#bib.bib204)) | 42.9 | 59.5 | 47.5 | 48.6 | 59.4 | 42.6 | 58.3
    | 53.7 | 46.2 | 58.7 | 46.5 | 57.7 | 51.8 |'
- en: 'Table 14: Cross-domain transferability benchmark. Accuracy (%) for unsupervised
    domain adaptation on ImageNet-scale datasets. Results are reproduced from TLlib.'
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: '表 14: 跨领域迁移能力基准。在 ImageNet 规模的数据集上进行无监督领域适应的准确率（%）。结果来自 TLlib。'
- en: '| Task | ImageNet$\shortrightarrow$ImageNet-R | ImageNet$\shortrightarrow$ImageNet-Sketch
    |'
  id: totrans-624
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | ImageNet$\shortrightarrow$ImageNet-R | ImageNet$\shortrightarrow$ImageNet-Sketch
    |'
- en: '| Model | ResNet50 | ig_resnext101_32x8d |'
  id: totrans-625
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | ResNet50 | ig_resnext101_32x8d |'
- en: '| Source Only | 35.6 | 54.9 |'
  id: totrans-626
  prefs: []
  type: TYPE_TB
  zh: '| 仅源数据 | 35.6 | 54.9 |'
- en: '| DAN (Long et al., [2015](#bib.bib112)) | 39.8 | 55.7 |'
  id: totrans-627
  prefs: []
  type: TYPE_TB
  zh: '| DAN (龙等，[2015](#bib.bib112)) | 39.8 | 55.7 |'
- en: '| DANN (Ganin et al., [2016](#bib.bib46)) | 52.7 | 56.5 |'
  id: totrans-628
  prefs: []
  type: TYPE_TB
  zh: '| DANN (甘宁等，[2016](#bib.bib46)) | 52.7 | 56.5 |'
- en: '| JAN (Long et al., [2017](#bib.bib114)) | 41.7 | 55.7 |'
  id: totrans-629
  prefs: []
  type: TYPE_TB
  zh: '| JAN (龙等，[2017](#bib.bib114)) | 41.7 | 55.7 |'
- en: '| CDAN (Long et al., [2018](#bib.bib115)) | 53.9 | 58.2 |'
  id: totrans-630
  prefs: []
  type: TYPE_TB
  zh: '| CDAN (龙等，[2018](#bib.bib115)) | 53.9 | 58.2 |'
- en: '| MCD (Saito et al., [2018](#bib.bib146)) | 46.7 | 55.0 |'
  id: totrans-631
  prefs: []
  type: TYPE_TB
  zh: '| MCD (斋藤等，[2018](#bib.bib146)) | 46.7 | 55.0 |'
- en: '| MDD (Zhang et al., [2019c](#bib.bib204)) | 56.2 | 62.4 |'
  id: totrans-632
  prefs: []
  type: TYPE_TB
  zh: '| MDD (张等，[2019c](#bib.bib204)) | 56.2 | 62.4 |'
- en: 5 Conclusion
  id: totrans-633
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: In this paper, we investigate how to acquire and apply transferability in the
    whole lifecycle of deep learning. In the pre-training section, we focus on how
    to improve the transferability of the pre-trained models by designing architecture,
    pre-training task, and training strategy. In the task adaptation section, we discuss
    how to better preserve and utilize the transferable knowledge to improve the performance
    of target tasks. In the domain adaptation section, we illustrate how to bridge
    the domain gap to increase the transferability for real applications. This survey
    connects many isolated areas with their relation to transferability and provides
    a unified perspective to explore transferability in deep learning. We expect this
    study will attract the community’s attention to the fundamental role of transferability
    in deep learning.
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们探讨了如何在深度学习的整个生命周期中获取和应用迁移性。在预训练部分，我们关注于通过设计架构、预训练任务和训练策略来提升预训练模型的迁移性。在任务适应部分，我们讨论了如何更好地保留和利用可迁移知识，以提高目标任务的性能。在领域适应部分，我们阐述了如何弥合领域差距，以提高实际应用中的迁移性。本综述将许多孤立领域与迁移性的关系联系起来，并提供了一个统一的视角来探索深度学习中的迁移性。我们期望本研究能够引起社区对迁移性在深度学习中基本作用的关注。
- en: Acknowledgments
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 致谢
- en: This work was supported by the NSFC Grants (62022050 and 62021002), the Beijing
    Nova Program (Z201100006820041), and the BNRist Innovation Fund (BNR2021RC01002).
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了NSFC资助（62022050和62021002）、北京新星计划（Z201100006820041）和BNRist创新基金（BNR2021RC01002）的支持。
- en: References
  id: totrans-637
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Abnar et al. (2022) Samira Abnar, Mostafa Dehghani, Behnam Neyshabur, and Hanie
    Sedghi. Exploring the limits of large scale pre-training. In *ICLR*, 2022.
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abnar et al. (2022) Samira Abnar, Mostafa Dehghani, Behnam Neyshabur, 和 Hanie
    Sedghi。探索大规模预训练的极限。在*ICLR*，2022。
- en: Aghajanyan et al. (2021) Armen Aghajanyan, Luke Zettlemoyer, and Sonal Gupta.
    Intrinsic dimensionality explains the effectiveness of language model fine-tuning.
    In *ACL*, 2021.
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aghajanyan et al. (2021) Armen Aghajanyan, Luke Zettlemoyer, 和 Sonal Gupta。内在维度解释了语言模型微调的有效性。在*ACL*，2021。
- en: 'Amodei et al. (2016) Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai,
    Jingliang Bai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Qiang
    Cheng, Guoliang Chen, et al. Deep speech 2: End-to-end speech recognition in english
    and mandarin. In *ICML*, 2016.'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amodei et al. (2016) Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai,
    Jingliang Bai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Qiang
    Cheng, Guoliang Chen, 等。深度语音2：英文和中文的端到端语音识别。在*ICML*，2016。
- en: Arjovsky et al. (2019) Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David
    Lopez-Paz. Invariant risk minimization. *arXiv preprint arXiv:1907.02893*, 2019.
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arjovsky et al. (2019) Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, 和 David
    Lopez-Paz。变不变风险最小化。*arXiv preprint arXiv:1907.02893*，2019。
- en: Arora et al. (2017) Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang.
    Generalization and equilibrium in generative adversarial nets (GANs). In *ICML*,
    2017.
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arora et al. (2017) Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, 和 Yi Zhang。生成对抗网络（GANs）的泛化与平衡。在*ICML*，2017。
- en: 'Bartlett and Mendelson (2002) Peter L. Bartlett and Shahar Mendelson. Rademacher
    and gaussian complexities: Risk bounds and structural results. In *JMLR*, 2002.'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bartlett and Mendelson (2002) Peter L. Bartlett 和 Shahar Mendelson。拉德马赫和高斯复杂性：风险界限和结构结果。在*JMLR*，2002。
- en: 'Beltagy et al. (2019) Iz Beltagy, Kyle Lo, and Arman Cohan. Scibert: Pretrained
    language model for scientific text. In *EMNLP*, 2019.'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Beltagy et al. (2019) Iz Beltagy, Kyle Lo, 和 Arman Cohan。Scibert: 科学文本的预训练语言模型。在*EMNLP*，2019。'
- en: Ben-David et al. (2010a) S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza, F. Pereira,
    and J. W. Vaughan. A theory of learning from different domains. *Machine Learning,
    79*, page 151–175, 2010a.
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ben-David et al. (2010a) S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza, F.
    Pereira, 和 J. W. Vaughan。从不同领域学习的理论。*Machine Learning, 79*，页151–175，2010a。
- en: Ben-David et al. (2006) Shai Ben-David, John Blitzer, Koby Crammer, and Fernando
    Pereira. Analysis of representations for domain adaptation. In *NeurIPS*, 2006.
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ben-David et al. (2006) Shai Ben-David, John Blitzer, Koby Crammer, 和 Fernando
    Pereira。领域适应表示分析。在*NeurIPS*，2006。
- en: Ben-David et al. (2010b) Shai Ben-David, Tyler Lu, Teresa Luu, and David Pal.
    Impossibility theorems for domain adaptation. In *AISTATS*, pages 129–136, 2010b.
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ben-David et al. (2010b) Shai Ben-David, Tyler Lu, Teresa Luu, 和 David Pal。领域适应的不可行性定理。在*AISTATS*，页129–136，2010b。
- en: Bengio (2012) Yoshua Bengio. Deep learning of representations for unsupervised
    and transfer learning. In *ICML workshop*, 2012.
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengio (2012) 约书亚·本吉奥。无监督和迁移学习的深度表示学习。在*ICML workshop*，2012。
- en: Bengio et al. (2007) Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle.
    Greedy layer-wise training of deep networks. In *NeurIPS*, 2007.
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengio 等 (2007) Yoshua Bengio、Pascal Lamblin、Dan Popovici 和 Hugo Larochelle。深度网络的贪婪分层训练。发表于*NeurIPS*，2007年。
- en: 'Bengio et al. (2013) Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation
    learning: A review and new perspectives. *TPAMI*, 35(8):1798–1828, 2013.'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengio 等 (2013) Yoshua Bengio、Aaron Courville 和 Pascal Vincent。表示学习：综述与新视角。*TPAMI*，35(8)：1798–1828，2013年。
- en: Bengio et al. (2021) Yoshua Bengio, Yann Lecun, and Geoffrey Hinton. Deep learning
    for ai. *Communications of the ACM*, 64(7):58–65, 2021.
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengio 等 (2021) Yoshua Bengio、Yann Lecun 和 Geoffrey Hinton。人工智能的深度学习。*ACM 通讯*，64(7)：58–65，2021年。
- en: Bousmalis et al. (2016) Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman,
    Dilip Krishnan, and Dumitru Erhan. Domain separation networks. In *NeurIPS*, 2016.
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bousmalis 等 (2016) Konstantinos Bousmalis、George Trigeorgis、Nathan Silberman、Dilip
    Krishnan 和 Dumitru Erhan。领域分离网络。发表于*NeurIPS*，2016年。
- en: Bousmalis et al. (2017) Konstantinos Bousmalis, Nathan Silberman, David Dohan,
    Dumitru Erhan, and Dilip Krishnan. Unsupervised pixel-level domain adaptation
    with generative adversarial networks. In *CVPR*, 2017.
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bousmalis 等 (2017) Konstantinos Bousmalis、Nathan Silberman、David Dohan、Dumitru
    Erhan 和 Dilip Krishnan。基于生成对抗网络的无监督像素级领域适应。发表于*CVPR*，2017年。
- en: Bousmalis et al. (2018) Konstantinos Bousmalis, Alex Irpan, Paul Wohlhart, Yunfei
    Bai, Matthew Kelcey, Mrinal Kalakrishnan, Laura Downs, Julian Ibarz, Peter Pastor,
    Kurt Konolige, Sergey Levine, and Vincent Vanhoucke. Using simulation and domain
    adaptation to improve efficiency of deep robotic grasping. In *ICRA*, 2018.
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bousmalis 等 (2018) Konstantinos Bousmalis、Alex Irpan、Paul Wohlhart、Yunfei Bai、Matthew
    Kelcey、Mrinal Kalakrishnan、Laura Downs、Julian Ibarz、Peter Pastor、Kurt Konolige、Sergey
    Levine 和 Vincent Vanhoucke。利用仿真和领域适应提高深度机器人抓取的效率。发表于*ICRA*，2018年。
- en: Brown et al. (2020) Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, et al. Language models are few-shot learners. In *NeurIPS*, 2020.
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等 (2020) Tom B Brown、Benjamin Mann、Nick Ryder、Melanie Subbiah、Jared Kaplan、Prafulla
    Dhariwal、Arvind Neelakantan、Pranav Shyam、Girish Sastry、Amanda Askell 等。语言模型是少样本学习者。发表于*NeurIPS*，2020年。
- en: Busto and Gall (2017) Pau Panareda Busto and Juergen Gall. Open set domain adaptation.
    In *ICCV*, 2017.
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Busto 和 Gall (2017) Pau Panareda Busto 和 Juergen Gall。开放集领域适应。发表于*ICCV*，2017年。
- en: Caruana (1997) Rich Caruana. Multitask learning. Technical report, 1997.
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caruana (1997) Rich Caruana。多任务学习。技术报告，1997年。
- en: Chapelle et al. (2006) Olivier Chapelle, Bernhard Schölkopf, and Alexander Zien.
    *Semi-Supervised Learning (Adaptive Computation and Machine Learning)*. The MIT
    Press, 2006. ISBN 0262033585.
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chapelle 等 (2006) Olivier Chapelle、Bernhard Schölkopf 和 Alexander Zien。*半监督学习（自适应计算与机器学习）*。麻省理工学院出版社，2006年。ISBN
    0262033585。
- en: Chen et al. (2012) Minmin Chen, Zhixiang Xu, Kilian Q. Weinberger, and Fei Sha.
    Marginalized denoising autoencoders for domain adaptation. In *ICML*, 2012.
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2012) Minmin Chen、Zhixiang Xu、Kilian Q. Weinberger 和 Fei Sha。用于领域适应的边际去噪自编码器。发表于*ICML*，2012年。
- en: Chen et al. (2020) Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey
    Hinton. A simple framework for contrastive learning of visual representations.
    In *ICML*, 2020.
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2020) Ting Chen、Simon Kornblith、Mohammad Norouzi 和 Geoffrey Hinton。用于对比学习视觉表示的简单框架。发表于*ICML*，2020年。
- en: Chen et al. (2019a) Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang Frank
    Wang, and Jia-Bin Huang. A closer look at few-shot classification. In *ICLR*,
    2019a.
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2019a) Wei-Yu Chen、Yen-Cheng Liu、Zsolt Kira、Yu-Chiang Frank Wang 和 Jia-Bin
    Huang。对少样本分类的深入分析。发表于*ICLR*，2019年。
- en: Chen and He (2021) Xinlei Chen and Kaiming He. Exploring simple siamese representation
    learning. In *CVPR*, 2021.
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 和 He (2021) Xinlei Chen 和 Kaiming He。探索简单的孪生网络表示学习。发表于*CVPR*，2021年。
- en: Chen et al. (2021a) Xinlei Chen, Saining Xie, and Kaiming He. An empirical study
    of training self-supervised vision transformers. *arXiv preprint arXiv:2104.02057*,
    2021a.
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2021a) Xinlei Chen、Saining Xie 和 Kaiming He。自监督视觉变换器的训练实证研究。*arXiv 预印本
    arXiv:2104.02057*，2021年。
- en: 'Chen et al. (2019b) Xinyang Chen, Sinan Wang, Bo Fu, Mingsheng Long, and Jianmin
    Wang. Catastrophic forgetting meets negative transfer: Batch spectral shrinkage
    for safe transfer learning. In *NeurIPS*, 2019b.'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2019b) Xinyang Chen、Sinan Wang、Bo Fu、Mingsheng Long 和 Jianmin Wang。灾难性遗忘与负迁移的相遇：安全迁移学习的批量谱收缩。发表于*NeurIPS*，2019年。
- en: 'Chen et al. (2019c) Xinyang Chen, Sinan Wang, Mingsheng Long, and Jianmin Wang.
    Transferability vs. discriminability: Batch spectral penalization for adversarial
    domain adaptation. In *ICML*, 2019c.'
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2019c) Xinyang Chen、Sinan Wang、Mingsheng Long 和 Jianmin Wang。可迁移性与区分性：用于对抗性领域适应的批量谱惩罚。发表于*ICML*，2019年。
- en: Chen et al. (2021b) Xinyang Chen, Sinan Wang, Jianmin Wang, and Mingsheng Long.
    Representation subspace distance for domain adaptation regression. In *ICML*,
    2021b.
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2018) Yuhua Chen, Wen Li, Christos Sakaridis, Dengxin Dai, and
    Luc Van Gool. Domain adaptive faster R-CNN for object detection in the wild. In
    *CVPR*, 2018.
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cho et al. (2014) Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry
    Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations
    using RNN encoder–decoder for statistical machine translation. In *EMNLP*, 2014.
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chronopoulou et al. (2019) Alexandra Chronopoulou, Christos Baziotis, and Alexandros
    Potamianos. An embarrassingly simple approach for transfer learning from pretrained
    language models. In *NAACL*, 2019.
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Conneau et al. (2018) Alexis Conneau, Guillaume Lample, Ruty Rinott, Adina
    Williams, Samuel R. Bowman, Holger Schwenk, and Veselin Stoyanov. XNLI: evaluating
    cross-lingual sentence representations. In *EMNLP*, 2018.'
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Courty et al. (2017) Nicolas Courty, Rémi Flamary, Amaury Habrard, and Alain
    Rakotomamonjy. Joint distribution optimal transportation for domain adaptation.
    In *NeurIPS*, 2017.
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cui et al. (2018) Yin Cui, Yang Song, Chen Sun, Andrew Howard, and Serge Belongie.
    Large scale fine-grained categorization and domain-specific transfer learning.
    In *CVPR*, pages 4109–4118, 2018.
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Damodaran et al. (2018) Bharath Bhushan Damodaran, Benjamin Kellenberger, Rémi
    Flamary, Devis Tuia, and Nicolas Courty. Deepjdot: Deep joint distribution optimal
    transport for unsupervised domain adaptation. In *ECCV*, 2018.'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Delange et al. (2021) Matthias Delange, Rahaf Aljundi, Marc Masana, Sarah Parisot,
    Xu Jia, Ales Leonardis, Greg Slabaugh, and Tinne Tuytelaars. A continual learning
    survey: Defying forgetting in classification tasks. *TPAMI*, page 1–20, 2021.'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deng et al. (2009) Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and
    Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In *CVPR*, 2009.'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. Bert: Pre-training of deep bidirectional transformers for language
    understanding. In *NAACL*, 2019.'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doersch et al. (2015) Carl Doersch, Abhinav Gupta, and Alexei A. Efros. Unsupervised
    visual representation learning by context prediction. In *ICCV*, 2015.
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Donahue et al. (2014) Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman,
    Ning Zhang, Eric Tzeng, and Trevor Darrell. Decaf: A deep convolutional activation
    feature for generic visual recognition. In *ICML*, 2014.'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dosovitskiy et al. (2021) Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
    Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias
    Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An
    Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. In *ICLR*,
    2021.'
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finn et al. (2017) Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic
    meta-learning for fast adaptation of deep networks. In *ICML*, 2017.
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: French et al. (2018) Geoffrey French, Michal Mackiewicz, and Mark H. Fisher.
    Self-ensembling for domain adaptation. In *ICLR*, 2018.
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ganin and Lempitsky (2015) Yaroslav Ganin and Victor Lempitsky. Unsupervised
    domain adaptation by backpropagation. In *ICML*, 2015.
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ganin et al. (2016) Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain,
    Hugo Larochelle, François Laviolette, Mario March, and Victor Lempitsky. Domain-adversarial
    training of neural networks. *JMLR*, 17(59):1–35, 2016.
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Garcia and Bruna (2018) Victor Garcia and Joan Bruna. Few-shot learning with
    graph neural networks. In *ICLR*, 2018.
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ge et al. (2020) Yixiao Ge, Dapeng Chen, and Hongsheng Li. Mutual mean-teaching:
    Pseudo label refinery for unsupervised domain adaptation on person re-identification.
    In *ICLR*, 2020.'
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geirhos et al. (2019) Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias
    Bethge, Felix A Wichmann, and Wieland Brendel. Imagenet-trained cnns are biased
    towards texture; increasing shape bias improves accuracy and robustness. In *ICLR*,
    2019.
  id: totrans-686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Girshick et al. (2014) Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra
    Malik. Rich feature hierarchies for accurate object detection and semantic segmentation.
    In *CVPR*, 2014.
  id: totrans-687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Glorot et al. (2011) Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Domain
    adaptation for large-scale sentiment classification: A deep learning approach.
    In *ICML*, 2011.'
  id: totrans-688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gong et al. (2012) Boqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman. Geodesic
    flow kernel for unsupervised domain adaptation. In *CVPR*, 2012.
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gong et al. (2013) Boqing Gong, Kristen Grauman, and Fei Sha. Connecting the
    dots with landmarks: Discriminatively learning domain-invariant features for unsupervised
    domain adaptation. In *ICML*, 2013.'
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2014) Ian J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
    Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
    Generative adversarial networks. In *NeurIPS*, 2014.
  id: totrans-691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2015) Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.
    Explaining and harnessing adversarial examples. 2015.
  id: totrans-692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goyal et al. (2021) Anirudh Goyal, Alex Lamb, Jordan Hoffmann, Shagun Sodhani,
    Sergey Levine, Yoshua Bengio, and Bernhard Schölkopf. Recurrent independent mechanisms.
    In *ICLR*, 2021.
  id: totrans-693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gretton et al. (2012a) Arthur Gretton, Karsten M. Borgwardt, Malte J. Rasch,
    Bernhard Schölkopf, and Alexander Smola. A kernel two-sample test. *JMLR*, 13(25):723–773,
    2012a.
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gretton et al. (2012b) Arthur Gretton, Dino Sejdinovic, Heiko Strathmann, Sivaraman
    Balakrishnan, Massimiliano Pontil, Kenji Fukumizu, and Bharath K Sriperumbudur.
    Optimal kernel choice for large-scale two-sample tests. In *NeurIPS*, 2012b.
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grill et al. (2020) Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin
    Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires,
    Zhaohan Guo, Mohammad Gheshlaghi Azar, Bilal Piot, koray kavukcuoglu, Remi Munos,
    and Michal Valko. Bootstrap your own latent - a new approach to self-supervised
    learning. In *NeurIPS*, 2020.
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gulrajani and Lopez-Paz (2021) Ishaan Gulrajani and David Lopez-Paz. In search
    of lost domain generalization. In *ICLR*, 2021.
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. (2021) Demi Guo, Alexander Rush, and Yoon Kim. Parameter-efficient
    transfer learning with diff pruning. In *ACL*, 2021.
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guo et al. (2019) Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman,
    Tajana Rosing, and Rogerio Feris. Spottune: transfer learning through adaptive
    fine-tuning. In *CVPR*, 2019.'
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gururangan et al. (2020) Suchin Gururangan, Ana Marasović, Swabha Swayamdipta,
    Kyle Lo, Iz Beltagy, Doug Downey, and Noah A. Smith. Don’t stop pretraining: Adapt
    language models to domains and tasks. In *ACL*, 2020.'
  id: totrans-700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2016) Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep
    residual learning for image recognition. In *CVPR*, 2016.
  id: totrans-701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2017) Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick.
    Mask r-cnn. In *ICCV*, 2017.
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2019) Kaiming He, Ross Girshick, and Piotr Dollár. Rethinking imagenet
    pre-training. In *ICCV*, 2019.
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2020) Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
    Momentum contrast for unsupervised visual representation learning. In *CVPR*,
    2020.
  id: totrans-704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2021) Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár,
    and Ross Girshick. Masked autoencoders are scalable vision learners. *arXiv preprint
    arXiv:2111.06377*, 2021.
  id: totrans-705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hendrycks et al. (2021) Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath,
    Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn
    Song, Jacob Steinhardt, and Justin Gilmer. The many faces of robustness: A critical
    analysis of out-of-distribution generalization. *ICCV*, 2021.'
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hjelm et al. (2019) R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan
    Grewal, Phil Bachman, Adam Trischler, and Yoshua Bengio. Learning deep representations
    by mutual information estimation and maximization. In *ICLR*, 2019.
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hoffman et al. (2016) Judy Hoffman, Dequan Wang, Fisher Yu, and Trevor Darrell.
    Fcns in the wild: Pixel-level adversarial and constraint-based adaptation. 2016.'
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hoffman et al. (2018) Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu,
    Phillip Isola, Kate Saenko, Alexei Efros, and Trevor Darrell. Cycada: Cycle-consistent
    adversarial domain adaptation. In *ICML*, 2018.'
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Houlsby et al. (2019) Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna
    Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain
    Gelly. Parameter-efficient transfer learning for NLP. In *ICML*, 2019.
  id: totrans-710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Howard and Ruder (2018) Jeremy Howard and Sebastian Ruder. Universal language
    model fine-tuning for text classification. In *ACL*, 2018.
  id: totrans-711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. (2020) Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang,
    Vijay S. Pande, and Jure Leskovec. Pre-training graph neural networks. In *ICLR*,
    2020.
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2007) Jiayuan Huang, Arthur Gretton, Karsten Borgwardt, Bernhard
    Schölkopf, and Alex Smola. Correcting sample selection bias by unlabeled data.
    In *NeurIPS*, 2007.
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ioffe and Szegedy (2015) Sergey Ioffe and Christian Szegedy. Batch normalization:
    Accelerating deep network training by reducing internal covariate shift. In *ICML*,
    2015.'
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jang et al. (2019) Yunhun Jang, Hankook Lee, Sung Ju Hwang, and Jinwoo Shin.
    Learning what and where to transfer. In *ICML*, 2019.
  id: totrans-715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jiang et al. (2020) Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu,
    Jianfeng Gao, and Tuo Zhao. SMART: robust and efficient fine-tuning for pre-trained
    natural language models through principled regularized optimization. In *ACL*,
    2020.'
  id: totrans-716
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2021) Junguang Jiang, Yifei Ji, Ximei Wang, Yufeng Liu, Jianmin
    Wang, and Mingsheng Long. Regressive domain adaptation for unsupervised keypoint
    detection. In *CVPR*, 2021.
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2022) Junguang Jiang, Baixu Chen, Jianmin Wang, and Mingsheng
    Long. Decoupled adaptation for cross-domain object detection. In *ICLR*, 2022.
  id: totrans-718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jin et al. (2020) Ying Jin, Ximei Wang, Mingsheng Long, and Jianmin Wang. Minimum
    class confusion for versatile domain adaptation. In *ECCV*, 2020.
  id: totrans-719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Joshi et al. (2020) Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke
    Zettlemoyer, and Omer Levy. SpanBERT: Improving pre-training by representing and
    predicting spans. In *TACL*, 2020.'
  id: totrans-720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kang et al. (2019) Guoliang Kang, Lu Jiang, Yi Yang, and Alexander G Hauptmann.
    Contrastive adaptation network for unsupervised domain adaptation. In *CVPR*,
    2019.
  id: totrans-721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2019) Taekyung Kim, Minki Jeong, Seunghyeon Kim, Seokeon Choi,
    and Changick Kim. Diversify and match: A domain adaptive representation learning
    paradigm for object detection. In *CVPR*, 2019.'
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kirkpatrick et al. (2017) James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz,
    Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago
    Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting
    in neural networks. *PNAS*, 114(13):3521–3526, 2017.
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kolesnikov et al. (2020) Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan
    Puigcerver, Jessica Yung, Sylvain Gelly, and Neil Houlsby. Big transfer (bit):
    General visual representation learning. In *ECCV*, 2020.'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kornblith et al. (2019) Simon Kornblith, Jonathon Shlens, and Quoc V Le. Do
    better imagenet models transfer better? In *CVPR*, 2019.
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kou et al. (2020) Zhi Kou, Kaichao You, Mingsheng Long, and Jianmin Wang. Stochastic
    normalization. In *NeurIPS*, 2020.
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky et al. (2012) Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton.
    Imagenet classification with deep convolutional neural networks. In *NeurIPS*,
    2012.
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lample and Conneau (2019) Guillaume Lample and Alexis Conneau. Cross-lingual
    language model pretraining. In *NeurIPS*, 2019.
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lample et al. (2017) Guillaume Lample, Ludovic Denoyer, and Marc’Aurelio Ranzato.
    Unsupervised machine translation using monolingual corpora only. In *ICLR*, 2017.
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lan et al. (2020) Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel,
    Piyush Sharma, and Radu Soricut. Albert: A lite bert for self-supervised learning
    of language representations. In *ICLR*, 2020.'
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. (2015) Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning.
    *Nature*, 521(7553):436–444, 2015.
  id: totrans-731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee et al. (2019) Chen-Yu Lee, Tanmay Batra, Mohammad Haris Baig, and Daniel
    Ulbricht. Sliced wasserstein discrepancy for unsupervised domain adaptation. In
    *CVPR*, 2019.
  id: totrans-732
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2020a) Cheolhyoung Lee, Kyunghyun Cho, and Wanmo Kang. Mixout:
    Effective regularization to finetune large-scale pretrained language models. In
    *ICLR*, 2020a.'
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2020b) Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu
    Kim, Chan Ho So, and Jaewoo Kang. Biobert: a pre-trained biomedical language representation
    model for biomedical text mining. *Bioinformatics*, 36(4):1234–1240, 2020b.'
  id: totrans-734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lewis et al. (2020) Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad,
    Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART:
    Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation,
    and Comprehension. In *ACL*, 2020.'
  id: totrans-735
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2018) Chunyuan Li, Heerad Farkhoor, Rosanne Liu, and Jason Yosinski.
    Measuring the intrinsic dimension of objective landscapes. In *ICLR*, 2018.
  id: totrans-736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li and Liang (2021) Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing
    continuous prompts for generation. In *ACL*, 2021.'
  id: totrans-737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2019) Xingjian Li, Haoyi Xiong, Hanchao Wang, Yuxuan Rao, Liping
    Liu, Zeyu Chen, and Jun Huan. Delta: Deep learning transfer using feature map
    with attention for convolutional networks. In *ICLR*, 2019.'
  id: totrans-738
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2017) Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi
    Hou. Revisiting batch normalization for practical domain adaptation. In *ICLR
    Workshop*, 2017.
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li and Hoiem (2018) Zhizhong Li and Derek Hoiem. Learning without forgetting.
    *TPAMI*, 40(12):2935–2947, 2018.
  id: totrans-740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. (2020) Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need
    to access the source data? source hypothesis transfer for unsupervised domain
    adaptation. In *ICML*, 2020.
  id: totrans-741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2021a) Hong Liu, Jianmin Wang, and Mingsheng Long. Cycle self-training
    for domain adaptation. In *NeurIPS*, 2021a.
  id: totrans-742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu and Tuzel (2016) Ming-Yu Liu and Oncel Tuzel. Coupled generative adversarial
    networks. In *NeurIPS*, 2016.
  id: totrans-743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2021b) Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki
    Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey
    of prompting methods in natural language processing, 2021b.'
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2019a) Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao.
    Multi-task deep neural networks for natural language understanding. In *ACL*,
    2019a.
  id: totrans-745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019b) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta:
    A robustly optimized bert pretraining approach. *arXiv preprint arXiv:1907.11692*,
    2019b.'
  id: totrans-746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019c) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta:
    A robustly optimized BERT pretraining approach. 2019c.'
  id: totrans-747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2013) Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun,
    and Philip S. Yu. Transfer feature learning with joint distribution adaptation.
    In *ICCV*, 2013.
  id: totrans-748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2015) Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I. Jordan.
    Learning transferable features with deep adaptation networks. In *ICML*, 2015.
  id: totrans-749
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2016) Mingsheng Long, Jianmin Wang, and Michael I. Jordan. Unsupervised
    domain adaptation with residual transfer networks. In *NeurIPS*, 2016.
  id: totrans-750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2017) Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan.
    Deep transfer learning with joint adaptation networks. In *ICML*, 2017.
  id: totrans-751
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2018) Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I.
    Jordan. Conditional adversarial domain adaptation. In *NeurIPS*, 2018.
  id: totrans-752
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2019) Mingsheng Long, Yue Cao, Zhangjie Cao, Jianmin Wang, and
    Michael I. Jordan. Transferable representation learning with deep adaptation networks.
    *TPAMI*, 41(12):3071–3085, 2019.
  id: totrans-753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Louizos et al. (2018) Christos Louizos, Max Welling, and Diederik P. Kingma.
    Learning sparse neural networks through l_0 regularization. In *ICLR*, 2018.
  id: totrans-754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mahajan et al. (2018) Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming
    He, Manohar Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. Exploring
    the limits of weakly supervised pretraining. In *ECCV*, 2018.
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mallya and Lazebnik (2018) Arun Mallya and Svetlana Lazebnik. Piggyback: Adding
    multiple tasks to a single, fixed network by learning to mask. In *ECCV*, 2018.'
  id: totrans-756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mansour et al. (2009) Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh.
    Domain adaptation: Learning bounds and algorithms. In *COLT*, 2009.'
  id: totrans-757
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Munkhdalai and Yu (2017) Tsendsuren Munkhdalai and Hong Yu. Meta networks. In
    *ICML*, 2017.
  id: totrans-758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ngiam et al. (2018) Jiquan Ngiam, Daiyi Peng, Vijay Vasudevan, Simon Kornblith,
    Quoc V Le, and Ruoming Pang. Domain adaptive transfer learning with specialist
    models. *arXiv preprint arXiv:1811.07056*, 2018.
  id: totrans-759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nguyen et al. (2020) Cuong Nguyen, Tal Hassner, Matthias Seeger, and Cedric
    Archambeau. Leep: A new measure to evaluate transferability of learned representations.
    In *ICML*, 2020.'
  id: totrans-760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oord et al. (2019) Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation
    learning with contrastive predictive coding. *NeurIPS*, 2019.
  id: totrans-761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pan and Yang (2010) Sinno Jialin Pan and Qiang Yang. A survey on transfer learning.
    *TKDE*, pages 1345–1359, 2010.
  id: totrans-762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pan et al. (2011) Sinno Jialin Pan, Ivor W. Tsang, James T. Kwok, and Qiang
    Yang. Domain adaptation via transfer component analysis. *TNNLS*, pages 199–210,
    2011.
  id: totrans-763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Paszke et al. (2019) Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James
    Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca
    Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison,
    Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and
    Soumith Chintala. Pytorch: An imperative style, high-performance deep learning
    library. In *NeurIPS*, 2019.'
  id: totrans-764
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peng et al. (2019) Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko,
    and Bo Wang. Moment matching for multi-source domain adaptation. In *ICCV*, 2019.
  id: totrans-765
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peters et al. (2016) Jonas Peters, Peter Bühlmann, and Nicolai Meinshausen.
    Causal inference by using invariant prediction: identification and confidence
    intervals. *Journal of the Royal Statistical Society. Series B (Statistical Methodology)*,
    pages 947–1012, 2016.'
  id: totrans-766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peters et al. (2017) Jonas Peters, Dominik Janzing, and Bernhard Schölkopf.
    *Elements of causal inference: foundations and learning algorithms*. The MIT Press,
    2017.'
  id: totrans-767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peters et al. (2018) Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner,
    Christopher Clark, Kenton Lee, and Luke Zettlemoyer. Deep contextualized word
    representations. In *NAACL*, 2018.
  id: totrans-768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pires et al. (2019) Telmo Pires, Eva Schlinger, and Dan Garrette. How multilingual
    is multilingual bert? In *ACL*, 2019.
  id: totrans-769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quionero-Candela et al. (2009) J. Quionero-Candela, M. Sugiyama, A. Schwaighofer,
    and N. D. Lawrence. *Dataset shift in machine learning*. The MIT Press, 2009.
  id: totrans-770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2018) Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya
    Sutskever. Improving language understanding by generative pre-training. *Technical
    report, OpenAI*, 2018.
  id: totrans-771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2021) Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh,
    Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack
    Clark, et al. Learning transferable visual models from natural language supervision.
    In *ICML*, 2021.
  id: totrans-772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
    Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring
    the limits of transfer learning with a unified text-to-text transformer. *JMLR*,
    21(140):1–67, 2020.
  id: totrans-773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raghu et al. (2020) Aniruddh Raghu, Maithra Raghu, Samy Bengio, and Oriol Vinyals.
    Rapid learning or feature reuse? towards understanding the effectiveness of maml.
    In *ICLR*, 2020.
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Raghu et al. (2019) Maithra Raghu, Chiyuan Zhang, Jon Kleinberg, and Samy Bengio.
    Transfusion: Understanding transfer learning for medical imaging. In *NeurIPS*,
    2019.'
  id: totrans-775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rebuffi et al. (2017) S-A Rebuffi, H. Bilen, and A. Vedaldi. Learning multiple
    visual domains with residual adapters. In *NeurIPS*, 2017.
  id: totrans-776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Redko et al. (2020) Ievgen Redko, Emilie Morvant, Amaury Habrard, Marc Sebban,
    and Younès Bennani. A survey on domain adaptation theory: learning bounds and
    theoretical guarantees, 2020.'
  id: totrans-777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren et al. (2015) Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster
    r-cnn: Towards real-time object detection with region proposal networks. In *NeurIPS*,
    2015.'
  id: totrans-778
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rosenstein (2005) Michael T. Rosenstein. To transfer or not to transfer. In
    *NeurIPS*, 2005.
  id: totrans-779
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rusak et al. (2021) Evgenia. Rusak, Steffen Schneider, Peter Gehler, Oliver
    Bringmann, Wieland Brendel, and Matthias Bethge. Adapting imagenet-scale models
    to complex distribution shifts with self-learning. *arXiv preprint arXiv:2104.12928*,
    2021.
  id: totrans-780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Russakovsky et al. (2015) Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause,
    Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael
    Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition
    Challenge. *IJCV*, 115(3):211–252, 2015.
  id: totrans-781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rusu et al. (2019) Andrei A Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals,
    Razvan Pascanu, Simon Osindero, and Raia Hadsell. Meta-learning with latent embedding
    optimization. In *ICLR*, 2019.
  id: totrans-782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saito et al. (2018) Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya
    Harada. Maximum classifier discrepancy for unsupervised domain adaptation. In
    *CVPR*, 2018.
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saito et al. (2019) Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada, and Kate
    Saenko. Strong-weak distribution alignment for adaptive object detection. In *CVPR*,
    2019.
  id: totrans-784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Salman et al. (2020) Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor,
    and Aleksander Madry. Do adversarially robust imagenet models transfer better?
    In *NeurIPS*, 2020.
  id: totrans-785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sankaranarayanan et al. (2018) Swami Sankaranarayanan, Yogesh Balaji, Carlos D.
    Castillo, and Rama Chellappa. Generate to adapt: Aligning domains using generative
    adversarial networks. In *CVPR*, 2018.'
  id: totrans-786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Santoro et al. (2016) Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan
    Wierstra, and Timothy Lillicrap. Meta-learning with memory-augmented neural networks.
    In *ICML*, 2016.
  id: totrans-787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schick and Schütze (2020) Timo Schick and Hinrich Schütze. Exploiting cloze
    questions for few-shot text classification and natural language inference. In
    *EACL*, 2020.
  id: totrans-788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schmidhuber (1987) Jürgen Schmidhuber. *Evolutionary principles in self-referential
    learning*. PhD thesis, Technische Universität München, 1987.
  id: totrans-789
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schölkopf et al. (2012) Bernhard Schölkopf, Dominik Janzing, Jonas Peters, Eleni
    Sgouritsa, Kun Zhang, and Joris Mooij. On causal and anticausal learning. In *ICML*,
    2012.
  id: totrans-790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schölkopf et al. (2021) Bernhard Schölkopf, Francesco Locatello, Stefan Bauer,
    Nan Rosemary Ke, Nal Kalchbrenner, Anirudh Goyal, and Yoshua Bengio. Toward causal
    representation learning. *Proceedings of the IEEE*, 109(5):612–634, 2021.
  id: totrans-791
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Senior et al. (2020) Andrew W Senior, Richard Evans, John Jumper, James Kirkpatrick,
    Laurent Sifre, Tim Green, Chongli Qin, Augustin Žídek, Alexander WR Nelson, Alex
    Bridgland, et al. Improved protein structure prediction using potentials from
    deep learning. *Nature*, 577(7792):706–710, 2020.
  id: totrans-792
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sermanet et al. (2013) Pierre Sermanet, David Eigen, Xiang Zhang, Michaël Mathieu,
    Rob Fergus, and Yann LeCun. Overfeat: Integrated recognition, localization and
    detection using convolutional networks. *arXiv preprint arXiv:1312.6229*, 2013.'
  id: totrans-793
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shrivastava et al. (2017) Ashish Shrivastava, Tomas Pfister, Oncel Tuzel, Josh
    Susskind, Wenda Wang, and Russell Webb. Learning from simulated and unsupervised
    images through adversarial training. In *CVPR*, 2017.
  id: totrans-794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shu et al. (2018) Rui Shu, Hung H. Bui, Hirokazu Narui, and Stefano Ermon. A
    dirt-t approach to unsupervised domain adaptation. In *ICLR*, 2018.
  id: totrans-795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shu et al. (2021a) Yang Shu, Zhangjie Cao, Jinghan Gao, Jianmin Wang, and Mingsheng
    Long. Omni-training for data-efficient deep learning. *arXiv preprint arXiv:2110.07510*,
    2021a.
  id: totrans-796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shu et al. (2021b) Yang Shu, Zhi Kou, Zhangjie Cao, Jianmin Wang, and Mingsheng
    Long. Zoo-tuning: Adaptive transfer from a zoo of models. In *ICML*, 2021b.'
  id: totrans-797
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Silver et al. (2016) David Silver, Aja Huang, Chris J Maddison, Arthur Guez,
    Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou,
    Veda Panneershelvam, Marc Lanctot, et al. Mastering the game of go with deep neural
    networks and tree search. *Nature*, 529(7587):484–489, 2016.
  id: totrans-798
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snell et al. (2017) Jake Snell, Kevin Swersky, and Richard S. Zemel. Prototypical
    networks for few-shot learning. In *NeurIPS*, 2017.
  id: totrans-799
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sriperumbudur et al. (2010) Bharath K. Sriperumbudur, Arthur Gretton, Kenji
    Fukumizu, Bernhard Schölkopf, and Gert R. G. Lanckriet. Hilbert space embeddings
    and metrics on probability measures. *JMLR*, 2010.
  id: totrans-800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sugiyama et al. (2007) Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert
    Müller. Covariate shift adaptation by importance weighted cross validation. *JMLR*,
    8(35):985–1005, 2007.
  id: totrans-801
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sugiyama et al. (2008) Masashi Sugiyama, Shinichi Nakajima, Hisashi Kashima,
    Paul Buenau, and Motoaki Kawanabe. Direct importance estimation with model selection
    and its application to covariate shift adaptation. In *NeurIPS*, 2008.
  id: totrans-802
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun and Saenko (2016) Baochen Sun and Kate Saenko. Deep coral: Correlation
    alignment for deep domain adaptation. In *ECCV*, 2016.'
  id: totrans-803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2019a) Qianru Sun, Yaoyao Liu, Tat-Seng Chua, and Bernt Schiele.
    Meta-transfer learning for few-shot learning. In *CVPR*, 2019a.
  id: totrans-804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2019b) Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen,
    Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, and Hua Wu. Ernie: Enhanced representation
    through knowledge integration. *arXiv preprint arXiv:1904.09223*, 2019b.'
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taigman et al. (2017) Yaniv Taigman, Adam Polyak, and Lior Wolf. Unsupervised
    cross-domain image generation. In *ICLR*, 2017.
  id: totrans-806
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thrun and Pratt (1998) Sebastian Thrun and Lorien Pratt. *Learning to learn*.
    Springer Science & Business Media, 1998.
  id: totrans-807
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tian et al. (2020) Yonglong Tian, Dilip Krishnan, and Phillip Isola. Contrastive
    multiview coding. In *ECCV*, 2020.
  id: totrans-808
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Torrey and Shavlik (2010) Lisa Torrey and Jude Shavlik. Transfer learning. 2010.
  id: totrans-809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tsai et al. (2018) Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn,
    Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output
    space for semantic segmentation. In *CVPR*, 2018.
  id: totrans-810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tzeng et al. (2014) Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and
    Trevor Darrell. Deep domain confusion: Maximizing for domain invariance. 2014.'
  id: totrans-811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tzeng et al. (2015) Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko.
    Simultaneous deep transfer across domains and tasks. In *ICCV*, pages 4068–4076,
    2015.
  id: totrans-812
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tzeng et al. (2017) Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.
    Adversarial discriminative domain adaptation. In *CVPR*, 2017.
  id: totrans-813
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is
    all you need. In *NeurIPS*, 2017.
  id: totrans-814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Veličković et al. (2019) Petar Veličković, William Fedus, William L Hamilton,
    Pietro Liò, Yoshua Bengio, and R Devon Hjelm. Deep graph infomax. In *ICLR*, 2019.
  id: totrans-815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vincent et al. (2008) Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine
    Manzagol. Extracting and composing robust features with denoising autoencoders.
    In *ICML*, 2008.
  id: totrans-816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vinyals et al. (2016) Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan
    Wierstra, et al. Matching networks for one shot learning. In *NeurIPS*, 2016.
  id: totrans-817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vinyals et al. (2019) Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki,
    Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H Choi, Richard Powell,
    Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using multi-agent
    reinforcement learning. *Nature*, 575(7782):350–354, 2019.
  id: totrans-818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vu et al. (2019) Tuan-Hung Vu, Himalaya Jain, Maxime Bucher, Matthieu Cord,
    and Patrick Perez. Advent: Adversarial entropy minimization for domain adaptation
    in semantic segmentation. In *CVPR*, 2019.'
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2019a) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill,
    Omer Levy, and Samuel R. Bowman. GLUE: A multi-task benchmark and analysis platform
    for natural language understanding. In *ICLR*, 2019a.'
  id: totrans-820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019b) Haohan Wang, Songwei Ge, Zachary Lipton, and Eric P Xing.
    Learning robust global representations by penalizing local predictive power. In
    *NeurIPS*, 2019b.
  id: totrans-821
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2019c) Ximei Wang, Ying Jin, Mingsheng Long, Jianmin Wang, and
    Michael I Jordan. Transferable normalization: Towards improving transferability
    of deep neural networks. In *NeurIPS*, 2019c.'
  id: totrans-822
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2021) Ximei Wang, Jinghan Gao, Mingsheng Long, and Jianmin Wang.
    Self-tuning for data-efficient deep learning. In *ICML*, 2021.
  id: totrans-823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019d) Zirui Wang, Zihang Dai, Barnabás Póczos, and Jaime G. Carbonell.
    Characterizing and avoiding negative transfer. In *CVPR*, 2019d.
  id: totrans-824
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2022) Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei
    Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. Finetuned language models
    are zero-shot learners. In *ICLR*, 2022.
  id: totrans-825
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2018) Longhui Wei, Shiliang Zhang, Wen Gao, and Qi Tian. Person
    transfer gan to bridge domain gap for person re-identification. In *CVPR*, 2018.
  id: totrans-826
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wightman (2019) Ross Wightman. Pytorch image models. [https://github.com/rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models),
    2019.
  id: totrans-827
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu and He (2018) Yuxin Wu and Kaiming He. Group normalization. In *ECCV*, 2018.
  id: totrans-828
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2018) Zhirong Wu, Yuanjun Xiong, X Yu Stella, and Dahua Lin. Unsupervised
    feature learning via non-parametric instance discrimination. In *CVPR*, 2018.
  id: totrans-829
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2021) Runxin Xu, Fuli Luo, Zhiyuan Zhang, Chuanqi Tan, Baobao Chang,
    Songfang Huang, and Fei Huang. Raise a child in large language model: Towards
    effective and generalizable fine-tuning. In *EMNLP*, 2021.'
  id: totrans-830
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yalniz et al. (2019) I Zeki Yalniz, Hervé Jégou, Kan Chen, Manohar Paluri, and
    Dhruv Mahajan. Billion-scale semi-supervised learning for image classification.
    *arXiv preprint arXiv:1905.00546*, 2019.
  id: totrans-831
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2019) Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R
    Salakhutdinov, and Quoc V Le. Xlnet: Generalized autoregressive pretraining for
    language understanding. In *NeurIPS*, 2019.'
  id: totrans-832
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yao et al. (2019) Huaxiu Yao, Ying Wei, Junzhou Huang, and Zhenhui Li. Hierarchically
    structured meta-learning. In *ICML*, 2019.
  id: totrans-833
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yosinski et al. (2014) Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson.
    How transferable are features in deep neural networks? In *NeurIPS*, 2014.
  id: totrans-834
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You et al. (2021) Kaichao You, Yong Liu, Jianmin Wang, and Mingsheng Long.
    Logme: Practical assessment of pre-trained models for transfer learning. In *ICML*,
    2021.'
  id: totrans-835
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zamir et al. (2018) Amir Roshan Zamir, Alexander Sax, William B. Shen, Leonidas J.
    Guibas, Jitendra Malik, and Silvio Savarese. Taskonomy: Disentangling task transfer
    learning. In *CVPR*, 2018.'
  id: totrans-836
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zellinger et al. (2017) Werner Zellinger, Thomas Grubinger, Edwin Lughofer,
    Thomas Natschläger, and Susanne Saminger-Platz. Central moment discrepancy (cmd)
    for domain-invariant representation learning. In *ICLR*, 2017.
  id: totrans-837
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2017) Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht,
    and Oriol Vinyals. Understanding deep learning requires rethinking generalization.
    In *ICLR*, 2017.
  id: totrans-838
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2019a) Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P. Xing,
    Laurent El Ghaoui, and Michael I. Jordan. Theoretically principled trade-off between
    robustness and accuracy. In *ICML*, 2019a.
  id: totrans-839
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2019b) Jeffrey O. Zhang, Alexander Sax, Amir Zamir, Leonidas J.
    Guibas, and Jitendra Malik. Side-tuning: Network adaptation via additive side
    networks. 2019b.'
  id: totrans-840
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2019c) Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan.
    Bridging theory and algorithm for domain adaptation. In *ICML*, 2019c.
  id: totrans-841
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang and Sabuncu (2018) Zhilu Zhang and Mert R. Sabuncu. Generalized cross
    entropy loss for training deep neural networks with noisy labels. In *NeurIPS*,
    2018.
  id: totrans-842
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2021) Nanxuan Zhao, Zhirong Wu, Rynson W. H. Lau, and Stephen Lin.
    What makes instance discrimination good for transfer learning? In *ICLR*, 2021.
  id: totrans-843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zheng et al. (2021) Lucia Zheng, Neel Guha, Brandon R. Anderson, Peter Henderson,
    and Daniel E. Ho. When does pretraining help? assessing self-supervised learning
    for law and the casehold dataset. In *ICAIL*, 2021.
  id: totrans-844
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhong et al. (2020) Jincheng Zhong, Ximei Wang, Zhi Kou, Jianmin Wang, and Mingsheng
    Long. Bi-tuning of pre-trained representations. *arXiv preprint arXiv:2011.06182*,
    2020.
  id: totrans-845
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. (2017) Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros.
    Unpaired image-to-image translation using cycle-consistent adversarial networks.
    In *ICCV*, 2017.
  id: totrans-846
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2015) Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov,
    Raquel Urtasun, Antonio Torralba, and Sanja Fidler. Aligning books and movies:
    Towards story-like visual explanations by watching movies and reading books. In
    *ICCV*, 2015.'
  id: totrans-847
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhuang et al. (2021) Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun
    Zhu, Hengshu Zhu, Hui Xiong, and Qing He. A comprehensive survey on transfer learning.
    *Proceedings of the IEEE*, 109(1):43–76, 2021.
  id: totrans-848
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zou et al. (2018) Yang Zou, Zhiding Yu, B. V. K. Vijaya Kumar, and Jinsong Wang.
    Unsupervised domain adaptation for semantic segmentation via class-balanced self-training.
    In *ECCV*, 2018.
  id: totrans-849
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
