- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 20:00:34'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2006.13544] Spin Parity of Spiral Galaxies II: A catalogue of 80k spiral galaxies
    using big data from the Subaru Hyper Suprime-Cam Survey and deep learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2006.13544](https://ar5iv.labs.arxiv.org/html/2006.13544)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Spin Parity of Spiral Galaxies II: A catalogue of 80k spiral galaxies using
    big data from the Subaru Hyper Suprime-Cam Survey and deep learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ken-ichi Tadaki,¹ Masanori Iye,¹ Hideya Fukumoto,² Masao Hayashi,¹ Cristian
    E. Rusu,¹ Rhythm Shimakawa,¹ and Tomoka Tosaki,³
  prefs: []
  type: TYPE_NORMAL
- en: ¹National Astronomical Observatory of Japan, 2-21-1 Osawa, Mitaka, Tokyo 181-8588,
    Japan
  prefs: []
  type: TYPE_NORMAL
- en: ²The Open University of Japan, 2-11 Wakaba, Mihama-ku, Chiba 261- 8586 Japan
  prefs: []
  type: TYPE_NORMAL
- en: '³Joetsu University of Education, Yamayashiki-machi, Joetsu, Niigata 943-8512,
    Japan E-mail: tadaki.ken@nao.ac.jp(Accepted XXX. Received YYY; in original form
    ZZZ)'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We report an automated morphological classification of galaxies into S-wise
    spirals, Z-wise spirals, and non-spirals using big image data taken from Subaru/Hyper
    Suprime-Cam (HSC) Survey and a convolutional neural network(CNN)-based deep learning
    technique. The HSC $i$-band images are about 25 times deeper than those from the
    Sloan Digital Sky Survey (SDSS) and have a two times higher spatial resolution,
    allowing us to identify substructures such as spiral arms and bars in galaxies
    at $z>0.1$. We train CNN classifiers by using HSC images of 1447 S-spirals, 1382
    Z-spirals, and 51,650 non-spirals. As the number of images in each class is unbalanced,
    we augment the data of spiral galaxies by horizontal flipping, rotation, and rescaling
    of images to make the numbers of three classes similar. The trained CNN models
    correctly classify 97.5% of the validation data, which is not used for training.
    We apply the CNNs to HSC images of a half million galaxies with an i-band magnitude
    of $i<20$ over an area of 320 deg². 37,917 S-spirals and 38,718 Z-spirals are
    identified, indicating no significant difference between the numbers of two classes.
    Among a total of 76,635 spiral galaxies, 48,576 are located at $z>0.2$, where
    we are hardly able to identify spiral arms in the SDSS images. Our attempt demonstrates
    that a combination of the HSC big data and CNNs has a large potential to classify
    various types of morphology such as bars, mergers and strongly-lensed objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'galaxies: spiral – techniques: image processing – catalogueues^†^†pubyear:
    2020^†^†pagerange: Spin Parity of Spiral Galaxies II: A catalogue of 80k spiral
    galaxies using big data from the Subaru Hyper Suprime-Cam Survey and deep learning–[A](#A1
    "Appendix A Some extra material ‣ Spin Parity of Spiral Galaxies II: A catalogue
    of 80k spiral galaxies using big data from the Subaru Hyper Suprime-Cam Survey
    and deep learning")'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Spiral arms are one of the most beautiful structures in galaxies and attract
    the interest of many people. Density wave theory is a traditionally accepted concept
    to explain spiral patterns in galaxies (Lin & Shu, [1964](#bib.bib37)) whereas
    recent numerical simulations support that spiral arms are formed due to a swing
    amplification associated with galactic shear motion (e.g., Baba et al., [2013](#bib.bib5);
    Dobbs & Baba, [2014](#bib.bib13)), which was originally suggest by Goldreich &
    Lynden-Bell ([1965](#bib.bib21)). The winding direction of spiral arms with respect
    to the galaxy rotation direction has also been a classic subject of controversial
    debates in observational and theoretical studies of spiral galaxies until around
    the decade of the 1960s. Iye et al. ([2019](#bib.bib30)) demonstrate a corroborative
    evidence that all galaxies are trailing spirals provided that the dark lane dominant
    side is the side of the disk near to us. Once the winding direction of spiral
    arms is identified, we can infer the spin vector of galaxies, which is one of
    important physical properties in the process of galaxy formation. In the framework
    of the tidal torque theory (e.g., Doroshkevich, [1970](#bib.bib15); Peebles, [1969](#bib.bib47);
    White, [1984](#bib.bib57)), galaxies acquire angular momentum by the tidal fields
    of their neighbors in the linear stage of structure formation. Thus, the winding
    direction, that is the spin vectors, of galaxies would have been randomly located,
    leading to the isotropic distribution that the number of S-wise spirals (S-spirals)
    is identical to that of Z-wise spirals (Z-spirals). If there is a global anisotropy
    in the spatial distribution of the winding direction, a large-scale vorticity
    such as galaxy-cluster tidal interaction would affect the spin of galaxies (Sugai
    & Iye, [1995](#bib.bib55)). However, a statistical analysis of the winding direction
    was not well developed in the past two decades, except for a few studies (Hayes
    et al., [2017](#bib.bib24); Shamir, [2017](#bib.bib52)).
  prefs: []
  type: TYPE_NORMAL
- en: We can immediately identify spiral arms in a galaxy and judge whether it is
    a S-spiral or a Z-spiral by visual inspection. However, it is not easy to repeat
    this procedure 10,000 times or more. Another problem is that visual classification
    depends on the expertise and experience of people who look at images. In the Galaxy
    Zoo project (Lintott et al., [2011](#bib.bib39); Willett et al., [2013](#bib.bib58)),
    about 100,000 volunteers classified the morphology of $\sim$900,000 galaxies at
    $0.001<z<0.25$, drawn from the Sloan Digital Sky Survey (SDSS; York et al. [2000](#bib.bib59)).
    Masters et al. ([2010](#bib.bib43)) studied 5,433 face-on spiral galaxies at $0.03<z<0.085$
    from the Galaxy Zoo database. To make a similarly large sample of more distant
    spiral galaxies at $z>0.1$, we require higher sensitivity and higher resolution
    imaging data set over a wide area.
  prefs: []
  type: TYPE_NORMAL
- en: We are conducting a multi-band imaging survey by using Hyper Suprime-Cam (HSC)
    in Subaru Strategic Program (HSC-SSP; Aihara et al. [2018](#bib.bib2)). The HSC
    has the largest field of view of 1.5 degree diameter on 8-m class telescopes.
    The Wide layer of the survey covers 1400 deg² in five broad bands ($grizy$) with
    a 5$\sigma$ point-source depth of $i\sim 26.2$, which is about 3.5 magnitudes
    deeper than SDSS. The increased sensitivity allows us to characterize spiral arms
    in distant galaxies at $z>0.1$ while at the same time the wide survey produces
    images of more than one million galaxies. We therefore need to develop an automated
    method for morphological classification in the big data era. Commonly used parametric
    methods such as Sérsic model fitting (e.g., Peng et al., [2010](#bib.bib48)) and
    nonparametric ones such as the concentration (C), asymmetry (A), clumpiness (S)
    method and the Gini/M[20] parameters (e.g., Conselice, [2014](#bib.bib9)) are
    not suitable for identifying substructures in galaxies, such as spiral arms, bars,
    and tidal streams. Currently, only several studies succeed in automatically extracting
    spiral structures (Davis & Hayes, [2014](#bib.bib11); Kuminski & Shamir, [2016](#bib.bib34);
    Hart et al., [2017](#bib.bib23)).
  prefs: []
  type: TYPE_NORMAL
- en: In 2012, deep learning has been dramatically developed enough to correctly recognize
    the picture of a cat as a cat with high accuracy of $\sim$84% (Krizhevsky et al.,
    [2012](#bib.bib33)). The accuracy of image classification has exceeded human accuracy
    in 2015 ($\sim$95%; He et al. [2016](#bib.bib25)). A convolutional neural network
    (CNN) is now a commonly-used technique for classifying images into multiple categories
    (e.g., Fukushima, [1980](#bib.bib17); LeCun et al., [1998](#bib.bib36); Russakovsky
    et al., [2015](#bib.bib50)). CNNs convolve images with multiple kernels (filters)
    to reduce the amount of information and efficiently extract local features in
    images. Dieleman et al. ([2015](#bib.bib12)) have applied a CNN technique to astronomical
    images for galaxy morphology classification and successfully reproduced the results
    from the Galaxy Zoo with the accuracy of 99% (see also e.g., Huertas-Company et al.,
    [2015](#bib.bib28); Domínguez Sánchez et al., [2018](#bib.bib14); Abraham et al.,
    [2018](#bib.bib1)). These approaches are mostly supervised learning, which requires
    a training data set with pre-labelled images. On the other hand, there are some
    studies which adopt an unsupervised learning approach for automated morphological
    classification (e.g., Hocking et al., [2018](#bib.bib26); Martin et al., [2019](#bib.bib42)).
    Furthermore, Schawinski et al. ([2017](#bib.bib51)) generate super resolution
    images from artificially degraded low-resolution images using a generative adversarial
    network (Goodfellow et al., [2014](#bib.bib22)) although they caution about application
    to unknown galaxy population, which is not included in a training data set. CNNs
    and other deep learning techniques are becoming increasingly common in Astronomy.
  prefs: []
  type: TYPE_NORMAL
- en: In this paper, we present CNN models to identify spiral arms in galaxies by
    using the HSC imaging data. In Section 2, we describe the imaging data taken from
    the HSC-SSP survey and build a training data set. We show the architecture of
    CNNs and estimate the accuracy of morphological classification by using validation
    data sets in Section 3. We apply the trained CNNs to an unlabeled data set of
    a half million galaxy images and present a catalogue of 80k spiral galaxies in
    Section 4.
  prefs: []
  type: TYPE_NORMAL
- en: 2 Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1 Subaru Hyper Suprime Cam Data Sample
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This work is based on data from the second public data release (PDR-2) of the
    HSC-SSP for the Wide layer (Aihara et al., [2019](#bib.bib3)). For morphological
    classification, we use $i-$band images, which have reached an exposure time of
    about 20 minutes. Figure 1 shows the images from the HSC-SSP data and SDSS for
    two spiral galaxies, demonstrating the superb image quality with which we can
    identify the spiral winding sense even in distant galaxies at $z>0.1$.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/44416c642d58ba42bf55c8e2c24bbf1d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Comparisons between SDSS and HSC $i-$band images for a S-wise spiral
    galaxy (left) with $i=18.7$ at $z=0.16$ and a Z-wise spiral galaxy (right) with
    $i=18.8$ at $z=0.19$. The image sizes are all 10.8 arcsec $\times$ 10.8 arcsec.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5fcdb9a5553dd761244a3f3c034d9235.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Left: stellar mass vs. redshift for galaxies in a subsample of 56,787
    galaxies with $i<20$ in the Wide XMM-LSS field. Right: completeness as functions
    of stellar mass and redshift. Black lines denote the completeness of 90%.'
  prefs: []
  type: TYPE_NORMAL
- en: We use galaxies with 5.7 arcsec aperture magnitudes $i<20$ so that we can visually
    classify their morphology. It is still possible to identify spiral arms in HSC
    images even for galaxies with $i\sim 21$, allowing for morphological classification
    of galaxies at higher redshift. However, as such case are rare, the inclusion
    of fainter objects makes it difficult to identify a larger number of spiral galaxies
    for training CNNs. We therefore choose a magnitude cut of $i<20$ in this work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stars are removed in advance by the flag of i_extendedness_value in the HSC-SSP
    database. As most galaxies are observed in other four broad band filters ($grzy$),
    their photometric redshift is available, provided by the Direct Empirical Photometric
    code (DEmP: Hsieh & Yee [2014](#bib.bib27)). For galaxies with $i<20$, the photometric
    redshift error of $\Delta z=(z_{\mathrm{phot}}-z_{\mathrm{spec}})/(1+z_{\mathrm{spec}})$
    and the outlier fraction of $|\Delta z|>0.15$ is $\sigma_{\Delta z}=0.02$ and
    5–10%, respectively (Tanaka et al., [2018](#bib.bib56); Nishizawa et al., [2020](#bib.bib45)).
    We remove nearby galaxies with spectroscopic redshift of $z_{\mathrm{spec}}<0.05$,
    provided by VIPERS (Garilli et al., [2014](#bib.bib18)), SDSS (Alam et al., [2015](#bib.bib4)),
    Wiggle-Z (Drinkwater et al., [2010](#bib.bib16)), GAMA (Liske et al., [2015](#bib.bib40))
    and PRIMUS (Cool et al., [2013](#bib.bib10)), as the physical scale resolution
    becomes significantly different from that at $z>0.1$. Edge-on like objects with
    a major-to-minor axis ratio of less than 0.1 are also removed in advance because
    it is hard to distinguish between spirals and non-spirals.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a subsample of 56,787 galaxies with $i<20$ in the Wide XMM Large Scale
    Structure survey (XMM-LSS) field, the redshift and stellar mass distributions
    are shown in Figure [2](#S2.F2 "Figure 2 ‣ 2.1 Subaru Hyper Suprime Cam Data Sample
    ‣ 2 Data ‣ Spin Parity of Spiral Galaxies II: A catalogue of 80k spiral galaxies
    using big data from the Subaru Hyper Suprime-Cam Survey and deep learning"). The
    stellar mass is estimated from multi-wavelength photometry, empirically given
    by the DEmP code (Hsieh & Yee, [2014](#bib.bib27)). We also derive the completeness
    as functions of redshift and stellar mass by calculating the ratio of the number
    of galaxies with $i<20$ to the number of fainter galaxies with $i<22$. The stellar
    mass 90% completeness limits are $\log(M_{\star}/M_{\odot})\sim 10$ at $z=0.2$
    and $\log(M_{\star}/M_{\odot})\sim 11$ at $z=0.4$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We convert FITS images of galaxies to Joint Photographic Experts Group (JPEG)
    format by using STIFF software (Bertin, [2012](#bib.bib7)). We adopt GAMMA=2.2
    to automatically adjust the contrast and brightness of JPEG images for classification
    and slightly change this parameter for data augmentation (Section [2.2](#S2.SS2
    "2.2 Training data set ‣ 2 Data ‣ Spin Parity of Spiral Galaxies II: A catalogue
    of 80k spiral galaxies using big data from the Subaru Hyper Suprime-Cam Survey
    and deep learning")). Converting images to JPEG images could potentially loose
    information respect to the original FITS images. Optimization of the grayscale
    images is one of the key challenges for improving classification with deep learning,
    but is beyond the scope of our work. In this paper, we simply use JPEG images
    by following the previous works (e.g., Dieleman et al., [2015](#bib.bib12); Huertas-Company
    et al., [2015](#bib.bib28); Domínguez Sánchez et al., [2018](#bib.bib14); Abraham
    et al., [2018](#bib.bib1)). The size of post stamp images is 64 pixel $\times$
    64 pixel, covering 10.8 arcsec $\times$ 10.8 arcsec, where main spiral features
    are covered for most galaxies.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Although color composite images are often used for classifying galaxy morphology,
    we use monochromatic images in the $i$-band for two reasons. First, $i$-band observations
    are executed in the best observing conditions for cosmic shear measurements (Mandelbaum
    et al., [2018](#bib.bib41)). The median seeing is 0.6 arcsec in the $i$-band,
    corresponding to 1.1 kpc at $z=0.1$ and 2.1 kpc at $z=0.2$, while it is 0.7-0.8
    arcsec in other bands. Second, composite images have the information of galaxy
    colors as well as galaxy morphology. There is a strong correlation between color
    and morphology: blue galaxies tend to have a disk with spiral arms while red galaxies
    are ellipticals (e.g., Strateva et al., [2001](#bib.bib54)). Red spiral galaxies
    are likely to be an important population for understanding transitions from blue
    to red galaxies (Masters et al., [2010](#bib.bib43)) but the number density is
    smaller compared to blue spiral galaxies. If color information is taken into account,
    the trained models would tend to classify red galaxies into non-spirals rather
    than spirals. We therefore use $i$-band images to avoid the color bias and keep
    morphology information independent from colors.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Training data set
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5118c92f8675aa868e2f6533b3f0c183.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Examples of data augmentation. A FITS image of one galaxy is converted
    into multiple JPEG images with a different gray scale value, which is adjusted
    by the GAMMA parameter. The original images of S-spirals are horizontally flipped
    and are treated as Z-spiral images. Furthermore, these images are rotated by 90,
    180, 270 degrees.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We chose the XMM-LSS field (Pierre et al., [2004](#bib.bib49)) over an area
    of $\sim 28$ deg² to make a training data set for CNNs. Among 56,787 objects,
    we confirm 1,447 spiral galaxies with clear S-wise spiral structure and 1,382
    with clear Z-wise spiral structure by visual inspection. They are visually checked
    by all of the authors. Additional 1,177 and 1,131 galaxies are identified to have
    S-wise and Z-wise spiral structure with somewhat reduced confidence level. To
    define as clearly as possible spirals, we classify these galaxies into a category
    of unclear/dubious, which is not used for training CNNs. The remaining 51,650
    galaxies are non-spiral galaxies. In this work, we do not distinguish between
    mergers and non-mergers. Even if spiral galaxies are clearly affected by tidal
    interactions with their companions, they are categorized as S-spirals or Z-spirals.
    We show example images of randomly-selected 100 galaxies in each class from the
    training data set in Appendix [A](#A1 "Appendix A Some extra material ‣ Spin Parity
    of Spiral Galaxies II: A catalogue of 80k spiral galaxies using big data from
    the Subaru Hyper Suprime-Cam Survey and deep learning").'
  prefs: []
  type: TYPE_NORMAL
- en: 'We adopt a K-fold cross validation technique to evaluate the performance of
    CNN models. We randomly divide the original sample in each class into five subsets,
    which consist of 289 S-spirals, 276 Z-spirals, and 10,330 non-spirals. Four of
    them (1,156 S-spirals, 1,104 Z-spirals, and 41,320 non-spirals) are used for the
    training and the remaining one is used for validation. As the numbers of S-spirals
    and Z-spirals are much smaller than that of non-spirals, we augment the data of
    spiral galaxies. We add horizontally flipped images of Z-spirals and S-spirals
    to the S-spiral and Z-spiral classes, resulting in the same number in S-spirals
    and Z-spirals. Flipping spiral galaxies is also important for making an unbiased
    training dataset. When CNNs are trained by a sample biased to S-spirals, the trained
    model would naturally give more S-spirals than Z-spirals. We furthermore rotate
    the images by 90 degrees, 180 degrees and 270 degrees, and rescale the brightness
    of the images with GAMMA=2.0, 2.1, 2.3, 2.4 parameters (Figure [3](#S2.F3 "Figure
    3 ‣ 2.2 Training data set ‣ 2 Data ‣ Spin Parity of Spiral Galaxies II: A catalogue
    of 80k spiral galaxies using big data from the Subaru Hyper Suprime-Cam Survey
    and deep learning")). The data augmentation increases the number of spiral galaxies
    by 40 times and make the numbers of three classes similar. The training data set
    therefore contains images of 45,200 S-spirals, 45,200 Z-spirals and 41,320 non-spirals.
    We eventually make five different training data sets by selecting a different
    subset for validation.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Convolutional neural networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We make CNN models to classify galaxy morphology into non-spirals, S-spirals
    and Z-spirals in a similar way to previous works (e.g., Dieleman et al., [2015](#bib.bib12)).
    Table [1](#S3.T1 "Table 1 ‣ 3 Convolutional neural networks ‣ Spin Parity of Spiral
    Galaxies II: A catalogue of 80k spiral galaxies using big data from the Subaru
    Hyper Suprime-Cam Survey and deep learning") summarizes the configuration of the
    CNN used in this paper. The size of input images is 64 pixel $\times$ 64 pixel.
    There are four convolutional layers with kernel sizes of 5 pixel $\times$ 5 pixel,
    $5\times 5$, $3\times 3$ and $3\times 3$, respectively. The number of convolutional
    filters is 32, 64, 128, 128, respectively. Each filter generates a feature map.
    We add two pooling layers, which take the maximum value in 4 pixel $\times$ 4
    pixel and $2\times 2$. The maximum pooling efficiently extracts important features
    like edges as well as reduces the amount of information by resampling. After convolutional
    layers, 128 feature maps with 5 pixel $\times$ 5 pixel are flatten and fed into
    a fully-connected layer with 3200 features. These features are combined in dense
    layers. We also include three dropout layers to avoid overfitting of the CNNs
    (Srivastava et al., [2014](#bib.bib53)). In these layers, 20%, 50%, 50% of input
    units are randomly set to zero. The final layer uses the Softmax function, which
    is computed as'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $p_{i,c}=e^{s_{i,c}}/\sum_{c=1}^{3}e^{s_{i,c}},$ |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: where $s_{i,c}$ is the output score for the $c$-th category for morphology classification
    (non-spiral, S-spiral and Z-spiral) of the $i$-th image and $p_{i,c}$ corresponds
    to the predicted probabilities of each class. We eventually adopt the class with
    the highest probability to determine the morphology.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Structure of CNNs used in this paper'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | layer | output shape |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Input | (64 pix, 64 pix, 1 map) |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Convolution (5 pix $\times$ 5 pix) | (60 pix, 60 pix, 32 maps) |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Convolution (5 pix $\times$ 5 pix) | (56 pix, 56 pix, 64 maps) |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | MaxPooling (4 pix $\times$ 4 pix) | (14 pix, 14 pix, 64 maps) |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | Convolution (3 pix $\times$ 3 pix) | (12 pix, 12 pix, 128 maps) |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | Convolution (3 pix $\times$ 3 pix) | (10 pix, 10 pix, 128 maps) |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | MaxPooling (2 pix $\times$ 2 pix) | (5 pix, 5 pix, 128 maps) |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | Dropout | (5 pix, 5 pix, 128 maps) |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | Flatten | (3200 features) |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | Dense | (3200 features) |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | Dropout | (3200 features) |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | Dense | (3200 features) |'
  prefs: []
  type: TYPE_TB
- en: '| 13 | Dropout | (3200 features) |'
  prefs: []
  type: TYPE_TB
- en: '| 14 | Dense | (3 classes) |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/99833c342d91e392c6a32b02fecfec07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: The accuracy and the CE loss function for the training (black lines)
    and validation data set (red lines) for one of the six cross-validation tests.
    The blue horizontal line indicate the epoch when the validation loss is minimized.'
  prefs: []
  type: TYPE_NORMAL
- en: We train the CNNs using the Keras library (Chollet et al., [2015](#bib.bib8))
    with a single GPU, NVIDIA GeForce GTX 1080 Ti. A total of 20,769,539 trainable
    parameters of the model are determined by minimizing a loss function, which expresses
    inconsistency between actual classes and predicted probabilities (Krizhevsky &
    Inc, [2014](#bib.bib32)). We adopt a cross-entropy (CE) loss function defined
    as,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathrm{CE\ loss}=-\sum_{i=1}^{256}\sum_{c=1}^{3}t_{i,c}\log p_{i,c},$
    |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: 'where $t_{i,c}$ is the ground truth label (1 if true and 0 if false). We use
    Adam algorithm (Kingma & Ba, [2014](#bib.bib31)), which optimizes the parameters
    based on the gradient descent of the loss function with a subsample of 256 images
    randomly-selected from the training data set. This method is called the mini-batch
    stochastic gradient descent. One epoch ends with 33 seconds when the entire training
    data set has been used once for the calculation of the loss function. We repeat
    this 60 times and derive the accuracy, which is simply a ratio of correctly predicted
    images to all the images, and the CE loss in each epoch. The results of one CNN
    model are shown in Figure [4](#S3.F4 "Figure 4 ‣ 3 Convolutional neural networks
    ‣ Spin Parity of Spiral Galaxies II: A catalogue of 80k spiral galaxies using
    big data from the Subaru Hyper Suprime-Cam Survey and deep learning"). The training
    accuracy continues to increase to almost 100% while the validation accuracy saturates
    at about 20 epochs. The loss function takes the minimum at 32 epochs and turns
    to increase at the later epochs. As this is clearly overfitting the training data
    set, we adopt the CNN models where the validation loss is minimized. Other four
    CNN models reach the minimum at 29, 32, 41, and 28 epochs. The validation data
    set is not directly used for the training of CNNs, but indirectly affects the
    choice of the best model. We therefore compute the average accuracy of 5 CNN models
    from the cross-validation (see section [2.2](#S2.SS2 "2.2 Training data set ‣
    2 Data ‣ Spin Parity of Spiral Galaxies II: A catalogue of 80k spiral galaxies
    using big data from the Subaru Hyper Suprime-Cam Survey and deep learning")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: The fractions of images with the predicted class in each labeled class
    from the cross-validation.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Predicted class | Labeled class |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  | non-spiral | S-spiral | Z-spiral |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| non-spiral | 96.31$\pm$0.47% | 1.86$\pm$0.20% | 1.83$\pm$0.34% |'
  prefs: []
  type: TYPE_TB
- en: '| S-spiral | 1.71$\pm$0.17% | 98.12$\pm$0.24% | 0.16$\pm$0.10% |'
  prefs: []
  type: TYPE_TB
- en: '| Z-spiral | 1.90$\pm$0.22% | 0.19$\pm$0.13% | 97.91$\pm$0.34% |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/8f367489d94695a68ec96499f7246f9e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Examples of HSC images of misclassification in each class. From left
    to right in the bottom of each images, we show the predicted probabilities of
    non-spiral, S-spiral and Z-spiral.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/effe876c0129c3885ead303fd0af6966.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: The accuracy of the CNN models for the validation data set as a function
    of $i$-band magnitude, photometric redshift, FWHM size and major-to-minor axis
    ratio. A blue line shows the overall accuracy, 0.9748.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The average accuracy and standard deviation is 97.48$\pm$0.14%. For galaxy
    images with the predicted probability of $>$0.95, the accuracy is increased to
    99.37$\pm$0.10%. Note that the accuracy is different among the morphology classes.
    We show the confusion matrix, which is the fraction of correct or incorrect predictions
    in each predicted class, in Table [2](#S3.T2 "Table 2 ‣ 3 Convolutional neural
    networks ‣ Spin Parity of Spiral Galaxies II: A catalogue of 80k spiral galaxies
    using big data from the Subaru Hyper Suprime-Cam Survey and deep learning"). Most
    of the failures are for the case that non-spirals are misclassified as either
    S-spirals or Z-spirals and vice versa. The fraction that S-spirals (Z-spirals)
    are misclassified as Z-spirals (S-spirals) is only 0.2%.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For about 2.5% of the validation data set, the predicted class is different
    from the labeled one. Figure [5](#S3.F5 "Figure 5 ‣ 3 Convolutional neural networks
    ‣ Spin Parity of Spiral Galaxies II: A catalogue of 80k spiral galaxies using
    big data from the Subaru Hyper Suprime-Cam Survey and deep learning") shows examples
    of misclassification. Some objects have the second highest probability of 0.1–0.5
    in the labeled class while others are misclassified with the high probability
    of $>0.95$. Non-spirals with different predictions seem to have some substructures,
    suggesting that they potentially have spiral arms with low contrast. Edge-on galaxies
    seem to be often misclassified, compared to face-on ones. The accuracy in the
    validation data set depends on the major-to-minor axis, which can be interpreted
    as an inclination angle (Figure [6](#S3.F6 "Figure 6 ‣ 3 Convolutional neural
    networks ‣ Spin Parity of Spiral Galaxies II: A catalogue of 80k spiral galaxies
    using big data from the Subaru Hyper Suprime-Cam Survey and deep learning")).
    For galaxies with an axis ratio of $<0.2$, the accuracy decreases to 96%. This
    may be due to a lack of edge-on objects in the training data set as it becomes
    more difficult to identify spiral arms by visual inspection.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We evaluate the accuracy as a function of $i-$band magnitude, photometric redshift
    and FWHM size (Figure [6](#S3.F6 "Figure 6 ‣ 3 Convolutional neural networks ‣
    Spin Parity of Spiral Galaxies II: A catalogue of 80k spiral galaxies using big
    data from the Subaru Hyper Suprime-Cam Survey and deep learning")). There is also
    a weak trend that brighter objects are more correctly classified. On the other
    hand, the accuracy tends to be constant across a redshift range to $z\sim 0.5$.
    The FWHM size is estimated from Gaussian-weighted 2nd-order moment in the $i$-band
    images (Bernstein & Jarvis, [2002](#bib.bib6)). The moment is stored as i_sdssshape_shape11,22,12
    in the PDR2 database. We compute the determinant radius as $r_{\mathrm{det}}=($shape11
    $\times$ shape22 - shape12${}^{2})^{0.25}$. Under the assumption of Gaussian,
    we convert the radius to FWHM by applying $2\sqrt{2\ln 2}$. The high accuracy
    in compact galaxies with FWHM$\sim$1″is due to the fact that most galaxies are
    classified as non-spirals in the HSC images.'
  prefs: []
  type: TYPE_NORMAL
- en: We also look at how the sample size affects the performance of CNNs. We train
    CNNs by using images of randomly-selected 100, 200, 400 and 800 galaxies in each
    class and measure the accuracy of validation data. When only original images are
    used for training, the accuracy gradually increases from 52% at 100 to 90% at
    800. The data augmentation including horizontal flipping, rotation, and rescaling
    significantly improves the accuracy from 52% to 89% with the same training data
    set of 100 images. It requires at least 100 images to reach an accuracy of more
    than 90% with the data augmentation.
  prefs: []
  type: TYPE_NORMAL
- en: 4 A catalogue of spiral galaxies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Table 3: A spin parity Catalogue of spiral galaxies. Object ID is the same
    in the PDR-2 of the HSC-SSP for the Wide layer (Aihara et al., [2019](#bib.bib3)).
    $p_{0}$, $p_{1}$, and $p_{2}$ indicate the predicted probabilities of non-spirals,
    S-spirals and Z-spirals, respectively. The full table is available online.'
  prefs: []
  type: TYPE_NORMAL
- en: '| object ID | class flag^a | $p_{0}$ | $p_{1}$ | $p_{2}$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 40959011452899104 | 2 | 0.091 | 0.000 | 0.909 |'
  prefs: []
  type: TYPE_TB
- en: '| 40959011452899880 | 2 | 0.093 | 0.000 | 0.907 |'
  prefs: []
  type: TYPE_TB
- en: '| 40959011452901552 | 1 | 0.272 | 0.728 | 0.000 |'
  prefs: []
  type: TYPE_TB
- en: '| 40959015747870352 | 2 | 0.009 | 0.000 | 0.991 |'
  prefs: []
  type: TYPE_TB
- en: '| 40959015747871064 | 1 | 0.011 | 0.989 | 0.000 |'
  prefs: []
  type: TYPE_TB
- en: '| 40959020042835800 | 2 | 0.006 | 0.000 | 0.994 |'
  prefs: []
  type: TYPE_TB
- en: '| 40959020042837000 | 1 | 0.000 | 1.000 | 0.000 |'
  prefs: []
  type: TYPE_TB
- en: '| . | . | . | . | . |'
  prefs: []
  type: TYPE_TB
- en: '^aFlag: 1=S-spiral; 2=Z-spiral'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/20464888a0e8a07667c234f6c02382cb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: The fraction of S-spirals (red circles) and Z-spirals (blue circles)
    to all the galaxies as functions of $i$-band magnitude, photometric redshift,
    FWHM size and major-to-minor axis ratio (top four panels). The middle four panels
    and the bottom four panels show the number of spiral galaxies and the significance
    level of the number difference between S-spirals and Z-spirals, respectively.
    The error, $\Delta(N_{\mathrm{S}}-N_{\mathrm{Z}})$, takes into account both the
    Poisson error and the incompleteness of CNN-based classification.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we apply the trained CNN models to a large data set in other HSC-SSP fields,
    where 561,251 galaxy images are available over an area of $\sim$320 deg². We use
    5 CNN models made from the cross validation to derive average predicted probabilities
    of each class. We identify 37,917 S-spirals and 38,718 Z-spirals and provide the
    catalogue including the predicted probabilities in Table [3](#S4.T3 "Table 3 ‣
    4 A catalogue of spiral galaxies ‣ Spin Parity of Spiral Galaxies II: A catalogue
    of 80k spiral galaxies using big data from the Subaru Hyper Suprime-Cam Survey
    and deep learning"). The remaining 484,616 galaxies are non-spirals. The difference
    between the numbers of S-spirals and Z-spirals is $N_{\mathrm{S}}-N_{\mathrm{Z}}=-801$.
    The significance level of is 2.9$\sigma$ when only Poisson statistics is applied
    to estimate the uncertainties in the number of galaxy images (Gehrels, [1986](#bib.bib20)).
    However, the uncertainties on these numbers are likely to be dominated by misclassification
    of CNN-based classification, rather than Poisson errors. S-spirals and Z-spirals
    are in principle affected to the same degree by the contamination. In the validation
    data set, the fraction that S-spirals are misclassified as non-spirals is similar
    to the fraction that Z-spirals are misclassified as non-spirals while there are
    some variations (0.20%, 0.34%) between the CNN models (Table [2](#S3.T2 "Table
    2 ‣ 3 Convolutional neural networks ‣ Spin Parity of Spiral Galaxies II: A catalogue
    of 80k spiral galaxies using big data from the Subaru Hyper Suprime-Cam Survey
    and deep learning")). This is non-negligible because the vast majority of a half
    million galaxies is non-spirals. Considering the uncertainties in the misclassification,
    the error of the difference would be $\Delta(N_{\mathrm{S}}-N_{\mathrm{Z}})$=1,932,
    which is larger than the actual measurement. We also use 5 individual trained
    CNNs for classification of 561,251 images to calculate the average and the standard
    deviation of the numbers of spirals, $N_{\mathrm{S}}=38625\pm 1138$ and $N_{\mathrm{Z}}=39537\pm
    1479$, corresponding to the error of $\Delta(N_{\mathrm{S}}-N_{\mathrm{Z}})$=1866).
    A stable performance of 0.04% in misclassification is required so that the uncertainty
    is dominated by Poisson errors in the HSC imaging data. We would need to train
    the model with more validation data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We do not find a significant difference of the numbers between S-spirals and
    Z-spirals. On the other hand, there is a significant excess of S-spirals over
    Z-spirals in our training data set and in the Galaxy Zoo Catalogue (Land et al.,
    [2008](#bib.bib35); Lintott et al., [2008](#bib.bib38)). This is likely to be
    caused by a human selection bias (Hayes et al., [2017](#bib.bib24)). Visual inspection
    by human eyes may unconsciously select more S-spirals. We also calculate the significance
    level of the number difference between S-spirals and Z-spirals, $(N_{\mathrm{S}}-N_{\mathrm{Z}})/\Delta(N_{\mathrm{S}}-N_{\mathrm{Z}})$,
    in bins of $i-$band magnitude, photometric redshift, FWHM size and major-to-minor
    axis ratio (Figure [7](#S4.F7 "Figure 7 ‣ 4 A catalogue of spiral galaxies ‣ Spin
    Parity of Spiral Galaxies II: A catalogue of 80k spiral galaxies using big data
    from the Subaru Hyper Suprime-Cam Survey and deep learning")). We take into account
    the incompleteness of CNN-based classification (Table [2](#S3.T2 "Table 2 ‣ 3
    Convolutional neural networks ‣ Spin Parity of Spiral Galaxies II: A catalogue
    of 80k spiral galaxies using big data from the Subaru Hyper Suprime-Cam Survey
    and deep learning")) as well as the Poisson errors. We do not find a significant
    excess of S-spirals or Z-spirals with $|(N_{\mathrm{S}}-N_{\mathrm{Z}})|>3\Delta(N_{\mathrm{S}}-N_{\mathrm{Z}})$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The fraction of both spirals including S-spirals and Z-spirals to all the galaxies
    is 13.7% though it depends on galaxy properties. Note that we can identify only
    galaxies with visible spiral arms, depending on the sensitivity and spatial resolution
    of images used in the classification. In the Galaxy Zoo project, the fraction
    of galaxies with features such as spiral arms is 10% at $z=0.1$ and $\sim 0$%
    at $z=0.2$ (Willett et al., [2013](#bib.bib58)). In the deeper HSC images, spiral
    arms are visible in $\sim$20% of galaxies at $z=0.1-0.2$ (Figure [7](#S4.F7 "Figure
    7 ‣ 4 A catalogue of spiral galaxies ‣ Spin Parity of Spiral Galaxies II: A catalogue
    of 80k spiral galaxies using big data from the Subaru Hyper Suprime-Cam Survey
    and deep learning")). The measured fraction of spiral galaxies should be still
    a lower limit because more galaxies with fainter or lower contrast spiral arms
    can be identified in even deeper and higher-resolution images. We actually find
    that $\sim$50% of extended galaxies with FWHM$\sim$3 arcsec are classified as
    spirals since the HSC resolution is high enough to identify their spiral arms.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/cc6d469130c2a0100aeccad344d516ce.png)![Refer to caption](img/636693274a2c2eebb5d62d25fd922da4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Examples of HSC images of S-spirals (left) and Z-spirals (right)
    with the predicted probability of $>$0.95\. They are randomly selected from spectroscopically-confirmed
    galaxies at $z_{\mathrm{spec}}=0.2-0.3$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [8](#S4.F8 "Figure 8 ‣ 4 A catalogue of spiral galaxies ‣ Spin Parity
    of Spiral Galaxies II: A catalogue of 80k spiral galaxies using big data from
    the Subaru Hyper Suprime-Cam Survey and deep learning") presents examples of S-spirals
    and Z-spirals with a spectroscopic redshift of $z_{\mathrm{spec}}=0.2-0.3$. 48,576
    of 76,635 spiral galaxies are located at $z_{\mathrm{phot}}>0.2$, where we are
    not able to identify spiral arms with the SDSS images. The fraction of spiral
    galaxies decreases from 20% at $z_{\mathrm{phot}}=0.2$ to 10% at $z_{\mathrm{phot}}=0.6$.
    The redshift dependence is strongly affected by the cosmological dimming of the
    surface brightness, which decreases as $(1+z)^{-4}$. It becomes difficult to detect
    an extended substructure such as spiral arms in high-redshift galaxies. The magnitude
    dependence of the spiral fraction is coupled with the redshift dependence since
    faint sources tend to be at higher redshift. The decrease of spirals with a small
    axis ratio of $<0.2$ is likely to be caused by human bias since it becomes hard
    to visually identify spiral arms in edge-on galaxies.'
  prefs: []
  type: TYPE_NORMAL
- en: '2,524 galaxies are identified to have spiral arms at $z_{\mathrm{phot}}=0.5-0.7$
    in spite of the strong effect of the cosmological dimming. 1,455 of them have
    a stellar mass of $\log(M_{\star}/M_{\odot})>10.8$, which is similar to that of
    Andromeda (M31: Geehan et al. [2006](#bib.bib19)). The existence of spiral arms
    indicates that the galaxies are still forming stars. The majority of M31-mass
    galaxies have an early type morphology without spiral arms at $0<z<0.7$ and quench
    the star formation (Papovich et al., [2015](#bib.bib46)). The identified massive
    spiral galaxies are likely to be the progenitors of M31.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have developed a CNN model to classify galaxy morphology into three categories
    (S-spiral, Z-spiral, and non-spiral) by using images taken by the Subaru HSC survey.
    The superb image quality allows us to identify spiral arms in faint galaxies with
    $i\sim 20$ by visual inspection. We have used a total of 0.2 million images after
    data augmentation such as flipping, rescaling, and rotation for training the model.
    The trained model successfully classifies the test data set, which is not used
    for training and validation, and results in an accuracy of 97.5$\pm$0.1%. The
    accuracy decreases to $\sim$90% in the case that the training data set consists
    of less than 100 images in each class. This would become more of a problem when
    one finds rare objects.
  prefs: []
  type: TYPE_NORMAL
- en: We have applied the trained CNN model to 561,251 galaxy images over an area
    of $\sim$320 deg². Our automated classification efficiently picks up spiral galaxies
    and determines their winding direction of spiral arms, providing 37,917 S-spirals
    and 38,718 Z-spirals. We do not find a significant excess of S-spirals over Z-spirals,
    which is seen in the training data set and the Galaxy Zoo Catalogue. We have also
    identified 1,455 massive spiral galaxies with $\log(M_{\star}/M_{\odot})>10.8$
    at $z_{\mathrm{phot}}=0.5-0.7$, which are likely the progenitors of M31.
  prefs: []
  type: TYPE_NORMAL
- en: There are some limitations to our CNN-based classification. The criterion of
    spiral arms is defined by the training data set, which is selected by our visual
    inspection. Although we have used the sample of galaxies whose spiral arms are
    clearly seen for the training to minimize the contamination of non-spirals, the
    criterion of clear spirals is still somewhat ambiguous. The ambiguous definition
    is probably one of the reasons that 2.5% of the validation data set is misclassified.
    It would be important to make a clean training sample. Creating mock images from
    numerical simulations is one of several efficient methods to prepare a large data
    set for training models (e.g., Huertas-Company et al., [2018](#bib.bib29); Metcalf
    et al., [2019](#bib.bib44)). Another direction to define a repeatable class of
    morphology is an unsupervised learning approach, which does not require visually-classified
    training data sets (e.g., Hocking et al., [2018](#bib.bib26); Martin et al., [2019](#bib.bib42)).
    Nevertheless, our attempt already demonstrates that CNN is powerful for making
    a large sample of galaxies with particular substructures such as spiral arms from
    a large data-set and efficiently picking up rare objects such as massive spiral
    galaxies.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are very grateful to the referee for constructive suggestions to improve
    the paper. The Hyper Suprime-Cam (HSC) collaboration includes the astronomical
    communities of Japan and Taiwan, and Princeton University. The HSC instrumentation
    and software were developed by the National Astronomical Observatory of Japan
    (NAOJ), the Kavli Institute for the Physics and Mathematics of the Universe (Kavli
    IPMU), the University of Tokyo, the High Energy Accelerator Research Organization
    (KEK), the Academia Sinica Institute for Astronomy and Astrophysics in Taiwan
    (ASIAA), and Princeton University. Funding was contributed by the FIRST program
    from the Japanese Cabinet Office, the Ministry of Education, Culture, Sports,
    Science and Technology (MEXT), the Japan Society for the Promotion of Science
    (JSPS), Japan Science and Technology Agency (JST), the Toray Science Foundation,
    NAOJ, Kavli IPMU, KEK, ASIAA, and Princeton University.
  prefs: []
  type: TYPE_NORMAL
- en: This paper makes use of software developed for the Large Synoptic Survey Telescope.
    We thank the LSST Project for making their code available as free software at
    http://dm.lsst.org
  prefs: []
  type: TYPE_NORMAL
- en: This paper is based on data collected at the Subaru Telescope and retrieved
    from the HSC data archive system, which is operated by Subaru Telescope and Astronomy
    Data Center (ADC) at NAOJ. Data analysis was in part carried out with the cooperation
    of Center for Computational Astrophysics (CfCA), NAOJ.
  prefs: []
  type: TYPE_NORMAL
- en: The Pan-STARRS1 Surveys (PS1) and the PS1 public science archive have been made
    possible through contributions by the Institute for Astronomy, the University
    of Hawaii, the Pan-STARRS Project Office, the Max Planck Society and its participating
    institutes, the Max Planck Institute for Astronomy, Heidelberg, and the Max Planck
    Institute for Extraterrestrial Physics, Garching, The Johns Hopkins University,
    Durham University, the University of Edinburgh, the Queen’s University Belfast,
    the Harvard-Smithsonian Center for Astrophysics, the Las Cumbres Observatory Global
    Telescope Network Incorporated, the National Central University of Taiwan, the
    Space Telescope Science Institute, the National Aeronautics and Space Administration
    under grant No. NNX08AR22G issued through the Planetary Science Division of the
    NASA Science Mission Directorate, the National Science Foundation grant No. AST-1238877,
    the University of Maryland, Eotvos Lorand University (ELTE), the Los Alamos National
    Laboratory, and the Gordon and Betty Moore Foundation.
  prefs: []
  type: TYPE_NORMAL
- en: C.E.R acknowledges Anupreeta More for providing a tool for visual inspection
    of images.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Abraham et al. (2018) Abraham S., Aniyan A. K., Kembhavi A. K., Philip N. S.,
    Vaghmare K., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/sty627), [477, 894](https://ui.adsabs.harvard.edu/abs/2018MNRAS.477..894A)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aihara et al. (2018) Aihara H., et al., 2018, [PASJ](http://dx.doi.org/10.1093/pasj/psx066),
    [70, S4](https://ui.adsabs.harvard.edu/abs/2018PASJ...70S...4A)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aihara et al. (2019) Aihara H., et al., 2019, [PASJ](http://dx.doi.org/10.1093/pasj/psz103),
    [71, 114](https://ui.adsabs.harvard.edu/abs/2019PASJ...71..114A)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alam et al. (2015) Alam S., et al., 2015, [ApJS](http://dx.doi.org/10.1088/0067-0049/219/1/12),
    [219, 12](https://ui.adsabs.harvard.edu/abs/2015ApJS..219...12A)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baba et al. (2013) Baba J., Saitoh T. R., Wada K., 2013, [ApJ](http://dx.doi.org/10.1088/0004-637X/763/1/46),
    [763, 46](https://ui.adsabs.harvard.edu/abs/2013ApJ...763...46B)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bernstein & Jarvis (2002) Bernstein G. M., Jarvis M., 2002, [AJ](http://dx.doi.org/10.1086/338085),
    [123, 583](https://ui.adsabs.harvard.edu/abs/2002AJ....123..583B)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bertin (2012) Bertin E., 2012, in Ballester P., Egret D., Lorente N. P. F.,
    eds, Astronomical Society of the Pacific Conference Series Vol. 461, Astronomical
    Data Analysis Software and Systems XXI. p. 263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chollet et al. (2015) Chollet F., et al., 2015, Keras, [https://keras.io](https://keras.io)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conselice (2014) Conselice C. J., 2014, [ARA&A](http://dx.doi.org/10.1146/annurev-astro-081913-040037),
    [52, 291](https://ui.adsabs.harvard.edu/abs/2014ARA&A..52..291C)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cool et al. (2013) Cool R. J., et al., 2013, [ApJ](http://dx.doi.org/10.1088/0004-637X/767/2/118),
    [767, 118](https://ui.adsabs.harvard.edu/abs/2013ApJ...767..118C)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Davis & Hayes (2014) Davis D. R., Hayes W. B., 2014, [ApJ](http://dx.doi.org/10.1088/0004-637X/790/2/87),
    [790, 87](https://ui.adsabs.harvard.edu/abs/2014ApJ...790...87D)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dieleman et al. (2015) Dieleman S., Willett K. W., Dambre J., 2015, [MNRAS](http://dx.doi.org/10.1093/mnras/stv632),
    [450, 1441](https://ui.adsabs.harvard.edu/abs/2015MNRAS.450.1441D)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dobbs & Baba (2014) Dobbs C., Baba J., 2014, [Publ. Astron. Soc. Australia](http://dx.doi.org/10.1017/pasa.2014.31),
    [31, e035](https://ui.adsabs.harvard.edu/abs/2014PASA...31...35D)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Domínguez Sánchez et al. (2018) Domínguez Sánchez H., Huertas-Company M., Bernardi
    M., Tuccillo D., Fischer J. L., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/sty338),
    [476, 3661](https://ui.adsabs.harvard.edu/abs/2018MNRAS.476.3661D)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doroshkevich (1970) Doroshkevich A. G., 1970, [Astrophysics](http://dx.doi.org/10.1007/BF01001625),
    [6, 320](https://ui.adsabs.harvard.edu/abs/1970Ap......6..320D)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drinkwater et al. (2010) Drinkwater M. J., et al., 2010, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2009.15754.x),
    [401, 1429](https://ui.adsabs.harvard.edu/abs/2010MNRAS.401.1429D)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fukushima (1980) Fukushima K., 1980, Biological Cybernetics, 36, 193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Garilli et al. (2014) Garilli B., et al., 2014, [A&A](http://dx.doi.org/10.1051/0004-6361/201322790),
    [562, A23](https://ui.adsabs.harvard.edu/abs/2014A&A...562A..23G)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geehan et al. (2006) Geehan J. J., Fardal M. A., Babul A., Guhathakurta P.,
    2006, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2005.09863.x), [366, 996](https://ui.adsabs.harvard.edu/abs/2006MNRAS.366..996G)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gehrels (1986) Gehrels N., 1986, [ApJ](http://dx.doi.org/10.1086/164079), [303,
    336](https://ui.adsabs.harvard.edu/abs/1986ApJ...303..336G)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goldreich & Lynden-Bell (1965) Goldreich P., Lynden-Bell D., 1965, [MNRAS](http://dx.doi.org/10.1093/mnras/130.2.125),
    [130, 125](https://ui.adsabs.harvard.edu/abs/1965MNRAS.130..125G)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2014) Goodfellow I., Pouget-Abadie J., Mirza M., Xu B., Warde-Farley
    D., Ozair S., Courville A., Bengio Y., 2014, in Ghahramani Z., Welling M., Cortes
    C., Lawrence N. D., Weinberger K. Q., eds, , Advances in Neural Information Processing
    Systems 27. Curran Associates, Inc., pp 2672–2680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hart et al. (2017) Hart R. E., et al., 2017, [MNRAS](http://dx.doi.org/10.1093/mnras/stx2137),
    [472, 2263](https://ui.adsabs.harvard.edu/abs/2017MNRAS.472.2263H)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hayes et al. (2017) Hayes W. B., Davis D., Silva P., 2017, [MNRAS](http://dx.doi.org/10.1093/mnras/stw3290),
    [466, 3928](https://ui.adsabs.harvard.edu/abs/2017MNRAS.466.3928H)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2016) He K., Zhang X., Ren S., Sun J., 2016, in 2016 IEEE Conference
    on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June
    27-30, 2016\. pp 770–778, [doi:10.1109/CVPR.2016.90](http://dx.doi.org/10.1109/CVPR.2016.90)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hocking et al. (2018) Hocking A., Geach J. E., Sun Y., Davey N., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/stx2351),
    [473, 1108](https://ui.adsabs.harvard.edu/abs/2018MNRAS.473.1108H)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hsieh & Yee (2014) Hsieh B. C., Yee H. K. C., 2014, [ApJ](http://dx.doi.org/10.1088/0004-637X/792/2/102),
    [792, 102](https://ui.adsabs.harvard.edu/abs/2014ApJ...792..102H)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huertas-Company et al. (2015) Huertas-Company M., et al., 2015, [ApJS](http://dx.doi.org/10.1088/0067-0049/221/1/8),
    [221, 8](https://ui.adsabs.harvard.edu/abs/2015ApJS..221....8H)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huertas-Company et al. (2018) Huertas-Company M., et al., 2018, [ApJ](http://dx.doi.org/10.3847/1538-4357/aabfed),
    [858, 114](https://ui.adsabs.harvard.edu/abs/2018ApJ...858..114H)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iye et al. (2019) Iye M., Tadaki K.-i., Fukumoto H., 2019, [ApJ](http://dx.doi.org/10.3847/1538-4357/ab4a18),
    [886, 133](https://ui.adsabs.harvard.edu/abs/2019ApJ...886..133I)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kingma & Ba (2014) Kingma D. P., Ba J., 2014, arXiv preprint arXiv:1412.6980
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky & Inc (2014) Krizhevsky A., Inc G., 2014, Technical report, One weird
    trick for parallelizing convolutional neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky et al. (2012) Krizhevsky A., Sutskever I., Hinton G. E., 2012, in
    Pereira F., Burges C. J. C., Bottou L., Weinberger K. Q., eds, , Advances in Neural
    Information Processing Systems 25. Curran Associates, Inc., pp 1097–1105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kuminski & Shamir (2016) Kuminski E., Shamir L., 2016, [ApJS](http://dx.doi.org/10.3847/0067-0049/223/2/20),
    [223, 20](https://ui.adsabs.harvard.edu/abs/2016ApJS..223...20K)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Land et al. (2008) Land K., et al., 2008, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2008.13490.x),
    [388, 1686](https://ui.adsabs.harvard.edu/abs/2008MNRAS.388.1686L)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. (1998) LeCun Y., Bottou L., Bengio Y., Haffner P., 1998, [Proceedings
    of the IEEE](http://dx.doi.org/10.1109/5.726791), 86, 2278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin & Shu (1964) Lin C. C., Shu F. H., 1964, [ApJ](http://dx.doi.org/10.1086/147955),
    [140, 646](https://ui.adsabs.harvard.edu/abs/1964ApJ...140..646L)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lintott et al. (2008) Lintott C. J., et al., 2008, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2008.13689.x),
    [389, 1179](https://ui.adsabs.harvard.edu/abs/2008MNRAS.389.1179L)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lintott et al. (2011) Lintott C., et al., 2011, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2010.17432.x),
    [410, 166](https://ui.adsabs.harvard.edu/abs/2011MNRAS.410..166L)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liske et al. (2015) Liske J., et al., 2015, [MNRAS](http://dx.doi.org/10.1093/mnras/stv1436),
    [452, 2087](https://ui.adsabs.harvard.edu/abs/2015MNRAS.452.2087L)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mandelbaum et al. (2018) Mandelbaum R., et al., 2018, [PASJ](http://dx.doi.org/10.1093/pasj/psx130),
    [70, S25](https://ui.adsabs.harvard.edu/abs/2018PASJ...70S..25M)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Martin et al. (2019) Martin G., Kaviraj S., Hocking A., Read S. C., Geach J. E.,
    2019, arXiv e-prints, [p. arXiv:1909.10537](https://ui.adsabs.harvard.edu/abs/2019arXiv190910537M)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Masters et al. (2010) Masters K. L., et al., 2010, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2010.16503.x),
    [405, 783](https://ui.adsabs.harvard.edu/abs/2010MNRAS.405..783M)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metcalf et al. (2019) Metcalf R. B., et al., 2019, [A&A](http://dx.doi.org/10.1051/0004-6361/201832797),
    [625, A119](https://ui.adsabs.harvard.edu/abs/2019A&A...625A.119M)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nishizawa et al. (2020) Nishizawa A. J., Hsieh B.-C., Tanaka M., Takata T.,
    2020, arXiv e-prints, [p. arXiv:2003.01511](https://ui.adsabs.harvard.edu/abs/2020arXiv200301511N)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Papovich et al. (2015) Papovich C., et al., 2015, [ApJ](http://dx.doi.org/10.1088/0004-637X/803/1/26),
    [803, 26](https://ui.adsabs.harvard.edu/abs/2015ApJ...803...26P)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peebles (1969) Peebles P. J. E., 1969, [ApJ](http://dx.doi.org/10.1086/149876),
    [155, 393](https://ui.adsabs.harvard.edu/abs/1969ApJ...155..393P)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peng et al. (2010) Peng C. Y., Ho L. C., Impey C. D., Rix H.-W., 2010, [AJ](http://dx.doi.org/10.1088/0004-6256/139/6/2097),
    [139, 2097](https://ui.adsabs.harvard.edu/abs/2010AJ....139.2097P)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pierre et al. (2004) Pierre M., et al., 2004, [J. Cosmology Astropart. Phys.](http://dx.doi.org/10.1088/1475-7516/2004/09/011),
    [2004, 011](https://ui.adsabs.harvard.edu/abs/2004JCAP...09..011P)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Russakovsky et al. (2015) Russakovsky O., et al., 2015, [International Journal
    of Computer Vision (IJCV)](http://dx.doi.org/10.1007/s11263-015-0816-y), 115,
    211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schawinski et al. (2017) Schawinski K., Zhang C., Zhang H., Fowler L., Santhanam
    G. K., 2017, [MNRAS](http://dx.doi.org/10.1093/mnrasl/slx008), [467, L110](https://ui.adsabs.harvard.edu/abs/2017MNRAS.467L.110S)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shamir (2017) Shamir L., 2017, [Publ. Astron. Soc. Australia](http://dx.doi.org/10.1017/pasa.2017.40),
    [34, e044](https://ui.adsabs.harvard.edu/abs/2017PASA...34...44S)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Srivastava et al. (2014) Srivastava N., Hinton G., Krizhevsky A., Sutskever
    I., Salakhutdinov R., 2014, Journal of Machine Learning Research, 15, 1929
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strateva et al. (2001) Strateva I., et al., 2001, [AJ](http://dx.doi.org/10.1086/323301),
    [122, 1861](https://ui.adsabs.harvard.edu/abs/2001AJ....122.1861S)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sugai & Iye (1995) Sugai H., Iye M., 1995, [MNRAS](http://dx.doi.org/10.1093/mnras/276.1.327),
    [276, 327](https://ui.adsabs.harvard.edu/abs/1995MNRAS.276..327S)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tanaka et al. (2018) Tanaka M., et al., 2018, [PASJ](http://dx.doi.org/10.1093/pasj/psx077),
    [70, S9](https://ui.adsabs.harvard.edu/abs/2018PASJ...70S...9T)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: White (1984) White S. D. M., 1984, [ApJ](http://dx.doi.org/10.1086/162573),
    [286, 38](https://ui.adsabs.harvard.edu/abs/1984ApJ...286...38W)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Willett et al. (2013) Willett K. W., et al., 2013, [MNRAS](http://dx.doi.org/10.1093/mnras/stt1458),
    [435, 2835](https://ui.adsabs.harvard.edu/abs/2013MNRAS.435.2835W)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: York et al. (2000) York D. G., et al., 2000, [AJ](http://dx.doi.org/10.1086/301513),
    [120, 1579](https://ui.adsabs.harvard.edu/abs/2000AJ....120.1579Y)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Some extra material
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Figure [9](#A1.F9 "Figure 9 ‣ Appendix A Some extra material ‣ Spin Parity
    of Spiral Galaxies II: A catalogue of 80k spiral galaxies using big data from
    the Subaru Hyper Suprime-Cam Survey and deep learning") and Figure [10](#A1.F10
    "Figure 10 ‣ Appendix A Some extra material ‣ Spin Parity of Spiral Galaxies II:
    A catalogue of 80k spiral galaxies using big data from the Subaru Hyper Suprime-Cam
    Survey and deep learning"), we show example images of S-spirals and Z-spirals,
    which are randomly selected from the training data set. We use them for training
    a CNN model after data augmentation such as flipping, rescaling, and rotation
    of images.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f50ff5e58c8f1f510a89161a68a54da0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Example images of S-spirals.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/09ad880170727e960bd8ceb926c60762.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Example images of Z-spirals.'
  prefs: []
  type: TYPE_NORMAL
