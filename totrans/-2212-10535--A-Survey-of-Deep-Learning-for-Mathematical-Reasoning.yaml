- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:42:45'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2212.10535] A Survey of Deep Learning for Mathematical Reasoning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2212.10535](https://ar5iv.labs.arxiv.org/html/2212.10535)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Survey of Deep Learning for Mathematical Reasoning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pan Lu¹, Liang Qiu¹, Wenhao Yu², Sean Welleck^(3∗), Kai-Wei Chang^(1∗)
  prefs: []
  type: TYPE_NORMAL
- en: ¹UCLA, ²University of Notre Dame, ³University of Washington
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/lupantech/dl4math](https://github.com/lupantech/dl4math)'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Mathematical reasoning is a fundamental aspect of human intelligence and is
    applicable in various fields, including science, engineering, finance, and everyday
    life. The development of artificial intelligence (AI) systems capable of solving
    math problems and proving theorems in language has garnered significant interest
    in the fields of machine learning and natural language processing. For example,
    mathematics serves as a testbed for aspects of reasoning that are challenging
    for powerful deep learning models, driving new algorithmic and modeling advances.
    On the other hand, recent advances in large-scale neural language models have
    opened up new benchmarks and opportunities to use deep learning for mathematical
    reasoning. In this survey paper, we review the key tasks, datasets, and methods
    at the intersection of mathematical reasoning and deep learning over the past
    decade. We also evaluate existing benchmarks and methods, and discuss future research
    directions in this domain.
  prefs: []
  type: TYPE_NORMAL
- en: '^($*$)^($*$)footnotetext: denotes co-senior authors.'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: “The study of mathematics, like the Nile, begins in minuteness but ends in magnificence.”
  prefs: []
  type: TYPE_NORMAL
- en: — Charles Caleb Colton, English writer
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematical reasoning is a key aspect of human intelligence that enables us
    to comprehend and make decisions based on numerical data and language. It is applicable
    in various fields, including science, engineering, finance, and everyday life,
    and encompasses a range of abilities, from basic skills such as pattern recognition
    and numerical operations to more advanced skills like problem-solving, logical
    reasoning, and abstract thinking. The development of artificial intelligence (AI)
    systems capable of solving math problems and proving theorems in language has
    been a long-standing focus of research in the fields of machine learning and natural
    language processing (NLP), dating back to the 1960s Feigenbaum et al. ([1963](#bib.bib35));
    Bobrow ([1964](#bib.bib14)). In recent years, there has been a surge of interest
    in this area: for instance, the number of papers has grown from approximately
    10 in 2018 to 66 in 2022 (see [Figure 3](#A1.F3 "Figure 3 ‣ Appendix A Mathematical
    Reasoning Datasets ‣ A Survey of Deep Learning for Mathematical Reasoning") in
    the Appendix).'
  prefs: []
  type: TYPE_NORMAL
- en: As deep learning continues to revolutionize NLP tasks such as question answering
    and machine translation Sutskever et al. ([2014](#bib.bib168)); Devlin et al.
    ([2019](#bib.bib33)), it has also made significant strides in the field of mathematical
    reasoning Wang et al. ([2017](#bib.bib183)); Yang and Deng ([2019](#bib.bib203));
    Geva et al. ([2020](#bib.bib46)); Wei et al. ([2022](#bib.bib184)). However, despite
    the impressive capabilities of these models, there is still a lack of a clear
    taxonomy of the different types of mathematical reasoning tasks and the specific
    capabilities required of deep learning models to solve them.
  prefs: []
  type: TYPE_NORMAL
- en: Previous literature has been limited to the discussion of specific aspects,
    such as solving math word problems Bhattacharya ([2017](#bib.bib13)); Zhang et al.
    ([2019](#bib.bib209)); Ughade and Kumbhar ([2019](#bib.bib173)), representing
    numbers representation Thawani et al. ([2021](#bib.bib172)), or solving informal
    problems Meadows and Freitas ([2022](#bib.bib119)). Additionally, with the recent
    advancements in large language models like GPT-3 Brown et al. ([2020](#bib.bib15)),
    there is a growing need to understand the capabilities and limitations of these
    models in the context of mathematical reasoning. This is where a comprehensive
    survey of this rapidly advancing domain becomes crucial, as it can provide an
    overview of the current state and limitations of the field, and indicate further
    research areas.
  prefs: []
  type: TYPE_NORMAL
- en: '{forest}'
  prefs: []
  type: TYPE_NORMAL
- en: forked edges, for tree= grow=east, reversed=true, anchor=base west, parent anchor=east,
    child anchor=west, base=left, font=, rectangle, draw=hidden-black, rounded corners,
    align=left, minimum width=4em, edge+=darkgray, line width=1pt, s sep=3pt, inner
    xsep=2pt, inner ysep=3pt, line width=0.8pt, ver/.style=rotate=90, child anchor=north,
    parent anchor=south, anchor=center, , where level=1text width=6.2em,font=,, where
    level=2text width=10.5em,font=,, where level=3text width=13.5em,font=,, where
    level=4text width=12em,font=,, [ Deep Learning for Mathematical Reasoning, ver
    [ Tasks and
  prefs: []
  type: TYPE_NORMAL
- en: Datasets (§[2](#S2 "2 Mathematical Reasoning Tasks ‣ A Survey of Deep Learning
    for Mathematical Reasoning")) [ Math Word Problem
  prefs: []
  type: TYPE_NORMAL
- en: Solving (§[A.1](#A1.SS1 "A.1 Math Word Problem Solving ‣ Appendix A Mathematical
    Reasoning Datasets ‣ A Survey of Deep Learning for Mathematical Reasoning")) [
    Textual [ E.g., MathQA Amini et al. ([2019](#bib.bib4)), SVAMP Patel et al. ([2021](#bib.bib134))
    , leaf, text width=32em ] ] [ Multimodal [ E.g., IconQA Lu et al. ([2021b](#bib.bib116)),
    TabMWP Lu et al. ([2022b](#bib.bib115)) , leaf, text width=32em ] ] ] [ Theorem
    Proving (§[A.2](#A1.SS2 "A.2 Theorem Proving ‣ Appendix A Mathematical Reasoning
    Datasets ‣ A Survey of Deep Learning for Mathematical Reasoning")) [ Formal [
    E.g., CoqGym Yang and Deng ([2019](#bib.bib203)) , leaf, text width=32em ] ] [
    Informal [ E.g., NaturalProofs Welleck et al. ([2021](#bib.bib185)) , leaf, text
    width=32em ] ] [ Formal + Informal [ E.g., miniF2F+informal Jiang et al. ([2022a](#bib.bib66))
    , leaf, text width=32em ] ] ] [ Geometry Problem
  prefs: []
  type: TYPE_NORMAL
- en: Solving (§[A.3](#A1.SS3 "A.3 Geometry Problem Solving ‣ Appendix A Mathematical
    Reasoning Datasets ‣ A Survey of Deep Learning for Mathematical Reasoning")) [
    Without Annotations [ E.g., GEOS Seo et al. ([2015](#bib.bib162)), GEOS++ Sachan
    et al. ([2017](#bib.bib157)) , leaf, text width=32em ] ] [ With Annotations [
    E.g., Geometry3K Lu et al. ([2021a](#bib.bib112)), UniGeo Chen et al. ([2022a](#bib.bib19))
    , leaf, text width=32em ] ] ] [ Math Question
  prefs: []
  type: TYPE_NORMAL
- en: Answering (§[A.4](#A1.SS4 "A.4 Math Question Answering ‣ Appendix A Mathematical
    Reasoning Datasets ‣ A Survey of Deep Learning for Mathematical Reasoning")) [
    Single Benchmark [ E.g., DROP Dua et al. ([2019](#bib.bib34)), Mathematics Saxton
    et al. ([2020](#bib.bib159)) , leaf, text width=32em ] ] [ Unified Benchmark [
    E.g., Lila Mishra et al. ([2022a](#bib.bib125)), TheoremQA Chen et al. ([2023](#bib.bib23))
    , leaf, text width=32em ] ] ] [ Other Quantitative
  prefs: []
  type: TYPE_NORMAL
- en: Problems (§[A.5](#A1.SS5 "A.5 Other Quantitative Problems ‣ Appendix A Mathematical
    Reasoning Datasets ‣ A Survey of Deep Learning for Mathematical Reasoning")) [
    Diagram [ E.g., FigureQA Kahou et al. ([2018](#bib.bib72)), DVQA Kafle et al.
    ([2018](#bib.bib71)) , leaf, text width=32em ] ] [ Finance, [ E.g., ConvFinQA Chen
    et al. ([2022c](#bib.bib25)) , leaf, text width=32em ] ] [ Science [ E.g., ScienceQA Lu
    et al. ([2022a](#bib.bib113)) , leaf, text width=32em ] ] [ Programming [ E.g., P3 Schuster
    et al. ([2021](#bib.bib160)) , leaf, text width=32em ] ] ] ] [ Deep Learning
  prefs: []
  type: TYPE_NORMAL
- en: Methods [ Neural Networks (§[3](#S3 "3 Neural Networks for Mathematical Reasoning
    ‣ A Survey of Deep Learning for Mathematical Reasoning")) [ Seq2Seq-based (§[3.1](#S3.SS1
    "3.1 Seq2Seq-based Networks for Math ‣ 3 Neural Networks for Mathematical Reasoning
    ‣ A Survey of Deep Learning for Mathematical Reasoning")) [ E.g., DNS Wang et al.
    ([2017](#bib.bib183)), AnsRat Ling et al. ([2017](#bib.bib105)) , leaf, text width=32em
    ] ] [ Graph-based (§[3.2](#S3.SS2 "3.2 Graph-based Networks for Math ‣ 3 Neural
    Networks for Mathematical Reasoning ‣ A Survey of Deep Learning for Mathematical
    Reasoning")) [ E.g., GTS Xie and Sun ([2019](#bib.bib201)), Graph2Tree Li et al.
    ([2020b](#bib.bib96)) , leaf, text width=32em ] ] [ Attention-based (§[3.3](#S3.SS3
    "3.3 Attention-based Networks for Math ‣ 3 Neural Networks for Mathematical Reasoning
    ‣ A Survey of Deep Learning for Mathematical Reasoning")) [ E.g., Math-EN Wang
    et al. ([2018a](#bib.bib179)), GROUP-ATT Li et al. ([2019](#bib.bib93)) , leaf,
    text width=32em ] ] [ Other (§[3.4](#S3.SS4 "3.4 Other Neural Networks for Math
    ‣ 3 Neural Networks for Mathematical Reasoning ‣ A Survey of Deep Learning for
    Mathematical Reasoning")) [ E.g., CNNTP Loos et al. ([2017](#bib.bib111)), MathDQN Wang
    et al. ([2018b](#bib.bib180)) , leaf, text width=32em ] ] ] [ Pre-trained Language
  prefs: []
  type: TYPE_NORMAL
- en: Models (§[4](#S4 "4 Pre-trained Language Models for Mathematical Reasoning ‣
    A Survey of Deep Learning for Mathematical Reasoning")) [ Self-Supervised Learning
    (§[4.1](#S4.SS1 "4.1 Self-Supervised Learning for Math ‣ 4 Pre-trained Language
    Models for Mathematical Reasoning ‣ A Survey of Deep Learning for Mathematical
    Reasoning")) [ E.g., GenBERT Geva et al. ([2020](#bib.bib46)), Minerva Lewkowycz
    et al. ([2022](#bib.bib92)) , leaf, text width=32em ] ] [ Task-specific Fine-tuning
    (§[4.2](#S4.SS2 "4.2 Task-specific Fine-tuning for Math ‣ 4 Pre-trained Language
    Models for Mathematical Reasoning ‣ A Survey of Deep Learning for Mathematical
    Reasoning")) [ E.g., Scratchpad Nye et al. ([2021](#bib.bib132)), Bhaskara Mishra
    et al. ([2022a](#bib.bib125)) , leaf, text width=32em ] ] ] [ In-context Learning
    (§[5](#S5 "5 In-context Learning for Mathematical Reasoning ‣ A Survey of Deep
    Learning for Mathematical Reasoning")) [ Example Selection (§[5.1](#S5.SS1 "5.1
    In-context Example Selection ‣ 5 In-context Learning for Mathematical Reasoning
    ‣ A Survey of Deep Learning for Mathematical Reasoning")) [ E.g., Few-shot-CoT Wei
    et al. ([2022](#bib.bib184)), PromptPG Lu et al. ([2022b](#bib.bib115)) , leaf,
    text width=32em ] ] [ High-quality Chains (§[5.2](#S5.SS2 "5.2 High-quality Reasoning
    Chains ‣ 5 In-context Learning for Mathematical Reasoning ‣ A Survey of Deep Learning
    for Mathematical Reasoning")) [ E.g., Self-Consistency Wang et al. ([2023](#bib.bib182)),
    Least-to-most Zhou et al. ([2023](#bib.bib224)) , leaf, text width=32em ] ] ]
    ] ]
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1: Taxonomy of deep learning for mathematical reasoning. The associated
    tasks are elaborated in §[2](#S2 "2 Mathematical Reasoning Tasks ‣ A Survey of
    Deep Learning for Mathematical Reasoning"), with a comprehensive dataset list
    found in §[A](#A1 "Appendix A Mathematical Reasoning Datasets ‣ A Survey of Deep
    Learning for Mathematical Reasoning"). Deep learning methods are further discussed
    in §[3](#S3 "3 Neural Networks for Mathematical Reasoning ‣ A Survey of Deep Learning
    for Mathematical Reasoning"), §[4](#S4 "4 Pre-trained Language Models for Mathematical
    Reasoning ‣ A Survey of Deep Learning for Mathematical Reasoning"), and §[5](#S5
    "5 In-context Learning for Mathematical Reasoning ‣ A Survey of Deep Learning
    for Mathematical Reasoning").'
  prefs: []
  type: TYPE_NORMAL
- en: In this paper, we survey over 180 papers from the NLP and AI communities in
    the field of deep learning for mathematical reasoning. We study various types
    of mathematical reasoning problems, such as math word problems, theorem proving,
    geometry problem solving, math question answering, and other quantitative problems
    (§[2](#S2 "2 Mathematical Reasoning Tasks ‣ A Survey of Deep Learning for Mathematical
    Reasoning"), §[A](#A1 "Appendix A Mathematical Reasoning Datasets ‣ A Survey of
    Deep Learning for Mathematical Reasoning")). Additionally, we explore different
    deep learning architectures for mathematical reasoning, including neural networks
    (§[3](#S3 "3 Neural Networks for Mathematical Reasoning ‣ A Survey of Deep Learning
    for Mathematical Reasoning")), pre-trained language models (§[4](#S4 "4 Pre-trained
    Language Models for Mathematical Reasoning ‣ A Survey of Deep Learning for Mathematical
    Reasoning")), and recent in-context learning for large language models (§[5](#S5
    "5 In-context Learning for Mathematical Reasoning ‣ A Survey of Deep Learning
    for Mathematical Reasoning")).
  prefs: []
  type: TYPE_NORMAL
- en: We also analyze existing benchmarks and find that there is less focus on multi-modal
    and low-resource settings (§[6.1](#S6.SS1 "6.1 Analysis of Benchmarks ‣ 6 Discussion
    and Findings ‣ A Survey of Deep Learning for Mathematical Reasoning")). Our evidence-based
    studies suggest that current numeracy representations are insufficient and deep
    learning methods are inconsistent for mathematical reasoning (§[6.2](#S6.SS2 "6.2
    Analysis of Deep Learning Methods ‣ 6 Discussion and Findings ‣ A Survey of Deep
    Learning for Mathematical Reasoning")). Following this, we suggest future research
    directions related to generalization and robustness, trustworthy reasoning, learning
    from feedback, and multi-modal mathematical reasoning (§[7](#S7 "7 Future Work
    ‣ A Survey of Deep Learning for Mathematical Reasoning")).
  prefs: []
  type: TYPE_NORMAL
- en: 2 Mathematical Reasoning Tasks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we briefly introduce different tasks for mathematical reasoning.
    A detailed summary and discussion of commonly used datasets can be found in [Table 7](#A1.T7
    "Table 7 ‣ A.5 Other Quantitative Problems ‣ Appendix A Mathematical Reasoning
    Datasets ‣ A Survey of Deep Learning for Mathematical Reasoning") and Appendix
    [A](#A1 "Appendix A Mathematical Reasoning Datasets ‣ A Survey of Deep Learning
    for Mathematical Reasoning").
  prefs: []
  type: TYPE_NORMAL
- en: Math Word Problem Solving. Developing algorithms to automatically solve math
    word problems (MWPs) has been of interest to NLP researchers for decades Feigenbaum
    et al. ([1963](#bib.bib35)); Bobrow ([1964](#bib.bib14)). An example of a MWP
    is shown in [Table 1](#S2.T1 "Table 1 ‣ 2 Mathematical Reasoning Tasks ‣ A Survey
    of Deep Learning for Mathematical Reasoning"). A question involves four basic
    arithmetic operations with single or multiple operation steps. The challenge posed
    by MWPs lies in the need for language comprehension, semantic parsing, and the
    application of multiple mathematical reasoning skills.
  prefs: []
  type: TYPE_NORMAL
- en: '| Question: Bod has 2 apples and David has 5 apples. How many apples do they
    have in total? |'
  prefs: []
  type: TYPE_TB
- en: '| Rationale: $x=2+5$ |'
  prefs: []
  type: TYPE_TB
- en: '| Solution: $7$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: A typical math word problem.'
  prefs: []
  type: TYPE_NORMAL
- en: Theorem Proving. Automating theorem proving is a long-standing challenge in
    AI Newell et al. ([1957](#bib.bib130)); Feigenbaum et al. ([1963](#bib.bib35)).
    The problem is to demonstrate the truth of a mathematical claim (a theorem) through
    a sequence of logical arguments (a proof). Theorem proving tests various skills,
    such as choosing effective multi-step strategies, using background knowledge,
    and performing symbolic manipulations.
  prefs: []
  type: TYPE_NORMAL
- en: Geometry Problem Solving. Automated geometry problem solving (GPS) is also a
    long-standing mathematical reasoning task Gelernter et al. ([1960](#bib.bib45));
    Wen-Tsun ([1986](#bib.bib189)). As shown in [Figure 2](#S2.F2 "Figure 2 ‣ 2 Mathematical
    Reasoning Tasks ‣ A Survey of Deep Learning for Mathematical Reasoning"), a geometry
    problem consists of a textual description and a diagram. The multimodal inputs
    describe the entities, attributes, and relationships of geometric elements, and
    the goal is to find the numeric solution to an unknown variable.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/cddafec82f375b87429e154f1b320e98.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: An example of geometry problems.'
  prefs: []
  type: TYPE_NORMAL
- en: Math Question Answering. There is a wide range of question answering (QA) benchmarks
    that center around mathematical reasoning, which we refer to as math question
    answering (MathQA). For example, DROP Dua et al. ([2019](#bib.bib34)) is a MathQA
    dataset that requires discrete reasoning to answer questions such as “Which kicker
    kicked the most field goals?” over the content of paragraphs.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Neural Networks for Mathematical Reasoning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Neural networks have become a popular tool in the field of mathematical reasoning,
    mirroring their success in NLP. In recent years, a number of different neural
    network architectures have been proposed for mathematical reasoning tasks, including
    Seq2Seq-based networks, graph-based networks, and attention-based networks. These
    methods are outlined in more detail in [Table 8](#A1.T8 "Table 8 ‣ A.5 Other Quantitative
    Problems ‣ Appendix A Mathematical Reasoning Datasets ‣ A Survey of Deep Learning
    for Mathematical Reasoning") in the Appendix.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Seq2Seq-based Networks for Math
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Sequence-to-sequence (Seq2Seq) Sutskever et al. ([2014](#bib.bib168)) neural
    networks have been successfully applied to mathematical reasoning tasks, such
    as math word problem solving Wang et al. ([2017](#bib.bib183)), theorem proving
     Yang and Deng ([2019](#bib.bib203)), geometry problem solving Robaidek et al.
    ([2018](#bib.bib151)), and math question answering Tafjord et al. ([2019](#bib.bib169)).
    A Seq2Seq model uses an encoder-decoder architecture and usually formalizes mathematical
    reasoning as a sequence generation task. The basic idea behind this approach is
    to map an input sequence (e.g. a mathematical problem) to an output sequence (e.g.
    an equation, program, and proof). Common encoders and decoders include Long Short
    Term Memory network (LSTM) Hochreiter and Schmidhuber ([1997](#bib.bib58)), Gated
    Recurrent Unit (GRU) Cho et al. ([2014](#bib.bib28)), and their bidirectional
    variants: BiLSTM and BiGRU. A large amount of work has shown the performance advantage
    of Seq2Seq models over previous statistical learning approaches Ling et al. ([2017](#bib.bib105));
    Wang et al. ([2018a](#bib.bib179)); Huang et al. ([2018](#bib.bib63)); Wang et al.
    ([2019](#bib.bib181)); Li et al. ([2019](#bib.bib93)).'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Graph-based Networks for Math
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Seq2Seq approaches show their advantages of generating mathematical expressions
    without relying on hand-crafted features. It is noteworthy that mathematical expressions
    can be represented as tree-based structures, such as abstract syntax trees (ASTs)
    and graph-based structures, which capture the structural information in the expressions.
    However, Seq2Seq methods do not explicitly this important information. To address
    this limitation, graph-based neural networks have been developed to explicitly
    model the structure within expressions. Sequence-to-tree (Seq2Tree) models explicitly
    model the tree structure when encoding the output sequences Xie and Sun ([2019](#bib.bib201));
    Wu et al. ([2020](#bib.bib192)); Zaporojets et al. ([2021](#bib.bib208)); Qin
    et al. ([2021](#bib.bib139)). For example,  Liu et al. ([2019a](#bib.bib109))
    devise a Seq2Tree model to better use information from an equation’s AST. Seq2DAG
    Cao et al. ([2021](#bib.bib17)), instead, applies a sequence-to-graph (Seq2Graph)
    framework when generating the equations since the graph decoder is able to extract
    complex relationships among multiple variables. The graph-based information can
    also be embedded when encoding the input mathematical sequences Zhang et al. ([2020b](#bib.bib211));
    Shen and Jin ([2020](#bib.bib164)); Li et al. ([2020b](#bib.bib96)); Wu et al.
    ([2021a](#bib.bib193)).
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Attention-based Networks for Math
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The attention mechanism has been successfully applied to NLP Bahdanau et al.
    ([2015](#bib.bib9)) and vision problems Xu et al. ([2015](#bib.bib202)); Woo et al.
    ([2018](#bib.bib191)), taking into account the hidden vectors of the inputs during
    the decoding processing. Recently, researchers have been exploring its usefulness
    in mathematical reasoning tasks, as it can be used to identify the most important
    relationships between mathematical concepts. For instance, MATH-EN Wang et al.
    ([2018a](#bib.bib179)) is a math word problem solver which benefits from long-distance
    dependency information learned by self-attention. Attention-based methods have
    also been applied to other mathematical reasoning tasks such as geometry problems
    solving Robaidek et al. ([2018](#bib.bib151)); Chen et al. ([2021a](#bib.bib20))
    and theorem proving Yang and Deng ([2019](#bib.bib203)). Various attention mechanisms
    have been studied to extract better representations, such as Group-ATT Li et al.
    ([2019](#bib.bib93)) which uses different multi-head attention to extract various
    types of MWP features, and graph attention which is applied to extract knowledge-aware
    information in Wu et al. ([2020](#bib.bib192)).
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Other Neural Networks for Math
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deep learning approaches to mathematical reasoning tasks can also make use of
    other neural networks, such as convolutional neural networks (CNN) and multimodal
    networks. Some work encodes the input text using a convolutional neural network
    architecture, giving the model the ability to capture long-term relationships
    between symbols in the input Gehring et al. ([2017](#bib.bib44)); Wang et al.
    ([2018a](#bib.bib179), [a](#bib.bib179)); Robaidek et al. ([2018](#bib.bib151));
    Alemi et al. ([2016](#bib.bib1)); Loos et al. ([2017](#bib.bib111)). For example,
    the first application of deep neural networks for theorem proving is proposed
    in Alemi et al. ([2016](#bib.bib1)), which relies on convolutional networks for
    premise selection.
  prefs: []
  type: TYPE_NORMAL
- en: Multimodal mathematical reasoning tasks, such as geometry problem solving and
    diagram-based mathematical reasoning, are formalized as visual question answer
    (VQA) problems Kafle et al. ([2018](#bib.bib71)); Chen et al. ([2021a](#bib.bib20));
    Lu et al. ([2021b](#bib.bib116)). In this domain, visual inputs are encoded using
    ResNet He et al. ([2016](#bib.bib53)) or Faster-RCNN Ren et al. ([2015](#bib.bib149)),
    while textual representations are obtained via GRU or LTSM. Subsequently, the
    joint representation is learned using multimodal fusion models, such as BAN Kim
    et al. ([2018](#bib.bib79)), FiLM Perez et al. ([2018](#bib.bib136)), and DAFA
    Gao et al. ([2019](#bib.bib42)).
  prefs: []
  type: TYPE_NORMAL
- en: Other deep neural network structures can also be used in mathematical reasoning.
    A Graph Neural Network (GNN) is employed for geometry problem parsing in Zhang
    et al. ([2022](#bib.bib212)), taking advantage of its success in spatial reasoning.
    WaveNet has been applied to theorem proving Loos et al. ([2017](#bib.bib111));
    Bansal et al. ([2019](#bib.bib10)), due to its ability to address longitudinal
    time-series data. Furthermore, Transformers are found to outperform GRU in generating
    mathematical equations in DDT Meng and Rumshisky ([2019](#bib.bib121)). Finally,
    MathDQN Wang et al. ([2018b](#bib.bib180)) is the first work to explore reinforcement
    learning for math word problem solving, taking advantage of its strong search
    capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Pre-trained Language Models for Mathematical Reasoning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Paper | Backbone | Size | Corpus | Pre-training task |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-f Polu and Sutskever ([2020](#bib.bib138)) | Transformer ([2017](#bib.bib177))
    | 774M | Math | Causal language modeling |'
  prefs: []
  type: TYPE_TB
- en: '| LISA Jiang et al. ([2021](#bib.bib67)) | Transformer ([2017](#bib.bib177))
    | 163M | Math | Causal language modeling |'
  prefs: []
  type: TYPE_TB
- en: '| MATH-PLM Hendrycks et al. ([2021b](#bib.bib55)) | GPT-2 ([2020](#bib.bib144))
    | 1.5B | Math | Causal language modeling |'
  prefs: []
  type: TYPE_TB
- en: '| MWP-BERT Liang et al. ([2022b](#bib.bib102)) | RoBERTa ([2019b](#bib.bib110))
    | 123M | Math | 8 numeracy augmented tasks |'
  prefs: []
  type: TYPE_TB
- en: '| TaPEx Liu et al. ([2022b](#bib.bib107)) | BART ([2020](#bib.bib91)) | 406M
    | SQL | Query result generation |'
  prefs: []
  type: TYPE_TB
- en: '| HTPS Lample et al. ([2022](#bib.bib87)) | Transformer ([2017](#bib.bib177))
    | 600M | Math | Masked Seq2Seq modeling |'
  prefs: []
  type: TYPE_TB
- en: '| Thor Jiang et al. ([2022b](#bib.bib68)) | Transformer ([2017](#bib.bib177))
    | 700M | Github, arXiv | Causal language modeling |'
  prefs: []
  type: TYPE_TB
- en: '| PACT Han et al. ([2022](#bib.bib51)) | Transformer ([2017](#bib.bib177))
    | 837M | Math | Masked/Causal language modeling |'
  prefs: []
  type: TYPE_TB
- en: '| Minerva Lewkowycz et al. ([2022](#bib.bib92)) | PaLM ([2022](#bib.bib30))
    | 540B | Science & Math | Causal language modeling |'
  prefs: []
  type: TYPE_TB
- en: '| GenBERT Geva et al. ([2020](#bib.bib46)) | BERT ([2019](#bib.bib33)) | 110M
    | Number, Text | Masked/Causal language modeling |'
  prefs: []
  type: TYPE_TB
- en: '| NF-NSM Feng et al. ([2021](#bib.bib36)) | RoBERTa ([2019b](#bib.bib110))
    | 110M | Number | Number prediction |'
  prefs: []
  type: TYPE_TB
- en: '| LIME Wu et al. ([2021d](#bib.bib200)) | Transformer ([2017](#bib.bib177))
    | 11B | Math | Causal language modeling |'
  prefs: []
  type: TYPE_TB
- en: '| Set Wu et al. ([2022c](#bib.bib199)) | T5 ([2020](#bib.bib146)) | 60M | Math
    | Unique token generation |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Comparison of pre-training language models for mathematical reasoning.'
  prefs: []
  type: TYPE_NORMAL
- en: Pre-trained language models Devlin et al. ([2019](#bib.bib33)); Radford et al.
    ([2020](#bib.bib144)); Brown et al. ([2020](#bib.bib15)) have demonstrated remarkable
    performance gains on a wide range of NLP tasks. By pre-training on a large corpus
    of text, the models learn valuable world knowledge Guu et al. ([2020](#bib.bib50)),
    which could be applied to downstream tasks. Similar ideas can be applied to math-related
    problems, and previous work has shown the promising performance of pre-trained
    language models in answering math word problems Kim et al. ([2020](#bib.bib78)),
    assisting with theorem proving Wu et al. ([2022b](#bib.bib198)), as well as solving
    other mathematical tasks Charton ([2022](#bib.bib18)).
  prefs: []
  type: TYPE_NORMAL
- en: However, though large language models excel in modeling natural language, there
    are several challenges to using them for mathematical reasoning. First, pre-trained
    language models are not specifically trained on mathematical data. This likely
    contributes to them being less proficient in math-related tasks compared to natural
    language tasks. There is also less mathematical or scientific data available for
    large-scale pre-training compared to text data. Second, the size of pre-trained
    models continues to grow, making it expensive to train the entire model from scratch
    for specific downstream tasks. Additionally, downstream tasks may deal with different
    input formats or modalities, such as structured tables Zhao et al. ([2022](#bib.bib220))
    or diagrams Lu et al. ([2021b](#bib.bib116)). To address these challenges, researchers
    have to adjust pre-trained models by finetuning them on downstream tasks or adapting
    the neural architectures.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Self-Supervised Learning for Math
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Self-supervised learning is a machine learning approach in which an algorithm
    learns to perform a task without being explicitly provided with labeled training
    data. [Table 2](#S4.T2 "Table 2 ‣ 4 Pre-trained Language Models for Mathematical
    Reasoning ‣ A Survey of Deep Learning for Mathematical Reasoning") provides a
    list of language models pre-trained with self-supervised tasks for mathematical
    reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Model scale. There is a clear trend that pre-trained language models have become
    increasingly larger in the past few years Devlin et al. ([2019](#bib.bib33));
    Lewis et al. ([2020](#bib.bib91)); Raffel et al. ([2020](#bib.bib146)); Radford
    et al. ([2020](#bib.bib144)); Brown et al. ([2020](#bib.bib15)). A recent study Liang
    et al. ([2022a](#bib.bib100)) shows that model scale within a model family reliably
    predicts model accuracy. The study also mentions an interesting thresholding effect:
    “all models that win head-to-head model comparisons for accuracy at a rate well
    above chance are at least 50B parameters”. A similar size-growing trend can be
    observed in the field of mathematical reasoning with pre-trained language models.
    For example, MWP-BERT Liang et al. ([2022b](#bib.bib102)) uses a backbone of BERT
    (110M) Devlin et al. ([2019](#bib.bib33)) and RoBERTa (123M) Liu et al. ([2019b](#bib.bib110))
    for Math Word Problems. Most recently, Minerva Lewkowycz et al. ([2022](#bib.bib92)),
    which is based on the PaLM Chowdhery et al. ([2022](#bib.bib30)) pre-trained language
    model, has a size up to 540B parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: Pre-training corpus. There are generally two types of pre-training corpus for
    mathematical language models. (i) Curated datasets from openly accessible sources.
    For example, Hendrycks et al. ([2021b](#bib.bib55)) present the first large-scale
    mathematics pre-training dataset with step-by-step solutions in natural language
    and LaTeX, called the Auxiliary Mathematics Problems and Solutions (AMPS). AMPS
    consists of Khan Academy and Mathematica data. Minerva Lewkowycz et al. ([2022](#bib.bib92))
    collects a high-quality dataset containing scientific and mathematical data, which
    contains 38.5B tokens from webpages filtered for mathematical content and from
    papers submitted to the arXiv preprint server. Thor Jiang et al. ([2022b](#bib.bib68))
    pre-trains a language model on the GitHub + arXiv subsets of The Pile Gao et al.
    ([2020](#bib.bib40)). (ii) Synthetic datasets based on templates or interaction
    with engines. Recent work Wu et al. ([2021d](#bib.bib200)); Krishna et al. ([2021](#bib.bib84));
    Ri and Tsuruoka ([2022](#bib.bib150)); Anderson and Farrell ([2022](#bib.bib5));
    Wu et al. ([2022c](#bib.bib199)) shows that pre-training on data that is fully
    synthetically generated—synthetic pre-training can actually provide substantial
    gains. Representative work includes TaPEX Liu et al. ([2022b](#bib.bib107)), which
    obtains a pre-training corpus by automatically synthesizing executable SQL queries
    and their execution outputs. LISA Jiang et al. ([2021](#bib.bib67)) extracts lemmas
    and theorems by interacting with the Isabelle standard library and the Archive
    of Formal Proofs. GenBERT Geva et al. ([2020](#bib.bib46)) generates numerical
    and textual pre-training datasets based on manually crafted and extracted templates.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pre-training tasks. General pre-training language models have two typical self-supervised
    learning tasks: (i) Masked Language Modeling (MLM), where it randomly masks a
    portion of words in each sequence to predict the outcome; (ii) Causal Language
    Modeling (CLM), where the model is trained to predict the next token in a sequence
    of tokens. Following the same paradigm, researchers pre-train language models
    with MLM and CLM tasks on mathematical or scientific corpora for downstream tasks Polu
    and Sutskever ([2020](#bib.bib138)); Hendrycks et al. ([2021b](#bib.bib55)); Han
    et al. ([2022](#bib.bib51)); Jiang et al. ([2022b](#bib.bib68)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is also recent work that designs customized tasks to inject mathematical
    reasoning capabilities into language models. For instance, Liang et al. ([2022b](#bib.bib102))
    pre-train language models with a suite of 8 numeracy-augmented tasks with consideration
    of reasoning logic and numerical properties. LIME Wu et al. ([2021d](#bib.bib200))
    proposes synthetic pre-training tasks to learn three reasoning primitives: deduction,
    induction, and abduction before learning more complex reasoning skills, which
    also be regarded as a form of curriculum learning.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Paper | Backbone | Task |'
  prefs: []
  type: TYPE_TB
- en: '| EPT ([2020](#bib.bib78)) | ALBERT ([2019](#bib.bib89)) | MWP |'
  prefs: []
  type: TYPE_TB
- en: '| Generate & Rank ([2021](#bib.bib163)) | BART ([2020](#bib.bib91)) | MWP |'
  prefs: []
  type: TYPE_TB
- en: '| RPKHS ([2021b](#bib.bib206)) | RoBERTa ([2019b](#bib.bib110)) | MWP |'
  prefs: []
  type: TYPE_TB
- en: '| PatchTRM ([2021b](#bib.bib116)) | ResNet+BERT ([2019](#bib.bib33)) | MWP
    |'
  prefs: []
  type: TYPE_TB
- en: '| GSM8K-PLM ([2021](#bib.bib32)) | GPT-3 ([2020](#bib.bib15)) | MWP |'
  prefs: []
  type: TYPE_TB
- en: '| BERT-TD+CL ([2022b](#bib.bib99)) | BERT ([2019](#bib.bib33)) | MWP |'
  prefs: []
  type: TYPE_TB
- en: '| DeductReasoner ([2022](#bib.bib69)) | RoBERTa ([2019b](#bib.bib110)) | MWP
    |'
  prefs: []
  type: TYPE_TB
- en: '| Self-Sampling ([2023](#bib.bib131)) | GPT-Neo ([2020](#bib.bib40)) | MWP
    |'
  prefs: []
  type: TYPE_TB
- en: '| Bhaskara ([2022a](#bib.bib125)) | GPT-Neo ([2020](#bib.bib40)) | MWP |'
  prefs: []
  type: TYPE_TB
- en: '| miniF2F-PLM ([2022](#bib.bib222)) | GPT-f ([2020](#bib.bib138)) | TP |'
  prefs: []
  type: TYPE_TB
- en: '| NaturalProver ([2022a](#bib.bib186)) | GPT-3 ([2020](#bib.bib15)) | TP |'
  prefs: []
  type: TYPE_TB
- en: '| Inter-GPS ([2021a](#bib.bib112)) | BART ([2020](#bib.bib91)) | GPS |'
  prefs: []
  type: TYPE_TB
- en: '| UniGeo ([2022a](#bib.bib19)) | VL-T5 ([2021](#bib.bib27)) | GPS |'
  prefs: []
  type: TYPE_TB
- en: '| DPE-NGS ([2022](#bib.bib16)) | RoBERTa ([2019b](#bib.bib110)) | GPS |'
  prefs: []
  type: TYPE_TB
- en: '| Aristo ([2020](#bib.bib31)) | RoBERTa ([2019b](#bib.bib110)) | MathQA |'
  prefs: []
  type: TYPE_TB
- en: '| FinQANet ([2021c](#bib.bib24)) | RoBERTa ([2019b](#bib.bib110)) | MathQA
    |'
  prefs: []
  type: TYPE_TB
- en: '| TAGOP ([2021](#bib.bib225)) | RoBERTa ([2019b](#bib.bib110)) | MathQA |'
  prefs: []
  type: TYPE_TB
- en: '| MT2Net ([2022](#bib.bib220)) | RoBERTa ([2019b](#bib.bib110)) | MathQA |'
  prefs: []
  type: TYPE_TB
- en: '| Scratchpad ([2021](#bib.bib132)) | Transformer ([2017](#bib.bib177)) | Mixed
    |'
  prefs: []
  type: TYPE_TB
- en: '| LAMT ([2022](#bib.bib18)) | Transformer ([2017](#bib.bib177)) | Mixed |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: Finetuned pre-trained language models for downstream mathematical
    reasoning tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Task-specific Fine-tuning for Math
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Task-specific fine-tuning is a technique to improve the performance of a pre-trained
    language model on a specific task. This is also a common practice when there is
    not enough data for training the large models from scratch. As shown in [Table 3](#S4.T3
    "Table 3 ‣ 4.1 Self-Supervised Learning for Math ‣ 4 Pre-trained Language Models
    for Mathematical Reasoning ‣ A Survey of Deep Learning for Mathematical Reasoning"),
    existing work fine-tunes pre-trained language models on a variety of downstream
    tasks, such as math word problems Kim et al. ([2020](#bib.bib78)); Shen et al.
    ([2021](#bib.bib163)), MathQA Zhao et al. ([2022](#bib.bib220)), geometry problem
    solving Lu et al. ([2021a](#bib.bib112)), linear algebra Charton ([2022](#bib.bib18)),
    and theorem proving Welleck et al. ([2022a](#bib.bib186)). Apart from fine-tuning
    the model parameters, some work also uses pre-trained language models as encoders
    and ensembles them with other modules for downstream tasks Lu et al. ([2021b](#bib.bib116)).
  prefs: []
  type: TYPE_NORMAL
- en: 5 In-context Learning for Mathematical Reasoning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Models | Engine | ICL | Rationale | Rationale | Post method |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| (best performed) | source | type | source |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Few-shot-CoT Wei et al. ([2022](#bib.bib184)) | PaLM (540B) | Random | Language
    | Hand-crafted | - |'
  prefs: []
  type: TYPE_TB
- en: '| Self-Consistency-CoT Wang et al. ([2023](#bib.bib182)) | Codex (175B) | Random
    | Language | Hand-crafted | Self-consistency |'
  prefs: []
  type: TYPE_TB
- en: '| Least-to-most CoT Zhou et al. ([2023](#bib.bib224)) | Codex (175B) | Random
    | Language | Hand-crafted | - |'
  prefs: []
  type: TYPE_TB
- en: '| PromptPG-CoT Lu et al. ([2022b](#bib.bib115)) | GPT-3 (175B) | RL | Language
    | Hand-crafted | - |'
  prefs: []
  type: TYPE_TB
- en: '| Retrieval-CoT Zhang et al. ([2023](#bib.bib218)) | GPT-3 (175B) | Retrival
    | Language | Auto-generated | - |'
  prefs: []
  type: TYPE_TB
- en: '| Auto-CoT Zhang et al. ([2023](#bib.bib218)) | Codex (175B) | Clustering |
    Language | Auto-generated | - |'
  prefs: []
  type: TYPE_TB
- en: '| Complexity-CoT Fu et al. ([2023](#bib.bib39)) | GPT-3 (175B) | Complexity
    | Language | Hand-crafted | Self-consistency |'
  prefs: []
  type: TYPE_TB
- en: '| Few-shot-PoT Chen et al. ([2022b](#bib.bib22)) | GPT-3 (175B) | Random |
    Code | Hand-crafted | - |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: In-context learning with large language models for mathematical reasoning.
    For GPT-3, all papers use the $\mathrm{text}$-$\mathrm{davinci}$-$\mathrm{002}$
    version; for Codex, all papers use the $\mathrm{code}$-$\mathrm{davinci}$-$\mathrm{002}$.
    RL is short for reinforcement learning.'
  prefs: []
  type: TYPE_NORMAL
- en: Large language models (LLMs), such as GPT-3 (Brown et al., [2020](#bib.bib15)),
    have recently revolutionized the field of natural language processing (NLP), especially
    on account of their powerful few-shot in-context learning capabilities Brown et al.
    ([2020](#bib.bib15)). In-context Learning (ICL) enables LLMs to perform target
    tasks by providing some task examples as conditions at inference time, without
    updating model parameters Radford et al. ([2020](#bib.bib144)); Brown et al. ([2020](#bib.bib15)).
    ICL allows users to quickly build models for new use cases without worrying about
    fine-tuning and storing a large amount of new parameters for each task, so it
    is widely used in few-shot settings nowadays Min et al. ([2022](#bib.bib123)).
  prefs: []
  type: TYPE_NORMAL
- en: 'An in-context example typically contains an input-output pair with some prompt
    words, e.g., Please select the largest number from the list. Input: [2, 4, 1,
    5, 8]. Output: 8, and few-shot works by giving multiple examples, and then a final
    input example, where the model is expected to predict the output. However, such
    standard few-shot promptings, in which the LLM is given in-context examples of
    input–output pairs in front of test-time examples, have not yet proved sufficient
    to achieve high performance on challenging tasks such as mathematical reasoning Rae
    et al. ([2021](#bib.bib145)).'
  prefs: []
  type: TYPE_NORMAL
- en: Chain-of-thought prompting (CoT) Wei et al. ([2022](#bib.bib184)) leverages
    intermediate natural language rationales as prompts to enable LLMs to first generate
    reasoning chains and then predict an answer for an input question. For example,
    a CoT prompt for solving the math word problem could be
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each
    can has 3 tennis balls. Then, how many tennis balls does Roger have now?'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Answer: Roger started with 5 balls. 2 cans of 3 tennis balls each are 6 tennis
    balls. 5 + 6 = 11. The answer is 11.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Apart from Kojima et al. ([2022](#bib.bib81)) showing that LLMs are decent zero-shot
    reasoners when given the “Let’s think step by step!” prompt, most of the recent
    work has focused on how to improve chain-of-thought reasoning under the few-shot
    setting. This work is mainly divided into two parts, (i) selecting better in-context
    examples and (ii) creating better reasoning chains.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 In-context Example Selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Early chain-of-thought work randomly or heuristically selects in-context examples.
    However, recent studies have shown that this type of few-shot learning can be
    highly unstable across different selections of in-context examples Rubin et al.
    ([2022](#bib.bib156)); Liu et al. ([2022a](#bib.bib106)). Therefore, which in-context
    reasoning examples make the most effective prompts is still an unknown problem
    in the literature. To address the limitation, recent work has investigated various
    methods to optimize the in-context examples selection process Rubin et al. ([2022](#bib.bib156));
    Zhang et al. ([2023](#bib.bib218)); Lu et al. ([2022b](#bib.bib115)); Yu et al.
    ([2023](#bib.bib207)); Fu et al. ([2023](#bib.bib39)). For example, Rubin et al.
    ([2022](#bib.bib156)) attempt to address this issue by retrieving semantically
    similar examples. In addition, Fu et al. ([2023](#bib.bib39)) propose complexity-based
    prompting, which chooses examples with complex reasoning chains, i.e., chains
    with more reasoning steps, as the prompt. PromptPG Lu et al. ([2022b](#bib.bib115))
    learns to select optimal in-context examples via reinforcement learning (RL) from
    a candidate pool.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 High-quality Reasoning Chains
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Early chain of thought work (e.g., Wei et al. ([2022](#bib.bib184))) mainly
    relies on a single human-annotated reasoning chain as a prompt. However, manually
    creating reasoning chains has two disadvantages. First, as tasks become more complex,
    current models may not be sufficient to learn to perform all necessary reasoning
    steps and cannot easily generalize to different tasks. Second, a single decoding
    process is vulnerable to incorrect inference steps, leading to an incorrect prediction
    as the final answer. To address this limitation, recent studies mainly focus on
    two aspects, (i) hand-crafting more complex demonstrations, which we refer to
    as process-based approaches Zhou et al. ([2023](#bib.bib224)); Chen et al. ([2022b](#bib.bib22)),
    (ii) leveraging ensemble-like methods, which we refer to as outcome-based approaches Wang
    et al. ([2023](#bib.bib182)); Li et al. ([2022a](#bib.bib98)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Process-based approaches aim to improve the chain-of-thought reasoning quality,
    especially for complex reasoning tasks. In least-to-most prompting Zhou et al.
    ([2023](#bib.bib224)), the problem-solving process is implemented through two-stage
    prompting: (i) reducing a complex problem into a list of sub-problems; (ii) solving
    these sub-problems sequentially, so that solving a given sub-problem is facilitated
    by the answers to previously solved sub-problems. Similarly, Khot et al. ([2022](#bib.bib77))
    leverage diverse decomposition structures and use different prompts to answer
    each sub-question. Apart from these multi-step reasoning methods, Chen et al.
    ([2022b](#bib.bib22)); Gao et al. ([2022](#bib.bib41)) propose program-of-thoughts
    (PoT), an alternative solution that uses large language models to express the
    reasoning process as a program. The computation is then relegated to an external
    computer, which executes the generated programs to derive the answer. A more recent
    work, Chameleon Lu et al. ([2023](#bib.bib114)), integrates different tools to
    enhance the abilities of LLMs for compositional reasoning.'
  prefs: []
  type: TYPE_NORMAL
- en: Outcome-based approaches acknowledge the potential incorrectness of an individual
    reasoning path, and instead use multiple reasoning paths Wang et al. ([2023](#bib.bib182));
    Li et al. ([2022a](#bib.bib98)). Self-consistency Wang et al. ([2023](#bib.bib182))
    generates a set of reasoning paths by sampling from the language model, and marginalizes
    out the reasoning paths by choosing the most common answer. In addition to using
    sampling with a single prompt to produce multiple reasoning paths, Li et al. ([2022a](#bib.bib98))
    propose to introduce diverse prompts through “self-teaching”, as a complementary
    solution to produce a higher degree of diversity.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Discussion and Findings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 6.1 Analysis of Benchmarks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The multi-modal setting is underexplored but is gaining increasing attention.
    Most existing benchmarks for mathematical reasoning have targeted the textual-only
    modality. However, visual elements can provide a rich source of quantitative information,
    making multi-modal datasets beneficial for reasoning over quantitative relations
    in natural images Lu et al. ([2022a](#bib.bib113)), abstract diagrams Lu et al.
    ([2021b](#bib.bib116)), figures Kahou et al. ([2018](#bib.bib72)), and charts
    Kafle et al. ([2018](#bib.bib71)). Tables, which are commonly found in daily documents
    and contain hierarchically structured information, have also been the focus of
    tasks that require quantitative reasoning over textual and tabular context Chen
    et al. ([2021c](#bib.bib24)); Zhu et al. ([2021](#bib.bib225)); Zhao et al. ([2022](#bib.bib220));
    Lu et al. ([2022b](#bib.bib115)). In addition, recent datasets have been developed
    for mathematical reasoning grounded on conversations Sun et al. ([2019](#bib.bib167));
    Zhang et al. ([2021](#bib.bib213)); Chen et al. ([2022c](#bib.bib25)), as well
    as reports Chen et al. ([2022c](#bib.bib25)).
  prefs: []
  type: TYPE_NORMAL
- en: Pioneering work is emerging in the exploration of low-resource settings. Despite
    the creation of various datasets, mathematical reasoning in low-resource settings
    remains largely under-explored. Pioneering research has developed mathematical
    reasoning benchmarks for financial Chen et al. ([2021c](#bib.bib24)); Zhu et al.
    ([2021](#bib.bib225)); Zhao et al. ([2022](#bib.bib220)) and scientific domains
    Lu et al. ([2022a](#bib.bib113)). Additionally, there have been attempts to build
    non-English datasets for Chinese Wang et al. ([2017](#bib.bib183)); Qin et al.
    ([2020](#bib.bib140)); Yu et al. ([2021a](#bib.bib205)) and Arabic Alghamdi et al.
    ([2022](#bib.bib2)) for mathematical reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: Diverse rationale annotations have been widely explored. Complex reasoning usually
    involves multiple steps to arrive at the final answer. To bridge this gap, datasets
    annotated with intermediate rationales such as logic forms Tafjord et al. ([2019](#bib.bib169));
    Lu et al. ([2021a](#bib.bib112)), programs Amini et al. ([2019](#bib.bib4)); Chen
    et al. ([2021c](#bib.bib24), [a](#bib.bib20)); Cao and Xiao ([2022](#bib.bib16));
    Chen et al. ([2022a](#bib.bib19)), and reasoning graphs Zhang et al. ([2021](#bib.bib213))
    have been proposed to train models for complex reasoning tasks. Python programs
    are used as reasoning annotations in Austin et al. ([2021](#bib.bib8)); Mishra
    et al. ([2022a](#bib.bib125)) due to their enhanced accessibility and readability.
    To imitate the reasoning process of a human, a more recent trend is to annotate
    solutions in natural language Ling et al. ([2017](#bib.bib105)); Cobbe et al.
    ([2021](#bib.bib32)); Lu et al. ([2022b](#bib.bib115)); Hendrycks et al. ([2021b](#bib.bib55));
    Lu et al. ([2022a](#bib.bib113)).
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Analysis of Deep Learning Methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '|  | T5 | UnifiedQA | GPT-3 | GPT-3 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  | (Large) | (Large) | (davinci-002) | (davinci-003) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 3 balls + 5 balls = | ✗ | 5 balls | 8 balls | 8 balls |'
  prefs: []
  type: TYPE_TB
- en: '| 23 balls + 145 balls = | ✗ | ✗ | 58 balls | 168 balls |'
  prefs: []
  type: TYPE_TB
- en: '| 23 balls + 1,855 balls = | ✗ | ✗ | 2,878 balls | 2,988 balls |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5: Language models struggle with large numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: Is the current representation of numeracy sufficient? The standard practice
    for deep learning techniques is to treat numbers in the same way as words. Early
    neural network methods create a vocabulary that maps input words and numbers to
    token IDs, resulting in less frequent numbers being collapsed into an “UNK” token.
    Recent language models use subword tokenization techniques Wu et al. ([2016](#bib.bib196));
    Sennrich et al. ([2016](#bib.bib161)) to split numbers into atomic tokens. Recent
    studies have shown that these tokenization approaches are suboptimal Wallace et al.
    ([2019](#bib.bib178)); Lin et al. ([2020](#bib.bib103)); Zhang et al. ([2020d](#bib.bib215));
    Thawani et al. ([2022](#bib.bib171)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Two numbers on the same or close number line could have surface forms with
    no shared common tokens. For example, a number like $1598$ is tokenized as “$15$”
    and “$98$” in GPT-3, while another format like $1,598$ is split as three different
    tokens: “$1$”, “,”, and “$598$”. This lack of consistent representation can make
    it difficult for deep learning models to effectively process numbers, especially
    when compared to pure text. The insufficient representations of numbers can lead
    to out-of-distribution (OOD) problems. [Table 5](#S6.T5 "Table 5 ‣ 6.2 Analysis
    of Deep Learning Methods ‣ 6 Discussion and Findings ‣ A Survey of Deep Learning
    for Mathematical Reasoning") provides examples of where language models tend to
    struggle with large numbers. Although increasing model scales could help, even
    the state-of-the-art large language model GPT-3 performs poorly when reasoning
    over large numbers. Some recent work suggests that using scientific notation Zhang
    et al. ([2020d](#bib.bib215)) and digit-level decomposition Geva et al. ([2020](#bib.bib46))
    may be helpful in improving numeracy representation, but this remains an open
    problem.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Problems | GPT-3 (text-davinci-002) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| John had 8 balls and he gave 3 to Mary. How many balls does John have now?
    | John has 5 balls. |'
  prefs: []
  type: TYPE_TB
- en: '| John had 3 apples. John had 8 balls and he gave 3 to Mary. How many balls
    does Mary have now? | Mary has 5 balls. |'
  prefs: []
  type: TYPE_TB
- en: '| John had 8 balls and he gave 3 to Mary. Who has more balls now? | John has
    more balls. |'
  prefs: []
  type: TYPE_TB
- en: '| John had 8 balls and he gave 3 to Mary. Does John have more balls now? |
    No, John has 5 balls now. |'
  prefs: []
  type: TYPE_TB
- en: '| John had 8 balls and he gave 4 to Mary. Does John have more balls now? |
    No, John has 4 balls now. |'
  prefs: []
  type: TYPE_TB
- en: '| John had 8 balls and he gave 4 to Mary. Who has more balls now? | John has
    more balls. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6: Examples where large language models are not consistent for mathematical
    reasoning.'
  prefs: []
  type: TYPE_NORMAL
- en: Are deep learning methods consistent for mathematical reasoning? Recent developments
    in deep learning have led to impressive results on various mathematical reasoning
    tasks. The zero-shot-CoT Minerva 540B achieves a score of 75.0% on the MMLU-STEM
    benchmark Hendrycks et al. ([2021a](#bib.bib54)), which assesses multitask reasoning
    ability in the fields of science, technology, engineering, and mathematics (STEM)
    at both high school and college levels. Similarly, few-shot-CoT GPT-3 175B achieves
    a high accuracy of 93.0% on the MultiArith task. However, the question remains
    as to whether these methods are sufficiently advanced to tackle more complex problems.
  prefs: []
  type: TYPE_NORMAL
- en: There is strong evidence that deep learning methods for mathematical reasoning
    are not robust and susceptible to adversarial attacks Lin et al. ([2020](#bib.bib103));
    Patel et al. ([2021](#bib.bib134)); Mishra et al. ([2022b](#bib.bib126), [a](#bib.bib125));
    Welleck et al. ([2022b](#bib.bib188)). The SVAMP Patel et al. ([2021](#bib.bib134))
    dataset is a collection of one-unknown arithmetic word problems up to grade 4,
    with slight word variations from previous datasets. It is surprising that current
    state-of-the-art (SOTA) methods perform poorly on this dataset, with Graph2Tree
    achieving only a 43.8% accuracy and zero-shot-CoT GPT-3 (175B) only reaching 63.7%,
    which is just above an “F” grade. [Table 6](#S6.T6 "Table 6 ‣ 6.2 Analysis of
    Deep Learning Methods ‣ 6 Discussion and Findings ‣ A Survey of Deep Learning
    for Mathematical Reasoning") also shows the inconsistent performance of the zero-shot
    GPT-3 model in scenarios with slightly different descriptions, while human performance
    remains unchanged. This indicates a lack of consistency in the mathematical reasoning
    ability of SOTA large language models.
  prefs: []
  type: TYPE_NORMAL
- en: 7 Future Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 7.1 Generalization and Robustness
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Despite impressive progress, neural models commonly display generalization and
    robustness failures on reasoning tasks. For example, above we discussed difficulties
    in generalizing to larger numbers ([Table 5](#S6.T5 "Table 5 ‣ 6.2 Analysis of
    Deep Learning Methods ‣ 6 Discussion and Findings ‣ A Survey of Deep Learning
    for Mathematical Reasoning")) or remaining robust to nearby problems ([Table 6](#S6.T6
    "Table 6 ‣ 6.2 Analysis of Deep Learning Methods ‣ 6 Discussion and Findings ‣
    A Survey of Deep Learning for Mathematical Reasoning")), while others identify
    failures in generalizing to longer problems than those observed in training (e.g.,
    Anil et al. ([2022](#bib.bib7))). One direction is to explore new inference-time Jung
    et al. ([2022](#bib.bib70)); Mitchell et al. ([2022](#bib.bib127)) or fine-tuning Anil
    et al. ([2022](#bib.bib7)) strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Another aspect of generalization relates to the role of memorization. For example,
    is the ability to produce a complex solution dependent on seeing many similar
    solutions during training, or even on memorizing the solution? Term frequency
    in the pretraining corpus is known to impact accuracy in simple arithmetic tasks Razeghi
    et al. ([2022](#bib.bib148)) or factual question answering Kandpal et al. ([2022](#bib.bib75)).
    On the other hand, Lewkowycz et al. ([2022](#bib.bib92)) did not find evidence
    of memorization in complex outputs, yet their training set and model are not available
    for inspection. Gaining a full understanding of these factors for complex problems
    and outputs (e.g., multi-step solutions or proofs) requires more analysis, as
    well as accessible datasets and models.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Trustworthy Reasoning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Recent advances in language models have demonstrated their powerful capabilities
    for mathematical reasoning. However, due to the potential for generating ungrounded
    answers Nakano et al. ([2021](#bib.bib129)), users can’t always trust the predicted
    outcomes or have to verify then with extra efforts. Even with recent prompting
    strategies that provide rationales before making predictions Wei et al. ([2022](#bib.bib184)),
    language models can still hallucinate statements, produce flawed reasoning, and
    output wrong answers. Consequently, novel approaches that enable more reliable
    reasoning are needed urgently. Some potential directions for this include: (i)
    using language models to provide evidence, such as theorems, to support the reasoning
    process; (ii) incorporating a mechanism that makes a judgment when the model is
    unsure of the answer; and (iii) using a model itself or another module to detect
    and locate mistakes in a model’s reasoning.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.3 Learning from Feedback
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another important direction to further improve language models for mathematical
    reasoning is to let the model learn from feedback. Such a process makes the continual
    improvement of models’ output quality and safety possible. An example is using
    reinforcement learning from human feedback (RLHF) Ouyang et al. ([2022](#bib.bib133))
    to align language models with instructions. The idea is to let humans rank the
    generated outputs of language models and use the learned reward function to finetune
    the language model with policy gradient Ouyang et al. ([2022](#bib.bib133)); Glaese
    et al. ([2022](#bib.bib48)); Qiu et al. ([2022a](#bib.bib141)). In the context
    of mathematical reasoning, feedback does not necessarily come from humans directly.
    The outcome of a theorem-proof engine Jiang et al. ([2021](#bib.bib67)); Wu et al.
    ([2021d](#bib.bib200), [2022c](#bib.bib199)) or the execution result of model-generated
    scripts can also be used as the reward source Polu and Sutskever ([2020](#bib.bib138)).
  prefs: []
  type: TYPE_NORMAL
- en: 7.4 Multi-modal Mathematical Reasoning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In recent years, there has been growing interest in multi-modal mathematical
    reasoning, which involves using multiple sources of information, such as text,
    tables, natural images, and diagrams  Kahou et al. ([2018](#bib.bib72)); Kafle
    et al. ([2018](#bib.bib71)); Lu et al. ([2021b](#bib.bib116), [2022b](#bib.bib115)).
    However, currently available datasets in this domain tend to be small Zhao et al.
    ([2022](#bib.bib220)), generated from templates Kahou et al. ([2018](#bib.bib72)),
    or focus on specific topics Lu et al. ([2021a](#bib.bib112)); Chen et al. ([2022a](#bib.bib19)).
    One line of current research involves applying VQA-based frameworks to analyze
    figures and plots, but this approach can result in significant semantic gaps due
    to the fact that most VQA models are trained on natural images. One potential
    direction for future work is to enhance the ability of multi-modal mathematical
    reasoning systems to tackle more complex and realistic problems. This may involve
    creating unified models for interpreting and integrating different modalities,
    as well as developing better evaluation benchmarks to assess the performance of
    these systems.
  prefs: []
  type: TYPE_NORMAL
- en: 8 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we present a comprehensive survey of deep learning for mathematical
    reasoning. We review the various tasks, datasets, and deep learning approaches.
    We also identify several gaps in the existing datasets and methods. Finally, we
    outline directions for future research and highlight the potential for further
    exploration in this field. Our goal with this paper is to provide a comprehensive
    and useful resource for readers interested in the development of deep learning
    for mathematical reasoning. To aid in this effort, we have created a reading list
    that will be continually updated in a GitHub repository at [https://github.com/lupantech/dl4math](https://github.com/lupantech/dl4math).
  prefs: []
  type: TYPE_NORMAL
- en: Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One limitation of our survey work is that it is focused on the intersection
    of mathematical reasoning and deep learning over the past decade, which may not
    encompass the entire field and its history. Additionally, our evaluation of existing
    benchmarks and methods is based on a curated set of papers and may not fully represent
    the state of the art in the field. Furthermore, due to the fast-paced nature of
    the field, our survey may not reflect the latest developments and advancements
    which may have come out close to or after the survey was conducted. Despite these
    limitations, our survey still provides a valuable overview of the current state
    and key trends in the field of mathematical reasoning and deep learning, and can
    serve as a valuable resource for researchers and practitioners working in this
    field.
  prefs: []
  type: TYPE_NORMAL
- en: Broader Impact
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our survey paper on the intersection of mathematical reasoning and deep learning
    has the potential to significantly impact the field of artificial intelligence.
    By providing a comprehensive overview of the key tasks, datasets, and methods
    that have been developed in the past decade, we give researchers and practitioners
    a clear understanding of the current state-of-the-art and help them make informed
    decisions about their own research. Additionally, by evaluating existing benchmarks
    and methods and discussing future research directions, we aim to identify gaps
    in the current state of the art and guide future research and development efforts
    towards more advanced and effective mathematical reasoning systems. Overall, our
    survey has the potential to contribute to the advancement of mathematical reasoning
    and deep learning, and have a profound impact on machine learning and natural
    language processing.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Alemi et al. (2016) Alexander A. Alemi, François Chollet, Niklas Een, Geoffrey
    Irving, Christian Szegedy, and Josef Urban. 2016. [Deepmath - deep sequence models
    for premise selection](https://arxiv.org/abs/1606.04442). *Advances in neural
    information processing systems (NeurIPS)*, 29.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alghamdi et al. (2022) Reem Alghamdi, Zhenwen Liang, and Xiangliang Zhang.
    2022. [Armath: a dataset for solving arabic math word problems](https://aclanthology.org/2022.lrec-1.37/).
    In *Proceedings of the Thirteenth Language Resources and Evaluation Conference
    (LREC)*, pages 351–362.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alvin et al. (2017) Chris Alvin, Sumit Gulwani, Rupak Majumdar, and Supratik
    Mukhopadhyay. 2017. [Synthesis of solutions for shaded area geometry problems](https://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS17/paper/viewFile/15416/14902).
    In *The Thirtieth International Flairs Conference*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Amini et al. (2019) Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski,
    Yejin Choi, and Hannaneh Hajishirzi. 2019. [Mathqa: Towards interpretable math
    word problem solving with operation-based formalisms](https://aclanthology.org/N19-1245/).
    In *Proceedings of the 2019 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies (NAACL-HLT)*, pages
    2357–2367.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anderson and Farrell (2022) Connor Anderson and Ryan Farrell. 2022. [Improving
    fractal pre-training](https://arxiv.org/abs/2110.03091). In *Proceedings of the
    IEEE/CVF Winter Conference on Applications of Computer Vision*, pages 1300–1309.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anderson et al. (2018) Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney,
    Mark Johnson, Stephen Gould, and Lei Zhang. 2018. [Bottom-up and top-down attention
    for image captioning and visual question answering](https://arxiv.org/abs/1707.07998).
    In *Proceedings of the IEEE conference on computer vision and pattern recognition
    (CVPR)*, pages 6077–6086.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anil et al. (2022) Cem Anil, Yuhuai Wu, Anders Johan Andreassen, Aitor Lewkowycz,
    Vedant Misra, Vinay Venkatesh Ramasesh, Ambrose Slone, Guy Gur-Ari, Ethan Dyer,
    and Behnam Neyshabur. 2022. [Exploring length generalization in large language
    models](https://openreview.net/forum?id=zSkYVeX7bC4). In *Advances in Neural Information
    Processing Systems (NeurIPS)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Austin et al. (2021) Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma,
    Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc
    Le, et al. 2021. [Program synthesis with large language models](https://arxiv.org/abs/2108.07732).
    *arXiv preprint arXiv:2108.07732*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bahdanau et al. (2015) Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015.
    [Neural machine translation by jointly learning to align and translate](https://arxiv.org/abs/1409.0473).
    In *International Conference on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bansal et al. (2019) Kshitij Bansal, Sarah Loos, Markus Rabe, Christian Szegedy,
    and Stewart Wilcox. 2019. [Holist: An environment for machine learning of higher
    order logic theorem proving](https://arxiv.org/abs/1904.03241). In *International
    Conference on Machine Learning (ICML)*, pages 454–463\. PMLR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Barras et al. (1999) Bruno Barras, Samuel Boutin, Cristina Cornes, Judicaël
    Courant, Yann Coscoy, David Delahaye, Daniel de Rauglaudre, Jean-Christophe Filliâtre,
    Eduardo Giménez, Hugo Herbelin, et al. 1999. [The coq proof assistant reference
    manual](https://flint.cs.yale.edu/cs430/coq/pdf/Reference-Manual.pdf). *INRIA,
    version*, 6(11).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Berg-Kirkpatrick and Spokoyny (2020) Taylor Berg-Kirkpatrick and Daniel Spokoyny.
    2020. [An empirical investigation of contextualized number prediction](https://doi.org/10.18653/v1/2020.emnlp-main.385).
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 4754–4764.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bhattacharya (2017) Arindam Bhattacharya. 2017. [A survey of question answering
    for math and science problem](https://arxiv.org/abs/1705.04530). *arXiv preprint
    arXiv:1705.04530*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bobrow (1964) Daniel G Bobrow. 1964. [Natural language input for a computer
    problem solving system](http://dspace.mit.edu/handle/1721.1/5922). *AI Technical
    Reports*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. [Language models are few-shot learners](https://arxiv.org/abs/2005.14165).
    *Advances in Neural Information Processing Systems (NeurIPS)*, 33:1877–1901.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cao and Xiao (2022) Jie Cao and Jing Xiao. 2022. [An augmented benchmark dataset
    for geometric question answering through dual parallel text encoding](https://aclanthology.org/2022.coling-1.130/).
    In *Proceedings of the 29th International Conference on Computational Linguistics
    (COLING)*, pages 1511–1520.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cao et al. (2021) Yixuan Cao, Feng Hong, Hongwei Li, and Ping Luo. 2021. [A
    bottom-up dag structure extraction model for math word problems](https://ojs.aaai.org/index.php/AAAI/article/view/16075).
    In *Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)*, pages
    39–46.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Charton (2022) François Charton. 2022. [Linear algebra with transformers](https://openreview.net/forum?id=Hp4g7FAXXG).
    *Transactions on Machine Learning Research*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2022a) Jiaqi Chen, Tong Li, Jinghui Qin, Pan Lu, Liang Lin, Chongyu
    Chen, and Xiaodan Liang. 2022a. [Unigeo: Unifying geometry logical reasoning via
    reformulating mathematical expression](https://lupantech.github.io/papers/emnlp22_unigeo.pdf).
    In *The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2021a) Jiaqi Chen, Jianheng Tang, Jinghui Qin, Xiaodan Liang,
    Lingbo Liu, Eric Xing, and Liang Lin. 2021a. [Geoqa: A geometric question answering
    benchmark towards multimodal numerical reasoning](https://aclanthology.org/2021.findings-acl.46.pdf).
    In *Findings of the Association for Computational Linguistics (ACL)*, pages 513–523.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2021b) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique
    Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, et al. 2021b. [Evaluating large language models trained on code](https://arxiv.org/abs/2107.03374).
    *arXiv preprint arXiv:2107.03374*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2022b) Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen.
    2022b. [Program of thoughts prompting: Disentangling computation from reasoning
    for numerical reasoning tasks](https://arxiv.org/abs/2211.12588). *arXiv preprint
    arXiv:2211.12588*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2023) Wenhu Chen, Ming Yin, Max Ku, Elaine Wan, Xueguang Ma, Jianyu
    Xu, Tony Xia, Xinyi Wang, and Pan Lu. 2023. Theoremqa: A theorem-driven question
    answering dataset. *arXiv preprint arXiv:2305.12524*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2021c) Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana
    Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan R Routledge,
    et al. 2021c. [Finqa: A dataset of numerical reasoning over financial data](https://arxiv.org/abs/2109.00122).
    In *Proceedings of the 2021 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 3697–3711.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2022c) Zhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang Ma, Sameena
    Shah, and William Yang Wang. 2022c. [Convfinqa: Exploring the chain of numerical
    reasoning in conversational finance question answering](https://arxiv.org/abs/2210.03849).
    *arXiv preprint arXiv:2210.03849*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chiang and Chen (2019) Ting-Rui Chiang and Yun-Nung Chen. 2019. [Semantically-aligned
    equation generation for solving and reasoning math word problems](https://aclanthology.org/N19-1272/).
    In *Proceedings of the 2019 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies (NAACL-HLT)*, pages
    2656–2668.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cho et al. (2021) Jaemin Cho, Jie Lei, Hao Tan, and Mohit Bansal. 2021. [Unifying
    vision-and-language tasks via text generation](https://proceedings.mlr.press/v139/cho21a.html).
    In *Proceedings of the 38th International Conference on Machine Learning (ICML)*,
    pages 1931–1942.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cho et al. (2014) Kyunghyun Cho, Bart van Merrienboer Caglar Gulcehre, Dzmitry
    Bahdanau, Fethi Bougares Holger Schwenk, and Yoshua Bengio. 2014. [Learning phrase
    representations using rnn encoder–decoder for statistical machine translation](https://aclanthology.org/D14-1179/).
    In *Proceedings of the 2014 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 1724–1734.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chou et al. (1996) Shang-Ching Chou, Xiao-Shan Gao, and Jing-Zhong Zhang. 1996.
    [Automated generation of readable proofs with geometric invariants](https://link.springer.com/article/10.1007/BF00283133).
    *Journal of Automated Reasoning*, 17(3):325–347.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chowdhery et al. (2022) Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten
    Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton,
    Sebastian Gehrmann, et al. 2022. [Palm: Scaling language modeling with pathways](https://arxiv.org/abs/2204.02311).
    *arXiv preprint arXiv:2204.02311*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Clark et al. (2020) Peter Clark, Oren Etzioni, Tushar Khot, Daniel Khashabi,
    Bhavana Mishra, Kyle Richardson, Ashish Sabharwal, Carissa Schoenick, Oyvind Tafjord,
    Niket Tandon, et al. 2020. [From ‘f’to ‘a’on the ny regents science exams: An
    overview of the aristo project](https://arxiv.org/abs/1909.01958). *AI Magazine*,
    41(4):39–53.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton,
    Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021. [Training verifiers
    to solve math word problems](https://arxiv.org/abs/2110.14168). *arXiv preprint
    arXiv:2110.14168*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2019. [BERT: Pre-training of deep bidirectional transformers for language
    understanding](https://doi.org/10.18653/v1/N19-1423). In *Proceedings of the 2019
    Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies (NAACL-HLT)*, pages 4171–4186.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dua et al. (2019) Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky,
    Sameer Singh, and Matt Gardner. 2019. [Drop: A reading comprehension benchmark
    requiring discrete reasoning over paragraphs](https://aclanthology.org/N19-1246/).
    In *Proceedings of the 2019 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies (NAACL-HLT)*, pages
    2368–2378.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feigenbaum et al. (1963) Edward A Feigenbaum et al. 1963. [*Computers and thought*](https://mitpress.mit.edu/9780262691338/computers-and-thought/).
    McGraw-Hill.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feng et al. (2021) Yu Feng, Jing Zhang, Xiaokang Zhang, Lemao Liu, Cuiping Li,
    and Hong Chen. 2021. [Injecting numerical reasoning skills into knowledge base
    question answering models](https://arxiv.org/abs/2112.06109). *arXiv preprint
    arXiv:2112.06109*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ferreira and Freitas (2020a) Deborah Ferreira and André Freitas. 2020a. [Natural
    language premise selection: Finding supporting statements for mathematical text](https://aclanthology.org/2020.lrec-1.266).
    In *Proceedings of the Twelfth Language Resources and Evaluation Conference*,
    pages 2175–2182.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ferreira and Freitas (2020b) Deborah Ferreira and André Freitas. 2020b. [Premise
    selection in natural language mathematical texts](https://doi.org/10.18653/v1/2020.acl-main.657).
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics (ACL)*, pages 7365–7374.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fu et al. (2023) Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar
    Khot. 2023. [Complexity-based prompting for multi-step reasoning](https://arxiv.org/abs/2210.00720).
    In *International Conference on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. (2020) Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis
    Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, et al.
    2020. [The pile: An 800gb dataset of diverse text for language modeling](https://arxiv.org/abs/2101.00027).
    *arXiv preprint arXiv:2101.00027*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. (2022) Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu,
    Yiming Yang, Jamie Callan, and Graham Neubig. 2022. [Pal: Program-aided language
    models](https://arxiv.org/abs/2211.10435). *arXiv preprint arXiv:2211.10435*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao et al. (2019) Peng Gao, Zhengkai Jiang, Haoxuan You, Pan Lu, Steven CH Hoi,
    Xiaogang Wang, and Hongsheng Li. 2019. [Dynamic fusion with intra-and inter-modality
    attention flow for visual question answering](https://arxiv.org/abs/1812.05252).
    In *The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, pages
    6639–6648.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gauthier et al. (2021) Thibault Gauthier, Cezary Kaliszyk, Josef Urban, Ramana
    Kumar, and Michael Norrish. 2021. [TacticToe: Learning to Prove with Tactics](https://doi.org/10.1007/s10817-020-09580-x).
    *Journal of Automated Reasoning*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gehring et al. (2017) Jonas Gehring, Michael Auli, David Grangier, Denis Yarats,
    and Yann N Dauphin. 2017. [Convolutional sequence to sequence learning](https://arxiv.org/abs/1705.03122).
    In *International conference on machine learning (ICML)*, pages 1243–1252\. PMLR.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gelernter et al. (1960) Herbert Gelernter, James R Hansen, and Donald W Loveland.
    1960. [Empirical explorations of the geometry theorem machine](https://dl.acm.org/doi/10.1145/1460361.1460381).
    In *Papers presented at the May 3-5, 1960, western joint IRE-AIEE-ACM computer
    conference*, pages 143–149.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geva et al. (2020) Mor Geva, Ankit Gupta, and Jonathan Berant. 2020. [Injecting
    numerical reasoning skills into language models](https://arxiv.org/abs/2004.04487).
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics (ACL)*, pages 946–958.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gimpel et al. (2010) Kevin Gimpel, Dipanjan Das, and Noah A Smith. 2010. [Distributed
    asynchronous online learning for natural language processing](https://aclanthology.org/W10-2925/).
    In *Proceedings of the Fourteenth Conference on Computational Natural Language
    Learning*, pages 213–222.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Glaese et al. (2022) Amelia Glaese, Nat McAleese, Maja Trębacz, John Aslanides,
    Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe
    Thacker, et al. 2022. [Improving alignment of dialogue agents via targeted human
    judgements](https://arxiv.org/abs/2209.14375). *arXiv preprint arXiv:2209.14375*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grabowski et al. (2015) Adam Grabowski, Artur Korniłowicz, and Adam Naumowicz.
    2015. [Four decades of mizar](https://dl.acm.org/doi/abs/10.1007/s10817-015-9345-1).
    *Journal of Automated Reasoning*, 55(3):191–198.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guu et al. (2020) Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei
    Chang. 2020. [Retrieval augmented language model pre-training](https://arxiv.org/abs/2002.08909).
    In *International Conference on Machine Learning (ICML)*, pages 3929–3938\. PMLR.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Han et al. (2022) Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward W Ayers,
    and Stanislas Polu. 2022. [Proof artifact co-training for theorem proving with
    language models](https://arxiv.org/abs/2102.06203). In *International Conference
    on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hao et al. (2022) Yihan Hao, Mingliang Zhang, Fei Yin, and Linlin Huang. 2022.
    [Pgdp5k: A diagram parsing dataset for plane geometry problems](https://arxiv.org/abs/2205.09947).
    In *26th International Conference on Pattern Recognition (ICPR)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2016) Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.
    [Deep residual learning for image recognition](https://arxiv.org/abs/1512.03385).
    In *Proceedings of the IEEE conference on computer vision and pattern recognition
    (CVPR)*, pages 770–778.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hendrycks et al. (2021a) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou,
    Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021a. [Measuring massive multitask
    language understanding](https://arxiv.org/abs/2009.03300). In *International Conference
    on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hendrycks et al. (2021b) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul
    Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021b. [Measuring
    mathematical problem solving with the math dataset](https://arxiv.org/abs/2103.03874).
    In *35th Conference on Neural Information Processing Systems (NeurIPS) Track on
    Datasets and Benchmarks*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hendrycks et al. (2020) Dan Hendrycks, Xiaoyuan Liu, Eric Wallace, Adam Dziedzic,
    Rishabh Krishnan, and Dawn Song. 2020. [Pretrained transformers improve out-of-distribution
    robustness](https://arxiv.org/abs/2004.06100). In *Proceedings of the 58th Annual
    Meeting of the Association for Computational Linguistics (ACL)*, pages 2744–2751.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Herzig et al. (2020) Jonathan Herzig, Pawel Krzysztof Nowak, Thomas Mueller,
    Francesco Piccinno, and Julian Eisenschlos. 2020. [Tapas: Weakly supervised table
    parsing via pre-training](https://arxiv.org/abs/2004.02349). In *Proceedings of
    the 58th Annual Meeting of the Association for Computational Linguistics (ACL)*,
    pages 4320–4333.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hochreiter and Schmidhuber (1997) Sepp Hochreiter and Jürgen Schmidhuber. 1997.
    [Long short-term memory](https://ieeexplore.ieee.org/abstract/document/6795963).
    *Neural computation*, 9(8):1735–1780.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hong et al. (2021a) Yining Hong, Qing Li, Daniel Ciao, Siyuan Huang, and Song-Chun
    Zhu. 2021a. [Learning by fixing: Solving math word problems with weak supervision](https://arxiv.org/abs/2012.10582).
    In *Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)*, pages
    4959–4967.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hong et al. (2021b) Yining Hong, Qing Li, Ran Gong, Daniel Ciao, Siyuan Huang,
    and Song-Chun Zhu. 2021b. [Smart: A situation model for algebra story problems
    via attributed grammar](https://arxiv.org/abs/2012.14011). In *AAAI*, pages 13009–13017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hosseini et al. (2014) Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni,
    and Nate Kushman. 2014. [Learning to solve arithmetic word problems with verb
    categorization](https://aclanthology.org/D14-1058). In *Proceedings of the 2014
    Conference on Empirical Methods in Natural Language Processing (EMNLP)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. (2019) Daniel Huang, Prafulla Dhariwal, Dawn Song, and Ilya Sutskever.
    2019. [Gamepad: A learning environment for theorem proving](https://arxiv.org/abs/1806.00608).
    In *International Conference on Learning Representations (ICLR)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2018) Danqing Huang, Jing Liu, Chin-Yew Lin, and Jian Yin. 2018.
    [Neural math word problem solver with reinforcement learning](https://aclanthology.org/C18-1018/).
    In *Proceedings of the 27th International Conference on Computational Linguistics
    (COLING)*, pages 213–223.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2017) Danqing Huang, Shuming Shi, Chin-Yew Lin, and Jian Yin.
    2017. [Learning fine-grained expressions to solve math word problems](https://aclanthology.org/D17-1084/).
    In *Proceedings of Empirical Methods in Natural Language Processing (EMNLP)*,
    pages 805–814.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2016) Danqing Huang, Shuming Shi, Chin-Yew Lin, Jian Yin, and
    Wei-Ying Ma. 2016. [How well do computers solve math word problems? large-scale
    dataset construction and evaluation](https://aclanthology.org/P16-1084/). In *Proceedings
    of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)*,
    pages 887–896.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jiang et al. (2022a) Albert Q. Jiang, Sean Welleck, Jin Peng Zhou, Wenda Li,
    Jiacheng Liu, Mateja Jamnik, Timothée Lacroix, Yuhuai Wu, and Guillaume Lample.
    2022a. [Draft, sketch, and prove: Guiding formal theorem provers with informal
    proofs](https://arxiv.org/abs/2210.12283). In *Submitted to The Eleventh International
    Conference on Learning Representations*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jiang et al. (2021) Albert Qiaochu Jiang, Wenda Li, Jesse Michael Han, and
    Yuhuai Wu. 2021. [Lisa: Language models of isabelle proofs](http://aitp-conference.org/2021/abstract/paper_17.pdf).
    In *6th Conference on Artificial Intelligence and Theorem Proving (AITP)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jiang et al. (2022b) Albert Qiaochu Jiang, Wenda Li, Szymon Tworkowski, Konrad
    Czechowski, Tomasz Odrzygóźdź, Piotr Miłoś, Yuhuai Wu, and Mateja Jamnik. 2022b.
    Thor: Wielding hammers to integrate language models and automated theorem provers.
    *Advances in Neural Information Processing Systems (NeurIPS)*, 35:8360–8373.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jie et al. (2022) Zhanming Jie, Jierui Li, and Wei Lu. 2022. [Learning to reason
    deductively: Math word problem solving as complex relation extraction](https://arxiv.org/abs/2203.10316).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (ACL)*, pages 5944–5955.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jung et al. (2022) Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra
    Bhagavatula, Ronan Le Bras, and Yejin Choi. 2022. [Maieutic prompting: Logically
    consistent reasoning with recursive explanations](https://aclanthology.org/2022.emnlp-main.82).
    In *Proceedings of the 2022 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 1266–1279.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kafle et al. (2018) Kushal Kafle, Brian Price, Scott Cohen, and Christopher
    Kanan. 2018. [Dvqa: Understanding data visualizations via question answering](https://arxiv.org/abs/1801.08163).
    In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
    (CVPR)*, pages 5648–5656.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kahou et al. (2018) Samira Ebrahimi Kahou, Vincent Michalski, Adam Atkinson,
    Ákos Kádár, Adam Trischler, and Yoshua Bengio. 2018. [Figureqa: An annotated figure
    dataset for visual reasoning](https://arxiv.org/abs/1710.07300). In *International
    Conference on Learning Representations (ICLR)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kaliszyk et al. (2017) Cezary Kaliszyk, François Chollet, and Christian Szegedy.
    2017. [Holstep: A machine learning dataset for higher-order logic theorem proving](https://arxiv.org/abs/1703.00426).
    In *International Conference on Learning Representations (ICLR)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kalyan et al. (2021) Ashwin Kalyan, Abhinav Kumar, Arjun Chandrasekaran, Ashish
    Sabharwal, and Peter Clark. 2021. [How much coffee was consumed during emnlp 2019?
    fermi problems: A new reasoning challenge for ai](https://arxiv.org/abs/2110.14207).
    In *Proceedings of the 2021 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 7318–7328.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kandpal et al. (2022) Nikhil Kandpal, H. Deng, Adam Roberts, Eric Wallace, and
    Colin Raffel. 2022. [Large language models struggle to learn long-tail knowledge](https://arxiv.org/abs/2211.08411).
    *ArXiv*, abs/2211.08411.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Khashabi et al. (2020) Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal,
    Oyvind Tafjord, Peter Clark, and Hannaneh Hajishirzi. 2020. [Unifiedqa: Crossing
    format boundaries with a single qa system](https://arxiv.org/abs/2005.00700).
    In *Findings of the Association for Computational Linguistics (EMNLP)*, pages
    1896–1907.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Khot et al. (2022) Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle
    Richardson, Peter Clark, and Ashish Sabharwal. 2022. [Decomposed prompting: A
    modular approach for solving complex tasks](https://arxiv.org/abs/2210.02406).
    *arXiv preprint arXiv:2210.02406*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2020) Bugeun Kim, Kyung Seo Ki, Donggeon Lee, and Gahgene Gweon.
    2020. [Point to the expression: Solving algebraic word problems using the expression-pointer
    transformer model](https://aclanthology.org/2020.emnlp-main.308/). In *Proceedings
    of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)*,
    pages 3768–3779.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2018) Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang. 2018. [Bilinear
    attention networks](https://arxiv.org/abs/1805.07932). In *Advances in Neural
    Information Processing Systems (NeurIPS)*, pages 1571–1581.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2021) Wonjae Kim, Bokyung Son, and Ildoo Kim. 2021. [Vilt: Vision-and-language
    transformer without convolution or region supervision](https://arxiv.org/abs/2102.03334).
    In *Proceedings of the 38th International Conference on Machine Learning (ICML)*,
    pages 5583–5594.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. [Large language models are zero-shot reasoners](https://arxiv.org/abs/2205.11916).
    In *36th Conference on Neural Information Processing Systems (NeurIPS)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Koncel-K. et al. (2016) Rik Koncel-K., Subhro Roy, Aida Amini, Nate Kushman,
    and Hannaneh Hajishirzi. 2016. [Mawps: A math word problem repository](https://aclanthology.org/N16-1136/).
    In *Proceedings of the 2016 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies (NAACL)*, pages 1152–1157.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Koncel-Kedziorski et al. (2015) Rik Koncel-Kedziorski, Hannaneh Hajishirzi,
    Ashish Sabharwal, Oren Etzioni, and Siena Dumas Ang. 2015. [Parsing algebraic
    word problems into equations](https://aclanthology.org/Q15-1042/). *Transactions
    of the Association for Computational Linguistics (TACL)*, 3:585–597.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Krishna et al. (2021) Kundan Krishna, Jeffrey Bigham, and Zachary C Lipton.
    2021. [Does pretraining for summarization require knowledge transfer?](https://aclanthology.org/2021.findings-emnlp.273)
    In *Findings of the Association for Computational Linguistics: EMNLP 2021*, pages
    3178–3189.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kushman et al. (2014) Nate Kushman, Yoav Artzi, Luke Zettlemoyer, and Regina
    Barzilay. 2014. [Learning to automatically solve algebra word problems](https://aclanthology.org/P14-1026/).
    In *Proceedings of the 52nd Annual Meeting of the Association for Computational
    Linguistics (ACL)*, pages 271–281.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lample and Charton (2020) Guillaume Lample and François Charton. 2020. [Deep
    learning for symbolic mathematics](https://arxiv.org/abs/1912.01412). In *International
    Conference on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lample et al. (2022) Guillaume Lample, Timothee Lacroix, Marie-Anne Lachaux,
    Aurelien Rodriguez, Amaury Hayat, Thibaut Lavril, Gabriel Ebner, and Xavier Martinet.
    2022. Hypertree proof search for neural theorem proving. *Advances in Neural Information
    Processing Systems (NeurIPS)*, 35:26337–26349.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lan et al. (2022) Yihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian
    Dai, Yan Wang, Dongxiang Zhang, and Ee-Peng Lim. 2022. [Mwptoolkit: an open-source
    framework for deep learning-based math word problem solvers](https://arxiv.org/abs/2109.00799).
    In *Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)*, pages
    13188–13190.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lan et al. (2019) Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel,
    Piyush Sharma, and Radu Soricut. 2019. [Albert: A lite bert for self-supervised
    learning of language representations](https://arxiv.org/abs/1909.11942). *arXiv
    preprint arXiv:1909.11942*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. (1998) Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner.
    1998. [Gradient-based learning applied to document recognition](https://ieeexplore.ieee.org/document/726791).
    *Proceedings of the IEEE*, 86(11):2278–2324.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lewis et al. (2020) Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad,
    Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020.
    [BART: Denoising sequence-to-sequence pre-training for natural language generation,
    translation, and comprehension](https://arxiv.org/abs/1910.13461). In *Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)*,
    pages 7871–7880.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lewkowycz et al. (2022) Aitor Lewkowycz, Anders Johan Andreassen, David Dohan,
    Ethan Dyer, Henryk Michalewski, Vinay Venkatesh Ramasesh, Ambrose Slone, Cem Anil,
    Imanol Schlag, Theo Gutman-Solo, et al. 2022. [Solving quantitative reasoning
    problems with language models](https://arxiv.org/abs/2206.14858). In *Advances
    in Neural Information Processing Systems (NeurIPS)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2019) Jierui Li, Lei Wang, Jipeng Zhang, Yan Wang, Bing Tian Dai,
    and Dongxiang Zhang. 2019. [Modeling intra-relation in math word problems with
    different functional multi-head attentions](https://aclanthology.org/P19-1619/).
    In *Proceedings of the 57th Annual Meeting of the Association for Computational
    Linguistics (ACL)*, pages 6162–6167.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2017) Jiwei Li, Alexander H Miller, Sumit Chopra, Marc’Aurelio Ranzato,
    and Jason Weston. 2017. [Dialogue learning with human-in-the-loop](https://arxiv.org/abs/1611.09823).
    In *International Conference on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2020a) Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and
    Kai-Wei Chang. 2020a. [What does bert with vision look at?](https://aclanthology.org/2020.acl-main.469/)
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics (ACL)*, pages 5265–5275.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2020b) Shucheng Li, Lingfei Wu, Shiwei Feng, Fangli Xu, Fengyuan
    Xu, and Sheng Zhong. 2020b. [Graph-to-tree neural networks for learning structured
    input-output translation with applications to semantic parsing and math word problem](https://arxiv.org/abs/2004.13781).
    In *Findings of the Association for Computational Linguistics (EMNLP)*, pages
    2841–2852.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2021) Wenda Li, Lei Yu, Yuhuai Wu, and Lawrence C Paulson. 2021.
    [Isarstep: a benchmark for high-level mathematical reasoning](https://arxiv.org/abs/2006.09265).
    In *International Conference on Learning Representations (ICLR)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2022a) Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang
    Lou, and Weizhu Chen. 2022a. [On the advance of making language models better
    reasoners](https://arxiv.org/abs/2206.02336). *arXiv preprint arXiv:2206.02336*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2022b) Zhongli Li, Wenxuan Zhang, Chao Yan, Qingyu Zhou, Chao Li,
    Hongzhi Liu, and Yunbo Cao. 2022b. [Seeking patterns, not just memorizing procedures:
    Contrastive learning for solving math word problems](https://arxiv.org/abs/2110.08464).
    In *Findings of the Association for Computational Linguistics (ACL)*, pages 2486–2496.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. (2022a) Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras,
    Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya
    Kumar, et al. 2022a. [Holistic evaluation of language models](https://arxiv.org/abs/2211.09110).
    *arXiv preprint arXiv:2211.09110*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liang and Klein (2009) Percy Liang and Dan Klein. 2009. [Online em for unsupervised
    models](https://aclanthology.org/N09-1069/). In *Proceedings of human language
    technologies: The 2009 annual conference of the North American chapter of the
    association for computational linguistics (NAACL)*, pages 611–619.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liang et al. (2022b) Zhenwen Liang, Jipeng Zhang, Lei Wang, Wei Qin, Yunshi
    Lan, Jie Shao, and Xiangliang Zhang. 2022b. [Mwp-bert: Numeracy-augmented pre-training
    for math word problem solving](https://arxiv.org/abs/2107.13435). In *Findings
    of the Association for Computational Linguistics (NAACL)*, pages 997–1009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. (2020) Bill Yuchen Lin, Seyeon Lee, Rahul Khanna, and Xiang Ren.
    2020. [Birds have four legs?! numersense: Probing numerical commonsense knowledge
    of pre-trained language models](https://arxiv.org/abs/2005.00683). In *Proceedings
    of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)*,
    pages 6862–6868.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. (2021) Xin Lin, Zhenya Huang, Hongke Zhao, Enhong Chen, Qi Liu,
    Hao Wang, and Shijin Wang. 2021. [Hms: A hierarchical solver with dependency-enhanced
    understanding for math word problem](https://ojs.aaai.org/index.php/AAAI/article/view/16547).
    In *Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)*, pages
    4232–4240.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ling et al. (2017) Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom.
    2017. [Program induction by rationale generation: Learning to solve and explain
    algebraic word problems](https://arxiv.org/abs/1705.04146). In *Proceedings of
    the 55th Annual Meeting of the Association for Computational Linguistics (ACL)*,
    pages 158–167.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2022a) Jiachang Liu, Dinghan Shen, Yizhe Zhang, William B Dolan,
    Lawrence Carin, and Weizhu Chen. 2022a. [What makes good in-context examples for
    gpt-3?](https://arxiv.org/abs/2101.06804) In *Proceedings of Deep Learning Inside
    Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for
    Deep Learning Architectures*, pages 100–114.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2022b) Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin,
    Weizhu Chen, and Jian-Guang Lou. 2022b. [TAPEX: Table pre-training via learning
    a neural SQL executor](https://openreview.net/forum?id=O50443AsCP). In *International
    Conference on Learning Representations*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2020) Qianying Liu, Wenyu Guan, Sujian Li, Fei Cheng, Daisuke Kawahara,
    and Sadao Kurohashi. 2020. [Reverse operation based data augmentation for solving
    math word problems](https://arxiv.org/abs/2010.01556). *IEEE Transactions on Audio,
    Speech and Language Processing*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2019a) Qianying Liu, Wenyv Guan, Sujian Li, and Daisuke Kawahara.
    2019a. [Tree-structured decoding for solving math word problems](https://aclanthology.org/D19-1241/).
    In *Proceedings of the 2019 conference on empirical methods in natural language
    processing and the 9th international joint conference on natural language processing
    (EMNLP-IJCNLP)*, pages 2370–2379.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019b) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019b.
    [Roberta: A robustly optimized bert pretraining approach](https://aclanthology.org/N19-1423).
    *Proceedings of the 2019 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies (NAACL-HLT)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loos et al. (2017) Sarah Loos, Geoffrey Irving, Christian Szegedy, and Cezary
    Kaliszyk. 2017. [Deep network guided proof search](https://arxiv.org/abs/1701.06972).
    *arXiv preprint arXiv:1701.06972*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2021a) Pan Lu, Ran Gong, Shibiao Jiang, Liang Qiu, Siyuan Huang,
    Xiaodan Liang, and Song-Chun Zhu. 2021a. [Inter-gps: Interpretable geometry problem
    solving with formal language and symbolic reasoning](https://aclanthology.org/2021.acl-long.528/).
    In *The 59th Annual Meeting of the Association for Computational Linguistics (ACL)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2022a) Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang,
    Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. 2022a. [Learn to
    explain: Multimodal reasoning via thought chains for science question answering](https://arxiv.org/abs/2209.09513).
    In *The 36th Conference on Neural Information Processing Systems (NeurIPS)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2023) Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang,
    Ying Nian Wu, Song-Chun Zhu, and Jianfeng Gao. 2023. Chameleon: Plug-and-play
    compositional reasoning with large language models. *arXiv preprint arXiv:2304.09842*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu et al. (2022b) Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Song-Chun
    Zhu, Tanmay Rajpurohit, Peter Clark, and Ashwin Kalyan. 2022b. [Dynamic prompt
    learning via policy gradient for semi-structured mathematical reasoning](https://arxiv.org/abs/2209.14610).
    In *International Conference on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2021b) Pan Lu, Liang Qiu, Jiaqi Chen, Tony Xia, Yizhou Zhao, Wei
    Zhang, Zhou Yu, Xiaodan Liang, and Song-Chun Zhu. 2021b. [Iconqa: A new benchmark
    for abstract diagram understanding and visual language reasoning](https://arxiv.org/abs/2110.13214).
    In *The 35th Conference on Neural Information Processing Systems (NeurIPS) Track
    on Datasets and Benchmarks*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2022c) Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and
    Pontus Stenetorp. 2022c. [Fantastically ordered prompts and where to find them:
    Overcoming few-shot prompt order sensitivity](https://arxiv.org/abs/2104.08786).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (ACL)*, pages 8086–8098.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: mathlib Community (2020) The mathlib Community. 2020. [The lean mathematical
    library](https://doi.org/10.1145/3372885.3373824). In *CPP 2020 - Proceedings
    of the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs,
    co-located with POPL 2020*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meadows and Freitas (2022) Jordan Meadows and Andre Freitas. 2022. [A survey
    in mathematical language processing](https://arxiv.org/abs/2205.15231). *arXiv
    preprint arXiv:2205.15231*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Megill and Wheeler (2019) Norman D. Megill and David A. Wheeler. 2019. [*Metamath:
    A Computer Language for Mathematical Proofs*](https://us.metamath.org/downloads/metamath.pdf).
    Lulu Press, Morrisville, North Carolina. http://us.metamath.org/downloads/metamath.pdf.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meng and Rumshisky (2019) Yuanliang Meng and Anna Rumshisky. 2019. [Solving
    math word problems with double-decoder transformer](https://arxiv.org/abs/1908.10924).
    *arXiv preprint arXiv:1908.10924*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miao et al. (2020) Shen-Yun Miao, Chao-Chun Liang, and Keh-Yih Su. 2020. [A
    diverse corpus for evaluating and developing english math word problem solvers](https://arxiv.org/abs/2106.15772).
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics (ACL)*, pages 975–984.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Min et al. (2022) Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis,
    Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. [Rethinking the role of demonstrations:
    What makes in-context learning work?](https://arxiv.org/abs/2202.12837) *Proceedings
    of Empirical Methods in Natural Language Processing (EMNLP)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Minaee et al. (2021) Shervin Minaee, Nal Kalchbrenner, Erik Cambria, Narjes
    Nikzad, Meysam Chenaghlu, and Jianfeng Gao. 2021. [Deep learning based text classification:
    a comprehensive review](https://arxiv.org/abs/2004.03705). *ACM Computing Surveys
    (CSUR)*, 54(3):1–40.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mishra et al. (2022a) Swaroop Mishra, Matthew Finlayson, Pan Lu, Leonard Tang,
    Sean Welleck, Chitta Baral, Tanmay Rajpurohit, Oyvind Tafjord, Ashish Sabharwal,
    Peter Clark, and Ashwin Kalyan. 2022a. [Lila: A unified benchmark for mathematical
    reasoning](https://arxiv.org/abs/2210.17517). In *Proceedings of the 2022 Conference
    on Empirical Methods in Natural Language Processing (EMNLP)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mishra et al. (2022b) Swaroop Mishra, Arindam Mitra, Neeraj Varshney, Bhavdeep
    Sachdeva, Peter Clark, Chitta Baral, and Ashwin Kalyan. 2022b. [Numglue: A suite
    of fundamental yet challenging mathematical reasoning tasks](https://aclanthology.org/2022.acl-long.246/).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (ACL)*, pages 3505–3523.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mitchell et al. (2022) Eric Mitchell, Joseph J. Noh, Siyan Li, William S. Armstrong,
    Ananth Agarwal, Patrick Liu, Chelsea Finn, and Christopher D. Manning. 2022. [Enhancing
    self-consistency and performance of pretrained language models with nli](https://ericmitchell.ai/concord.pdf).
    In *Proceedings of the 2022 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*. Association for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moura et al. (2015) Leonardo de Moura, Soonho Kong, Jeremy Avigad, Floris van
    Doorn, and Jakob von Raumer. 2015. [The lean theorem prover (system description)](https://link.springer.com/chapter/10.1007/978-3-319-21401-6_26).
    In *International Conference on Automated Deduction*, pages 378–388\. Springer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nakano et al. (2021) Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,
    Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju,
    William Saunders, et al. 2021. [Webgpt: Browser-assisted question-answering with
    human feedback](https://arxiv.org/abs/2112.09332). *arXiv preprint arXiv:2112.09332*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Newell et al. (1957) Allen Newell, John Clifford Shaw, and Herbert A Simon.
    1957. [Empirical explorations of the logic theory machine: A case study in heuristic](https://doi.org/10.1145/1455567.1455605).
    In *Proceedings of the Western Joint Computer Conference, IRE-AIEE-ACM 1957*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ni et al. (2023) Ansong Ni, Jeevana Priya Inala, Chenglong Wang, Oleksandr Polozov,
    Christopher Meek, Dragomir Radev, and Jianfeng Gao. 2023. [Learning from self-sampled
    correct and partially-correct programs](https://arxiv.org/abs/2205.14318). In
    *International Conference on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nye et al. (2021) Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk
    Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten
    Bosma, David Luan, et al. 2021. [Show your work: Scratchpads for intermediate
    computation with language models](https://arxiv.org/abs/2112.00114). *arXiv preprint
    arXiv:2112.00114*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ouyang et al. (2022) Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, et al. 2022. [Training language models to follow instructions with human
    feedback](https://arxiv.org/abs/2203.02155). In *Advances in Neural Information
    Processing Systems (NeurIPS)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Patel et al. (2021) Arkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021.
    [Are nlp models really able to solve simple math word problems?](https://arxiv.org/abs/2103.07191)
    In *Proceedings of the 2021 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies (NAACL-HIT)*, pages
    2080–2094.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paulson (1994) Lawrence C. Paulson. 1994. [*Isabelle - A Generic Theorem Prover
    (with a contribution by T. Nipkow)*](https://doi.org/10.1007/BFb0030541), volume
    828 of *Lecture Notes in Computer Science*. Springer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Perez et al. (2018) Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin,
    and Aaron Courville. 2018. [Film: Visual reasoning with a general conditioning
    layer](https://arxiv.org/abs/1709.07871). In *Proceedings of the AAAI Conference
    on Artificial Intelligence (AAAI)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polu et al. (2023) Stanislas Polu, Jesse Michael Han, Kunhao Zheng, Mantas Baksys,
    Igor Babuschkin, and Ilya Sutskever. 2023. [Formal mathematics statement curriculum
    learning](https://arxiv.org/abs/2202.01344). In *International Conference on Learning
    Representations (ICLR)*, volume abs/2202.01344.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polu and Sutskever (2020) Stanislas Polu and Ilya Sutskever. 2020. [Generative
    language modeling for automated theorem proving](https://arxiv.org/abs/2009.03393).
    *arXiv preprint arXiv:2009.03393*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qin et al. (2021) Jinghui Qin, Xiaodan Liang, Yining Hong, Jianheng Tang, and
    Liang Lin. 2021. [Neural-symbolic solver for math word problems with auxiliary
    tasks](https://arxiv.org/abs/2107.01431). In *Proceedings of the 59th Annual Meeting
    of the Association for Computational Linguistics and the 11th International Joint
    Conference on Natural Language Processing (ACL)*, pages 5870–5881.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qin et al. (2020) Jinghui Qin, Lihui Lin, Xiaodan Liang, Rumin Zhang, and Liang
    Lin. 2020. [Semantically-aligned universal tree-structured solver for math word
    problems](https://arxiv.org/abs/2010.06823). In *Proceedings of the 2020 Conference
    on Empirical Methods in Natural Language Processing (EMNLP)*, pages 3780–3789.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qiu et al. (2022a) Liang Qiu, Yizhou Zhao, Jinchao Li, Pan Lu, Baolin Peng,
    Jianfeng Gao, and Song-Chun Zhu. 2022a. [Valuenet: A new dataset for human value
    driven dialogue system](https://arxiv.org/abs/2112.06346). In *Proceedings of
    the AAAI Conference on Artificial Intelligence (AAAI)*, pages 2468–2484.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qiu et al. (2022b) Liang Qiu, Yizhou Zhao, Yuan Liang, Pan Lu, Weiyan Shi, Zhou
    Yu, and Song-chun Zhu. 2022b. [Towards socially intelligent agents with mental
    state transition and human value](https://arxiv.org/abs/2103.07011). In *Proceedings
    of the 23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue*,
    pages 146–158.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qiu et al. (2020) Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai,
    and Xuanjing Huang. 2020. [Pre-trained models for natural language processing:
    A survey](https://arxiv.org/abs/2003.08271). *Science China Technological Sciences*,
    63(10):1872–1897.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2020) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario
    Amodei, Ilya Sutskever, et al. 2020. [Language models are unsupervised multitask
    learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf).
    *OpenAI Blog*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rae et al. (2021) Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican,
    Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah
    Young, et al. 2021. [Scaling language models: Methods, analysis & insights from
    training gopher](https://arxiv.org/abs/2112.11446). *arXiv preprint arXiv:2112.11446*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
    Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. [Exploring
    the limits of transfer learning with a unified text-to-text transformer](https://arxiv.org/abs/1910.10683).
    *Journal of Machine Learning Research (JMLR)*, 21:1–67.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ravichander et al. (2019) Abhilasha Ravichander, Aakanksha Naik, Carolyn Rose,
    and Eduard Hovy. 2019. [Equate: A benchmark evaluation framework for quantitative
    reasoning in natural language inference](https://arxiv.org/abs/1901.03735). In
    *Proceedings of the 23rd Conference on Computational Natural Language Learning
    (CoNLL)*, pages 349–361.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Razeghi et al. (2022) Yasaman Razeghi, Robert L Logan IV, Matt Gardner, and
    Sameer Singh. 2022. [Impact of pretraining term frequencies on few-shot numerical
    reasoning](https://aclanthology.org/2022.findings-emnlp.59). In *Findings of the
    Association for Computational Linguistics: EMNLP 2022*, pages 840–854.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren et al. (2015) Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. 2015.
    [Faster r-cnn: Towards real-time object detection with region proposal networks](https://arxiv.org/abs/1506.01497).
    *Advances in neural information processing systems (NeurIPS)*, 28.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ri and Tsuruoka (2022) Ryokan Ri and Yoshimasa Tsuruoka. 2022. [Pretraining
    with artificial language: Studying transferable knowledge in language models](https://arxiv.org/abs/2203.10326).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (ACL)*, pages 7302–7315.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robaidek et al. (2018) Benjamin Robaidek, Rik Koncel-Kedziorski, and Hannaneh
    Hajishirzi. 2018. [Data-driven methods for solving algebra word problems](https://arxiv.org/abs/1804.10718).
    *arXiv preprint arXiv:1804.10718*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roy and Roth (2015) Subhro Roy and Dan Roth. 2015. [Solving general arithmetic
    word problems](https://arxiv.org/abs/1608.01413). In *Proceedings of the 2015
    Conference on Empirical Methods in Natural Language Processing (EMNLP)*, pages
    1743–1752.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roy and Roth (2017) Subhro Roy and Dan Roth. 2017. [Unit dependency graph and
    its application to arithmetic word problem solving](https://arxiv.org/abs/1612.00969).
    In *Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roy and Roth (2018) Subhro Roy and Dan Roth. 2018. [Mapping to declarative knowledge
    for word problem solving](https://arxiv.org/abs/1712.09391). *Transactions of
    the Association for Computational Linguistics (TACL)*, 6:159–172.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roy et al. (2015) Subhro Roy, Tim Vieira, and Dan Roth. 2015. [Reasoning about
    quantities in natural language](https://aclanthology.org/Q15-1001/). *Transactions
    of the Association for Computational Linguistics (TACL)*, 3:1–13.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rubin et al. (2022) Ohad Rubin, Jonathan Herzig, and Jonathan Berant. 2022.
    [Learning to retrieve prompts for in-context learning](https://arxiv.org/abs/2112.08633).
    *North American Chapter of the Association for Computational Linguistics (NAACL)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sachan et al. (2017) Mrinmaya Sachan, Kumar Dubey, and Eric Xing. 2017. [From
    textbooks to knowledge: A case study in harvesting axiomatic knowledge from textbooks
    to solve geometry problems](https://aclanthology.org/D17-1081/). In *Proceedings
    of Empirical Methods in Natural Language Processing (EMNLP)*, pages 773–784.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sachan and Xing (2017) Mrinmaya Sachan and Eric Xing. 2017. [Learning to solve
    geometry problems from natural language demonstrations in textbooks](https://aclanthology.org/S17-1029/).
    In *Proceedings of the 6th Joint Conference on Lexical and Computational Semantics*,
    pages 251–261.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saxton et al. (2020) David Saxton, Edward Grefenstette, Felix Hill, and Pushmeet
    Kohli. 2020. [Analysing mathematical reasoning abilities of neural models](https://arxiv.org/abs/1904.01557).
    In *International Conference on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schuster et al. (2021) Tal Schuster, Ashwin Kalyan, Alex Polozov, and Adam Tauman
    Kalai. 2021. [Programming puzzles](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/3988c7f88ebcb58c6ce932b957b6f332-Abstract-round1.html).
    In *Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS)
    Datasets and Benchmarks Track*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sennrich et al. (2016) Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016.
    [Neural machine translation of rare words with subword units](https://arxiv.org/abs/1508.07909).
    In *Proceedings of the 54th Annual Meeting of the Association for Computational
    Linguistics (ACL)*, pages 1715–1725.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Seo et al. (2015) Minjoon Seo, Hannaneh Hajishirzi, Ali Farhadi, Oren Etzioni,
    and Clint Malcolm. 2015. [Solving geometry problems: Combining text and diagram
    interpretation](https://aclanthology.org/D15-1171/). In *Proceedings of Empirical
    Methods in Natural Language Processing (EMNLP)*, pages 1466–1476.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shen et al. (2021) Jianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang,
    Ming Zhang, and Qun Liu. 2021. [Generate & rank: A multi-task framework for math
    word problems](https://arxiv.org/abs/2109.03034). In *Findings of the Association
    for Computational Linguistics (EMNLP)*, pages 2269–2279.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shen and Jin (2020) Yibin Shen and Cheqing Jin. 2020. [Solving math word problems
    with multi-encoders and multi-decoders](https://aclanthology.org/2020.coling-main.262/).
    In *Proceedings of the 28th International Conference on Computational Linguistics
    (COLING)*, pages 2924–2934.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shi et al. (2015) Shuming Shi, Yuehui Wang, Chin-Yew Lin, Xiaojiang Liu, and
    Yong Rui. 2015. [Automatically solving number word problems by semantic parsing
    and reasoning](https://aclanthology.org/D15-1135/). In *Proceedings of the 2015
    conference on empirical methods in natural language processing (EMNLP)*, pages
    1132–1142.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Song et al. (2019) Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu.
    2019. [Mass: Masked sequence to sequence pre-training for language generation](https://arxiv.org/abs/1905.02450).
    In *36th International Conference on Machine Learning (ICML)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2019) Kai Sun, Dian Yu, Jianshu Chen, Dong Yu, Yejin Choi, and
    Claire Cardie. 2019. [Dream: A challenge data set and models for dialogue-based
    reading comprehension](https://arxiv.org/abs/1902.00164). *Transactions of the
    Association for Computational Linguistics (TACL)*, 7:217–231.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sutskever et al. (2014) Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
    [Sequence to sequence learning with neural networks](https://arxiv.org/abs/1409.3215).
    *Advances in neural information processing systems (NeurIPS)*, 27.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tafjord et al. (2019) Oyvind Tafjord, Peter Clark, Matt Gardner, Wen-tau Yih,
    and Ashish Sabharwal. 2019. [Quarel: A dataset and models for answering questions
    about qualitative relationships](https://arxiv.org/abs/1811.08048). In *Proceedings
    of the AAAI Conference on Artificial Intelligence (AAAI)*, pages 7063–7071.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tai et al. (2015) Kai Sheng Tai, Richard Socher, and Christopher D Manning.
    2015. [Improved semantic representations from tree-structured long short-term
    memory networks](https://arxiv.org/abs/1503.00075). In *Proceedings of the 53rd
    Annual Meeting of the Association for Computational Linguistics and the 7th International
    Joint Conference on Natural Language Processing (ACL)*, pages 1556–1566.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thawani et al. (2022) Avijit Thawani, Jay Pujara, and Ashwin Kalyan. 2022. [Estimating
    numbers without regression](https://mathai2022.github.io/papers/11.pdf). In *36th
    Conference on Neural Information Processing Systems (NeurIPS 2022) Workshop on
    MATH-AI*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thawani et al. (2021) Avijit Thawani, Jay Pujara, Pedro A Szekely, and Filip
    Ilievski. 2021. [Representing numbers in nlp: a survey and a vision](https://aclanthology.org/2021.naacl-main.53).
    In *Proceedings of the 2021 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies (NAACL-HIT)*, pages
    644–656.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ughade and Kumbhar (2019) Shounaak Ughade and Satish Kumbhar. 2019. [Survey
    on mathematical word problem solving using natural language processing](https://ieeexplore.ieee.org/document/8741437).
    In *2019 1st International Conference on Innovations in Information and Communication
    Technology (ICIICT)*, pages 1–5\. IEEE.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Upadhyay and Chang (2015) Shyam Upadhyay and Ming-Wei Chang. 2015. [Draw: A
    challenging and diverse algebra word problem set](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tech_rep.pdf).
    Technical report, Citeseer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Upadhyay and Chang (2017) Shyam Upadhyay and Ming-Wei Chang. 2017. [Annotating
    derivations: A new evaluation strategy and dataset for algebra word problems](https://aclanthology.org/E17-1047/).
    In *Proceedings of the 15th Conference of the European Chapter of the Association
    for Computational Linguistics (ACL)*, pages 494–504.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Urban (2006) Josef Urban. 2006. [Mptp 0.2: Design, implementation, and initial
    experiments](https://link.springer.com/article/10.1007/s10817-006-9032-3). *Journal
    of Automated Reasoning*, 37(1):21–43.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. [Attention
    is all you need](https://arxiv.org/abs/1706.03762). In *Advances in Neural Information
    Processing Systems (NeurIPS)*, pages 5998–6008.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wallace et al. (2019) Eric Wallace, Yizhong Wang, Sujian Li, Sameer Singh, and
    Matt Gardner. 2019. [Do nlp models know numbers? probing numeracy in embeddings](https://arxiv.org/abs/1909.07940).
    In *Proceedings of the 2019 Conference on Empirical Methods in Natural Language
    Processing and the 9th International Joint Conference on Natural Language Processing
    (EMNLP-IJCNLP)*, pages 5307–5315.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2018a) Lei Wang, Yan Wang, Deng Cai, Dongxiang Zhang, and Xiaojiang
    Liu. 2018a. [Translating a math word problem to a expression tree](https://arxiv.org/abs/1811.05632).
    In *Proceedings of the 2018 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 1064–1069.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2018b) Lei Wang, Dongxiang Zhang, Lianli Gao, Jingkuan Song, Long
    Guo, and Heng Tao Shen. 2018b. [Mathdqn: Solving arithmetic word problems via
    deep reinforcement learning](https://ojs.aaai.org/index.php/AAAI/article/view/11981).
    In *Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019) Lei Wang, Dongxiang Zhang, Jipeng Zhang, Xing Xu, Lianli
    Gao, Bing Tian Dai, and Heng Tao Shen. 2019. [Template-based math word problem
    solvers with recursive neural networks](https://ojs.aaai.org/index.php/AAAI/article/view/4697).
    In *Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)*, pages
    7144–7151.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2023) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi,
    and Denny Zhou. 2023. [Self-consistency improves chain of thought reasoning in
    language models](https://arxiv.org/abs/2203.11171). In *International Conference
    on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2017) Yan Wang, Xiaojiang Liu, and Shuming Shi. 2017. [Deep neural
    solver for math word problems](https://aclanthology.org/D17-1088/). In *Proceedings
    of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)*,
    pages 845–854.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi,
    Quoc Le, and Denny Zhou. 2022. [Chain of thought prompting elicits reasoning in
    large language models](https://arxiv.org/abs/2201.11903). *Advances in Neural
    Information Processing Systems (NeurIPS)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Welleck et al. (2021) Sean Welleck, Jiacheng Liu, Ronan Le Bras, Hannaneh Hajishirzi,
    Yejin Choi, and Kyunghyun Cho. 2021. [Naturalproofs: Mathematical theorem proving
    in natural language](https://arxiv.org/abs/2104.01112). In *Thirty-fifth Conference
    on Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Welleck et al. (2022a) Sean Welleck, Jiacheng Liu, Ximing Lu, Hannaneh Hajishirzi,
    and Yejin Choi. 2022a. [Naturalprover: Grounded mathematical proof generation
    with language models](https://arxiv.org/abs/2205.12910). In *Advances in Neural
    Information Processing Systems (NeurIPS)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Welleck et al. (2023) Sean Welleck, Ximing Lu, Peter West, Faeze Brahman, Tianxiao
    Shen, Daniel Khashabi, and Yejin Choi. 2023. [Generating sequences by learning
    to self-correct](https://arxiv.org/abs/2211.00053). In *International Conference
    on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Welleck et al. (2022b) Sean Welleck, Peter West, Jize Cao, and Yejin Choi.
    2022b. [Symbolic brittleness in sequence models: on systematic generalization
    in symbolic mathematics](https://arxiv.org/pdf/2109.13986.pdf). In *AAAI*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wen-Tsun (1986) Wu Wen-Tsun. 1986. [Basic principles of mechanical theorem proving
    in elementary geometries](https://link.springer.com/article/10.1007/BF02328447).
    *Journal of automated Reasoning*, 2(3):221–252.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Whalen (2016) Daniel Whalen. 2016. [Holophrasm: a neural automated theorem
    prover for higher-order logic](https://arxiv.org/abs/1608.02644). *arXiv preprint
    arXiv:1608.02644*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Woo et al. (2018) Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In So Kweon.
    2018. [Cbam: Convolutional block attention module](https://arxiv.org/abs/1807.06521).
    In *Proceedings of the European conference on computer vision (ECCV)*, pages 3–19.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2020) Qinzhuo Wu, Qi Zhang, Jinlan Fu, and Xuan-Jing Huang. 2020.
    [A knowledge-aware sequence-to-tree network for math word problem solving](https://aclanthology.org/2020.emnlp-main.579/).
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 7137–7146.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2021a) Qinzhuo Wu, Qi Zhang, and Zhongyu Wei. 2021a. [An edge-enhanced
    hierarchical graph-to-tree network for math word problem solving](https://aclanthology.org/2021.findings-emnlp.127/).
    In *Findings of the Association for Computational Linguistics (EMNLP)*, pages
    1473–1482.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2021b) Qinzhuo Wu, Qi Zhang, Zhongyu Wei, and Xuan-Jing Huang. 2021b.
    [Math word problem solving with explicit numerical values](https://aclanthology.org/2021.acl-long.455/).
    In *Proceedings of the 59th Annual Meeting of the Association for Computational
    Linguistics and the 11th International Joint Conference on Natural Language Processing
    (ACL)*, pages 5859–5869.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2022a) Xingjiao Wu, Luwei Xiao, Yixuan Sun, Junhang Zhang, Tianlong
    Ma, and Liang He. 2022a. [A survey of human-in-the-loop for machine learning](https://arxiv.org/abs/2108.00941).
    *Future Generation Computer Systems*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2016) Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad
    Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al.
    2016. [Google’s neural machine translation system: Bridging the gap between human
    and machine translation](https://arxiv.org/abs/1609.08144). *arXiv preprint arXiv:1609.08144*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2021c) Yuhuai Wu, Albert Jiang, Jimmy Ba, and Roger Baker Grosse.
    2021c. [Int: An inequality benchmark for evaluating generalization in theorem
    proving](https://arxiv.org/abs/2007.02924). In *International Conference on Learning
    Representations (ICLR)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2022b) Yuhuai Wu, Albert Qiaochu Jiang, Wenda Li, Markus Norman Rabe,
    Charles E Staats, Mateja Jamnik, and Christian Szegedy. 2022b. [Autoformalization
    with large language models](https://openreview.net/forum?id=IUikebJ1Bf0). In *Advances
    in Neural Information Processing Systems (NeurIPS)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2022c) Yuhuai Wu, Felix Li, and Percy Liang. 2022c. [Insights into
    pre-training via simpler synthetic tasks](https://arxiv.org/abs/2206.10139). *arXiv
    preprint arXiv:2206.10139*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2021d) Yuhuai Wu, Markus N Rabe, Wenda Li, Jimmy Ba, Roger B Grosse,
    and Christian Szegedy. 2021d. [Lime: Learning inductive bias for primitives of
    mathematical reasoning](https://arxiv.org/abs/2101.06223). In *International Conference
    on Machine Learning (ICML)*, pages 11251–11262\. PMLR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xie and Sun (2019) Zhipeng Xie and Shichao Sun. 2019. [A goal-driven tree-structured
    neural model for math word problems](https://www.ijcai.org/proceedings/2019/736).
    In *International Joint Conference on Artificial Intelligence (IJCAI)*, pages
    5299–5305.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2015) Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville,
    Ruslan Salakhudinov, Rich Zemel, and Yoshua Bengio. 2015. [Show, attend and tell:
    Neural image caption generation with visual attention](https://arxiv.org/abs/1502.03044).
    In *International conference on machine learning (ICML)*, pages 2048–2057\. PMLR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang and Deng (2019) Kaiyu Yang and Jia Deng. 2019. [Learning to prove theorems
    via interacting with proof assistants](https://arxiv.org/abs/1905.09381). In *International
    Conference on Machine Learning (ICML)*, pages 6984–6994\. PMLR.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ye et al. (2008) Zheng Ye, Shang-Ching Chou, and Xiao-Shan Gao. 2008. [An introduction
    to java geometry expert](https://link.springer.com/chapter/10.1007/978-3-642-21046-4_10).
    In *International workshop on automated deduction in geometry*, pages 189–195\.
    Springer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yu et al. (2021a) Wei Yu, Mengzhu Wang, Xiaodong Wang, Xun Zhou, Yongfu Zha,
    Yongjian Zhang, Shuyu Miao, and Jingdong Liu. 2021a. [Geore: A relation extraction
    dataset for chinese geometry problems](https://mathai4ed.github.io/papers/papers/paper_6.pdf).
    In *35th Conference on Neural Information Processing Systems (NeurIPS) Workshop
    on Math AI for Education (MATHAI4ED)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu et al. (2021b) Weijiang Yu, Yingpeng Wen, Fudan Zheng, and Nong Xiao. 2021b.
    [Improving math word problems with pre-trained knowledge and hierarchical reasoning](https://aclanthology.org/2021.emnlp-main.272/).
    In *Proceedings of the 2021 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 3384–3394.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yu et al. (2023) Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju,
    Soumya Sanyal, Chenguang Zhu, Michael Zeng, and Meng Jiang. 2023. [Generate rather
    than retrieve: Large language models are strong context generators](https://arxiv.org/abs/2209.10063).
    In *International Conference on Learning Representations (ICLR)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zaporojets et al. (2021) Klim Zaporojets, Giannis Bekoulis, Johannes Deleu,
    Thomas Demeester, and Chris Develder. 2021. [Solving arithmetic word problems
    by scoring equations with recursive neural networks](https://arxiv.org/abs/2009.05639).
    *Expert Systems with Applications*, 174:114704.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2019) Dongxiang Zhang, Lei Wang, Luming Zhang, Bing Tian Dai,
    and Heng Tao Shen. 2019. [The gap of semantic parsing: A survey on automatic math
    word problem solvers](https://arxiv.org/abs/1808.07290). *IEEE transactions on
    pattern analysis and machine intelligence*, 42(9):2287–2305.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2020a) Jipeng Zhang, Roy Ka-Wei Lee, Ee-Peng Lim, Wei Qin, Lei
    Wang, Jie Shao, and Qianru Sun. 2020a. [Teacher-student networks with multiple
    decoders for solving math word problem](https://www.ijcai.org/proceedings/2020/555).
    In *International Joint Conference on Artificial Intelligence (IJCAI)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2020b) Jipeng Zhang, Lei Wang, Roy Ka-Wei Lee, Yi Bin, Yan Wang,
    Jie Shao, and Ee-Peng Lim. 2020b. [Graph-to-tree learning for solving math word
    problems](https://aclanthology.org/2020.acl-main.362/). In *Proceedings of the
    58th Annual Meeting of the Association for Computational Linguistics (ACL)*, pages
    3928–3937.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2022) Ming-Liang Zhang, Fei Yin, Yi-Han Hao, and Cheng-Lin Liu.
    2022. [Learning to understand plane geometry diagram](https://mathai2022.github.io/papers/6.pdf).
    In *36th Conference on Neural Information Processing Systems (NeurIPS) Workshop
    on MATH-AI*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2021) Qiyuan Zhang, Lei Wang, Sicheng Yu, Shuohang Wang, Yang
    Wang, Jing Jiang, and Ee-Peng Lim. 2021. [Noahqa: Numerical reasoning with interpretable
    graph question answering dataset](NOAHQA:%20Numerical%20Reasonin). In *Findings
    of the Association for Computational Linguistics (EMNLP)*, pages 4147–4161.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2020c) Wenhe Zhang, Chi Zhang, Yixin Zhu, and Song-Chun Zhu.
    2020c. [Machine number sense: A dataset of visual arithmetic problems for abstract
    and relational reasoning](https://arxiv.org/abs/2004.12193). In *Proceedings of
    the AAAI Conference on Artificial Intelligence (AAAI)*, pages 1332–1340.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2020d) Xikun Zhang, Deepak Ramachandran, Ian Tenney, Yanai Elazar,
    and Dan Roth. 2020d. [Do language embeddings capture scales?](https://aclanthology.org/2020.findings-emnlp.439/)
    In *Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting
    Neural Networks for NLP*, pages 292–299.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2020e) Xikun Zhang, Deepak Ramachandran, Ian Tenney, Yanai Elazar,
    and Dan Roth. 2020e. [Do language embeddings capture scales?](https://doi.org/10.18653/v1/2020.blackboxnlp-1.27)
    In *Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting
    Neural Networks for NLP*, pages 292–299.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2020f) Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris
    Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2020f. [Dialogpt:
    Large-scale generative pre-training for conversational response generation](https://arxiv.org/abs/1911.00536).
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics: System Demonstrations*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2023) Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2023.
    [Automatic chain of thought prompting in large language models](https://arxiv.org/abs/2210.03493).
    In *International Conference on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2020) Wei Zhao, Mingyue Shang, Yang Liu, Liang Wang, and Jingming
    Liu. 2020. [Ape210k: A large-scale and template-rich dataset of math word problems](https://arxiv.org/abs/2009.11506).
    *arXiv preprint arXiv:2009.11506*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2022) Yilun Zhao, Yunxiang Li, Chenying Li, and Rui Zhang. 2022.
    [Multihiertt: Numerical reasoning over multi hierarchical tabular and textual
    data](https://aclanthology.org/2022.acl-long.454/). In *Proceedings of the 60th
    Annual Meeting of the Association for Computational Linguistics (ACL)*, pages
    6588–6600.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2021) Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer
    Singh. 2021. [Calibrate before use: Improving few-shot performance of language
    models](https://arxiv.org/abs/2102.09690). In *International Conference on Machine
    Learning (ICML)*, pages 12697–12706\. PMLR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zheng et al. (2022) Kunhao Zheng, Jesse Michael Han, and Stanislas Polu. 2022.
    [Minif2f: a cross-system benchmark for formal olympiad-level mathematics](https://arxiv.org/abs/2109.00110).
    In *International Conference on Learning Representations (ICLR)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2019) Ben Zhou, Daniel Khashabi, Qiang Ning, and Dan Roth. 2019.
    ["Going on a vacation" takes longer than "Going for a walk": A Study of Temporal
    Commonsense Understanding](https://cogcomp.seas.upenn.edu/papers/ZKNR19.pdf).
    In *Proc. of the Conference on Empirical Methods in Natural Language Processing
    (EMNLP)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2023) Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan
    Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, and Ed Chi. 2023.
    [Least-to-most prompting enables complex reasoning in large language models](https://arxiv.org/abs/2205.10625).
    In *International Conference on Learning Representations (ICLR)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2021) Fengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo
    Zhang, Jiancheng Lv, Fuli Feng, and Tat-Seng Chua. 2021. [Tat-qa: A question answering
    benchmark on a hybrid of tabular and textual content in finance](https://arxiv.org/abs/2105.07624).
    In *Proceedings of the 59th Annual Meeting of the Association for Computational
    Linguistics and the 11th International Joint Conference on Natural Language Processing
    (ACL-JCNLP)*, pages 3277–3287.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Mathematical Reasoning Datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7f72337d9f2db59c1513b961841baee8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Estimated counts of annually published papers on deep learning for
    mathematical reasoning. This field has been experiencing rapid growth since 2018.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will examine the various datasets currently available for
    the study of mathematical reasoning using deep learning methods. A summary of
    the commonly used datasets in this field can be found in [Table 7](#A1.T7 "Table
    7 ‣ A.5 Other Quantitative Problems ‣ Appendix A Mathematical Reasoning Datasets
    ‣ A Survey of Deep Learning for Mathematical Reasoning").
  prefs: []
  type: TYPE_NORMAL
- en: A.1 Math Word Problem Solving
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Developing algorithms to solve math word problems (MWPs) automatically has been
    an interest of NLP researchers for decades Feigenbaum et al. ([1963](#bib.bib35));
    Bobrow ([1964](#bib.bib14)). A math word problem (also termed an algebraic or
    arithmetic word problem) describes a brief narrative that involves characters,
    entities, and quantities. The mathematical relationship of an MWP can be modeled
    with a set of equations whose solution reveals the final answer to the question.
    A typical example is shown in [Table 1](#S2.T1 "Table 1 ‣ 2 Mathematical Reasoning
    Tasks ‣ A Survey of Deep Learning for Mathematical Reasoning"). A question involves
    the four basic arithmetic operations of addition, subtraction, multiplication,
    and division with single or multiple operation steps. The challenge of MWPs for
    NLP systems lies in the need for language comprehension, semantic parsing, and
    multiple mathematical reasoning skills.
  prefs: []
  type: TYPE_NORMAL
- en: Existing MWP datasets cover grade school problems, which are crawled from online
    learning websites Koncel-Kedziorski et al. ([2015](#bib.bib83)), collected from
    textbooks, or manually annotated by human workers Patel et al. ([2021](#bib.bib134)).
    Early math word problem datasets are relatively small or limited to a small number
    of operation steps Hosseini et al. ([2014](#bib.bib61)); Kushman et al. ([2014](#bib.bib85));
    Roy et al. ([2015](#bib.bib155)). Some recently curated datasets aim to increase
    problem diversity and difficulty levels. For example, Ape210K Zhao et al. ([2020](#bib.bib219))
    consists of 210k elementary math word problems, which is the largest publicly
    available. The problems in GSM8K Cobbe et al. ([2021](#bib.bib32)) can involve
    up to 8 steps to solve. SVAMP Patel et al. ([2021](#bib.bib134)) is a benchmark
    that tests the robustness of deep learning models to math word problems with simple
    variations. More recently built datasets involve modalities beyond text. For example,
    IconQA Lu et al. ([2021b](#bib.bib116)) provides an abstract diagram as a visual
    context, while TabMWP Lu et al. ([2022b](#bib.bib115)) provides a tabular context
    for each problem.
  prefs: []
  type: TYPE_NORMAL
- en: Most MWP datasets provide annotated equations as a rationale for the solution
    (e.g., [Table 1](#S2.T1 "Table 1 ‣ 2 Mathematical Reasoning Tasks ‣ A Survey of
    Deep Learning for Mathematical Reasoning")). To improve the performance and interpretability
    of the learned solvers, MathQA Tafjord et al. ([2019](#bib.bib169)) is annotated
    with precise operation programs, and MathQA-Python Austin et al. ([2021](#bib.bib8))
    is provided with specific Python programs instead. Another line of datasets annotates
    the problems with multi-step natural language solutions that are regarded as more
    human-readable Ling et al. ([2017](#bib.bib105)); Cobbe et al. ([2021](#bib.bib32));
    Lu et al. ([2022b](#bib.bib115)). Lila Mishra et al. ([2022a](#bib.bib125)) annotates
    many of the previously mentioned MWP datasets with Python program rationales.
  prefs: []
  type: TYPE_NORMAL
- en: A.2 Theorem Proving
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Recently, there has been increased interest in using language models for theorem
    proving in formal interactive theorem provers (ITP) (e.g., Polu and Sutskever
    ([2020](#bib.bib138)); Han et al. ([2022](#bib.bib51)); Polu et al. ([2023](#bib.bib137));
    Jiang et al. ([2022b](#bib.bib68), [a](#bib.bib66)); Lample et al. ([2022](#bib.bib87))).
    Example ITPs include Lean Moura et al. ([2015](#bib.bib128)), Isabelle Paulson
    ([1994](#bib.bib135)), Coq Barras et al. ([1999](#bib.bib11)), and Metamath Megill
    and Wheeler ([2019](#bib.bib120)). To prove a theorem in an ITP, the theorem is
    stated in the ITP’s programming language, then simplified by generating “proof
    steps” until it is reduced to known facts. The result is a sequence of steps that
    constitutes a verified proof.
  prefs: []
  type: TYPE_NORMAL
- en: Data sources for neural theorem proving in ITPs include interactive learning
    environments that interface with ITPs, and datasets derived from proofs in ITP
    libraries. For example, CoqGym Yang and Deng ([2019](#bib.bib203)) provides an
    interactive environment and 71K human-written proofs for the Coq ITP. For Isabelle,
    PISA Jiang et al. ([2021](#bib.bib67)) enables interaction and provides a dataset
    of 183k proofs mined from the Isabelle standard library and Archive of Formal
    Proofs. For Lean, LeanStep Han et al. ([2022](#bib.bib51)) provides a dataset
    of proof-steps from Lean’s mathematical library along with auxiliary tasks, while
    Lean-Gym Polu et al. ([2023](#bib.bib137)) provides an interactive REPL. The miniF2F
    Zheng et al. ([2022](#bib.bib222)) benchmark aims to provide a shared benchmark
    across ITPs, consisting of 488 problem statements sourced from mathematical competitions.
  prefs: []
  type: TYPE_NORMAL
- en: Other resources provide proxy environments or tasks. For example, INT Wu et al.
    ([2021c](#bib.bib197)) provide a synthetic proving environment to measure six
    different types of generalization. [Li et al.](#bib.bib97) construct IsarStep
    using the Isabelle Archive of Formal Proofs, and propose a task of filling in
    a missing intermediate proposition. Early applications of deep learning for formal
    theorem proving focus on selecting relevant premises Alemi et al. ([2016](#bib.bib1)).
  prefs: []
  type: TYPE_NORMAL
- en: Informal theorem proving presents an alternative medium for theorem proving,
    in which statements and proofs are written in the mixture of natural language
    and symbols used in “standard” mathematics (e.g., in LaTeX), and are checked for
    correctness by humans. Early work focuses on selecting relevant premises Ferreira
    and Freitas ([2020b](#bib.bib38), [a](#bib.bib37)). Welleck et al. ([2021](#bib.bib185))
    develop NaturalProofs, a large-scale dataset of 32k informal mathematical theorems,
    definitions, and proofs, and provide a benchmark for premise selection via retrieval
    and generation tasks. Welleck et al. ([2022a](#bib.bib186)) adapt NaturalProofs
    for full proof generation, and provide a human evaluation protocol and proxy automatic
    metrics.
  prefs: []
  type: TYPE_NORMAL
- en: An emerging area of research aims to combine elements of informal and formal
    theorem proving. For example, Wu et al. ([2022b](#bib.bib198)) explore translating
    informal statements into formal statements, while Jiang et al. ([2022a](#bib.bib66))
    release a new version of the miniF2F benchmark augmented with informal statements
    and proofs, which we refer to as miniF2F+informal. Jiang et al. ([2022a](#bib.bib66))
    explore translating provided (or generated) informal proofs into formal proofs.
  prefs: []
  type: TYPE_NORMAL
- en: A.3 Geometry Problem Solving
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Automated geometry problem solving (GPS) is also a long-standing AI task in
    mathematical reasoning research Gelernter et al. ([1960](#bib.bib45)); Wen-Tsun
    ([1986](#bib.bib189)); Chou et al. ([1996](#bib.bib29)); Ye et al. ([2008](#bib.bib204))
    and has attracted much attention in recent years. Different from a math word problem,
    a geometry problem consists of a textual description in natural language and a
    geometric diagram. As shown in [Figure 2](#S2.F2 "Figure 2 ‣ 2 Mathematical Reasoning
    Tasks ‣ A Survey of Deep Learning for Mathematical Reasoning"), the multimodal
    inputs describe the entities, attributes, and relationships of geometric elements,
    and the goal is to find the numeric solution to an unknown variable. GPS is a
    challenging task for deep learning methods due to the complex skills it requires.
    It involves the ability to parse multimodal information, perform symbolic abstraction,
    utilize theorem knowledge, and conduct quantitative reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: Some early datasets are proposed to facilitate research in this domain Seo et al.
    ([2015](#bib.bib162)); Alvin et al. ([2017](#bib.bib3)); Sachan et al. ([2017](#bib.bib157));
    Sachan and Xing ([2017](#bib.bib158)). However, these datasets are relatively
    small or not publicly available, which limits the development of deep learning
    methods. In response to this limitation, [Lu et al.](#bib.bib112) create the Geometry3K
    dataset, which consists of 3,002 multi-choice geometry problems with unified logic
    form annotations for the multimodal inputs. More recently, larger-scale datasets
    such as GeoQA Chen et al. ([2021a](#bib.bib20)), GeoQA+ Cao and Xiao ([2022](#bib.bib16)),
    and UniGeo Chen et al. ([2022a](#bib.bib19)) have been introduced and are annotated
    with programs that can be learned by neural solvers and executed to obtain the
    final answers.
  prefs: []
  type: TYPE_NORMAL
- en: A.4 Math Question Answering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Numerical reasoning is a core ability within human intelligence and plays an
    important role in many NLP tasks. Aside from theorem proving and grade-level math
    word problem solving, there is a wide range of question answering (QA) benchmarks
    that center around mathematical reasoning. In this work, we refer to these tasks
    as math question answering (MathQA). A large number of datasets have been presented
    recently. For example, QuaRel Tafjord et al. ([2019](#bib.bib169)) is a dataset
    of diverse story questions that involve 19 different types of quantities. McTaco
    Zhou et al. ([2019](#bib.bib223)) studies temporal commonsense problems, while
    Fermi Kalyan et al. ([2021](#bib.bib74)) studies Fermi problems whose answers
    can only be approximately estimated.
  prefs: []
  type: TYPE_NORMAL
- en: Recent studies have shown that state-of-the-art mathematical reasoning systems
    might suffer from brittleness in reasoning, in that the models rely on spurious
    signals and plug-and-chug calculations in the specific dataset to achieve “satisfactory”
    performance Hendrycks et al. ([2021b](#bib.bib55)); Mishra et al. ([2022b](#bib.bib126)).
    To address this issue, new benchmarks are proposed from various aspects. The Mathematics
    dataset Saxton et al. ([2020](#bib.bib159)) consists of many different types of
    mathematics problems, covering arithmetic, algebra, probability, and calculus.
    The dataset allows for measuring the algebraic generalization ability of a model.
    Similarly, MATH Hendrycks et al. ([2021b](#bib.bib55)) consists of challenging
    competition mathematics to measure the problem-solving ability of models in complex
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Some work incorporates tabular contexts in the question inputs. For example,
    FinQA Chen et al. ([2021c](#bib.bib24)), TAT-QA Zhu et al. ([2021](#bib.bib225)),
    and MultiHiertt Zhao et al. ([2022](#bib.bib220)) collect questions that require
    both table understanding and numeric reasoning to answer. Others, instead, present
    large-scale unified benchmarks for mathematical reasoning Mishra et al. ([2022b](#bib.bib126),
    [a](#bib.bib125)); Chen et al. ([2023](#bib.bib23)). NumGLUE Mishra et al. ([2022b](#bib.bib126))
    is a multi-task benchmark with the goal of evaluating the performance of models
    on eight different tasks. Mishra et al. [2022a](#bib.bib125) push this direction
    further and presents Lila, which consists of 23 mathematical reasoning tasks,
    spanning a wide range of mathematics topics, linguistic complexity, question formats,
    and background knowledge requirements.
  prefs: []
  type: TYPE_NORMAL
- en: A.5 Other Quantitative Problems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Numbers are an integral part of our daily lives, and we humans reason with numbers
    in a variety of tasks, such as understanding news, reports, elections, and markets.
    This has led many in the community to question whether AI systems can effectively
    perform quantitative reasoning in everyday scenarios. To this end, various benchmarks
    have been developed to evaluate the capabilities of AI systems in this area.
  prefs: []
  type: TYPE_NORMAL
- en: Diagrams, such as figures, charts, and plots, are essential media that convey
    large amounts of information in a concise way. FigureQA Kahou et al. ([2018](#bib.bib72)),
    DVQA Kafle et al. ([2018](#bib.bib71)), MNS Zhang et al. ([2020c](#bib.bib214)),
    PGDP5K Hao et al. ([2022](#bib.bib52)), and GeoRE Yu et al. ([2021a](#bib.bib205)),
    are released to investigate models’ abilities to reason about quantitative relationships
    among entities grounded in diagrams. NumerSense Lin et al. ([2020](#bib.bib103)),
    instead, examines whether and to what extent existing pre-trained language models
    can induce numerical commonsense knowledge. EQUATE Ravichander et al. ([2019](#bib.bib147))
    formalizes aspects of quantitative reasoning in a natural language inference framework.
    Quantitative reasoning can appear frequently in specific domains like finance,
    science, and programming. For instance, the ConvFinQA Chen et al. ([2022c](#bib.bib25))
    targets numerical reasoning over financial reports in a conversational question
    answering format. ScienceQA Lu et al. ([2022a](#bib.bib113)) involves numerical
    reasoning in scientific domains, while P3 Schuster et al. ([2021](#bib.bib160))
    studies the function inference ability of deep learning models to find a valid
    input which makes the given program return True.
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Task | Size | Input | Output | Rationale | Domain |'
  prefs: []
  type: TYPE_TB
- en: '| Verb395 ([2014](#bib.bib61)) | MWP | 395 | Question | Number | Equation |
    Math |'
  prefs: []
  type: TYPE_TB
- en: '| Alg514 ([2014](#bib.bib85)) | MWP | 514 | Question | Number | Equation |
    Math |'
  prefs: []
  type: TYPE_TB
- en: '| IL ([2015](#bib.bib155)) | MWP | - | Question | Number | Equation | Math
    |'
  prefs: []
  type: TYPE_TB
- en: '| SingleEQ ([2015](#bib.bib83)) | MWP | 508 | Question | Number | Equation
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| DRAW ([2015](#bib.bib174)) | MWP | 1,000 | Question | Number | Equation |
    Math |'
  prefs: []
  type: TYPE_TB
- en: '| Dolphin1878 ([2015](#bib.bib165)) | MWP | 1,878 | Question | Number | Equation
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| Dolphin18K ([2016](#bib.bib65)) | MWP | 18,460 | Question | Number | Equation
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| MAWPS ([2016](#bib.bib82)) | MWP | 3,320 | Question | Number | Equation |
    Math |'
  prefs: []
  type: TYPE_TB
- en: '| AllArith ([2017](#bib.bib153)) | MWP | 831 | Question | Number | Equation
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| DRAW-1K ([2017](#bib.bib175)) | MWP | 1,000 | Question | Number | Equation
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| Math23K ([2017](#bib.bib183)) | MWP | 23,162 | Question | Number | Equation
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| AQuA ([2017](#bib.bib105)) | MWP | 100,000 | Question | Option | Natural
    language | Math |'
  prefs: []
  type: TYPE_TB
- en: '| Aggregate ([2018](#bib.bib154)) | MWP | 1,492 | Question | Number | Equation
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| MathQA ([2019](#bib.bib4)) | MWP | 37,297 | Question | Number | Program |
    Math |'
  prefs: []
  type: TYPE_TB
- en: '| ASDiv ([2020](#bib.bib122)) | MWP | 2,305 | Question | Number | Equation
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| HMWP ([2020](#bib.bib140)) | MWP | 5,470 | Question | Number | Equation |
    Math |'
  prefs: []
  type: TYPE_TB
- en: '| Ape210K ([2020](#bib.bib219)) | MWP | 210,488 | Question | Number | Equation
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| SVAMP ([2021](#bib.bib134)) | MWP | 1,000 | Question | Number | Equation
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| GSM8K ([2021](#bib.bib32)) | MWP | 8,792 | Question | Number | Natural language
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| IconQA ([2021b](#bib.bib116)) | MWP | 107,439 | Figure+Question | Option+Text
    span | ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| MathQA-Python ([2021](#bib.bib8)) | MWP | 23,914 | Question | Number | Python
    program | Math |'
  prefs: []
  type: TYPE_TB
- en: '| ArMATH ([2022](#bib.bib2)) | MWP | 6,000 | Question | Number | Equation |
    Math |'
  prefs: []
  type: TYPE_TB
- en: '| TabMWP ([2022b](#bib.bib115)) | MWP | 38,431 | Table+Question | Option+Number
    | Natural language | Math |'
  prefs: []
  type: TYPE_TB
- en: '| MML ([2015](#bib.bib49)) | TP | 57,882 | Statement | Proof steps | ✗ | Math
    |'
  prefs: []
  type: TYPE_TB
- en: '| HolStep ([2017](#bib.bib73)) | TP | 2,209,076 | Statement | Proof steps |
    ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| Gamepad ([2019](#bib.bib62)) | TP | - | Statement | Proof steps | ✗ | Math
    |'
  prefs: []
  type: TYPE_TB
- en: '| CoqGym ([2019](#bib.bib203)) | TP | 71,000 | Statement | Proof steps | ✗
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| HOList ([2019](#bib.bib10)) | TP | 29,462 | Statement | Proof steps | ✗ |
    Math |'
  prefs: []
  type: TYPE_TB
- en: '| IsarStep ([2021](#bib.bib97)) | TP | 860,000 | Statement | Proof steps |
    ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| PISA ([2021](#bib.bib67)) | TP | 183,000 | Statement | Proof steps | ✗ |
    Math |'
  prefs: []
  type: TYPE_TB
- en: '| INT ([2021c](#bib.bib197)) | TP | - | Statement | Proof steps | ✗ | Math
    |'
  prefs: []
  type: TYPE_TB
- en: '| NaturalProofs ([2021](#bib.bib185)) | TP | 32,000 | Statement | Proof steps
    | ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| NaturalProofs-Gen ([2022a](#bib.bib186)) | TP | 14,500 | Statement | Proof
    steps | ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| miniF2F ([2022](#bib.bib222)) | TP | 488 | Statement | Proof steps | ✗ |
    Math |'
  prefs: []
  type: TYPE_TB
- en: '| miniF2F+informal ([2022a](#bib.bib66)) | TP | 488 | Statement | Proof steps
    | ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| LeanStep ([2022](#bib.bib51)) | TP | 21,606,000 | Statement | Proof steps
    | ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| GEOS ([2015](#bib.bib162)) | GPS | 186 | Figure+Question | Option | ✗ | Geometry
    |'
  prefs: []
  type: TYPE_TB
- en: '| GeoShader ([2017](#bib.bib3)) | GPS | 102 | Figure+Question | Number | ✗
    | Geometry |'
  prefs: []
  type: TYPE_TB
- en: '| GEOS++ ([2017](#bib.bib157)) | GPS | 1,406 | Figure+Question | Number | ✗
    | Geometry |'
  prefs: []
  type: TYPE_TB
- en: '| GEOS-OS ([2017](#bib.bib158)) | GPS | 2,235 | Figure+Question | Option |
    Demonstration | Geometry |'
  prefs: []
  type: TYPE_TB
- en: '| Geometry3K ([2021a](#bib.bib112)) | GPS | 3,002 | Figure+Question | Option
    | Logical form | Geometry |'
  prefs: []
  type: TYPE_TB
- en: '| GeoQA ([2021a](#bib.bib20)) | GPS | 4,998 | Figure+Question | Option | Program
    | Geometry |'
  prefs: []
  type: TYPE_TB
- en: '| GeoQA+ ([2022](#bib.bib16)) | GPS | 12,054 | Figure+Question | Option | Program
    | Geometry |'
  prefs: []
  type: TYPE_TB
- en: '| UniGeo ([2022a](#bib.bib19)) | GPS/TP | 14,541 | Figure+Question | Option
    | Program | Geometry |'
  prefs: []
  type: TYPE_TB
- en: '| Quarel ([2019](#bib.bib169)) | MathQA | 2,771 | Question | Option | Logical
    form | Math |'
  prefs: []
  type: TYPE_TB
- en: '| McTaco ([2019](#bib.bib223)) | MathQA | 13,225 | Text+Question | Option |
    ✗ | Time |'
  prefs: []
  type: TYPE_TB
- en: '| DROP ([2019](#bib.bib34)) | MathQA | 96,567 | Passage+Question | Number+Text
    span | ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| Mathematics ([2020](#bib.bib159)) | MathQA | 2,010,000 | Question | Free-form
    | Number | Math |'
  prefs: []
  type: TYPE_TB
- en: '| FinQA ([2021c](#bib.bib24)) | MathQA | 8,281 | Text+Table+Q | Number | Program
    | Finance |'
  prefs: []
  type: TYPE_TB
- en: '| Fermi ([2021](#bib.bib74)) | MathQA | 11,000 | Question | Number | Program+Fact
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| MATH ([2021b](#bib.bib55)) | MathQA | 12,500 | Question | Number | Natural
    language | Math |'
  prefs: []
  type: TYPE_TB
- en: '| TAT-QA ([2021](#bib.bib225)) | MathQA | 16,552 | Text+Table+Q | Number+Text
    span | ✗ | Finance |'
  prefs: []
  type: TYPE_TB
- en: '| AMPS ([2021b](#bib.bib55)) | MathQA | 5,000,000 | Question | - | LaTeX |
    Math |'
  prefs: []
  type: TYPE_TB
- en: '| MultiHiertt ([2022](#bib.bib220)) | MathQA | 10,440 | Text+Table+Q | Number+Text
    span | Expression | Finance |'
  prefs: []
  type: TYPE_TB
- en: '| NumGLUE ([2022b](#bib.bib126)) | MathQA | 101,835 | Text+Question | Number+Text
    span | ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| Lila ([2022a](#bib.bib125)) | MathQA | 134,000 | Text+Question | Free-form
    | Python program | Math |'
  prefs: []
  type: TYPE_TB
- en: '| FigureQA ([2018](#bib.bib72)) | VQA | 1,000,000+ | Figure+Question | Binary
    | ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| DVQA ([2018](#bib.bib71)) | VQA | 3,487,194 | Figure+Question | Text span
    | Number+Text span | Math |'
  prefs: []
  type: TYPE_TB
- en: '| DREAM ([2019](#bib.bib167)) | ConvQA | 10,197 | Dialog+Question | Option
    | ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| EQUATE ([2019](#bib.bib147)) | NLI | - | Premise+Hypothesis | Binary | ✗
    | Math |'
  prefs: []
  type: TYPE_TB
- en: '| NumerSense ([2020](#bib.bib103)) | Filling | 13,600 | Masked question | Word
    | ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| MNS ([2020c](#bib.bib214)) | IQ Test | - | Figure | Number | ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| P3 ([2021](#bib.bib160)) | Puzzle | 397 | Text | Program | ✗ | Math |'
  prefs: []
  type: TYPE_TB
- en: '| NOAHQA ([2021](#bib.bib213)) | ConvQA | 21,347 | Dialog+Question | Text span
    | Reasoning graph | Math |'
  prefs: []
  type: TYPE_TB
- en: '| ConvFinQA ([2022c](#bib.bib25)) | ConvQA | 3,892 | Report+Dialog+Q | Number
    | Expression | Math |'
  prefs: []
  type: TYPE_TB
- en: '| PGDP5K ([2022](#bib.bib52)) | Parsing | 5,000 | Figure+Question | Number
    | ✗ | Geometry |'
  prefs: []
  type: TYPE_TB
- en: '| GeoRE ([2022a](#bib.bib19)) | Parsing | 12,901 | Figure+Question | Number
    | ✗ | Geometry |'
  prefs: []
  type: TYPE_TB
- en: '| ScienceQA ([2022a](#bib.bib113)) | VQA | 21,208 | Context+Question | Option
    | Natural language | Science |'
  prefs: []
  type: TYPE_TB
- en: 'Table 7: A summarization of mathematical reasoning datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Paper | Task | Problem | Network | Encod | Decod | ATT | Description |'
  prefs: []
  type: TYPE_TB
- en: '| DNS Wang et al. ([2017](#bib.bib183)) | MWP | Generation | Seq2Seq | GRU
    | LSTM | ✗ | The first deep MWP solver |'
  prefs: []
  type: TYPE_TB
- en: '| AnsRat Ling et al. ([2017](#bib.bib105)) | MWP | Generation | Seq2Seq | LSTM
    | LSTM | ✗ | Trained with staged back-propagation |'
  prefs: []
  type: TYPE_TB
- en: '| Math-EN Wang et al. ([2018a](#bib.bib179)) | MWP | Generation | Seq2Seq |
    BiLSTM | LSTM | ✔ | A standard Seq2Seq model with attention |'
  prefs: []
  type: TYPE_TB
- en: '| CASS Huang et al. ([2018](#bib.bib63)) | MWP | Generation | Seq2Seq | BiGRU
    | BiGRU | ✔ | Copy and alignment with RL |'
  prefs: []
  type: TYPE_TB
- en: '| S-Aligned Chiang and Chen ([2019](#bib.bib26)) | MWP | Generation | Seq2Seq
    | BiLSTM | LSTM | ✔ | Operating symbols |'
  prefs: []
  type: TYPE_TB
- en: '| T-RNN Wang et al. ([2019](#bib.bib181)) | MWP | Generation | Seq2Seq | BiLSTM
    | BiLSTM | ✔ | Predicting a tree-structure math template |'
  prefs: []
  type: TYPE_TB
- en: '| GROUP-ATT Li et al. ([2019](#bib.bib93)) | MWP | Generation | Seq2Seq | BiLSTM
    | LSTM | ✔ | Group attention |'
  prefs: []
  type: TYPE_TB
- en: '| SMART Hong et al. ([2021b](#bib.bib60)) | MWP | Generation | Seq2Seq | -
    | - | ✗ | Explicitly incorporating values |'
  prefs: []
  type: TYPE_TB
- en: '| SelfAtt Robaidek et al. ([2018](#bib.bib151)) | GPS | Classification | Seq2Seq
    | BiLSTM | - | ✔ | Multi-hop self-attention |'
  prefs: []
  type: TYPE_TB
- en: '| QuaSP+ Tafjord et al. ([2019](#bib.bib169)) | MathQA | Generation | Seq2Seq
    | BiLSTM | LSTM | ✗ | Adopting attributed grammar |'
  prefs: []
  type: TYPE_TB
- en: '| AST-Dec Liu et al. ([2019a](#bib.bib109)) | MWP | Generation | Seq2Tree |
    BiLSTM | Tree | ✔ | Using prefix order decoding |'
  prefs: []
  type: TYPE_TB
- en: '| GTS Xie and Sun ([2019](#bib.bib201)) | MWP | Generation | Seq2Tree | BiGRU
    | Tree | ✔ | A goal-driven tree-structured approach |'
  prefs: []
  type: TYPE_TB
- en: '| KA-S2T Wu et al. ([2020](#bib.bib192)) | MWP | Generation | Seq2Tree | BiLSTM
    | Tree | ✔ | A knowledge-aware method |'
  prefs: []
  type: TYPE_TB
- en: '| TSN-MD Zhang et al. ([2020a](#bib.bib210)) | MWP | Generation | Seq2Tree
    | BiGRU | Tree | ✔ | A teacher-student network |'
  prefs: []
  type: TYPE_TB
- en: '| T-LSTM Zaporojets et al. ([2021](#bib.bib208)) | MWP | Generation | Seq2Tree
    | BiLSTM | Tree | ✗ | A child-sum tree-LSTM model |'
  prefs: []
  type: TYPE_TB
- en: '| NT-LSTM Zaporojets et al. ([2021](#bib.bib208)) | MWP | Generation | Seq2Tree
    | BiLSTM | Tree | ✗ | An N-ary tree-LSTM model |'
  prefs: []
  type: TYPE_TB
- en: '| NS-Solver Qin et al. ([2021](#bib.bib139)) | MWP | Generation | Seq2Tree
    | BiGRU | Tree | ✔ | A neural-symbolic solver with programs |'
  prefs: []
  type: TYPE_TB
- en: '| NumS2T Wu et al. ([2021b](#bib.bib194)) | MWP | Generation | Seq2Tree | BiLSTM
    | Tree | ✔ | Explicitly incorporating values |'
  prefs: []
  type: TYPE_TB
- en: '| HMS Lin et al. ([2021](#bib.bib104)) | MWP | Generation | Seq2Tree | GRU
    | Tree | ✔ | A word-clause-problem encoder |'
  prefs: []
  type: TYPE_TB
- en: '| LBF Hong et al. ([2021a](#bib.bib59)) | MWP | Generation | Seq2Tree | BiGRU
    | Tree | ✔ | A learning-by-fixing (LBF) framework |'
  prefs: []
  type: TYPE_TB
- en: '| Seq2DAG Cao et al. ([2021](#bib.bib17)) | MWP | Generation | Seq2Graph |
    GRU | Graph | ✗ | A direct acyclic graph (DAG) structure |'
  prefs: []
  type: TYPE_TB
- en: '| Graph2Tree Zhang et al. ([2020b](#bib.bib211)) | MWP | Generation | Graph2Tree
    | Graph | Tree | ✗ | Generating better solution expressions |'
  prefs: []
  type: TYPE_TB
- en: '| Multi-E/D Shen and Jin ([2020](#bib.bib164)) | MWP | Generation | Graph2Tree
    | Graph | Tree | ✔ | A graph encoder and a tree-bad decoder |'
  prefs: []
  type: TYPE_TB
- en: '| Graph2Tree Li et al. ([2020b](#bib.bib96)) | MWP | Generation | Graph2Tree
    | Graph | Tree | ✔ | A graph-to-tree neural network |'
  prefs: []
  type: TYPE_TB
- en: '| EEH-G2T Wu et al. ([2021a](#bib.bib193)) | MWP | Generation | Graph2Tree
    | Graph | Tree | ✗ | A hierarchical graph-to-tree model |'
  prefs: []
  type: TYPE_TB
- en: '| ASTactic Yang and Deng ([2019](#bib.bib203)) | TP | Generation | Tree2Seq
    | TreeLSTM | GRU | ✔ | Generating tactics as programs |'
  prefs: []
  type: TYPE_TB
- en: '| MathDQN Wang et al. ([2018b](#bib.bib180)) | MWP | Search | DQN | - | - |
    ✗ | RL with a deep Q-network (DQN) |'
  prefs: []
  type: TYPE_TB
- en: '| DDT Meng and Rumshisky ([2019](#bib.bib121)) | MWP | Generation | Transformer
    | Trm | Trm | ✔ | A Transformer-based model |'
  prefs: []
  type: TYPE_TB
- en: '| DeepMath Alemi et al. ([2016](#bib.bib1)) | TP | Classification | CNN | CNN
    | - | ✗ | The first deep large scale theorem prover |'
  prefs: []
  type: TYPE_TB
- en: '| Holophrasm Whalen ([2016](#bib.bib190)) | TP | Classification | BiGRU | BiGRU
    | - | ✗ | A neural prover for higher-order logic |'
  prefs: []
  type: TYPE_TB
- en: '| CNNTP Loos et al. ([2017](#bib.bib111)) | TP | Classification | CNN | CNN
    | - | ✗ | A CNN-based theorem prover |'
  prefs: []
  type: TYPE_TB
- en: '| WaveNetTP Loos et al. ([2017](#bib.bib111)) | TP | Classification | WaveNet
    | WaveNet | - | ✗ | A WaveNet-based theorem prover |'
  prefs: []
  type: TYPE_TB
- en: '| DeepHOL Bansal et al. ([2019](#bib.bib10)) | TP | Generation | WaveNet |
    WaveNet | - | ✗ | A neural theorem prover with RL |'
  prefs: []
  type: TYPE_TB
- en: '| NGS Chen et al. ([2021a](#bib.bib20)) | GPS | Generation | VQA | LSTM* |
    LSTM | ✔ | The first deep geometry solver |'
  prefs: []
  type: TYPE_TB
- en: '| PGDPNet Zhang et al. ([2022](#bib.bib212)) | Parsing | Generation | GNN |
    - | - | ✗ | A neural diagram parser with GNN |'
  prefs: []
  type: TYPE_TB
- en: 'Table 8: A summarization of deep neural network models for mathematical reasoning.
    Encod: encoder, Decod: decoder, ATT: Attention. LSTM*: ResNet + LSTM, Trm: Transformer'
  prefs: []
  type: TYPE_NORMAL
