- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 20:06:46'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[1901.03407] Deep Learning for Anomaly Detection: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1901.03407](https://ar5iv.labs.arxiv.org/html/1901.03407)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'missing 2⟧E_#1⟦ #2 ⟧ 1⟧⟦#1 ⟧ 1⟧¹¹1Sanjay: #1'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep Learning for Anomaly Detection: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Raghavendra Chalapathy
  prefs: []
  type: TYPE_NORMAL
- en: University of Sydney,
  prefs: []
  type: TYPE_NORMAL
- en: Capital Markets Co-operative Research Centre (CMCRC)
  prefs: []
  type: TYPE_NORMAL
- en: rcha9612@uni.sydney.edu.au
  prefs: []
  type: TYPE_NORMAL
- en: '&Sanjay Chawla'
  prefs: []
  type: TYPE_NORMAL
- en: Qatar Computing Research Institute (QCRI), HBKU
  prefs: []
  type: TYPE_NORMAL
- en: schawla@qf.org.qa
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Anomaly detection is an important problem that has been well-studied within
    diverse research areas and application domains. The aim of this survey is two-fold,
    firstly we present a structured and comprehensive overview of research methods
    in deep learning-based anomaly detection. Furthermore, we review the adoption
    of these methods for anomaly across various application domains and assess their
    effectiveness. We have grouped state-of-the-art deep anomaly detection research
    techniques into different categories based on the underlying assumptions and approach
    adopted. Within each category, we outline the basic anomaly detection technique,
    along with its variants and present key assumptions, to differentiate between
    normal and anomalous behavior. Besides, for each category, we also present the
    advantages and limitations and discuss the computational complexity of the techniques
    in real application domains. Finally, we outline open issues in research and challenges
    faced while adopting deep anomaly detection techniques for real-world problems.
  prefs: []
  type: TYPE_NORMAL
- en: '*K*eywords anomalies, outlier, novelty, deep learning'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A common need when analyzing real-world data-sets is determining which instances
    stand out as being dissimilar to all others. Such instances are known as *anomalies*,
    and the goal of *anomaly detection* (also known as *outlier detection*) is to
    determine all such instances in a data-driven fashion (chandola2007outlier). Anomalies
    can be caused by errors in the data but sometimes are indicative of a new, previously
    unknown, underlying process;  hawkins defines an outlier as an observation that
    deviates so significantly from other observations as to arouse suspicion that
    it was generated by a different mechanism. In the broader field of machine learning,
    the recent years have witnessed a proliferation of deep neural networks, with
    unprecedented results across various application domains. Deep learning is a subset
    of machine learning that achieves good performance and flexibility by learning
    to represent the data as a nested hierarchy of concepts within layers of the neural
    network. Deep learning outperforms the traditional machine learning as the scale
    of data increases as illustrated in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Deep Learning for Anomaly Detection: A Survey"). In recent years, deep learning-based
    anomaly detection algorithms have become increasingly popular and have been applied
    for a diverse set of tasks as illustrated in Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction
    ‣ Deep Learning for Anomaly Detection: A Survey"); studies have shown that deep
    learning completely surpasses traditional methods  (javaid2016deep; peng2015multi).
    The aim of this survey is two-fold, firstly we present a structured and comprehensive
    review of research methods in deep anomaly detection (DAD). Furthermore, we also
    discuss the adoption of DAD methods across various application domains and assess
    their effectiveness.'
  prefs: []
  type: TYPE_NORMAL
- en: ⟦h⟧ ![Refer to caption](img/7310de803425b6effac1396bba508f25.png)scale=0.5⟧images/traditionalVsDeepLearning
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1: Performance Comparison of Deep learning-based algorithms Vs Traditional
    Algorithms deeplearningVstraditionalAlgorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: ⟦h⟧ ![Refer to caption](img/7310de803425b6effac1396bba508f25.png)scale=0.5⟧images/applications
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2: Applications Deep learning-based anomaly detection algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: '(a) Video Surveillance, Image Analysis: Illegal Traffic detection xie2017real,
    (b) Health-care: Detecting Retinal Damage schlegl2017unsupervised'
  prefs: []
  type: TYPE_NORMAL
- en: '(c) Networks: Cyber-intrusion detection javaid2016deep (d) Sensor Networks:
    Internet of Things (IoT) big-data anomaly detection mohammadi2017deep'
  prefs: []
  type: TYPE_NORMAL
- en: 2 What are anomalies?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Anomalies are also referred to as abnormalities, deviants, or outliers in the
    data mining and statistics literature (aggarwal2013introduction). As illustrated
    in Figure  [4](#S2.F4 "Figure 4 ‣ 2 What are anomalies? ‣ Deep Learning for Anomaly
    Detection: A Survey"), $N_{1}$ and $N_{2}$ are regions consisting of a majority
    of observations and hence considered as normal data instance regions, whereas
    the region $O_{3}$, and data points $O_{1}$ and $O_{2}$ are few data points which
    are located further away from the bulk of data points and hence are considered
    anomalies. arise due to several reasons, such as malicious actions, system failures,
    intentional fraud. These anomalies reveal exciting insights about the data and
    are often convey valuable information about data. Therefore, anomaly detection
    considered an essential step in various decision-making systems.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7310de803425b6effac1396bba508f25.png)'
  prefs: []
  type: TYPE_IMG
- en: scale=0.35⟧images/anomalies.png
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3: Illustration of anomalies in two-dimensional data set.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7310de803425b6effac1396bba508f25.png)'
  prefs: []
  type: TYPE_IMG
- en: scale=0.35⟧images/novel.png
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4: Illustration of novelty in the image data set.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 What are novelties?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Novelty detection is the identification of a novel (new) or unobserved patterns
    in the data (miljkovic2010review). The novelties detected are not considered as
    anomalous data points; instead, they are been applied to the regular data model.
    A novelty score may be assigned for these previously unseen data points, using
    a decision threshold score  (pimentel2014review). The points which significantly
    deviate from this decision threshold may be considered as anomalies or outliers.
    For instance, in Figure  [4](#S2.F4 "Figure 4 ‣ 2 What are anomalies? ‣ Deep Learning
    for Anomaly Detection: A Survey") the images of (white tigers) among regular tigers
    may be considered as a novelty, while the image of (horse, panther, lion, and
    cheetah) are considered as anomalies. The techniques used for anomaly detection
    are often used for novelty detection and vice versa.'
  prefs: []
  type: TYPE_NORMAL
- en: '4 Motivation and Challenges: Deep anomaly detection (DAD) techniques'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance of traditional algorithms in detecting outliers is sub-optimal on
    the image (e.g. medical images) and sequence datasets since it fails to capture
    complex structures in the data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Need for large-scale anomaly detection: As the volume of data increases let’s
    say to gigabytes then, it becomes nearly impossible for the traditional methods
    to scale to such large scale data to find outliers.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep anomaly detection (DAD) techniques learn hierarchical discriminative features
    from data. This automatic feature learning capability eliminates the need of developing
    manual features by domain experts, therefore advocates to solve the problem end-to-end
    taking raw input data in domains such as text and speech recognition.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The boundary between normal and anomalous (erroneous) behavior is often not
    precisely defined in several data domains and is continually evolving. This lack
    of well-defined representative normal boundary poses challenges for both conventional
    and deep learning-based algorithms.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ⟦ht!⟧ 1 2 3 4 5 6 7 Methods Supervised ✓ Unsupervised ✓ Hybrid Models ✓ one-Class
    Neural Networks ✓ Applications Fraud Detection ✓ ✓ Cyber-Intrusion Detection ✓
    ✓ Medical Anomaly Detection ✓ ✓ Sensor Networks Anomaly Detection ✓ ✓ Internet
    Of Things (IoT) Big-data Anomaly Detection ✓ ✓ Log-Anomaly Detection ✓ Video Surveillance
    ✓ ✓ Industrial Damage Detection ✓
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Comparison of our Survey to Other Related Survey Articles.'
  prefs: []
  type: TYPE_NORMAL
- en: 1 —Our Survey, 2 —Kwon and Donghwoon  kwon2017survey, 5 —John and Derek  ball2017comprehensive
  prefs: []
  type: TYPE_NORMAL
- en: 3 —Kiran and Thomas  kiran2018overview, 6 —Mohammadi and Al-Fuqaha  mohammadi2017deep
  prefs: []
  type: TYPE_NORMAL
- en: 4 —Adewumi and Andronicus  adewumi2017survey 7 —Geert and Kooi et.al  litjens2017survey.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Despite the substantial advances made by deep learning methods in many machine
    learning problems, there is a relative scarcity of deep learning approaches for
    anomaly detection.  adewumi2017survey provide a comprehensive survey of deep learning-based
    methods for fraud detection. A broad review of deep anomaly detection (DAD) techniques
    for cyber-intrusion detection is presented by  kwon2017survey. An extensive review
    of using DAD techniques in the medical domain is presented by  litjens2017survey.
    An overview of DAD techniques for the Internet of Things (IoT) and big-data anomaly
    detection is introduced by  mohammadi2017deep. Sensor networks anomaly detection
    has been reviewed by  ball2017comprehensive. The state-of-the-art deep learning
    based methods for video anomaly detection along with various categories have been
    presented in kiran2018overview. Although there are some reviews in applying DAD
    techniques, there is a shortage of comparative analysis of deep learning architecture
    adopted for outlier detection. For instance, a substantial amount of research
    on anomaly detection is conducted using deep autoencoders, but there is a lack
    of comprehensive survey of various deep architecture’s best suited for a given
    data-set and application domain. We hope that this survey bridges this gap and
    provides a comprehensive reference for researchers and engineers aspiring to leverage
    deep learning for anomaly detection. Table [1](#S4.T1 "Table 1 ‣ 4 Motivation
    and Challenges: Deep anomaly detection (DAD) techniques ‣ Deep Learning for Anomaly
    Detection: A Survey") shows the set of research methods and application domains
    covered by our survey.'
  prefs: []
  type: TYPE_NORMAL
- en: ⟦h⟧ ![Refer to caption](img/7310de803425b6effac1396bba508f25.png)scale=0.45⟧images/AnomalyDetectionTaxonomy
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5: Key components associated with deep learning-based anomaly detection
    technique.'
  prefs: []
  type: TYPE_NORMAL
- en: 6 Our Contributions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We follow the survey approach of  (chandola2007outlier) for deep anomaly detection
    (DAD). Our survey presents a detailed and structured overview of research and
    applications of DAD techniques. We summarize our main contributions as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most of the existing surveys on DAD techniques either focus on a particular
    application domain or specific research area of interest (kiran2018overview; mohammadi2017deep;
    litjens2017survey; kwon2017survey; adewumi2017survey; ball2017comprehensive).
    This review aims to provide a comprehensive outline of state-of-the-art research
    in DAD techniques as well as several real-world applications these techniques
    is presented.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In recent years several new deep learning based anomaly detection techniques
    with greatly reduced computational requirements have been developed. The purpose
    of this paper is to survey these techniques and classify them into an organized
    schema for better understanding. We introduce two more sub-categories Hybrid models
     (erfani2016high)and one-class neural networks techniques  (chalapathy2018anomaly)
    as illustrated in Figure [5](#S5.F5 "Figure 5 ‣ 5 Related Work ‣ Deep Learning
    for Anomaly Detection: A Survey") based on the choice of training objective. For
    each category we discuss both the assumptions and techniques adopted for best
    performance. Furthermore, within each category, we also present the challenges,
    advantages, and disadvantages and provide an overview of the computational complexity
    of DAD methods.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 7 Organization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This chapter is organized by following structure described in Figure [5](#S5.F5
    "Figure 5 ‣ 5 Related Work ‣ Deep Learning for Anomaly Detection: A Survey").
    In Section [8](#S8 "8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey"), we identify the various aspects
    that determine the formulation of the problem and highlight the richness and complexity
    associated with anomaly detection. We introduce and define two types of models:
    contextual and collective or group anomalies. In Section [9](#S9 "9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey"), we briefly describe the different application domains to
    which deep learning-based anomaly detection has been applied. In subsequent sections,
    we provide a categorization of deep learning-based techniques based on the research
    area to which they belong. Based on training objectives employed and availability
    of labels deep learning-based anomaly detection techniques can be categorized
    into supervised (Section [10.1](#S10.SS1 "10.1 Supervised deep anomaly detection
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey")), unsupervised (Section  [10.5](#S10.SS5 "10.5 Unsupervised
    Deep Anomaly Detection ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance
    ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD
    Techniques ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly
    ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training objective
    ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly
    detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on Availability
    of labels ‣ 8 Different aspects of deep learning-based anomaly detection. ‣ Deep
    Learning for Anomaly Detection: A Survey")), hybrid (Section [10.3](#S10.SS3 "10.3
    Hybrid deep anomaly detection ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10
    Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey")), and one-class neural network
    (Section [10.4](#S10.SS4 "10.4 One-class neural networks (OC-NN) for anomaly detection
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey")). For each category of techniques we also discuss their
    computational complexity for training and testing phases. In Section [8.4](#S8.SS4
    "8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") we discuss the point, contextual,
    and collective (group) deep learning-based anomaly detection techniques. We present
    some discussion of the limitations and relative performance of various existing
    techniques in Section [12](#S12 "12 Relative Strengths and Weakness : Deep Anomaly
    Detection Methods ‣ 11.8 Autoencoders ‣ 11 Deep neural network architectures for
    locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6
    Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video
    Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5
    Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4
    Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training
    objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey"). Section [13](#S13 "13 Conclusion
    ‣ 12 Relative Strengths and Weakness : Deep Anomaly Detection Methods ‣ 11.8 Autoencoders
    ‣ 11 Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey") contains concluding remarks.'
  prefs: []
  type: TYPE_NORMAL
- en: 8 Different aspects of deep learning-based anomaly detection.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section identifies and discusses the different aspects of deep learning-based
    anomaly detection.
  prefs: []
  type: TYPE_NORMAL
- en: 8.1 Nature of Input Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The choice of a deep neural network architecture in deep anomaly detection
    methods primarily depends on the nature of input data. Input data can be broadly
    classified into sequential (eg, voice, text, music, time series, protein sequences)
    or non-sequential data (eg, images, other data). Table [8.2.1](#S8.SS2.SSS1 "8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") illustrates the nature of input data and deep model architectures
    used in anomaly detection. Additionally input data depending on the number of
    features (or attributes) can be further classified into either low or high-dimensional
    data. DAD techniques have been to learn complex hierarchical feature relations
    within high-dimensional raw input data  (lecun2015deep). The number of layers
    used in DAD techniques is driven by input data dimension, deeper networks are
    shown to produce better performance on high dimensional data. Later on, in Section
     [10](#S10 "10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣
    9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques
    ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") various models considered for outlier detection are reviewed
    at depth.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.2 Based on Availability of labels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Labels indicate whether a chosen data instance is normal or an outlier. Anomalies
    are rare entities hence it is challenging to obtain their labels. Furthermore,
    anomalous behavior may change over time, for instance, the nature of anomaly had
    changed so significantly and that it remained unnoticed at Maroochy water treatment
    plant, for a long time which resulted in leakage of 150 million liters of untreated
    sewerage to local waterways  (ramotsoela2018survey).
  prefs: []
  type: TYPE_NORMAL
- en: Deep anomaly detection (DAD) models can be broadly classified into three categories
    based on the extent of availability of labels. (1) Supervised deep anomaly detection.
    (2) Semi-supervised deep anomaly detection. (3) Unsupervised deep anomaly detection.
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.1 Supervised deep anomaly detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Supervised deep anomaly detection involves training a deep supervised binary
    or multi-class classifier, using labels of both normal and anomalous data instances.
    For instance supervised DAD models, formulated as multi-class classifier aids
    in detecting rare brands, prohibited drug name mention and fraudulent health-care
    transactions  (chalapathy2016investigation; chalapathy2016bidirectional). Despite
    the improved performance of supervised DAD methods, these methods are not as popular
    as semi-supervised or unsupervised methods, owing to the lack of availability
    of labeled training samples. Moreover, the performance of deep supervised classifier
    used an anomaly detector is sub-optimal due to class imbalance (the total number
    of positive class instances are far more than the total number of negative class
    of data). Therefore we do not consider the review of supervised DAD methods in
    this survey.
  prefs: []
  type: TYPE_NORMAL
- en: '| Type of Data | Examples | DAD model architecture |'
  prefs: []
  type: TYPE_TB
- en: '| ⟦0.5ex⟧ Sequential | Video,Speech |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Protein Sequence,Time Series | CNN, RNN, LSTM |'
  prefs: []
  type: TYPE_TB
- en: '|  | Text (Natural language) |  |'
  prefs: []
  type: TYPE_TB
- en: '| Non-Sequential | Image,Sensor |  |'
  prefs: []
  type: TYPE_TB
- en: '| Other (data) | CNN, AE and its variants |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Table illustrating nature of input data and corresponding deep anomaly
    detection model architectures proposed in literature. CNN: Convolution Neural
    Networks, LSTM : Long Short Term Memory Networks AE: Autoencoders.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.2 Semi-supervised deep anomaly detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The labels of normal instances are far more easy to obtain than anomalies,
    as a result, semi-supervised DAD techniques are more widely adopted, these techniques
    leverage existing labels of single (normally positive class) to separate outliers.
    One common way of using deep autoencoders in anomaly detection is to train them
    in a semi-supervised way on data samples with no anomalies. With sufficient training
    samples, of normal class autoencoders would produce low reconstruction errors
    for normal instances, over unusual events  (wulsin2010semi; nadeem2016semi; song2017hybrid).
    We consider a detailed review of these methods in Section [10.2](#S10.SS2 "10.2
    Semi-supervised deep anomaly detection ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: ⟦h⟧ ![Refer to caption](img/7310de803425b6effac1396bba508f25.png)scale=0.7⟧images/TypeOfModels
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6: Taxonomy based on the type of deep learning models for anomaly detection.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.3 Unsupervised deep anomaly detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Unsupervised deep anomaly detection techniques detect outliers solely based
    on intrinsic properties of the data instances. Unsupervised DAD techniques are
    used in automatic labeling of unlabelled data samples since labeled data is very
    hard to obtain  (patterson2017deep). Variants of Unsupervised DAD models (tuor2017deep)
    are shown to outperform traditional methods such as principal component analysis
    (PCA)  (wold1987principal), support vector machine (SVM)  cortes1995support and
    Isolation Forest (liu2008isolation) techniques in applications domains such as
    health and cyber-security. Autoencoders are the core of all Unsupervised DAD models.
    These models assume a high prevalence of normal instances than abnormal data instances
    failing which would result in high false positive rate. Additionally unsupervised
    learning algorithms such as restricted Boltzmann machine (RBM) (sutskever2009recurrent),
    deep Boltzmann machine (DBM), deep belief network (DBN) (salakhutdinov2010efficient),
    generalized denoising autoencoders (vincent2008extracting) , recurrent neural
    network (RNN) (rodriguez1999recurrent) Long short term memory networks (lample2016neural)
    which are used to detect outliers are discussed in detail in Section  [11.7](#S11.SS7
    "11.7 Sequence Models ‣ 11 Deep neural network architectures for locating anomalies
    ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 8.3 Based on the training objective
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this survey we introduce two new categories of deep anomaly detection (DAD)
    techniques based on training objectives employed 1) Deep hybrid models (DHM).
    2) One class neural networks (OC-NN).
  prefs: []
  type: TYPE_NORMAL
- en: 8.3.1 Deep Hybrid Models (DHM)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Deep hybrid models for anomaly detection use deep neural networks mainly autoencoders
    as feature extractors, the features learned within the hidden representations
    of autoencoders are input to traditional anomaly detection algorithms such as
    one-class SVM (OC-SVM) to detect outliers (andrews2016detecting). Figure [7](#S8.F7
    "Figure 7 ‣ 8.3.1 Deep Hybrid Models (DHM) ‣ 8.3 Based on the training objective
    ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly
    detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on Availability
    of labels ‣ 8 Different aspects of deep learning-based anomaly detection. ‣ Deep
    Learning for Anomaly Detection: A Survey") illustrates the deep hybrid model architecture
    used for anomaly detection. Following the success of transfer learning to obtain
    rich representative features from models pre-trained on large data-sets, hybrid
    models have also employed these pre-trained transfer learning models as feature
    extractors with great success  (pan2010survey). A variant of hybrid model was
    proposed by  ergen2017unsupervised which considers joint training of feature extractor
    along-with OC-SVM (or SVDD) objective to maximize the detection performance. A
    notable shortcoming of these hybrid approaches is the lack of trainable objective
    customized for anomaly detection, hence these models fail to extract rich differential
    features to detect outliers. In order to overcome this limitation customized objective
    for anomaly detection such as Deep one-class classification  (ruff2018deep) and
    One class neural networks  (chalapathy2018anomaly) is introduced.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7310de803425b6effac1396bba508f25.png)'
  prefs: []
  type: TYPE_IMG
- en: scale=0.7⟧images/HybridDeepModels
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7: Deep Hybrid Model Architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.3.2 One-Class Neural Networks (OC-NN)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'One class neural network (OC-NN) chalapathy2018anomaly methods are inspired
    by kernel-based one-class classification which combines the ability of deep networks
    to extract a progressively rich representation of data with the one-class objective
    of creating a tight envelope around normal data. The OC-NN approach breaks new
    ground for the following crucial reason: data representation in the hidden layer
    is driven by the OC-NN objective and is thus customized for anomaly detection.
    This is a departure from other approaches which use a hybrid approach of learning
    deep features using an autoencoder and then feeding the features into a separate
    anomaly detection method like one-class SVM (OC-SVM). The details of training
    and evaluation of one class neural networks is discussed in Section  [10.4](#S10.SS4
    "10.4 One-class neural networks (OC-NN) for anomaly detection ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"). Another variant of one class neural network architecture Deep Support
    Vector Data Description (Deep SVDD) (ruff2018deep) trains deep neural network
    to extract common factors of variation by closely mapping the normal data instances
    to the center of sphere, is shown to produce performance improvements on MNIST (lecun2010mnist)
    and CIFAR-10  (krizhevsky2009learning) datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.4 Type of Anomaly
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Anomalies can be broadly classified into three types: point anomalies, contextual
    anomalies and collective anomalies. Deep anomaly detection (DAD) methods have
    been shown to detect all three types of anomalies with great success.'
  prefs: []
  type: TYPE_NORMAL
- en: ⟦h⟧ ![Refer to caption](img/7310de803425b6effac1396bba508f25.png)scale=0.7⟧images/TypeOfAnomaly
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8: Deep learning techniques classification based on the type of anomaly.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.4.1 Point Anomalies
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The majority of work in literature focuses on point anomalies. Point anomalies
    often represent an irregularity or deviation that happens randomly and may have
    no particular interpretation. For instance, in Figure [10](#S8.F10 "Figure 10
    ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") a credit card transaction with high expenditure recorded
    at Monaco restaurant seems a point anomaly since it significantly deviates from
    the rest of the transactions. Several real world applications, considering point
    anomaly detection, are reviewed in Section [9](#S9 "9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 8.4.2 Contextual Anomaly Detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A contextual anomaly is also known as the conditional anomaly is a data instance
    that could be considered as anomalous in some specific context  (song2007conditional).
    Contextual anomaly is identified by considering both contextual and behavioural
    features. The contextual features, normally used are time and space. While the
    behavioral features may be a pattern of spending money, the occurrence of system
    log events or any feature used to describe the normal behavior. Figure  [9(a)](#S8.F9.sf1
    "Figure 9(a) ‣ Figure 9 ‣ 8.4.2 Contextual Anomaly Detection ‣ 8.4 Type of Anomaly
    ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training objective
    ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly
    detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on Availability
    of labels ‣ 8 Different aspects of deep learning-based anomaly detection. ‣ Deep
    Learning for Anomaly Detection: A Survey") illustrates the example of a contextual
    anomaly considering temperature data indicated by a drastic drop just before June;
    this value is not indicative of a normal value found during this time. Figure
     [9(b)](#S8.F9.sf2 "Figure 9(b) ‣ Figure 9 ‣ 8.4.2 Contextual Anomaly Detection
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") illustrates using deep Long
    Short-Term Memory (LSTM)  (hochreiter1997long) based model to identify anomalous
    system log events  (du2017deeplog) in a given context (e.g event 53 is detected
    as being out of context).'
  prefs: []
  type: TYPE_NORMAL
- en: ⟦htp⟧
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7310de803425b6effac1396bba508f25.png)'
  prefs: []
  type: TYPE_IMG
- en: scale=0.35⟧images/temperature.png
  prefs: []
  type: TYPE_NORMAL
- en: (a) Temperature data hayes2015contextual.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7310de803425b6effac1396bba508f25.png)'
  prefs: []
  type: TYPE_IMG
- en: scale=0.35⟧images/deeplog.png
  prefs: []
  type: TYPE_NORMAL
- en: (b) System logs  du2017deeplog.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9: Illustration of contextual anomaly detection.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.4.3 Collective or Group Anomaly Detection.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Anomalous collections of individual data points are known as collective or
    group anomalies, wherein each of the individual points in isolation appears as
    normal data instances while observed in a group exhibit unusual characteristics.
    For example, consider an illustration of a fraudulent credit card transaction,
    in the log data shown in Figure [10](#S8.F10 "Figure 10 ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"), if a single transaction of ”MISC” would have occurred, it might probably
    not seem as anomalous. The following group of transactions of valued at $\$75$
    certainly seems to be a candidate for collective or group anomaly. Group anomaly
    detection (GAD) with an emphasis on irregular group distributions (e.g., irregular
    mixtures of image pixels are detected using a variant of autoencoder model  (chalapathy2018group;
    bontemps2016collective; araya2016collective; zhuang2017group).'
  prefs: []
  type: TYPE_NORMAL
- en: ⟦h⟧ ![Refer to caption](img/7310de803425b6effac1396bba508f25.png)scale=0.5⟧images/PointAndCollectiveAnomaly
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 10: Credit Card Fraud Detection: Illustrating Point and Collective anomaly.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.5 Output of DAD Techniques
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A critical aspect for anomaly detection methods is the way in which the anomalies
    are detected. Generally, the outputs produced by anomaly detection methods are
    either anomaly score or binary labels.
  prefs: []
  type: TYPE_NORMAL
- en: '8.5.1 Anomaly Score:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Anomaly score describes the level of outlierness for each data point. The data
    instances may be ranked according to anomalous score, and a domain-specific threshold
    (commonly known as decision score) will be selected by subject matter expert to
    identify the anomalies. In general, decision scores reveal more information than
    binary labels. For instance, in Deep SVDD approach the decision score is the measure
    of the distance of data point from the center of the sphere, the data points which
    are farther away from the center are considered anomalous  (pmlrv80ruff18a).
  prefs: []
  type: TYPE_NORMAL
- en: '8.5.2 Labels:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Instead of assigning scores, some techniques may assign a category label as
    normal or anomalous to each data instance. Unsupervised anomaly detection techniques
    using autoencoders measure the magnitude of the residual vector (i,e reconstruction
    error) for obtaining anomaly scores, later on, the reconstruction errors are either
    ranked or thresholded by domain experts to label data instances.
  prefs: []
  type: TYPE_NORMAL
- en: 9 Applications of Deep Anomaly Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we discuss several applications of deep anomaly detection.
    For each application domain, we discuss the following four aspects: —the notion
    of an anomaly; —nature of the data; —challenges associated with detecting anomalies;
    —existing deep anomaly detection techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: 9.1 Intrusion Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The intrusion detection system (IDS) refers to identifying malicious activity
    in a computer-related system (phoha2002internet). IDS may be deployed at single
    computers known as Host Intrusion Detection (HIDS) to large networks Network Intrusion
    Detection (NIDS). The classification of deep anomaly detection techniques for
    intrusion detection is in Figure  [11](#S9.F11 "Figure 11 ‣ 9.1.2 Network Intrusion
    Detection Systems (NIDS): ‣ 9.1 Intrusion Detection ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"). IDS depending on detection method are classified into signature-based
    or anomaly based. Using signature-based IDS is not efficient to detect new attacks,
    for which no specific signature pattern is available, hence anomaly based detection
    methods are more popular. In this survey, we focus on deep anomaly detection (DAD)
    methods and architectures employed in intrusion detection.'
  prefs: []
  type: TYPE_NORMAL
- en: '9.1.1 Host-Based Intrusion Detection Systems (HIDS):'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Such systems are installed software programs which monitors a single host or
    computer for malicious activity or policy violations by listening to system calls
    or events occurring within that host (vigna2005host). The system call logs could
    be generated by programs or by user interaction resulting in logs as shown in
    Figure  [9(b)](#S8.F9.sf2 "Figure 9(b) ‣ Figure 9 ‣ 8.4.2 Contextual Anomaly Detection
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey"). Malicious interactions lead
    to the execution of these system calls in different sequences. HIDS may also monitor
    the state of a system, its stored information, in Random Access Memory (RAM),
    in the file system, log files or elsewhere for a valid sequence. Deep anomaly
    detection (DAD) techniques applied for HIDS are required to handle the variable
    length and sequential nature of data. The DAD techniques have to either model
    the sequence data or compute the similarity between sequences. Some of the success-full
    DAD techniques for HIDS is illustrated in Table [3](#S9.T3 "Table 3 ‣ 9.1.2 Network
    Intrusion Detection Systems (NIDS): ‣ 9.1 Intrusion Detection ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '9.1.2 Network Intrusion Detection Systems (NIDS):'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'NIDS systems deal with monitoring the entire network for suspicious traffic
    by examining each and every network packet. Owing to real-time streaming behavior,
    the nature of data is synonymous to big data with high volume, velocity, variety.
    The network data also has a temporal aspect associated with it. Some of the success-full
    DAD techniques for NIDS is illustrated in Table [4](#S9.T4 "Table 4 ‣ 9.1.2 Network
    Intrusion Detection Systems (NIDS): ‣ 9.1 Intrusion Detection ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") . This survey also lists the data-sets used for evaluating
    the DAD intrusion detection methods in Table [5](#S9.T5 "Table 5 ‣ 9.1.2 Network
    Intrusion Detection Systems (NIDS): ‣ 9.1 Intrusion Detection ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey"). A challenge faced by DAD techniques in intrusion detection
    is that the nature of anomalies keeps changing over time as the intruders adapt
    their network attacks to evade the existing intrusion detection solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7310de803425b6effac1396bba508f25.png)'
  prefs: []
  type: TYPE_IMG
- en: scale=0.4⟧images/IDS
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11: Classification of deep learning methods for intrusion detection.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: Examples of DAD Techniques employed in HIDS CNN: Convolution Neural
    Networks, LSTM : Long Short Term Memory Networks GRU: Gated Recurrent Unit, DNN
    : Deep Neural Networks SPN: Sum Product Networks'
  prefs: []
  type: TYPE_NORMAL
- en: '| Techniques | Model Architecture | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Discriminative | LSTM , CNN-LSTM-GRU, DNN | Section  [11.7](#S11.SS7 "11.7
    Sequence Models ‣ 11 Deep neural network architectures for locating anomalies
    ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey"), [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11
    Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"), [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") | kim2016lstm,chawla2018host,chen2018henet,sohi2018recurrent,vinayakumar2017applying
    |'
  prefs: []
  type: TYPE_TB
- en: '| Hybrid | GAN | Section  [10.3](#S10.SS3 "10.3 Hybrid deep anomaly detection
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") | aghakhani2018detecting, li2018anomaly |'
  prefs: []
  type: TYPE_TB
- en: '| Generative | AE, SPN, | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11
    Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"), [11.3](#S11.SS3 "11.3 Sum-Product Networks (SPN) ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") | gao2014intrusion,peharz2018probabilistic,umer2018two
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: Examples of DAD Techniques employed in NIDS. CNN: Convolution Neural
    Networks, LSTM : Long Short Term Memory Networks RNN: Recurrent Neural Networks,
    RBM : Restricted Boltzmann Machines DCA: Dilated Convolution Autoencoders, DBN
    : Deep Belief Network AE: Autoencoders, SAE: Stacked Autoencoders GAN: Generative
    Adversarial Networks, CVAE : Convolutional Variational Autoencoder.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Techniques | Model Architecture | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Generative | DCA, SAE, RBM, DBN, CVAE | Section  [11.6](#S11.SS6 "11.6 Convolutional
    Neural Networks ‣ 11 Deep neural network architectures for locating anomalies
    ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey"), [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey"), [11.1](#S11.SS1 "11.1 Deep
    Neural Networks (DNN) ‣ 11 Deep neural network architectures for locating anomalies
    ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey"), [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") | yu2017network,thing2017ieee,
    zolotukhin2016increasing, cordero2016analyzing,alrawashdeh2016toward,tang2016deep,lopez2017conditional,al2018deep,mirsky2018kitsune,aygun2017network
    |'
  prefs: []
  type: TYPE_TB
- en: '| Hybrid | GAN | Section  [10.3](#S10.SS3 "10.3 Hybrid deep anomaly detection
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") | lin2018idsgan,yin2018enhancing, ring2018flow, latah2018deep,intrator2018mdgan,matsubara2018anomaly, nicolau2016hybrid
    ,rigaki2017adversarial. |'
  prefs: []
  type: TYPE_TB
- en: '| Discriminative | RNN , LSTM ,CNN | Section  [11.7](#S11.SS7 "11.7 Sequence
    Models ‣ 11 Deep neural network architectures for locating anomalies ‣ 10.6.6
    Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey"), [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11
    Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey") | yu2017network, malaiya2018empirical kwon2018empirical,gao2014intrusion,staudemeyer2015applying,naseer2018enhanced
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5: Datasets Used in Intrusion Detection'
  prefs: []
  type: TYPE_NORMAL
- en: '| DataSet | IDS | Description | Type | References |'
  prefs: []
  type: TYPE_TB
- en: '| CTU-UNB | NIDS | CTU-UNB ucsdAnomalyDetect2017 dataset consists of various
    botnet traffics from CTU-13 dataset ⟦20⟧ and normal traffics from the UNB ISCX
    IDS 2012 dataset  shiravi2012toward | Hexadecimal | yu2017network |'
  prefs: []
  type: TYPE_TB
- en: '| Contagio-CTU-UNB | NIDS | Contagio-CTU-UNB dataset consists of six types
    of network traffic data.  adam2008robust | Text |  yu2017network. |'
  prefs: []
  type: TYPE_TB
- en: '| NSL-KDD ²²2http://nsl.cs.unb.ca/NSL-KDD/ | NIDS | The NSL-KDD data set is
    a refined version of its predecessor KDD-99 data set.  ucsdAnomalyDetect2017 |
    Text |  yin2017deep, javaid2016deep,  tang2016deep, yousefi2017autoencoder, mohammadi2017new,
     lopez2017conditional |'
  prefs: []
  type: TYPE_TB
- en: '| DARPA KDD- CUP 99 | NIDS | DARPA KDD stolfo2000cost The competition task
    was to build a network intrusion detector, a predictive model capable of distinguishing
    between “bad” connections, called intrusions or attacks, and “good” normal connections.
    | Text |  alrawashdeh2016toward , van2017anomaly, mohammadi2017new |'
  prefs: []
  type: TYPE_TB
- en: '| MAWI | NIDS | The MAWI fontugne2010mawilab dataset consists of network traffic
    capturedfrom backbone links between Japan and USA. Every daysince 2007 | Text
    |  cordero2016analyzing |'
  prefs: []
  type: TYPE_TB
- en: '| Realistic Global Cyber Environment (RGCE) | NIDS | RGCE jamkRGCE contains
    realistic Internet Service Providers (ISPs) and numerous different web services
    as in the real Internet. | Text |  zolotukhin2016increasing |'
  prefs: []
  type: TYPE_TB
- en: '| ADFA-LD | HIDS | The ADFA Linux Dataset (ADFA-LD). This dataset provides
    a contemporary Linux dataset for evaluation by traditional HIDS creech2014semantic
    | Text |  kim2016lstm, chawla2018host |'
  prefs: []
  type: TYPE_TB
- en: '| UNM-LPR | HIDS | Consists of system calls to evalute HIDS system ImmuneDatasets
    | Text |  kim2016lstm |'
  prefs: []
  type: TYPE_TB
- en: '| Infected PDF samples | HIDS | Consists of set of Infected PDF samples, which
    are used to monitor the malicious traffic | Text |  chen2018henet |'
  prefs: []
  type: TYPE_TB
- en: 9.2 Fraud Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Fraud is a deliberate act of deception to access valuable resources  (abdallah2016fraud).
    The PricewaterhouseCoopers (PwC) global economic crime survey of 2018  (Lavion2018;
    zhao2013fraud) found that half of the 7,200 companies they surveyed had experienced
    fraud of some nature. Fraud detection refers to the detection of unlawful activities
    across various industries, illustrated in  [12](#S9.F12 "Figure 12 ‣ 9.2 Fraud
    Detection ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output
    of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of
    Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training
    objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: ⟦h⟧ ![Refer to caption](img/7310de803425b6effac1396bba508f25.png)scale=0.5⟧images/AreasOfFraud
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12: Fraud detection across various application domains.'
  prefs: []
  type: TYPE_NORMAL
- en: Fraud in telecommunications, insurance ( health, automobile, etc) claims, banking
    ( tax return claims, credit card transactions etc) represent significant problems
    in both governments and private businesses. Detecting and preventing fraud is
    not a simple task since fraud is an adaptive crime. Many traditional machine learning
    algorithms have been applied successfully in fraud detection  (sorournejad2016survey).
    The challenge associated with detecting fraud is that it requires real-time detection
    and prevention. This section focuses on deep anomaly detection (DAD) techniques
    for fraud detection.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.1 Banking fraud
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Credit card has become a popular payment method in online shopping for goods
    and services. Credit card fraud involves theft of a payment card details, and
    use it as a fraudulent source of funds in a transaction. Many techniques for credit
    card fraud detection have been presented in the last few years  (zhou2018state;
    suganya2015survey). We will briefly review some of DAD techniques as shown in
    Table [6](#S9.T6 "Table 6 ‣ 9.2.1 Banking fraud ‣ 9.2 Fraud Detection ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey"). The challenge in credit card fraud detection is that frauds
    have no consistent patterns. The typical approach in credit card fraud detection
    is to maintain a usage profile for each user and monitor the user profiles to
    detect any deviations. Since there are billions of credit card users this technique
    of user profile approach is not very scalable. Owing to the inherent scalable
    nature of DAD techniques techniques are gaining broad spread adoption in credit
    card fraud detection.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6: Examples of DAD techniques used in credit card fraud detection. AE:
    Autoencoders, LSTM : Long Short Term Memory Networks RBM: Restricted Botlzmann
    Machines, DNN : Deep Neural Networks GRU: Gated Recurrent Unit, RNN: Recurrent
    Neural Networks CNN: Convolutional Neural Networks,VAE: Variational Autoencoders
    GAN: Generative Adversarial Networks'
  prefs: []
  type: TYPE_NORMAL
- en: '| Technique Used | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  schreyer2017detection, wedge2017solving
    , paula2016deep, renstrom2018fraud, kazemi2017using, zheng2018one, pumsirirat2018credit
    |'
  prefs: []
  type: TYPE_TB
- en: '| RBM | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  pumsirirat2018credit
    |'
  prefs: []
  type: TYPE_TB
- en: '| DBN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  seeja2014fraudminer
    |'
  prefs: []
  type: TYPE_TB
- en: '| VAE | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  sweers2018autoencoding |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  fiore2017using, choi2018generative
    |'
  prefs: []
  type: TYPE_TB
- en: '| DNN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  dorronsoro1997neural,
     gomez2018end |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM,RNN,GRU | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  wiese2009credit,
     jurgovsky2018sequence, heryadi2017learning, ando2016detecting, wang2017session, alowais2012credit, amarasinghe2018critical, abroyan2017neural, lp2018transaction
    |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  shen2007application, chouiekh2018convnets, abroyan2017convolutional, fu2016credit, lu2017deep, wang2018credit, abroyan2017neural
    , zhang2018model |'
  prefs: []
  type: TYPE_TB
- en: 9.2.2 Mobile cellular network fraud
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In recent times, mobile cellular networks have witnessed rapid deployment and
    evolution supporting billions of users and a vastly diverse array of mobile devices.
    Due to this broad adoption and low mobile cellular service rates, mobile cellular
    networks is now faced with frauds such as voice scams targeted to steal customer
    private information, and messaging related scams to extort money from customers.
    Detecting such fraud is of paramount interest and not an easy task due to volume
    and velocity of the mobile cellular network. Traditional machine learning methods
    with static feature engineering techniques fail to adapt to the nature of evolving
    fraud. Table  [7](#S9.T7 "Table 7 ‣ 9.2.2 Mobile cellular network fraud ‣ 9.2
    Fraud Detection ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5
    Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4
    Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training
    objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") lists DAD techniques for mobile
    cellular network fraud detection.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7: Examples of DAD techniques used in mobile cellular network fraud detection.
    CNN: convolution neural networks,DBN: Deep Belief Networks SAE: Stacked Autoencoders,
    DNN : Deep neural networks GAN: Generative Adversarial Networks'
  prefs: []
  type: TYPE_NORMAL
- en: '| Technique Used | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  chouiekh2018convnets
    |'
  prefs: []
  type: TYPE_TB
- en: '| SAE, DBN | Section [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey"), [11.1](#S11.SS1 "11.1 Deep
    Neural Networks (DNN) ‣ 11 Deep neural network architectures for locating anomalies
    ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") |  alsheikh2016mobile, badhe2017click |'
  prefs: []
  type: TYPE_TB
- en: '| DNN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  akhter2012detecting, jain2017perspective
    |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  zheng2018generative |'
  prefs: []
  type: TYPE_TB
- en: 9.2.3 Insurance fraud
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Several traditional machine learning methods have been applied successfully
    to detect fraud in insurance claims  (joudaki2015using; roy2017detecting). The
    traditional approach for fraud detection is based on features which are fraud
    indicators. The challenge with these traditional approaches is that the need for
    manual expertise to extract robust features. Another challenge is insurance fraud
    detection is the that the incidence of frauds is far less than the total number
    of claims, and also each fraud is unique in its way. In order to overcome these
    limitations several DAD techniques are proposed which are illustrated in Table
     [8](#S9.T8 "Table 8 ‣ 9.2.3 Insurance fraud ‣ 9.2 Fraud Detection ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 8: Examples of DAD techniques used in insurance fraud detection. DBN:
    Deep Belief Networks, DNN : Deep Neural Networks CNN: Convolutional Neural Networks,VAE:
    Variational Autoencoders GAN: Generative Adversarial Networks'
  prefs: []
  type: TYPE_NORMAL
- en: '| DBN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  viaene2005auto
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| VAE | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  fajardo2018vos |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  fiore2017using, choi2018generative
    |'
  prefs: []
  type: TYPE_TB
- en: '| DNN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  keung2009neural
    |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  shen2007application, zhang2018model
    |'
  prefs: []
  type: TYPE_TB
- en: 9.2.4 Healthcare fraud
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Healthcare is an integral component in people’s lives, waste, abuse, and fraud
    drive up costs in healthcare by tens of billions of dollars each year. Healthcare
    insurance claims fraud is a significant contributor to increased healthcare costs,
    but its impact can be mitigated through fraud detection. Several machine learning
    models have been used effectively in health care insurance fraud  (bauder2017medicare).
    Table [9](#S9.T9 "Table 9 ‣ 9.2.4 Healthcare fraud ‣ 9.2 Fraud Detection ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") presents an overview of DAD methods for health-care fraud
    identification.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 9: Examples of DAD techniques used in healthcare fraud detection. RBM:
    Restricted Botlzmann Machines, GAN: Generative Adversarial Networks'
  prefs: []
  type: TYPE_NORMAL
- en: '| Technique Used | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| RBM | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  lasaga2018deep
    |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  ghasedi2018semi, finlayson2018adversarial
    |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  esteva2017dermatologist
    |'
  prefs: []
  type: TYPE_TB
- en: 9.3 Malware Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Malware, short for Malicious Software. In order to protect legitimate users
    from malware, machine learning based efficient malware detection methods are proposed
     (ye2017survey). In classical machine learning methods, the process of malware
    detection is usually divided into two stages: feature extraction and classification/clustering.
    The performance of traditional malware detection approaches critically depend
    on the extracted features and the methods for classification/clustering. The challenge
    associated in malware detection problems is the sheer scale of data, for instance
    considering data as bytes a specific sequence classification problem could be
    of the order of two million time steps. Furthermore, the malware is very adaptive
    in nature, wherein the attackers would use advanced techniques to hide the malicious
    behavior. Some DAD techniques which address these challenges effectively and detect
    malware are shown in Table [10](#S9.T10 "Table 10 ‣ 9.3 Malware Detection ‣ 9
    Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques
    ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 10: Examples of DAD techniques used for malware detection. AE: Autoencoders,
    LSTM : Long Short Term Memory Networks RBM: Restricted Botlzmann Machines, DNN
    : Deep Neural Networks GRU: Gated Recurrent Unit, RNN: Recurrent Neural Networks
    CNN: Convolutional Neural Networks,VAE: Variational Autoencoders GAN: Generative
    Adversarial Networks,CNN-BiLSTM: CNN- Bidirectional LSTM'
  prefs: []
  type: TYPE_NORMAL
- en: '| Technique Used | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  yousefi2017autoencoder, hardy2016dl4md, yousefi2017autoencoder, de2018malware, sewak2018investigation, kebede2017classification, de2018malware, david2015deepsign
    |'
  prefs: []
  type: TYPE_TB
- en: '| word2vec | Section  [11.4](#S11.SS4 "11.4 Word2vec Models ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  cakir2018malware, silva2018improving
    |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  kolosnjaji2018adversarial, suciu2018exploring, srisakaokul2018muldef, srisakaokul2018muldef, king2018artificial, huang2017r2, guo2017malware, abdelsalam2018malware,
     raff2017malware, karbab2018maldozer, martinelli2017evaluating, mclaughlin2017deep, gibert2018using, kolosnjaji2017empowering
    |'
  prefs: []
  type: TYPE_TB
- en: '| DNN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  rosenberg2018end, wang2017adversary
    |'
  prefs: []
  type: TYPE_TB
- en: '| DBN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  david2015deepsign, yang2016application, ding2016application, yuxin2017malware, selvaganapathy2018deep, yuxin2017malware, hou2017deep
    |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  tobiyama2016malware,  hu2017black, tobiyama2018method
    , passalislong |'
  prefs: []
  type: TYPE_TB
- en: '| CNN-BiLSTM | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks
    ‣ 11 Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"), [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network architectures
    for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly detection
    ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10
    Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  le2018deep, wang2017adversary
    |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  kim2018zero |'
  prefs: []
  type: TYPE_TB
- en: '| Hybrid model(AE-CNN),(AE-DBN) | Section  [10.3](#S10.SS3 "10.3 Hybrid deep
    anomaly detection ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance
    ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD
    Techniques ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly
    ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training objective
    ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly
    detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on Availability
    of labels ‣ 8 Different aspects of deep learning-based anomaly detection. ‣ Deep
    Learning for Anomaly Detection: A Survey") |  wang2018effective, li2015hybrid
    |'
  prefs: []
  type: TYPE_TB
- en: '| RNN | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  haddadpajouh2018deep |'
  prefs: []
  type: TYPE_TB
- en: 9.4 Medical Anomaly Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Several studies have been conducted to understand the theoretical and practical
    applications of deep learning in medical and bio-informatics  (min2017deep; cao2018deep;
    zhao2016deep; khan2018review). Finding rare events (anomalies) in areas such as
    medical image analysis, clinical electroencephalography (EEG) records, enable
    to diagnose and provide preventive treatments for a variety of medical conditions.
    Deep learning based architectures are employed with great success to detect medical
    anomalies as illustrated in Table  [11](#S9.T11 "Table 11 ‣ 9.4 Medical Anomaly
    Detection ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output
    of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of
    Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training
    objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey"). The vast amount of imbalanced
    data in medical domain presents significant challenges to detect outliers. Additionally
    deep learning techniques for long have been considered as black-box techniques.
    Even though deep learning models produce outstanding performance, these models
    lack interpret-ability. In recent times models with good interpret-ability are
    proposed and shown to produce state-of-the-art performance  (gugulothusparse;
    amarasinghe2018toward; choi2018doctor).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 11: Examples of DAD techniques Used for medical anomaly detection. AE:
    Autoencoders, LSTM : Long Short Term Memory Networks GRU: Gated Recurrent Unit,
    RNN: Recurrent Neural Networks CNN: Convolutional Neural Networks,VAE: Variational
    Autoencoders GAN: Generative Adversarial Networks, KNN: K-nearest neighbours RBM:
    Restricted Boltzmann Machines.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Technique Used | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AE | Section [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  wang2016research; cowton2018combined, sato2018primitive
    |'
  prefs: []
  type: TYPE_TB
- en: '| DBN | Section [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  turner2014deep, sharma2016abnormality, wulsin2010semi, ma2018unsupervised, zhang2016automatic, wulsin2011modeling
    , wu2015adaptive |'
  prefs: []
  type: TYPE_TB
- en: '| RBM | Section [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  liao2016enhanced
    |'
  prefs: []
  type: TYPE_TB
- en: '| VAE | Section [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  xu2018unsupervised, lu2018anomaly
    |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Section [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  ghasedi2018semi, chen2018unsupervised
    |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM ,RNN,GRU | Section [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  yang2018toward, jagannatha2016bidirectional, cowton2018combined, o2016recurrent, latif2018phonocardiographic, zhang2018time, chauhan2015anomaly, gugulothusparse;
    amarasinghe2018toward |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | Section [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  schmidt2018artificial, esteva2017dermatologist, wang2016research, iakovidis2018detecting
    |'
  prefs: []
  type: TYPE_TB
- en: '| Hybrid( AE+ KNN) | Section [11.6](#S11.SS6 "11.6 Convolutional Neural Networks
    ‣ 11 Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey") |  song2017hybrid |'
  prefs: []
  type: TYPE_TB
- en: 9.5 Deep learning for Anomaly detection in Social Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In recent times, online social networks have become part and parcel of daily
    life. Anomalies in a social network are irregular often unlawful behavior pattern
    of individuals within a social network; such individuals may be identified as
    spammers, sexual predators, online fraudsters, fake users or rumor-mongers. Detecting
    these irregular patterns is of prime importance since if not detected, the act
    of such individuals can have a serious social impact. A survey of traditional
    anomaly detection techniques and its challenges to detect anomalies in social
    networks is a well studied topic in literature (liu2017social; savage2014anomaly;
    anand2017anomaly; yu2016survey; cao2018automatic; yu2016survey). The heterogeneous
    and dynamic nature of data presents significant challenges to DAD techniques.
    Despite these challenges, several DAD techniques illustrated in Table  [12](#S9.T12
    "Table 12 ‣ 9.5 Deep learning for Anomaly detection in Social Networks ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") are shown outperform state-of-the-art methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 12: Examples of DAD techniques used to detect anomalies in social network.
    CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks AE: Autoencoders,
    DAE: Denoising Autoencoders SVM : Support Vector Machines., DNN : Deep Neural
    Network'
  prefs: []
  type: TYPE_NORMAL
- en: '| Technique Used | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AE,DAE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  zhang2017detecting, castellini2017fake
    |'
  prefs: []
  type: TYPE_TB
- en: '| CNN-LSTM | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣
    11 Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"),  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network architectures
    for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly detection
    ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10
    Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  sun2018detecting, shu2017doc, yang2018anomaly
    |'
  prefs: []
  type: TYPE_TB
- en: '| DNN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  li2017detecting
    |'
  prefs: []
  type: TYPE_TB
- en: '| Hybrid Models (CNN-LSTM-SVM) | Section  [10.3](#S10.SS3 "10.3 Hybrid deep
    anomaly detection ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance
    ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD
    Techniques ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly
    ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training objective
    ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly
    detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on Availability
    of labels ‣ 8 Different aspects of deep learning-based anomaly detection. ‣ Deep
    Learning for Anomaly Detection: A Survey") |  wei2017new |'
  prefs: []
  type: TYPE_TB
- en: 9.6 Log Anomaly Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Anomaly detection in log file aims to find text, which can indicate the reasons
    and the nature of the failure of a system. Most commonly, a domain-specific regular-expression
    is constructed from past experience which finds new faults by pattern matching.
    The limitation of such approaches is that newer messages of failures are easily
    are not detected (memon2008log). The unstructured and diversity in both format
    and semantics of log data pose significant challenges to log anomaly detection.
    Anomaly detection techniques should adapt to the concurrent set of log data generated
    and detect outliers in real time. Following the success of deep neural networks
    in real time text analysis, several DAD techniques illustrated in Table [13](#S9.T13
    "Table 13 ‣ 9.6 Log Anomaly Detection ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") model the
    log data as a natural language sequence are shown very effective in detecting
    outliers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 13: Examples of Deep learning anomaly detection techniques used in system
    logs. CNN: Convolution Neural Networks, LSTM : Long Short Term Memory Networks
    GRU: Gated Recurrent Unit, DNN : Deep Neural Networks AE: Autoencoders, DAE: Denoising
    Autoencoders'
  prefs: []
  type: TYPE_NORMAL
- en: '| Techniques | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  hochreiter1997long, brown2018recurrent, tuor2017deep, das2018desh, malhotra2015long
    |'
  prefs: []
  type: TYPE_TB
- en: '| AE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  du2017deeplog, andrews2016detecting
    , sakurada2014anomaly, nolle2018analyzing, nolle2016unsupervised |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM-AE | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey"),  [11.8](#S11.SS8
    "11.8 Autoencoders ‣ 11 Deep neural network architectures for locating anomalies
    ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") |  grover2018anomaly, wolpher2018anomaly |'
  prefs: []
  type: TYPE_TB
- en: '| RNN | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  brown2018recurrent, zhang2018role, nanduri2016anomaly, fengming2017anomaly
    |'
  prefs: []
  type: TYPE_TB
- en: '| DAE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  marchi2015non, nolle2016unsupervised
    |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  lu2018detecting, yuan2018insider, racki2018compact, zhou2016spatial, gorokhov2017convolutional, liao2017deep, cheng2017deep, zhang2018alphamex
    |'
  prefs: []
  type: TYPE_TB
- en: 9.7 Internet of things (IoT) Big Data Anomaly Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'IoT is identified as a network of devices that are interconnected with soft-wares,
    servers, sensors and etc. In the field of the Internet of things (IoT), data generated
    by weather stations, Radio-frequency identification (RFID) tags, IT infrastructure
    components, and some other sensors are mostly time-series sequential data. Anomaly
    detection in these IoT networks identifies fraudulent, faulty behavior of these
    massive scales of interconnected devices. The challenges associated with outlier
    detection is that heterogeneous devices are interconnected which renders the system
    more complex. A thorough overview of using deep learning (DL), to facilitate analytics
    and learning in the IoT domain is presented by  (mohammadi2018deep). Table  [14](#S9.T14
    "Table 14 ‣ 9.7 Internet of things (IoT) Big Data Anomaly Detection ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") illustrates the DAD techniques employed IoT devices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 14: Examples of DAD techniques used in Internet of things (IoT) Big Data
    Anomaly Detection. AE: Autoencoders, LSTM : Long Short Term Memory Networks DBN
    : Deep Belief Networks.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Techniques | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  luo2018distributed, mohammadi2018neural
    |'
  prefs: []
  type: TYPE_TB
- en: '| DBN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  kakanakova2017outlier
    |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  zhang2018lstm, mudassar2018unsupervised
    |'
  prefs: []
  type: TYPE_TB
- en: 9.8 Industrial Anomalies Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Industrial systems consisting of wind turbines, power plants, high-temperature
    energy systems, storage devices and with rotating mechanical parts are exposed
    to enormous stress on a day-to-day basis. Damage to these type of systems not
    only causes economic loss but also a loss of reputation, therefore detecting and
    repairing them early is of utmost importance. Several machine learning techniques
    have been used to detect such damage in industrial systems  (ramotsoela2018survey;
    marti2015anomaly). Several papers published utilizing deep learning models for
    detecting early industrial damage show great promise  (atha2018evaluation; de2018automatic;
    wang2018residential). Damages caused to equipment are rare events, thus detecting
    such events can be formulated as an outlier detection problem. The challenges
    associated with outlier detection in this domain is both volumes as well as the
    dynamic nature of data since failure is caused due to a variety of factors. Some
    of the DAD techniques employed across various industries are illustrated in Table
     [15](#S9.T15 "Table 15 ‣ 9.8 Industrial Anomalies Detection ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 15: Examples of DAD techniques used in industrial operations. CNN: Convolution
    Neural Networks, LSTM : Long Short Term Memory Networks GRU: Gated Recurrent Unit,
    DNN : Deep Neural Networks AE: Autoencoders, DAE: Denoising Autoencoders, SVM:
    Support Vector Machines SDAE: Stacked Denoising Autoencoders, RNN : Recurrent
    Neural Networks.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Techniques | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  inoue2017anomaly, thi2017one, kravchik2018detecting, huang2018deep, park2018lired, chang2018review
    |'
  prefs: []
  type: TYPE_TB
- en: '| AE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  yuan2015distributed, araya2017ensemble, qu2017detection, sakurada2014anomaly, bhattad2018detecting
    |'
  prefs: []
  type: TYPE_TB
- en: '| DNN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  lodhi2017power
    |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  faghih2016deep, christiansen2016deepanomaly, lee2016convolutional, faghih2016deep,
     dong2016camera, nanduri2016anomaly, fuentes2017robust, huang2018deep, chang2018review
    |'
  prefs: []
  type: TYPE_TB
- en: '| SDAE,DAE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  yan2015accurate, luo2017gas, dai2017cleaning
    |'
  prefs: []
  type: TYPE_TB
- en: '| RNN | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  banjanovic2017neural, thi2017one
    |'
  prefs: []
  type: TYPE_TB
- en: '| Hybrid Models (DNN-SVM) | Section  [10.3](#S10.SS3 "10.3 Hybrid deep anomaly
    detection ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣
    9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques
    ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") |  inoue2017anomaly |'
  prefs: []
  type: TYPE_TB
- en: 9.9 Anomaly Detection in Time Series
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Data recorded continuously over duration is known as time series. Time series
    data can be broadly classified into univariate and multivariate time series. In
    case of univariate time series, only single variable (or feature) varies over
    time. For instance, the data collected from a temperature sensor within the room
    for each second is an uni-variate time series data. A multivariate time series
    consists several variables (or features) which change over time. An accelerometer
    which produces three-dimensional data for every second one for each axis $(x,y,z)$
    is a perfect example of multivariate time series data. In the literature, types
    of anomalies in univariate and multivariate time series are categorized into following
    groups: (1) Point Anomalies. [8.4.1](#S8.SS4.SSS1 "8.4.1 Point Anomalies ‣ 8.4
    Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training
    objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") (2) Contextual Anomalies [8.4.2](#S8.SS4.SSS2
    "8.4.2 Contextual Anomaly Detection ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural
    Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep
    anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised
    deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey") (3) Collective Anomalies  [8.4.3](#S8.SS4.SSS3 "8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"). In recent times, many deep learning models have been proposed for
    detecting anomalies within univariate and multivariate time series data as illustrated
    in Table [16](#S9.T16 "Table 16 ‣ 9.9.1 Uni-variate time series deep anomaly detection
    ‣ 9.9 Anomaly Detection in Time Series ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") and Table
     [17](#S9.T17 "Table 17 ‣ 9.9.2 Multi-variate time series deep anomaly detection
    ‣ 9.9 Anomaly Detection in Time Series ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") respectively.
    Some of the challenges to detect anomalies in time series using deep learning
    models data are:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lack of defined pattern in which an anomaly is occurring may be defined.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Noise within the input data seriously affects the performance of algorithms.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the length of the time series data increases the computational complexity
    also increases.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series data is usually non-stationary, non-linear and dynamically evolving.
    Hence DAD models should be able to detect anomalies in real time.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 9.9.1 Uni-variate time series deep anomaly detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The advancements in deep learning domain offer opportunities to extract rich
    hierarchical features which can greatly improve outlier detection within uni-variate
    time series data. The list of industry standard tools and datasets (both deep
    learning based and non-deep learning based) for benchmarking anomaly detection
    algorithms on both univariate and multivariate time-series data is presented and
    maintained at Github repository ³³3[https://github.com/rob-med/awesome-TS-anomaly-detection](https://github.com/rob-med/awesome-TS-anomaly-detection).
    Table [16](#S9.T16 "Table 16 ‣ 9.9.1 Uni-variate time series deep anomaly detection
    ‣ 9.9 Anomaly Detection in Time Series ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") illustrates
    various deep architectures adopted for anomaly detection within uni-variate time
    series data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 16: Examples of DAD techniques used in uni-variate time series data.
    CNN: Convolution Neural Networks, GAN: Generative Adversarial networks, DNN: Deep
    Neural Networks,AE: Autoencoders,DAE: Denoising Autoencoders, VAE: Variational
    Autoencoder,SDAE: Stacked Denoising Autoencoders, LSTM: Long Short Term Memory
    Networks, GRU: Gated Recurrent Unit RNN: Recurrent Neural Networks, RNN: Replicator
    Neural Networks'
  prefs: []
  type: TYPE_NORMAL
- en: '| Techniques | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") | shipmon2017time,hundman2018detecting,zhu2017deepmalhotra2015long,chauhan2015anomaly,assendorp2017deep
    ahmad2017unsupervised,malhotra2016lstm,bontemps2016collective,taylor2016anomaly,cheng2016ms,loganathan2018sequence,chauhan2015anomaly,malhotra2015long,gorokhov2017convolutional, munir2018deepant
    |'
  prefs: []
  type: TYPE_TB
- en: '| AE,LSTM-AE,CNN-AE,GRU-AE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣
    11 Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey") |  Dominique, malhotra2016multi,  filonov2016multivariate, sugimoto2018deep, oh2018residual, ebrahimzadehmulti, veeramachaneni2016ai, dau2014anomaly
    |'
  prefs: []
  type: TYPE_TB
- en: '| RNN | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  wielgosz2017recurrent, saurav2018online, wielgosz2018model, guo2016robust, filonov2017rnn
    |'
  prefs: []
  type: TYPE_TB
- en: '| CNN, CNN-LSTM | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks
    ‣ 11 Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"), [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network architectures
    for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly detection
    ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10
    Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  kanarachos2017detecting, dumodeling, gorokhov2017convolutional, napoletano2018anomaly, shanmugam2018jiffy,medel2016anomaly
    |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM-VAE | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey"), [11.5](#S11.SS5
    "11.5 Generative Models ‣ 11 Deep neural network architectures for locating anomalies
    ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") |  park2018multimodal, solch2016variational |'
  prefs: []
  type: TYPE_TB
- en: '| DNN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  amarasinghe2018toward
    |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  li2018anomaly, zenati2018efficient, lim2018doping, laptevanogen,wei2018unsupervised
    |'
  prefs: []
  type: TYPE_TB
- en: 9.9.2 Multi-variate time series deep anomaly detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Anomaly detection in multivariate time series data is a challenging task. Effective
    multivariate anomaly detection enables fault isolation diagnostics. RNN and LSTM
    based methods ⁴⁴4[https://github.com/pnnl/safekit](https://github.com/pnnl/safekit)
    are shown to perform well in detecting interpretable anomalies within multivariate
    time series dataset. DeepAD, a generic framework based on deep learning for multivariate
    time series anomaly detection is proposed by  (buda2018deepad). Interpretable,
    anomaly detection systems designed using deep attention based models are effective
    in explaining the anomalies detected (yuan2018muvan; guo2018exploring). Table
     [17](#S9.T17 "Table 17 ‣ 9.9.2 Multi-variate time series deep anomaly detection
    ‣ 9.9 Anomaly Detection in Time Series ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") illustrates
    various deep architectures adopted for anomaly detection within multivariate time
    series data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 17: Examples of DAD techniques used in multivariate time series data.
    CNN: Convolution Neural Networks, GAN: Generative Adversarial networks, DNN: Deep
    Neural Networks,AE: Autoencoders,DAE: Denoising Autoencoders, VAE: Variational
    Autoencoder,SDAE: Stacked Denoising Autoencoders, LSTM: Long Short Term Memory
    Networks, GRU: Gated Recurrent Unit'
  prefs: []
  type: TYPE_NORMAL
- en: '| Techniques | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  nucci2018real, hundman2018detecting, Assendorp2017DeepLF, nolle2018binet
    |'
  prefs: []
  type: TYPE_TB
- en: '| AE,LSTM-AE,CNN-AE,GRU-AE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣
    11 Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey") |  zhang2018deep guo2018multidimensional, fu2019aircraft, kieu2018outlier
    |'
  prefs: []
  type: TYPE_TB
- en: '| CNN, CNN-LSTM | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks
    ‣ 11 Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"), [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network architectures
    for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly detection
    ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10
    Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  basumallik2019packet, shanmugam2018jiffy
    |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM-VAE | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey"), [11.5](#S11.SS5
    "11.5 Generative Models ‣ 11 Deep neural network architectures for locating anomalies
    ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") |  ikeda2018estimation, park2018multimodal |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  assendorp2017deep, li2018anomaly, li2019mad cowton2018combined
    |'
  prefs: []
  type: TYPE_TB
- en: '| DNN-RNN | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  tuor2017deep, tuor2018recurrent
    |'
  prefs: []
  type: TYPE_TB
- en: ⟦!htbp⟧ ⟦t⟧ Dataset Description References NASA Shuttle Valve Data¹ Includes
    spacecraft anomaly data and experiments from the Mars Science Laboratory and SMAP
    missions hundman2018detecting² Vessels³ Multivariate temporal data analysis for
    Vessels behavior anomaly detection multivariate17 SWaT and WADI Secure Water Treatment
    (SWaT) and the Water Distribution (WADI) li2019mad Credit Card Fraud Detection
    Anonymized credit card transactions labeled as fraudulent or genuine dal2015calibrating
    NYC taxi passenger count⁵ The New York City taxi passenger data stream cui2016comparative
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 18: Datasets used in multivariate anomaly detection.'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ⟦1⟧ [https://cs.fit.edu/~pkc/nasa/data/](https://cs.fit.edu/~pkc/nasa/data/)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ⟦2⟧ [https://github.com/khundman/telemanom](https://github.com/khundman/telemanom)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ⟦3⟧ [http://conferences.inf.ed.ac.uk/EuroDW2018/papers/eurodw18-Maia.pdf](http://conferences.inf.ed.ac.uk/EuroDW2018/papers/eurodw18-Maia.pdf)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ⟦4⟧ [https://www.kaggle.com/peterkim95/multivariate-gaussian-anomaly-detection/data](https://www.kaggle.com/peterkim95/multivariate-gaussian-anomaly-detection/data)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ⟦5⟧ [https://github.com/chickenbestlover/RNN-Time-series-Anomaly-Detection](https://github.com/chickenbestlover/RNN-Time-series-Anomaly-Detection)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Table 19: Examples of DAD techniques used in video surveillance. CNN: Convolution
    Neural Networks, LSTM : Long Short Term Memory Networks RBM: Restricted Boltzmann
    Machine, DNN : Deep Neural Networks AE: Autoencoders, DAE: Denoising Autoencoders
    OCSVM: One class Support vector machines, CAE: Convolutional Autoencoders SDAE:
    Stacked Denoising Autoencoders, STN : Spatial Transformer Networks'
  prefs: []
  type: TYPE_NORMAL
- en: '| Technique Used | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") | dong2016camera,andrewsaanomaly,sabokrou2016fully,sabokrou2017deep,munawar2017spatio,li2017transferred,qiao2017abnormal,tripathi2018convolutional,nogas2018deepfall,christiansen2016deepanomaly,li2017transferred,
    |'
  prefs: []
  type: TYPE_TB
- en: '| SAE (AE-CNN-LSTM) | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey"), [11.6](#S11.SS6
    "11.6 Convolutional Neural Networks ‣ 11 Deep neural network architectures for
    locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6
    Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video
    Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5
    Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4
    Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training
    objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey"), [11.7](#S11.SS7 "11.7 Sequence
    Models ‣ 11 Deep neural network architectures for locating anomalies ‣ 10.6.6
    Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") |  chong2017abnormal, qiao2017abnormal, khaleghi2018improved
    |'
  prefs: []
  type: TYPE_TB
- en: '| AE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") | qiao2017abnormal,yang2015unsupervised,chen2015detecting,gutoskidetection,d2017autoencoder,dotti2017unsupervised,yang2015unsupervised,chen2015detecting,sabokrou2016video,tran2017anomaly,chen2015detecting
    ,d2017autoencoder,hasan2016learning,yang2015unsupervised,cinelli2017anomaly,sultani2018real
    |'
  prefs: []
  type: TYPE_TB
- en: '| Hybrid Model (CAE-OCSVM) | Section  [10.3](#S10.SS3 "10.3 Hybrid deep anomaly
    detection ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣
    9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques
    ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") |  gutoskidetection,  dotti2017unsupervised |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM-AE | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey"),  [11.8](#S11.SS8
    "11.8 Autoencoders ‣ 11 Deep neural network architectures for locating anomalies
    ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") |  d2017autoencoder |'
  prefs: []
  type: TYPE_TB
- en: '| STN | Section [11.2](#S11.SS2 "11.2 Spatio Temporal Networks (STN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") | chianucci2016unsupervised
    |'
  prefs: []
  type: TYPE_TB
- en: '| RBM | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") | munawar2017spatio
    |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  medel2016anomaly, luo2017remembering, ben2018attentioned, singh2017anomaly
    |'
  prefs: []
  type: TYPE_TB
- en: '| RNN | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") | luo2017revisit,zhou2015abnormal
    ,hu2016video, chong2015modeling |'
  prefs: []
  type: TYPE_TB
- en: '| AAE | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  ravanbakhsh2017training |'
  prefs: []
  type: TYPE_TB
- en: 9.10 Video Surveillance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Video Surveillance also popularly known as Closed-circuit television (CCTV)
    involves monitoring designated areas of interest in order to ensure security.
    In videos surveillance applications unlabelled data is available in large amounts,
    this is a significant challenge for supervised machine learning and deep learning
    methods. Hence video surveillance applications have been modeled as anomaly detection
    problems owing to lack of availability of labeled data. Several works have studied
    the state-of-the-art deep models for video anomaly detection and have classified
    them based on the type of model and criteria of detection  (kiran2018overview;
    chong2015modeling). The challenges of robust 24/7 video surveillance systems are
    discussed in detail by  (boghossian2005challenges). The lack of an explicit definition
    of an anomaly in real-life video surveillance is a significant issue that hampers
    the performance of DAD methods as well. DAD techniques used in video surveillance
    are illustrated in Table  [19](#S9.T19 "Table 19 ‣ 9.9.2 Multi-variate time series
    deep anomaly detection ‣ 9.9 Anomaly Detection in Time Series ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 10 Deep Anomaly Detection (DAD) Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we discuss various DAD models classified based on the availability
    of labels and training objective. For each model types domain, we discuss the
    following four aspects: —assumptions; —type of model architectures; —computational
    complexity; —advantages and disadvantages;'
  prefs: []
  type: TYPE_NORMAL
- en: 10.1 Supervised deep anomaly detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Supervised anomaly detection techniques are superior in performance compared
    to unsupervised anomaly detection techniques since these techniques use labeled
    samples (gornitz2013toward). Supervised anomaly detection learns the separating
    boundary from a set of annotated data instances (training) and then, classify
    a test instance into either normal or anomalous classes with the learned model
    (testing). Assumptions: Deep supervised learning methods depend on separating
    data classes whereas unsupervised techniques focus on explaining and understanding
    the characteristics of data. Multi-class classification based anomaly detection
    techniques assumes that the training data contains labeled instances of multiple
    normal classes  (shilton2013combined; jumutc2014multi; kim2015deep; erfani2017shared).
    Multi-class anomaly detection techniques learn a classifier to distinguish between
    anomalous class from the rest of the classes. In general, supervised deep learning-based
    classification schemes for anomaly detection have two sub-networks, a feature
    extraction network followed by a classifier network. Deep models require a substantial
    number of training samples (in the order of thousands or millions) to learn feature
    representations to discriminate various class instances effectively. Due to, lack
    of availability of clean data labels supervised deep anomaly detection techniques
    are not so popular as semi-supervised and unsupervised methods. Computational
    Complexity: The computational complexity of deep supervised anomaly detection
    methods based techniques depends on the input data dimension and the number of
    hidden layers trained using back-propagation algorithm. High dimensional data
    tend to have more hidden layers to ensure meaning-full hierarchical learning of
    input features.The computational complexity also increases linearly with the number
    of hidden layers and require greater model training and update time.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Advantages and Disadvantages: The advantages of supervised DAD techniques are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supervised DAD methods are more accurate than semi-supervised and unsupervised
    models.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The testing phase of classification based techniques is fast since each test
    instance needs to be compared against the precomputed model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The disadvantages of Supervised DAD techniques are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-class supervised techniques require accurate labels for various normal
    classes and anomalous instances, which is often not available.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep supervised techniques fail to separate normal from anomalous data if the
    feature space is highly complex and non-linear.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 10.2 Semi-supervised deep anomaly detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Semi-supervised or (one-class classification) DAD techniques assume that all
    training instances have only one class label. A review of deep learning based
    semi-supervised techniques for anomaly detection is presented by  kiran2018overview
    and min2018ids. DAD techniques learn a discriminative boundary around the normal
    instances. The test instance that does not belong to the majority class is flagged
    as being anomalous (perera2018learning; blanchard2010semi). Various semi-supervised
    DAD model architectures are illustrated in Table [20](#S10.T20 "Table 20 ‣ 10.2
    Semi-supervised deep anomaly detection ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 20: Semi-supervised DAD models overview AE: Autoencoders, DAE: Denoising
    Autoencoders, KNN : K- Nearest Neighbours CorGAN: Corrupted Generative Adversarial
    Networks, DBN: Deep Belief Networks AAE: Adversarial Autoencoders, CNN: Convolution
    neural networks SVM: Support vector machines.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Techniques | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  edmunds2017deep , estiri2018semi
    |'
  prefs: []
  type: TYPE_TB
- en: '| RBM | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  jia2014novel
    |'
  prefs: []
  type: TYPE_TB
- en: '| DBN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN) ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  wulsin2010semi, wulsin2011modeling
    |'
  prefs: []
  type: TYPE_TB
- en: '| CorGAN,GAN | Section [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  gu2018semi
     akcay2018ganomaly, sabokrou2018adversarially |'
  prefs: []
  type: TYPE_TB
- en: '| AAE | Section [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  dimokranitou2017adversarial
    |'
  prefs: []
  type: TYPE_TB
- en: '| Hybrid Models (DAE-KNN altman1992introduction), (DBN-Random Forest ho1995random),CNN-Relief kira1992feature,CNN-SVM cortes1995support
    | Section [8.3.1](#S8.SS3.SSS1 "8.3.1 Deep Hybrid Models (DHM) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  song2017hybrid, shi2017semi, zhu2018hybrid
    |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | Section [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  racah2017extremeweather, perera2018learning
    |'
  prefs: []
  type: TYPE_TB
- en: '| RNN | Section [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  wu2018semi |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Section [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  kliger2018novelty, gu2018semi
    |'
  prefs: []
  type: TYPE_TB
- en: 'Assumptions: Semi-supervised DAD methods proposed to rely on one of the following
    assumptions to score a data instance as an anomaly.'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Proximity and Continuity: Points which are close to each other both in input
    space and learned feature space are more likely to share the same label.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robust features are learned within hidden layers of deep neural network layers
    and retain the discriminative attributes for separating normal from outlier data
    points.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Computational Complexity: The computational complexity of semi-supervised DAD
    methods based techniques is similar to supervised DAD techniques, which primarily
    depends on the dimensionality of the input data and the number of hidden layers
    used for representative feature learning.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Advantages and Disadvantages: The advantages of semi-supervised deep anomaly
    detection techniques are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative Adversarial Networks (GANs) trained in semi-supervised learning mode
    have shown great promise, even with very few labeled data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use of labeled data ( usually of one class), can produce considerable performance
    improvement over unsupervised techniques.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The fundamental disadvantages of semi-supervised techniques presented by (lu2009fundamental)
    are applicable even in a deep learning context. Furthermore, the hierarchical
    features extracted within hidden layers may not be representative of fewer anomalous
    instances hence are prone to the over-fitting problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 21: Examples of Hybrid DAD techniques. CNN: Convolution Neural Networks,
    LSTM : Long Short Term Memory Networks DBN: Deep Belief Networks, DNN : Deep Neural
    Networks. AE: Autoencoders, DAE: Denoising Autoencoders, SVM: Support Vector Machines cortes1995support
    SVDD: Support Vector Data Description, RNN : Recurrent Neural Networks Relief:
    Feature selection Algorithm kira1992feature, KNN: K- Nearest Neighbours altman1992introduction
    CSI: Capture, Score, and Integrate ruchansky2017csi.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Techniques | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| AE-OCSVM, AE-SVM | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey"), |  andrews2016detecting
    |'
  prefs: []
  type: TYPE_TB
- en: '| DBN-SVDD, AE-SVDD | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN)
    ‣ 11 Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"), |  erfani2016high, kim2015deep |'
  prefs: []
  type: TYPE_TB
- en: '| DNN-SVM | 21D |  inoue2017anomaly |'
  prefs: []
  type: TYPE_TB
- en: '| DAE-KNN, DBN-Random Forest ho1995random,CNN-Relief,CNN-SVM | Section  [11.1](#S11.SS1
    "11.1 Deep Neural Networks (DNN) ‣ 11 Deep neural network architectures for locating
    anomalies ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous
    Techniques ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance
    ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD
    Techniques ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly
    ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training objective
    ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly
    detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on Availability
    of labels ‣ 8 Different aspects of deep learning-based anomaly detection. ‣ Deep
    Learning for Anomaly Detection: A Survey"),[11.8](#S11.SS8 "11.8 Autoencoders
    ‣ 11 Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey") |  song2017hybrid, shi2017semi, zhu2018hybrid; urbanowicz2018relief
    |'
  prefs: []
  type: TYPE_TB
- en: '| AE-CNN, AE-DBN | Section  [11.1](#S11.SS1 "11.1 Deep Neural Networks (DNN)
    ‣ 11 Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"), [11.6](#S11.SS6 "11.6 Convolutional Neural Networks ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey"),[11.8](#S11.SS8
    "11.8 Autoencoders ‣ 11 Deep neural network architectures for locating anomalies
    ‣ 10.6.6 Statistical techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques
    ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications
    of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3
    Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") |  wang2018effective, li2015hybrid |'
  prefs: []
  type: TYPE_TB
- en: '| AE+ KNN | Section [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  song2017hybrid |'
  prefs: []
  type: TYPE_TB
- en: '| CNN-LSTM-SVM | Section  [11.6](#S11.SS6 "11.6 Convolutional Neural Networks
    ‣ 11 Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey"),[11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network architectures
    for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly detection
    ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10
    Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  wei2017new |'
  prefs: []
  type: TYPE_TB
- en: '| RNN-CSI | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural
    network architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep
    anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") |  ruchansky2017csi
    |'
  prefs: []
  type: TYPE_TB
- en: '| CAE-OCSVM | Section [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  gutoskidetection,  dotti2017unsupervised
    |'
  prefs: []
  type: TYPE_TB
- en: 10.3 Hybrid deep anomaly detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Deep learning models are widely used as feature extractors to learn robust
    features  (andrews2016detecting). In deep hybrid models, the representative features
    learned within deep models are input to traditional algorithms like one-class
    Radial Basis Function (RBF), Support Vector Machine (SVM) classifiers. The hybrid
    models employ two step learning and are shown to produce state-of-the-art results
     (erfani2016high; erfani2016robust; wu2015harvesting). Deep hybrid architectures
    used in anomaly detection is presented in Table  [21](#S10.T21 "Table 21 ‣ 10.2
    Semi-supervised deep anomaly detection ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Assumptions: The deep hybrid models proposed for anomaly detection rely on
    one of the following assumptions to detect outliers:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robust features are extracted within hidden layers of the deep neural network,
    aid in separating the irrelevant features which can conceal the presence of anomalies.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Building a robust anomaly detection model on complex, high-dimensional spaces
    require feature extractor and an anomaly detector. Various anomaly detectors used
    alongwith are illustrated in Table  [21](#S10.T21 "Table 21 ‣ 10.2 Semi-supervised
    deep anomaly detection ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance
    ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD
    Techniques ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly
    ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training objective
    ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly
    detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on Availability
    of labels ‣ 8 Different aspects of deep learning-based anomaly detection. ‣ Deep
    Learning for Anomaly Detection: A Survey")'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Computational Complexity : The computational complexity of a hybrid model includes
    the complexity of both deep architectures as well as traditional algorithms used
    within. Additionally, an inherent issue of non-trivial choice of deep network
    architecture and parameters which involves searching optimized parameters in a
    considerably larger space introduces the computational complexity of using deep
    layers within hybrid models. Furthermore considering the classical algorithms
    such as linear SVM which has prediction complexity of $O(d)$ with d the number
    of input dimensions. For most kernels, including polynomial and RBF, the complexity
    is $O(nd)$ where $n$ is the number of support vectors although an approximation
    $O(d^{2})$ is considered for SVMs with an RBF kernel.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Advantages and Disadvantages The advantages of hybrid DAD techniques are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The feature extractor significantly reduces the ‘curse of dimensionality’, especially
    in the high dimensional domain.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hybrid models are more scalable and computationally efficient since the linear
    or nonlinear kernel models operate on reduced input dimension.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The significant disadvantages of hybrid DAD techniques are:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The hybrid approach is suboptimal because it is unable to influence representational
    learning within the hidden layers of feature extractor since generic loss functions
    are employed instead of the customized objective for anomaly detection.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The deeper hybrid models tend to perform better if the individual layers are
     (saxe2011random) which introduces computational expenditure.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 10.4 One-class neural networks (OC-NN) for anomaly detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One-class neural networks (OC-NN) combines the ability of deep networks to
    extract a progressively rich representation of data alongwith the one-class objective,
    such as a hyperplane (chalapathy2018anomaly) or hypersphere  (ruff2018deep) to
    separate all the normal data points from the outliers. The OC-NN approach is novel
    for the following crucial reason: data representation in the hidden layer are
    learned by optimizing the objective function customized for anomaly detection
    as illustrated in The experimental results in  (chalapathy2018anomaly; ruff2018deep)
    demonstrate that OC-NN can achieve comparable or better performance than existing
    state-of-the-art methods for complex datasets, while having reasonable training
    and testing time compared to the existing methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Assumptions: The OC-NN models proposed for anomaly detection rely on the following
    assumptions to detect outliers:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OC-NN models extract the common factors of variation within the data distribution
    within the hidden layers of the deep neural network.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performs combined representation learning and produces an outlier score for
    a test data instance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anomalous samples do not contain common factors of variation and hence hidden
    layers fail to capture the representations of outliers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Computational Complexity: The Computational complexity of an OC-NN model as
    against the hybrid model includes only the complexity of the deep network of choice
     (saxe2011random). OC-NN models do not require data to be stored for prediction,
    thus have very low memory complexity. However, it is evident that the OC-NN training
    time is proportional to the input dimension.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Advantages and Disadvantages: The advantages of OC-NN are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OC-NN models jointly train a deep neural network while optimizing a data-enclosing
    hypersphere or hyper-plane in output space.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OC-NN propose an alternating minimization algorithm for learning the parameters
    of the OC-NN model. We observe that the subproblem of the OC-NN objective is equivalent
    to a solving a quantile selection problem which is well defined.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The significant disadvantages of OC-NN for anomaly detection are:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training times and model update time may be longer for high dimensional input
    data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model updates would also take longer time, given the change in input space.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 10.5 Unsupervised Deep Anomaly Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Unsupervised DAD is an essential area of research in both fundamental machine
    learning research and industrial applications. Several deep learning frameworks
    that address challenges in unsupervised anomaly detection are proposed and shown
    to produce a state-of-the-art performance as illustrated in Table  [22](#S10.T22
    "Table 22 ‣ 10.5 Unsupervised Deep Anomaly Detection ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey"). Autoencoders
    are the fundamental unsupervised deep architectures used in anomaly detection
     (baldi2012autoencoders).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 22: Examples of Un-supervised DAD techniques . CNN: Convolution Neural
    Networks, LSTM : Long Short Term Memory Networks DNN : Deep Neural Networks.,
    GAN: Generative Adversarial Network AE: Autoencoders, DAE: Denoising Autoencoders,
    SVM: Support Vector Machines STN: Spatial Transformer Networks, RNN : Recurrent
    Neural Networks AAE: Adversarial Autoencoders, VAE : Variational Autoencoders.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Techniques | Section | References |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  singh2017anomaly, chandola2008comparative, dasigi2014modeling,malhotra2015long
    |'
  prefs: []
  type: TYPE_TB
- en: '| AE | Section  [11.8](#S11.SS8 "11.8 Autoencoders ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  abati2018and, zong2018deep, tagawa2015structured, dau2014anomaly, sakurada2014anomaly, wu2015adaptive,
     xu2015learning, hawkins2002outlier, zhao2015robust, qi2014robust, chalapathy2017robust, yang2015unsupervised,'
  prefs: []
  type: TYPE_NORMAL
- en: zhai2016deep, lyudchik2016outlier, lu2017unsupervised, mehrotra2017deep, meng2018relational,parchami2017using
    |
  prefs: []
  type: TYPE_NORMAL
- en: '| STN | Section  [11.2](#S11.SS2 "11.2 Spatio Temporal Networks (STN) ‣ 11
    Deep neural network architectures for locating anomalies ‣ 10.6.6 Statistical
    techniques deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey") |  chianucci2016unsupervised |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  lawson2017finding |'
  prefs: []
  type: TYPE_TB
- en: '| RNN | Section  [11.7](#S11.SS7 "11.7 Sequence Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  dasigi2014modeling,filonov2017rnn
    |'
  prefs: []
  type: TYPE_TB
- en: '| AAE | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  dimokranitou2017adversarial, leveau2017adversarial
    |'
  prefs: []
  type: TYPE_TB
- en: '| VAE | Section  [11.5](#S11.SS5 "11.5 Generative Models ‣ 11 Deep neural network
    architectures for locating anomalies ‣ 10.6.6 Statistical techniques deep anomaly
    detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") |  an2015variational, suh2016echo, solch2016variational, xu2018unsupervised, mishra2017generative
    |'
  prefs: []
  type: TYPE_TB
- en: 'Assumptions: The deep unsupervised models proposed for anomaly detection rely
    on one of the following assumptions to detect outliers:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The “normal” regions in the original or latent feature space can be distinguished
    from ”anomalous” regions in the original or latent feature space.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The majority of the data instances are normal compared to the remainder of the
    data set.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsupervised anomaly detection algorithm produces an outlier score of the data
    instances based on intrinsic properties of the data-set such as distances or densities.
    The hidden layers of deep neural network aim to capture these intrinsic properties
    within the dataset (goldstein2016comparative).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Computational Complexity: The autoencoders are the most common architecture
    employed in outlier detection with quadratic cost, the optimization problem is
    non-convex, similar to any other neural network architecture. The computational
    complexity of model depends on the number of operations, network parameters, and
    hidden layers. However, the computational complexity of training an autoencoder
    is much higher than traditional methods such as Principal Component Analysis (PCA)
    since PCA is based on matrix decomposition  (meng2018relational; parchami2017using).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Advantages and Disadvantages: The advantages of unsupervised deep anomaly detection
    techniques are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learns the inherent data characteristics to separate normal from an anomalous
    data point. This technique identifies commonalities within the data and facilitates
    outlier detection.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cost effective technique to find the anomalies since it does not require annotated
    data for training the algorithms.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The significant disadvantages of unsupervised deep anomaly detection techniques
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often it is challenging to learn commonalities within data in a complex and
    high dimensional space.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While using autoencoders the choice of right degree of compression, i.e., dimensionality
    reduction is often an hyper-parameter that requires tuning for optimal results.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsupervised techniques techniques are very sensitive to noise, and data corruptions
    and are often less accu-rate than supervised or semi-supervised techniques.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 10.6 Miscellaneous Techniques
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section explores, various DAD techniques which are shown to be effective
    and promising, we discuss the key idea behind those techniques and their area
    of applicability.
  prefs: []
  type: TYPE_NORMAL
- en: 10.6.1 Transfer Learning based anomaly detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Deep learning for long has been criticized for the need to have enough data
    to produce good results. Both litjens2017survey and pan2010survey present the
    review of deep transfer learning approaches and illustrate their significance
    to learn good feature representations. Transfer learning is an essential tool
    in machine learning to solve the fundamental problem of insufficient training
    data. It aims to transfer the knowledge from the source domain to the target domain
    by relaxing the assumption that training and future data must be in the same feature
    space and have the same distribution. Deep transfer representation-learning has
    been explored by  (andrews2016transfer; vercruyssen2017transfer; li2012detecting;
    almajai2012anomaly; kumar2017transfer; liang2018transfer) are shown to produce
    very promising results. The open research questions using transfer learning for
    anomaly detection is, the degree of transfer-ability, that is to define how well
    features transfer the knowledge and improve the classification performance from
    one task to another.
  prefs: []
  type: TYPE_NORMAL
- en: 10.6.2 Zero Shot learning based anomaly detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Zero shot learning (ZSL) aims to recognize objects never seen before within
    training set  (romera2015embarrassingly). ZSL achieves this in two phases: Firstly
    the knowledge about the objects in natural language descriptions or attributes
    (commonly known as meta-data) is captured Secondly this knowledge is then used
    to classify instances among a new set of classes. This setting is important in
    the real world since one may not be able to obtain images of all the possible
    classes at training. The primary challenge associated with this approach is the
    obtaining the meta-data about the data instances. However several approaches of
    using ZSL in anomaly and novelty detection are shown to produce state-of-the-art
    results  (mishra2017generative; socher2013zero; xian2017zero; liu2017generalized;
    rivero2017grassmannian).'
  prefs: []
  type: TYPE_NORMAL
- en: 10.6.3 Ensemble based anomaly detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A notable issue with deep neural networks is that they are sensitive to noise
    within input data and often require extensive training data to perform robustly (kim2016lstm).
    In order to achieve robustness even in noisy data an idea to randomly vary on
    the connectivity architecture of the autoencoder is shown to obtain significantly
    better performance. Autoencoder ensembles consisting of various randomly connected
    autoencoders are experimented by  chen2017outlier to achieve promising results
    on several benchmark datasets. The ensemble approaches are still an active area
    of research which has been shown to produce improved diversity, thus avoid overfitting
    problem while reducing training time.
  prefs: []
  type: TYPE_NORMAL
- en: 10.6.4 Clustering based anomaly detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Several anomaly detection algorithms based on clustering have been proposed
    in literature (ester1996density). Clustering involves grouping together similar
    patterns based on features extracted detect new anomalies. The time and space
    complexity grows linearly with number of classes to be clustered  (sreekanth2010generalized),
    which renders the clustering based anomaly detection prohibitive for real-time
    practical applications. The dimensionality of the input data is reduced extracting
    features within the hidden layers of deep neural network which ensures scalability
    for complex and high dimensional datasets. Deep learning enabled clustering approach
    anomaly detection utilizes e.g word2vec  (mikolov2013efficient) models to get
    the semantical presentations of normal data and anomalies to form clusters and
    detect outliers  (yuan2017deep). Several works rely on variants of hybrid models
    along with auto-encoders for obtaining representative features for clustering
    to find anomalies.
  prefs: []
  type: TYPE_NORMAL
- en: 10.6.5 Deep Reinforcement Learning (DRL) based anomaly detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Deep reinforcement learning (DRL) methods have attracted significant interest
    due to its ability to learn complex behaviors in high-dimensional data space.
    Efforts to detect anomalies using deep reinforcement learning have been proposed
    by  de2017learning; rlanomaly. The DRL based anomaly detector does not consider
    any assumption about the concept of the anomaly, the detector identifies new anomalies
    by consistently enhancing its knowledge through reward signals accumulated. DRL
    based anomaly detection is a very novel concept which requires further investigation
    and identification of the research gap and its applications.
  prefs: []
  type: TYPE_NORMAL
- en: 10.6.6 Statistical techniques deep anomaly detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Hilbert transform is a statistical signal processing technique which derives
    the analytic representation of a real-valued signal. This property is leveraged
    by  (kanarachos2015anomaly) for real-time detection of anomalies in health-related
    time series dataset and is shown to be a very promising technique. The algorithm
    combines the ability of wavelet analysis, neural networks and Hilbert transform
    in a sequential manner to detect real-time anomalies. The topic of statistical
    techniques DAD techniques requires further investigation to understand their potential
    and applicability for anomaly detections fully.
  prefs: []
  type: TYPE_NORMAL
- en: 11 Deep neural network architectures for locating anomalies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 11.1 Deep Neural Networks (DNN)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The ”deep” in ”deep neural networks” refers to the number of layers through
    which the features of data are extracted  (schmidhuber2015deep; bengio2009learning).
    Deep architectures overcome the limitations of traditional machine learning approaches
    of scalability, and generalization to new variations within data (lecun2015deep)
    and the need for manual feature engineering. Deep Belief Networks (DBNs) are class
    of deep neural network which comprises multiple layers of graphical models known
    as Restricted Boltzmann Machine (RBMs). The hypothesis in using DBNs for anomaly
    detection is that RBMs are used as a directed encoder-decoder network with backpropagation
    algorithm  (werbos1990backpropagation). DBNs fail to capture the characteristic
    variations of anomalous samples, resulting in high reconstruction error. DBNs
    are shown to scale efficiently to big-data and improve interpretability  (wulsin2010semi).
  prefs: []
  type: TYPE_NORMAL
- en: 11.2 Spatio Temporal Networks (STN)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Researchers for long have explored techniques to learn both spatial and temporal
    relation features  (zhang2018detecting). Deep learning architectures is leveraged
    to perform well at learning spatial aspects ( using CNN’s) and temporal features
    ( using LSTMs) individually. Spatio Temporal Networks (STNs) comprises of deep
    neural architectures combining both CNN’s and LSTMs to extract spatiotemporal
    features. The temporal features (modeling correlations between near time points
    via LSTM), spatial features (modeling local spatial correlation via local CNN’s)
    are shown to be effective in detecting outliers  (lee2018stan; szeker2014spatio;
    nie2018spatio; dereszynski2011spatiotemporal).
  prefs: []
  type: TYPE_NORMAL
- en: 11.3 Sum-Product Networks (SPN)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sum-Product Networks (SPNs) are directed acyclic graphs with variables as leaves,
    and the internal nodes, and weighted edges constitute the sums and products. SPNs
    are considered as a combination of mixture models which have fast exact probabilistic
    inference over many layers (poon2011sum; peharz2018probabilistic). The main advantage
    of SPNs is that, unlike graphical models, SPNs are more traceable over high treewidth
    models without requiring approximate inference. Furthermore, SPNs are shown to
    capture uncertainty over their inputs in a convincing manner, yielding robust
    anomaly detection (peharz2018probabilistic). SPNs are shown to be impressive results
    on numerous datasets, while much remains to be further explored in relation to
    outlier detection.
  prefs: []
  type: TYPE_NORMAL
- en: 11.4 Word2vec Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Word2vec is a group of deep neural network models used to produce word embeddings
     (mikolov2013efficient). These models are capable of capturing sequential relationships
    within data instance such as sentences, time sequence data. Obtaining word embedding
    features as inputs are shown to improve the performance in several deep learning
    architectures  (rezaeinia2017improving; naili2017comparative; altszyler2016comparative).
    Anomaly detection models leveraging the word2vec embeddings are shown to significantly
    improve performance (schnabel2015evaluation; bertero2017experience; bakarov2018anomaly;
    bamler2017dynamic).
  prefs: []
  type: TYPE_NORMAL
- en: 11.5 Generative Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Generative models aim to learn exact data distribution in order to generate
    new data points with some variations. The two most common and efficient generative
    approaches are Variational Autoencoders (VAE)  (kingma2013auto) and Generative
    Adversarial Networks (GAN) (NIPS2014_5423; goodfellow2014generative). A variant
    of GAN architecture known as Adversarial autoencoders (AAE) ( makhzani2015adversarial)
    that use adversarial training to impose an arbitrary prior on the latent code
    learned within hidden layers of autoencoder are also shown to learn the input
    distribution effectively. Leveraging this ability of learning input distributions,
    several Generative Adversarial Networks-based Anomaly Detection (GAN-AD) frameworks
     (li2018anomaly; deecke2018anomaly; schlegl2017unsupervised; ravanbakhsh2017abnormal;
    eide2018applying) proposed are shown to be effective in identifying anomalies
    on high dimensional and complex datasets. However traditional methods such as
    K-nearest neighbors (KNN) are shown to perform better in scenarios which have
    a lesser number of anomalies when compared to deep generative models  (vskvara2018generative).
  prefs: []
  type: TYPE_NORMAL
- en: 11.6 Convolutional Neural Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Convolutional Neural Networks (CNN), are the popular choice of neural networks
    for analyzing visual imagery  (krizhevsky2012imagenet). CNN’s ability to extract
    complex hidden features from high dimensional data with complex structure has
    enabled its use as feature extractors in outlier detection for both sequential
    and image dataset  (gorokhov2017convolutional; kim2014convolutional). Evaluation
    of CNN’s based frameworks for anomaly detection is currently still an active area
    of research  (kwon2018empirical).
  prefs: []
  type: TYPE_NORMAL
- en: 11.7 Sequence Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Recurrent Neural Networks (RNNs)  (williams1989complexity) are shown to capture
    features of time sequence data. The limitations with RNNs is that they fail to
    capture the context as time steps increases, in order to resolve this problem,
    Long Short-Term Memory  (hochreiter1997long) networks were introduced, they are
    a particular type of RNNs comprising of a memory cell that can store information
    about previous time steps. Gated Recurrent Unit  (cho2014learning) (GRU) are similar
    to LSTMs, but use a set of gates to control the flow of information, instead of
    separate memory cells. Anomaly detection in sequential data has attracted significant
    interest in the literature due to its applications in a wide range of engineering
    problems illustrated in Section  [9.9](#S9.SS9 "9.9 Anomaly Detection in Time
    Series ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output
    of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of
    Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on the training
    objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey"). Long Short Term Memory (LSTM)
    neural network based algorithms for anomaly detection have been investigated and
    reported to produce significant performance gains over conventional methods  (ergen2017unsupervised).'
  prefs: []
  type: TYPE_NORMAL
- en: 11.8 Autoencoders
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Autoencoders with single layer along with a linear activation function are
    nearly equivalent to Principal Component Analysis (PCA) (pearson1901liii). While
    PCA is restricted to a linear dimensionality reduction, auto encoders enable both
    linear or nonlinear tranformations (liou2008modeling; liou2014autoencoder). One
    of the popular applications of Autoencoders is anomaly detection. Autoencoders
    are also referenced by the name Replicator Neural Networks (RNN)  (hawkins2002outlier, williams2002comparative).
    Autoencoders represent data within multiple hidden layers by reconstructing the
    input data, effectively learning an identity function. The autoencoders, when
    trained solely on normal data instances ( which are the majority in anomaly detection
    tasks), fail to reconstruct the anomalous data samples, therefore, producing a
    large reconstruction error. The data samples which produce high residual errors
    are considered outliers. Several variants of autoencoder architectures are proposed
    as illustrated in Figure  [13](#S11.F13 "Figure 13 ‣ 11.8 Autoencoders ‣ 11 Deep
    neural network architectures for locating anomalies ‣ 10.6.6 Statistical techniques
    deep anomaly detection ‣ 10.6 Miscellaneous Techniques ‣ 10 Deep Anomaly Detection
    (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection
    ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly
    Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3
    Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣
    8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection
    ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects of deep learning-based
    anomaly detection. ‣ Deep Learning for Anomaly Detection: A Survey") produce promising
    results in anomaly detection. The choice of autoencoder architecture depends on
    the nature of data, convolution networks are preferred for image datasets while
    Long short-term memory (LSTM) based models tend to produce good results for sequential
    data. Efforts to combine both convolution and LSTM layers where the encoder is
    a convolutional neural network (CNN) and decoder is a multilayer LSTM network
    to reconstruct input images are shown to be effective in detecting anomalies within
    data. The use of combined models such as Gated recurrent unit autoencoders (GRU-AE),
    Convolutional neural networks autoencoders (CNN-AE), Long short-term memory (LSTM)
    autoencoder (LSTM-AE) eliminates the need for preparing hand-crafted features
    and facilitates the use of raw data with minimal preprocessing in anomaly detection
    tasks. Although autoencoders are simple and effective architectures for outlier
    detection, the performance gets degraded due to noisy training data  (zhou2017anomaly).'
  prefs: []
  type: TYPE_NORMAL
- en: <svg  class="ltx_picture ltx_centering" height="48.89" overflow="visible"
    version="1.1" width="657.64"><g transform="translate(0,48.89) matrix(1 0 0 -1
    0 0) translate(328.82,0) translate(0,24.44) matrix(1.0 0.0 0.0 1.0 -324.21 -19.83)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 19.835)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 19.83)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0) translate(324.21,0) matrix(1.0 0.0 0.0 1.0 -319.6 5.53)" fill="#000000"
    stroke="#000000"><foreignobject width="20.76" height="12.45" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">\Tree⟦.Autoencoders ⟦.Images ⟦CAE CNN-AE CNN-LSTM-AE
    DAE ⟧ ⟧ ⟦.Sequential Data ⟦ LSTM-AE GRU-AE AE SDAE ⟧⟧⟧</foreignobject></g></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13: Autoencoder architectures for anomaly detection. AE: Autoencoders liou2014autoencoder,
    LSTM : Long Short Term Memory Networks hochreiter1997long SDAE: Stacked Denoising
    Autoencoder vincent2010stacked, DAE : Denoising Autoencoders vincent2010stacked
    GRU: Gated Recurrent Unit cho2014learning, CNN: Convolutional Neural Networks krizhevsky2012imagenet
    CNN-LSTM-AE: Convolution Long Short Term Memory Autoencoders haque2018image CAE:
    Convolutional Autoencoders masci2011stacked'
  prefs: []
  type: TYPE_NORMAL
- en: '12 Relative Strengths and Weakness : Deep Anomaly Detection Methods'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Each of the deep anomaly detection (DAD) techniques discussed in previous sections
    have their unique strengths and weaknesses. It is critical to understand which
    anomaly detection technique is best suited for a given anomaly detection problem
    context. Given the fact that DAD is an active research area, it is not feasible
    to provide such an understanding for every anomaly detection problem. Hence in
    this section, we analyze the relative strengths and weaknesses of different categories
    of techniques for a few simple problem settings. Classification based supervised
    DAD techniques illustrated in Section [10.1](#S10.SS1 "10.1 Supervised deep anomaly
    detection ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣
    9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques
    ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") are better choices in scenario consisting of the equal amount
    of labels for both normal and anomalous instances. The computational complexity
    of supervised DAD technique is a key aspect, especially when the technique is
    applied to a real domain. While classification based, supervised or semi-supervised
    techniques have expensive training times, testing is usually fast since it uses
    a pre-trained model. Unsupervised DAD techniques presented in Section [10.5](#S10.SS5
    "10.5 Unsupervised Deep Anomaly Detection ‣ 10 Deep Anomaly Detection (DAD) Models
    ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels:
    ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or Group Anomaly Detection.
    ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks (OC-NN) ‣ 8.3 Based on
    the training objective ‣ 8.2.3 Unsupervised deep anomaly detection ‣ 8.2.2 Semi-supervised
    deep anomaly detection ‣ 8.2.1 Supervised deep anomaly detection ‣ 8.2 Based on
    Availability of labels ‣ 8 Different aspects of deep learning-based anomaly detection.
    ‣ Deep Learning for Anomaly Detection: A Survey") are being widely used since
    label acquisition is a costly and time-consuming process. Most of the unsupervised
    deep anomaly detection requires priors to be assumed on the anomaly distribution
    hence the models are less robust in handling noisy data. Hybrid models illustrated
    in Section [10.3](#S10.SS3 "10.3 Hybrid deep anomaly detection ‣ 10 Deep Anomaly
    Detection (DAD) Models ‣ 9.10 Video Surveillance ‣ 9 Applications of Deep Anomaly
    Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques ‣ 8.4.3 Collective or
    Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class Neural Networks
    (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised deep anomaly
    detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1 Supervised deep
    anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different aspects
    of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly Detection:
    A Survey") extract robust features within hidden layers of the deep neural network
    and feed to best performing classical anomaly detection algorithms. The hybrid
    model approach is suboptimal because it is unable to influence representational
    learning in the hidden layers. The One-class Neural Networks (OC-NN) described
    in Section [10.4](#S10.SS4 "10.4 One-class neural networks (OC-NN) for anomaly
    detection ‣ 10 Deep Anomaly Detection (DAD) Models ‣ 9.10 Video Surveillance ‣
    9 Applications of Deep Anomaly Detection ‣ 8.5.2 Labels: ‣ 8.5 Output of DAD Techniques
    ‣ 8.4.3 Collective or Group Anomaly Detection. ‣ 8.4 Type of Anomaly ‣ 8.3.2 One-Class
    Neural Networks (OC-NN) ‣ 8.3 Based on the training objective ‣ 8.2.3 Unsupervised
    deep anomaly detection ‣ 8.2.2 Semi-supervised deep anomaly detection ‣ 8.2.1
    Supervised deep anomaly detection ‣ 8.2 Based on Availability of labels ‣ 8 Different
    aspects of deep learning-based anomaly detection. ‣ Deep Learning for Anomaly
    Detection: A Survey") combines the ability of deep networks to extract a progressively
    rich representation of data along with the one-class objective, such as a hyperplane
     (chalapathy2018anomaly) or hypersphere  (ruff2018deep) to separate all the normal
    data points from anomalous data points. Further research and exploration is necessary
    to comprehend better the benefits of this new architecture proposed.'
  prefs: []
  type: TYPE_NORMAL
- en: 13 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this survey paper, we have discussed various research methods in deep learning-based
    anomaly detection along with its application across various domains. This article
    discusses the challenges in deep anomaly detection and presents several existing
    solutions to these challenges. For each category of deep anomaly detection techniques,
    we present the assumption regarding the notion of normal and anomalous data along
    with its strength and weakness. The goal of this survey was to investigate and
    identify the various deep learning models for anomaly detection and evaluate its
    suitability for a given dataset. When choosing a deep learning model to a particular
    domain or data, these assumptions can be used as guidelines to assess the effectiveness
    of the technique in that domain. Deep learning based anomaly detection is still
    active research, and a possible future work would be to extend and update this
    survey as more sophisticated techniques are proposed.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 1⟧#1 1⟧#1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[1] Chandola et al.(2007)Chandola, Banerjee, and Kumar⟧chandola2007outlier
    Varun Chandola, Arindam Banerjee, and Vipin Kumar. Outlier detection: A survey.
    *ACM Computing Surveys*, 2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Hawkins(1980)⟧hawkins D. Hawkins. *Identification of Outliers*. Chapman
    and Hall, London, 1980.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Javaid et al.(2016)Javaid, Niyaz, Sun, and Alam⟧javaid2016deep Ahmad Javaid,
    Quamar Niyaz, Weiqing Sun, and Mansoor Alam. A deep learning approach for network
    intrusion detection system. In *Proceedings of the 9th EAI International Conference
    on Bio-inspired Information and Communications Technologies (formerly BIONETICS)*,
    pages 21–26\. ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications
    Engineering), 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Peng and Marculescu(2015)⟧peng2015multi Huan-Kai Peng and Radu Marculescu.
    Multi-scale compositionality: identifying the compositional structures of social
    dynamics using deep learning. *PloS one*, 10(4):e0118309, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] Alejandro(2016)⟧deeplearningVstraditionalAlgorithms Bahnsen Alejandro,
    Correa. Building ai applications using deep learning. 2016. URL [https://blog.easysol.net/wp-content/uploads/2017/06/image1.png](https://blog.easysol.net/wp-content/uploads/2017/06/image1.png).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] Xie et al.(2017)Xie, Wang, Chen, Shi, and Zhao⟧xie2017real Xuemei Xie,
    Chenye Wang, Shu Chen, Guangming Shi, and Zhifu Zhao. Real-time illegal parking
    detection system based on deep learning. In *Proceedings of the 2017 International
    Conference on Deep Learning Technologies*, pages 23–27\. ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] Schlegl et al.(2017)Schlegl, Seeböck, Waldstein, Schmidt-Erfurth, and Langs⟧schlegl2017unsupervised
    Thomas Schlegl, Philipp Seeböck, Sebastian M Waldstein, Ursula Schmidt-Erfurth,
    and Georg Langs. Unsupervised anomaly detection with generative adversarial networks
    to guide marker discovery. In *International Conference on Information Processing
    in Medical Imaging*, pages 146–157\. Springer, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Mohammadi et al.(2017)Mohammadi, Al-Fuqaha, Sorour, and Guizani⟧mohammadi2017deep
    Mehdi Mohammadi, Ala Al-Fuqaha, Sameh Sorour, and Mohsen Guizani. Deep learning
    for iot big data and streaming analytics: A survey. *arXiv preprint arXiv:1712.04301*,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Aggarwal(2013)⟧aggarwal2013introduction Charu C Aggarwal. An introduction
    to outlier analysis. In *Outlier analysis*, pages 1–40\. Springer, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Miljković(2010)⟧miljkovic2010review Dubravko Miljković. Review of novelty
    detection methods. In *MIPRO, 2010 proceedings of the 33rd international convention*,
    pages 593–598\. IEEE, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Pimentel et al.(2014)Pimentel, Clifton, Clifton, and Tarassenko⟧pimentel2014review
    Marco AF Pimentel, David A Clifton, Lei Clifton, and Lionel Tarassenko. A review
    of novelty detection. *Signal Processing*, 99:215–249, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] Kwon et al.(2017)Kwon, Kim, Kim, Suh, Kim, and Kim⟧kwon2017survey Donghwoon
    Kwon, Hyunjoo Kim, Jinoh Kim, Sang C Suh, Ikkyun Kim, and Kuinam J Kim. A survey
    of deep learning-based network anomaly detection. *Cluster Computing*, pages 1–13,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Ball et al.(2017)Ball, Anderson, and Chan⟧ball2017comprehensive John E
    Ball, Derek T Anderson, and Chee Seng Chan. Comprehensive survey of deep learning
    in remote sensing: theories, tools, and challenges for the community. *Journal
    of Applied Remote Sensing*, 11(4):042609, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Kiran et al.(2018)Kiran, Thomas, and Parakkal⟧kiran2018overview B Ravi
    Kiran, Dilip Mathew Thomas, and Ranjith Parakkal. An overview of deep learning
    based methods for unsupervised and semi-supervised anomaly detection in videos.
    *arXiv preprint arXiv:1801.03149*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] Adewumi and Akinyelu(2017)⟧adewumi2017survey Aderemi O Adewumi and Andronicus A
    Akinyelu. A survey of machine-learning and nature-inspired based credit card fraud
    detection techniques. *International Journal of System Assurance Engineering and
    Management*, 8(2):937–953, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] Litjens et al.(2017)Litjens, Kooi, Bejnordi, Setio, Ciompi, Ghafoorian,
    Van Der Laak, Van Ginneken, and Sánchez⟧litjens2017survey Geert Litjens, Thijs
    Kooi, Babak Ehteshami Bejnordi, Arnaud Arindra Adiyoso Setio, Francesco Ciompi,
    Mohsen Ghafoorian, Jeroen Awm Van Der Laak, Bram Van Ginneken, and Clara I Sánchez.
    A survey on deep learning in medical image analysis. *Medical image analysis*,
    42:60–88, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Erfani et al.(2016a)Erfani, Rajasegarar, Karunasekera, and Leckie⟧erfani2016high
    Sarah M Erfani, Sutharshan Rajasegarar, Shanika Karunasekera, and Christopher
    Leckie. High-dimensional and large-scale anomaly detection using a linear one-class
    svm with deep learning. *Pattern Recognition*, 58:121–134, 2016a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Chalapathy et al.(2018a)Chalapathy, Menon, and Chawla⟧chalapathy2018anomaly
    Raghavendra Chalapathy, Aditya Krishna Menon, and Sanjay Chawla. Anomaly detection
    using one-class neural networks. *arXiv preprint arXiv:1802.06360*, 2018a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] LeCun et al.(2015)LeCun, Bengio, and Hinton⟧lecun2015deep Yann LeCun,
    Yoshua Bengio, and Geoffrey Hinton. Deep learning. *nature*, 521(7553):436, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Ramotsoela et al.(2018)Ramotsoela, Abu-Mahfouz, and Hancke⟧ramotsoela2018survey
    Daniel Ramotsoela, Adnan Abu-Mahfouz, and Gerhard Hancke. A survey of anomaly
    detection in industrial wireless sensor networks with critical water system infrastructure
    as a case study. *Sensors*, 18(8):2491, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Chalapathy et al.(2016a)Chalapathy, Borzeshi, and Piccardi⟧chalapathy2016investigation
    Raghavendra Chalapathy, Ehsan Zare Borzeshi, and Massimo Piccardi. An investigation
    of recurrent neural architectures for drug name recognition. *arXiv preprint arXiv:1609.07585*,
    2016a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Chalapathy et al.(2016b)Chalapathy, Borzeshi, and Piccardi⟧chalapathy2016bidirectional
    Raghavendra Chalapathy, Ehsan Zare Borzeshi, and Massimo Piccardi. Bidirectional
    lstm-crf for clinical concept extraction. *arXiv preprint arXiv:1611.08373*, 2016b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] Wulsin et al.(2010)Wulsin, Blanco, Mani, and Litt⟧wulsin2010semi Drausin
    Wulsin, Justin Blanco, Ram Mani, and Brian Litt. Semi-supervised anomaly detection
    for eeg waveforms using deep belief nets. In *Machine Learning and Applications
    (ICMLA), 2010 Ninth International Conference on*, pages 436–441\. IEEE, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Nadeem et al.(2016)Nadeem, Marshall, Singh, Fang, and Yuan⟧nadeem2016semi
    Mutahir Nadeem, Ochaun Marshall, Sarbjit Singh, Xing Fang, and Xiaohong Yuan.
    Semi-supervised deep neural network for network intrusion detection. 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] Song et al.(2017)Song, Jiang, Men, and Yang⟧song2017hybrid Hongchao Song,
    Zhuqing Jiang, Aidong Men, and Bo Yang. A hybrid semi-supervised anomaly detection
    model for high-dimensional data. *Computational intelligence and neuroscience*,
    2017, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] Patterson and Gibson(2017)⟧patterson2017deep Josh Patterson and Adam Gibson.
    *Deep Learning: A Practitioner’s Approach*. ” O’Reilly Media, Inc.”, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] Tuor et al.(2017)Tuor, Kaplan, Hutchinson, Nichols, and Robinson⟧tuor2017deep
    Aaron Tuor, Samuel Kaplan, Brian Hutchinson, Nicole Nichols, and Sean Robinson.
    Deep learning for unsupervised insider threat detection in structured cybersecurity
    data streams. *arXiv preprint arXiv:1710.00811*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] Wold et al.(1987)Wold, Esbensen, and Geladi⟧wold1987principal Svante Wold,
    Kim Esbensen, and Paul Geladi. Principal component analysis. *Chemometrics and
    intelligent laboratory systems*, 2(1-3):37–52, 1987.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] Cortes and Vapnik(1995)⟧cortes1995support Corinna Cortes and Vladimir
    Vapnik. Support-vector networks. *Machine learning*, 20(3):273–297, 1995.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] Liu et al.(2008)Liu, Ting, and Zhou⟧liu2008isolation Fei Tony Liu, Kai Ming
    Ting, and Zhi-Hua Zhou. Isolation forest. In *Data Mining, 2008\. ICDM’08\. Eighth
    IEEE International Conference on*, pages 413–422\. IEEE, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Sutskever et al.(2009)Sutskever, Hinton, and Taylor⟧sutskever2009recurrent
    Ilya Sutskever, Geoffrey E Hinton, and Graham W Taylor. The recurrent temporal
    restricted boltzmann machine. In *Advances in Neural Information Processing Systems*,
    pages 1601–1608, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] Salakhutdinov and Larochelle(2010)⟧salakhutdinov2010efficient Ruslan Salakhutdinov
    and Hugo Larochelle. Efficient learning of deep boltzmann machines. In *Proceedings
    of the Thirteenth International Conference on Artificial Intelligence and Statistics*,
    pages 693–700, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Vincent et al.(2008)Vincent, Larochelle, Bengio, and Manzagol⟧vincent2008extracting
    Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. Extracting
    and composing robust features with denoising autoencoders. In *Proceedings of
    the 25th international conference on Machine learning*, pages 1096–1103\. ACM,
    2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] Rodriguez et al.(1999)Rodriguez, Wiles, and Elman⟧rodriguez1999recurrent
    Paul Rodriguez, Janet Wiles, and Jeffrey L Elman. A recurrent neural network that
    learns to count. *Connection Science*, 11(1):5–40, 1999.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] Lample et al.(2016)Lample, Ballesteros, Subramanian, Kawakami, and Dyer⟧lample2016neural
    Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and
    Chris Dyer. Neural architectures for named entity recognition. *arXiv preprint
    arXiv:1603.01360*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] Andrews et al.(2016a)Andrews, Morton, and Griffin⟧andrews2016detecting
    Jerone TA Andrews, Edward J Morton, and Lewis D Griffin. Detecting anomalous data
    using auto-encoders. *International Journal of Machine Learning and Computing*,
    6(1):21, 2016a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] Pan et al.(2010)Pan, Yang, et al.⟧pan2010survey Sinno Jialin Pan, Qiang
    Yang, et al. A survey on transfer learning. *IEEE Transactions on knowledge and
    data engineering*, 22(10):1345–1359, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] Ergen et al.(2017)Ergen, Mirza, and Kozat⟧ergen2017unsupervised Tolga
    Ergen, Ali Hassan Mirza, and Suleyman Serdar Kozat. Unsupervised and semi-supervised
    anomaly detection with lstm neural networks. *arXiv preprint arXiv:1710.09207*,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] Ruff et al.(2018a)Ruff, Görnitz, Deecke, Siddiqui, Vandermeulen, Binder,
    Müller, and Kloft⟧ruff2018deep Lukas Ruff, Nico Görnitz, Lucas Deecke, Shoaib Ahmed
    Siddiqui, Robert Vandermeulen, Alexander Binder, Emmanuel Müller, and Marius Kloft.
    Deep one-class classification. In *International Conference on Machine Learning*,
    pages 4390–4399, 2018a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] LeCun et al.(2010)LeCun, Cortes, and Burges⟧lecun2010mnist Yann LeCun,
    Corinna Cortes, and Christopher JC Burges. Mnist handwritten digit database. *AT&T
    Labs ⟦Online⟧. Available: http://yann. lecun. com/exdb/mnist*, 2, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] Krizhevsky and Hinton(2009)⟧krizhevsky2009learning Alex Krizhevsky and
    Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical
    report, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] Song et al.(2007)Song, Wu, Jermaine, and Ranka⟧song2007conditional Xiuyao
    Song, Mingxi Wu, Christopher Jermaine, and Sanjay Ranka. Conditional anomaly detection.
    *IEEE Transactions on Knowledge and Data Engineering*, 19(5):631–645, 2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] Hochreiter and Schmidhuber(1997)⟧hochreiter1997long Sepp Hochreiter and
    Jürgen Schmidhuber. Long short-term memory. *Neural computation*, 9(8):1735–1780,
    1997.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] Du et al.(2017)Du, Li, Zheng, and Srikumar⟧du2017deeplog Min Du, Feifei
    Li, Guineng Zheng, and Vivek Srikumar. Deeplog: Anomaly detection and diagnosis
    from system logs through deep learning. In *Proceedings of the 2017 ACM SIGSAC
    Conference on Computer and Communications Security*, pages 1285–1298\. ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] Hayes and Capretz(2015)⟧hayes2015contextual Michael A Hayes and Miriam AM
    Capretz. Contextual anomaly detection framework for big sensor data. *Journal
    of Big Data*, 2(1):2, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] Chalapathy et al.(2018b)Chalapathy, Toth, and Chawla⟧chalapathy2018group
    Raghavendra Chalapathy, Edward Toth, and Sanjay Chawla. Group anomaly detection
    using deep generative models. *arXiv preprint arXiv:1804.04876*, 2018b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] Bontemps et al.(2016)Bontemps, McDermott, Le-Khac, et al.⟧bontemps2016collective
    Loïc Bontemps, James McDermott, Nhien-An Le-Khac, et al. Collective anomaly detection
    based on long short-term memory recurrent neural networks. In *International Conference
    on Future Data and Security Engineering*, pages 141–152\. Springer, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] Araya et al.(2016)Araya, Grolinger, ElYamany, Capretz, and Bitsuamlak⟧araya2016collective
    Daniel B Araya, Katarina Grolinger, Hany F ElYamany, Miriam AM Capretz, and G Bitsuamlak.
    Collective contextual anomaly detection framework for smart buildings. In *Neural
    Networks (IJCNN), 2016 International Joint Conference on*, pages 511–518\. IEEE,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] Zhuang et al.(2017)Zhuang, Yusufu, Ye, and Hua⟧zhuang2017group Naifan
    Zhuang, Tuoerhongjiang Yusufu, Jun Ye, and Kien A Hua. Group activity recognition
    with differential recurrent convolutional neural networks. In *Automatic Face
    & Gesture Recognition (FG 2017), 2017 12th IEEE International Conference on*,
    pages 526–531\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] Ruff et al.(2018b)Ruff, Vandermeulen, Goernitz, Deecke, Siddiqui, Binder,
    Müller, and Kloft⟧pmlrv80ruff18a Lukas Ruff, Robert Vandermeulen, Nico Goernitz,
    Lucas Deecke, Shoaib Ahmed Siddiqui, Alexander Binder, Emmanuel Müller, and Marius
    Kloft. Deep one-class classification. In Jennifer Dy and Andreas Krause, editors,
    *Proceedings of the 35th International Conference on Machine Learning*, volume 80
    of *Proceedings of Machine Learning Research*, pages 4393–4402, Stockholmsmässan,
    Stockholm Sweden, 10–15 Jul 2018b. PMLR. URL [http://proceedings.mlr.press/v80/ruff18a.html](http://proceedings.mlr.press/v80/ruff18a.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] Phoha(2002)⟧phoha2002internet Vir V Phoha. *Internet security dictionary*,
    volume 1. Taylor & Francis, 2002.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] Vigna and Kruegel(2005)⟧vigna2005host Giovanna Vigna and Christopher Kruegel.
    Host-based intrusion detection. 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] Kim et al.(2016)Kim, Yi, Lee, Paek, and Yoon⟧kim2016lstm Gyuwan Kim, Hayoon
    Yi, Jangho Lee, Yunheung Paek, and Sungroh Yoon. Lstm-based system-call language
    modeling and robust ensemble method for designing host-based intrusion detection
    systems. *arXiv preprint arXiv:1611.01726*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] Chawla et al.(2018)Chawla, Lee, Fallon, and Jacob⟧chawla2018host Ashima
    Chawla, Brian Lee, Sheila Fallon, and Paul Jacob. Host based intrusion detection
    system with combined cnn/rnn model. In *Proceedings of Second International Workshop
    on AI in Security*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] Chen et al.(2018)Chen, Sultana, and Sahita⟧chen2018henet Li Chen, Salmin
    Sultana, and Ravi Sahita. Henet: A deep learning approach on intel® processor
    trace for effective exploit detection. In *2018 IEEE Security and Privacy Workshops
    (SPW)*, pages 109–115\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] Sohi et al.(2018)Sohi, Ganji, and Seifert⟧sohi2018recurrent Soroush M
    Sohi, Fatemeh Ganji, and Jean-Pierre Seifert. Recurrent neural networks for enhancement
    of signature-based network intrusion detection systems. *arXiv preprint arXiv:1807.03212*,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] Vinayakumar et al.(2017)Vinayakumar, Soman, and Poornachandran⟧vinayakumar2017applying
    R Vinayakumar, KP Soman, and Prabaharan Poornachandran. Applying convolutional
    neural network for network intrusion detection. In *Advances in Computing, Communications
    and Informatics (ICACCI), 2017 International Conference on*, pages 1222–1228\.
    IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] Aghakhani et al.(2018)Aghakhani, Machiry, Nilizadeh, Kruegel, and Vigna⟧aghakhani2018detecting
    Hojjat Aghakhani, Aravind Machiry, Shirin Nilizadeh, Christopher Kruegel, and
    Giovanni Vigna. Detecting deceptive reviews using generative adversarial networks.
    *arXiv preprint arXiv:1805.10364*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] Li et al.(2018)Li, Chen, Goh, and Ng⟧li2018anomaly Dan Li, Dacheng Chen,
    Jonathan Goh, and See-kiong Ng. Anomaly detection with generative adversarial
    networks for multivariate time series. *arXiv preprint arXiv:1809.04758*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] Gao et al.(2014)Gao, Gao, Gao, and Wang⟧gao2014intrusion Ni Gao, Ling
    Gao, Quanli Gao, and Hai Wang. An intrusion detection model based on deep belief
    networks. In *Advanced Cloud and Big Data (CBD), 2014 Second International Conference
    on*, pages 247–252\. IEEE, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] Peharz et al.(2018)Peharz, Vergari, Stelzner, Molina, Trapp, Kersting,
    and Ghahramani⟧peharz2018probabilistic Robert Peharz, Antonio Vergari, Karl Stelzner,
    Alejandro Molina, Martin Trapp, Kristian Kersting, and Zoubin Ghahramani. Probabilistic
    deep learning using random sum-product networks. *arXiv preprint arXiv:1806.01910*,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] Umer et al.(2018)Umer, Sher, and Bi⟧umer2018two Muhammad Fahad Umer, Muhammad
    Sher, and Yaxin Bi. A two-stage flow-based intrusion detection model for next-generation
    networks. *PloS one*, 13(1):e0180945, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] Yu et al.(2017)Yu, Long, and Cai⟧yu2017network Yang Yu, Jun Long, and
    Zhiping Cai. Network intrusion detection through stacking dilated convolutional
    autoencoders. *Security and Communication Networks*, 2017, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] Thing(2017)⟧thing2017ieee Vrizlynn LL Thing. Ieee 802.11 network anomaly
    detection and attack classification: A deep learning approach. In *Wireless Communications
    and Networking Conference (WCNC), 2017 IEEE*, pages 1–6\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] Zolotukhin et al.(2016)Zolotukhin, Hämäläinen, Kokkonen, and Siltanen⟧zolotukhin2016increasing
    Mikhail Zolotukhin, Timo Hämäläinen, Tero Kokkonen, and Jarmo Siltanen. Increasing
    web service availability by detecting application-layer ddos attacks in encrypted
    traffic. In *Telecommunications (ICT), 2016 23rd International Conference on*,
    pages 1–6\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] Cordero et al.(2016)Cordero, Hauke, Mühlhäuser, and Fischer⟧cordero2016analyzing
    Carlos García Cordero, Sascha Hauke, Max Mühlhäuser, and Mathias Fischer. Analyzing
    flow-based anomaly intrusion detection using replicator neural networks. In *Privacy,
    Security and Trust (PST), 2016 14th Annual Conference on*, pages 317–324\. IEEE,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] Alrawashdeh and Purdy(2016)⟧alrawashdeh2016toward Khaled Alrawashdeh and
    Carla Purdy. Toward an online anomaly intrusion detection system based on deep
    learning. In *Machine Learning and Applications (ICMLA), 2016 15th IEEE International
    Conference on*, pages 195–200\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] Tang et al.(2016)Tang, Mhamdi, McLernon, Zaidi, and Ghogho⟧tang2016deep
    Tuan A Tang, Lotfi Mhamdi, Des McLernon, Syed Ali Raza Zaidi, and Mounir Ghogho.
    Deep learning approach for network intrusion detection in software defined networking.
    In *Wireless Networks and Mobile Communications (WINCOM), 2016 International Conference
    on*, pages 258–263\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] Lopez-Martin et al.(2017)Lopez-Martin, Carro, Sanchez-Esguevillas, and
    Lloret⟧lopez2017conditional Manuel Lopez-Martin, Belen Carro, Antonio Sanchez-Esguevillas,
    and Jaime Lloret. Conditional variational autoencoder for prediction and feature
    recovery applied to intrusion detection in iot. *Sensors*, 17(9):1967, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] Al-Qatf et al.(2018)Al-Qatf, Alhabib, Al-Sabahi, et al.⟧al2018deep Majjed
    Al-Qatf, Mohammed Alhabib, Kamal Al-Sabahi, et al. Deep learning approach combining
    sparse autoen-coder with svm for network intrusion detection. *IEEE Access*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] Mirsky et al.(2018)Mirsky, Doitshman, Elovici, and Shabtai⟧mirsky2018kitsune
    Yisroel Mirsky, Tomer Doitshman, Yuval Elovici, and Asaf Shabtai. Kitsune: an
    ensemble of autoencoders for online network intrusion detection. *arXiv preprint
    arXiv:1802.09089*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] Aygun and Yavuz(2017)⟧aygun2017network R Can Aygun and A Gokhan Yavuz.
    Network anomaly detection with stochastically improved autoencoder based models.
    In *Cyber Security and Cloud Computing (CSCloud), 2017 IEEE 4th International
    Conference on*, pages 193–198\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] Lin et al.(2018)Lin, Shi, and Xue⟧lin2018idsgan Zilong Lin, Yong Shi,
    and Zhi Xue. Idsgan: Generative adversarial networks for attack generation against
    intrusion detection. *arXiv preprint arXiv:1809.02077*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] Yin et al.(2018)Yin, Zhu, Liu, Fei, and Zhang⟧yin2018enhancing Chuanlong
    Yin, Yuefei Zhu, Shengli Liu, Jinlong Fei, and Hetong Zhang. An enhancing framework
    for botnet detection using generative adversarial networks. In *2018 International
    Conference on Artificial Intelligence and Big Data (ICAIBD)*, pages 228–234\.
    IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] Ring et al.(2018)Ring, Schlör, Landes, and Hotho⟧ring2018flow Markus Ring,
    Daniel Schlör, Dieter Landes, and Andreas Hotho. Flow-based network traffic generation
    using generative adversarial networks. *arXiv preprint arXiv:1810.07795*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] Latah(2018)⟧latah2018deep Majd Latah. When deep learning meets security.
    *arXiv preprint arXiv:1807.04739*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] Intrator et al.(2018)Intrator, Katz, and Shabtai⟧intrator2018mdgan Yotam
    Intrator, Gilad Katz, and Asaf Shabtai. Mdgan: Boosting anomaly detection using$\backslash$$\backslash$multi-discriminator
    generative adversarial networks. *arXiv preprint arXiv:1810.05221*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] Matsubara et al.(2018)Matsubara, Tachibana, and Uehara⟧matsubara2018anomaly
    Takashi Matsubara, Ryosuke Tachibana, and Kuniaki Uehara. Anomaly machine component
    detection by deep generative model with unregularized score. In *2018 International
    Joint Conference on Neural Networks (IJCNN)*, pages 1–8\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] Nicolau et al.(2016)Nicolau, McDermott, et al.⟧nicolau2016hybrid Miguel
    Nicolau, James McDermott, et al. A hybrid autoencoder and density estimation model
    for anomaly detection. In *International Conference on Parallel Problem Solving
    from Nature*, pages 717–726\. Springer, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] Rigaki(2017)⟧rigaki2017adversarial Maria Rigaki. Adversarial deep learning
    against intrusion detection classifiers, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] Malaiya et al.(2018)Malaiya, Kwon, Kim, Suh, Kim, and Kim⟧malaiya2018empirical
    Ritesh K Malaiya, Donghwoon Kwon, Jinoh Kim, Sang C Suh, Hyunjoo Kim, and Ikkyun
    Kim. An empirical evaluation of deep learning for network anomaly detection. In
    *2018 International Conference on Computing, Networking and Communications (ICNC)*,
    pages 893–898\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] Kwon et al.(2018)Kwon, Natarajan, Suh, Kim, and Kim⟧kwon2018empirical
    Donghwoon Kwon, Kathiravan Natarajan, Sang C Suh, Hyunjoo Kim, and Jinoh Kim.
    An empirical study on network anomaly detection using convolutional neural networks.
    In *2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS)*,
    pages 1595–1598\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] Staudemeyer(2015)⟧staudemeyer2015applying Ralf C Staudemeyer. Applying
    long short-term memory recurrent neural networks to intrusion detection. *South
    African Computer Journal*, 56(1):136–154, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] Naseer et al.(2018)Naseer, Saleem, Khalid, Bashir, Han, Iqbal, and Han⟧naseer2018enhanced
    Sheraz Naseer, Yasir Saleem, Shehzad Khalid, Muhammad Khawar Bashir, Jihun Han,
    Muhammad Munwar Iqbal, and Kijun Han. Enhanced network anomaly detection based
    on deep neural networks. *IEEE Access*, 6:48231–48246, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] ucs(2017)⟧ucsdAnomalyDetect2017 Ucsd anomaly detection dataset. 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] Shiravi et al.(2012)Shiravi, Shiravi, Tavallaee, and Ghorbani⟧shiravi2012toward
    Ali Shiravi, Hadi Shiravi, Mahbod Tavallaee, and Ali A Ghorbani. Toward developing
    a systematic approach to generate benchmark datasets for intrusion detection.
    *computers & security*, 31(3):357–374, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] Adam et al.(2008)Adam, Rivlin, Shimshoni, and Reinitz⟧adam2008robust Amit
    Adam, Ehud Rivlin, Ilan Shimshoni, and Daviv Reinitz. Robust real-time unusual
    event detection using multiple fixed-location monitors. *IEEE transactions on
    pattern analysis and machine intelligence*, 30(3):555–560, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] Yin et al.(2017)Yin, Zhu, Fei, and He⟧yin2017deep Chuanlong Yin, Yuefei
    Zhu, Jinlong Fei, and Xinzheng He. A deep learning approach for intrusion detection
    using recurrent neural networks. *IEEE Access*, 5:21954–21961, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] Yousefi-Azar et al.(2017)Yousefi-Azar, Varadharajan, Hamey, and Tupakula⟧yousefi2017autoencoder
    Mahmood Yousefi-Azar, Vijay Varadharajan, Len Hamey, and Uday Tupakula. Autoencoder-based
    feature learning for cyber security applications. In *Neural Networks (IJCNN),
    2017 International Joint Conference on*, pages 3854–3861\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] Mohammadi and Namadchian(2017)⟧mohammadi2017new Shahriar Mohammadi and
    Amin Namadchian. A new deep learning approach for anomaly base ids using memetic
    classifier. *International Journal of Computers, Communications & Control*, 12(5),
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] Stolfo et al.(2000)Stolfo, Fan, Lee, Prodromidis, and Chan⟧stolfo2000cost
    J Stolfo, Wei Fan, Wenke Lee, Andreas Prodromidis, and Philip K Chan. Cost-based
    modeling and evaluation for data mining with application to fraud and intrusion
    detection. *Results from the JAM Project by Salvatore*, pages 1–15, 2000.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] Van et al.(2017)Van, Thinh, and Sach⟧van2017anomaly Nguyen Thanh Van,
    Tran Ngoc Thinh, and Le Thanh Sach. An anomaly-based network intrusion detection
    system using deep learning. In *System Science and Engineering (ICSSE), 2017 International
    Conference on*, pages 210–214\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] Fontugne et al.(2010)Fontugne, Borgnat, Abry, and Fukuda⟧fontugne2010mawilab
    Romain Fontugne, Pierre Borgnat, Patrice Abry, and Kensuke Fukuda. Mawilab: combining
    diverse anomaly detectors for automated anomaly labeling and performance benchmarking.
    In *Proceedings of the 6th International COnference*, page 8. ACM, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] jam(2009)⟧jamkRGCE Jamk university of applied sciences,realistic global
    cyber environment (rgce). 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] Creech and Hu(2014)⟧creech2014semantic Gideon Creech and Jiankun Hu. A
    semantic approach to host-based intrusion detection systems using contiguousand
    discontiguous system call patterns. *IEEE Transactions on Computers*, 63(4):807–819,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] University(2012)⟧ImmuneDatasets New Mexico University. Computer immune
    systems data sets. 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] Abdallah et al.(2016)Abdallah, Maarof, and Zainal⟧abdallah2016fraud Aisha
    Abdallah, Mohd Aizaini Maarof, and Anazida Zainal. Fraud detection system: A survey.
    *Journal of Network and Computer Applications*, 68:90–113, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] Lavion(2018)⟧Lavion2018 Didier; et al Lavion. Pwc’s global economic crime
    and fraud survey 2018. PwC.com, 2018. URL [https://www.pwc.com/gx/en/forensics/global-economic-crime-and-fraud-survey-2018.pdf](https://www.pwc.com/gx/en/forensics/global-economic-crime-and-fraud-survey-2018.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] Zhao(2013)⟧zhao2013fraud Lucy Ma Zhao. Fraud detection system, December 12
    2013. US Patent App. 13/494,741.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] Sorournejad et al.(2016)Sorournejad, Zojaji, Atani, and Monadjemi⟧sorournejad2016survey
    Samaneh Sorournejad, Zahra Zojaji, Reza Ebrahimi Atani, and Amir Hassan Monadjemi.
    A survey of credit card fraud detection techniques: data and technique oriented
    perspective. *CoRR abs/1611.06439*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] Zhou et al.(2018)Zhou, Cheng, Zhu, Guo, Zhou, Xu, Xue, and Zhang⟧zhou2018state
    Xun Zhou, Sicong Cheng, Meng Zhu, Chengkun Guo, Sida Zhou, Peng Xu, Zhenghua Xue,
    and Weishi Zhang. A state of the art survey of data mining-based fraud detection
    and credit scoring. In *MATEC Web of Conferences*, volume 189, page 03002\. EDP
    Sciences, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] Suganya and Kamalraj(2015)⟧suganya2015survey S Suganya and N Kamalraj.
    A survey on credit card fraud detection. *International Journal of Computer Science
    and Mobile Computing*, 4:241–244, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] Schreyer et al.(2017)Schreyer, Sattarov, Borth, Dengel, and Reimer⟧schreyer2017detection
    Marco Schreyer, Timur Sattarov, Damian Borth, Andreas Dengel, and Bernd Reimer.
    Detection of anomalies in large scale accounting data using deep autoencoder networks.
    *arXiv preprint arXiv:1709.05254*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] Wedge et al.(2017)Wedge, Kanter, Rubio, Perez, and Veeramachaneni⟧wedge2017solving
    Roy Wedge, James Max Kanter, Santiago Moral Rubio, Sergio Iglesias Perez, and
    Kalyan Veeramachaneni. Solving the” false positives” problem in fraud prediction.
    *arXiv preprint arXiv:1710.07709*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] Paula et al.(2016)Paula, Ladeira, Carvalho, and Marzagão⟧paula2016deep
    Ebberth L Paula, Marcelo Ladeira, Rommel N Carvalho, and Thiago Marzagão. Deep
    learning anomaly detection as support fraud investigation in brazilian exports
    and anti-money laundering. In *Machine Learning and Applications (ICMLA), 2016
    15th IEEE International Conference on*, pages 954–960\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] Renström and Holmsten(2018)⟧renstrom2018fraud Martin Renström and Timothy
    Holmsten. Fraud detection on unlabeled data with unsupervised machine learning,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] Kazemi and Zarrabi(2017)⟧kazemi2017using Zahra Kazemi and Houman Zarrabi.
    Using deep networks for fraud detection in the credit card transactions. In *Knowledge-Based
    Engineering and Innovation (KBEI), 2017 IEEE 4th International Conference on*,
    pages 0630–0633\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] Zheng et al.(2018a)Zheng, Yuan, Wu, Li, and Lu⟧zheng2018one Panpan Zheng,
    Shuhan Yuan, Xintao Wu, Jun Li, and Aidong Lu. One-class adversarial nets for
    fraud detection. *arXiv preprint arXiv:1803.01798*, 2018a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] Pumsirirat and Yan(2018)⟧pumsirirat2018credit Apapan Pumsirirat and Liu
    Yan. Credit card fraud detection using deep learning based on auto-encoder and
    restricted boltzmann machine. *INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE
    AND APPLICATIONS*, 9(1):18–25, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] Seeja and Zareapoor(2014)⟧seeja2014fraudminer KR Seeja and Masoumeh Zareapoor.
    Fraudminer: A novel credit card fraud detection model based on frequent itemset
    mining. *The Scientific World Journal*, 2014, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] Sweers et al.(2018)Sweers, Heskes, and Krijthe⟧sweers2018autoencoding
    Tom Sweers, Tom Heskes, and Jesse Krijthe. Autoencoding credit card fraud. 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] Fiore et al.(2017)Fiore, De Santis, Perla, Zanetti, and Palmieri⟧fiore2017using
    Ugo Fiore, Alfredo De Santis, Francesca Perla, Paolo Zanetti, and Francesco Palmieri.
    Using generative adversarial networks for improving classification effectiveness
    in credit card fraud detection. *Information Sciences*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] Choi and Jang(2018)⟧choi2018generative Hyunsun Choi and Eric Jang. Generative
    ensembles for robust anomaly detection. *arXiv preprint arXiv:1810.01392*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] Dorronsoro et al.(1997)Dorronsoro, Ginel, Sánchez, and Santa Cruz⟧dorronsoro1997neural
    Jose R Dorronsoro, Francisco Ginel, Carmen R Sánchez, and Carlos Santa Cruz. Neural
    fraud detection in credit card operations. *IEEE transactions on neural networks*,
    1997.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] Gómez et al.(2018)Gómez, Arévalo, Paredes, and Nin⟧gomez2018end Jon Ander
    Gómez, Juan Arévalo, Roberto Paredes, and Jordi Nin. End-to-end neural network
    architecture for fraud scoring in card payments. *Pattern Recognition Letters*,
    105:175–181, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[116] Wiese and Omlin(2009)⟧wiese2009credit Bénard Wiese and Christian Omlin.
    Credit card transactions, fraud detection, and machine learning: Modelling time
    with lstm recurrent neural networks. In *Innovations in neural information paradigms
    and applications*, pages 231–268\. Springer, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[117] Jurgovsky et al.(2018)Jurgovsky, Granitzer, Ziegler, Calabretto, Portier,
    He-Guelton, and Caelen⟧jurgovsky2018sequence Johannes Jurgovsky, Michael Granitzer,
    Konstantin Ziegler, Sylvie Calabretto, Pierre-Edouard Portier, Liyun He-Guelton,
    and Olivier Caelen. Sequence classification for credit-card fraud detection. *Expert
    Systems with Applications*, 100:234–245, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[118] Heryadi and Warnars(2017)⟧heryadi2017learning Yaya Heryadi and Harco
    Leslie Hendric Spits Warnars. Learning temporal representation of transaction
    amount for fraudulent transaction recognition using cnn, stacked lstm, and cnn-lstm.
    In *Cybernetics and Computational Intelligence (CyberneticsCom), 2017 IEEE International
    Conference on*, pages 84–89\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[119] Ando et al.(2016)Ando, Gomi, and Tanaka⟧ando2016detecting Yoshihiro Ando,
    Hidehito Gomi, and Hidehiko Tanaka. Detecting fraudulent behavior using recurrent
    neural networks. 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[120] Wang et al.(2017a)Wang, Liu, Gao, Qu, and Xu⟧wang2017session Shuhao Wang,
    Cancheng Liu, Xiang Gao, Hongtao Qu, and Wei Xu. Session-based fraud detection
    in online e-commerce transactions using recurrent neural networks. In *Joint European
    Conference on Machine Learning and Knowledge Discovery in Databases*, pages 241–252\.
    Springer, 2017a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[121] Alowais and Soon(2012)⟧alowais2012credit Mohammed Ibrahim Alowais and
    Lay-Ki Soon. Credit card fraud detection: Personalized or aggregated model. In
    *Mobile, Ubiquitous, and Intelligent Computing (MUSIC), 2012 Third FTRA International
    Conference on*, pages 114–119\. IEEE, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[122] Amarasinghe et al.(2018a)Amarasinghe, Aponso, and Krishnarajah⟧amarasinghe2018critical
    Thushara Amarasinghe, Achala Aponso, and Naomi Krishnarajah. Critical analysis
    of machine learning based approaches for fraud detection in financial transactions.
    In *Proceedings of the 2018 International Conference on Machine Learning Technologies*,
    pages 12–17\. ACM, 2018a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[123] Abroyan(2017a)⟧abroyan2017neural Narek Abroyan. Neural networks for financial
    market risk classification. 2017a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[124] Lp et al.(2018)Lp, Yu, Luwang, Zheng, Qiu, Zhao, Xia, and Li⟧lp2018transaction
    Xurui Lp, Wei Yu, Tianyu Luwang, Jianbin Zheng, Xuetao Qiu, Jintao Zhao, Lei Xia,
    and Yujiao Li. Transaction fraud detection using gru-centered sandwich-structured
    model. In *2018 IEEE 22nd International Conference on Computer Supported Cooperative
    Work in Design ((CSCWD))*, pages 467–472\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[125] Shen et al.(2007)Shen, Tong, and Deng⟧shen2007application Aihua Shen,
    Rencheng Tong, and Yaochen Deng. Application of classification models on credit
    card fraud detection. In *Service Systems and Service Management, 2007 International
    Conference on*, pages 1–4\. IEEE, 2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[126] Chouiekh and Haj(2018)⟧chouiekh2018convnets Alae Chouiekh and EL Hassane
    Ibn EL Haj. Convnets for fraud detection analysis. *Procedia Computer Science*,
    127:133–138, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[127] Abroyan(2017b)⟧abroyan2017convolutional Narek Abroyan. Convolutional
    and recurrent neural networks for real-time data classification. In *Innovative
    Computing Technology (INTECH), 2017 Seventh International Conference on*, pages
    42–45\. IEEE, 2017b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[128] Fu et al.(2016)Fu, Cheng, Tu, and Zhang⟧fu2016credit Kang Fu, Dawei Cheng,
    Yi Tu, and Liqing Zhang. Credit card fraud detection using convolutional neural
    networks. In *International Conference on Neural Information Processing*, pages
    483–490\. Springer, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[129] Lu(2017)⟧lu2017deep Yifei Lu. Deep neural networks and fraud detection,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[130] Wang et al.(2018a)Wang, Wang, Ye, Yan, Cai, and Pan⟧wang2018credit Chunzhi
    Wang, Yichao Wang, Zhiwei Ye, Lingyu Yan, Wencheng Cai, and Shang Pan. Credit
    card fraud detection based on whale algorithm optimized bp neural network. In
    *2018 13th International Conference on Computer Science & Education (ICCSE)*,
    pages 1–4\. IEEE, 2018a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[131] Zhang et al.(2018a)Zhang, Zhou, Zhang, Wang, and Wang⟧zhang2018model
    Zhaohui Zhang, Xinxin Zhou, Xiaobo Zhang, Lizhi Wang, and Pengwei Wang. A model
    based on convolutional neural network for online transaction fraud detection.
    *Security and Communication Networks*, 2018, 2018a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[132] Alsheikh et al.(2016)Alsheikh, Niyato, Lin, Tan, and Han⟧alsheikh2016mobile
    Mohammad Abu Alsheikh, Dusit Niyato, Shaowei Lin, Hwee-Pink Tan, and Zhu Han.
    Mobile big data analytics using deep learning and apache spark. *IEEE network*,
    30(3):22–29, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[133] Badhe(2017)⟧badhe2017click Anup Badhe. Click fraud detection in mobile
    ads served in programmatic inventory. *Neural Networks & Machine Learning*, 1(1):1–1,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[134] Akhter and Ahamad(2012)⟧akhter2012detecting Mohammad Iquebal Akhter and
    Mohammad Gulam Ahamad. Detecting telecommunication fraud using neural networks
    through data mining. *International Journal of Scientific and Engineering Research*,
    3(3):601–6, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[135] Jain(2017)⟧jain2017perspective Vanita Jain. Perspective analysis of telecommunication
    fraud detection using data stream analytics and neural network classification
    based data mining. *International Journal of Information Technology*, 9(3):303–310,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[136] Zheng et al.(2018b)Zheng, Zhou, Sheng, Xue, and Chen⟧zheng2018generative
    Yu-Jun Zheng, Xiao-Han Zhou, Wei-Guo Sheng, Yu Xue, and Sheng-Yong Chen. Generative
    adversarial network based telecom fraud detection at the receiving bank. *Neural
    Networks*, 102:78–86, 2018b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[137] Joudaki et al.(2015)Joudaki, Rashidian, Minaei-Bidgoli, Mahmoodi, Geraili,
    Nasiri, and Arab⟧joudaki2015using Hossein Joudaki, Arash Rashidian, Behrouz Minaei-Bidgoli,
    Mahmood Mahmoodi, Bijan Geraili, Mahdi Nasiri, and Mohammad Arab. Using data mining
    to detect health care fraud and abuse: a review of literature. *Global journal
    of health science*, 7(1):194, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[138] Roy and George(2017)⟧roy2017detecting Riya Roy and K Thomas George. Detecting
    insurance claims fraud using machine learning techniques. In *Circuit, Power and
    Computing Technologies (ICCPCT), 2017 International Conference on*, pages 1–6\.
    IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[139] Viaene et al.(2005)Viaene, Dedene, and Derrig⟧viaene2005auto Stijn Viaene,
    Guido Dedene, and Richard A Derrig. Auto claim fraud detection using bayesian
    learning neural networks. *Expert Systems with Applications*, 29(3):653–666, 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[140] Fajardo et al.(2018)Fajardo, Findlay, Houmanfar, Jaiswal, Liang, and
    Xie⟧fajardo2018vos Val Andrei Fajardo, David Findlay, Roshanak Houmanfar, Charu
    Jaiswal, Jiaxi Liang, and Honglei Xie. Vos: a method for variational oversampling
    of imbalanced data. *arXiv preprint arXiv:1809.02596*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[141] Keung et al.(2009)Keung, Karel, and Bright⟧keung2009neural Phillip Keung,
    Joycelin Karel, and Curtis Bright. Neural networks for insurance fraud detection,
    2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[142] Bauder and Khoshgoftaar(2017)⟧bauder2017medicare Richard A Bauder and
    Taghi M Khoshgoftaar. Medicare fraud detection using machine learning methods.
    In *Machine Learning and Applications (ICMLA), 2017 16th IEEE International Conference
    on*, pages 858–865\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[143] Lasaga and Santhana(2018)⟧lasaga2018deep Daniel Lasaga and Prakash Santhana.
    Deep learning to detect medical treatment fraud. In *KDD 2017 Workshop on Anomaly
    Detection in Finance*, pages 114–120, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[144] Ghasedi Dizaji et al.(2018)Ghasedi Dizaji, Wang, and Huang⟧ghasedi2018semi
    Kamran Ghasedi Dizaji, Xiaoqian Wang, and Heng Huang. Semi-supervised generative
    adversarial network for gene expression inference. In *Proceedings of the 24th
    ACM SIGKDD International Conference on Knowledge Discovery & Data Mining*, pages
    1435–1444\. ACM, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[145] Finlayson et al.(2018)Finlayson, Kohane, and Beam⟧finlayson2018adversarial
    Samuel G Finlayson, Isaac S Kohane, and Andrew L Beam. Adversarial attacks against
    medical deep learning systems. *arXiv preprint arXiv:1804.05296*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[146] Esteva et al.(2017)Esteva, Kuprel, Novoa, Ko, Swetter, Blau, and Thrun⟧esteva2017dermatologist
    Andre Esteva, Brett Kuprel, Roberto A Novoa, Justin Ko, Susan M Swetter, Helen M
    Blau, and Sebastian Thrun. Dermatologist-level classification of skin cancer with
    deep neural networks. *Nature*, 542(7639):115, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[147] Ye et al.(2017)Ye, Li, Adjeroh, and Iyengar⟧ye2017survey Yanfang Ye,
    Tao Li, Donald Adjeroh, and S Sitharama Iyengar. A survey on malware detection
    using data mining techniques. *ACM Computing Surveys (CSUR)*, 50(3):41, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[148] Hardy et al.(2016)Hardy, Chen, Hou, Ye, and Li⟧hardy2016dl4md William
    Hardy, Lingwei Chen, Shifu Hou, Yanfang Ye, and Xin Li. Dl4md: A deep learning
    framework for intelligent malware detection. In *Proceedings of the International
    Conference on Data Mining (DMIN)*, page 61\. The Steering Committee of The World
    Congress in Computer Science, Computer Engineering and Applied Computing (WorldComp),
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[149] De Paola et al.(2018)De Paola, Favaloro, Gaglio, Lo Re, and Morana⟧de2018malware
    Alessandra De Paola, Salvatore Favaloro, Salvatore Gaglio, G Lo Re, and Marco
    Morana. Malware detection through low-level features and stacked denoising autoencoders.
    In *2nd Italian Conference on Cyber Security, ITASEC 2018*, volume 2058\. CEUR-WS,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[150] Sewak et al.(2018)Sewak, Sahay, and Rathore⟧sewak2018investigation Mohit
    Sewak, Sanjay K Sahay, and Hemant Rathore. An investigation of a deep learning
    based malware detection system. In *Proceedings of the 13th International Conference
    on Availability, Reliability and Security*, page 26\. ACM, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[151] Kebede et al.(2017)Kebede, Djaneye-Boundjou, Narayanan, Ralescu, and
    Kapp⟧kebede2017classification Temesguen Messay Kebede, Ouboti Djaneye-Boundjou,
    Barath Narayanan Narayanan, Anca Ralescu, and David Kapp. Classification of malware
    programs using autoencoders based deep learning architecture and its application
    to the microsoft malware classification challenge (big 2015) dataset. In *Aerospace
    and Electronics Conference (NAECON), 2017 IEEE National*, pages 70–75\. IEEE,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[152] David and Netanyahu(2015)⟧david2015deepsign Omid E David and Nathan S
    Netanyahu. Deepsign: Deep learning for automatic malware signature generation
    and classification. In *Neural Networks (IJCNN), 2015 International Joint Conference
    on*, pages 1–8\. IEEE, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[153] Cakir and Dogdu(2018)⟧cakir2018malware Bugra Cakir and Erdogan Dogdu.
    Malware classification using deep learning methods. In *Proceedings of the ACMSE
    2018 Conference*, page 10\. ACM, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[154] Silva et al.(2018)Silva, Akhavan-Masouleh, and Li⟧silva2018improving
    Pedro Silva, Sepehr Akhavan-Masouleh, and Li Li. Improving malware detection accuracy
    by extracting icon information. In *2018 IEEE Conference on Multimedia Information
    Processing and Retrieval (MIPR)*, pages 408–411\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[155] Kolosnjaji et al.(2018)Kolosnjaji, Demontis, Biggio, Maiorca, Giacinto,
    Eckert, and Roli⟧kolosnjaji2018adversarial Bojan Kolosnjaji, Ambra Demontis, Battista
    Biggio, Davide Maiorca, Giorgio Giacinto, Claudia Eckert, and Fabio Roli. Adversarial
    malware binaries: Evading deep learning for malware detection in executables.
    *arXiv preprint arXiv:1803.04173*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[156] Suciu et al.(2018)Suciu, Coull, and Johns⟧suciu2018exploring Octavian
    Suciu, Scott E Coull, and Jeffrey Johns. Exploring adversarial examples in malware
    detection. *arXiv preprint arXiv:1810.08280*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[157] Srisakaokul et al.(2018)Srisakaokul, Zhong, Zhang, Yang, and Xie⟧srisakaokul2018muldef
    Siwakorn Srisakaokul, Zexuan Zhong, Yuhao Zhang, Wei Yang, and Tao Xie. Muldef:
    Multi-model-based defense against adversarial examples for neural networks. *arXiv
    preprint arXiv:1809.00065*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[158] King et al.(2018)King, Aggarwal, Taddeo, and Floridi⟧king2018artificial
    Thomas King, Nikita Aggarwal, Mariarosaria Taddeo, and Luciano Floridi. Artificial
    intelligence crime: An interdisciplinary analysis of foreseeable threats and solutions.
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[159] Huang and Kao(2017)⟧huang2017r2 TonTon Hsien-De Huang and Hung-Yu Kao.
    R2-d2: color-inspired convolutional neural network (cnn)-based android malware
    detections. *arXiv preprint arXiv:1705.04448*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[160] Guo et al.(2017)Guo, Wang, and Wei⟧guo2017malware Wei Guo, Tenghai Wang,
    and Jizeng Wei. Malware detection with convolutional neural network using hardware
    events. In *CCF National Conference on Compujter Engineering and Technology*,
    pages 104–115\. Springer, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[161] Abdelsalam et al.(2018)Abdelsalam, Krishnan, Huang, and Sandhu⟧abdelsalam2018malware
    Mahmoud Abdelsalam, Ram Krishnan, Yufei Huang, and Ravi Sandhu. Malware detection
    in cloud infrastructures using convolutional neural networks. In *2018 IEEE 11th
    International Conference on Cloud Computing (CLOUD)*, pages 162–169\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[162] Raff et al.(2017)Raff, Barker, Sylvester, Brandon, Catanzaro, and Nicholas⟧raff2017malware
    Edward Raff, Jon Barker, Jared Sylvester, Robert Brandon, Bryan Catanzaro, and
    Charles Nicholas. Malware detection by eating a whole exe. *arXiv preprint arXiv:1710.09435*,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[163] Karbab et al.(2018)Karbab, Debbabi, Derhab, and Mouheb⟧karbab2018maldozer
    ElMouatez Billah Karbab, Mourad Debbabi, Abdelouahid Derhab, and Djedjiga Mouheb.
    Maldozer: Automatic framework for android malware detection using deep learning.
    *Digital Investigation*, 24:S48–S59, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[164] Martinelli et al.(2017)Martinelli, Marulli, and Mercaldo⟧martinelli2017evaluating
    Fabio Martinelli, Fiammetta Marulli, and Francesco Mercaldo. Evaluating convolutional
    neural network for effective mobile malware detection. *Procedia Computer Science*,
    112:2372–2381, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[165] McLaughlin et al.(2017)McLaughlin, Martinez del Rincon, Kang, Yerima,
    Miller, Sezer, Safaei, Trickel, Zhao, Doupe, et al.⟧mclaughlin2017deep Niall McLaughlin,
    Jesus Martinez del Rincon, BooJoong Kang, Suleiman Yerima, Paul Miller, Sakir
    Sezer, Yeganeh Safaei, Erik Trickel, Ziming Zhao, Adam Doupe, et al. Deep android
    malware detection. In *Proceedings of the Seventh ACM on Conference on Data and
    Application Security and Privacy*, pages 301–308\. ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[166] Gibert et al.(2018)Gibert, Mateu, Planes, and Vicens⟧gibert2018using
    Daniel Gibert, Carles Mateu, Jordi Planes, and Ramon Vicens. Using convolutional
    neural networks for classification of malware represented as images. *Journal
    of Computer Virology and Hacking Techniques*, pages 1–14, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[167] Kolosnjaji et al.(2017)Kolosnjaji, Eraisha, Webster, Zarras, and Eckert⟧kolosnjaji2017empowering
    Bojan Kolosnjaji, Ghadir Eraisha, George Webster, Apostolis Zarras, and Claudia
    Eckert. Empowering convolutional networks for malware classification and analysis.
    In *Neural Networks (IJCNN), 2017 International Joint Conference on*, pages 3838–3845\.
    IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[168] Rosenberg et al.(2018)Rosenberg, Sicard, and David⟧rosenberg2018end Ishai
    Rosenberg, Guillaume Sicard, and Eli Omid David. End-to-end deep neural networks
    and transfer learning for automatic analysis of nation-state malware. *Entropy*,
    20(5):390, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[169] Wang et al.(2017b)Wang, Guo, Zhang, Ororbia II, Xing, Liu, and Giles⟧wang2017adversary
    Qinglong Wang, Wenbo Guo, Kaixuan Zhang, Alexander G Ororbia II, Xinyu Xing, Xue
    Liu, and C Lee Giles. Adversary resistant deep neural networks with an application
    to malware detection. In *Proceedings of the 23rd ACM SIGKDD International Conference
    on Knowledge Discovery and Data Mining*, pages 1145–1153\. ACM, 2017b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[170] YANG et al.(2016)YANG, ZHANG, MAO, and CHEN⟧yang2016application JIA YANG,
    HUIXIANG ZHANG, BAOLEI MAO, and CHUNLEI CHEN. Application of deep belief networks
    for android malware detection. *ICIC express letters. Part B, Applications: an
    international journal of research and surveys*, 7(7):1505–1510, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[171] Ding et al.(2016)Ding, Chen, and Xu⟧ding2016application Yuxin Ding, Sheng
    Chen, and Jun Xu. Application of deep belief networks for opcode based malware
    detection. In *Neural Networks (IJCNN), 2016 International Joint Conference on*,
    pages 3901–3908\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[172] Yuxin and Siyi(2017)⟧yuxin2017malware Ding Yuxin and Zhu Siyi. Malware
    detection based on deep learning algorithm. *Neural Computing and Applications*,
    pages 1–12, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[173] Selvaganapathy et al.(2018)Selvaganapathy, Nivaashini, and Natarajan⟧selvaganapathy2018deep
    ShymalaGowri Selvaganapathy, Mathappan Nivaashini, and HemaPriya Natarajan. Deep
    belief network based detection and categorization of malicious urls. *Information
    Security Journal: A Global Perspective*, 27(3):145–161, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[174] Hou et al.(2017)Hou, Saas, Chen, Ye, and Bourlai⟧hou2017deep Shifu Hou,
    Aaron Saas, Lingwei Chen, Yanfang Ye, and Thirimachos Bourlai. Deep neural networks
    for automatic android malware detection. In *Proceedings of the 2017 IEEE/ACM
    International Conference on Advances in Social Networks Analysis and Mining 2017*,
    pages 803–810\. ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[175] Tobiyama et al.(2016)Tobiyama, Yamaguchi, Shimada, Ikuse, and Yagi⟧tobiyama2016malware
    Shun Tobiyama, Yukiko Yamaguchi, Hajime Shimada, Tomonori Ikuse, and Takeshi Yagi.
    Malware detection with deep neural network using process behavior. In *Computer
    Software and Applications Conference (COMPSAC), 2016 IEEE 40th Annual*, volume 2,
    pages 577–582\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[176] Hu and Tan(2017)⟧hu2017black Weiwei Hu and Ying Tan. Black-box attacks
    against rnn based malware detection algorithms. *arXiv preprint arXiv:1705.08131*,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[177] Tobiyama et al.(2018)Tobiyama, Yamaguchi, Hasegawa, Shimada, Akiyama,
    and Yagi⟧tobiyama2018method Shun Tobiyama, Yukiko Yamaguchi, Hirokazu Hasegawa,
    Hajime Shimada, Mitsuaki Akiyama, and Takeshi Yagi. A method for estimating process
    maliciousness with seq2seq model. In *2018 International Conference on Information
    Networking (ICOIN)*, pages 255–260\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[178] Passalis and Tefas()⟧passalislong Nikolaos Passalis and Anastasios Tefas.
    Long-term temporal averaging for stochastic optimization of deep neural networks.
    *Neural Computing and Applications*, pages 1–13.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[179] Le et al.(2018)Le, Boydell, Mac Namee, and Scanlon⟧le2018deep Quan Le,
    Oisín Boydell, Brian Mac Namee, and Mark Scanlon. Deep learning at the shallow
    end: Malware classification for non-domain experts. *Digital Investigation*, 26:S118–S126,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[180] Kim et al.(2018)Kim, Bu, and Cho⟧kim2018zero Jin-Young Kim, Seok-Jun
    Bu, and Sung-Bae Cho. Zero-day malware detection using transferred generative
    adversarial networks based on deep autoencoders. *Information Sciences*, 460:83–102,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[181] Wang et al.(2018b)Wang, Zhao, and Wang⟧wang2018effective Wei Wang, Mengxue
    Zhao, and Jigang Wang. Effective android malware detection with a hybrid model
    based on deep autoencoder and convolutional neural network. *Journal of Ambient
    Intelligence and Humanized Computing*, pages 1–9, 2018b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[182] Li et al.(2015)Li, Ma, and Jiao⟧li2015hybrid Yuancheng Li, Rong Ma, and
    Runhai Jiao. A hybrid malicious code detection method based on deep learning.
    *methods*, 9(5), 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[183] HaddadPajouh et al.(2018)HaddadPajouh, Dehghantanha, Khayami, and Choo⟧haddadpajouh2018deep
    Hamed HaddadPajouh, Ali Dehghantanha, Raouf Khayami, and Kim-Kwang Raymond Choo.
    A deep recurrent neural network based approach for internet of things malware
    threat hunting. *Future Generation Computer Systems*, 85:88–96, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[184] Min et al.(2017)Min, Lee, and Yoon⟧min2017deep Seonwoo Min, Byunghan
    Lee, and Sungroh Yoon. Deep learning in bioinformatics. *Briefings in bioinformatics*,
    18(5):851–869, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[185] Cao et al.(2018a)Cao, Liu, Tan, Song, Shu, Li, Zhou, Bo, and Xie⟧cao2018deep
    Chensi Cao, Feng Liu, Hai Tan, Deshou Song, Wenjie Shu, Weizhong Li, Yiming Zhou,
    Xiaochen Bo, and Zhi Xie. Deep learning and its applications in biomedicine. *Genomics,
    proteomics & bioinformatics*, 2018a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[186] Zhao et al.(2016)Zhao, Yan, Chen, Mao, Wang, and Gao⟧zhao2016deep Rui
    Zhao, Ruqiang Yan, Zhenghua Chen, Kezhi Mao, Peng Wang, and Robert X Gao. Deep
    learning and its applications to machine health monitoring: A survey. *arXiv preprint
    arXiv:1612.07640*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[187] Khan and Yairi(2018)⟧khan2018review Samir Khan and Takehisa Yairi. A
    review on the application of deep learning in system health management. *Mechanical
    Systems and Signal Processing*, 107:241–265, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[188] Gugulothu et al.()Gugulothu, Malhotra, Vig, and Shroff⟧gugulothusparse
    Narendhar Gugulothu, Pankaj Malhotra, Lovekesh Vig, and Gautam Shroff. Sparse
    neural networks for anomaly detection in high-dimensional time series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[189] Amarasinghe et al.(2018b)Amarasinghe, Kenney, and Manic⟧amarasinghe2018toward
    Kasun Amarasinghe, Kevin Kenney, and Milos Manic. Toward explainable deep neural
    network based anomaly detection. In *2018 11th International Conference on Human
    System Interaction (HSI)*, pages 311–317\. IEEE, 2018b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[190] Choi(2018)⟧choi2018doctor Edward Choi. *Doctor AI: Interpretable Deep
    Learning for Modeling Electronic Health Records*. PhD thesis, Georgia Institute
    of Technology, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[191] Wang et al.(2016)Wang, Zhao, Xiong, Fan, Sun, Ma, and Liu⟧wang2016research
    Kai Wang, Youjin Zhao, Qingyu Xiong, Min Fan, Guotan Sun, Longkun Ma, and Tong
    Liu. Research on healthy anomaly detection model based on deep learning from multiple
    time-series physiological signals. *Scientific Programming*, 2016, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[192] Cowton et al.(2018)Cowton, Kyriazakis, Plötz, and Bacardit⟧cowton2018combined
    Jake Cowton, Ilias Kyriazakis, Thomas Plötz, and Jaume Bacardit. A combined deep
    learning gru-autoencoder for the early detection of respiratory disease in pigs
    using multiple environmental sensors. *Sensors*, 18(8):2521, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[193] Sato et al.(2018)Sato, Hanaoka, Nomura, Takenaga, Miki, Yoshikawa, Hayashi,
    and Abe⟧sato2018primitive Daisuke Sato, Shouhei Hanaoka, Yukihiro Nomura, Tomomi
    Takenaga, Soichiro Miki, Takeharu Yoshikawa, Naoto Hayashi, and Osamu Abe. A primitive
    study on unsupervised anomaly detection with an autoencoder in emergency head
    ct volumes. In *Medical Imaging 2018: Computer-Aided Diagnosis*, volume 10575,
    page 105751P. International Society for Optics and Photonics, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[194] Turner et al.(2014)Turner, Page, Mohsenin, and Oates⟧turner2014deep JT Turner,
    Adam Page, Tinoosh Mohsenin, and Tim Oates. Deep belief networks used on high
    resolution multichannel electroencephalography data for seizure detection. In
    *2014 AAAI Spring Symposium Series*, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[195] Sharma et al.(2016)Sharma, Sheet, and Biswas⟧sharma2016abnormality Manoj Kumar
    Sharma, Debdoot Sheet, and Prabir Kumar Biswas. Abnormality detecting deep belief
    network. In *Proceedings of the International Conference on Advances in Information
    Communication Technology & Computing*, page 11\. ACM, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[196] Ma et al.(2018)Ma, Peng, Wang, and Leong⟧ma2018unsupervised Ning Ma,
    Yu Peng, Shaojun Wang, and Philip HW Leong. An unsupervised deep hyperspectral
    anomaly detector. *Sensors*, 18(3):693, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[197] Zhang et al.(2016)Zhang, Wu, Bai, and Chen⟧zhang2016automatic Junming
    Zhang, Yan Wu, Jing Bai, and Fuqiang Chen. Automatic sleep stage classification
    based on sparse deep belief net and combination of multiple classifiers. *Transactions
    of the Institute of Measurement and Control*, 38(4):435–451, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[198] Wulsin et al.(2011)Wulsin, Gupta, Mani, Blanco, and Litt⟧wulsin2011modeling
    DF Wulsin, JR Gupta, R Mani, JA Blanco, and B Litt. Modeling electroencephalography
    waveforms with semi-supervised deep belief nets: fast classification and anomaly
    measurement. *Journal of neural engineering*, 8(3):036015, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[199] Wu et al.(2015a)Wu, Guo, and Ma⟧wu2015adaptive C Wu, Y Guo, and Y Ma.
    Adaptive anomalies detection with deep network. In *Proceeding of the Seventh
    International Conference on Adaptive and Self-Adaptive Systems and Applications*,
    2015a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[200] Liao et al.(2016)Liao, Jin, and Pavel⟧liao2016enhanced Linxia Liao, Wenjing
    Jin, and Radu Pavel. Enhanced restricted boltzmann machine with prognosability
    regularization for prognostics and health assessment. *IEEE Transactions on Industrial
    Electronics*, 63(11):7076–7083, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[201] Xu et al.(2018)Xu, Chen, Zhao, Li, Bu, Li, Liu, Zhao, Pei, Feng, et al.⟧xu2018unsupervised
    Haowen Xu, Wenxiao Chen, Nengwen Zhao, Zeyan Li, Jiahao Bu, Zhihan Li, Ying Liu,
    Youjian Zhao, Dan Pei, Yang Feng, et al. Unsupervised anomaly detection via variational
    auto-encoder for seasonal kpis in web applications. In *Proceedings of the 2018
    World Wide Web Conference on World Wide Web*, pages 187–196\. International World
    Wide Web Conferences Steering Committee, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[202] Lu and Xu(2018)⟧lu2018anomaly Yuchen Lu and Peng Xu. Anomaly detection
    for skin disease images using variational autoencoder. *arXiv preprint arXiv:1807.01349*,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[203] Chen and Konukoglu(2018)⟧chen2018unsupervised Xiaoran Chen and Ender
    Konukoglu. Unsupervised detection of lesions in brain mri using constrained adversarial
    auto-encoders. *arXiv preprint arXiv:1806.04972*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[204] Yang and Gao(2018)⟧yang2018toward Hangzhou Yang and Huiying Gao. Toward
    sustainable virtualized healthcare: Extracting medical entities from chinese online
    health consultations using deep neural networks. *Sustainability*, 10(9):3292,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[205] Jagannatha and Yu(2016)⟧jagannatha2016bidirectional Abhyuday N Jagannatha
    and Hong Yu. Bidirectional rnn for medical event detection in electronic health
    records. In *Proceedings of the conference. Association for Computational Linguistics.
    North American Chapter. Meeting*, volume 2016, page 473\. NIH Public Access, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[206] O’Shea et al.(2016)O’Shea, Clancy, and McGwier⟧o2016recurrent Timothy J
    O’Shea, T Charles Clancy, and Robert W McGwier. Recurrent neural radio anomaly
    detection. *arXiv preprint arXiv:1611.00301*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[207] Latif et al.(2018)Latif, Usman, Rana, and Qadir⟧latif2018phonocardiographic
    Siddique Latif, Muhammad Usman, Rajib Rana, and Junaid Qadir. Phonocardiographic
    sensing using deep learning for abnormal heartbeat detection. *IEEE Sensors Journal*,
    18(22):9393–9400, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[208] Zhang and Zou(2018)⟧zhang2018time Runtian Zhang and Qian Zou. Time series
    prediction and anomaly detection of light curve using lstm neural network. In
    *Journal of Physics: Conference Series*, volume 1061, page 012012\. IOP Publishing,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[209] Chauhan and Vig(2015)⟧chauhan2015anomaly Sucheta Chauhan and Lovekesh
    Vig. Anomaly detection in ecg time signals via deep long short-term memory networks.
    In *Data Science and Advanced Analytics (DSAA), 2015\. 36678 2015\. IEEE International
    Conference on*, pages 1–7\. IEEE, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[210] Schmidt-Erfurth et al.(2018)Schmidt-Erfurth, Sadeghipour, Gerendas, Waldstein,
    and Bogunović⟧schmidt2018artificial Ursula Schmidt-Erfurth, Amir Sadeghipour,
    Bianca S Gerendas, Sebastian M Waldstein, and Hrvoje Bogunović. Artificial intelligence
    in retina. *Progress in retinal and eye research*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[211] Iakovidis et al.(2018)Iakovidis, Georgakopoulos, Vasilakakis, Koulaouzidis,
    and Plagianakos⟧iakovidis2018detecting Dimitris K Iakovidis, Spiros V Georgakopoulos,
    Michael Vasilakakis, Anastasios Koulaouzidis, and Vassilis P Plagianakos. Detecting
    and locating gastrointestinal anomalies using deep learning and iterative cluster
    unification. *IEEE Transactions on Medical Imaging*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[212] Liu and Chawla(2017)⟧liu2017social Yan Liu and Sanjay Chawla. Social
    media anomaly detection: Challenges and solutions. In *Proceedings of the Tenth
    ACM International Conference on Web Search and Data Mining*, pages 817–818\. ACM,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[213] Savage et al.(2014)Savage, Zhang, Yu, Chou, and Wang⟧savage2014anomaly
    David Savage, Xiuzhen Zhang, Xinghuo Yu, Pauline Chou, and Qingmai Wang. Anomaly
    detection in online social networks. *Social Networks*, 39:62–70, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[214] Anand et al.(2017)Anand, Kumar, and Anand⟧anand2017anomaly Ketan Anand,
    Jay Kumar, and Kunal Anand. Anomaly detection in online social network: A survey.
    In *Inventive Communication and Computational Technologies (ICICCT), 2017 International
    Conference on*, pages 456–459\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[215] Yu et al.(2016)Yu, Qiu, Wen, Lin, and Liu⟧yu2016survey Rose Yu, Huida
    Qiu, Zhen Wen, ChingYung Lin, and Yan Liu. A survey on social media anomaly detection.
    *ACM SIGKDD Explorations Newsletter*, 18(1):1–14, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[216] Cao et al.(2018b)Cao, Guo, Li, Jin, Guo, and Li⟧cao2018automatic Juan
    Cao, Junbo Guo, Xirong Li, Zhiwei Jin, Han Guo, and Jintao Li. Automatic rumor
    detection on microblogs: A survey. *arXiv preprint arXiv:1807.03505*, 2018b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[217] Zhang et al.(2017)Zhang, Chen, Yeo, Lau, and Lee⟧zhang2017detecting Yan
    Zhang, Weiling Chen, Chai Kiat Yeo, Chiew Tong Lau, and Bu Sung Lee. Detecting
    rumors on online social networks using multi-layer autoencoder. In *Technology
    & Engineering Management Conference (TEMSCON), 2017 IEEE*, pages 437–441\. IEEE,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[218] Castellini et al.(2017)Castellini, Poggioni, and Sorbi⟧castellini2017fake
    Jacopo Castellini, Valentina Poggioni, and Giulia Sorbi. Fake twitter followers
    detection by denoising autoencoder. In *Proceedings of the International Conference
    on Web Intelligence*, pages 195–202\. ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[219] Sun et al.(2018)Sun, Zhang, Ding, and Quan⟧sun2018detecting Xiao Sun,
    Chen Zhang, Shuai Ding, and Changqin Quan. Detecting anomalous emotion through
    big data from social networks based on a deep learning method. *Multimedia Tools
    and Applications*, pages 1–22, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[220] Shu et al.(2017)Shu, Xu, and Liu⟧shu2017doc Lei Shu, Hu Xu, and Bing
    Liu. Doc: Deep open classification of text documents. *arXiv preprint arXiv:1709.08716*,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[221] Yang et al.(2018)Yang, Cao, Ni, and Zou⟧yang2018anomaly Biao Yang, Jinmeng
    Cao, Rongrong Ni, and Ling Zou. Anomaly detection in moving crowds through spatiotemporal
    autoencoding and additional attention. *Advances in Multimedia*, 2018, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[222] Li et al.(2017a)Li, Sun, Zhu, and Lin⟧li2017detecting Ze Li, Duoyong
    Sun, Renqi Zhu, and Zihan Lin. Detecting event-related changes in organizational
    networks using optimized neural network models. *PloS one*, 12(11):e0188733, 2017a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[223] Wei(2017)⟧wei2017new Wei. Hybrid models for anomaly detection in social
    networks. *arXiv preprint arXiv:1709.08716*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[224] Memon(2008)⟧memon2008log Ahmed Umar Memon. *Log file categorization and
    anomaly analysis using grammar inference*. PhD thesis, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[225] Brown et al.(2018)Brown, Tuor, Hutchinson, and Nichols⟧brown2018recurrent
    Andy Brown, Aaron Tuor, Brian Hutchinson, and Nicole Nichols. Recurrent neural
    network attention mechanisms for interpretable system log anomaly detection. *arXiv
    preprint arXiv:1803.04967*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[226] Das et al.(2018)Das, Mueller, Siegel, and Vishnu⟧das2018desh Anwesha
    Das, Frank Mueller, Charles Siegel, and Abhinav Vishnu. Desh: deep learning for
    system health prediction of lead times to failure in hpc. In *Proceedings of the
    27th International Symposium on High-Performance Parallel and Distributed Computing*,
    pages 40–51\. ACM, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[227] Malhotra et al.(2015)Malhotra, Vig, Shroff, and Agarwal⟧malhotra2015long
    Pankaj Malhotra, Lovekesh Vig, Gautam Shroff, and Puneet Agarwal. Long short term
    memory networks for anomaly detection in time series. In *Proceedings*, page 89\.
    Presses universitaires de Louvain, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[228] Sakurada and Yairi(2014)⟧sakurada2014anomaly Mayu Sakurada and Takehisa
    Yairi. Anomaly detection using autoencoders with nonlinear dimensionality reduction.
    In *Proceedings of the MLSDA 2014 2nd Workshop on Machine Learning for Sensory
    Data Analysis*, page 4\. ACM, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[229] Nolle et al.(2018a)Nolle, Luettgen, Seeliger, and Mühlhäuser⟧nolle2018analyzing
    Timo Nolle, Stefan Luettgen, Alexander Seeliger, and Max Mühlhäuser. Analyzing
    business process anomalies using autoencoders. *Machine Learning*, pages 1–19,
    2018a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[230] Nolle et al.(2016)Nolle, Seeliger, and Mühlhäuser⟧nolle2016unsupervised
    Timo Nolle, Alexander Seeliger, and Max Mühlhäuser. Unsupervised anomaly detection
    in noisy business process event logs using denoising autoencoders. In *International
    conference on discovery science*, pages 442–456\. Springer, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[231] Grover(2018)⟧grover2018anomaly Aarish Grover. Anomaly detection for application
    log data. 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[232] Wolpher(2018)⟧wolpher2018anomaly Maxim Wolpher. Anomaly detection in
    unstructured time series datausing an lstm autoencoder, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[233] Zhang et al.(2018b)Zhang, Zheng, Wen, Xu, Wang, Yu, and Meng⟧zhang2018role
    Dongxue Zhang, Yang Zheng, Yu Wen, Yujue Xu, Jingchuo Wang, Yang Yu, and Dan Meng.
    Role-based log analysis applying deep learning for insider threat detection. In
    *Proceedings of the 1st Workshop on Security-Oriented Designs of Computer Architectures
    and Processors*, pages 18–20\. ACM, 2018b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[234] Nanduri and Sherry(2016)⟧nanduri2016anomaly Anvardh Nanduri and Lance
    Sherry. Anomaly detection in aircraft data using recurrent neural networks (rnn).
    In *Integrated Communications Navigation and Surveillance (ICNS), 2016*, pages
    5C2–1\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[235] Fengming et al.(2017)Fengming, Shufang, Zhimin, Bo, Shiming, and Mingming⟧fengming2017anomaly
    Zheng Fengming, Li Shufang, Guo Zhimin, Wu Bo, Tian Shiming, and Pan Mingming.
    Anomaly detection in smart grid based on encoder-decoder framework with recurrent
    neural network. *The Journal of China Universities of Posts and Telecommunications*,
    24(6):67–73, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[236] Marchi et al.(2015)Marchi, Vesperini, Weninger, Eyben, Squartini, and
    Schuller⟧marchi2015non Erik Marchi, Fabio Vesperini, Felix Weninger, Florian Eyben,
    Stefano Squartini, and Björn Schuller. Non-linear prediction with lstm recurrent
    neural networks for acoustic novelty detection. In *Neural Networks (IJCNN), 2015
    International Joint Conference on*, pages 1–7\. IEEE, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[237] Lu et al.(2018)Lu, Wei, Li, and Wang⟧lu2018detecting Siyang Lu, Xiang
    Wei, Yandong Li, and Liqiang Wang. Detecting anomaly in big data system logs using
    convolutional neural network. In *2018 IEEE 16th Intl Conf on Dependable, Autonomic
    and Secure Computing, 16th Intl Conf on Pervasive Intelligence and Computing,
    4th Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology
    Congress (DASC/PiCom/DataCom/CyberSciTech)*, pages 151–158\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[238] Yuan et al.(2018a)Yuan, Cao, Shang, Liu, Tan, and Fang⟧yuan2018insider
    Fangfang Yuan, Yanan Cao, Yanmin Shang, Yanbing Liu, Jianlong Tan, and Binxing
    Fang. Insider threat detection with deep neural network. In *International Conference
    on Computational Science*, pages 43–54\. Springer, 2018a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[239] Racki et al.(2018)Racki, Tomazevic, and Skocaj⟧racki2018compact Domen
    Racki, Dejan Tomazevic, and Danijel Skocaj. A compact convolutional neural network
    for textured surface anomaly detection. In *2018 IEEE Winter Conference on Applications
    of Computer Vision (WACV)*, pages 1331–1339\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[240] Zhou et al.(2016)Zhou, Shen, Zeng, Fang, Wei, and Zhang⟧zhou2016spatial
    Shifu Zhou, Wei Shen, Dan Zeng, Mei Fang, Yuanwang Wei, and Zhijiang Zhang. Spatial–temporal
    convolutional neural networks for anomaly detection and localization in crowded
    scenes. *Signal Processing: Image Communication*, 47:358–368, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[241] Gorokhov et al.(2017)Gorokhov, Petrovskiy, and Mashechkin⟧gorokhov2017convolutional
    Oleg Gorokhov, Mikhail Petrovskiy, and Igor Mashechkin. Convolutional neural networks
    for unsupervised anomaly detection in text data. In *International Conference
    on Intelligent Data Engineering and Automated Learning*, pages 500–507\. Springer,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[242] Liao et al.(2017)Liao, Guzdial, and Riedl⟧liao2017deep Nicholas Liao,
    Matthew Guzdial, and Mark Riedl. Deep convolutional player modeling on log and
    level data. In *Proceedings of the 12th International Conference on the Foundations
    of Digital Games*, page 41\. ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[243] Cheng et al.(2017)Cheng, Ren, Wang, and Zhan⟧cheng2017deep Jiechao Cheng,
    Rui Ren, Lei Wang, and Jianfeng Zhan. Deep convolutional neural networks for anomaly
    event classification on distributed systems. *arXiv preprint arXiv:1710.09052*,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[244] Zhang et al.(2018c)Zhang, Zhao, Feng, and Lyu⟧zhang2018alphamex Boxue
    Zhang, Qi Zhao, Wenquan Feng, and Shuchang Lyu. Alphamex: A smarter global pooling
    method for convolutional neural networks. *Neurocomputing*, 321:36–48, 2018c.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[245] Mohammadi et al.(2018)Mohammadi, Al-Fuqaha, Sorour, and Guizani⟧mohammadi2018deep
    Mehdi Mohammadi, Ala Al-Fuqaha, Sameh Sorour, and Mohsen Guizani. Deep learning
    for iot big data and streaming analytics: A survey. *IEEE Communications Surveys
    & Tutorials*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[246] Luo and Nagarajany(2018)⟧luo2018distributed Tie Luo and Sai G Nagarajany.
    Distributed anomaly detection using autoencoder neural networks in wsn for iot.
    In *2018 IEEE International Conference on Communications (ICC)*, pages 1–6\. IEEE,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[247] Mohammadi and Kwasinski(2018)⟧mohammadi2018neural Fatemeh Shah Mohammadi
    and Andres Kwasinski. Neural network cognitive engine for autonomous and distributed
    underlay dynamic spectrum access. *arXiv preprint arXiv:1806.11038*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[248] Kakanakova and Stoyanov(2017)⟧kakanakova2017outlier Irina Kakanakova
    and Stefan Stoyanov. Outlier detection via deep learning architecture. In *Proceedings
    of the 18th International Conference on Computer Systems and Technologies*, pages
    73–79\. ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[249] Zhang et al.(2018d)Zhang, Guo, Liu, Liu, Zhou, Li, Lu, and Yang⟧zhang2018lstm
    Weishan Zhang, Wuwu Guo, Xin Liu, Yan Liu, Jiehan Zhou, Bo Li, Qinghua Lu, and
    Su Yang. Lstm-based analysis of industrial iot equipment. *IEEE Access*, 6:23551–23560,
    2018d.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[250] Mudassar et al.(2018)Mudassar, Ko, and Mukhopadhyay⟧mudassar2018unsupervised
    Burhan A Mudassar, Jong Hwan Ko, and Saibal Mukhopadhyay. An unsupervised anomalous
    event detection framework with class aware source separation. In *2018 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP)*, pages 2671–2675\.
    IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[251] Martí et al.(2015)Martí, Sanchez-Pi, Molina, and Garcia⟧marti2015anomaly
    Luis Martí, Nayat Sanchez-Pi, José Manuel Molina, and Ana Cristina Bicharra Garcia.
    Anomaly detection based on sensor data in petroleum industry applications. *Sensors*,
    15(2):2774–2797, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[252] Atha and Jahanshahi(2018)⟧atha2018evaluation Deegan J Atha and Mohammad R
    Jahanshahi. Evaluation of deep learning approaches based on convolutional neural
    networks for corrosion detection. *Structural Health Monitoring*, 17(5):1110–1128,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[253] de Deijn(2018)⟧de2018automatic Jeffrey de Deijn. Automatic car damage
    recognition using convolutional neural networks. 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[254] Wang et al.(2018c)Wang, Kerekes, Xu, and Wang⟧wang2018residential Fan
    Wang, John P Kerekes, Zhuoyi Xu, and Yandong Wang. Residential roof condition
    assessment system using deep learning. *Journal of Applied Remote Sensing*, 12(1):016040,
    2018c.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[255] Inoue et al.(2017)Inoue, Yamagata, Chen, Poskitt, and Sun⟧inoue2017anomaly
    Jun Inoue, Yoriyuki Yamagata, Yuqi Chen, Christopher M Poskitt, and Jun Sun. Anomaly
    detection for a water treatment system using unsupervised machine learning. In
    *Data Mining Workshops (ICDMW), 2017 IEEE International Conference on*, pages
    1058–1065\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[256] Thi et al.(2017)Thi, Le-Khac, et al.⟧thi2017one Nga Nguyen Thi, Nhien-An
    Le-Khac, et al. One-class collective anomaly detection based on lstm-rnns. In
    *Transactions on Large-Scale Data-and Knowledge-Centered Systems XXXVI*, pages
    73–85\. Springer, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[257] Kravchik and Shabtai(2018)⟧kravchik2018detecting Moshe Kravchik and Asaf
    Shabtai. Detecting cyber attacks in industrial control systems using convolutional
    neural networks. In *Proceedings of the 2018 Workshop on Cyber-Physical Systems
    Security and PrivaCy*, pages 72–83\. ACM, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[258] Huang et al.(2018)Huang, Chu, and Wu⟧huang2018deep Guanjie Huang, Chao-Hsien
    Chu, and Xiaodan Wu. A deep learning-based method for sleep stage classification
    using physiological signal. In *International Conference on Smart Health*, pages
    249–260. Springer, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[259] Park et al.(2018a)Park, Kim, An, and Jung⟧park2018lired Donghyun Park,
    Seulgi Kim, Yelin An, and Jae-Yoon Jung. Lired: A light-weight real-time fault
    detection system for edge computing using lstm recurrent neural networks. *Sensors*,
    18(7):2110, 2018a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[260] Chang et al.(2018)Chang, Lee, and Liu⟧chang2018review Chih-Wen Chang,
    Hau-Wei Lee, and Chein-Hung Liu. A review of artificial intelligence algorithms
    used for smart machine tools. *Inventions*, 3(3):41, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[261] Yuan and Jia(2015)⟧yuan2015distributed Ye Yuan and Kebin Jia. A distributed
    anomaly detection method of operation energy consumption using smart meter data.
    In *Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP),
    2015 International Conference on*, pages 310–313. IEEE, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[262] Araya et al.(2017)Araya, Grolinger, ElYamany, Capretz, and Bitsuamlak⟧araya2017ensemble
    Daniel B Araya, Katarina Grolinger, Hany F ElYamany, Miriam AM Capretz, and Girma
    Bitsuamlak. An ensemble learning framework for anomaly detection in building energy
    consumption. *Energy and Buildings*, 144:191–206, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[263] Qu et al.(2017)Qu, He, Deutsch, and He⟧qu2017detection Yongzhi Qu, Miao
    He, Jason Deutsch, and David He. Detection of pitting in gears using a deep sparse
    autoencoder. *Applied Sciences*, 7(5):515, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[264] Bhattad et al.(2018)Bhattad, Rock, and Forsyth⟧bhattad2018detecting Anand
    Bhattad, Jason Rock, and David Forsyth. Detecting anomalous faces with’no peeking’autoencoders.
    *arXiv preprint arXiv:1802.05798*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[265] Lodhi et al.(2017)Lodhi, Hasan, Hasan, and Awwadl⟧lodhi2017power Faiq Khalid
    Lodhi, Syed Rafay Hasan, Osman Hasan, and Falah Awwadl. Power profiling of microcontroller’s
    instruction set for runtime hardware trojans detection without golden circuit
    models. In *Proceedings of the Conference on Design, Automation & Test in Europe*,
    pages 294–297\. European Design and Automation Association, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[266] Faghih-Roohi et al.(2016)Faghih-Roohi, Hajizadeh, Núñez, Babuska, and
    De Schutter⟧faghih2016deep Shahrzad Faghih-Roohi, Siamak Hajizadeh, Alfredo Núñez,
    Robert Babuska, and Bart De Schutter. Deep convolutional neural networks for detection
    of rail surface defects. In *Neural Networks (IJCNN), 2016 International Joint
    Conference on*, pages 2584–2589\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[267] Christiansen et al.(2016)Christiansen, Nielsen, Steen, Jørgensen, and
    Karstoft⟧christiansen2016deepanomaly Peter Christiansen, Lars N Nielsen, Kim A
    Steen, Rasmus N Jørgensen, and Henrik Karstoft. Deepanomaly: Combining background
    subtraction and deep learning for detecting obstacles and anomalies in an agricultural
    field. *Sensors*, 16(11):1904, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[268] Lee et al.(2016)Lee, Siu, Cruz, and Yetman⟧lee2016convolutional Dean
    Lee, Vincent Siu, Rick Cruz, and Charles Yetman. Convolutional neural net and
    bearing fault analysis. In *Proceedings of the International Conference on Data
    Mining series (ICDM) Barcelona*, pages 194–200, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[269] Dong et al.(2016)Dong, Zhang, Wen, and Wu⟧dong2016camera Lingping Dong,
    Yongliang Zhang, Conglin Wen, and Hongtao Wu. Camera anomaly detection based on
    morphological analysis and deep learning. In *Digital Signal Processing (DSP),
    2016 IEEE International Conference on*, pages 266–270\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[270] Fuentes et al.(2017)Fuentes, Yoon, Kim, and Park⟧fuentes2017robust Alvaro
    Fuentes, Sook Yoon, Sang Cheol Kim, and Dong Sun Park. A robust deep-learning-based
    detector for real-time tomato plant diseases and pests recognition. *Sensors*,
    17(9):2022, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[271] Yan and Yu(2015)⟧yan2015accurate Weizhong Yan and Lijie Yu. On accurate
    and reliable anomaly detection for gas turbine combustors: A deep learning approach.
    In *Proceedings of the annual conference of the prognostics and health management
    society*, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[272] Luo and Zhong(2017)⟧luo2017gas Hui Luo and Shisheng Zhong. Gas turbine
    engine gas path anomaly detection using deep learning with gaussian distribution.
    In *Prognostics and System Health Management Conference (PHM-Harbin), 2017*, pages
    1–6\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[273] Dai et al.(2017)Dai, Song, Sheng, and Jiang⟧dai2017cleaning Jiejie Dai,
    Hui Song, Gehao Sheng, and Xiuchen Jiang. Cleaning method for status monitoring
    data of power equipment based on stacked denoising autoencoders. *IEEE Access*,
    5:22863–22870, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[274] Banjanovic-Mehmedovic et al.(2017)Banjanovic-Mehmedovic, Hajdarevic,
    Kantardzic, Mehmedovic, and Dzananovic⟧banjanovic2017neural Lejla Banjanovic-Mehmedovic,
    Amel Hajdarevic, Mehmed Kantardzic, Fahrudin Mehmedovic, and Izet Dzananovic.
    Neural network-based data-driven modelling of anomaly detection in thermal power
    plant. *Automatika*, 58(1):69–79, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[275] Shipmon et al.(2017a)Shipmon, Gurevitch, Piselli, and Edwards⟧shipmon2017time
    Dominique T Shipmon, Jason M Gurevitch, Paolo M Piselli, and Stephen T Edwards.
    Time series anomaly detection; detection of anomalous drops with limited features
    and sparse examples in noisy highly periodic data. *arXiv preprint arXiv:1708.03665*,
    2017a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[276] Hundman et al.(2018)Hundman, Constantinou, Laporte, Colwell, and Soderstrom⟧hundman2018detecting
    Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, and Tom
    Soderstrom. Detecting spacecraft anomalies using lstms and nonparametric dynamic
    thresholding. *arXiv preprint arXiv:1802.04431*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[277] Zhu and Laptev(2017)⟧zhu2017deep Lingxue Zhu and Nikolay Laptev. Deep
    and confident prediction for time series at uber. In *Data Mining Workshops (ICDMW),
    2017 IEEE International Conference on*, pages 103–110\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[278] Assendorp(2017)⟧assendorp2017deep Jan Paul Assendorp. *Deep learning
    for anomaly detection in multivariate time series data*. PhD thesis, Hochschule
    für Angewandte Wissenschaften Hamburg, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[279] Ahmad et al.(2017)Ahmad, Lavin, Purdy, and Agha⟧ahmad2017unsupervised
    Subutai Ahmad, Alexander Lavin, Scott Purdy, and Zuha Agha. Unsupervised real-time
    anomaly detection for streaming data. *Neurocomputing*, 262:134–147, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[280] Malhotra et al.(2016a)Malhotra, Ramakrishnan, Anand, Vig, Agarwal, and
    Shroff⟧malhotra2016lstm Pankaj Malhotra, Anusha Ramakrishnan, Gaurangi Anand,
    Lovekesh Vig, Puneet Agarwal, and Gautam Shroff. Lstm-based encoder-decoder for
    multi-sensor anomaly detection. *arXiv preprint arXiv:1607.00148*, 2016a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[281] Taylor et al.(2016)Taylor, Leblanc, and Japkowicz⟧taylor2016anomaly Adrian
    Taylor, Sylvain Leblanc, and Nathalie Japkowicz. Anomaly detection in automobile
    control network data with long short-term memory networks. In *Data Science and
    Advanced Analytics (DSAA), 2016 IEEE International Conference on*, pages 130–139\.
    IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[282] Cheng et al.(2016)Cheng, Xu, Lv, Liu, Li, Wang, et al.⟧cheng2016ms Min
    Cheng, Qian Xu, Jianming Lv, Wenyin Liu, Qing Li, Jianping Wang, et al. Ms-lstm:
    A multi-scale lstm model for bgp anomaly detection. In *2016 IEEE 24th International
    Conference on Network Protocols (ICNP)*, pages 1–6\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[283] Loganathan et al.(2018)Loganathan, Samarabandu, and Wang⟧loganathan2018sequence
    Gobinath Loganathan, Jagath Samarabandu, and Xianbin Wang. Sequence to sequence
    pattern learning algorithm for real-time anomaly detection in network traffic.
    In *2018 IEEE Canadian Conference on Electrical & Computer Engineering (CCECE)*,
    pages 1–4\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[284] Munir et al.(2018)Munir, Siddiqui, Dengel, and Ahmed⟧munir2018deepant
    Mohsin Munir, Shoaib Ahmed Siddiqui, Andreas Dengel, and Sheraz Ahmed. Deepant:
    A deep learning approach for unsupervised anomaly detection in time series. *IEEE
    Access*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[285] Shipmon et al.(2017b)Shipmon, Gurevitch, Piselli, and Edwards⟧Dominique
    Dominique Shipmon, Jason Gurevitch, Paolo M Piselli, and Steve Edwards. Time series
    anomaly detection: Detection of anomalous drops with limited features and sparse
    examples in noisy periodic data. Technical report, Google Inc., 2017b. URL [https://arxiv.org/abs/1708.03665](https://arxiv.org/abs/1708.03665).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[286] Malhotra et al.(2016b)Malhotra, TV, Ramakrishnan, Anand, Vig, Agarwal,
    and Shroff⟧malhotra2016multi Pankaj Malhotra, Vishnu TV, Anusha Ramakrishnan,
    Gaurangi Anand, Lovekesh Vig, Puneet Agarwal, and Gautam Shroff. Multi-sensor
    prognostics using an unsupervised health index based on lstm encoder-decoder.
    *arXiv preprint arXiv:1608.06154*, 2016b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[287] Filonov et al.(2016)Filonov, Lavrentyev, and Vorontsov⟧filonov2016multivariate
    Pavel Filonov, Andrey Lavrentyev, and Artem Vorontsov. Multivariate industrial
    time series with cyber-attack simulation: Fault detection using an lstm-based
    predictive data model. *arXiv preprint arXiv:1612.06676*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[288] Sugimoto et al.(2018)Sugimoto, Lee, and Okada⟧sugimoto2018deep Kaiji
    Sugimoto, Saerom Lee, and Yoshifumi Okada. Deep learning-based detection of periodic
    abnormal waves in ecg data. In *Proceedings of the International MultiConference
    of Engineers and Computer Scientists*, volume 1, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[289] Oh and Yun(2018)⟧oh2018residual Dong Yul Oh and Il Dong Yun. Residual
    error based anomaly detection using auto-encoder in smd machine sound. *Sensors
    (Basel, Switzerland)*, 18(5), 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[290] Ebrahimzadeh and Kleinberg()⟧ebrahimzadehmulti Zahra Ebrahimzadeh and
    Samantha Kleinberg. Multi-scale change point detection in multivariate time series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[291] Veeramachaneni et al.(2016)Veeramachaneni, Arnaldo, Korrapati, Bassias,
    and Li⟧veeramachaneni2016ai Kalyan Veeramachaneni, Ignacio Arnaldo, Vamsi Korrapati,
    Constantinos Bassias, and Ke Li. Ai^ 2: training a big data machine to defend.
    In *Big Data Security on Cloud (BigDataSecurity), IEEE International Conference
    on High Performance and Smart Computing (HPSC), and IEEE International Conference
    on Intelligent Data and Security (IDS), 2016 IEEE 2nd International Conference
    on*, pages 49–54\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[292] Dau et al.(2014)Dau, Ciesielski, and Song⟧dau2014anomaly Hoang Anh Dau,
    Vic Ciesielski, and Andy Song. Anomaly detection using replicator neural networks
    trained on examples of one class. In *Asia-Pacific Conference on Simulated Evolution
    and Learning*, pages 311–322\. Springer, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[293] Wielgosz et al.(2017)Wielgosz, Skoczeń, and Mertik⟧wielgosz2017recurrent
    Maciej Wielgosz, Andrzej Skoczeń, and Matej Mertik. Recurrent neural networks
    for anomaly detection in the post-mortem time series of lhc superconducting magnets.
    *arXiv preprint arXiv:1702.00833*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[294] Saurav et al.(2018)Saurav, Malhotra, TV, Gugulothu, Vig, Agarwal, and
    Shroff⟧saurav2018online Sakti Saurav, Pankaj Malhotra, Vishnu TV, Narendhar Gugulothu,
    Lovekesh Vig, Puneet Agarwal, and Gautam Shroff. Online anomaly detection with
    concept drift adaptation using recurrent neural networks. In *Proceedings of the
    ACM India Joint International Conference on Data Science and Management of Data*,
    pages 78–87\. ACM, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[295] Wielgosz et al.(2018)Wielgosz, Mertik, Skoczeń, and De Matteis⟧wielgosz2018model
    Maciej Wielgosz, Matej Mertik, Andrzej Skoczeń, and Ernesto De Matteis. The model
    of an anomaly detector for hilumi lhc magnets based on recurrent neural networks
    and adaptive quantization. *Engineering Applications of Artificial Intelligence*,
    74:166–185, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[296] Guo et al.(2016)Guo, Xu, Yao, Chen, Aberer, and Funaya⟧guo2016robust
    Tian Guo, Zhao Xu, Xin Yao, Haifeng Chen, Karl Aberer, and Koichi Funaya. Robust
    online time series prediction with recurrent neural networks. In *Data Science
    and Advanced Analytics (DSAA), 2016 IEEE International Conference on*, pages 816–825\.
    Ieee, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[297] Filonov et al.(2017)Filonov, Kitashov, and Lavrentyev⟧filonov2017rnn
    Pavel Filonov, Fedor Kitashov, and Andrey Lavrentyev. Rnn-based early cyber-attack
    detection for the tennessee eastman process. *arXiv preprint arXiv:1709.02232*,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[298] Kanarachos et al.(2017)Kanarachos, Christopoulos, Chroneos, and Fitzpatrick⟧kanarachos2017detecting
    Stratis Kanarachos, Stavros-Richard G Christopoulos, Alexander Chroneos, and Michael E
    Fitzpatrick. Detecting anomalies in time series data via a deep learning algorithm
    combining wavelets, neural networks and hilbert transform. *Expert Systems with
    Applications*, 85:292–304, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[299] Du et al.()Du, Pandey, and Xing⟧dumodeling Shuyang Du, Madhulima Pandey,
    and Cuiqun Xing. Modeling approaches for time series forecasting and anomaly detection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[300] Napoletano et al.(2018)Napoletano, Piccoli, and Schettini⟧napoletano2018anomaly
    Paolo Napoletano, Flavio Piccoli, and Raimondo Schettini. Anomaly detection in
    nanofibrous materials by cnn-based self-similarity. *Sensors*, 18(1):209, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[301] Shanmugam et al.(2018)Shanmugam, Blalock, and Guttag⟧shanmugam2018jiffy
    Divya Shanmugam, Davis Blalock, and John Guttag. Jiffy: A convolutional approach
    to learning time series similarity. 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[302] Medel and Savakis(2016)⟧medel2016anomaly Jefferson Ryan Medel and Andreas
    Savakis. Anomaly detection in video using predictive convolutional long short-term
    memory networks. *arXiv preprint arXiv:1612.00390*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[303] Park et al.(2018b)Park, Hoshi, and Kemp⟧park2018multimodal Daehyung Park,
    Yuuna Hoshi, and Charles C Kemp. A multimodal anomaly detector for robot-assisted
    feeding using an lstm-based variational autoencoder. *IEEE Robotics and Automation
    Letters*, 3(3):1544–1551, 2018b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[304] Sölch et al.(2016)Sölch, Bayer, Ludersdorfer, and van der Smagt⟧solch2016variational
    Maximilian Sölch, Justin Bayer, Marvin Ludersdorfer, and Patrick van der Smagt.
    Variational inference for on-line anomaly detection in high-dimensional time series.
    *arXiv preprint arXiv:1602.07109*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[305] Zenati et al.(2018)Zenati, Foo, Lecouat, Manek, and Chandrasekhar⟧zenati2018efficient
    Houssam Zenati, Chuan Sheng Foo, Bruno Lecouat, Gaurav Manek, and Vijay Ramaseshan
    Chandrasekhar. Efficient gan-based anomaly detection. *arXiv preprint arXiv:1802.06222*,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[306] Lim et al.(2018)Lim, Loo, Tran, Cheung, Roig, and Elovici⟧lim2018doping
    Swee Kiat Lim, Yi Loo, Ngoc-Trung Tran, Ngai-Man Cheung, Gemma Roig, and Yuval
    Elovici. Doping: Generative data augmentation for unsupervised anomaly detection
    with gan. *arXiv preprint arXiv:1808.07632*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[307] Laptev()⟧laptevanogen Nikolay Laptev. Anogen: Deep anomaly generator.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[308] Wei et al.(2018)Wei, Zhao, Zhao, and Zhao⟧wei2018unsupervised JiaYi Wei,
    JianFei Zhao, YanYun Zhao, and ZhiCheng Zhao. Unsupervised anomaly detection for
    traffic surveillance based on background modeling. In *Proceedings of the IEEE
    Conference on Computer Vision and Pattern Recognition Workshops*, pages 129–136,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[309] Buda et al.(2018)Buda, Caglayan, and Assem⟧buda2018deepad Teodora Sandra
    Buda, Bora Caglayan, and Haytham Assem. Deepad: A generic framework based on deep
    learning for time series anomaly detection. In *Pacific-Asia Conference on Knowledge
    Discovery and Data Mining*, pages 577–588\. Springer, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[310] Yuan et al.(2018b)Yuan, Xun, Ma, Wang, Du, Jia, Su, and Zhang⟧yuan2018muvan
    Ye Yuan, Guangxu Xun, Fenglong Ma, Yaqing Wang, Nan Du, Kebin Jia, Lu Su, and
    Aidong Zhang. Muvan: A multi-view attention network for multivariate temporal
    data. In *2018 IEEE International Conference on Data Mining (ICDM)*, pages 717–726\.
    IEEE, 2018b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[311] Guo and Lin(2018)⟧guo2018exploring Tian Guo and Tao Lin. Exploring the
    interpretability of lstm neural networks over multi-variable data. 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[312] Nucci et al.(2018)Nucci, Cui, Garrett, Singh, and Croley⟧nucci2018real
    Antonio Nucci, Song Cui, John Garrett, Gurvinder Singh, and Kenneth Croley. Real-time
    multi-variate multi-time-scale anomaly detection system for next generation networks.
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[313] Assendorp et al.(2017)Assendorp, Meisel, Bohlen, and Sommer⟧Assendorp2017DeepLF
    Jan Paul Assendorp, Andreas Meisel, H. Glenn Bohlen, and C Sommer. Deep learning
    for anomaly detectionin multivariate time series data. 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[314] Nolle et al.(2018b)Nolle, Seeliger, and Mühlhäuser⟧nolle2018binet Timo
    Nolle, Alexander Seeliger, and Max Mühlhäuser. Binet: Multivariate business process
    anomaly detection using deep learning. In *International Conference on Business
    Process Management*, pages 271–287\. Springer, 2018b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[315] Zhang et al.(2018e)Zhang, Song, Chen, Feng, Lumezanu, Cheng, Ni, Zong,
    Chen, and Chawla⟧zhang2018deep Chuxu Zhang, Dongjin Song, Yuncong Chen, Xinyang
    Feng, Cristian Lumezanu, Wei Cheng, Jingchao Ni, Bo Zong, Haifeng Chen, and Nitesh V
    Chawla. A deep neural network for unsupervised anomaly detection and diagnosis
    in multivariate time series data. *arXiv preprint arXiv:1811.08055*, 2018e.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[316] Guo et al.(2018)Guo, Liao, Wang, Yu, Ji, and Li⟧guo2018multidimensional
    Yifan Guo, Weixian Liao, Qianlong Wang, Lixing Yu, Tianxi Ji, and Pan Li. Multidimensional
    time series anomaly detection: A gru-based gaussian mixture variational autoencoder
    approach. In *Asian Conference on Machine Learning*, pages 97–112, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[317] Fu et al.(2019)Fu, Luo, Zhong, and Lin⟧fu2019aircraft Xuyun Fu, Hui Luo,
    Shisheng Zhong, and Lin Lin. Aircraft engine fault detection based on grouped
    convolutional denoising autoencoders. *Chinese Journal of Aeronautics*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[318] Kieu et al.(2018)Kieu, Yang, and Jensen⟧kieu2018outlier Tung Kieu, Bin
    Yang, and Christian S Jensen. Outlier detection for multidimensional time series
    using deep neural networks. In *2018 19th IEEE International Conference on Mobile
    Data Management (MDM)*, pages 125–134\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[319] Basumallik et al.(2019)Basumallik, Ma, and Eftekharnejad⟧basumallik2019packet
    Sagnik Basumallik, Rui Ma, and Sara Eftekharnejad. Packet-data anomaly detection
    in pmu-based state estimator using convolutional neural network. *International
    Journal of Electrical Power & Energy Systems*, 107:690–702, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[320] Ikeda et al.(2018)Ikeda, Tajiri, Nakano, Watanabe, and Ishibashi⟧ikeda2018estimation
    Yasuhiro Ikeda, Kengo Tajiri, Yuusuke Nakano, Keishiro Watanabe, and Keisuke Ishibashi.
    Estimation of dimensions contributing to detected anomalies with variational autoencoders.
    *arXiv preprint arXiv:1811.04576*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[321] Li et al.(2019)Li, Chen, Shi, Jin, Goh, and Ng⟧li2019mad Dan Li, Dacheng
    Chen, Lei Shi, Baihong Jin, Jonathan Goh, and See-Kiong Ng. Mad-gan: Multivariate
    anomaly detection for time series data with generative adversarial networks. *arXiv
    preprint arXiv:1901.04997*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[322] Tuor et al.(2018)Tuor, Baerwolf, Knowles, Hutchinson, Nichols, and Jasper⟧tuor2018recurrent
    Aaron Randall Tuor, Ryan Baerwolf, Nicolas Knowles, Brian Hutchinson, Nicole Nichols,
    and Robert Jasper. Recurrent neural network language models for open vocabulary
    event-level cyber anomaly detection. In *Workshops at the Thirty-Second AAAI Conference
    on Artificial Intelligence*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[323] Maia(2017)⟧multivariate17 Rui Maia. Multivariate temporal data analysis
    for vessels behavior anomaly detection. 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[324] Dal Pozzolo et al.(2015)Dal Pozzolo, Caelen, Johnson, and Bontempi⟧dal2015calibrating
    Andrea Dal Pozzolo, Olivier Caelen, Reid A Johnson, and Gianluca Bontempi. Calibrating
    probability with undersampling for unbalanced classification. In *Computational
    Intelligence, 2015 IEEE Symposium Series on*, pages 159–166\. IEEE, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[325] Cui et al.(2016)Cui, Surpur, Ahmad, and Hawkins⟧cui2016comparative Yuwei
    Cui, Chetan Surpur, Subutai Ahmad, and Jeff Hawkins. A comparative study of htm
    and other neural network models for online sequence learning with streaming data.
    In *Neural Networks (IJCNN), 2016 International Joint Conference on*, pages 1530–1538\.
    IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[326] Andrewsa et al.()Andrewsa, Jaccarda, Rogersa, Tanaya, and Griffina⟧andrewsaanomaly
    JTA Andrewsa, N Jaccarda, TW Rogersa, T Tanaya, and LD Griffina. Anomaly detection
    for security imaging.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[327] Sabokrou et al.(2016a)Sabokrou, Fayyaz, Fathy, et al.⟧sabokrou2016fully
    Mohammad Sabokrou, Mohsen Fayyaz, Mahmood Fathy, et al. Fully convolutional neural
    network for fast anomaly detection in crowded scenes. *arXiv preprint arXiv:1609.00866*,
    2016a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[328] Sabokrou et al.(2017)Sabokrou, Fayyaz, Fathy, and Klette⟧sabokrou2017deep
    Mohammad Sabokrou, Mohsen Fayyaz, Mahmood Fathy, and Reinhard Klette. Deep-cascade:
    cascading 3d deep neural networks for fast anomaly detection and localization
    in crowded scenes. *IEEE Transactions on Image Processing*, 26(4):1992–2004, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[329] Munawar et al.(2017)Munawar, Vinayavekhin, and De Magistris⟧munawar2017spatio
    Asim Munawar, Phongtharin Vinayavekhin, and Giovanni De Magistris. Spatio-temporal
    anomaly detection for industrial robots through prediction in unsupervised feature
    space. In *Applications of Computer Vision (WACV), 2017 IEEE Winter Conference
    on*, pages 1017–1025\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[330] Li et al.(2017b)Li, Wu, and Du⟧li2017transferred Wei Li, Guodong Wu,
    and Qian Du. Transferred deep learning for anomaly detection in hyperspectral
    imagery. *IEEE Geosci. Remote Sensing Lett.*, 14(5):597–601, 2017b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[331] Qiao et al.(2017)Qiao, Wang, Li, Li, Lin, and Snoussi⟧qiao2017abnormal
    Meina Qiao, Tian Wang, Jiakun Li, Ce Li, Zhiwei Lin, and Hichem Snoussi. Abnormal
    event detection based on deep autoencoder fusing optical flow. In *Control Conference
    (CCC), 2017 36th Chinese*, pages 11098–11103\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[332] Tripathi et al.(2018)Tripathi, Singh, and Vishwakarma⟧tripathi2018convolutional
    Gaurav Tripathi, Kuldeep Singh, and Dinesh Kumar Vishwakarma. Convolutional neural
    networks for crowd behaviour analysis: a survey. *The Visual Computer*, pages
    1–24, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[333] Nogas et al.(2018)Nogas, Khan, and Mihailidis⟧nogas2018deepfall Jacob
    Nogas, Shehroz S Khan, and Alex Mihailidis. Deepfall–non-invasive fall detection
    with deep spatio-temporal convolutional autoencoders. *arXiv preprint arXiv:1809.00977*,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[334] Chong and Tay(2017)⟧chong2017abnormal Yong Shean Chong and Yong Haur
    Tay. Abnormal event detection in videos using spatiotemporal autoencoder. In *International
    Symposium on Neural Networks*, pages 189–196. Springer, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[335] Khaleghi and Moin(2018)⟧khaleghi2018improved Ali Khaleghi and Mohammad Shahram
    Moin. Improved anomaly detection in surveillance videos based on a deep learning
    method. In *2018 8th Conference of AI & Robotics and 10th RoboCup Iranopen International
    Symposium (IRANOPEN)*, pages 73–81\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[336] Yang et al.(2015)Yang, Wang, Lin, Wipf, Guo, and Guo⟧yang2015unsupervised
    Huan Yang, Baoyuan Wang, Stephen Lin, David Wipf, Minyi Guo, and Baining Guo.
    Unsupervised extraction of video highlights via robust recurrent auto-encoders.
    In *Proceedings of the IEEE international conference on computer vision*, pages
    4633–4641, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[337] Chen et al.(2015)Chen, Tian, Zeng, and Huang⟧chen2015detecting Zhengying
    Chen, Yonghong Tian, Wei Zeng, and Tiejun Huang. Detecting abnormal behaviors
    in surveillance videos based on fuzzy clustering and multiple auto-encoders. In
    *Multimedia and Expo (ICME), 2015 IEEE International Conference on*, pages 1–6\.
    IEEE, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[338] Gutoski et al.()Gutoski, Aquino, Ribeiro, Lazzaretti, and Lopes⟧gutoskidetection
    Matheus Gutoski, Nelson Marcelo Romero Aquino, Manassés Ribeiro, André Engênio
    Lazzaretti, and Heitor Silvério Lopes. Detection of video anomalies using convolutional
    autoencoders and one-class support vector machines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[339] D’Avino et al.(2017)D’Avino, Cozzolino, Poggi, and Verdoliva⟧d2017autoencoder
    Dario D’Avino, Davide Cozzolino, Giovanni Poggi, and Luisa Verdoliva. Autoencoder
    with recurrent neural networks for video forgery detection. *Electronic Imaging*,
    2017(7):92–99, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[340] Dotti et al.(2017)Dotti, Popa, and Asteriadis⟧dotti2017unsupervised Dario
    Dotti, Mirela Popa, and Stylianos Asteriadis. Unsupervised discovery of normal
    and abnormal activity patterns in indoor and outdoor environments. In *VISIGRAPP
    (5: VISAPP)*, pages 210–217, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[341] Sabokrou et al.(2016b)Sabokrou, Fathy, and Hoseini⟧sabokrou2016video
    M Sabokrou, M Fathy, and M Hoseini. Video anomaly detection and localisation based
    on the sparsity and reconstruction error of auto-encoder. *Electronics Letters*,
    52(13):1122–1124, 2016b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[342] Tran and Hogg(2017)⟧tran2017anomaly Hanh TM Tran and DC Hogg. Anomaly
    detection using a convolutional winner-take-all autoencoder. In *Proceedings of
    the British Machine Vision Conference 2017*. Leeds, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[343] Hasan et al.(2016)Hasan, Choi, Neumann, Roy-Chowdhury, and Davis⟧hasan2016learning
    Mahmudul Hasan, Jonghyun Choi, Jan Neumann, Amit K Roy-Chowdhury, and Larry S
    Davis. Learning temporal regularity in video sequences. In *Proceedings of the
    IEEE Conference on Computer Vision and Pattern Recognition*, pages 733–742, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[344] Cinelli(2017)⟧cinelli2017anomaly Lucas Pinheiro Cinelli. *ANOMALY DETECTION
    IN SURVEILLANCE VIDEOS USING DEEP RESIDUAL NETWORKS*. PhD thesis, Universidade
    Federal do Rio de Janeiro, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[345] Sultani et al.(2018)Sultani, Chen, and Shah⟧sultani2018real Waqas Sultani,
    Chen Chen, and Mubarak Shah. Real-world anomaly detection in surveillance videos.
    *Center for Research in Computer Vision (CRCV), University of Central Florida
    (UCF)*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[346] Chianucci and Savakis(2016)⟧chianucci2016unsupervised Dan Chianucci and
    Andreas Savakis. Unsupervised change detection using spatial transformer networks.
    In *Signal Processing Workshop (WNYISPW), 2016 IEEE Western New York Image and*,
    pages 1–5\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[347] Luo et al.(2017a)Luo, Liu, and Gao⟧luo2017remembering Weixin Luo, Wen
    Liu, and Shenghua Gao. Remembering history with convolutional lstm for anomaly
    detection. In *Multimedia and Expo (ICME), 2017 IEEE International Conference
    on*, pages 439–444\. IEEE, 2017a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[348] Ben-Ari and Shwartz-Ziv(2018)⟧ben2018attentioned Itamar Ben-Ari and Ravid
    Shwartz-Ziv. Attentioned convolutional lstm inpaintingnetwork for anomaly detection
    in videos. *arXiv preprint arXiv:1811.10228*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[349] Singh(2017)⟧singh2017anomaly Akash Singh. Anomaly detection for temporal
    data using long short-term memory (lstm), 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[350] Luo et al.(2017b)Luo, Liu, and Gao⟧luo2017revisit Weixin Luo, Wen Liu,
    and Shenghua Gao. A revisit of sparse coding based anomaly detection in stacked
    rnn framework. *ICCV, Oct*, 1(2):3, 2017b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[351] Zhou and Zhang(2015)⟧zhou2015abnormal Xu-Gang Zhou and Li-Qing Zhang.
    Abnormal event detection using recurrent neural network. In *Computer Science
    and Applications (CSA), 2015 International Conference on*, pages 222–226\. IEEE,
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[352] Hu et al.(2016)Hu, Hu, Huang, Zhang, and Wu⟧hu2016video Xing Hu, Shiqiang
    Hu, Yingping Huang, Huanlong Zhang, and Hanbing Wu. Video anomaly detection using
    deep incremental slow feature analysis network. *IET Computer Vision*, 10(4):258–265,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[353] Chong and Tay(2015)⟧chong2015modeling Yong Shean Chong and Yong Haur
    Tay. Modeling representation of videos for anomaly detection using deep learning:
    A review. *arXiv preprint arXiv:1505.00523*, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[354] Ravanbakhsh et al.(2017a)Ravanbakhsh, Sangineto, Nabi, and Sebe⟧ravanbakhsh2017training
    Mahdyar Ravanbakhsh, Enver Sangineto, Moin Nabi, and Nicu Sebe. Training adversarial
    discriminators for cross-channel abnormal event detection in crowds. *arXiv preprint
    arXiv:1706.07680*, 2017a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[355] Boghossian and Black(2005)⟧boghossian2005challenges B Boghossian and
    J Black. The challenges of robust 24/7 video surveillance systems. 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[356] Görnitz et al.(2013)Görnitz, Kloft, Rieck, and Brefeld⟧gornitz2013toward
    Nico Görnitz, Marius Kloft, Konrad Rieck, and Ulf Brefeld. Toward supervised anomaly
    detection. *Journal of Artificial Intelligence Research*, 46:235–262, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[357] Shilton et al.(2013)Shilton, Rajasegarar, and Palaniswami⟧shilton2013combined
    Alistair Shilton, Sutharshan Rajasegarar, and Marimuthu Palaniswami. Combined
    multiclass classification and anomaly detection for large-scale wireless sensor
    networks. In *Intelligent Sensors, Sensor Networks and Information Processing,
    2013 IEEE Eighth International Conference on*, pages 491–496. IEEE, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[358] Jumutc and Suykens(2014)⟧jumutc2014multi Vilen Jumutc and Johan AK Suykens.
    Multi-class supervised novelty detection. *IEEE transactions on pattern analysis
    and machine intelligence*, 36(12):2510–2523, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[359] Kim et al.(2015)Kim, Choi, and Lee⟧kim2015deep Sangwook Kim, Yonghwa
    Choi, and Minho Lee. Deep learning with support vector data description. *Neurocomputing*,
    165:111–117, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[360] Erfani et al.(2017)Erfani, Baktashmotlagh, Moshtaghi, Nguyen, Leckie,
    Bailey, and Ramamohanarao⟧erfani2017shared Sarah M Erfani, Mahsa Baktashmotlagh,
    Masud Moshtaghi, Vinh Nguyen, Christopher Leckie, James Bailey, and Kotagiri Ramamohanarao.
    From shared subspaces to shared landmarks: A robust multi-source classification
    approach. In *AAAI*, pages 1854–1860, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[361] Min et al.(2018)Min, Long, Liu, Cui, Cai, and Ma⟧min2018ids Erxue Min,
    Jun Long, Qiang Liu, Jianjing Cui, Zhiping Cai, and Junbo Ma. Su-ids: A semi-supervised
    and unsupervised framework for network intrusion detection. In *International
    Conference on Cloud Computing and Security*, pages 322–334\. Springer, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[362] Perera and Patel(2018)⟧perera2018learning Pramuditha Perera and Vishal M
    Patel. Learning deep features for one-class classification. *arXiv preprint arXiv:1801.05365*,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[363] Blanchard et al.(2010)Blanchard, Lee, and Scott⟧blanchard2010semi Gilles
    Blanchard, Gyemin Lee, and Clayton Scott. Semi-supervised novelty detection. *Journal
    of Machine Learning Research*, 11(Nov):2973–3009, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[364] Edmunds and Feinstein(2017)⟧edmunds2017deep Riley Edmunds and Efraim
    Feinstein. Deep semi-supervised embeddings for dynamic targeted anomaly detection.
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[365] Estiri and Murphy(2018)⟧estiri2018semi Hossein Estiri and Shawn Murphy.
    Semi-supervised encoding for outlier detection in clinical observation data. *bioRxiv*,
    page 334771, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[366] Jia et al.(2014)Jia, Li, Li, and Zhang⟧jia2014novel Xiaowei Jia, Kang
    Li, Xiaoyi Li, and Aidong Zhang. A novel semi-supervised deep learning framework
    for affective state recognition on eeg signals. In *Bioinformatics and Bioengineering
    (BIBE), 2014 IEEE International Conference on*, pages 30–37\. IEEE, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[367] Gu et al.(2018)Gu, Schubert, and Tresp⟧gu2018semi Jindong Gu, Matthias
    Schubert, and Volker Tresp. Semi-supervised outlier detection using generative
    and adversary framework. 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[368] Akcay et al.(2018)Akcay, Atapour-Abarghouei, and Breckon⟧akcay2018ganomaly
    Samet Akcay, Amir Atapour-Abarghouei, and Toby P Breckon. Ganomaly: Semi-supervised
    anomaly detection via adversarial training. *arXiv preprint arXiv:1805.06725*,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[369] Sabokrou et al.(2018)Sabokrou, Khalooei, Fathy, and Adeli⟧sabokrou2018adversarially
    Mohammad Sabokrou, Mohammad Khalooei, Mahmood Fathy, and Ehsan Adeli. Adversarially
    learned one-class classifier for novelty detection. In *Proceedings of the IEEE
    Conference on Computer Vision and Pattern Recognition*, pages 3379–3388, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[370] Dimokranitou(2017)⟧dimokranitou2017adversarial Asimenia Dimokranitou.
    *Adversarial autoencoders for anomalous event detection in images*. PhD thesis,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[371] Altman(1992)⟧altman1992introduction Naomi S Altman. An introduction to
    kernel and nearest-neighbor nonparametric regression. *The American Statistician*,
    46(3):175–185, 1992.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[372] Ho(1995)⟧ho1995random Tin Kam Ho. Random decision forests. In *Document
    analysis and recognition, 1995., proceedings of the third international conference
    on*, volume 1, pages 278–282\. IEEE, 1995.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[373] Kira and Rendell(1992)⟧kira1992feature Kenji Kira and Larry A Rendell.
    The feature selection problem: Traditional methods and a new algorithm. In *Aaai*,
    volume 2, pages 129–134, 1992.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[374] Shi et al.(2017)Shi, Yuan, and Nick⟧shi2017semi Ningxin Shi, Xiaohong
    Yuan, and William Nick. Semi-supervised random forest for intrusion detection
    network, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[375] Zhu et al.(2018)Zhu, Yang, Wang, and Yuan⟧zhu2018hybrid Bing Zhu, Wenchuan
    Yang, Huaxuan Wang, and Yuan Yuan. A hybrid deep learning model for consumer credit
    scoring. In *2018 International Conference on Artificial Intelligence and Big
    Data (ICAIBD)*, pages 205–208\. IEEE, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[376] Racah et al.(2017)Racah, Beckham, Maharaj, Kahou, Prabhat, and Pal⟧racah2017extremeweather
    Evan Racah, Christopher Beckham, Tegan Maharaj, Samira Ebrahimi Kahou, Mr Prabhat,
    and Chris Pal. Extremeweather: A large-scale climate dataset for semi-supervised
    detection, localization, and understanding of extreme weather events. In *Advances
    in Neural Information Processing Systems*, pages 3402–3413, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[377] Wu and Prasad(2018)⟧wu2018semi Hao Wu and Saurabh Prasad. Semi-supervised
    deep learning using pseudo labels for hyperspectral image classification. *IEEE
    Transactions on Image Processing*, 27(3):1259–1270, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[378] Kliger and Fleishman(2018)⟧kliger2018novelty Mark Kliger and Shachar
    Fleishman. Novelty detection with gan. *arXiv preprint arXiv:1802.10560*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[379] Lu(2009)⟧lu2009fundamental Tyler Tian Lu. Fundamental limitations of
    semi-supervised learning. Master’s thesis, University of Waterloo, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[380] Ruchansky et al.(2017)Ruchansky, Seo, and Liu⟧ruchansky2017csi Natali
    Ruchansky, Sungyong Seo, and Yan Liu. Csi: A hybrid deep model for fake news detection.
    In *Proceedings of the 2017 ACM on Conference on Information and Knowledge Management*,
    pages 797–806\. ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[381] Urbanowicz et al.(2018)Urbanowicz, Meeker, La Cava, Olson, and Moore⟧urbanowicz2018relief
    Ryan J Urbanowicz, Melissa Meeker, William La Cava, Randal S Olson, and Jason H
    Moore. Relief-based feature selection: introduction and review. *Journal of biomedical
    informatics*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[382] Erfani et al.(2016b)Erfani, Baktashmotlagh, Moshtaghi, Nguyen, Leckie,
    Bailey, and Kotagiri⟧erfani2016robust Sarah Erfani, Mahsa Baktashmotlagh, Masoud
    Moshtaghi, Vinh Nguyen, Christopher Leckie, James Bailey, and Ramamohanarao Kotagiri.
    Robust domain generalisation by enforcing distribution invariance. In *Proceedings
    of the Twenty-Fifth International Joint Conference on Artificial Intelligence*,
    pages 1455–1461\. AAAI Press/International Joint Conferences on Artificial Intelligence,
    2016b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[383] Wu et al.(2015b)Wu, Wang, Wang, and Yu⟧wu2015harvesting Ruobing Wu, Baoyuan
    Wang, Wenping Wang, and Yizhou Yu. Harvesting discriminative meta objects with
    deep cnn features for scene classification. In *Proceedings of the IEEE International
    Conference on Computer Vision*, pages 1287–1295, 2015b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[384] Saxe et al.(2011)Saxe, Koh, Chen, Bhand, Suresh, and Ng⟧saxe2011random
    Andrew M Saxe, Pang Wei Koh, Zhenghao Chen, Maneesh Bhand, Bipin Suresh, and Andrew Y
    Ng. On random weights and unsupervised feature learning. In *ICML*, pages 1089–1096,
    2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[385] Baldi(2012)⟧baldi2012autoencoders Pierre Baldi. Autoencoders, unsupervised
    learning, and deep architectures. In *Proceedings of ICML workshop on unsupervised
    and transfer learning*, pages 37–49, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[386] Chandola et al.(2008)Chandola, Mithal, and Kumar⟧chandola2008comparative
    Varun Chandola, Varun Mithal, and Vipin Kumar. Comparative evaluation of anomaly
    detection techniques for sequence data. In *Data Mining, 2008\. ICDM’08\. Eighth
    IEEE International Conference on*, pages 743–748\. IEEE, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[387] Dasigi and Hovy(2014)⟧dasigi2014modeling Pradeep Dasigi and Eduard Hovy.
    Modeling newswire events using neural networks for anomaly detection. In *Proceedings
    of COLING 2014, the 25th International Conference on Computational Linguistics:
    Technical Papers*, pages 1414–1422, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[388] Abati et al.(2018)Abati, Porrello, Calderara, and Cucchiara⟧abati2018and
    Davide Abati, Angelo Porrello, Simone Calderara, and Rita Cucchiara. And: Autoregressive
    novelty detectors. *arXiv preprint arXiv:1807.01653*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[389] Zong et al.(2018)Zong, Song, Min, Cheng, Lumezanu, Cho, and Chen⟧zong2018deep
    Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho,
    and Haifeng Chen. Deep autoencoding gaussian mixture model for unsupervised anomaly
    detection. 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[390] Tagawa et al.(2015)Tagawa, Tadokoro, and Yairi⟧tagawa2015structured Takaaki
    Tagawa, Yukihiro Tadokoro, and Takehisa Yairi. Structured denoising autoencoder
    for fault detection and analysis. In *Asian Conference on Machine Learning*, pages
    96–111, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[391] Xu et al.(2015)Xu, Ricci, Yan, Song, and Sebe⟧xu2015learning Dan Xu,
    Elisa Ricci, Yan Yan, Jingkuan Song, and Nicu Sebe. Learning deep representations
    of appearance and motion for anomalous event detection. *arXiv preprint arXiv:1510.01553*,
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[392] Hawkins et al.(2002)Hawkins, He, Williams, and Baxter⟧hawkins2002outlier
    Simon Hawkins, Hongxing He, Graham Williams, and Rohan Baxter. Outlier detection
    using replicator neural networks. In *International Conference on Data Warehousing
    and Knowledge Discovery*, pages 170–180\. Springer, 2002.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[393] Zhao et al.(2015)Zhao, Guo, Wu, Ning, and Yan⟧zhao2015robust Dan Zhao,
    Baolong Guo, Jinfu Wu, Weikang Ning, and Yunyi Yan. Robust feature learning by
    improved auto-encoder from non-gaussian noised images. In *Imaging Systems and
    Techniques (IST), 2015 IEEE International Conference on*, pages 1–5\. IEEE, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[394] Qi et al.(2014)Qi, Wang, Zheng, and Wu⟧qi2014robust Yu Qi, Yueming Wang,
    Xiaoxiang Zheng, and Zhaohui Wu. Robust feature learning by stacked autoencoder
    with maximum correntropy criterion. In *Acoustics, Speech and Signal Processing
    (ICASSP), 2014 IEEE International Conference on*, pages 6716–6720\. IEEE, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[395] Chalapathy et al.(2017)Chalapathy, Menon, and Chawla⟧chalapathy2017robust
    Raghavendra Chalapathy, Aditya Krishna Menon, and Sanjay Chawla. Robust, deep
    and inductive anomaly detection. In *Joint European Conference on Machine Learning
    and Knowledge Discovery in Databases*, pages 36–51\. Springer, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[396] Zhai et al.(2016)Zhai, Cheng, Lu, and Zhang⟧zhai2016deep Shuangfei Zhai,
    Yu Cheng, Weining Lu, and Zhongfei Zhang. Deep structured energy based models
    for anomaly detection. *arXiv preprint arXiv:1605.07717*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[397] Lyudchik(2016)⟧lyudchik2016outlier Olga Lyudchik. Outlier detection using
    autoencoders. Technical report, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[398] Lu et al.(2017)Lu, Cheng, Xiao, Chang, Huang, Liang, and Huang⟧lu2017unsupervised
    Weining Lu, Yu Cheng, Cao Xiao, Shiyu Chang, Shuai Huang, Bin Liang, and Thomas
    Huang. Unsupervised sequential outlier detection with deep architectures. *IEEE
    Transactions on Image Processing*, 26(9):4321–4330, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[399] Mehrotra et al.(2017)Mehrotra, Awadallah, Shokouhi, Yilmaz, Zitouni,
    El Kholy, and Khabsa⟧mehrotra2017deep Rishabh Mehrotra, Ahmed Hassan Awadallah,
    Milad Shokouhi, Emine Yilmaz, Imed Zitouni, Ahmed El Kholy, and Madian Khabsa.
    Deep sequential models for task satisfaction prediction. In *Proceedings of the
    2017 ACM on Conference on Information and Knowledge Management*, pages 737–746\.
    ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[400] Meng et al.(2018)Meng, Catchpoole, Skillicorn, and Kennedy⟧meng2018relational
    Qinxue Meng, Daniel Catchpoole, David Skillicorn, and Paul J Kennedy. Relational
    autoencoder for feature extraction. *arXiv preprint arXiv:1802.03145*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[401] Parchami et al.(2017)Parchami, Bashbaghi, Granger, and Sayed⟧parchami2017using
    Mostafa Parchami, Saman Bashbaghi, Eric Granger, and Saif Sayed. Using deep autoencoders
    to learn robust domain-invariant representations for still-to-video face recognition.
    In *Advanced Video and Signal Based Surveillance (AVSS), 2017 14th IEEE International
    Conference on*, pages 1–6\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[402] Lawson et al.(2017)Lawson, Bekele, and Sullivan⟧lawson2017finding Wallace E
    Lawson, Esube Bekele, and Keith Sullivan. Finding anomalies with generative adversarial
    networks for a patrolbot. In *CVPR Workshops*, pages 484–485, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[403] Leveau and Joly(2017)⟧leveau2017adversarial Valentin Leveau and Alexis
    Joly. Adversarial autoencoders for novelty detection. 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[404] An and Cho(2015)⟧an2015variational Jinwon An and Sungzoon Cho. Variational
    autoencoder based anomaly detection using reconstruction probability. *Special
    Lecture on IE*, 2:1–18, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[405] Suh et al.(2016)Suh, Chae, Kang, and Choi⟧suh2016echo Suwon Suh, Daniel H
    Chae, Hyon-Goo Kang, and Seungjin Choi. Echo-state conditional variational autoencoder
    for anomaly detection. In *Neural Networks (IJCNN), 2016 International Joint Conference
    on*, pages 1015–1022\. IEEE, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[406] Mishra et al.(2017)Mishra, Reddy, Mittal, and Murthy⟧mishra2017generative
    Ashish Mishra, M Reddy, Anurag Mittal, and Hema A Murthy. A generative model for
    zero shot learning using conditional variational autoencoders. *arXiv preprint
    arXiv:1709.00663*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[407] Goldstein and Uchida(2016)⟧goldstein2016comparative Markus Goldstein
    and Seiichi Uchida. A comparative evaluation of unsupervised anomaly detection
    algorithms for multivariate data. *PloS one*, 11(4):e0152173, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[408] Andrews et al.(2016b)Andrews, Tanay, Morton, and Griffin⟧andrews2016transfer
    Jerone TA Andrews, Thomas Tanay, Edward J Morton, and Lewis D Griffin. Transfer
    representation-learning for anomaly detection. ICML, 2016b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[409] Vercruyssen et al.(2017)Vercruyssen, Meert, and Davis⟧vercruyssen2017transfer
    Vincent Vercruyssen, Wannes Meert, and Jesse Davis. Transfer learning for time
    series anomaly detection. *IAL ECML PKDD 2017*, page 27, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[410] Li et al.(2012)Li, Du, and Zhang⟧li2012detecting Kang Li, Nan Du, and
    Aidong Zhang. Detecting ecg abnormalities via transductive transfer learning.
    In *Proceedings of the ACM Conference on Bioinformatics, Computational Biology
    and Biomedicine*, pages 210–217\. ACM, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[411] Almajai et al.(2012)Almajai, Yan, de Campos, Khan, Christmas, Windridge,
    and Kittler⟧almajai2012anomaly Ibrahim Almajai, Fei Yan, Teofilo de Campos, Aftab
    Khan, William Christmas, David Windridge, and Josef Kittler. Anomaly detection
    and knowledge transfer in automatic sports video annotation. In *Detection and
    identification of rare audiovisual cues*, pages 109–117\. Springer, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[412] Kumar and Vaidehi(2017)⟧kumar2017transfer PM Ashok Kumar and V Vaidehi.
    A transfer learning framework for traffic video using neuro-fuzzy approach. *Sādhanā*,
    42(9):1431–1442, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[413] Liang et al.(2018)Liang, Yang, Chen, Xiao, and Lan⟧liang2018transfer
    Peng Liang, Hai-Dong Yang, Wen-Si Chen, Si-Yuan Xiao, and Zhao-Ze Lan. Transfer
    learning for aluminium extrusion electricity consumption anomaly detection via
    deep neural networks. *International Journal of Computer Integrated Manufacturing*,
    31(4-5):396–405, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[414] Romera-Paredes and Torr(2015)⟧romera2015embarrassingly Bernardino Romera-Paredes
    and Philip Torr. An embarrassingly simple approach to zero-shot learning. In *International
    Conference on Machine Learning*, pages 2152–2161, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[415] Socher et al.(2013)Socher, Ganjoo, Manning, and Ng⟧socher2013zero Richard
    Socher, Milind Ganjoo, Christopher D Manning, and Andrew Ng. Zero-shot learning
    through cross-modal transfer. In *Advances in neural information processing systems*,
    pages 935–943, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[416] Xian et al.(2017)Xian, Schiele, and Akata⟧xian2017zero Yongqin Xian,
    Bernt Schiele, and Zeynep Akata. Zero-shot learning-the good, the bad and the
    ugly. *arXiv preprint arXiv:1703.04394*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[417] Liu et al.(2017)Liu, Liu, Ma, Huang, and Dong⟧liu2017generalized Kun
    Liu, Wu Liu, Huadong Ma, Wenbing Huang, and Xiongxiong Dong. Generalized zero-shot
    learning for action recognition with web-scale video data. *arXiv preprint arXiv:1710.07455*,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[418] Rivero et al.(2017)Rivero, Ribeiro, Chen, and Leite⟧rivero2017grassmannian
    Jorge Rivero, Bernardete Ribeiro, Ning Chen, and Fátima Silva Leite. A grassmannian
    approach to zero-shot learning for network intrusion detection. In *International
    Conference on Neural Information Processing*, pages 565–575\. Springer, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[419] Chen et al.(2017)Chen, Sathe, Aggarwal, and Turaga⟧chen2017outlier Jinghui
    Chen, Saket Sathe, Charu Aggarwal, and Deepak Turaga. Outlier detection with autoencoder
    ensembles. In *Proceedings of the 2017 SIAM International Conference on Data Mining*,
    pages 90–98\. SIAM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[420] Ester et al.(1996)Ester, Kriegel, Sander, Xu, et al.⟧ester1996density
    Martin Ester, Hans-Peter Kriegel, Jörg Sander, Xiaowei Xu, et al. A density-based
    algorithm for discovering clusters in large spatial databases with noise. In *Kdd*,
    volume 96, pages 226–231, 1996.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[421] Sreekanth et al.(2010)Sreekanth, Vedaldi, Zisserman, and Jawahar⟧sreekanth2010generalized
    V Sreekanth, Andrea Vedaldi, Andrew Zisserman, and C Jawahar. Generalized rbf
    feature maps for efficient detection. 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[422] Mikolov et al.(2013)Mikolov, Chen, Corrado, and Dean⟧mikolov2013efficient
    Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation
    of word representations in vector space. *arXiv preprint arXiv:1301.3781*, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[423] Yuan et al.(2017)Yuan, Li, Yao, and Zhang⟧yuan2017deep Guiqin Yuan, Bo Li,
    Yiyang Yao, and Simin Zhang. A deep learning enabled subspace spectral ensemble
    clustering approach for web anomaly detection. In *Neural Networks (IJCNN), 2017
    International Joint Conference on*, pages 3896–3903\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[424] de La Bourdonnaye et al.(2017)de La Bourdonnaye, Teulière, Chateau, and
    Triesch⟧de2017learning François de La Bourdonnaye, Céline Teulière, Thierry Chateau,
    and Jochen Triesch. Learning of binocular fixations using anomaly detection with
    deep reinforcement learning. In *Neural Networks (IJCNN), 2017 International Joint
    Conference on*, pages 760–767\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[425] Chengqiang Huang(2016)⟧rlanomaly Yuan Zuo Ke Pei Geyong Min Chengqiang Huang,
    Yulei Wu. Towards experienced anomaly detector through reinforcement learning.
    *The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18)*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[426] Kanarachos et al.(2015)Kanarachos, Mathew, Chroneos, and Fitzpatrick⟧kanarachos2015anomaly
    S Kanarachos, J Mathew, A Chroneos, and M Fitzpatrick. Anomaly detection in time
    series data using a combination of wavelets, neural networks and hilbert transform.
    In *IISA*, pages 1–6, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[427] Schmidhuber(2015)⟧schmidhuber2015deep Jürgen Schmidhuber. Deep learning
    in neural networks: An overview. *Neural networks*, 61:85–117, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[428] Bengio et al.(2009)⟧bengio2009learning Yoshua Bengio et al. Learning
    deep architectures for ai. *Foundations and trends® in Machine Learning*, 2(1):1–127,
    2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[429] Werbos(1990)⟧werbos1990backpropagation Paul J Werbos. Backpropagation
    through time: what it does and how to do it. *Proceedings of the IEEE*, 78(10):1550–1560,
    1990.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[430] Zhang et al.(2018f)Zhang, Zheng, and Yu⟧zhang2018detecting Huichu Zhang,
    Yu Zheng, and Yong Yu. Detecting urban anomalies using multiple spatio-temporal
    data sources. *Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous
    Technologies*, 2(1):54, 2018f.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[431] Lee et al.(2018)Lee, Kim, and Ro⟧lee2018stan Sangmin Lee, Hak Gu Kim,
    and Yong Man Ro. Stan: Spatio-temporal adversarial networks for abnormal event
    detection. *arXiv preprint arXiv:1804.08381*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[432] SZEKÉR(2014)⟧szeker2014spatio MÁTÉ SZEKÉR. Spatio-temporal outlier detection
    in streaming trajectory data, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[433] Nie et al.(2018)Nie, Li, and Kong⟧nie2018spatio Laisen Nie, Yongkang
    Li, and Xiangjie Kong. Spatio-temporal network traffic estimation and anomaly
    detection based on convolutional neural network in vehicular ad-hoc networks.
    *IEEE Access*, 6:40168–40176, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[434] Dereszynski and Dietterich(2011)⟧dereszynski2011spatiotemporal Ethan W
    Dereszynski and Thomas G Dietterich. Spatiotemporal models for data-anomaly detection
    in dynamic environmental monitoring campaigns. *ACM Transactions on Sensor Networks
    (TOSN)*, 8(1):3, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[435] Poon and Domingos(2011)⟧poon2011sum Hoifung Poon and Pedro Domingos.
    Sum-product networks: A new deep architecture. In *Computer Vision Workshops (ICCV
    Workshops), 2011 IEEE International Conference on*, pages 689–690\. IEEE, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[436] Rezaeinia et al.(2017)Rezaeinia, Ghodsi, and Rahmani⟧rezaeinia2017improving
    Seyed Mahdi Rezaeinia, Ali Ghodsi, and Rouhollah Rahmani. Improving the accuracy
    of pre-trained word embeddings for sentiment analysis. *arXiv preprint arXiv:1711.08609*,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[437] Naili et al.(2017)Naili, Chaibi, and Ghezala⟧naili2017comparative Marwa
    Naili, Anja Habacha Chaibi, and Henda Hajjami Ben Ghezala. Comparative study of
    word embedding methods in topic segmentation. *Procedia Computer Science*, 112:340–349,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[438] Altszyler et al.(2016)Altszyler, Sigman, Ribeiro, and Slezak⟧altszyler2016comparative
    Edgar Altszyler, Mariano Sigman, Sidarta Ribeiro, and Diego Fernández Slezak.
    Comparative study of lsa vs word2vec embeddings in small corpora: a case study
    in dreams database. *arXiv preprint arXiv:1610.01520*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[439] Schnabel et al.(2015)Schnabel, Labutov, Mimno, and Joachims⟧schnabel2015evaluation
    Tobias Schnabel, Igor Labutov, David Mimno, and Thorsten Joachims. Evaluation
    methods for unsupervised word embeddings. In *Proceedings of the 2015 Conference
    on Empirical Methods in Natural Language Processing*, pages 298–307, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[440] Bertero et al.(2017)Bertero, Roy, Sauvanaud, and Trédan⟧bertero2017experience
    Christophe Bertero, Matthieu Roy, Carla Sauvanaud, and Gilles Trédan. Experience
    report: Log mining using natural language processing and application to anomaly
    detection. In *Software Reliability Engineering (ISSRE), 2017 IEEE 28th International
    Symposium on*, pages 351–360\. IEEE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[441] Bakarov et al.(2018)Bakarov, Yadrintsev, and Sochenkov⟧bakarov2018anomaly
    Amir Bakarov, Vasiliy Yadrintsev, and Ilya Sochenkov. Anomaly detection for short
    texts: Identifying whether your chatbot should switch from goal-oriented conversation
    to chit-chatting. In *International Conference on Digital Transformation and Global
    Society*, pages 289–298\. Springer, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[442] Bamler and Mandt(2017)⟧bamler2017dynamic Robert Bamler and Stephan Mandt.
    Dynamic word embeddings. *arXiv preprint arXiv:1702.08359*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[443] Kingma and Welling(2013)⟧kingma2013auto Diederik P Kingma and Max Welling.
    Auto-encoding variational bayes. *arXiv preprint arXiv:1312.6114*, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[444] Goodfellow et al.(2014a)Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley,
    Ozair, Courville, and Bengio⟧NIPS2014_5423 Ian Goodfellow, Jean Pouget-Abadie,
    Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and
    Yoshua Bengio. Generative adversarial nets. In Z. Ghahramani, M. Welling, C. Cortes,
    N. D. Lawrence, and K. Q. Weinberger, editors, *Advances in Neural Information
    Processing Systems 27*, pages 2672–2680\. Curran Associates, Inc., 2014a. URL
    [http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[445] Goodfellow et al.(2014b)Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley,
    Ozair, Courville, and Bengio⟧goodfellow2014generative Ian Goodfellow, Jean Pouget-Abadie,
    Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and
    Yoshua Bengio. Generative adversarial nets. In *Advances in neural information
    processing systems*, pages 2672–2680, 2014b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[446] Makhzani et al.(2015)Makhzani, Shlens, Jaitly, Goodfellow, and Frey⟧makhzani2015adversarial
    Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan
    Frey. Adversarial autoencoders. *arXiv preprint arXiv:1511.05644*, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[447] Deecke et al.(2018)Deecke, Vandermeulen, Ruff, Mandt, and Kloft⟧deecke2018anomaly
    Lucas Deecke, Robert Vandermeulen, Lukas Ruff, Stephan Mandt, and Marius Kloft.
    Anomaly detection with generative adversarial networks. 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[448] Ravanbakhsh et al.(2017b)Ravanbakhsh, Nabi, Sangineto, Marcenaro, Regazzoni,
    and Sebe⟧ravanbakhsh2017abnormal Mahdyar Ravanbakhsh, Moin Nabi, Enver Sangineto,
    Lucio Marcenaro, Carlo Regazzoni, and Nicu Sebe. Abnormal event detection in videos
    using generative adversarial nets. In *Image Processing (ICIP), 2017 IEEE International
    Conference on*, pages 1577–1581\. IEEE, 2017b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[449] Eide(2018)⟧eide2018applying Aksel Wilhelm Wold Eide. Applying generative
    adversarial networks for anomaly detection in hyperspectral remote sensing imagery.
    Master’s thesis, NTNU, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[450] Škvára et al.(2018)Škvára, Pevnỳ, and Šmídl⟧vskvara2018generative Vít
    Škvára, Tomáš Pevnỳ, and Václav Šmídl. Are generative deep models for novelty
    detection truly better? *arXiv preprint arXiv:1807.05027*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[451] Krizhevsky et al.(2012)Krizhevsky, Sutskever, and Hinton⟧krizhevsky2012imagenet
    Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification
    with deep convolutional neural networks. In *Advances in neural information processing
    systems*, pages 1097–1105, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[452] Kim(2014)⟧kim2014convolutional Yoon Kim. Convolutional neural networks
    for sentence classification. *arXiv preprint arXiv:1408.5882*, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[453] Williams(1989)⟧williams1989complexity Ronald J Williams. Complexity of
    exact gradient computation algorithms for recurrent neural networks. Technical
    report, Technical Report Technical Report NU-CCS-89-27, Boston: Northeastern …,
    1989.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[454] Cho et al.(2014)Cho, Van Merriënboer, Gulcehre, Bahdanau, Bougares, Schwenk,
    and Bengio⟧cho2014learning Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre,
    Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning
    phrase representations using rnn encoder-decoder for statistical machine translation.
    *arXiv preprint arXiv:1406.1078*, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[455] Pearson(1901)⟧pearson1901liii Karl Pearson. Liii. on lines and planes
    of closest fit to systems of points in space. *The London, Edinburgh, and Dublin
    Philosophical Magazine and Journal of Science*, 2(11):559–572, 1901.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[456] Liou et al.(2008)Liou, Huang, and Yang⟧liou2008modeling Cheng-Yuan Liou,
    Jau-Chi Huang, and Wen-Chie Yang. Modeling word perception using the elman network.
    *Neurocomputing*, 71(16-18):3150–3157, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[457] Liou et al.(2014)Liou, Cheng, Liou, and Liou⟧liou2014autoencoder Cheng-Yuan
    Liou, Wei-Chen Cheng, Jiun-Wei Liou, and Daw-Ran Liou. Autoencoder for words.
    *Neurocomputing*, 139:84–96, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[458] Williams et al.(2002)Williams, Baxter, He, Hawkins, and Gu⟧williams2002comparative
    Graham Williams, Rohan Baxter, Hongxing He, Simon Hawkins, and Lifang Gu. A comparative
    study of rnn for outlier detection in data mining. In *Data Mining, 2002\. ICDM
    2003\. Proceedings. 2002 IEEE International Conference on*, pages 709–712\. IEEE,
    2002.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[459] Zhou and Paffenroth(2017)⟧zhou2017anomaly Chong Zhou and Randy C Paffenroth.
    Anomaly detection with robust deep autoencoders. In *Proceedings of the 23rd ACM
    SIGKDD International Conference on Knowledge Discovery and Data Mining*, pages
    665–674\. ACM, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[460] Vincent et al.(2010)Vincent, Larochelle, Lajoie, Bengio, and Manzagol⟧vincent2010stacked
    Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and Pierre-Antoine
    Manzagol. Stacked denoising autoencoders: Learning useful representations in a
    deep network with a local denoising criterion. *Journal of machine learning research*,
    11(Dec):3371–3408, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[461] Haque et al.(2018)Haque, Yousuf, and Rana⟧haque2018image Kazi Nazmul
    Haque, Mohammad Abu Yousuf, and Rajib Rana. Image denoising and restoration with
    cnn-lstm encoder decoder with direct attention. *arXiv preprint arXiv:1801.05141*,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[462] Masci et al.(2011)Masci, Meier, Cireşan, and Schmidhuber⟧masci2011stacked
    Jonathan Masci, Ueli Meier, Dan Cireşan, and Jürgen Schmidhuber. Stacked convolutional
    auto-encoders for hierarchical feature extraction. In *International Conference
    on Artificial Neural Networks*, pages 52–59\. Springer, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
