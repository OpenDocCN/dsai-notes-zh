- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:31:00'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2407.19153] A Survey of Malware Detection Using Deep Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.19153](https://ar5iv.labs.arxiv.org/html/2407.19153)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: \cormark
  prefs: []
  type: TYPE_NORMAL
- en: '[1] \cortext[cor1]Corresponding author:'
  prefs: []
  type: TYPE_NORMAL
- en: A Survey of Malware Detection Using Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ahmed Bensaoud abensaou@uccs.edu    Jugal Kalita jkalita@uccs.edu Deptarment
    of Computer Science, University of Colorado Colorado Springs, CO, USA    Mahmoud
    Bensaoud mbensao2@uccs.edu
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The problem of malicious software (malware) detection and classification is
    a complex task, and there is no perfect approach. There is still a lot of work
    to be done. Unlike most other research areas, standard benchmarks are difficult
    to find for malware detection. This paper aims to investigate recent advances
    in malware detection on MacOS, Windows, iOS, Android, and Linux using deep learning
    (DL) by investigating DL in text and image classification, the use of pre-trained
    and multi-task learning models for malware detection approaches to obtain high
    accuracy and which the best approach if we have a standard benchmark dataset.
    We discuss the issues and the challenges in malware detection using DL classifiers
    by reviewing the effectiveness of these DL classifiers and their inability to
    explain their decisions and actions to DL developers presenting the need to use
    Explainable Machine Learning (XAI) or Interpretable Machine Learning (IML) programs.
    Additionally, we discuss the impact of adversarial attacks on deep learning models,
    negatively affecting their generalization capabilities and resulting in poor performance
    on unseen data. We believe there is a need to train and test the effectiveness
    and efficiency of the current state-of-the-art deep learning models on different
    malware datasets. We examine eight popular DL approaches on various datasets.
    This survey will help researchers develop a general understanding of malware recognition
    using deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Malware Detection \sepMulti-task Learning \sepMalware Image \sepGenerative Adversarial
    Networks \sepMobile Malware \sepConvolutional Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Operating systems such as Windows, Android, Linux, and MacOS are updated every
    few weeks to protect against critical vulnerabilities. On the other hand, malware
    authors are also always looking for new ways to finesse their malicious code to
    overwhelm the new operating system updates. Every operating system is vulnerable.
    In addition, since operating systems run on desktops and servers, and even on
    routers, security cameras, drones and other devices, the biggest problem is diversity
    of systems to protect because all these devices are very different.
  prefs: []
  type: TYPE_NORMAL
- en: Most every day, there is a new story about malicious software in the news. For
    example, in Oct 2022, cyberattacks coming from a Russia-based hacker group known
    as Killnet targeted the government services of the state of Colorado, Alabama,
    Alaska, Delaware, Connecticut, Florida, Mississippi, and Kansas websites¹¹1https://www.nbcnews.com/tech/security/colorado-state-websites-struggle-russian-hackers-vow-attack-rcna51012.
    Again in 2022, hackers working on behalf of the Chinese government stole $20 million
    from covid relief benefits²²2https://www.nbcnews.com/tech/security/china-hacked-least-six-us-state-governments-report-says-rcna19255.
    The increase in the vulnerability of sensitive data due to cyber-attacks, cyber-threats,
    cyber-crimes, and malware needs to be countered. In 2023, Fig.  [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ A Survey of Malware Detection Using Deep Learning") shows
    countries that have been attacked by malware and the top origins of these malware
    ³³3https://attackmap.sonicwall.com/live-attack-map.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2f0386bd35ae6a1f8eca66ddce1f2e1b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Worldwide attacks'
  prefs: []
  type: TYPE_NORMAL
- en: Researchers have used deep learning to classify malware samples since it generalizes
    well to unseen data. Our survey focuses on static, dynamic and hybrid malware
    detection methods in Windows, Android, Linux, MacOS, and iOS. We describe the
    strengths and weaknesses of deep learning models for malware detection. Most recent
    research uses deep neural networks (DNNs) for malware classification and achieves
    high success. State-of-the-art DNN models have been developed against modern malware
    such as Zeus, Fleeceware, RaaS, Mount Locker, REvil, LockBit, Cryptesla, Snugy,
    and Shlayer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contributions of this paper are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It gives the big picture of how hackers attack (Sections 2,3,4,5).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It presents how to generate images form malware files (Section 6).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It discusses deep learning models for malware image classification (Section
    7).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It describes feature reduction that can improve performance (Section 8).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It discusses transfer learning approaches in the classification of malware and
    what needs to improve for better performance (Section 9).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It reviews the use of natural language processing in malware classification
    (Section 10).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It presents the deep learning models for cryptographer ransomware (Section 11).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It shows how we know if we can trust the results of a DL model using Explainable
    Artificial Intelligence, XAI (Section 12).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It discusses significant challenge for the reliability and security pozed by
    adversarial attacks on deep learning models (Section 13).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The rest of this paper, we discuss avenues for future research and we examine
    the Efficientnet B0, B1, B2, B3, B4, B5, B6, and B7 models on malware images datasets
    for classification.
  prefs: []
  type: TYPE_NORMAL
- en: 2 Mechanics of Malware Attacts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The hacker has one goal, which is to get malware installed onto a victim’s computer.
    Because most computers are protected by some type of firewall, direct attacks
    are difficult to impossible to perform. Therefore, attackers attempt to trick
    the computer into running the malicious code. The most common way to do this is
    by using documents or executable files. For instance, a hacker may send an email
    or a phish to the victim with a malicious document attachment or a link to a website
    where the malicious document is located. Once the victim opens the document, embedded
    exploits or scripts run and download or extract more malware. This is the real
    malware the hacker wants to run on the victim’s system and is often something
    like a backdoor or ransomware. However, malicious documents are usually not the
    final piece of malware in an attack, but are one of the compromised vectors used
    by the hacker to get on the system. As an example, below we discuss how a PDF
    document can be used to initiate an attack.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 PDF and Document Files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When analyzing PDF, we find three things: Object, which is the structure of
    the PDF, Keywords which control how the PDF works, and Data stored or encoded
    within a PDF.'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Objects are the building blocks of a PDFs. Every PDF starts with a Header which
    needs to be present in the first 1024 bytes of the documents. Some hackers take
    advantage of this by putting unrelated data within the first 1024 bytes. This
    is a very simple technique to try to avoid signature-based detection. PDFs are
    composed of objects; each section has specific data within the document or performs
    a specific function. Each object starts with two numbers, followed by the keyword
    obj, and ends with endobj. There are many kinds of objects, such as font objects,
    image objects, and even objects that contain metadata.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many keywords that begin with a /and describe how the PDF works. Some
    of the keywords related to malicious activity include /OpenAction, or its abbreviation
    /AA, both of which indicate an automatic action to be performed when the document
    is viewed⁴⁴4https://blog.didierstevens.com/programs/pdf-tools/. This keyword points
    to another object that automatically gets opened or executed when the PDF is opened.
    Malicious PDFs have /OpenAction pointing to some malicious JavaScript, or an object
    containing an export; whenever one opens the document, the system is automatically
    compromised. /JavaScript or /JS keyword indicate the presence of JavaScript code.
    Malicious PDFs usually contain malicious JavaScript to launch an exploit or download
    additional malware. Some objects can be referred to as /Name instead of their
    number. Some PDFs have the ability to have files embedded with keyword /EmbeddedFile,
    /URL or /SubmitForm. /URL is accessed or downloaded when the object is loaded.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'PDFs can encode data in multiple ways, which is very flexible and can store
    data in a number of ways. Hackers can encode and hide their data. For example,
    names are case sensitive, but can be fully or partially hex encoded. More precisely,
    the # sign followed by two hex characters represents hex encoded data. Data also
    can be octal encoded or represented by their base eight number. The octal encoded
    character has a $\displaystyle\backslash$ followed by three digits between 0 and
    7\. However, the hackers can mix hex, octal, and ASCII data all together, which
    makes it possible to hide data such as JavaScript code or URLs.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The names and strings can be encoded, but data streams can be modified and encoded
    further using filters. Filters are algorithms that are applied to the data to
    encode or compress within the PDF. There are multiple filters that can be used
    in PDFs, such as /ASCiiHexDecode, Hex encoding of characters; /LZWDecode, LZW
    compression algorithm; /FlateDecode, Zlib compression; /ASCii85Decode, ASCII base-85
    representation; and /Crypt, various encryption algorithms. For example, in Fig.
     [2](#S2.F2 "Figure 2 ‣ 2.1 PDF and Document Files ‣ 2 Mechanics of Malware Attacts
    ‣ A Survey of Malware Detection Using Deep Learning"), we have a PDF document
    with three objects. Object 1 is a catalog that has OpenAction and is referring
    to version 0 of object 2, which means as soon as the document is opened, Object
    2 will be run. Object 2 contains a JavaScript keyword, but we do not see any JavaScript
    code in this object because the JavaScript keyword refers to another object which
    is Object 3\. Object 3 is a stream object as indicated by the stream keyword and
    has been ASCiiHex encoded and compressed with the Zlib compression algorithm.
    However, we have been able to determine that as soon as the PDF opens, JavaScript
    will be executed, and we do not know what the JavaScript’s goal is. If this is
    a malicious PDF, it can cause problems. In Fig.  [3](#S2.F3 "Figure 3 ‣ 2.1 PDF
    and Document Files ‣ 2 Mechanics of Malware Attacts ‣ A Survey of Malware Detection
    Using Deep Learning"), the JavaScript code references the two hosts’ names, performs
    an HTTP GET request to each, saves an executable file, and finally runs it.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4d3a97e8592d50da7c884617db731369.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: PDF format example.'
  prefs: []
  type: TYPE_NORMAL
- en: Is malicious JavaScript used only in documents? The answer is everywhere. Malicious
    JavaScript is used in web pages that are created by web attack kits that perform
    drive-by downloads. The user opens the website that has been compromised or loads
    a malicious ad, which then loads malicious JavaScript. Without JavaScript, it
    is difficult for hackers to get their exploit to work.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/016fe454c7d2f904390bc8330a8fd785.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Malicious JavaScript code'
  prefs: []
  type: TYPE_NORMAL
- en: Most hackers try to hide what their script is doing using obfuscation techniques.
    Most techniques used to obfuscate script can be broken down into four different
    categories. How the format of a program is obfuscated is shown in Fig.  [4](#S2.F4
    "Figure 4 ‣ 2.1 PDF and Document Files ‣ 2 Mechanics of Malware Attacts ‣ A Survey
    of Malware Detection Using Deep Learning"); approaches include adding extra lines
    of code, obfuscating the data, and substituting variable names.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c6983df8390a79ba725431a6d0472473.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Obfuscated malicious JavaScript code.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Nature of Malware Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The nature of malware code encompasses various characteristics and behaviors
    that define its purpose and functionality. Malware, short for malicious software,
    refers to any code or program designed with malicious intent to compromise systems,
    steal information, or disrupt normal operations. The nature of malware code can
    vary depending on its specific type and objectives, but some common attributes
    include:'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Obfuscation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Obfuscation is an attempt by an author of a piece of code to obscure the meaning,
    to make something unclear, or make it very difficult to analyze. It may use encryption
    or compression to hide its true intentions or to evade signature-based detection
    by security software.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Payload Delivery
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Malware code typically carries a payload, which is the malicious action it intends
    to execute. This can range from stealing sensitive information (e.g., financial
    data, login credentials ) to launching distributed denial-of-service (DDoS) attacks,
    encrypting files for ransom (ransomware), or providing backdoor access for remote
    control.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Command and Control (C&C)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many malware strains establish communication channels with remote servers or
    command-and-control infrastructure. This allows attackers to remotely control
    and manage the infected systems, update the malware, and receive stolen data.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Self-Replication
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many malware strains possess the ability to self-replicate, allowing them to
    spread across networks, devices, or files. This replication can occur through
    various means, such as attaching to exploiting vulnerabilities, legitimate files,
    or utilizing network resources.
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 Exploitation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Malware leverages vulnerabilities and weaknesses in software, operating systems,
    or user behavior to gain unauthorized access or control. It can exploit security
    flaws, network vulnerabilities, or social engineering techniques to compromise
    systems and execute malicious actions.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6 Polymorphism
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some malware utilizes polymorphic or metamorphic techniques to dynamically change
    its code structure or appearance while preserving its functionality. This makes
    it more challenging for antivirus software to detect and block.
  prefs: []
  type: TYPE_NORMAL
- en: 3.7 Ransomware
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A ransomware usually combines cryptography with malware. How does it work? The
    hacker sends the file to an unknowing victim. When the victim opens the file,
    it executes the malware’s payload and encrypts victim data such as photos, documents,
    multimedia, files, and even confidential records. The hacker offten forces the
    victim to pay in cryptocurrency, in most cases Bitcoin.
  prefs: []
  type: TYPE_NORMAL
- en: Ransomware has worm-like properties and has names such as WannaCrypt, WanaCrypt0r,
    WCRY, WanaDecrypt0r, and WCrypt. Each encrypted file is locked by a different
    key and encrypted with the RSA algorithm, which makes the file unaccessible to
    the owner who does not have the keys. The WannaCry virus can encrypt a large number
    of file types. An exhaustive list is given in Appendix A.
  prefs: []
  type: TYPE_NORMAL
- en: The ransomware replaces the desktop wallpaper with the ransom note file by modifying
    Windows registry. It holds all files hostage to demand ransom payments of $300
    and later $600 in the Bitcoin cryptocurrency as shown in Fig.  [5](#S3.F5 "Figure
    5 ‣ 3.7 Ransomware ‣ 3 Nature of Malware Code ‣ A Survey of Malware Detection
    Using Deep Learning").
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8efc64d037a5cfb240d6659f4ca365e7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Oops, your files have been encrypted!'
  prefs: []
  type: TYPE_NORMAL
- en: As an example, on May 11, 2022, Costa Rica’s newly elected president had to
    declare a state of national emergency due to a ransomware attack carried out by
    the Conti ransomware gang. They requested $10 million, but the demand changed
    to $20 million after Costa Rica refused to pay⁵⁵5https://securityintelligence.com/news/costa-rica-state-emergency-ransomware/.
    As another example, in october 2022, ransomware gang accessed data on 270,000
    patients from Louisiana hospital system ⁶⁶6https://www.cnn.com/2022/12/28/politics/hackers-access-data-louisiana-hospital-system-ransomware/index.html.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the nature of malware code is crucial for developing effective
    defense mechanisms and mitigating its impact. It enables security professionals
    to develop robust detection methods, implement security best practices, and respond
    promptly to evolving threats.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Overview & Malware Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Malware detection methods are divided into three types: static, dynamic, and
    hybrid [[1](#bib.bib1)]. Static methods inspect an executable file without running
    it, while dynamic methods must run the executable file and analyze its behaviors
    inside a controlled environment. In hybrid methods, the information is collected
    regarding malware from static as well as dynamic analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: Some security researchers use static features by decompiling the target file.
    Naik et al. [[2](#bib.bib2)] proposed a fuzzy-import hashing technique based on
    static analysis for malware detection. Mohamad et al. [[3](#bib.bib3)] proposed
    machine learning classifiers based on permission-based features for static analysis
    to detect Android malware.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to static analysis, dynamic analysis includes system dynamic behavior
    monitoring, snapshot, debugging, etc. Kim et al. [[4](#bib.bib4)] presented a
    new encoding technique for dynamic features to identify anomalous events using
    Convolutional Neural Networks (CNNs).
  prefs: []
  type: TYPE_NORMAL
- en: Security researchers have also extracted combined features from different parts
    of malware files. Bai et al. [[5](#bib.bib5)] extracted features from static and
    dynamic analysis of Android apps and applied a deep learning technique. Chaulagain
    et al. [[6](#bib.bib6)] presented a deep learning-based hybrid analysis technique
    by collecting different artifacts during static and dynamic analysis to train
    the deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Data for Malware Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Numerous system logs of activities of machines such as phones, tablets, laptops,
    and other devices are generated by the operating system and other infrastructure
    software. The data are created and stored on the local device and sent to remote
    servers. Analyzing log data, we can not only detect breaches or suspicious activity,
    but we can track behavior through the network. Log data allow us to track security
    events, troubleshoot the infrastructure, and optimize the environment and the
    machines. Log data can take many different forms like syslog, authentication logs,
    local security event logs, network asset logs, and system logs. One of goals in
    malware detection is to be able to read, search, and analyze the data efficiently
    and effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Table 1 contains some information that is useful from syslog and windows logs.
    Both kinds of logs have many components in different format that helps us in the
    investigation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Syslog and Windows log'
  prefs: []
  type: TYPE_NORMAL
- en: '| Syslog | Windows Logs |'
  prefs: []
  type: TYPE_TB
- en: '| IETF standard | Event log |'
  prefs: []
  type: TYPE_TB
- en: '| Timestamp | Contains source, event ID, and log level |'
  prefs: []
  type: TYPE_TB
- en: '| Standard for network equipment logging | Logs Application, security, network
    events from a machine or server |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Device-ID, severity level, message number, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; message text &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Timestamp, user, computer, and process ID |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Can be customized on network equipment &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; for different events and severity levels &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Used in most enterprise environments running Windows |'
  prefs: []
  type: TYPE_TB
- en: 6 Generating Malware Images for Deep Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Several tools can visualize and edit a binary file in hexadecimal or ASCII formats
    such as IDA Pro⁷⁷7https://hex-rays.com/ida-pro, x32/x64 Debugger⁸⁸8https://x64dbg.com/#start,
    HxD⁹⁹9https://mh-nexus.de/en/hxd, PE-bear^(10)^(10)10https://hshrzd.wordpress.com/pe-bear,
    Yara^(11)^(11)11https://yara.readthedocs.io/en/stable, Fiddler^(12)^(12)12https://www.telerik.com/purchase/fiddler,
    Metadata^(13)^(13)13https://www.malwarebytes.com/glossary/metadata, XOR analysis^(14)^(14)14https://eternal-todo.com/var/scripts/xorbruteforcer,
    and Embedded strings^(15)^(15)15https://virustotal.github.io/yara/.
  prefs: []
  type: TYPE_NORMAL
- en: Malware file or code can be used to generate an image by converting the binary,
    octal, hexadecimal or decimal into a two dimensional matrix of pixels. The image
    can be grayscale or RGB. In greyscale, pixels are black and white values in the
    range [0-255] where 0 represents black, and 255 represents white.
  prefs: []
  type: TYPE_NORMAL
- en: 'Gray image feature: The machine stores images in a matrix of numbers. These
    numbers, or the pixel values, denote the intensity or brightness of the pixel.
    Smaller numbers (close to zero) represent black, and larger numbers (closer to
    255) denote white (see Fig.  [6](#S6.F6 "Figure 6 ‣ 6 Generating Malware Images
    for Deep Learning ‣ A Survey of Malware Detection Using Deep Learning")).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e98d6d535955054239b9656394cc2488.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Malware feature representation in grayscale image'
  prefs: []
  type: TYPE_NORMAL
- en: 'RGB images: There are three matrices or channels (Red, Green, Blue), where
    each matrix has values between $\displaystyle 0-255$. These three colors are combined
    together in various ways to represent one of 16,777,216 possible colors (see Fig.
     [7](#S6.F7 "Figure 7 ‣ 6 Generating Malware Images for Deep Learning ‣ A Survey
    of Malware Detection Using Deep Learning")).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7806073a371415e64d727a2c639052e0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Malware feature representation in RGB image'
  prefs: []
  type: TYPE_NORMAL
- en: 'Malware can be converted to images in different ways. Yuan et al. [[7](#bib.bib7)]
    converted malware binaries into Markov images by computing transfer probability
    of bytes where each pixel is generated by equation [1](#S6.E1 "In 6 Generating
    Malware Images for Deep Learning ‣ A Survey of Malware Detection Using Deep Learning"):'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $p_{m,n}=P(n&#124;m)=\frac{f(m,n)}{\displaystyle\sum_{n=0}^{255}f(m,n)}\quad
    m,n\in\{0,1,...,255\}.\\ $ |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: Mohammed et al. [[8](#bib.bib8)] used a vector of 16-bit signed hexadecimal
    numbers to represent a $\displaystyle 256\times 256$ image. Then, they computed
    bi-gram frequency counts which they used as pixel intensity values. Full-frame
    Discrete Cosine Transform (DCT) [[9](#bib.bib9)] was computed to de-sparsify,
    and the bigram-DCT was used to represent the output image. Euh et al. [[10](#bib.bib10)]
    proposed Window Entropy Map (WEM) to visualize malware as an image. They calculated
    the entropy for each byte to measure the degree of uncertainty. Ni et al. [[11](#bib.bib11)]
    converted malware code into gray images using SimHash [[12](#bib.bib12)] and then
    encoded them. They mapped SimHash values to pixels and then converted them to
    grayscale images.
  prefs: []
  type: TYPE_NORMAL
- en: 7 Image Classification for Malware Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning can solve diverse "vision" problems, including malware image classification
    tasks. Deep learning can extract features automatically obviating manual feature
    extraction. The content of the malware executable file is first converted into
    a digital image. Nataraj et al. [[13](#bib.bib13)] visualized the byte codes of
    samples from 25 malware families as grayscale images. Several visualization techniques
    have been used for malware classification. The basic idea used in these methods
    is to explore the distinguishing patterns in malware images. In addition, the
    visualization techniques help find the correlations among different malware families.
    Some existing approaches generate grayscale images and others generate RGB images.
    Most existing approaches use global features to generate malware image.
  prefs: []
  type: TYPE_NORMAL
- en: Yuan et al. [[7](#bib.bib7)] proposed a method based on Markov images according
    to the byte transmission probability matrix. They used a CNN to classify Markov
    malware images without scaling. Narayanan and Davuluru [[14](#bib.bib14)] proposed
    an ensemble approach using RNN and CNN architectures for malware image classification.
    Images were generated from assembly compiled files and classified using CNNs.
    Zhu et al. [[15](#bib.bib15)] proposed a Task-Aware Meta Learning-based Siamese
    Neural Network to classify obfuscated malware images. Their model showed high
    effectiveness on unique malware signature detection to classify obfuscated malware.
    Chauhan et al. [[16](#bib.bib16)] visualized malware files in different color
    modes, RGB, HSV, greyscale, and BGR. They used a support vector machine (SVM)
    to classify these malware images, with accuracy of 96% in all modes. Darem et al.
    [[17](#bib.bib17)] designed a semi-supervised method based on malware image and
    feature engineering for obfuscated malware detection. The model achieved 99.12%
    accuracy on obfuscated malware detection. Asam et al. [[18](#bib.bib18)] proposed
    two malware image classification approaches called Deep Feature Space-based Malware
    classification (DFS-MC) and Deep Boosted Feature Space-based Malware classification
    (DBFS-MC). The approach achieved a good accuracy of 98.61% on the MalImg malware
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Xiao et al. [[19](#bib.bib19)] presented a visualization method called Colored
    Label boxes (CoLab) to specify each section in a PE file and convert it to malware
    image. The authors built a composed CoLab image,cand used VGG16, and Support vector
    machine for classification. The model was applied on two datasets, VX-Heaven^(16)^(16)16https://archive.org/download/vxheavens-2010-05-18
    and BIG-2015, with 96.59% and 98.94% average accuracies, respectively. A comparison
    of reviewed malware images classification is discussed in Table 2.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: Comparative performance summary of Transfer Learning models for malware
    image classification.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Reference | Features | Model | Files | Accuracy | Dataset |'
  prefs: []
  type: TYPE_TB
- en: '| Çayır et al. [[20](#bib.bib20)] | gray-scale images | CapsNet | PE | 98.63%
    | Malimg |'
  prefs: []
  type: TYPE_TB
- en: '| Çayır et al. [[20](#bib.bib20)] | gray-scale images | RCNF | PE | 98.72%
    | Malimg |'
  prefs: []
  type: TYPE_TB
- en: '| Go et al. [[21](#bib.bib21)] | gray-scale images | ResNeXt | PE | 98.32%
    | Malimg |'
  prefs: []
  type: TYPE_TB
- en: '| Bensaoud et al. [[22](#bib.bib22)] | gray-scale images | Inception V3 | PE
    | 99.24% | Malimg |'
  prefs: []
  type: TYPE_TB
- en: '| El-Shafai et al. [[23](#bib.bib23)] | gray-scale images | VGG16 | PE | 99.97%
    | Malimg |'
  prefs: []
  type: TYPE_TB
- en: '| Hemalatha et al. [[24](#bib.bib24)] | gray-scale images | DenseNet | PE |
    98.23% | Malimg |'
  prefs: []
  type: TYPE_TB
- en: '| Hemalatha et al. [[24](#bib.bib24)] | gray-scale images | DenseNet | PE |
    98.46% | BIG 2015 |'
  prefs: []
  type: TYPE_TB
- en: '| Lo et al. [[25](#bib.bib25)] | gray-scale images | Xception | PE | 99.03%
    | Malimg |'
  prefs: []
  type: TYPE_TB
- en: '| Lo et al. [[25](#bib.bib25)] | gray-scale images | Xception | PE | 99.17%
    | BIG 2015 |'
  prefs: []
  type: TYPE_TB
- en: 8 Feature Reduction for Efficient Malware Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Feature Reduction reduces the number of variables or features in the representation
    of a data example. Approaches to feature reduction can be divided into two subcategories
    called a) Feature Selection which includes methods such as Wrappers, Filters,
    and Embedded, and b) Feature Extraction, which includes methods such as Principal
    Components Analysis [[26](#bib.bib26)]. How does Feature Reduction improve performance?
    It does by reducing the number of features that are considered for analysis.
  prefs: []
  type: TYPE_NORMAL
- en: In feature extraction, we start with $\displaystyle n$ features <math id="S8.p2.2.m2.1"
    class="ltx_math_unparsed" alttext="\displaystyle x_{1},x_{2},x_{3}\\
  prefs: []
  type: TYPE_NORMAL
- en: ',....,x_{n}" display="inline"><semantics id="S8.p2.2.m2.1a"><mrow id="S8.p2.2.m2.1b"><msub
    id="S8.p2.2.m2.1.2"><mi id="S8.p2.2.m2.1.2.2">x</mi><mn id="S8.p2.2.m2.1.2.3">1</mn></msub><mo
    id="S8.p2.2.m2.1.3">,</mo><msub id="S8.p2.2.m2.1.4"><mi id="S8.p2.2.m2.1.4.2">x</mi><mn
    id="S8.p2.2.m2.1.4.3">2</mn></msub><mo id="S8.p2.2.m2.1.5">,</mo><msub id="S8.p2.2.m2.1.6"><mi
    id="S8.p2.2.m2.1.6.2">x</mi><mn id="S8.p2.2.m2.1.6.3">3</mn></msub><mo id="S8.p2.2.m2.1.7">,</mo><mi
    mathvariant="normal" id="S8.p2.2.m2.1.1">…</mi><mo lspace="0em" rspace="0.167em"
    id="S8.p2.2.m2.1.8">.</mo><mo id="S8.p2.2.m2.1.9">,</mo><msub id="S8.p2.2.m2.1.10"><mi
    id="S8.p2.2.m2.1.10.2">x</mi><mi id="S8.p2.2.m2.1.10.3">n</mi></msub></mrow><annotation
    encoding="application/x-tex" id="S8.p2.2.m2.1c">\displaystyle x_{1},x_{2},x_{3}\\
    ,....,x_{n}</annotation></semantics></math>, which we map to a lower dimensional
    space to get the new features $\displaystyle z_{1},z_{2},z_{3},....,z_{m}$ where
    $\displaystyle m<n$. Each of the new features is usually linear a combination
    of the original feature set $\displaystyle x_{1},x_{2},x_{3},....,x_{n}$. Thus,
    each new feature is obtained as a function F(X) of the original feature set X.
    This makes a projection of a higher dimensional feature space to a lower dimensional
    feature space, so that the smaller dimensional feature set may lead to better
    classification or faster classification (see equation [2](#S8.E2 "In 8 Feature
    Reduction for Efficient Malware Detection ‣ A Survey of Malware Detection Using
    Deep Learning")).'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{bmatrix}z_{1}\ldots z_{m}\end{bmatrix}^{\intercal}\ =F\left(\begin{bmatrix}x_{1}\ldots
    x_{n}\end{bmatrix}^{\intercal}\right)$ |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: 'In feature selection, we choose a subset of the features, in contrast to feature
    extraction where we map the original features to a lower dimensional space. The
    smaller dimensional feature set can help produce better as well as faster classification.
    To do that, we need to find a projection matrix $\displaystyle W\ni\bar{Z}=W^{T}\bar{X}$.
    We expect from such a projection that the new features are uncorrelated and cannot
    be reduced further and are non redundant. Next, we need features to have large
    variance: Why? Because if a feature takes similar values for all the instances,
    that feature cannot be used as a discriminator.'
  prefs: []
  type: TYPE_NORMAL
- en: Feature extraction methods such as a Principal Component Analysis (PCA) [[26](#bib.bib26)],
    GIST [[27](#bib.bib27)], Hu Moments [[28](#bib.bib28)], Color Histogram [[29](#bib.bib29)],
    Haralick texture [[30](#bib.bib30)], Discrete Wavelet Transform (DWT) [[31](#bib.bib31)],
    Independent Component Analysis (ICA) [[32](#bib.bib32)], Linear discriminant analysis
    (LDA) [[33](#bib.bib33)], Oriented Fast and Rotated BRIEF (ORB) [[34](#bib.bib34)],
    Speeded Up Robust Feature (SURF) [[35](#bib.bib35)], Scale Invariant Feature Transform
    (SIFT) [[36](#bib.bib36)], Dense Scale Invariant Feature Transform (D-SIFT) [[36](#bib.bib36)],
    Local Binary Patterns (LBPs) [[37](#bib.bib37)], KAZE [[38](#bib.bib38)] have
    been combined with machine learning including deep learning. These methods successfully
    filter the characteristics of malware files.
  prefs: []
  type: TYPE_NORMAL
- en: Azad et al. [[39](#bib.bib39)] proposed a method named DEEPSEL (Deep Feature
    Selection) to identify malicious codes of 39 unique malware families. Their model
    achieved an accuracy of 83.6% and an F-measure of 82.5%. Tobiyama et al. [[40](#bib.bib40)]
    proposed feature extraction based on system calls. Recurrent Neural Network was
    used to extract features and Convolutional Neural Network to classify these features.
  prefs: []
  type: TYPE_NORMAL
- en: 9 Deep Transfer Leaning models for Malware detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Transfer learning takes place if we have a source model which has some pre-trained
    knowledge and this knowledge is needed as the foundation to build a new model
    [[41](#bib.bib41)]. For example, using a very large pre-trained convolutional
    neural network usually involves saving a network that was previously trained on
    some large dataset, typically on a large-scale image classification task, using
    a dataset like ImageNet [[42](#bib.bib42)]. After training a network on the ImageNet
    dataset, we can re-purpose this trained network. Research papers have discussed
    applying these pre-trained networks to malware image datasets [[43](#bib.bib43),
    [44](#bib.bib44), [45](#bib.bib45), [46](#bib.bib46)] that are generated form
    PE and APK malware files, which are quite different from each other.
  prefs: []
  type: TYPE_NORMAL
- en: Malware image datasets are very different from ImageNet, which is normally used
    to pre-train the model. The ImageNet dataset and a malware image dataset represent
    visually completely different images. However, pre-trained still seems to help.
    Training a machine learning algorithm on large datasets can be done in two ways,
    as discussed below.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1 Using feature extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Feature extraction discussed earlier is a practical and common, and low resource-intensive
    way of using pre-trained networks. It takes the convolutional base of a previously
    trained network and runs the malware data through it, and then trains a new classifier
    on top of the output. As shown in Fig.  [8](#S9.F8 "Figure 8 ‣ 9.1 Using feature
    extraction ‣ 9 Deep Transfer Leaning models for Malware detection ‣ A Survey of
    Malware Detection Using Deep Learning"), we can choose a network such as VGG16
    [[47](#bib.bib47)] that has been trained on ImageNet, as an example. The input
    fed at the bottom, goes up to the trained convolutional base, representing the
    CNN region of the VGG16\. The trained classifier resides in the dense region and
    the prediction is made by this dense region at the end. Usually, we have $\displaystyle
    1000$ neurons at the end to predict the actual ImageNet classes. We take this
    ImageNet trained model as base, and remove the classifier layer, keeping the convolutional
    layers of the pre-trained model, along with their weights. In the next step, we
    attach a new classifier that has new dense layers for malware classification on
    top. The weights of the base are frozen, which means that the malware input passes
    through convolutional layers which have their prior weights, during training.
    However, all dense layers are randomly initialized, and the interconnection weights
    for these layers are learned during the new training process for detecting malware.
  prefs: []
  type: TYPE_NORMAL
- en: Why remove the original dense layers? What has been observed is that the representations
    learned by the convolutional base are generic and therefore reusable for a variety
    of tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7d2b67e3cfb70113b8d2f855c845eb36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Feature Extraction for Transfer Learning'
  prefs: []
  type: TYPE_NORMAL
- en: 9.2 Using fine tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Fine-tuning involves changing some of the convolutional layers by learning new
    weights. In Fig.  [9](#S9.F9 "Figure 9 ‣ 9.2 Using fine tuning ‣ 9 Deep Transfer
    Leaning models for Malware detection ‣ A Survey of Malware Detection Using Deep
    Learning"), we have a network divided into three regions. The yellow region is
    a pre-trained model. The green region represents our dense layers for which we
    need to learn the weights. During training using a library such as Keras [[48](#bib.bib48)]
    and Tensorflow [[49](#bib.bib49)], we can select certain layers and freeze the
    weights of those layers.
  prefs: []
  type: TYPE_NORMAL
- en: For example, we can select convolutional block one and then freeze all the weights
    of the convolutional layers, in this block only. This means that during training,
    everything else will change, but the weights of the convolutional layers in this
    block will not change. Similarly, we can keep frozen the convolutional layers
    of the next block as well as blocks three and four if we so wish. Then, we can
    fine-tune the convolutional layers that are closer to the dense layer. As a result,
    the initial layers of representation are kept constant, but new representations
    are learned by later layers (yellow region) as their weights change, evolve and
    get updated.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, fine-tuning means unfreezing a few of the top layers of a frozen model
    base used for feature extraction. What we simply do is jointly train the newly
    added top part of the model (green region) consisting of dense layers, and the
    top convolutional layers (yellow region), for which we have unfrozen the weights.
  prefs: []
  type: TYPE_NORMAL
- en: Why fine-tune in this manner? Because, we slightly adjust the more abstract
    representations of the model being reused to make them more relevant for the problem
    at hand. Sudhakar and Kumar [[50](#bib.bib50)] redesigned ResNet50 [[51](#bib.bib51)]
    by changing the last layer with a fully connected dense layer to detect unknown
    malware samples without feature engineering. Go et al. [[52](#bib.bib52)] proposed
    a visualization approach to classify the malware families by using a ResNeXt50
    pre-trained model. The model achieved 98.86% accuracy on the Malimg dataset [[13](#bib.bib13)].
    Çayır et al. [[20](#bib.bib20)] built an ensemble pre-trained capsule network
    (CapsNet) [[53](#bib.bib53)] based on the bootstrap aggregating approach. The
    model was trained and tested on two public datasets, Malimg, and BIG2015\. Their
    model achieved F-Score 96.6% on the Malimg dataset [[13](#bib.bib13)] and 98.20%
    on the BIG2015 dataset^(17)^(17)17https://www.kaggle.com/c/malware-classification.
    Bensaoud et al. [[22](#bib.bib22)] used six convolutional neural network models
    for malware classification. Comparison among these models shows that the transfer
    learning model called Inception-V3 [[54](#bib.bib54)] achieved the current state-of-the-art
    in malware classification. Khan et al. [[55](#bib.bib55)] evaluated ResNet and
    GoogleNet [[56](#bib.bib56)] models for malware detection by converting an APK
    bytecode into grayscale image. Table 3 summarizes the most transfer learning models
    for malware classification. We conclude that CNN transfer learning models can
    be fine-tuned to specific image sizes that are robust enough and accurate to use
    malware image classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: Fine-tuned pre-trained models applied on different malware image datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Setting | Average Accuracy | Our Dataset |'
  prefs: []
  type: TYPE_TB
- en: '| Pre-trained Model | Samples | Resize image | Epoch | Malimg | Microsoft Challenge
    | Drebin | Accuracy |'
  prefs: []
  type: TYPE_TB
- en: '| EffNet B0 | 30,000 | 224 | 200 | 92.72% | 90.45% | 87.23% | 94.59% |'
  prefs: []
  type: TYPE_TB
- en: '| EffNet B1 | 30,000 | 240 | 200 | 95.64% | 93.65% | 88.91% | 95.89% |'
  prefs: []
  type: TYPE_TB
- en: '| EffNet B2 | 20,000 | 260 | 200 | 93.84% | 91.78% | 86.82% | 94.12% |'
  prefs: []
  type: TYPE_TB
- en: '| EffNet B3 | 15,000 | 300 | 400 | 90.32% | 94.19% | 89.35% | 95.73% |'
  prefs: []
  type: TYPE_TB
- en: '| EffNet B4 | 20,000 | 380 | 400 | 95.63% | 96.68% | 90.59% | 97.98% |'
  prefs: []
  type: TYPE_TB
- en: '| EffNet B5 | 25,000 | 456 | 400 | 80.19% | 87.54% | 84.23% | 94.68% |'
  prefs: []
  type: TYPE_TB
- en: '| EffNet B6 | 40,000 | 528 | 400 | 85.67% | 83.82% | 85.43% | 93.54% |'
  prefs: []
  type: TYPE_TB
- en: '| EffNet B7 | 30,000 | 600 | 1000 | 82.76% | 80.76% | 90.57% | 88.45% |'
  prefs: []
  type: TYPE_TB
- en: '| Inception V4 | 20,000 | 229 | 300 | 95.98% | 93.21% | 88.93% | 96.39% |'
  prefs: []
  type: TYPE_TB
- en: '| Xception | 20,000 | 229 | 200 | 89.50% | 90.84% | 84.39% | 93.53% |'
  prefs: []
  type: TYPE_TB
- en: '| CapsNet | 3,000 | 256 | 100 | 88.64% | 72.69% | 78.68% | 92.65% |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/19893baff79b11b63cadee7be6cc53cf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Fine Tuning of Transfer Learning'
  prefs: []
  type: TYPE_NORMAL
- en: Fig.  [10](#S9.F10 "Figure 10 ‣ 9.2 Using fine tuning ‣ 9 Deep Transfer Leaning
    models for Malware detection ‣ A Survey of Malware Detection Using Deep Learning")
    shows how to train the model on an image dataset. We randomly initialize the model,
    and then train the model on dataset X, which is a large-scale image dataset. This
    is the pre-training step. Next, we train the model on dataset Y; this dataset
    is typically smaller than dataset X. This is the fine-tuning step.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f36b592e7c323d43cea4a42f12a5c7ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Transfer Learning steps'
  prefs: []
  type: TYPE_NORMAL
- en: State-of-the-art transfer learning models we have trained and evaluated for
    malware classification are EffNet B0, B1, B2, B3, B4, B5, B6, and B7 [[57](#bib.bib57)];
    Inception-V4 [[58](#bib.bib58)], Xception [[59](#bib.bib59)], and CapsNet [[60](#bib.bib60)]
    as shown in Table 3\. The datasets used are our RGB malware image dataset and
    two other datasets, namely Malimg Dataset [[13](#bib.bib13)] and Microsoft Malware
    Dataset [[61](#bib.bib61)]. The accuracy and loss curve plots for EffNet B1, B2,
    B3, B4, B5, B6, and B7 are shown in Appendix B and EffNet B0 shows in Fig.  [11](#S9.F11
    "Figure 11 ‣ 9.2 Using fine tuning ‣ 9 Deep Transfer Leaning models for Malware
    detection ‣ A Survey of Malware Detection Using Deep Learning").
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/89861764118781e315856fd11b66a5a6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Training and testing for accuracy and loss of EfficientnetB0'
  prefs: []
  type: TYPE_NORMAL
- en: We found that the Inception-V4 model is most effective in classifying malware
    images among the ten models. In addition, the training times for each model increases
    with increase in the size of input images since the number of network cells grows
    quickly in GPU RAM.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3 Analysis of Transfer Learning for Malware Classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We found that transfer learning based image classification, with a small number
    of parameters to retrain successfully to classify malware images. On the other
    hand, we argue that scaled up wider and deeper transfer models with more parameters
    builds a new model that may improve performance. Inception-V3 and Inception-V4
    for malware detection and classification avoid the inefficiencies in classifying
    unknown malware grayscale and RGB images among transfer learning classification
    model. There are many transfer learning models techniques such as batch normalization
    [[62](#bib.bib62)], skip connections [[63](#bib.bib63)] that are designed to help
    in training, but the accuracy still needs to improve. For instance, ResNet-101
    and ResNet-50 have similar accuracies in terms of malware detection even though
    they have very different deep networks [[64](#bib.bib64)].
  prefs: []
  type: TYPE_NORMAL
- en: 10 Natural Language Processing for Malware Classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Natural Language Processing (NLP) extracts valuable information so that a program
    is able to read, understand and derive meaning from human language text or speech.
    Malware data contain executable files, Microsoft Word files, macro files, logs
    from different operating systems, emails, network activities, etc. Many of these
    files contain extensive amounts of text; some others contain snippets of text
    mixed with code and other information. NLP can be used to enhance malware classification
    due to the extensive use of text or text-like content within malware. A critical
    requirement for malware text classification is using effective text representation
    in the form text encoding. The initial step in text encoding is preprocessing
    by removing a redundant opcode or API fragments, discarding unnecessary text.
    After tokenization, there are different types of non-sequential text representations
    [[65](#bib.bib65)] such as Bag of Words (BoW), Term Frequency Inverse document
    frequency matrices (TFIDF), Term document matrices (TDM), n-grams, One hot encoding,
    ASCII representations, and modren word embedding such as Word2vec [[66](#bib.bib66)]
    and Sent2vec [[67](#bib.bib67)]. Table 4 presents text representation methods
    used in malware classification. Current word embeddings, when used in malware
    classification, do not carry much semantic and contextual significance. Bensaoud
    and Kalita [[68](#bib.bib68)] proposed a novel model for malware classification
    using API calls and opcodes, incorporating a combined Convolutional Neural Network
    and Long Short-Term Memory architecture. By transforming features into N-gram
    sequences and experimenting with various deep learning architectures, including
    Swin-T and Sequencer2D-L, the method achieves a high accuracy of 99.91%, surpassing
    state-of-the-art performance. Mimura and Ito [[69](#bib.bib69)] designed NLP-based
    malware detection by using printable ASCII strings. The model can detect effectively
    packed malware and anti-debugging. Sequence to Sequence neural models are commonly
    used for natural languages processing and therefore used for malware detection
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: The steps of encoding the domain by NLP.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Domain | Notes |'
  prefs: []
  type: TYPE_TB
- en: '| www.uccs.edu | Start with domain |'
  prefs: []
  type: TYPE_TB
- en: '| uccs | Extract second level |'
  prefs: []
  type: TYPE_TB
- en: '| ["u","c","c","s"] | Convert to sequence |'
  prefs: []
  type: TYPE_TB
- en: '| [21,3,3,18] |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Translate character to &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; numeric values &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| [0,0,0,….,0,21,3,3,18] | Pad sequence |'
  prefs: []
  type: TYPE_TB
- en: 10.1 Sequence to Sequence Neural Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Attention mechanism [[70](#bib.bib70)] has achieved high performance in sequential
    learning applications such as machine translation [[71](#bib.bib71)], image recognition
    [[72](#bib.bib72)], text summarization [[73](#bib.bib73)], and text classification
    [[74](#bib.bib74)]. Attention mechanism was designed to improve the performance
    of the encoder-decoder machine translation approach [[75](#bib.bib75)]. The encoder
    and decoder are usually many stacked RNN layers such as LSTM as shown in Fig.
     [12](#S10.F12 "Figure 12 ‣ 10.1 Sequence to Sequence Neural Models ‣ 10 Natural
    Language Processing for Malware Classification ‣ A Survey of Malware Detection
    Using Deep Learning"). The encoder converts the text into a fixed-length vector
    while the decoder generates the translation text from this vector. The sequence
    {$\displaystyle x_{1},x_{2},...,x_{n}$} can either be a representation of text
    or image as shown in Fig.  [13](#S10.F13 "Figure 13 ‣ 10.1 Sequence to Sequence
    Neural Models ‣ 10 Natural Language Processing for Malware Classification ‣ A
    Survey of Malware Detection Using Deep Learning"). In case of sequences, Recurrent
    Neural Networks (RNNs) can take two sequences with the same or arbitrary lengths.
    In Fig.  [14](#S10.F14 "Figure 14 ‣ 10.1 Sequence to Sequence Neural Models ‣
    10 Natural Language Processing for Malware Classification ‣ A Survey of Malware
    Detection Using Deep Learning"), the encoder creates a compressed representation
    called context vector of the input, while the decoder gets the context vector
    to generate the output sequence. In this approach, the network is incapable of
    remembering dependencies in long sentences. This is because the context vector
    needs to handle potentially long sentences, and a shoot overall representation
    does not have the especially to store many potential dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Attention in encoder-decoder: Bahdanau et al. [[76](#bib.bib76)] proposed an
    encoder-decoder attention mechanism framework for machine translation. A single
    fixed context vector is created by an RNN by encoding the input sequence. Rather
    than using just the fixed vector, we can also use each state of the encoder along
    with the current decoder state to generate a dynamic context vector. There are
    two benefits; the first benefit is encoding information contained in a sequence
    of vectors not just in one single context vector. The second benefit is to choose
    a subset of these vectors adaptively while decoding the translation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3e97fdde9b73a8c8fd87658397e69a5c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: Encoder and decoder'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e89130f94a06a05c69b481868bf2d2cc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Encoder and decoder include RNNs'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b0e9952889442decedc722cfec46ba50.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: Encoder and decoder include RNNs with attention mechanism'
  prefs: []
  type: TYPE_NORMAL
- en: An attention mechanism is another Lego block that can be used in any deep learning
    model. Vaswani et al. [[77](#bib.bib77)] showed that an attention mechanism is
    apparently the only Lego block one needs. It improved the performance of a language
    translation model by dynamically choosing important parts of the input sequence
    that matter at a certain point in the output sequence. We can entirely replace
    traditional Recurrent Neural Network (RRN) blocks by an attention mechanism block.
    When dealing with sequential data, the attention mechanisms allow models to not
    only perform better but also train faster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Applying attention mechanism in malware classification: Or-Meir et al. [[78](#bib.bib78)]
    added an attention mechanism to an LSTM model, which improved accuracy in malware
    classification. Yakura et al. [[79](#bib.bib79)] proposed a method by using Convolutional
    Neural Network with Attention Mechanism for malware image classification. Mimura
    and Ohminami [[80](#bib.bib80)] proposed a sliding local attention mechanism model
    (SLAM) based on API execution sequence. Ma et al. [[81](#bib.bib81)] proposed
    a malware classification framework (ACNN) based on two sections within the malware
    text, the assembly code and binary code, and converted them into multi-dimensional
    features. A CNN with attention mechanism for classification has a higher malware
    image classification accuracy than conventional methods [[79](#bib.bib79)]. To
    build predictive models using LSTM and attention mechanism for malware classification,
    we need to add an embedding layer followed by an LSTM layer and dense layers .
    This approach is superior to capturing a long sequence of Windows API call sequences
    and using them directly [[82](#bib.bib82)] (see Fig.  [15](#S10.F15 "Figure 15
    ‣ 10.1 Sequence to Sequence Neural Models ‣ 10 Natural Language Processing for
    Malware Classification ‣ A Survey of Malware Detection Using Deep Learning")).
    Malware’s longer sequence can be addressed by attention mechanisms that can help
    detect short repeating patterns and other dependencies [[83](#bib.bib83)]. While
    attention mechanism improves accuracy, it suffers from the heavy computation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/10e53b09aeb1434c73ecb712c7b20833.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: LSTM with attention mechanism for malware classification'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: State-of-the-art deep learning models.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Ref | Deep Learning Approach | OS | Features | Accuracy |'
  prefs: []
  type: TYPE_TB
- en: '| Kim et al. [[84](#bib.bib84)] | MAPAS | Android | API call graphs | 91.27%
    |'
  prefs: []
  type: TYPE_TB
- en: '| Onwuzurike et al. [[85](#bib.bib85)] | MaMaDroid | Android | API calls |
    84.99% |'
  prefs: []
  type: TYPE_TB
- en: '| Kim and Cho [[86](#bib.bib86)] | Deep Generative Model | Android |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Dalvik code, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; API call, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Malware images, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; developers’ signature &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 97.47% |'
  prefs: []
  type: TYPE_TB
- en: '| Olani et al. [[87](#bib.bib87)] | DeepWare | Windows/Linux | HPC | 96.8%
    |'
  prefs: []
  type: TYPE_TB
- en: '| Lian et al. [[88](#bib.bib88)] | Multi-Modal Deep Learning | Windows |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Grayscale image, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Byte/Entropy &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Histogram &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 97.01% |'
  prefs: []
  type: TYPE_TB
- en: '| Bensaoud and Kalita [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Deep multi-task &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; learning &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Windows &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Android &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Linux &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; MacOS &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Grayscale &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; color image &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 99.97% |'
  prefs: []
  type: TYPE_TB
- en: Table 5 shows various approaches and their corresponding accuracies. The methods
    presented, including MAPAS, MaMaDroid, Deep Generative Model, DeepWare, Multi-Modal
    Deep Learning, and Deep Multi-Task Learning, employ diverse techniques such as
    API call graph analysis, static analysis, and hybrid deep generative models. Particularly,
    these methods are evaluated on distinct datasets, indicating that the comparisons
    are not based on the same dataset. The authors aim to convey the effectiveness
    of these models in detecting malware across different datasets and scenarios.
    However, a comprehensive overview of the comparative performance of these methods
    is needed, highlighting their strengths and capabilities in addressing the challenges
    of malware detection.
  prefs: []
  type: TYPE_NORMAL
- en: 11 Deep Learning for Cryptographic Ransomware
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cryptography has been used traditionally for military and government use, to
    keep secrets from the enemy. Today most of us use cryptography when we use commercial
    websites or services. For example, we use it to protect our emails. A lot of countries
    try to control the export of cryptography to make sure that good cryptographic
    algorithms are not in the hands of criminals, enemies, or adversaries. This is
    the idea behind export administration, and regulations as codified in International
    Traffic in Arms Regulations (ITAR)^(18)^(18)18https://csrc.nist.gov/glossary/term/itar.
    In addition, we have various agreements like the Wassenaar Arrangement^(19)^(19)19https://www.federalregister.gov/documents/2022/08/15/2022-17125/implementation-of-certain-2021-wassenaar-arrangement-decisions-on-four-section-1758-technologies,
    where a number of countries got together and developed an agreement for what cryptographic
    elements can be exported and imported without any type of restrictions. This agreement
    allows publicly available cryptographic algorithms to be distributed freely. Cryptography
    provides various security capabilities for us.
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Confidentiality: To protect our intellectual property from somebody else being
    able to get hold of it.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Non-repudiation: To repudiate is to deny. For example, if we use digital signatures,
    we can provide proof that the message came from the person who signed. We can
    link the signed document to a trusted person, which gives us trust or assurance
    in the world of e-contracts and e-commerce. The signer cannot repudiate or deny
    being the source of the document.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Integrity: Hashing provides integrity, to know that a message was not changed
    either accidentally or intentionally as it was transmitted or stored. Integrity
    is built into implementation of electronic communication services today using
    such as SHA algorithms^(20)^(20)20https://csrc.nist.gov/glossary/term/sha and
    MD5^(21)^(21)21https://csrc.nist.gov/glossary/term/md5.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Proof-of-Origin: Cryptography can be used to prove where a message came from,
    the idea of Proof-of-Origin.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Authenticity: The idea is to ensure that communication is with the intended
    person. For example, if we go to a bank’s website, then we want to be sure that
    the website is truly of that bank, not that of an impostor or somebody else masquerading
    as that bank.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 11.1 Operations of Cryptography
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Cryptographic algorithms come in three basic flavors: Symmetric, Asymmetric,
    and Hash algorithms. Each of these different types of algorithms serves a different
    purpose, but all work together in a cryptography system.'
  prefs: []
  type: TYPE_NORMAL
- en: Cryptography is a key to keeping communicated information secret by converting
    it into an unreadable code that is hard to break. To encrypt or encipher is to
    take a plaintext message and convert it into something unreadable to anyone who
    does not have a key. To decrypt or decipher is the reverse step.
  prefs: []
  type: TYPE_NORMAL
- en: In Fig.  [16](#S11.F16 "Figure 16 ‣ 11.1 Operations of Cryptography ‣ 11 Deep
    Learning for Cryptographic Ransomware ‣ A Survey of Malware Detection Using Deep
    Learning"), the basic action includes plaintext being fed into a cryptosystem.
    This process is used to encrypt and decrypt a message. It contains an algorithm
    that uses a mathematical process to convert a message from plaintext to ciphertext
    and then back again. The algorithm includes a key or a cryptovariable. The variable
    is used by the algorithm during the encryption and decryption processes. Typically
    the key is a secret password, passphrase, or PIN chosen either by the person or
    by the tool that encrypts the message. This combination of the key (or a cryptovariable)
    and the algorithm in the cryptosystem produces a unique ciphertext.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f0a5f394beeaebcd3c4fa0d2ba2e24c7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: Crypto Action'
  prefs: []
  type: TYPE_NORMAL
- en: In the symmetric algorithm family, a symmetric key is one that is a shared secret
    between the sender and receiver of the information. The same key used for encryption
    is also used for decryption. It is not safe to send a copy of the key along with
    the message that it encrypts. We need to use another mode of communication to
    transmit the key. For example, Ahmed sends the symmetric key to Bryan using a
    certain secure node of communication. Once Bryan has the key, Ahmed can encrypt
    the plaintext message into ciphertext and send it over a public network to Bryan
    with confidence that it will remain encrypted until Bryan decides to decrypt with
    the received key.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple attacks, such as a man-in-middle attack, brute force attack, biclique
    attack, ciphertext only attack, known plaintext attack, chosen plaintext attack,
    chosen ciphertext attack, and chosen text attack can discover the key to find
    the plaintext. Attackers know the mathematical relationship of the keys for some
    algorithms, such as Advanced Encryption Standard (AES) [[90](#bib.bib90)], Triple
    DES [[91](#bib.bib91)], Blowfish [[92](#bib.bib92)], and Rivest-Shamir-Adleman
    (RSA) [[93](#bib.bib93)]. We perform cryptanalysts using statistical measures
    to try to get the cipher type, but a cryptanalyst can only test as many solvers
    via trial and error to test if the ciphertext was encrypted using a specific cipher.
    Machine learning can tell us what type a cipher is [[94](#bib.bib94)]. The cipher
    type detection problem is a classification problem. We can use statistical values
    as features for machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 11.2 Connection Between Deep Learning and Cryptography
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/88471287e8869fe28a07cd9ff1506f60.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17: Cryptocurrency malware detection using machine learning'
  prefs: []
  type: TYPE_NORMAL
- en: A neural network can deal with the complexity of computation applied to perform
    cryptography. Instead of giving an image to a neural network, we can give ciphertext
    to the neural network to classify the kind of algorithm that was used to obtain
    the ciphertext, as shown in Fig.  [17](#S11.F17 "Figure 17 ‣ 11.2 Connection Between
    Deep Learning and Cryptography ‣ 11 Deep Learning for Cryptographic Ransomware
    ‣ A Survey of Malware Detection Using Deep Learning"). To build a machine learning
    model, we can represent different features of the cipher, which cryptanalysts
    usually use to identify them. We need to put an intermediate layer between the
    network and ciphertext that computes the features, such as Unigram frequencies,
    Bigram frequencies, Index of Coincidence IoC, HasDoubleLetters, etc., and then
    we can train the network with millions of ciphertext and all American Cryptogram
    Association (ACA) cipher types. For example, in Fig.  [18](#S11.F18 "Figure 18
    ‣ 11.2 Connection Between Deep Learning and Cryptography ‣ 11 Deep Learning for
    Cryptographic Ransomware ‣ A Survey of Malware Detection Using Deep Learning"),
    the three blue neural networks are given the frequencies of N-grams (1-grams,
    2-grams, 3-grams, 4-grams, etc.), and the green neural network computes HasDoubleLetters.
    Then we have a hidden layer that connects the input and output layers. Finally,
    in this case the designed neural network shows 90% Seriated Playfair, and the
    green neural network shows 10% Bazeries. Baksi [[95](#bib.bib95)] designed a machine-learning
    model for differential attacks on the non-Markov 8-round GIMLI cipher and GIMLI
    hash. They applied multi-layer perceptron (MLP), Convolutional Neural Networks
    (CNN), and Long Short-Term Memory (LSTM).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/db306ed00ebaaa2e73b49263d9ead4e0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18: Detect the Cipher Type With Neural Networks'
  prefs: []
  type: TYPE_NORMAL
- en: The ransomware families to encrypt data and force the victim to make payment
    via cryptocurrency include WannaCry, Locky, Stop, CryptoJoker, CrypoWall, TeslaCrypt,
    Dharma, Locker, Cerber, and GandCrab. Recently, deep learning algorithms have
    been used for cryptography [[96](#bib.bib96)]. Ding et al. [[97](#bib.bib97)]
    proposed DeepEDN to fulfill the process of encrypting and decrypting medical images.
    Kim et al. [[98](#bib.bib98)] proposed detection of cryptographic ransomware using
    Convolutional Neural Network. Their model prevents crypto-ransomware infection
    by detecting a block cipher algorithm. Sharmeen et al. [[99](#bib.bib99)] proposed
    an approach to extract the intrinsic attack characteristics of unlabeled ransomware
    samples using a deep learning-based unsupervised learned model. Fischer et al.
    [[100](#bib.bib100)] designed a tool to detect security vulnerabilities of cryptographic
    APIs in Android by achieving an average AUC-ROC of 99.2%.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/983cbf0bd82d741aec1c32408401c4b4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19: Using explainable artificial intelligence in deep learning'
  prefs: []
  type: TYPE_NORMAL
- en: 12 Explainable Artificial Intelligence (XAI)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Explainable Artificial Intelligence (XAI) is a rapidly emerging field that focuses
    on creating transparent and interpretable models (see Fig.  [19](#S11.F19 "Figure
    19 ‣ 11.2 Connection Between Deep Learning and Cryptography ‣ 11 Deep Learning
    for Cryptographic Ransomware ‣ A Survey of Malware Detection Using Deep Learning")).
    In the context of malware detection, XAI can help security experts and analysts
    understand how a machine learning model arrived at its decisions, making it easier
    to identify and understand false positives and false negatives. By applying XAI
    techniques, such as Local Interpretable Model-Agnostic Explanations (LIME) [[101](#bib.bib101)]
    or Deep Learning Important Features (DeepLIFT) [[102](#bib.bib102)], security
    teams can gain insights into the most important features and decision-making processes
    of the model. This can help them identify areas where the model may be vulnerable
    to evasion or identify new malware strains that the model may have missed. Ultimately,
    XAI can improve the trustworthiness and reliability of machine learning models
    for malware detection, enabling more effective threat detection and response.
  prefs: []
  type: TYPE_NORMAL
- en: 'Nadeem et al. [[103](#bib.bib103)] provided a comprehensive survey and analysis
    of the current state of research on explainable machine learning (XAI) techniques
    for computer security applications. The paper highlights the challenges and opportunities
    for adopting XAI in the security domain and discusses several approaches for designing
    and evaluating explainable machine learning models. Vivek et al. [[104](#bib.bib104)]
    proposed an approach for detecting ATM fraud using explainable artificial intelligence
    (XAI) and causal inference techniques. They presented a detailed analysis of the
    proposed method and highlighted its effectiveness in improving the accuracy and
    interpretability of ATM fraud detection systems. Kinkead et al. [[105](#bib.bib105)]
    proposed an approach that uses LIME to identify important locations in the opcode
    sequence that are deemed significant by the Convolutional Neural Network (CNN).
    McLaughlin et al. [[106](#bib.bib106)] used LRP [[107](#bib.bib107)] and DeepLift
    [[102](#bib.bib102)] methods to identify the opcode sequences for most malware
    families, and they demonstrated that the CNN, while using the DAMD dataset, learned
    patterns from the underlying op-code representation. Hooker et al. [[108](#bib.bib108)]
    proposed a method to remove relevant features detected by an XAI approach and
    verify the accuracy degradation. Lin et al. [[109](#bib.bib109)] presented seven
    different XAI methods and automated the evaluation of the correctness of explanation
    techniques. The first four XAI methods are white-box approaches to determine the
    importance of input features: Backpropagation (BP), Guided Backpropagation (GBP),
    Gradient-weighted Class Activation Mapping (GCAM), and Guided GCAM (GGCAM). The
    last three are black-box approaches that observe an essential feature in the output
    probability using perturbed samples of the input: Occlusion Sensitivity (OCC),
    Feature Ablation (FA), and Local Interpretable Model-Agnostic Explanations (LIME).'
  prefs: []
  type: TYPE_NORMAL
- en: Guo et al. [[110](#bib.bib110)] proposed an approach called Explaining Deep
    Learning based Security Applications (LEMNA) for security applications, which
    generates interpretable features to explain how input samples are classified.
    Kuppa and Le-Khac [[111](#bib.bib111)] presented a comprehensive analysis of the
    vulnerability of XAI methods to adversarial attacks in the context of cybersecurity,
    discussing potential risks associated with deploying XAI models in real-world
    applications, and proposing a framework for designing robust and secure XAI systems.
    Rao and Mane [[112](#bib.bib112)] proposed an approach to protect and analyze
    systems against the alarm-flooding problem using the NSL-KDD dataset. They included
    a Security Information and Event Management (SIEM) system to generate a zero-shot
    method for detecting alarm labels specific to adversarial attacks. Although explainable
    artificial intelligence (XAI) has gained significant attention, its effectiveness
    in malware detection still requires further investigation to fully comprehend
    its performance.
  prefs: []
  type: TYPE_NORMAL
- en: 13 Adversarial Attack on Deep Neural Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adversarial examples refer to maliciously crafted inputs to machine learning
    models designed to deceive the model into making incorrect predictions. Deep detection
    in this context refers to the use of deep learning models for detecting and classifying
    objects or patterns in the input data. Adversarial examples can be specifically
    crafted to evade deep detection models and cause them to misclassify or miss the
    target objects or patterns. Therefore, adversarial examples can be seen as a type
    of attack on deep detection models. Adversarial examples can be generated using
    a variety of techniques, including optimization-based approaches and perturbation-based
    approaches, and can be used for various objectives, including evasion attacks
    and poisoning attacks. Zhong et al. [[113](#bib.bib113)] proposed a novel adversarial
    malware example generation method called Malfox, which uses conditional generative
    adversarial networks (conv-GANs) to generate camouflaged adversarial examples
    against black-box detectors. The presented method was evaluated on two real-world
    malware detection systems, and the results showed that Malfox achieved high attack
    success rates while maintaining low detection rates. Zhao et al. [[114](#bib.bib114)]
    proposed a new method called SAGE for steering the adversarial generation of examples
    with accelerations. The technique combines the advantages of gradient-based and
    gradient-free methods to generate more effective and efficient adversarial examples.
  prefs: []
  type: TYPE_NORMAL
- en: The development of defense mechanisms against adversarial attacks is a computationally
    expensive process, which can potentially affect the performance of the deep learning
    model. In addition, adversarial examples can impact the generalization ability
    of deep learning models, resulting in poor performance on new and unseen data.
    Moreover, generating adversarial examples can be computationally intensive, especially
    for large datasets and complex models, which can hinder the practical deployment
    of deep learning models in real-world applications. Thus, further research is
    required to improve the efficiency and effectiveness of defense mechanisms, as
    well as the generalization ability and robustness of deep learning models to adversarial
    attacks.
  prefs: []
  type: TYPE_NORMAL
- en: Hu and Tan [[115](#bib.bib115)] proposed a method to generate adversarial malware
    examples using Generative Adversarial Networks (GANs) for black-box attacks. Their
    results show that the generated adversarial malware samples can evade detection
    by existing machine learning models while maintaining high similarity to the original
    malware. Ling et al. [[116](#bib.bib116)] conducted a survey of the state-of-the-art
    in adversarial attacks against Windows PE malware detection, covering various
    types of attacks and defense mechanisms. The authors also provided insights on
    potential future research directions in this area. Xu et al. [[117](#bib.bib117)]
    proposed a semi-black-box adversarial sample attack framework called Ofei that
    can generate adversarial samples against Android apps deployed on a DLAAS platform.
    The framework utilizes a multi-objective optimization algorithm to generate robust
    and stealthy adversarial samples. Qiao et al. [[118](#bib.bib118)] proposed an
    adversarial detection method for ELF malware using model interpretation and show
    that their method can effectively identify adversarial ELF malware with high accuracy.
    The proposed approach combines random forests and LIME to identify the most important
    features and thus improve the interpretability and robustness of the model. Meenakshi
    and Maragatham [[119](#bib.bib119)] proposed a defensive technique using Curvelet
    transform to recognize adversarial iris images, optimizing the image classification
    accuracy. The designed method was shown to be effective against several existing
    adversarial attacks on iris recognition systems. Pintor et al. [[120](#bib.bib120)]
    introduced a method for debugging and improving the optimization of adversarial
    examples by identifying and analyzing the indicators of attack failure. The proposed
    method can help to improve the robustness of deep learning models against adversarial
    attacks.
  prefs: []
  type: TYPE_NORMAL
- en: 14 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Machine learning has started to gain the attention of malware detection researchers,
    notably in malware image classification and cipher cryptanalysis. However, more
    experimentation is required to understand the capabilities and limitations of
    deep learning when used to detect/classify malware. Deep learning can reduce the
    need for static and dynamic analysis and discover suspicious patterns. In the
    future, researchers may consider developing more accurate, robust, scalable, and
    efficient deep learning models for malware detection systems for various operating
    systems. Finally, multi-task learning and transfer learning can provide valuable
    results in classifying all types of malware. Furthermore, we show that the significant
    challenges of deep learning approaches that need to be considered are hyperparameters
    optimization, fine-tuning, and size and quality of datasets when features are
    overweighted or overrepresented. We also illustrate the opportunities and challenges
    of XAI in deep learning as well as future research directions in the context of
    malware detection. Finally, we presented the idea of adversarial attacks on deep
    neural networks by introducing small, carefully crafted perturbations to input
    data in order to cause misclassification or reduce model performance.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Damodaran et al. [2017] A. Damodaran, F. Di Troia, C. A. Visaggio, T. H. Austin,
    M. Stamp, A comparison of static, dynamic, and hybrid analysis for malware detection,
    Journal of Computer Virology and Hacking Techniques 13 (2017) 1–12.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Naik et al. [2021] N. Naik, P. Jenkins, N. Savage, L. Yang, T. Boongoen, N. Iam-On,
    Fuzzy-import hashing: A static analysis technique for malware detection, Forensic
    Science International: Digital Investigation 37 (2021) 301139.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mohamad et al. [2021] Mohamad, J. Arif, M. F. Ab Razak, S. Awang, S. R. Tuan Mat,
    N. S. N. Ismail, A. Firdaus, A static analysis approach for android permission-based
    malware detection systems, PloS one 16 (2021) e0257968.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. [2018] T. Kim, S. C. Suh, H. Kim, J. Kim, J. Kim, An encoding technique
    for cnn-based network anomaly detection, in: 2018 IEEE International Conference
    on Big Data (Big Data), 2018, pp. 2960–2965\. doi:[10.1109/BigData.2018.8622568](https:/doi.org/10.1109/BigData.2018.8622568).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bai et al. [2021] Y. Bai, Z. Xing, D. Ma, X. Li, Z. Feng, Comparative analysis
    of feature representations and machine learning methods in android family classification,
    Computer Networks 184 (2021) 107639.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chaulagain et al. [2020] D. Chaulagain, P. Poudel, P. Pathak, S. Roy, D. Caragea,
    G. Liu, X. Ou, Hybrid analysis of android apps for security vetting using deep
    learning, in: 2020 IEEE Conference on Communications and Network Security (CNS),
    2020, pp. 1–9\. doi:[10.1109/CNS48642.2020.9162341](https:/doi.org/10.1109/CNS48642.2020.9162341).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yuan et al. [2020] B. Yuan, J. Wang, D. Liu, W. Guo, P. Wu, X. Bao, Byte-level
    malware classification based on markov images and deep learning, Computers & Security
    92 (2020) 101740.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mohammed et al. [2021] T. M. Mohammed, L. Nataraj, S. Chikkagoudar, S. Chandrasekaran,
    B. Manjunath, Malware detection using frequency domain-based image visualization
    and deep learning, arXiv preprint arXiv:2101.10578 (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Khayam [2003] S. A. Khayam, The discrete cosine transform (dct): theory and
    application, Michigan State University 114 (2003) 1–31.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Euh et al. [2020] S. Euh, H. Lee, D. Kim, D. Hwang, Comparative analysis of
    low-dimensional features and tree-based ensembles for malware detection systems,
    IEEE Access 8 (2020) 76796–76808.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ni et al. [2018] S. Ni, Q. Qian, R. Zhang, Malware identification using visualization
    images and deep learning, Computers & Security 77 (2018) 871–885.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Charikar [2002] M. S. Charikar, Similarity estimation techniques from rounding
    algorithms, in: Proceedings of the thiry-fourth annual ACM symposium on Theory
    of computing, 2002, pp. 380–388.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nataraj et al. [2011] L. Nataraj, S. Karthikeyan, G. Jacob, B. S. Manjunath,
    Malware images: visualization and automatic classification, in: Proceedings of
    the 8th international symposium on visualization for cyber security, 2011, pp.
    1–7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Narayanan and Davuluru [2020] B. N. Narayanan, V. S. P. Davuluru, Ensemble malware
    classification system using deep neural networks, Electronics 9 (2020) 721.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. [2021] J. Zhu, J. Jang-Jaccard, A. Singh, P. A. Watters, S. Camtepe,
    Task-aware meta learning-based siamese neural network for classifying obfuscated
    malware, arXiv preprint arXiv:2110.13409 (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chauhan et al. [2022] D. Chauhan, H. Singh, H. Hooda, R. Gupta, Classification
    of malware using visualization techniques, in: International Conference on Innovative
    Computing and Communications, Springer, 2022, pp. 739–750.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Darem et al. [2021] A. Darem, J. Abawajy, A. Makkar, A. Alhashmi, S. Alanazi,
    Visualization and deep-learning-based malware variant detection using opcode-level
    features, Future Generation Computer Systems 125 (2021) 314–323.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asam et al. [2021] M. Asam, S. J. Hussain, M. Mohatram, S. H. Khan, T. Jamal,
    A. Zafar, A. Khan, M. U. Ali, U. Zahoora, Detection of exceptional malware variants
    using deep boosted feature spaces and machine learning, Applied Sciences 11 (2021)
    10464.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xiao et al. [2021] M. Xiao, C. Guo, G. Shen, Y. Cui, C. Jiang, Image-based malware
    classification using section distribution information, Computers & Security 110
    (2021) 102420.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Çayır et al. [2021] A. Çayır, U. Ünal, H. Dağ, Random capsnet forest model for
    imbalanced malware type classification task, Computers & Security 102 (2021) 102133.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Go et al. [2020] J. H. Go, T. Jan, M. Mohanty, O. P. Patel, D. Puthal, M. Prasad,
    Visualization approach for malware classification with resnext, in: 2020 IEEE
    Congress on Evolutionary Computation (CEC), 2020, pp. 1–7\. doi:[10.1109/CEC48606.2020.9185490](https:/doi.org/10.1109/CEC48606.2020.9185490).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bensaoud et al. [2020] A. Bensaoud, N. Abudawaood, J. Kalita, Classifying malware
    images with convolutional neural network models, International Journal of Network
    Security 22 (2020) 1022–1031.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: El-Shafai et al. [2021] W. El-Shafai, I. Almomani, A. AlKhayer, Visualized malware
    multi-classification framework using fine-tuned cnn-based transfer learning models,
    Applied Sciences 11 (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hemalatha et al. [2021] J. Hemalatha, S. A. Roseline, S. Geetha, S. Kadry, R. Damaševičius,
    An efficient densenet-based deep learning model for malware detection, Entropy
    23 (2021) 344.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lo et al. [2019] W. W. Lo, X. Yang, Y. Wang, An xception convolutional neural
    network for malware classification with transfer learning, in: 2019 10th IFIP
    International Conference on New Technologies, Mobility and Security (NTMS), 2019,
    pp. 1–5\. doi:[10.1109/NTMS.2019.8763852](https:/doi.org/10.1109/NTMS.2019.8763852).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Barath et al. [2016] N. Barath, D. Ouboti, M. Temesguen, Pattern recognition
    algorithms for malware classification, in: proceeding of 2016 IEEE Conference
    of Aerospace and Electronics, 2016, pp. 338–342.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Oliva and Torralba [2001] A. Oliva, A. Torralba, Modeling the shape of the
    scene: A holistic representation of the spatial envelope, International journal
    of computer vision 42 (2001) 145–175.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu [1962] M.-K. Hu, Visual pattern recognition by moment invariants, IRE transactions
    on information theory 8 (1962) 179–187.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Swain and Ballard [1991] M. J. Swain, D. H. Ballard, Color indexing, International
    journal of computer vision 7 (1991) 11–32.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. [2004] W.-C. Lin, J. Hays, C. Wu, V. Kwatra, Y. Liu, A comparison
    study of four texture synthesis algorithms on regular and near-regular textures,
    Tech. Rep. (2004).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kancherla et al. [2016] K. Kancherla, J. Donahue, S. Mukkamala, Packer identification
    using byte plot and markov plot, Journal of Computer Virology and Hacking Techniques
    12 (2016) 101–111.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Herault and Jutten [1986] J. Herault, C. Jutten, Space or time adaptive signal
    processing by neural network models, in: AIP conference proceedings, American
    Institute of Physics, 1986, pp. 206–211.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fan et al. [2011] Z. Fan, Y. Xu, D. Zhang, Local linear discriminant analysis
    framework using sample neighbors, IEEE Transactions on Neural Networks 22 (2011)
    1119–1132.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rublee et al. [2011] E. Rublee, V. Rabaud, K. Konolige, G. Bradski, Orb: An
    efficient alternative to sift or surf, in: 2011 International Conference on Computer
    Vision, 2011, pp. 2564–2571\. doi:[10.1109/ICCV.2011.6126544](https:/doi.org/10.1109/ICCV.2011.6126544).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bay et al. [2006] H. Bay, T. Tuytelaars, L. Van Gool, Surf: Speeded up robust
    features, in: European conference on computer vision, Springer, 2006, pp. 404–417.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lowe [1999] D. G. Lowe, Object recognition from local scale-invariant features,
    in: Proceedings of the seventh IEEE international conference on computer vision,
    volume 2, Ieee, 1999, pp. 1150–1157.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ojala et al. [1996] T. Ojala, M. Pietikäinen, D. Harwood, A comparative study
    of texture measures with classification based on featured distributions, Pattern
    recognition 29 (1996) 51–59.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alcantarilla et al. [2012] P. F. Alcantarilla, A. Bartoli, A. J. Davison, Kaze
    features, in: European conference on computer vision, Springer, 2012, pp. 214–227.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Azad et al. [2022] M. A. Azad, F. Riaz, A. Aftab, S. K. J. Rizvi, J. Arshad,
    H. F. Atlam, Deepsel: A novel feature selection for early identification of malware
    in mobile applications, Future Generation Computer Systems 129 (2022) 54–63.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tobiyama et al. [2016] S. Tobiyama, Y. Yamaguchi, H. Shimada, T. Ikuse, T. Yagi,
    Malware detection with deep neural network using process behavior, in: 2016 IEEE
    40th Annual Computer Software and Applications Conference (COMPSAC), volume 2,
    2016, pp. 577–582\. doi:[10.1109/COMPSAC.2016.151](https:/doi.org/10.1109/COMPSAC.2016.151).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ye and Dai [2021] R. Ye, Q. Dai, Implementing transfer learning across different
    datasets for time series forecasting, Pattern Recognition 109 (2021) 107617.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Russakovsky et al. [2015] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh,
    S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al., Imagenet large
    scale visual recognition challenge, International journal of computer vision 115
    (2015) 211–252.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vasan et al. [2020] D. Vasan, M. Alazab, S. Wassan, H. Naeem, B. Safaei, Q. Zheng,
    Imcfn: Image-based malware classification using fine-tuned convolutional neural
    network architecture, Computer Networks 171 (2020) 107138.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rezende et al. [2017] E. Rezende, G. Ruppert, T. Carvalho, F. Ramos, P. De Geus,
    Malicious software classification using transfer learning of resnet-50 deep neural
    network, in: 2017 16th IEEE International Conference on Machine Learning and Applications
    (ICMLA), IEEE, 2017, pp. 1011–1014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bhodia et al. [2019] N. Bhodia, P. Prajapati, F. Di Troia, M. Stamp, Transfer
    learning for image-based malware classification, arXiv preprint arXiv:1903.11551
    (2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qiao et al. [2020] Y. Qiao, B. Zhang, W. Zhang, Malware classification method
    based on word vector of bytes and multilayer perception, in: ICC 2020-2020 IEEE
    International Conference on Communications (ICC), IEEE, 2020, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonyan and Zisserman [2014] K. Simonyan, A. Zisserman, Very deep convolutional
    networks for large-scale image recognition, arXiv preprint arXiv:1409.1556 (2014).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ketkar and Santana [2017] N. Ketkar, E. Santana, Deep learning with Python,
    volume 1, Springer, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abadi et al. [2016] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean,
    M. Devin, S. Ghemawat, G. Irving, M. Isard, et al., Tensorflow: A system for large-scale
    machine learning, in: 12th $\displaystyle\{$USENIX$\displaystyle\}$ symposium
    on operating systems design and implementation ($\displaystyle\{$OSDI$\displaystyle\}$
    16), 2016, pp. 265–283.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sudhakar and Kumar [2021] Sudhakar, S. Kumar, Mcft-cnn: Malware classification
    with fine-tune convolution neural networks using traditional and transfer learning
    in internet of things, Future Generation Computer Systems 125 (2021) 334–351.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'He et al. [2016] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for
    image recognition, in: Proceedings of the IEEE conference on computer vision and
    pattern recognition, 2016, pp. 770–778.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Go et al. [2020] J. H. Go, T. Jan, M. Mohanty, O. P. Patel, D. Puthal, M. Prasad,
    Visualization approach for malware classification with resnext, in: 2020 IEEE
    Congress on Evolutionary Computation (CEC), 2020, pp. 1–7\. doi:[10.1109/CEC48606.2020.9185490](https:/doi.org/10.1109/CEC48606.2020.9185490).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Von Luxburg et al. [2017] U. Von Luxburg, I. Guyon, S. Bengio, H. Wallach,
    R. Fergus, S. Vishwanathan, R. Garnett, Advances in neural information processing
    systems 30, in: 31st annual conference on neural information processing systems
    (NIPS 2017), Long Beach, California, USA, 2017, pp. 4–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Szegedy et al. [2016] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna,
    Rethinking the inception architecture for computer vision, in: Proceedings of
    the IEEE conference on computer vision and pattern recognition, 2016, pp. 2818–2826.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Khan et al. [2019] R. U. Khan, X. Zhang, R. Kumar, Analysis of resnet and googlenet
    models for malware detection, Journal of Computer Virology and Hacking Techniques
    15 (2019) 29–37.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Szegedy et al. [2015] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov,
    D. Erhan, V. Vanhoucke, A. Rabinovich, Going deeper with convolutions, in: Proceedings
    of the IEEE conference on computer vision and pattern recognition, 2015, pp. 1–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tan and Le [2019] M. Tan, Q. Le, Efficientnet: Rethinking model scaling for
    convolutional neural networks, in: International Conference on Machine Learning,
    PMLR, 2019, pp. 6105–6114.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy et al. [2017] C. Szegedy, S. Ioffe, V. Vanhoucke, A. Alemi, Inception-v4,
    inception-resnet and the impact of residual connections on learning, Proceedings
    of the AAAI Conference on Artificial Intelligence 31 (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chollet [2017] F. Chollet, Xception: Deep learning with depthwise separable
    convolutions, in: Proceedings of the IEEE conference on computer vision and pattern
    recognition, 2017, pp. 1251–1258.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sabour et al. [2017] S. Sabour, N. Frosst, G. E. Hinton, Dynamic routing between
    capsules, arXiv preprint arXiv:1710.09829 (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gibert et al. [2020] D. Gibert, C. Mateu, J. Planes, The rise of machine learning
    for detection and classification of malware: Research developments, trends and
    challenges, Journal of Network and Computer Applications 153 (2020) 102526.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kocaman et al. [2021] V. Kocaman, O. M. Shir, T. Bäck, Improving model accuracy
    for imbalanced image classification tasks by adding a final batch normalization
    layer: An empirical study, in: 2020 25th International Conference on Pattern Recognition
    (ICPR), 2021, pp. 10404–10411\. doi:[10.1109/ICPR48806.2021.9412907](https:/doi.org/10.1109/ICPR48806.2021.9412907).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alaraimi et al. [2021] S. Alaraimi, K. E. Okedu, H. Tianfield, R. Holden, O. Uthmani,
    Transfer learning networks with skip connections for classification of brain tumors,
    International Journal of Imaging Systems and Technology (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Eum et al. [2018] S. Eum, H. Lee, H. Kwon, Going deeper with cnn in malicious
    crowd event classification, in: Signal Processing, Sensor/Information Fusion,
    and Target Recognition XXVII, volume 10646, International Society for Optics and
    Photonics, 2018, p. 1064616.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jurafsky and Martin [2021] D. Jurafsky, J. H. Martin, Speech and Language Processing,
    3rd ed., Prentice Hall, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mikolov et al. [2013] T. Mikolov, K. Chen, G. Corrado, J. Dean, Efficient estimation
    of word representations in vector space, arXiv preprint arXiv:1301.3781 (2013).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pagliardini et al. [2017] M. Pagliardini, P. Gupta, M. Jaggi, Unsupervised learning
    of sentence embeddings using compositional n-gram features, arXiv preprint arXiv:1703.02507
    (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bensaoud and Kalita [2024] A. Bensaoud, J. Kalita, Cnn-lstm and transfer learning
    models for malware classification based on opcodes and api calls, Knowledge-Based
    Systems (2024) 111543.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mimura and Ito [2021] M. Mimura, R. Ito, Applying nlp techniques to malware
    detection in a practical environment, International Journal of Information Security
    (2021) 1–13.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luong et al. [2015] M.-T. Luong, H. Pham, C. D. Manning, Effective approaches
    to attention-based neural machine translation, arXiv preprint arXiv:1508.04025
    (2015).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu et al. [2021] Z. Lu, X. Li, Y. Liu, C. Zhou, J. Cui, B. Wang, M. Zhang, J. Su,
    Exploring multi-stage information interactions for multi-source neural machine
    translation, IEEE/ACM Transactions on Audio, Speech, and Language Processing (2021)
    1–1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. [2021] Y. Gao, H. Gong, X. Ding, B. Guo, Image recognition based
    on mixed attention mechanism in smart home appliances, in: 2021 IEEE 5th Advanced
    Information Technology, Electronic and Automation Control Conference (IAEAC),
    volume 5, 2021, pp. 1501–1505\. doi:[10.1109/IAEAC50856.2021.9391092](https:/doi.org/10.1109/IAEAC50856.2021.9391092).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AlMazrouei et al. [2021] R. Z. AlMazrouei, J. Nelci, S. A. Salloum, K. Shaalan,
    Feasibility of using attention mechanism in abstractive summarization, in: International
    Conference on Emerging Technologies and Intelligent Systems, Springer, 2021, pp.
    13–20.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Niu et al. [2021] Z. Niu, G. Zhong, H. Yu, A review on the attention mechanism
    of deep learning, Neurocomputing 452 (2021) 48–62.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren et al. [2021] S. Ren, L. Zhou, S. Liu, F. Wei, M. Zhou, S. Ma, Semface:
    Pre-training encoder and decoder with a semantic interface for neural machine
    translation, in: Proceedings of the 59th Annual Meeting of the Association for
    Computational Linguistics and the 11th International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers), 2021, pp. 4518–4527.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bahdanau et al. [2014] D. Bahdanau, K. Cho, Y. Bengio, Neural machine translation
    by jointly learning to align and translate, arXiv preprint arXiv:1409.0473 (2014).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vaswani et al. [2017] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones,
    A. N. Gomez, Ł. Kaiser, I. Polosukhin, Attention is all you need, in: Advances
    in neural information processing systems, 2017, pp. 5998–6008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Or-Meir et al. [2021] O. Or-Meir, A. Cohen, Y. Elovici, L. Rokach, N. Nissim,
    Pay attention: Improving classification of pe malware using attention mechanisms
    based on system call analysis, in: 2021 International Joint Conference on Neural
    Networks (IJCNN), 2021, pp. 1–8\. doi:[10.1109/IJCNN52387.2021.9533481](https:/doi.org/10.1109/IJCNN52387.2021.9533481).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yakura et al. [2019] H. Yakura, S. Shinozaki, R. Nishimura, Y. Oyama, J. Sakuma,
    Neural malware analysis with attention mechanism, Computers & Security 87 (2019)
    101592.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mimura and Ohminami [2020] M. Mimura, T. Ohminami, Using lsi to detect unknown
    malicious vba macros, Journal of Information Processing 28 (2020) 493–501.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ma et al. [2019] X. Ma, S. Guo, H. Li, Z. Pan, J. Qiu, Y. Ding, F. Chen, How
    to make attention mechanisms more practical in malware classification, IEEE Access
    7 (2019) 155270–155280.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Girinoto et al. [2020] Girinoto, H. Setiawan, P. A. W. Putro, Y. R. Pramadi,
    Comparison of lstm architecture for malware classification, in: 2020 International
    Conference on Informatics, Multimedia, Cyber and Information System (ICIMCIS),
    2020, pp. 93–97\. doi:[10.1109/ICIMCIS51567.2020.9354301](https:/doi.org/10.1109/ICIMCIS51567.2020.9354301).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Agrawal et al. [2019] R. Agrawal, J. W. Stokes, K. Selvaraj, M. Marinescu,
    Attention in recurrent neural networks for ransomware detection, in: ICASSP 2019
    - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing
    (ICASSP), 2019, pp. 3222–3226\. doi:[10.1109/ICASSP.2019.8682899](https:/doi.org/10.1109/ICASSP.2019.8682899).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. [2022] J. Kim, Y. Ban, E. Ko, H. Cho, J. H. Yi, Mapas: a practical
    deep learning-based android malware detection system, International Journal of
    Information Security (2022) 1–14.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Onwuzurike et al. [2019] L. Onwuzurike, E. Mariconti, P. Andriotis, E. D. Cristofaro,
    G. Ross, G. Stringhini, Mamadroid: Detecting android malware by building markov
    chains of behavioral models (extended version), ACM Transactions on Privacy and
    Security (TOPS) 22 (2019) 1–34.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim and Cho [2022] J.-Y. Kim, S.-B. Cho, Obfuscated malware detection using
    deep generative model based on global/local features, Computers & Security 112
    (2022) 102501.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Olani et al. [2022] G. Olani, C.-F. Wu, Y.-H. Chang, W.-K. Shih, Deepware:
    Imaging performance counters with deep learning to detect ransomware, IEEE Transactions
    on Computers (2022) 1–1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lian et al. [2022] W. Lian, G. Nie, Y. Kang, B. Jia, Y. Zhang, Cryptomining
    malware detection based on edge computing-oriented multi-modal features deep learning,
    China Communications 19 (2022) 174–185.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bensaoud and Kalita [2022] A. Bensaoud, J. Kalita, Deep multi-task learning
    for malware image classification, Journal of Information Security and Applications
    64 (2022) 103057.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heron [2009] S. Heron, Advanced encryption standard (aes), Network Security
    2009 (2009) 8–12.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sasi and Sivanandam [2015] S. B. Sasi, N. Sivanandam, A survey on cryptography
    using optimization algorithms in wsns, Indian Journal of Science and Technology
    8 (2015) 216.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mahendra and Prabha [2022] M. Mahendra, P. S. Prabha, Classification of security
    levels to enhance the data sharing transmissions using blowfish algorithm in comparison
    with data encryption standard, in: 2022 International Conference on Sustainable
    Computing and Data Communication Systems (ICSCDS), IEEE, 2022, pp. 1154–1160.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kota and Aissi [2002] C. M. Kota, C. Aissi, Implementation of the rsa algorithm
    and its cryptanalysis, in: proceedings of the 2002 ASEE Gulf-Southwest Annual
    Conference, 2002, pp. 20–22.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee et al. [2021] T. R. Lee, J. S. Teh, N. Jamil, J. L. S. Yan, J. Chen, Lightweight
    block cipher security evaluation based on machine learning classifiers and active
    s-boxes, IEEE Access 9 (2021) 134052–134064.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Baksi [2022] A. Baksi, Machine learning-assisted differential distinguishers
    for lightweight ciphers, in: Classical and Physical Security of Symmetric Key
    Cryptographic Algorithms, Springer, 2022, pp. 141–162.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kok et al. [2020] S. Kok, A. Azween, N. Jhanjhi, Evaluation metric for crypto-ransomware
    detection using machine learning, Journal of Information Security and Applications
    55 (2020) 102646.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ding et al. [2020] Y. Ding, G. Wu, D. Chen, N. Zhang, L. Gong, M. Cao, Z. Qin,
    Deepedn: a deep-learning-based image encryption and decryption network for internet
    of medical things, IEEE Internet of Things Journal 8 (2020) 1504–1518.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. [2021] H. Kim, J. Park, H. Kwon, K. Jang, H. Seo, Convolutional neural
    network-based cryptography ransomware detection for low-end embedded processors,
    Mathematics 9 (2021) 705.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharmeen et al. [2020] S. Sharmeen, Y. A. Ahmed, S. Huda, B. Ş. Koçer, M. M.
    Hassan, Avoiding future digital extortion through robust protection against ransomware
    threats using deep learning based adaptive approaches, IEEE Access 8 (2020) 24522–24534.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fischer et al. [2019] F. Fischer, H. Xiao, C.-Y. Kao, Y. Stachelscheid, B. Johnson,
    D. Razar, P. Fawkesley, N. Buckley, K. Böttinger, P. Muntean, et al., Stack overflow
    considered helpful! deep learning security nudges towards stronger cryptography,
    in: 28th $\displaystyle\{$USENIX$\displaystyle\}$ Security Symposium ($\displaystyle\{$USENIX$\displaystyle\}$
    Security 19), 2019, pp. 339–356.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ribeiro et al. [2016] M. T. Ribeiro, S. Singh, C. Guestrin, " why should i
    trust you?" explaining the predictions of any classifier, in: Proceedings of the
    22nd ACM SIGKDD international conference on knowledge discovery and data mining,
    2016, pp. 1135–1144.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shrikumar et al. [2017] A. Shrikumar, P. Greenside, A. Kundaje, Learning important
    features through propagating activation differences, in: International conference
    on machine learning, PMLR, 2017, pp. 3145–3153.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nadeem et al. [2022] A. Nadeem, D. Vos, C. Cao, L. Pajola, S. Dieck, R. Baumgartner,
    S. Verwer, Sok: Explainable machine learning for computer security applications,
    arXiv preprint arXiv:2208.10605 (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vivek et al. [2022] Y. Vivek, V. Ravi, A. A. Mane, L. R. Naidu, Explainable
    artificial intelligence and causal inference based atm fraud detection, arXiv
    preprint arXiv:2211.10595 (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kinkead et al. [2021] M. Kinkead, S. Millar, N. McLaughlin, P. O’Kane, Towards
    explainable cnns for android malware detection, Procedia Computer Science 184
    (2021) 959–965.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'McLaughlin et al. [2017] N. McLaughlin, J. Martinez del Rincon, B. Kang, S. Yerima,
    P. Miller, S. Sezer, Y. Safaei, E. Trickel, Z. Zhao, A. Doupé, et al., Deep android
    malware detection, in: Proceedings of the seventh ACM on conference on data and
    application security and privacy, 2017, pp. 301–308.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bach et al. [2015] S. Bach, A. Binder, G. Montavon, F. Klauschen, K.-R. Müller,
    W. Samek, On pixel-wise explanations for non-linear classifier decisions by layer-wise
    relevance propagation, PloS one 10 (2015) e0130140.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hooker et al. [2019] S. Hooker, D. Erhan, P.-J. Kindermans, B. Kim, A benchmark
    for interpretability methods in deep neural networks, Advances in neural information
    processing systems 32 (2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. [2021] Y.-S. Lin, W.-C. Lee, Z. B. Celik, What do you see? evaluation
    of explainable artificial intelligence (xai) interpretability through neural backdoors,
    in: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data
    Mining, 2021, pp. 1027–1035.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guo et al. [2018] W. Guo, D. Mu, J. Xu, P. Su, G. Wang, X. Xing, Lemna: Explaining
    deep learning based security applications, in: proceedings of the 2018 ACM SIGSAC
    conference on computer and communications security, 2018, pp. 364–379.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kuppa and Le-Khac [2020] A. Kuppa, N.-A. Le-Khac, Black box attacks on explainable
    artificial intelligence (xai) methods in cyber security, in: 2020 International
    Joint Conference on Neural Networks (IJCNN), IEEE, 2020, pp. 1–8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rao and Mane [2021] D. Rao, S. Mane, Zero-shot learning approach to adaptive
    cybersecurity using explainable ai, arXiv preprint arXiv:2106.14647 (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhong et al. [2023] F. Zhong, X. Cheng, D. Yu, B. Gong, S. Song, J. Yu, Malfox:
    camouflaged adversarial malware example generation based on conv-gans against
    black-box detectors, IEEE Transactions on Computers (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. [2023] Z. Zhao, Z. Li, F. Zhang, Z. Yang, S. Luo, T. Li, R. Zhang,
    K. Ren, Sage: Steering the adversarial generation of examples with accelerations,
    IEEE Transactions on Information Forensics and Security 18 (2023) 789–803.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu and Tan [2023] W. Hu, Y. Tan, Generating adversarial malware examples for
    black-box attacks based on gan, in: Data Mining and Big Data: 7th International
    Conference, DMBD 2022, Beijing, China, November 21–24, 2022, Proceedings, Part
    II, Springer, 2023, pp. 409–423.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ling et al. [2023] X. Ling, L. Wu, J. Zhang, Z. Qu, W. Deng, X. Chen, Y. Qian,
    C. Wu, S. Ji, T. Luo, et al., Adversarial attacks against windows pe malware detection:
    A survey of the state-of-the-art, Computers & Security (2023) 103134.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. [2023] G. Xu, G. Xin, L. Jiao, J. Liu, S. Liu, M. Feng, X. Zheng,
    Ofei: A semi-black-box android adversarial sample attack framework against dlaas,
    IEEE Transactions on Computers (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qiao et al. [2022] Y. Qiao, W. Zhang, Z. Tian, L. T. Yang, Y. Liu, M. Alazab,
    Adversarial elf malware detection method using model interpretation, IEEE Transactions
    on Industrial Informatics 19 (2022) 605–615.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meenakshi and Maragatham [2023] K. Meenakshi, G. Maragatham, An optimised defensive
    technique to recognize adversarial iris images using curvelet transform, Intelligent
    Automation & Soft Computing 35 (2023) 627–643.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pintor et al. [2022] M. Pintor, L. Demetrio, A. Sotgiu, A. Demontis, N. Carlini,
    B. Biggio, F. Roli, Indicators of attack failure: Debugging and improving optimization
    of adversarial examples, Advances in Neural Information Processing Systems 35
    (2022) 23063–23076.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '15 Appendix A: File Types'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: . tbk, .jpeg , . brd, .dot , .jpg , .rtf , .doc , .js , .sch , .3dm , .mp3 ,
    .sh , .3ds , .key , .sldm , .3g2 , .lay , .sldm , .mkv , .std , .asp , .mml ,
    .sti , .avi , .mov , .stw , .backup , . jsp, .suo , .bak , .mp4 , .svg , .bat
    , .mpeg , .swf , .bmp , .mpg , .sxc , .rb , .msg , .sxd , .bz2 , .myd , .sxi ,
    .c , .myi , .sxm , .cgm , .nef , .sxw , .class , .odb , .tar , .cmd , .odg , .123
    , . onetoc2, .odp , .tgz , .crt , .ods , .tif , .3gp , .lay6 , .sldx , .7z , .ldf
    , .slk , .vsd , .m3u , .sln , .aes , .m4u , .snt , .ai , .max , .sql , . ppam,
    .mdb , .sqlite3 , .asc , .mdf , .sqlitedb , .asf , .mid , .stc , .asm , .cs ,
    .odt , .tiff , .csr , .cpp , .txt , .csv , .pas , .vmx , .docb , .pdf , .vob ,
    .docm , .pem , . accdb, .docx , .pfx , .vsdx , .602 , . p12, .wav , .dotm , .pl
    , .wb2 , .dotx , .png , .wk1 , .dwg , .pot , . xltx, .edb , .potm , .wma , .eml
    , .potx , .wmv , .fla , .ARC , .xlc , .flv , .pps , .xlm , .frm , .ppsm , .xls
    , .gif , .ppsx , .xlsb , .gpg , .ppt , .xlsm , .gz , .pptm , .xlsx , .h , .pptx
    , .xlt , .hwp , .ps1 , .xltm , .ibd , .psd , .wks , .iso , .pst , .xlw , .jar
    , .rar , . djvu, .java , .raw., .ost , .uop , .db , .otg , .uot , .dbf , .otp
    , .vb , .dch , .ots , .vbs , .der” , .ott , .vcd , .dif , .php, .vdi , .dip ,
    .PAQ , .vmdk , .zip
  prefs: []
  type: TYPE_NORMAL
- en: '16 Appendix B: The Accuracy and Loss Curves Plots'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a59281e93bc012eabacb7e4ba2476458.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20: Training and testing for accuracy and loss of EfficientnetB1'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/596de52c26921af8a36954f44f147260.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21: Training and testing for accuracy and loss of EfficientnetB2'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a5011f866cb7e20c068e2fff6f1eb715.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22: Training and testing for accuracy and loss of EfficientnetB3'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/69c852fcddf5582b8a3ebeabdaa5181d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 23: Training and testing for accuracy and loss of EfficientnetB4'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3e6ce93266aaaa636b72b51c790fcb20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 24: Training and testing for accuracy and loss of EfficientnetB5'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bfd63b8053dae9090a44005fb0fadc3f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 25: Training and testing for accuracy and loss of EfficientnetB6'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/42b61ee55c2560a1c9d17c82b24d62d3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 26: Training and testing for accuracy and loss of EfficientnetB7'
  prefs: []
  type: TYPE_NORMAL
