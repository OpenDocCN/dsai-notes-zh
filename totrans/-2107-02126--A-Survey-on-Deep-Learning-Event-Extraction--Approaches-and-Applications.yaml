- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:53:11'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:53:11
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2107.02126] A Survey on Deep Learning Event Extraction: Approaches and Applications'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2107.02126] 《深度学习事件抽取调查：方法与应用》'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2107.02126](https://ar5iv.labs.arxiv.org/html/2107.02126)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2107.02126](https://ar5iv.labs.arxiv.org/html/2107.02126)
- en: 'A Survey on Deep Learning Event Extraction: Approaches and Applications'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《深度学习事件抽取调查：方法与应用》
- en: 'Qian Li, Jianxin Li, Jiawei Sheng, Shiyao Cui, Jia Wu, Yiming Hei, Hao Peng,
    Shu Guo, Lihong Wang, Amin Beheshti, and Philip S. Yu, Qian Li, and Jianxin Li
    are with the School of Computer Science and Engineering, and Beijing Advanced
    Innovation Center for Big Data and Brain Computing in Beihang University, Beijing
    100083, China. E-mail: {liqian@act.buaa.edu.cn, lijx@buaa.edu.cn} (*Corresponding
    author: Jianxin Li.*)Jiawei Sheng and Shiyao Cui are with the Institute of Information
    Engineering, Chinese Academy of Sciences, Beijing 100083, China, and the School
    of Cyber Security, University of Chinese Academy of Sciences, Beijing 100083,
    China. E-mail: {shengjiawei,cuishiyao}@iie.ac.cn.Yiming Hei is with the School
    of Cyber Science and Technology, Beihang University, Beijing 100083, China. E-mail:
    black@buaa.edu.cn.Hao Peng is with Beijing Advanced Innovation Center for Big
    Data and Brain Computing in Beihang University, Beijing 100083, China. E-mail:
    penghao@act.buaa.edu.cn.Shu Guo and Lihong Wang are with the National Computer
    Network Emergency Response Technical Team/Coordination Center of China, Beijing
    100029, China. E-mail: {guoshu, wlh}@cert.org.cn.Jia Wu and Amin Beheshti are
    with the School of Computing, Macquarie University, Sydney, Australia. E-mail:
    {jia.wu, amin.beheshti} @mq.edu.au.Philip S. Yu is with the Department of Computer
    Science, University of Illinois at Chicago, Chicago 60607, USA. E-mail: psyu@uic.edu.Manuscript
    received August 9, 2022.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Qian Li、Jianxin Li、Jiawei Sheng、Shiyao Cui、Jia Wu、Yiming Hei、Hao Peng、Shu Guo、Lihong
    Wang、Amin Beheshti 和 **Philip S. Yu**，Qian Li 和 Jianxin Li 就职于北京航空航天大学计算机科学与工程学院及北京大数据与脑计算前沿创新中心，北京
    100083，中国。电子邮件：{liqian@act.buaa.edu.cn, lijx@buaa.edu.cn} (*通讯作者：Jianxin Li*)。Jiawei
    Sheng 和 Shiyao Cui 就职于中国科学院信息工程研究所，北京 100083，中国，以及中国科学院网络安全学院，北京 100083，中国。电子邮件：{shengjiawei,
    cuishiyao}@iie.ac.cn。Yiming Hei 就职于北京航空航天大学网络科学与技术学院，北京 100083，中国。电子邮件：black@buaa.edu.cn。Hao
    Peng 就职于北京航空航天大学北京大数据与脑计算前沿创新中心，北京 100083，中国。电子邮件：penghao@act.buaa.edu.cn。Shu
    Guo 和 Lihong Wang 就职于国家计算机网络应急技术处理协调中心，北京 100029，中国。电子邮件：{guoshu, wlh}@cert.org.cn。Jia
    Wu 和 Amin Beheshti 就职于麦考瑞大学计算机学院，悉尼，澳大利亚。电子邮件：{jia.wu, amin.beheshti}@mq.edu.au。Philip
    S. Yu 就职于伊利诺伊大学芝加哥分校计算机科学系，芝加哥 60607，美国。电子邮件：psyu@uic.edu。手稿收到日期：2022年8月9日。
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Event extraction is a crucial research task for promptly apprehending event
    information from massive textual data. With the rapid development of deep learning,
    event extraction based on deep learning technology has become a research hotspot.
    Numerous methods, datasets, and evaluation metrics have been proposed in the literature,
    raising the need for a comprehensive and updated survey. This paper fills the
    research gap by reviewing the state-of-the-art approaches, especially focusing
    on the general domain event extraction based on deep learning models. We introduce
    a new literature classification of current general domain event extraction research
    according to the task definition. Afterwards, we summarize the paradigm and models
    of event extraction approaches, and then discuss each of them in detail. As an
    important aspect, we summarize the benchmarks that support tests of predictions
    and evaluation metrics. A comprehensive comparison among different approaches
    is also provided in this survey. Finally, we conclude by summarizing future research
    directions facing the research area.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 事件抽取是从大量文本数据中迅速获取事件信息的关键研究任务。随着深度学习的快速发展，基于深度学习技术的事件抽取已成为研究热点。文献中提出了众多方法、数据集和评估指标，这就需要一项全面且更新的调查。本文通过回顾最先进的方法，特别关注基于深度学习模型的一般领域事件抽取，填补了这一研究空白。我们根据任务定义引入了当前一般领域事件抽取研究的新文献分类。随后，我们总结了事件抽取方法的范式和模型，并详细讨论了每种方法。作为一个重要方面，我们总结了支持预测测试和评估指标的基准。本文还提供了不同方法之间的全面比较。最后，我们总结了研究领域面临的未来研究方向。
- en: 'Index Terms:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 索引词：
- en: Event extraction, deep learning, evaluation metrics, research trends
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 事件抽取，深度学习，评估指标，研究趋势
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Event Extraction (EE) is an important yet challenging task in information extraction
    research. As a particular form of information, an event refers to a specific occurrence
    of something that happens in a certain time and a certain place involving one
    or more participants, which can usually be described as a change of state [[1](#bib.bib1)].
    The event extraction task aims at extracting such event information from unstructured
    plain texts into a structured form, which mostly describes “who, when, where,
    what, why” and “how” of real-world events that happened. In terms of application,
    the task facilitates people to retrieve event information and analyze people’s
    behaviors, arousing information retrieval [[2](#bib.bib2), [3](#bib.bib3)], recommendation
    [[4](#bib.bib4), [5](#bib.bib5)], intelligent question answering [[6](#bib.bib6),
    [7](#bib.bib7)], knowledge graph construction [[8](#bib.bib8), [9](#bib.bib9)],
    and other event-related applications [[10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12)].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 事件提取（EE）是信息提取研究中一个重要且具有挑战性的任务。事件作为一种特定形式的信息，指的是发生在特定时间和地点的某种特定事件，涉及一个或多个参与者，通常可以描述为状态的变化[[1](#bib.bib1)]。事件提取任务旨在从非结构化的纯文本中提取这种事件信息，转化为结构化形式，主要描述现实世界中事件的“谁、何时、何地、什么、为什么”和“如何”。在应用方面，该任务有助于人们检索事件信息和分析人们的行为，激发信息检索[[2](#bib.bib2)、[3](#bib.bib3)]、推荐[[4](#bib.bib4)、[5](#bib.bib5)]、智能问答[[6](#bib.bib6)、[7](#bib.bib7)]、知识图谱构建[[8](#bib.bib8)、[9](#bib.bib9)]及其他与事件相关的应用[[10](#bib.bib10)、[11](#bib.bib11)、[12](#bib.bib12)]。
- en: 'Event extraction can be divided into two groups: close-domain event extraction
    [[13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15)] and open-domain event extraction
    [[16](#bib.bib16), [17](#bib.bib17), [18](#bib.bib18)]. Events are usually considered
    in a predefined event schema, where some specific people and objects are interacted
    at a specific time and place. The close-domain event extraction task aims to find
    words that belong to a specific event schema, which refers to an action or state
    change that occurs, and its extraction targets include time, place, person, and
    action, etc. In the open-domain event extraction task, events are considered as
    a set of related descriptions of a topic, which can be formulated into a classification
    or clustering task. Open-domain event extraction refers to acquiring a series
    of events related to a specific theme, usually composed of multiple events. Whether
    the close-domain or open-domain event extraction task, the purpose of event extraction
    is to capture the event types that we are interested in from numerous texts and
    show the essential arguments of events in a structured form.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 事件提取可以分为两类：闭域事件提取[[13](#bib.bib13)、[14](#bib.bib14)、[15](#bib.bib15)]和开放域事件提取[[16](#bib.bib16)、[17](#bib.bib17)、[18](#bib.bib18)]。事件通常在预定义的事件模式中考虑，其中一些特定的人和对象在特定的时间和地点进行交互。闭域事件提取任务旨在找到属于特定事件模式的词汇，这指的是发生的动作或状态变化，其提取目标包括时间、地点、人物和动作等。在开放域事件提取任务中，事件被视为与某一主题相关的描述集合，这些描述可以被表述为分类或聚类任务。开放域事件提取指的是获取与特定主题相关的一系列事件，通常由多个事件组成。无论是闭域还是开放域事件提取任务，事件提取的目的都是从大量文本中捕捉我们感兴趣的事件类型，并以结构化形式展示事件的核心论点。
- en: Deep learning event extraction on general domain has a lot of work and has been
    a relatively mature research taxonomy. It discovers event mentions from texts
    and extracts events containing event triggers and event arguments, where event
    mentions are termed as sentences containing one or more triggers and arguments.
    Event extraction requires to identify the event, classify event type, identify
    the argument, and judge the argument role. Specifically, trigger identification
    and trigger classification are usually formed as the event detection task [[19](#bib.bib19),
    [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22)], while argument identification
    and argument role classification are usually defined as an argument extraction
    task. The trigger classification is a multi-classification classification [[23](#bib.bib23),
    [24](#bib.bib24), [25](#bib.bib25)] task to classify the type of each event. The
    role classification task is a multi-class classification task based on word pairs,
    determining the role relationship between any pair of triggers and entities in
    a sentence. From a technical perspective, event extraction can depend on some
    other foundational natural language processing (NLP) tasks such as named entity
    recognition (NER) [[26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28)], semantic
    parsing [[29](#bib.bib29), [30](#bib.bib30), [31](#bib.bib31)], and relation extraction
    [[32](#bib.bib32), [33](#bib.bib33), [34](#bib.bib34)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一般领域的深度学习事件提取工作量很大，并且已经形成了相对成熟的研究分类体系。它从文本中发现事件提及并提取包含事件触发词和事件参数的事件，其中事件提及被称为包含一个或多个触发词和参数的句子。事件提取需要识别事件、分类事件类型、识别参数和判断参数角色。具体而言，触发词识别和触发词分类通常被视为事件检测任务[[19](#bib.bib19),
    [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22)]，而参数识别和参数角色分类通常定义为参数提取任务。触发词分类是一个多分类任务[[23](#bib.bib23),
    [24](#bib.bib24), [25](#bib.bib25)]，用于对每个事件的类型进行分类。角色分类任务是一个基于词对的多分类任务，用于确定句子中任何一对触发词和实体之间的角色关系。从技术角度来看，事件提取可以依赖一些其他基础的自然语言处理（NLP）任务，如命名实体识别（NER）[[26](#bib.bib26),
    [27](#bib.bib27), [28](#bib.bib28)]，语义解析[[29](#bib.bib29), [30](#bib.bib30), [31](#bib.bib31)]，以及关系提取[[32](#bib.bib32),
    [33](#bib.bib33), [34](#bib.bib34)]。
- en: '![Refer to caption](img/718e27a3b6bd54d2b7470ac5553bac57.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/718e27a3b6bd54d2b7470ac5553bac57.png)'
- en: 'Figure 1: The flowchart of deep learning event extraction on general domain.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：一般领域深度学习事件提取的流程图。
- en: 'We give the flow chart of deep learning event extraction on the general domain,
    as shown in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ A Survey on Deep Learning
    Event Extraction: Approaches and Applications"). The event extraction is to find
    the focused event type and extract its arguments with it roles. For a pipeline
    paradigm event extraction, it is necessary to distinguish the event type in the
    text for a given text, called trigger classification. For different event types,
    different event schema is designed. Then, event arguments are extracted according
    to the schema, which includes argument identification and argument role classification
    sub-tasks. In the earliest stage, argument role classification is regarded as
    a word classification task, and each word in the text is classified. In addition,
    there are sequence labeling, machine reading comprehension (MRC) and sequence-to-structure
    generation methods. For a joint paradigm event extraction, the model classifies
    the event type and argument roles simultaneously to avoid error coming from trigger
    classification sub-task.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '我们给出了如图[1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ A Survey on Deep Learning Event
    Extraction: Approaches and Applications")所示的一般领域深度学习事件提取的流程图。事件提取是找到关注的事件类型并提取其参数及其角色。对于流水线范式事件提取，必须区分给定文本中的事件类型，这称为触发词分类。对于不同的事件类型，设计不同的事件模式。然后，根据模式提取事件参数，包括参数识别和参数角色分类子任务。在最早的阶段，参数角色分类被视为词分类任务，每个词都被分类。此外，还有序列标注、机器阅读理解（MRC）和序列到结构生成方法。对于联合范式事件提取，模型同时分类事件类型和参数角色，以避免来自触发词分类子任务的错误。'
- en: 1.1 Contributions
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 贡献
- en: 'For the traditional event extraction method, the feature designing is necessary,
    while for the deep learning event extraction method on general domain, the features
    can be end-to-end extracted by deep learning models. The existing reviews mainly
    introduce the extraction of subject events, where there are few event extraction
    methods based on deep learning models [[35](#bib.bib35), [18](#bib.bib18), [36](#bib.bib36)].
    In recent years, a large number of event extraction methods have been proposed,
    and the event extraction methods based on Transformer have achieved significant
    improvement [[37](#bib.bib37)]. Furthermore, event extraction is no longer limited
    to classification and sequence annotation manner [[38](#bib.bib38), [39](#bib.bib39),
    [40](#bib.bib40)], but can also be formulated in machine reading comprehension
    and generation [[41](#bib.bib41), [42](#bib.bib42)] manner. Therefore, we comprehensively
    analyze the existing deep learning-based event extraction methods on general domain
    and outlook for future research work. The main contributions of this paper are
    as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于传统的事件抽取方法，需要进行特征设计，而对于通用领域的深度学习事件抽取方法，特征可以通过深度学习模型进行端到端的提取。现有的综述主要介绍了主体事件的抽取，其中基于深度学习模型的事件抽取方法较少
    [[35](#bib.bib35), [18](#bib.bib18), [36](#bib.bib36)]。近年来，提出了大量的事件抽取方法，基于 Transformer
    的事件抽取方法取得了显著的改进 [[37](#bib.bib37)]。此外，事件抽取不再仅限于分类和序列标注的方式 [[38](#bib.bib38), [39](#bib.bib39),
    [40](#bib.bib40)]，还可以以机器阅读理解和生成 [[41](#bib.bib41), [42](#bib.bib42)] 的方式进行。因此，我们对现有的基于深度学习的通用领域事件抽取方法进行了综合分析，并展望了未来的研究工作。本文的主要贡献如下：
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'We introduce the general domain event extraction technology, review the development
    history of event extraction methods, and point out that the event extraction methods
    with deep learning have become the mainstream. We summarize the necessary information
    of deep learning models according to year of publication in Table [I](#S3.T1 "TABLE
    I ‣ 3.2 Joint-based Paradigm ‣ 3 Event Extraction Paradigm ‣ A Survey on Deep
    Learning Event Extraction: Approaches and Applications").'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '我们介绍了通用领域的事件抽取技术，回顾了事件抽取方法的发展历史，并指出基于深度学习的事件抽取方法已成为主流。我们根据发表年份在表格 [I](#S3.T1
    "TABLE I ‣ 3.2 Joint-based Paradigm ‣ 3 Event Extraction Paradigm ‣ A Survey on
    Deep Learning Event Extraction: Approaches and Applications") 中总结了深度学习模型的必要信息。'
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'We analyze various deep learning-based extraction paradigm and models, including
    their advantages and disadvantages in detail. We introduce the currently available
    datasets and give the formulation of main evaluation metrics. We summarize the
    necessary information of primary datasets in Table [II](#S5.T2 "TABLE II ‣ 5.5
    Chinese Event Extraction Scenario ‣ 5 Event Extraction Scenarios ‣ A Survey on
    Deep Learning Event Extraction: Approaches and Applications").'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '我们详细分析了各种基于深度学习的抽取范式和模型，包括它们的优缺点。我们介绍了当前可用的数据集，并给出了主要评估指标的公式。我们在表格 [II](#S5.T2
    "TABLE II ‣ 5.5 Chinese Event Extraction Scenario ‣ 5 Event Extraction Scenarios
    ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications") 中总结了主要数据集的必要信息。'
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'We summarize event extraction accuracy scores on ACE 2005 dataset in Table [IV](#S6.T4
    "TABLE IV ‣ 6.2 Sentence-level ‣ 6 Event Extraction Corpus ‣ A Survey on Deep
    Learning Event Extraction: Approaches and Applications") and event extraction
    applications. We conclude the review by discussing the future research trends
    facing the event extraction.'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '我们在表格 [IV](#S6.T4 "TABLE IV ‣ 6.2 Sentence-level ‣ 6 Event Extraction Corpus
    ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications") 中总结了
    ACE 2005 数据集上的事件抽取准确率，并讨论了事件抽取的应用。我们通过讨论未来事件抽取面临的研究趋势来总结综述。'
- en: '![Refer to caption](img/2bd7449d7b6060d94afc943a84335af6.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/2bd7449d7b6060d94afc943a84335af6.png)'
- en: 'Figure 2: A diagram of event extraction. The example can be divided into two
    type of event. The type of Die is triggered by “died” with three argument roles
    of Place, Victim and Instrument and the type of Attack is triggered by “fired”
    with three argument roles of Place, Target and Instrument.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：事件抽取的示意图。该示例可以分为两类事件。类型为 Die 的事件由“died”触发，具有三个论元角色：地点、受害者和工具；类型为 Attack
    的事件由“fired”触发，具有三个论元角色：地点、目标和工具。
- en: 1.2 Organization of the Survey
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2 调研的组织
- en: 'The rest of the survey is organized as follows. Section [2](#S2 "2 Preliminary
    ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications") introduces
    the concepts and task definitions of event extraction. Section [3](#S3 "3 Event
    Extraction Paradigm ‣ A Survey on Deep Learning Event Extraction: Approaches and
    Applications") summarizes the existing paradigm related to event extraction, including
    pipeline-based methods and joint-based methods, constituting a summary table.
    Section [4](#S4 "4 Deep Learning Event Extraction Models ‣ A Survey on Deep Learning
    Event Extraction: Approaches and Applications") introduces traditional event extraction
    and deep learning-based event extraction with a comparison. Section [5](#S5 "5
    Event Extraction Scenarios ‣ A Survey on Deep Learning Event Extraction: Approaches
    and Applications") introduces the event extraction on different scenarios. Section [6](#S6
    "6 Event Extraction Corpus ‣ A Survey on Deep Learning Event Extraction: Approaches
    and Applications") and Section [7](#S7 "7 Metrics ‣ A Survey on Deep Learning
    Event Extraction: Approaches and Applications") primary event extraction corpus
    and metrics. We then give quantitative results of the leading models in classic
    event extraction datasets in Section [8](#S8 "8 Quantitative Results ‣ A Survey
    on Deep Learning Event Extraction: Approaches and Applications"). Finally, we
    summarize event extraction applications and main challenges for event extraction
    in Section [9](#S9 "9 Event Extraction Applications ‣ A Survey on Deep Learning
    Event Extraction: Approaches and Applications") and Section [10](#S10 "10 Future
    Research Trends ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications")
    before concluding the article in Section [11](#S11 "11 Conclusion ‣ A Survey on
    Deep Learning Event Extraction: Approaches and Applications").'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '剩余的调查组织如下。第[2](#S2 "2 Preliminary ‣ A Survey on Deep Learning Event Extraction:
    Approaches and Applications")节介绍了事件抽取的概念和任务定义。第[3](#S3 "3 Event Extraction Paradigm
    ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications")节总结了与事件抽取相关的现有范式，包括基于管道的方法和基于联合的方法，构成了一个总结表。第[4](#S4
    "4 Deep Learning Event Extraction Models ‣ A Survey on Deep Learning Event Extraction:
    Approaches and Applications")节介绍了传统事件抽取和基于深度学习的事件抽取，并进行了比较。第[5](#S5 "5 Event Extraction
    Scenarios ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications")节介绍了不同场景下的事件抽取。第[6](#S6
    "6 Event Extraction Corpus ‣ A Survey on Deep Learning Event Extraction: Approaches
    and Applications")节和第[7](#S7 "7 Metrics ‣ A Survey on Deep Learning Event Extraction:
    Approaches and Applications")节主要讨论了事件抽取的语料库和评估指标。然后在第[8](#S8 "8 Quantitative Results
    ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications")节给出了经典事件抽取数据集中领先模型的定量结果。最后，我们在第[9](#S9
    "9 Event Extraction Applications ‣ A Survey on Deep Learning Event Extraction:
    Approaches and Applications")节和第[10](#S10 "10 Future Research Trends ‣ A Survey
    on Deep Learning Event Extraction: Approaches and Applications")节总结了事件抽取的应用和主要挑战，然后在第[11](#S11
    "11 Conclusion ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications")节对文章进行了总结。'
- en: 2 Preliminary
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 初步
- en: This section introduces concepts, sub-tasks and model manners in current event
    extraction researches.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了当前事件抽取研究中的概念、子任务和模型方法。
- en: 2.1 Concepts
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 概念
- en: 'An event indicates an occurrence of an action or state change, often driven
    by verbs or gerunds. It contains the primary components involving in the action,
    such as time, place, and character. Event extraction technology extracts events
    that users are interested in from unstructured texts and presents them to users
    in a structured form [[39](#bib.bib39)]. In short, event extraction detects event
    with its type and extracts the core arguments from the text, as shown in Fig.
    [2](#S1.F2 "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning
    Event Extraction: Approaches and Applications"). Given a text, an event extraction
    technology can predict the events mentions in the text, the triggers and arguments
    corresponding to each event, and classify the role of each argument. Event extraction
    requires to recognize the two events (Die and Attack), triggered by the words
    “died” and “fired” respectively, as shown in Fig. [2](#S1.F2 "Figure 2 ‣ 1.1 Contributions
    ‣ 1 Introduction ‣ A Survey on Deep Learning Event Extraction: Approaches and
    Applications"). For Die event type, we recognize that “Baghdad”, “cameraman” and
    “American tank” take on the event argument roles Place, Victim and Instrument,
    respectively. For Attack, “Baghdad” and “American tank” take on the event argument
    roles Place and Instrument respectively. And “cameraman” and “Palestine Hotel”
    take on the event argument roles Target.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '事件指的是动作或状态变化的发生，通常由动词或动名词驱动。它包含涉及该动作的主要组件，如时间、地点和角色。事件提取技术从非结构化文本中提取用户感兴趣的事件，并以结构化的形式呈现给用户[[39](#bib.bib39)]。简而言之，事件提取检测事件及其类型，并从文本中提取核心论据，如图[2](#S1.F2
    "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event
    Extraction: Approaches and Applications")所示。给定一个文本，事件提取技术可以预测文本中的事件提及、每个事件对应的触发词和论据，并对每个论据的角色进行分类。事件提取需要识别由“died”和“fired”分别触发的两个事件（Die和Attack），如图[2](#S1.F2
    "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event
    Extraction: Approaches and Applications")所示。对于Die事件类型，我们识别到“Baghdad”、“cameraman”和“American
    tank”分别承担事件论据角色地点、受害者和工具。对于Attack，“Baghdad”和“American tank”分别承担事件论据角色地点和工具。而“cameraman”和“Palestine
    Hotel”则承担事件论据角色目标。'
- en: 'Event extraction involves many frontier disciplines, such as machine learning,
    pattern matching, and NLP. At the same time, event extraction in various fields
    can help relevant personnel quickly extract relevant content from massive information,
    improve work timeliness, and provide technical support for quantitative analysis.
    Therefore, event extraction has a broad application prospect in various fields.
    Typically, Automatic Content Extraction (ACE) describes an event extraction task
    holding the following terminologies:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 事件提取涉及许多前沿学科，如机器学习、模式匹配和自然语言处理（NLP）。同时，各个领域的事件提取可以帮助相关人员从海量信息中快速提取相关内容，提高工作时效，并为定量分析提供技术支持。因此，事件提取在各个领域具有广泛的应用前景。通常，自动内容提取（ACE）描述了一种事件提取任务，并包含以下术语：
- en: •
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '`Entity`: The entity is an object or group of objects in a semantic category.
    Entity mainly includes people, organizations, places, times, things, etc. In Fig.
    [2](#S1.F2 "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning
    Event Extraction: Approaches and Applications"), the words“Baghdad”,“cameraman”,“American
    tank”, and “Palestine Hotel” are Entity.'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Entity`：实体是语义类别中的对象或对象群体。实体主要包括人、组织、地点、时间、事物等。在图[2](#S1.F2 "Figure 2 ‣ 1.1
    Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event Extraction: Approaches
    and Applications")中，词汇“Baghdad”、“cameraman”、“American tank”和“Palestine Hotel”是实体。'
- en: •
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '`Event mentions`: The phrases or sentences that describe the event contains
    a trigger and corresponding arguments.'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Event mentions`：描述事件的短语或句子包含一个触发词和相应的论据。'
- en: •
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '`Event type`: The event type describes the nature of the event and refers to
    the category to which the event corresponds, usually represented by the type of
    the event trigger. For sentence in Fig. [2](#S1.F2 "Figure 2 ‣ 1.1 Contributions
    ‣ 1 Introduction ‣ A Survey on Deep Learning Event Extraction: Approaches and
    Applications"), it contains Die and Attack event types.'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Event type`：事件类型描述事件的性质，并指事件对应的类别，通常由事件触发词的类型表示。如图[2](#S1.F2 "Figure 2 ‣ 1.1
    Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event Extraction: Approaches
    and Applications")中的句子，它包含Die和Attack事件类型。'
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '`Event trigger`: Event trigger refers to the core unit in event extraction,
    a verb or a noun. Trigger identification is a key step in pipeline-based event
    extraction. For event Die in Fig. [2](#S1.F2 "Figure 2 ‣ 1.1 Contributions ‣ 1
    Introduction ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications"),
    the event trigger is “died”.'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`事件触发词`：事件触发词指的是事件抽取中的核心单元，一个动词或名词。触发词识别是基于管道的事件抽取中的关键步骤。例如，图 [2](#S1.F2 "Figure
    2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event Extraction:
    Approaches and Applications") 中的 Die 事件，其事件触发词是“死亡”。'
- en: •
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '`Event argument`: Event argument is the main attribute of events. It includes
    entities, nonentity participants, and time, and so on. For event Die in Fig. [2](#S1.F2
    "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event
    Extraction: Approaches and Applications"), the event arguments are “Baghdad”,
    “cameraman”, and “American tank”.'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`事件论据`：事件论据是事件的主要属性。它包括实体、非实体参与者和时间等。例如，图 [2](#S1.F2 "Figure 2 ‣ 1.1 Contributions
    ‣ 1 Introduction ‣ A Survey on Deep Learning Event Extraction: Approaches and
    Applications") 中的 Die 事件，其事件论据是“巴格达”、“摄像师”和“美国坦克”。'
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '`Argument role`: An argument role is a role played by an argument in an event,
    that is, the relationship representation between the event arguments and the event
    triggers. For argument “Baghdad” of Die event in Fig. [2](#S1.F2 "Figure 2 ‣ 1.1
    Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event Extraction: Approaches
    and Applications"), the argument role is Place.'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`论据角色`：论据角色是指论据在事件中扮演的角色，即事件论据与事件触发词之间的关系表示。例如，图 [2](#S1.F2 "Figure 2 ‣ 1.1
    Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event Extraction: Approaches
    and Applications") 中 Die 事件的论据“巴格达”其角色是地点。'
- en: 2.2 Sub-tasks
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 子任务
- en: 'Event extraction includes four sub-tasks: trigger classification, trigger identification,
    argument identification and argument role classification.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 事件抽取包括四个子任务：触发词分类、触发词识别、论据识别和论据角色分类。
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '`Trigger identification`: It is generally considered that the trigger is the
    core unit in event extraction that can clearly express an event’s occurrence.
    The trigger identification subtask is to find the trigger from the text. In Fig.
    [2](#S1.F2 "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning
    Event Extraction: Approaches and Applications"), trigger identification is to
    identify the trigger “died” and “fired”.'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`触发词识别`：通常认为触发词是事件抽取中的核心单元，能够明确表达事件的发生。触发词识别子任务是从文本中找出触发词。在图 [2](#S1.F2 "Figure
    2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event Extraction:
    Approaches and Applications") 中，触发词识别是识别“死亡”和“开火”这两个触发词。'
- en: •
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '`Trigger classification`: Trigger classification is to determine whether each
    sentence is an event according to existing triggers. Furthermore, if the sentence
    is an event, we need to determine one or several events types the sentence belongs
    to. For example of Fig. [2](#S1.F2 "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction
    ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications"), the
    subtask aims to classify the event type of trigger “died” and “fired”, which respectively
    corresponds to Die and Attack. Therefore, the trigger classification sub-task
    can be seen as a multi-label text classification task.'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`触发词分类`：触发词分类是根据现有的触发词来判断每个句子是否为事件。此外，如果句子是事件，我们还需要确定句子属于一个或多个事件类型。例如，图 [2](#S1.F2
    "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event
    Extraction: Approaches and Applications") 中的子任务旨在分类触发词“死亡”和“开火”的事件类型，分别对应 Die
    和 Attack。因此，触发词分类子任务可以看作是一个多标签文本分类任务。'
- en: •
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '`Argument identification`: Argument identification is to identify all the arguments
    contained in an event type from the text. Argument identification usually depends
    on the result of trigger classification and trigger identification. For example
    of Die event in Fig. [2](#S1.F2 "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction
    ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications"), argument
    identification is to extract the words “Baghdad”, “cameraman” and “American tank”.'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`论据识别`：论据识别是从文本中识别事件类型所包含的所有论据。论据识别通常依赖于触发词分类和触发词识别的结果。例如，图 [2](#S1.F2 "Figure
    2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event Extraction:
    Approaches and Applications") 中的 Die 事件，论据识别就是提取“巴格达”、“摄像师”和“美国坦克”这些词汇。'
- en: •
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '`Argument role classification`: Argument role classification is based on the
    arguments contained in the event extraction schema, and the category of each argument
    is classified according to the identified arguments. For the extracted words of
    Fig. [2](#S1.F2 "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep
    Learning Event Extraction: Approaches and Applications"), such as “cameraman”,
    this subtask is to classify the word to Object category. Thus, it also can be
    seen as a multi-label text classification task.'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Argument role classification`：论元角色分类基于事件提取模式中的论元，每个论元的类别根据识别出的论元进行分类。对于图[2](#S1.F2
    "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event
    Extraction: Approaches and Applications")中的提取词，例如“摄影师”，该子任务是将该词分类为Object类别。因此，它也可以视为一个多标签文本分类任务。'
- en: '![Refer to caption](img/e4ff535b4463d6e3c3c51a83ad37b705.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/e4ff535b4463d6e3c3c51a83ad37b705.png)'
- en: (a) Classification-based task.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 基于分类的任务。
- en: '![Refer to caption](img/734295d2d327c0dab580502dfc8254cc.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/734295d2d327c0dab580502dfc8254cc.png)'
- en: (b) Question answering-based task.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 基于问答的任务。
- en: '![Refer to caption](img/8a1c839cfc0ad57b15e4f45a9ca9d2de.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/8a1c839cfc0ad57b15e4f45a9ca9d2de.png)'
- en: (c) Sequence labeling-based task.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 基于序列标注的任务。
- en: '![Refer to caption](img/03d5afac3e0b4db42af2b387987864c8.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/03d5afac3e0b4db42af2b387987864c8.png)'
- en: (d) Sequence-to-structure generation-based task.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 基于序列到结构生成的任务。
- en: 'Figure 3: How to implement argument extraction for Die event on classification-based,
    sequence labeling-based, question answering-based and sequence-to-structure generation-based
    tasks.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：如何在基于分类、基于序列标注、基于问答和基于序列到结构生成的任务中实现对Die事件的论元提取。
- en: 2.3 Event Extraction Manner
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 事件提取方式
- en: 'Event extraction is a very representative hot topic in information extraction,
    which studies how to extract a specific type of event information from unstructured
    text containing event information (news, blog, etc.). It can be simplified as
    multiple classification tasks, which determine the type of event and the argument
    role that each entity belongs to. For example, the word “cameraman” in Fig. [2](#S1.F2
    "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event
    Extraction: Approaches and Applications"), classification based methods are to
    classify which argument role it belongs to in a given role set. The classification
    method depends on Named Entity Recognition (NER), leading to the propagation of
    error information. Based on this, an event extraction method based on sequence
    labeling is proposed, which labels the start and end position of each argument.
    Sequence labeling based methods give a label in BIO of the word “cameraman”, where
    B stands for ’beginning’, I stands for ’inside’ and O stands for ’outside’. The
    task of event extraction is complex, and arguments are closely related to each
    other. Machine Reading Comprehension (MRC) is adopted to learn association, and
    each argument is found through question and answering pairs. MRC-based methods
    generate a question for argument role, such as Object, the model is to find the
    word play the argument role Object. Therefore, event extraction task can be regarded
    as classification task, sequence labeling task and machine reading comprehension
    task. Recently, some works focus on using a generative way [[43](#bib.bib43),
    [44](#bib.bib44)]. The definitions of these four tasks in more detail are as follows.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '事件提取是信息提取中的一个非常具有代表性的热门话题，研究如何从包含事件信息的非结构化文本（如新闻、博客等）中提取特定类型的事件信息。它可以简化为多个分类任务，确定事件类型及每个实体所属的论元角色。例如，图[2](#S1.F2
    "Figure 2 ‣ 1.1 Contributions ‣ 1 Introduction ‣ A Survey on Deep Learning Event
    Extraction: Approaches and Applications")中的词“摄影师”，基于分类的方法是将其分类到给定角色集中的某个论元角色。分类方法依赖于命名实体识别（NER），导致错误信息的传播。在此基础上，提出了一种基于序列标注的事件提取方法，标注每个论元的开始和结束位置。基于序列标注的方法给词“摄影师”一个BIO标签，其中B代表“开始”，I代表“内部”，O代表“外部”。事件提取任务复杂，论元之间关系密切。采用机器阅读理解（MRC）来学习关联，通过问答对找到每个论元。MRC基于的方法生成一个针对论元角色的问题，例如Object，模型的任务是找到扮演Object角色的词。因此，事件提取任务可以看作是分类任务、序列标注任务和机器阅读理解任务。最近，一些研究集中于使用生成的方法[[43](#bib.bib43),
    [44](#bib.bib44)]。这四个任务的详细定义如下。'
- en: 2.3.1 Classification-based Task
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1 基于分类的任务
- en: 'For the classification task [[45](#bib.bib45), [46](#bib.bib46)], authors usually
    predefine $n$ event types and their corresponding argument roles, $e.g.$ the event
    $e_{i}$ ($i\in[1,n]$) contains a set of argument roles [$r_{i,1},r_{i,2}...,r_{i,l}$].
    Given an input event mention $m$, the model needs to output a result vector $T$,
    where the $i$-th argument $T_{i}$ represents the probability that $m$ belongs
    to the event $e_{i}$. In the classification-based task, the trigger identification
    is to classify whether a word is a trigger. After obtaining the final event (or
    a set) $e_{k}$ of $m$, the model outputs a matrix $R$ where the argument $R_{i,j}$
    means the probability that the extracted argument $a_{i}$ belongs to argument
    roles $r_{k,j}$. As shown in Fig. [3](#S2.F3 "Figure 3 ‣ 2.2 Sub-tasks ‣ 2 Preliminary
    ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications")(a),
    it classifies each entity to a predefined argument role.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '对于分类任务 [[45](#bib.bib45), [46](#bib.bib46)]，作者通常预定义 $n$ 个事件类型及其对应的论元角色，例如事件
    $e_{i}$ ($i\in[1,n]$) 包含一组论元角色 [$r_{i,1},r_{i,2}...,r_{i,l}$]。给定一个输入事件提及 $m$，模型需要输出一个结果向量
    $T$，其中第 $i$ 个论元 $T_{i}$ 表示 $m$ 属于事件 $e_{i}$ 的概率。在基于分类的任务中，触发词识别是为了分类一个词是否为触发词。在获得最终事件（或一组）
    $e_{k}$ 后，模型输出一个矩阵 $R$，其中论元 $R_{i,j}$ 表示提取的论元 $a_{i}$ 属于论元角色 $r_{k,j}$ 的概率。如图
    [3](#S2.F3 "Figure 3 ‣ 2.2 Sub-tasks ‣ 2 Preliminary ‣ A Survey on Deep Learning
    Event Extraction: Approaches and Applications")(a) 所示，它将每个实体分类到预定义的论元角色中。'
- en: 2.3.2 Machine Reading Comprehension-based Task
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.2 基于机器阅读理解的任务
- en: 'The machine reading comprehension model [[47](#bib.bib47), [48](#bib.bib48),
    [49](#bib.bib49)] can understand a piece of text in natural language and answer
    questions about it [[50](#bib.bib50)]. In the machine reading comprehension-based
    task, the trigger identification is also to classify whether a word is a trigger.
    Firstly, a question schema is designed for each argument role $r$, called $Q_{r}$.
    Since different event types have different arguments, the model needs to first
    identify the event type to which the text belongs. Then, the argument roles to
    be extracted are determined according to the event types. Finally, the event extraction
    method based on machine reading comprehension is to input the text $T$, and apply
    the designed questions $Q_{r}$ one by one to the extraction model, as shown in
    Fig. [3](#S2.F3 "Figure 3 ‣ 2.2 Sub-tasks ‣ 2 Preliminary ‣ A Survey on Deep Learning
    Event Extraction: Approaches and Applications")(b). The model extracts the answer
    $A_{r}$, which is the corresponding argument for each argument role $r$.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '机器阅读理解模型 [[47](#bib.bib47), [48](#bib.bib48), [49](#bib.bib49)] 能够理解自然语言中的一段文本并回答有关它的问题
    [[50](#bib.bib50)]。在基于机器阅读理解的任务中，触发词识别也用于分类一个词是否为触发词。首先，为每个论元角色 $r$ 设计一个问题模式 $Q_{r}$。由于不同的事件类型具有不同的论元，模型需要首先识别文本所属的事件类型。然后，根据事件类型确定需要提取的论元角色。最终，基于机器阅读理解的事件提取方法是输入文本
    $T$，并将设计好的问题 $Q_{r}$ 逐一应用到提取模型中，如图 [3](#S2.F3 "Figure 3 ‣ 2.2 Sub-tasks ‣ 2 Preliminary
    ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications")(b)
    所示。模型提取出答案 $A_{r}$，这是每个论元角色 $r$ 的对应论元。'
- en: 2.3.3 Sequence labeling-based Task
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.3 基于序列标注的任务
- en: 'Sequence labeling task [[51](#bib.bib51), [52](#bib.bib52), [53](#bib.bib53)]
    is a multi-classification task [[54](#bib.bib54), [55](#bib.bib55), [56](#bib.bib56)]
    based on word level, which can directly match event arguments based on word level
    event type extraction. The event extraction mainly includes two core tasks: identifying
    and classifying event categories and extracting event arguments. Event extraction
    based on sequence labeling can simply and quickly realize the matching of event
    type and event argument without additional features. In the sequence labeling-based
    task, the trigger identification is to label a word is a trigger. The sequence
    labeling method marks out the target from the text, which is suitable for the
    event extraction task. As shown in Fig. [3](#S2.F3 "Figure 3 ‣ 2.2 Sub-tasks ‣
    2 Preliminary ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications")(c),
    for a given text $T={x_{1},x_{2},\dots,x_{N}}$ and event schema, the argument
    role $r$ corresponding to the argument is labeled with the sequence labeling model.
    The output $y={y_{1},y_{2},\dots,y_{N}}$ of sequence labeling model is to tag
    all words in the text.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '序列标注任务[[51](#bib.bib51), [52](#bib.bib52), [53](#bib.bib53)]是基于词级的多分类任务[[54](#bib.bib54),
    [55](#bib.bib55), [56](#bib.bib56)]，可以直接根据词级事件类型抽取来匹配事件参数。事件抽取主要包括两个核心任务：识别和分类事件类别以及抽取事件参数。基于序列标注的事件抽取可以简单快速地实现事件类型和事件参数的匹配，而无需额外的特征。在基于序列标注的任务中，触发词识别是标记一个词为触发词。序列标注方法从文本中标出目标，这对于事件抽取任务非常适合。如图
    [3](#S2.F3 "Figure 3 ‣ 2.2 Sub-tasks ‣ 2 Preliminary ‣ A Survey on Deep Learning
    Event Extraction: Approaches and Applications")(c) 所示，对于给定的文本 $T={x_{1},x_{2},\dots,x_{N}}$
    和事件模式，参数角色 $r$ 对应的参数由序列标注模型标记。序列标注模型的输出 $y={y_{1},y_{2},\dots,y_{N}}$ 是对文本中所有词的标记。'
- en: 2.3.4 Sequence-to-structure Generation-based Task
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.4 基于序列到结构生成的任务
- en: 'The sequence-to-structure generation-based event extraction extracts events
    from the text in an end-to-end manner [[43](#bib.bib43)]. In the sequence-to-structure
    generation-based task, the trigger identification is to generate a trigger. It
    uniformly models all tasks in a single model and universally predicts different
    labels. As shown in Fig. [3](#S2.F3 "Figure 3 ‣ 2.2 Sub-tasks ‣ 2 Preliminary
    ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications")(d),
    the sequence-to-structure generation-based methods directly generate all arguments
    and their roles. It usually adopts encoder-decoder models [[43](#bib.bib43)],
    which is an easy way to convert text into a structured form.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '基于序列到结构生成的事件抽取以端到端的方式从文本中抽取事件[[43](#bib.bib43)]。在序列到结构生成的任务中，触发词识别是生成一个触发词。它将所有任务统一建模在一个模型中，并普遍预测不同的标签。如图
    [3](#S2.F3 "Figure 3 ‣ 2.2 Sub-tasks ‣ 2 Preliminary ‣ A Survey on Deep Learning
    Event Extraction: Approaches and Applications")(d) 所示，基于序列到结构生成的方法直接生成所有参数及其角色。它通常采用编码器-解码器模型[[43](#bib.bib43)]，这是一种将文本转换为结构化形式的简便方法。'
- en: '![Refer to caption](img/2d9924d3334b948d540d83e32f77581f.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2d9924d3334b948d540d83e32f77581f.png)'
- en: 'Figure 4: An example of pipeline-based event extraction.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：基于管道的事件抽取示例。
- en: 3 Event Extraction Paradigm
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 事件抽取范式
- en: 'Event extraction includes four sub-tasks: trigger identification, event type
    classification, argument identification, and argument role classification. According
    to the procedure to settle these four subtasks, the event extraction task is divided
    into pipeline-based event extraction and joint-based event extraction. The pipeline
    based method is first adopted [[39](#bib.bib39), [57](#bib.bib57)]. It first detects
    the triggers, and judges the event type according to the triggers. The argument
    extraction model then extracts arguments and classifies argument roles according
    to the prediction results of event type and the triggers. To overcome the propagation
    of error information caused by event detection, researchers propose a joint-based
    event extraction paradigm [[58](#bib.bib58), [59](#bib.bib59), [60](#bib.bib60)].
    It reduces the propagation of error information by combining event detection and
    argument extraction tasks.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 事件提取包括四个子任务：触发器识别、事件类型分类、论据识别和论据角色分类。根据处理这四个子任务的程序，事件提取任务被分为基于管道的事件提取和基于联合的事件提取。首先采用基于管道的方法[[39](#bib.bib39),
    [57](#bib.bib57)]。它首先检测触发器，然后根据触发器判断事件类型。然后，论据提取模型根据事件类型和触发器的预测结果提取论据并分类论据角色。为了克服事件检测导致的错误信息传播，研究人员提出了一种基于联合的事件提取范式[[58](#bib.bib58),
    [59](#bib.bib59), [60](#bib.bib60)]。它通过将事件检测和论据提取任务结合起来，减少了错误信息的传播。
- en: 3.1 Pipeline-based Paradigm
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 基于管道的范式
- en: 'The pipeline-based method treats all sub-tasks as independent classification
    problems [[61](#bib.bib61), [62](#bib.bib62), [63](#bib.bib63)]. The pipeline
    approach is widely used since it simplifies the entire event extraction task.
    The pipeline-based event extraction method, as shown in Fig. [4](#S2.F4 "Figure
    4 ‣ 2.3.4 Sequence-to-structure Generation-based Task ‣ 2.3 Event Extraction Manner
    ‣ 2 Preliminary ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications"),
    converts event extraction tasks into a multi-stage classification problem. The
    required classifiers include: 1) A trigger classifier is used to determine whether
    the term is the event trigger and the type of event. 2) An argument classifier
    is used to determine whether the word is the argument of the event. 3) An argument
    role classifier is used to determine the category of arguments.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '基于管道的方法将所有子任务视为独立的分类问题[[61](#bib.bib61), [62](#bib.bib62), [63](#bib.bib63)]。由于它简化了整个事件提取任务，因此管道方法被广泛使用。基于管道的事件提取方法，如图[4](#S2.F4
    "Figure 4 ‣ 2.3.4 Sequence-to-structure Generation-based Task ‣ 2.3 Event Extraction
    Manner ‣ 2 Preliminary ‣ A Survey on Deep Learning Event Extraction: Approaches
    and Applications")所示，将事件提取任务转换为多阶段分类问题。所需的分类器包括：1）触发器分类器用于确定术语是否是事件触发器及事件类型。2）论据分类器用于确定单词是否为事件的论据。3）论据角色分类器用于确定论据的类别。'
- en: The classical deep learning-based event extraction model Dynamic Multi-Pooling
    Convolutional Neural Network (DMCNN) [[39](#bib.bib39)] uses two dynamic multi-pooling
    convolutional neural networks for trigger classification and argument classification.
    The trigger classification model identifies the trigger. If there is a trigger,
    the argument classification model is used to identify arguments and their roles.
    PLMEE [[37](#bib.bib37)] also uses two models employing trigger extraction and
    argument extraction. Argument extractor uses the result of trigger extraction
    to reason. It performs well through introducing Bidirectional Encoder Representation
    from Transformers (BERT) [[64](#bib.bib64)].
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的基于深度学习的事件提取模型动态多池卷积神经网络（DMCNN）[[39](#bib.bib39)]使用两个动态多池卷积神经网络进行触发器分类和论据分类。触发器分类模型识别触发器。如果存在触发器，则使用论据分类模型识别论据及其角色。PLMEE
    [[37](#bib.bib37)]也使用两个模型进行触发器提取和论据提取。论据提取器利用触发器提取结果进行推理。通过引入双向编码器表示的变换器（BERT）[[64](#bib.bib64)]，表现良好。
- en: Pipeline-based event extraction methods provide additional information for subsequent
    sub-tasks through previous sub-tasks, and take advantage of dependencies between
    subtasks. Du et al. [[41](#bib.bib41)] adopt a question answering method to implement
    event extraction. Firstly, the model identifies the trigger in the input sentence
    through the designed question template of the trigger. The input of the model
    includes the input sentence and question. Then, it classifies the event type according
    to the identified trigger. The trigger can provide additional information for
    trigger classification, but the result of wrong trigger identification can also
    affect trigger classification. Finally, the model identifies the event argument
    and classifies argument roles according to the schema corresponding to the event
    type. In argument extraction, the model utilizes the answers of the previous round
    of history content.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 基于管道的事件提取方法通过先前的子任务为后续子任务提供额外信息，并利用子任务之间的依赖关系。Du等人[[41](#bib.bib41)]采用问答方法实现事件提取。首先，模型通过设计的触发器问题模板识别输入句子中的触发器。模型的输入包括输入句子和问题。然后，根据识别出的触发器对事件类型进行分类。触发器可以为触发器分类提供额外信息，但错误的触发器识别结果也会影响触发器分类。最后，模型识别事件参数，并根据与事件类型对应的模式对参数角色进行分类。在参数提取中，模型利用上一轮历史内容的答案。
- en: The most significant defect of this method is error propagation. Intuitively,
    if there is an error in trigger identification in the first step, then the accuracy
    of argument identification will be lowed. Therefore, when using pipelines to extract
    events, there will be error cascading and task splitting problems. The pipeline
    event extraction method can extract event arguments by using the information of
    triggers. However, this requires high accuracy of trigger identification. A wrong
    trigger will seriously affect the accuracy rate of argument extraction. Therefore,
    the pipeline event extraction method considers the trigger as the core of an event.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法最显著的缺陷是错误传播。直观地说，如果在第一步的触发器识别中存在错误，那么论证识别的准确性将降低。因此，在使用管道提取事件时，将会出现错误级联和任务拆分的问题。管道事件提取方法可以通过使用触发器的信息来提取事件参数。然而，这要求触发器识别的准确性很高。错误的触发器会严重影响参数提取的准确率。因此，管道事件提取方法将触发器视为事件的核心。
- en: Summary. The pipeline-based method transforms the event extraction task into
    a multi-stage classification problem. The pipeline-based event extraction method
    first identifies the triggers, and argument identification is based on the result
    of the trigger identification. It considers the trigger as the core of an event.
    Yet, this staged strategy will lead to error propagation. The recognition error
    of the trigger will be passed to the argument classification stage, which will
    lead to the degradation of the overall performance. Moreover, because the trigger
    detection always precedes the argument detection, the argument won’t be considered
    while detecting triggers. Therefore, each link is independent and lacks interaction,
    ignoring the impact between them. Thus, the overall dependency relationship cannot
    be handled. The classic case is DMCNN [[39](#bib.bib39)].
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 总结。基于管道的方法将事件提取任务转化为多阶段分类问题。基于管道的事件提取方法首先识别触发器，参数识别则基于触发器识别的结果。它将触发器视为事件的核心。然而，这种阶段性策略会导致错误传播。触发器的识别错误会传递到参数分类阶段，从而导致整体性能的下降。此外，由于触发器检测总是优先于参数检测，因此在检测触发器时不会考虑参数。因此，每个环节都是独立的，缺乏互动，忽略了它们之间的影响。因此，无法处理整体依赖关系。经典案例是DMCNN
    [[39](#bib.bib39)]。
- en: '![Refer to caption](img/2f9debdf16fe4e07d4f79c8b237cb99d.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2f9debdf16fe4e07d4f79c8b237cb99d.png)'
- en: 'Figure 5: The simplified architecture of joint-based event extraction paradigm.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：基于联合的事件提取范式的简化架构。
- en: 3.2 Joint-based Paradigm
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 基于联合的范式
- en: 'Event extraction is of great practical value in NLP. Before using deep learning
    to model event extraction tasks, the joint learning method has been studied in
    event extraction. As shown in Fig. [5](#S3.F5 "Figure 5 ‣ 3.1 Pipeline-based Paradigm
    ‣ 3 Event Extraction Paradigm ‣ A Survey on Deep Learning Event Extraction: Approaches
    and Applications"), this method identifies the triggers and arguments according
    to candidate triggers and entities in the first stage. In the second stage, to
    avoid the error information propagation from event type, trigger classification
    and argument role classification are realized simultaneously. It classifies trigger
    “died” to Die event type, and argument “Baghdad” to Place argument role, etc.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '事件抽取在自然语言处理中的实际价值很大。在使用深度学习对事件抽取任务建模之前，已经在事件抽取中研究了联合学习方法。如图[5](#S3.F5 "Figure
    5 ‣ 3.1 Pipeline-based Paradigm ‣ 3 Event Extraction Paradigm ‣ A Survey on Deep
    Learning Event Extraction: Approaches and Applications")所示，该方法在第一阶段根据候选触发词和实体来识别触发词和参数。在第二阶段，为了避免事件类型的信息错误传播，同时实现触发词分类和参数角色分类。它将触发词“died”分类为Die事件类型，将参数“Baghdad”分类为Place参数角色，等等。'
- en: The deep learning event extraction method based on the joint model mainly uses
    the deep learning and the joint learning to interact with the feature learning,
    which can avoid the extended learning time and the complex feature engineering [[65](#bib.bib65),
    [66](#bib.bib66), [67](#bib.bib67)]. Li et al. [[38](#bib.bib38)] study the joint
    learning of trigger extraction and argument extraction tasks based on the traditional
    feature extraction method and obtain the optimal result through the structured
    perceptron model. Zhu et al. [[68](#bib.bib68)] design efficient discrete features,
    including local features of all information contained in feature words and global
    features that can connect trigger with argument information. Nguyen et al. [[40](#bib.bib40)]
    successfully construct local features and global features through deep learning
    and joint learning. It uses a recurrent neural network to combine event recognition
    and argument role classification. The local features constructed are text sequence
    features and local window features. The input text consists of word vectors, entity
    vectors, and event arguments. Then the text is transferred to the recurrent neural
    network model to obtain the sequence characteristics of the deep learning. A deep
    learning model with memory is also proposed to model it. It mainly aimed at the
    global characteristics between event triggers, between event arguments, and between
    event triggers and event arguments to improve the performance of tasks simultaneously.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 基于联合模型的深度学习事件抽取方法主要利用深度学习和联合学习与特征学习进行互动，这可以避免扩展学习时间和复杂的特征工程[[65](#bib.bib65),
    [66](#bib.bib66), [67](#bib.bib67)]。李等人[[38](#bib.bib38)]研究了基于传统特征提取方法的触发词提取和参数提取任务的联合学习，并通过结构感知机模型获得了最佳结果。朱等人[[68](#bib.bib68)]设计了高效的离散特征，包括特征词中包含的所有信息的局部特征和能够连接触发词与参数信息的全局特征。阮等人[[40](#bib.bib40)]通过深度学习和联合学习成功构建了局部特征和全局特征。它使用递归神经网络将事件识别和参数角色分类结合起来。构建的局部特征包括文本序列特征和局部窗口特征。输入文本由词向量、实体向量和事件参数组成。然后，文本被传递到递归神经网络模型中，以获得深度学习的序列特征。同时还提出了一种具有记忆的深度学习模型，主要针对事件触发词、事件参数以及事件触发词与事件参数之间的全局特征，以同时提高任务的性能。
- en: Event extraction involves related tasks such as entity recognition, which helps
    improve event extraction. Liu et al. [[69](#bib.bib69)] use the local characteristics
    of arguments to assist role classification. They adopted a joint learning task
    for entities for the first time, aiming to reduce the complexity of the task.
    The previous methods input the dataset with characteristics which are marked and
    output the event. Chen et al. [[70](#bib.bib70)] simplify the process, namely
    plain text input and output. In the middle of the process, it is the joint learning
    on event arguments. This joint learning factor mainly provides the relationship
    and entity information of different events within each input event.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 事件抽取涉及与实体识别等相关的任务，这些任务有助于提高事件抽取的效果。刘等人[[69](#bib.bib69)]利用参数的局部特征来辅助角色分类。他们首次采用了实体的联合学习任务，旨在减少任务的复杂性。之前的方法将具有特征的数据集输入并输出事件。陈等人[[70](#bib.bib70)]简化了这一过程，即纯文本输入和输出。在过程中间，是事件参数的联合学习。这一联合学习因素主要提供了每个输入事件中不同事件的关系和实体信息。
- en: The above joint learning method can achieve joint modeling event extraction
    of triggers and arguments. However, in the actual work process, the extraction
    of triggers and arguments is carried out successively rather than concurrently,
    which is an urgent problem to be discussed later. Besides, if an end-to-end mode
    is added to the deep learning, the feature selection workload will be significantly
    reduced, which will also be discussed later. The joint event extraction method
    avoids the influence of trigger identification error on event argument extraction,
    considering trigger and argument are equally important, but it cannot use the
    information of triggers.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 上述联合学习方法可以实现触发词和论元的联合建模提取。然而，在实际工作过程中，触发词和论元的提取是顺序进行的，而不是同时进行的，这仍是一个亟待讨论的问题。此外，如果将端到端模式添加到深度学习中，特征选择的工作量将显著减少，这也将在后续讨论中涉及。联合事件提取方法避免了触发词识别错误对事件论元提取的影响，认为触发词和论元同等重要，但无法利用触发词的信息。
- en: Summary. In order to overcome the shortcomings of the pipeline method, researchers
    proposed a joint method. The joint method constructs a joint learning model to
    trigger recognition and argument recognition, where the trigger and argument can
    mutually promote each other’s extraction effect. The experiment proves that the
    effect of the joint learning method is better than the pipeline learning method.
    The classic case is Joint Event Extraction via Recurrent Neural Networks (JRNN)
    [[40](#bib.bib40)]. The joint event extraction method avoids trigger identification
    on event argument extraction, but it cannot use the information of trigger. The
    joint event extraction method considers that the trigger and argument in an event
    are equally important. However, neither pipeline-based event extraction nor joint-based
    event extraction can avoid the impact of event type prediction errors on the performance
    of argument extraction. Moreover, these methods can not share information among
    different event types and learn each type independently, which is disadvantageous
    to the event extraction with only a small amount of labeled data.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 总结。为了克服流水线方法的缺点，研究人员提出了一种联合方法。联合方法构建了一个联合学习模型，用于触发词识别和论元识别，其中触发词和论元可以相互促进提取效果。实验证明，联合学习方法的效果优于流水线学习方法。经典案例是通过递归神经网络（JRNN）[[40](#bib.bib40)]的联合事件提取方法。联合事件提取方法避免了事件论元提取中的触发词识别，但它无法利用触发词的信息。联合事件提取方法认为事件中的触发词和论元同等重要。然而，无论是基于流水线的事件提取还是基于联合的事件提取，都无法避免事件类型预测错误对论元提取性能的影响。此外，这些方法不能在不同事件类型之间共享信息，而是独立学习每种类型，这对只有少量标注数据的事件提取是不利的。
- en: 'TABLE I: Basic information of different models. ED: event detection, AE: argument
    extraction, NER: named entity recognition, MRC: machine reading comprehension.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：不同模型的基本信息。ED：事件检测，AE：论元提取，NER：命名实体识别，MRC：机器阅读理解。
- en: '| Year | Model | Setting | Manner | Venue | Datasets | ED | AE | NER |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 年份 | 模型 | 设置 | 方式 | 会议 | 数据集 | ED | AE | NER |'
- en: '| 2021 | TEXT2EVENT [[43](#bib.bib43)] | supervised | generation | ACL | ACE05-EN,
    ERE-EN | ✓ | ✓ | - |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 2021 | TEXT2EVENT [[43](#bib.bib43)] | 监督 | 生成 | ACL | ACE05-EN, ERE-EN |
    ✓ | ✓ | - |'
- en: '| CasEE [[15](#bib.bib15)] | supervised | sequence labeling | ACL(Findings)
    | FewFC | ✓ | ✓ | - |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| CasEE [[15](#bib.bib15)] | 监督 | 序列标注 | ACL(Findings) | FewFC | ✓ | ✓ | -
    |'
- en: '| CLEVE [[71](#bib.bib71)] | supervised | classification | ACL | ACE, MAVEN
    | ✓ | ✓ | ✓ |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| CLEVE [[71](#bib.bib71)] | 监督 | 分类 | ACL | ACE, MAVEN | ✓ | ✓ | ✓ |'
- en: '| FEAE [[72](#bib.bib72)] | supervised | MRC | ACL | RAMS | ✓ | ✓ | ✓ |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| FEAE [[72](#bib.bib72)] | 监督 | MRC | ACL | RAMS | ✓ | ✓ | ✓ |'
- en: '| GIT [[73](#bib.bib73)] | supervised | classification | ACL | ChFinAnn ¹¹1http://www.cninfo.com.cn/new/index
    | ✓ | ✓ | ✓ |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| GIT [[73](#bib.bib73)] | 监督 | 分类 | ACL | ChFinAnn ¹¹1http://www.cninfo.com.cn/new/index
    | ✓ | ✓ | ✓ |'
- en: '| NoFPFN [[74](#bib.bib74)] | supervised | classification | ACL(Findings) |
    ChFinAnn | ✓ | ✓ | ✓ |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| NoFPFN [[74](#bib.bib74)] | 监督 | 分类 | ACL(Findings) | ChFinAnn | ✓ | ✓ |
    ✓ |'
- en: '| DualQA [[75](#bib.bib75)] | semi-supervised | MRC | AAAI | ACE, FewFC | -
    | ✓ | - |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| DualQA [[75](#bib.bib75)] | 半监督 | MRC | AAAI | ACE, FewFC | - | ✓ | - |'
- en: '| GRIT [[76](#bib.bib76)] | supervised | generation | EACL | (Message Understanding
    Conference) MUC-4 | ✓ | ✓ | - |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| GRIT [[76](#bib.bib76)] | 监督 | 生成 | EACL | (信息理解会议) MUC-4 | ✓ | ✓ | - |'
- en: '| Wen et al.[[77](#bib.bib77)] | supervised | classification | NAACL | ACE
    | ✓ | ✓ | - |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Wen 等人[[77](#bib.bib77)] | 监督 | 分类 | NAACL | ACE | ✓ | ✓ | - |'
- en: '|  | HPNet [[78](#bib.bib78)] | supervised | sequence labeling | COLING | ACE2005,
    Text Analysis Conference 2015 (TAC2015) | ✓ | ✓ | - |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '|  | HPNet [[78](#bib.bib78)] | 监督 | 序列标注 | COLING | ACE2005, 文本分析会议2015 (TAC2015)
    | ✓ | ✓ | - |'
- en: '|  | M2E2 [[79](#bib.bib79)] | weakly supervised | classification | ACL | M2E2
    | ✓ | ✓ | - |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|  | M2E2 [[79](#bib.bib79)] | 弱监督 | 分类 | ACL | M2E2 | ✓ | ✓ | - |'
- en: '|  | MQAEE [[42](#bib.bib42)] | supervised | MRC | EMNLP | ACE | ✓ | ✓ | -
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '|  | MQAEE [[42](#bib.bib42)] | 监督 | MRC | EMNLP | ACE | ✓ | ✓ | - |'
- en: '|  | Du et al. [[41](#bib.bib41)] | supervised | MRC | EMNLP | ACE | ✓ | ✓
    | - |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|  | Du 等人 [[41](#bib.bib41)] | 监督 | MRC | EMNLP | ACE | ✓ | ✓ | - |'
- en: '|  | Min et al. [[80](#bib.bib80)] | supervised | classification | LREC | ACE
    | - | ✓ | - |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '|  | Min 等人 [[80](#bib.bib80)] | 监督 | 分类 | LREC | ACE | - | ✓ | - |'
- en: '|  | Chen et al. [[81](#bib.bib81)] | supervised | MRC | EMNLP | ACE | - |
    ✓ | - |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|  | Chen 等人 [[81](#bib.bib81)] | 监督 | MRC | EMNLP | ACE | - | ✓ | - |'
- en: '|  | EEGCN [[82](#bib.bib82)] | supervised | sequence labeling | EMNLP(Findings)
    | ACE | ✓ | - | - |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|  | EEGCN [[82](#bib.bib82)] | 监督 | 序列标注 | EMNLP(发现) | ACE | ✓ | - | - |'
- en: '| 2019 | Doc2EDAG²²2The EDAG means entity-based directed acyclic graph. [[83](#bib.bib83)]
    | supervised | generation | EMNLP | ChFinAnn | ✓ | ✓ | ✓ |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 2019 | Doc2EDAG²²2EDAG指的是基于实体的有向无环图。[[83](#bib.bib83)] | 监督 | 生成 | EMNLP
    | ChFinAnn | ✓ | ✓ | ✓ |'
- en: '| Chen et al.[[81](#bib.bib81)] | supervised | MRC | arXiv | ACE | ✓ | ✓ |
    - |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人[[81](#bib.bib81)] | 监督 | MRC | arXiv | ACE | ✓ | ✓ | - |'
- en: '| GAIL-ELMo³³3The ELMo means embeddings from language models. [[84](#bib.bib84)]
    | supervised | sequence labeling | Data Intell. | ACE | ✓ | ✓ | ✓ |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| GAIL-ELMo³³3ELMo指的是语言模型中的嵌入。[[84](#bib.bib84)] | 监督 | 序列标注 | Data Intell.
    | ACE | ✓ | ✓ | ✓ |'
- en: '| DYGIE++ [[85](#bib.bib85)] | supervised | sequence labeling | EMNLP | ACE,
    SciERC, etc. | ✓ | ✓ | - |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| DYGIE++ [[85](#bib.bib85)] | 监督 | 序列标注 | EMNLP | ACE, SciERC 等 | ✓ | ✓ |
    - |'
- en: '| HMEAE [[86](#bib.bib86)] | supervised | classification | EMNLP | ACE, TAC-KBP
    | - | ✓ | ✓ |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| HMEAE [[86](#bib.bib86)] | 监督 | 分类 | EMNLP | ACE, TAC-KBP | - | ✓ | ✓ |'
- en: '| Han et al. [[87](#bib.bib87)] | supervised | classification | EMNLP | TB-Dense,
    MATRES | ✓ | ✓ | ✓ |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| Han 等人 [[87](#bib.bib87)] | 监督 | 分类 | EMNLP | TB-Dense, MATRES | ✓ | ✓ |
    ✓ |'
- en: '| PLMEE [[37](#bib.bib37)] | supervised | sequence labeling | ACL | ACE | ✓
    | ✓ | ✓ |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| PLMEE [[37](#bib.bib37)] | 监督 | 序列标注 | ACL | ACE | ✓ | ✓ | ✓ |'
- en: '| JointTransition [[58](#bib.bib58)] | supervised | classification | IJCAI
    | ACE | ✓ | ✓ | ✓ |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| JointTransition [[58](#bib.bib58)] | 监督 | 分类 | IJCAI | ACE | ✓ | ✓ | ✓ |'
- en: '| Joint3EE [[88](#bib.bib88)] | supervised | sequence labeling | AAAI | ACE
    | ✓ | ✓ | - |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| Joint3EE [[88](#bib.bib88)] | 监督 | 序列标注 | AAAI | ACE | ✓ | ✓ | - |'
- en: '| Chan et al. [[89](#bib.bib89)] | supervised | classification | ACL | ACE
    | ✓ | ✓ | ✓ |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| Chan 等人 [[89](#bib.bib89)] | 监督 | 分类 | ACL | ACE | ✓ | ✓ | ✓ |'
- en: '| Li et al. [[90](#bib.bib90)] | supervised | MRC | ACL | ACE, CoNLL04 | ✓
    | ✓ | - |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| Li 等人 [[90](#bib.bib90)] | 监督 | MRC | ACL | ACE, CoNLL04 | ✓ | ✓ | - |'
- en: '| 2018 | DCFEE⁴⁴4The DCFEE means document-level Chinese financial event extraction. [[91](#bib.bib91)]
    | distance supervision | sequence labeling | ACL | NO.(ANN, POS, NEG) | ✓ | ✓
    | - |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 2018 | DCFEE⁴⁴4DCFEE指的是文档级中文金融事件提取。[[91](#bib.bib91)] | 距离监督 | 序列标注 | ACL
    | NO.(ANN, POS, NEG) | ✓ | ✓ | - |'
- en: '| Zeng et al. [[92](#bib.bib92)] | distance supervision | sequence labeling
    | AAAI | FBWiki, ACE | ✓ | ✓ | ✓ |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| Zeng 等人 [[92](#bib.bib92)] | 距离监督 | 序列标注 | AAAI | FBWiki, ACE | ✓ | ✓ | ✓
    |'
- en: '| Huang et al.[[61](#bib.bib61)] | supervised | classification | ACL | ACE
    | ✓ | ✓ | - |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| Huang 等人[[61](#bib.bib61)] | 监督 | 分类 | ACL | ACE | ✓ | ✓ | - |'
- en: '| DEEB-RNN⁵⁵5The DEEB means document embedding enhanced Bi-RNN. [[93](#bib.bib93)]
    | supervised | classification | ACL | ACE | ✓ | - | - |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| DEEB-RNN⁵⁵5DEEB指的是文档嵌入增强型双向RNN。[[93](#bib.bib93)] | 监督 | 分类 | ACL | ACE |
    ✓ | - | - |'
- en: '| SELF [[94](#bib.bib94)] | supervised | classification | ACL | ACE, TAC-KBP
    | ✓ | - | - |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| SELF [[94](#bib.bib94)] | 监督 | 分类 | ACL | ACE, TAC-KBP | ✓ | - | - |'
- en: '| DBRNN [[95](#bib.bib95)] | supervised | classification | AAAI | ACE | ✓ |
    ✓ | ✓ |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| DBRNN [[95](#bib.bib95)] | 监督 | 分类 | AAAI | ACE | ✓ | ✓ | ✓ |'
- en: '| JMEE [[96](#bib.bib96)] | supervised | sequence labeling | EMNLP | ACE |
    ✓ | ✓ | ✓ |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| JMEE [[96](#bib.bib96)] | 监督 | 序列标注 | EMNLP | ACE | ✓ | ✓ | ✓ |'
- en: '| Ferguson et al.[[14](#bib.bib14)] | semi-supervised | classification | NAACL
    | ACE, TAC-KBP | ✓ | ✓ | - |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| Ferguson 等人[[14](#bib.bib14)] | 半监督 | 分类 | NAACL | ACE, TAC-KBP | ✓ | ✓ |
    - |'
- en: '| 2017 | DMCNN-MIL⁶⁶6The DMCNN-MIL means dynamic multi-pooling convolutional
    neural network with multi-instance learning. [[70](#bib.bib70)] | distance supervision
    | classification | ACL | ACE | ✓ | ✓ | ✓ |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 2017 | DMCNN-MIL⁶⁶6DMCNN-MIL指的是动态多池化卷积神经网络与多实例学习。[[70](#bib.bib70)] | 距离监督
    | 分类 | ACL | ACE | ✓ | ✓ | ✓ |'
- en: '| Liu et al.[[97](#bib.bib97)] | supervised | classification | ACL | ACE |
    ✓ | - | - |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| Liu 等人[[97](#bib.bib97)] | 监督 | 分类 | ACL | ACE | ✓ | - | - |'
- en: '| 2016 | RBPB⁷⁷footnotemark: 7 [[98](#bib.bib98)] | supervised | classification
    | ACL | ACE | ✓ | ✓ | - |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 2016 | RBPB⁷⁷脚注标记：7 [[98](#bib.bib98)] | 有监督 | 分类 | ACL | ACE | ✓ | ✓ | -
    |'
- en: '| Zeng et al.[[99](#bib.bib99)] | supervised | sequence labeling | NLPCC |
    ACE | ✓ | ✓ | - |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| Zeng et al.[[99](#bib.bib99)] | 有监督 | 序列标注 | NLPCC | ACE | ✓ | ✓ | - |'
- en: '| JRNN [[40](#bib.bib40)] | supervised | sequence labeling | NAACL | ACE |
    ✓ | ✓ | ✓ |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| JRNN [[40](#bib.bib40)] | 有监督 | 序列标注 | NAACL | ACE | ✓ | ✓ | ✓ |'
- en: '| JOINTEVENTENTITY [[13](#bib.bib13)] | supervised | sequence labeling | NAACL
    | ACE | ✓ | ✓ | ✓ |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| JOINTEVENTENTITY [[13](#bib.bib13)] | 有监督 | 序列标注 | NAACL | ACE | ✓ | ✓ |
    ✓ |'
- en: '| BDLSTM-TNNs [[100](#bib.bib100)] | supervised | classification | CCL | ACE
    | ✓ | ✓ | ✓ |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| BDLSTM-TNNs [[100](#bib.bib100)] | 有监督 | 分类 | CCL | ACE | ✓ | ✓ | ✓ |'
- en: '| Liu et al. [[69](#bib.bib69)] | supervised | classification | ACL | ACE |
    ✓ | - | - |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| Liu et al. [[69](#bib.bib69)] | 有监督 | 分类 | ACL | ACE | ✓ | - | - |'
- en: '| 2015 | DMCNN  [[39](#bib.bib39)] | supervised | classification | ACL | ACE
    | ✓ | ✓ | ✓ | ⁶⁶footnotetext: The RBPB means regularization-based pattern balancing
    method for event extraction.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '| 2015 | DMCNN [[39](#bib.bib39)] | 有监督 | 分类 | ACL | ACE | ✓ | ✓ | ✓ | ⁶⁶脚注：RBPB
    意为基于正则化的模式平衡方法用于事件提取。'
- en: 4 Deep Learning Event Extraction Models
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 深度学习事件提取模型
- en: 'Traditional event extraction methods are challenging to learn in-depth features,
    making it difficult to improve the task of event extraction that depends on complex
    semantic relations. Most recent event extraction works are based on a deep learning
    architecture like Convolutional Neural Networks (CNN) [[39](#bib.bib39), [101](#bib.bib101)],
    Recurrent Neural Network (RNN) [[102](#bib.bib102), [95](#bib.bib95)], Graph Neural
    Network (GNN) [[96](#bib.bib96), [82](#bib.bib82), [103](#bib.bib103), [104](#bib.bib104),
    [105](#bib.bib105)], Transformer [[37](#bib.bib37), [106](#bib.bib106), [107](#bib.bib107)],
    or other networks [[58](#bib.bib58), [78](#bib.bib78)]. As shown in TABLE [I](#S3.T1
    "TABLE I ‣ 3.2 Joint-based Paradigm ‣ 3 Event Extraction Paradigm ‣ A Survey on
    Deep Learning Event Extraction: Approaches and Applications"), we show the basic
    information of existing models according to the publish year. It includes the
    domain which is the model exploring, venue the model published, and datasets the
    model used. Furthermore, we conclude whether each model contains event detection,
    argument extraction and named entity recognition. The deep learning method can
    capture complex semantic relations and significantly improve multiple event extraction
    data sets. We introduce several typical event extraction models.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的事件提取方法难以深入学习特征，使得依赖复杂语义关系的事件提取任务难以改进。最近的大多数事件提取工作基于深度学习架构，如卷积神经网络 (CNN) [[39](#bib.bib39),
    [101](#bib.bib101)]、递归神经网络 (RNN) [[102](#bib.bib102), [95](#bib.bib95)]、图神经网络
    (GNN) [[96](#bib.bib96), [82](#bib.bib82), [103](#bib.bib103), [104](#bib.bib104),
    [105](#bib.bib105)]、变换器 [[37](#bib.bib37), [106](#bib.bib106), [107](#bib.bib107)]
    或其他网络 [[58](#bib.bib58), [78](#bib.bib78)]。如表 [I](#S3.T1 "TABLE I ‣ 3.2 基于联合的范式
    ‣ 3 事件提取范式 ‣ 深度学习事件提取综述：方法与应用") 所示，我们展示了现有模型的基本信息，根据发布时间进行分类。包括模型探讨的领域、模型发布的会议和模型使用的数据集。此外，我们总结了每个模型是否包含事件检测、论据提取和命名实体识别。深度学习方法能够捕捉复杂的语义关系，并显著改善多个事件提取数据集。我们介绍了几种典型的事件提取模型。
- en: 4.1 CNN-based Models
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 基于 CNN 的模型
- en: '![Refer to caption](img/9b9ec43d14770cba8076bda70f47d44b.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/9b9ec43d14770cba8076bda70f47d44b.png)'
- en: 'Figure 6: The architecture of CNN-based argument extraction. It illustrates
    processing of one instance with predicted trigger ’fired’ and candidate argument
    ’cameraman’.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：基于 CNN 的论据提取架构。它展示了一个实例的处理，其中预测触发词为“触发”且候选论据为“摄影师”。
- en: 'To automatically extract lexical and sentence-level features without using
    complex natural language processing tools, Chen et al. [[39](#bib.bib39)] introduce
    a word representation model, called DMCNN. It captures the meaningful semantic
    rules of words and adopts a framework based on a CNN to capture sentence-level
    clues. However, CNN can only capture the essential information in a sentence,
    and it uses a dynamic multi-pool layer to store more critical information based
    on event triggers and arguments. Event extraction is a two-stage multi-class classification
    realized by a dynamic multi-pool convolutional neural network with automatic learning
    features. The first stage is trigger classification. DMCNN classifies each word
    in the sentence to identify triggers. For a sentence having a trigger, this phase
    applies a similar DMCNN to assign arguments to the trigger and align the arguments’
    roles. Fig. [6](#S4.F6 "Figure 6 ‣ 4.1 CNN-based Models ‣ 4 Deep Learning Event
    Extraction Models ‣ A Survey on Deep Learning Event Extraction: Approaches and
    Applications") depicts the architecture of argument classification. Lexical-level
    feature representation and sentence-level features extraction are used to capture
    lexical clues and learn the sentences’ compositional semantic features.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '为了在不使用复杂自然语言处理工具的情况下自动提取词汇和句子级特征，Chen 等人 [[39](#bib.bib39)] 引入了一种词表示模型，称为 DMCNN。它捕捉了词语的有意义的语义规则，并采用基于
    CNN 的框架来捕捉句子级线索。然而，CNN 只能捕捉句子中的基本信息，它使用一个动态多池层来基于事件触发器和论元存储更多关键的信息。事件提取是一个通过动态多池卷积神经网络实现的两阶段多类分类过程，具有自动学习特征。第一阶段是触发器分类。DMCNN
    对句子中的每个词进行分类，以识别触发器。对于包含触发器的句子，该阶段应用类似的 DMCNN 来分配论元给触发器并对齐论元的角色。图 [6](#S4.F6 "Figure
    6 ‣ 4.1 CNN-based Models ‣ 4 Deep Learning Event Extraction Models ‣ A Survey
    on Deep Learning Event Extraction: Approaches and Applications") 描述了论元分类的架构。词汇级特征表示和句子级特征提取用于捕捉词汇线索并学习句子的组合语义特征。'
- en: CNN induces the underlying structures of the k-grams in the sentences. Thus,
    some researchers also study event extraction techniques based on convolutional
    neural networks. Nguyen et al. [[108](#bib.bib108)] use CNN to investigate the
    event detection task, which overcomes complex feature engineering and error propagation
    limitations compared with traditional feature-based approaches. But it relies
    extensively on other supervised modules and manual resources to obtain features.
    It is significantly superior to the feature-based method in terms of cross-domain
    generalization performance. Furthermore, to consider non-consecutive k-grams,
    Nguyen et al. [[102](#bib.bib102)] introduce non-consecutive CNN. CNN models apply
    in pipeline-based and joint-based paradigm through structured predictions with
    rich local and global characteristics to automatically learn hidden feature representations.
    Joint-based paradigm can mitigate error propagation problems compared with the
    pipeline-based approach and exploit the interdependencies between event triggers
    and argument roles.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 引入了句子中 k-grams 的潜在结构。因此，一些研究人员还研究了基于卷积神经网络的事件提取技术。Nguyen 等人 [[108](#bib.bib108)]
    使用 CNN 来研究事件检测任务，与传统的基于特征的方法相比，它克服了复杂特征工程和错误传播的限制。但是，它在很大程度上依赖于其他监督模块和手动资源来获取特征。在跨领域泛化性能方面，它显著优于基于特征的方法。此外，为了考虑非连续的
    k-grams，Nguyen 等人 [[102](#bib.bib102)] 引入了非连续 CNN。CNN 模型通过结构化预测应用于基于管道和联合的范式，结合丰富的局部和全局特征来自动学习隐藏的特征表示。与基于管道的方法相比，联合范式可以缓解错误传播问题，并利用事件触发器和论元角色之间的相互依赖关系。
- en: 4.2 RNN-based Models
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 基于 RNN 的模型
- en: 'In addition to the CNN-based event extraction method, some other researches
    are carried out on RNN. The RNN is used for modeling sequence information to extract
    arguments in the event, as shown in Fig. [7](#S4.F7 "Figure 7 ‣ 4.2 RNN-based
    Models ‣ 4 Deep Learning Event Extraction Models ‣ A Survey on Deep Learning Event
    Extraction: Approaches and Applications"). JRNN [[40](#bib.bib40)] is proposed
    with a bidirectional RNN for event extraction in a joint-based paradigm. It has
    an encoding stage and prediction stage. In the encoding stage, it uses RNN to
    summarize the context information. Furthermore, it predicts both trigger and argument
    roles in the prediction stage.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '除了基于 CNN 的事件提取方法，还有一些其他研究基于 RNN。RNN 用于建模序列信息，以提取事件中的论证，如图 [7](#S4.F7 "Figure
    7 ‣ 4.2 RNN-based Models ‣ 4 Deep Learning Event Extraction Models ‣ A Survey
    on Deep Learning Event Extraction: Approaches and Applications") 所示。JRNN [[40](#bib.bib40)]
    提出了一个双向 RNN 用于联合模型中的事件提取。它包括编码阶段和预测阶段。在编码阶段，它使用 RNN 总结上下文信息。此外，在预测阶段，它预测触发词和论证角色。'
- en: '![Refer to caption](img/ffc32eaa885887c4f57d527592680419.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ffc32eaa885887c4f57d527592680419.png)'
- en: 'Figure 7: The simplified architecture of RNN-based argument extraction for
    the input sentence “a man died when a tank fired in Baghdad” for candidate trigger
    “fired”.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：RNN 基于的论证提取的简化架构，用于输入句子“一个人在巴格达被坦克射击时死亡”中的候选触发词“射击”。
- en: Previous approaches relied heavily on language-specific knowledge and existing
    NLP tools. A more promising method from data automatically learning useful features,
    Feng et al. [[109](#bib.bib109)] develop a hybrid neural network to capture in
    the context of a specific sequence and pieces of information and use them for
    training a multilingual event detector. The model uses a Bidirectional long short-term
    memory (LSTM) to obtain the document’s sequence information that needs to be recognized.
    Then it uses the convolutional neural network to get the phrase chunk information
    in the document, combine the two kinds of information, and finally identify the
    trigger. The method are robust, efficient, and accurate detection for multiple
    languages (English, Chinese, and Spanish). The composite model is superior to
    the traditional feature-based approach in terms of cross-language generalization
    performance. The tree structure and sequence structure in a deep learning have
    better performance than a sequential structure. To avoid over-reliance on lexical
    and syntactic features, dependence bridge recursive neural network (DBRNN) [[95](#bib.bib95)]
    is based on bidirectional RNNs for event extraction. The DBRNN is enhanced by
    relying on bridging grammar-related words. DBRNN is an RNN-based framework that
    leverages the dependency graph information to extract event triggers and argument
    roles.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 以前的方法严重依赖于语言特定知识和现有 NLP 工具。Feng 等人 [[109](#bib.bib109)] 提出了从数据中自动学习有用特征的更有前景的方法，开发了一种混合神经网络以捕捉特定序列和信息片段的上下文，并用于训练多语言事件检测器。该模型使用双向长短期记忆（LSTM）来获取需要识别的文档序列信息。然后，它使用卷积神经网络来获取文档中的短语块信息，将这两种信息结合起来，最终识别触发词。这种方法在多语言（英语、中文和西班牙语）检测方面表现出强大的鲁棒性、高效性和准确性。该复合模型在跨语言泛化性能方面优于传统的基于特征的方法。在深度学习中，树结构和序列结构的表现优于序列结构。为了避免对词汇和句法特征的过度依赖，基于双向
    RNN 的依赖桥接递归神经网络（DBRNN） [[95](#bib.bib95)] 被提出用于事件提取。DBRNN 通过依赖于桥接语法相关词汇得到增强。DBRNN
    是一个基于 RNN 的框架，利用依赖图信息来提取事件触发词和论证角色。
- en: 4.3 Attention-based Models
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 基于注意力的模型
- en: 'The automatic extraction of event features by deep learning model and the enhancement
    of event features by external resources mainly focus on the information of event
    triggers, and less on the information of event arguments and inter-word dependencies.
    Sentence-level sequential modeling suffer a lot from the low efficiency in capturing
    very long-range dependencies. Furthermore, RNN-based and CNN-based models do not
    fully model the associations between events. The modeling of structural information
    in the attention mechanism has gradually attracted the attention of researchers.
    As research methods are constantly proposed, models that add attention mechanisms
    appear gradually, as shown in Fig. [8](#S4.F8 "Figure 8 ‣ 4.3 Attention-based
    Models ‣ 4 Deep Learning Event Extraction Models ‣ A Survey on Deep Learning Event
    Extraction: Approaches and Applications"). The attention mechanism’s feature determines
    that it can use global information to model local context without considering
    location information. It has a good application effect when updating the semantic
    representation of words.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '深度学习模型的事件特征自动提取以及外部资源对事件特征的增强主要关注事件触发词的信息，对事件论元和词间依赖的信息关注较少。句子级别的顺序建模在捕捉非常长距离依赖时效率较低。此外，基于RNN和CNN的模型未能完全建模事件之间的关联。注意力机制中结构信息的建模逐渐引起了研究者的关注。随着研究方法的不断提出，逐渐出现了加入注意力机制的模型，如图[8](#S4.F8
    "Figure 8 ‣ 4.3 Attention-based Models ‣ 4 Deep Learning Event Extraction Models
    ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications")所示。注意力机制的特点决定了它可以利用全局信息来建模局部上下文，而无需考虑位置信息。在更新词语语义表示时具有良好的应用效果。'
- en: By controlling the different weight information of each part of the sentence,
    the attention mechanism makes the model pay attention to the important feature
    information of the sentence while ignoring other unimportant feature information,
    and rationally allocate resources to extract more accurate results. At the same
    time, the attention mechanism itself can be used as a kind of alignment, explaining
    the alignment between input and output in the end-to-end model, to make the model
    more interpretable.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 通过控制句子每个部分的不同权重信息，注意力机制使模型关注句子的重点特征信息，同时忽略其他不重要的特征信息，并合理分配资源以提取更准确的结果。与此同时，注意力机制本身可以作为一种对齐方式，解释端到端模型中输入与输出之间的对齐，使模型更加可解释。
- en: '![Refer to caption](img/d5be0502a615ee9d184400f0197c4f30.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/d5be0502a615ee9d184400f0197c4f30.png)'
- en: 'Figure 8: The architecture of attention-based event extraction.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：基于注意力的事件抽取架构。
- en: 'Some researchers also use a hierarchical attention mechanism to conduct the
    global aggregation of information. The jointly multiple event extraction (JMEE)
    [[96](#bib.bib96)] composes of four modules: word representation, syntactic graph
    convolution network, self-attention trigger classification, and argument classification
    modules. The information flow is enhanced by introducing a syntax shortcut arc.
    The graph convolution network based on attention is used to jointly model the
    graph information to extract multiple event triggers and arguments. Furthermore,
    it optimizes a biased loss function when jointly extract event triggers and arguments
    to settle the dataset imbalances.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究者还使用层次化的注意力机制来进行信息的全局聚合。联合多事件抽取（JMEE）[[96](#bib.bib96)]由四个模块组成：词表示、句法图卷积网络、自注意力触发分类和论元分类模块。通过引入语法快捷弧来增强信息流。基于注意力的图卷积网络用于联合建模图信息，以提取多个事件触发词和论元。此外，它在联合提取事件触发词和论元时优化了一个有偏差的损失函数，以解决数据集的不平衡问题。
- en: 4.4 Graph Convolutional Network-based (GCN-based) Models
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 基于图卷积网络（GCN）的模型
- en: Syntactic representations present an efficient method for straight linking words
    to their informative context for event detection in sentences [[110](#bib.bib110),
    [111](#bib.bib111), [82](#bib.bib82), [33](#bib.bib33)]. Nguyen et al. [[110](#bib.bib110)]
    which investigate a convolutional neural network based on dependency trees to
    perform event detection are the first to integrate dependency tree relation information
    into neural event detection. The model uses the proposed model with graph convolutional
    networks (GCNs) [[111](#bib.bib111)] and entity mention-based pooling. They propose
    a novel pooling method that relies on entity mentions to aggregate convolution
    vectors. The model operates a pooling over the graph-based convolution vectors
    of the current word and the entity mentions in the sentences. The model aggregates
    convolution vectors to generate a single vector representation for event type
    prediction. The model is to explicitly model the information from entity mentions
    to improve performance for event detection.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 句法表示提供了一种高效的方法，将词汇直接链接到其信息上下文中，以进行事件检测[[110](#bib.bib110), [111](#bib.bib111),
    [82](#bib.bib82), [33](#bib.bib33)]。Nguyen等人[[110](#bib.bib110)]研究了一种基于依赖树的卷积神经网络来执行事件检测，首次将依赖树关系信息集成到神经事件检测中。该模型使用了带有图卷积网络（GCNs）[[111](#bib.bib111)]和基于实体提及的池化方法。它们提出了一种依赖实体提及来聚合卷积向量的新颖池化方法。该模型在当前词汇和句子中的实体提及的图卷积向量上进行池化。模型将卷积向量聚合为一个单一的向量表示，用于事件类型预测。该模型明确建模来自实体提及的信息，以提高事件检测的性能。
- en: 'In [[77](#bib.bib77)], the Text Analysis Conference Knowledge Base Population
    (TAC-KBP) time slot is used to fill the quaternary time representation proposed
    in the task, and the model predicts the earliest and latest start and end times
    of the event, thus representing the ambiguous time span of the event. The model
    constructs a document-level event graph for each input document based on shared
    arguments and time relationships and uses a graph-based attention network method
    to propagate time information on the graph, as shown in Fig. [9](#S4.F9 "Figure
    9 ‣ 4.4 Graph Convolutional Network-based (GCN-based) Models ‣ 4 Deep Learning
    Event Extraction Models ‣ A Survey on Deep Learning Event Extraction: Approaches
    and Applications"), where entities are underlined and events are in bold face.
    Wen et al. construct a document-level event diagram method based on event-event
    relationships for input documents. The event arguments in the document are extracted.
    The events then are arranged in the order of time according to keywords such as
    Before and After and the time logic of the occurrence of the events. Entity argument
    are shared among different events. The model implementation incorporates events
    into a more accurate timeline.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[77](#bib.bib77)]中，文本分析会议知识库填充（TAC-KBP）的时间槽用于填充任务中提出的四分之一时间表示，模型预测事件的最早和最晚开始时间及结束时间，从而表示事件的模糊时间跨度。模型基于共享的参数和时间关系，为每个输入文档构建文档级事件图，并使用基于图的注意力网络方法在图上传播时间信息，如图[9](#S4.F9
    "图 9 ‣ 4.4 基于图卷积网络（GCN）的模型 ‣ 4 深度学习事件抽取模型 ‣ 深度学习事件抽取综述：方法与应用")所示，其中实体用下划线标出，事件以粗体显示。温等人基于事件-事件关系构建了一个文档级事件图方法用于输入文档。文档中的事件参数被提取。然后，根据“Before”和“After”等关键词及事件发生的时间逻辑，将事件按时间顺序排列。实体参数在不同事件间共享。模型实现将事件纳入更准确的时间轴中。
- en: '![Refer to caption](img/e64904d7124ce6f0fc5d94dcfc8007a7.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/e64904d7124ce6f0fc5d94dcfc8007a7.png)'
- en: 'Figure 9: The example event graph. The solid line consists of event arguments,
    while the dashed line graph is constructed based on time relationships [[77](#bib.bib77)].'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：事件图示例。实线由事件参数组成，而虚线图是基于时间关系构建的[[77](#bib.bib77)]。
- en: '![Refer to caption](img/ef5160e078342f8ef31b7653f8b7121e.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/ef5160e078342f8ef31b7653f8b7121e.png)'
- en: 'Figure 10: The architecture of PLMEE [[37](#bib.bib37)] for extraction.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：PLMEE [[37](#bib.bib37)] 的提取架构。
- en: 4.5 Transformer-based Models
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 基于 Transformer 的模型
- en: 'It is challenging to exploit one argument that plays different roles in various
    events to improve event extraction. Yang et al. [[37](#bib.bib37)] employ a method
    to separate the argument prediction in terms of argument roles for overcoming
    the roles overlap problem. Moreover, this method automatically generates labeled
    data by editing prototypes and screening developed samples through ranking the
    quality due to inadequate training data. They present a framework, Pre-trained
    Language Model-based Event Extractor (PLMEE) [[37](#bib.bib37)], as shown in Fig.
    [10](#S4.F10 "Figure 10 ‣ 4.4 Graph Convolutional Network-based (GCN-based) Models
    ‣ 4 Deep Learning Event Extraction Models ‣ A Survey on Deep Learning Event Extraction:
    Approaches and Applications"). The PLMEE promotes event extraction by using a
    combination of an extraction model and a generation method based on pre-trained
    language models. It is a two-stage task, including trigger extraction and argument
    extraction, and consists of a trigger extractor and an argument extractor, both
    of which rely on BERT’s feature representation. Then it exploits the importance
    of roles to re-weight the loss function.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '利用一个在各种事件中扮演不同角色的论据来改进事件提取是一项挑战。杨等人[[37](#bib.bib37)]采用了一种方法，通过根据论据角色分离论据预测，以克服角色重叠问题。此外，由于训练数据不足，该方法通过编辑原型和通过对质量进行排名筛选开发的样本，自动生成标记数据。他们提出了一个框架，基于预训练语言模型的事件提取器（PLMEE）[[37](#bib.bib37)]，如图[10](#S4.F10
    "Figure 10 ‣ 4.4 Graph Convolutional Network-based (GCN-based) Models ‣ 4 Deep
    Learning Event Extraction Models ‣ A Survey on Deep Learning Event Extraction:
    Approaches and Applications")所示。PLMEE通过结合提取模型和基于预训练语言模型的生成方法来促进事件提取。这是一个两阶段任务，包括触发词提取和论据提取，包含一个触发词提取器和一个论据提取器，它们都依赖于BERT的特征表示。然后，它利用角色的重要性来重新加权损失函数。'
- en: GAIL [[84](#bib.bib84)] is an ELMo-based [[112](#bib.bib112)] model utilizing
    a generative adversarial network to help the model focus on harder-to-detect events.
    They propose an entity and event extraction framework based on generative adversarial
    imitation learning. It is an inverse reinforcement learning (IRL) method employing
    generative adversarial networks (GAN). The model directly evaluates the correct
    and incorrect labeling of instances in entity and event extraction through a dynamic
    mechanism using IRL.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: GAIL [[84](#bib.bib84)] 是一个基于ELMo[[112](#bib.bib112)] 的模型，利用生成对抗网络帮助模型关注更难检测的事件。他们提出了一个基于生成对抗模仿学习的实体和事件提取框架。这是一种逆向强化学习（IRL）方法，使用生成对抗网络（GAN）。该模型通过使用IRL的动态机制直接评估实体和事件提取中实例的正确和错误标记。
- en: DYGIE++¹¹1The DYGIE means dynamic graph information extraction. [[85](#bib.bib85)]
    is a BERT-based framework that models text spans and captures within-sentence
    and cross-sentence context. Much information extraction tasks, such as named entity
    recognition, relationship extraction, event extraction, and co-reference resolution,
    can benefit from the global context across sentences or from phrases that are
    not locally dependent. They carry out event extraction as additional task and
    span update in the relation graph of event trigger and its argument. The span
    representation is constructed on the basis of multi-sentence BERT coding.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: DYGIE++¹¹1DYGIE代表动态图信息提取。[[85](#bib.bib85)] 是一个基于BERT的框架，模型化文本跨度，并捕捉句内和跨句上下文。许多信息提取任务，如命名实体识别、关系提取、事件提取和共指解析，可以从跨句的全局上下文或从不依赖于局部的短语中受益。他们将事件提取作为附加任务，并在事件触发器及其论据的关系图中进行跨度更新。跨度表示是基于多句BERT编码构建的。
- en: Summary. Most of the traditional event extraction methods adopt the artificial
    construction method for feature representation and use the classification model
    to classify triggers and identify the role of the argument. In recent years, the
    deep learning has shown outstanding effects in image processing, speech recognition,
    and natural language processing, etc. To settle drawbacks of traditional methods,
    deep learning-based event extraction is systematically discussed. Before the emergence
    of BERT model, the mainstream method is to find the trigger from the text and
    judge the event type of the text according to the trigger. Recently, with the
    introduction of the event extraction model by BERT, the method of identifying
    event types based on the full text has become mainstream. It is because BERT has
    outstanding contextual representation ability and performs well in text classification
    tasks, especially when there is only a small amount of data.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 总结。大多数传统事件抽取方法采用人工构建特征表示的方法，并使用分类模型对触发词进行分类并识别论元的角色。近年来，深度学习在图像处理、语音识别和自然语言处理等领域表现出色。为了弥补传统方法的不足，系统地讨论了基于深度学习的事件抽取。在BERT模型出现之前，主流方法是从文本中找到触发词，并根据触发词判断文本的事件类型。最近，随着BERT引入事件抽取模型，基于全文识别事件类型的方法已成为主流。这是因为BERT具有出色的上下文表示能力，并在文本分类任务中表现良好，尤其是在数据量较少的情况下。
- en: 5 Event Extraction Scenarios
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 事件抽取场景
- en: There are some works focus on document-level, low-resource, multilingual, and
    Chinese event extraction, and their goal is to improve the ability of event extraction
    on different scenarios.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 有些工作专注于文档级、低资源、多语言和中文事件抽取，其目标是提高不同场景下的事件抽取能力。
- en: 5.1 Document-level Event Extraction Scenario
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 文档级事件抽取场景
- en: 'Document-level Event Extraction (DEE) aims to extract events across an article.
    Comparing with sentence-level event extraction (SEE), two challenges are proposed:
    (i) Arguments-scattering: arguments of one event may be scattered in multiple
    sentences in the document, which means that one event record can not be extracted
    from a single sentence; (ii) Multi-events: one document may simultaneously contain
    multiple events, which demands a holistic modeling about inter-dependency among
    the events. By far, existing DEE researches could be generally grouped into two
    lines.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 文档级事件抽取（DEE）旨在从一篇文章中提取事件。与句子级事件抽取（SEE）相比，提出了两个挑战：（i）论元分散：一个事件的论元可能分散在文档的多个句子中，这意味着一个事件记录无法从单个句子中提取；（ii）多事件：一个文档可能同时包含多个事件，这需要对事件之间的相互依赖关系进行整体建模。迄今为止，现有的DEE研究大致可以分为两类。
- en: The first line mainly focuses on extracting the scattering event arguments in
    the document, namely the first challenge. Early works [[113](#bib.bib113), [114](#bib.bib114)]
    cast document-level argument extraction as a slot-filling paradigm following the
    task setting of MUC-4 [[115](#bib.bib115)]. Further, researchers [[116](#bib.bib116),
    [117](#bib.bib117)] cast document-level event arguments as an Argument-linking
    problem in RAMS [[116](#bib.bib116)] dataset, which seeks to identify event arguments
    throughout the document of given event triggers. Still, the works above are conducted
    under the assumption that the event type or triggers are given in advance, which
    may be unrealistic in real-world scenarios.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 第一类主要关注在文档中提取分散的事件论元，即第一个挑战。早期工作[[113](#bib.bib113)、[114](#bib.bib114)]将文档级论元抽取视为一种槽填充范式，遵循MUC-4的任务设置[[115](#bib.bib115)]。进一步的研究者[[116](#bib.bib116)、[117](#bib.bib117)]将文档级事件论元视为RAMS[[116](#bib.bib116)]数据集中的论元链接问题，旨在识别给定事件触发词的整个文档中的事件论元。然而，上述工作是在事件类型或触发词事先给定的假设下进行的，这在现实场景中可能不够现实。
- en: Instead of directly identifying event arguments, the second line of works follow
    the detect-then-extraction paradigm similar in SEE to extract events from the
    document. Specifically, Yang et al. [[118](#bib.bib118)], Huang et al. [[119](#bib.bib119)]
    and Li et al. [[120](#bib.bib120)] first identify the specific event triggers
    to decide the event type, and then extract the event arguments beyond the sentence
    boundaries. Further, researchers [[83](#bib.bib83), [121](#bib.bib121), [122](#bib.bib122)]
    also attempt to conduct DEE in a trigger-free manner in ChFinAnn dataset [[83](#bib.bib83)],
    where event types are directly judged based on the document semantics. Du et al. [[123](#bib.bib123)]
    propose to simultaneously identify the event type and arguments in a generative
    template manner. These methods attempt to simultaneously tackle the two challenges
    of DEE, and have drawn much research attention.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 第二类工作并非直接识别事件论元，而是遵循类似于 SEE 的检测后提取范式，从文档中提取事件。具体而言，杨等人 [[118](#bib.bib118)]、黄等人
    [[119](#bib.bib119)] 和李等人 [[120](#bib.bib120)] 首先识别特定的事件触发词以决定事件类型，然后提取超出句子边界的事件论元。此外，研究人员
    [[83](#bib.bib83), [121](#bib.bib121), [122](#bib.bib122)] 还尝试在 ChFinAnn 数据集 [[83](#bib.bib83)]
    中以无触发词的方式进行 DEE，其中事件类型直接根据文档语义判断。杜等人 [[123](#bib.bib123)] 提出了在生成模板的方式下同时识别事件类型和论元的方法。这些方法试图同时解决
    DEE 的两个挑战，并引起了大量研究关注。
- en: 5.2 Open-domain Event Extraction Scenario
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 开放领域事件抽取场景
- en: In the absence of a predefined event pattern, open domain event extraction is
    designed to detect events from text and, in most cases, to cluster similar events
    through extracted event keywords. Event keywords are those words/phrases that
    primarily describe events, sometimes further divided into triggers and parameters.
    Open-domain event extraction [[16](#bib.bib16), [17](#bib.bib17), [18](#bib.bib18)]
    does not have a fixed argument role template. Therefore, arguments are often obtained
    by extracting key words. Chau et al.[[16](#bib.bib16)] propose a method to filter
    irrelevant headlines and perform preliminary event extraction, relying on public
    news headlines. Both price and text are fed back into a 3D convolutional neural
    network to learn correlations between events and market movements. Liu et al.
    [[17](#bib.bib17)] design a novel latent variable neural model using a unsupervised
    generative method to explore latent event type vectors and entity mention redundancy.
    Experimental results show that it is scalable to very large corpus.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在缺乏预定义事件模式的情况下，开放领域事件抽取旨在从文本中检测事件，并且在大多数情况下，通过提取的事件关键词将相似事件进行聚类。事件关键词是主要描述事件的单词/短语，有时进一步分为触发词和参数。开放领域事件抽取
    [[16](#bib.bib16), [17](#bib.bib17), [18](#bib.bib18)] 没有固定的论元角色模板。因此，论元通常通过提取关键词获得。Chau
    等人 [[16](#bib.bib16)] 提出了一个方法，用于过滤无关的头条新闻并进行初步事件抽取，该方法依赖于公开的新闻头条。价格和文本都反馈到一个 3D
    卷积神经网络中，以学习事件与市场变动之间的关联。刘等人 [[17](#bib.bib17)] 设计了一种新颖的潜变量神经模型，使用无监督生成方法来探索潜在事件类型向量和实体提及冗余。实验结果表明，该方法可以扩展到非常大的语料库。
- en: 5.3 Low-Resource Event Extraction Scenario
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 低资源事件抽取场景
- en: 'Due to the arduously expensive annotation in data emerging, there usually only
    exist insufficient data to train an accurate EE model with fully-supervised methods.
    In this survey, we term such a situation as the low-resource scenario. To alleviate
    the data sparsity, existing researches have explored distant supervision [[91](#bib.bib91)]
    methods to boost annotation data. Besides, several promising methods also investigate
    semi-supervised methods [[75](#bib.bib75), [14](#bib.bib14), [124](#bib.bib124)]
    or multilingual methods (See Sec. [5.4](#S5.SS4 "5.4 Multilingual Event Extraction
    Scenario ‣ 5 Event Extraction Scenarios ‣ A Survey on Deep Learning Event Extraction:
    Approaches and Applications")) to enrich supervision information. Recently, several
    researches have explored EE in three typical low-resource settings, including
    few-shot learning setting, zero-shot learning setting and incremental learning
    setting. In this section, we will briefly introduce recent EE methods in the above
    settings as a quick reference.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '由于数据标注的昂贵成本，通常只有不足的数据来训练一个准确的完全监督EE模型。在本调查中，我们将这种情况称为低资源场景。为了缓解数据稀缺问题，现有研究探索了远程监督[[91](#bib.bib91)]方法以增加标注数据。此外，一些有前景的方法还研究了半监督方法[[75](#bib.bib75),
    [14](#bib.bib14), [124](#bib.bib124)]或多语言方法（见第[5.4节](#S5.SS4 "5.4 Multilingual
    Event Extraction Scenario ‣ 5 Event Extraction Scenarios ‣ A Survey on Deep Learning
    Event Extraction: Approaches and Applications")）来丰富监督信息。最近，一些研究探讨了在三种典型的低资源设置下的EE，包括少样本学习设置、零样本学习设置和增量学习设置。在本节中，我们将简要介绍上述设置中的近期EE方法，以供快速参考。'
- en: Few-shot Learning Setting. Recently, few-shot learning methods [[125](#bib.bib125),
    [126](#bib.bib126)] have been widely researched in several NLP tasks [[127](#bib.bib127),
    [128](#bib.bib128)], which aims to conduct task predictions with extremely limited
    (few-shot, like 1-shot, 3-shot, … ) observed training samples. In event extraction
    area, most existing studies focus on the event detection subtask applied in the
    few-shot learning setting (FSED). The first line of works [[129](#bib.bib129),
    [130](#bib.bib130), [131](#bib.bib131), [132](#bib.bib132), [133](#bib.bib133),
    [134](#bib.bib134)] aims to conduct trigger classification given the candidate
    triggers with meta-learning methods. To approach real applications, the second
    line of works [[135](#bib.bib135), [136](#bib.bib136), [137](#bib.bib137)] jointly
    conducts trigger identification and trigger classification with only plain textual
    data. Among them, Cong et al. [[136](#bib.bib136)] further learn robust sequence
    label transition scores with a prototypical amortized conditional random fields
    (CRF), achieving significant improvements.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本学习设置。最近，少样本学习方法[[125](#bib.bib125), [126](#bib.bib126)]在多个NLP任务中得到了广泛研究[[127](#bib.bib127),
    [128](#bib.bib128)]，旨在利用极其有限的（如1-shot、3-shot等）观察训练样本进行任务预测。在事件抽取领域，大多数现有研究集中于在少样本学习设置（FSED）中应用的事件检测子任务。第一类工作[[129](#bib.bib129),
    [130](#bib.bib130), [131](#bib.bib131), [132](#bib.bib132), [133](#bib.bib133),
    [134](#bib.bib134)]旨在利用元学习方法对候选触发器进行触发器分类。为了接近实际应用，第二类工作[[135](#bib.bib135), [136](#bib.bib136),
    [137](#bib.bib137)]仅使用纯文本数据进行触发器识别和触发器分类。其中，Cong等人[[136](#bib.bib136)]进一步使用原型化的摊销条件随机场（CRF）学习鲁棒的序列标签转移分数，取得了显著的改进。
- en: Zero-shot Learning Setting. Most of the previous supervised EE methods rely
    on features derived from manual annotations, which cannot handle new event types
    without additional annotations. An extremely challenging low-resource scenario
    is to achieve EE without any available labeled data. To investigate the possibility
    of this scenario, recent researches [[61](#bib.bib61), [138](#bib.bib138)] explore
    zero-shot learning (ZSL) for event extraction. Huang et al. [[61](#bib.bib61)]
    firstly address this problem, which exploits the structural ontology of event
    mentions and types for representations, and conducts predictions with a semantic
    similarity measurement. Lyu et al. [[138](#bib.bib138)] further investigates transfer
    learning methods for new events, which formulates EE into textual entailment (TE)
    and question answering (QA) queries (e.g. “A city was attacked” entails “There
    is an attack”), and exploits pretrained TE/QA models for direct transfer. Though
    these methods still have a large gap from supervised approaches, they reveal an
    insightful vision and provide possible improvement directions for the extremely
    low-resource EE.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 零样本学习设置。大多数以往的监督事件抽取（EE）方法依赖于从人工标注中提取的特征，这些特征无法处理没有额外标注的新事件类型。在极具挑战性的低资源场景中，实现无标注数据的事件抽取是一个难题。为了探索这种场景的可能性，最近的研究[[61](#bib.bib61),
    [138](#bib.bib138)]探讨了零样本学习（ZSL）在事件抽取中的应用。黄等人[[61](#bib.bib61)]首次解决了这个问题，利用事件提及和类型的结构本体进行表示，并通过语义相似性度量进行预测。吕等人[[138](#bib.bib138)]进一步研究了针对新事件的迁移学习方法，将事件抽取表述为文本蕴涵（TE）和问答（QA）查询（例如，“一座城市遭到了攻击”蕴涵“发生了攻击”），并利用预训练的TE/QA模型进行直接迁移。尽管这些方法与监督方法仍存在较大差距，但它们揭示了有价值的视角，并为极低资源条件下的事件抽取提供了可能的改进方向。
- en: Incremental Learning Setting. Existing ED methods usually require a fixed number
    of event types, and perform once-and-for-all training on a fixed dataset. Such
    a paradigm usually encounters challenges when there continually occur new event
    types along with new emerging data. For realistic consideration, a practical ED
    system ought to incrementally learn new event types and simultaneously remain
    predictive on existing types, instead of requiring a fixed dataset to re-train
    all the event types again. Recent researches [[139](#bib.bib139), [140](#bib.bib140)]
    on incremental learning (also called continual learning or lifelong learning)
    focus on the catastrophic forgetting, where the learned system usually suffers
    from significant performance drop on old types when it adapts to new types. Cao
    et al. [[141](#bib.bib141)] is the first work to tackle the incremental ED, which
    solves catastrophic forgetting and semantic ambiguity issues by a proposed knowledge
    consolidation network, achieving effective performance on incremental ED.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 增量学习设置。现有的事件检测（ED）方法通常需要固定数量的事件类型，并在固定数据集上进行一次性训练。这种范式通常在新的事件类型和数据不断出现时面临挑战。实际应用中，实际的ED系统应该能够增量学习新的事件类型，并同时保持对现有类型的预测能力，而不是需要一个固定的数据集重新训练所有事件类型。最近的研究[[139](#bib.bib139),
    [140](#bib.bib140)]关注增量学习（也称为持续学习或终身学习），重点解决灾难性遗忘问题，即系统在适应新类型时通常会在旧类型上表现显著下降。曹等人[[141](#bib.bib141)]是首个解决增量ED问题的工作，通过提出的知识巩固网络解决了灾难性遗忘和语义模糊问题，在增量ED中取得了有效的表现。
- en: 5.4 Multilingual Event Extraction Scenario
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 多语言事件抽取场景
- en: Monolingual training for event extraction is also an effective method in low
    resource environments [[142](#bib.bib142), [143](#bib.bib143), [33](#bib.bib33)].
    Liu et al. [[143](#bib.bib143)] propose a new multilingual approach called gated
    multilingual attention (GMLATT) framework to address both problems simultaneously
    and develop consistent information in multilingual data through contextual attention
    mechanisms. It uses consistent evidence in multilingual data, models the credibility
    of cues provided by other languages, and controls information integration in various
    languages. Ahmad et al. [[33](#bib.bib33)] propose a graph attention transformer
    encoder (GATE) framework, which uses GCNS to learn language-independent sentences.
    The model embeds the dependency structure into the contextual representation.
    It introduces a self-attention mechanism to learn the dependencies between words
    with different syntactic distances. The method can capture the long distance dependencies
    and then calculate the syntactic distance matrix between words through the mask
    algorithm. It performs well in cross-language sentence-level relationships and
    event extraction.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在低资源环境中，单语训练也是一种有效的事件抽取方法[[142](#bib.bib142), [143](#bib.bib143), [33](#bib.bib33)]。Liu
    等人[[143](#bib.bib143)] 提出了一个新的多语言方法，称为门控多语言注意力（GMLATT）框架，以同时解决这两个问题，并通过上下文注意力机制在多语言数据中开发一致的信息。它使用多语言数据中的一致证据，建模其他语言提供的线索的可信度，并控制各种语言中的信息整合。Ahmad
    等人[[33](#bib.bib33)] 提出了一个图注意力变换器编码器（GATE）框架，该框架使用 GCNS 学习语言无关的句子。该模型将依赖结构嵌入到上下文表示中，引入自注意力机制以学习具有不同句法距离的词之间的依赖关系。该方法能够捕捉长距离依赖关系，并通过掩码算法计算词之间的句法距离矩阵。在跨语言句子级关系和事件抽取方面表现良好。
- en: 5.5 Chinese Event Extraction Scenario
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 中文事件抽取场景
- en: Comparing with event extraction in English corpus, Chinese Event Extraction
    can be regarded as a special case of event extraction, having particular properties
    and challenges. Early methods [[144](#bib.bib144), [145](#bib.bib145), [146](#bib.bib146),
    [147](#bib.bib147)] conduct Chinese EE using elaborately designed linguistic features.
    In the following, neural network based approaches [[99](#bib.bib99), [148](#bib.bib148)]
    are proposed to reduce the heavy rely on feature engineering. Note that comparing
    with English EE, Chinese EE suffer from the absence of natural word delimiters
    and are thus conducted at token-wise instead of word-wise. To alleviate the semantic
    limitation at token-wise in Chinese, exquisite methods are designed to incorporate
    the word-level information to enrich the token semantics. Specifically, Lin et
    al. [[149](#bib.bib149)] proposes Nugget Proposal Networks (NPN), which derives
    hybrid character representations for event trigger tagging, by capturing both
    the structural and semantic information from characters and words. Still, the
    scope of event triggers in NPN are restricted within a fix-sized window, making
    it inflexible and suffering from the overlapping between event triggers. Consequently,
    Ding et al. [[150](#bib.bib150)] propose Trigger-aware Lattice Neural Network
    (TLNN), which makes advantage of the Lattice-structure [[151](#bib.bib151)] to
    incorporate the word and character semantics. Since NPN and TLNN limit that each
    character could interact with only one matched word, Cui et al. [[152](#bib.bib152)]
    propose a heterogeneous graph equipped with two types of nodes (words/characters)
    and three kinds of edges to maximally preserve word-character interactions.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 与英语语料中的事件抽取相比，中文事件抽取可以被视为事件抽取的一个特殊情况，具有特定的属性和挑战。早期方法[[144](#bib.bib144), [145](#bib.bib145),
    [146](#bib.bib146), [147](#bib.bib147)] 使用精心设计的语言特征进行中文事件抽取。随后，基于神经网络的方法[[99](#bib.bib99),
    [148](#bib.bib148)] 被提出以减少对特征工程的高度依赖。值得注意的是，与英语事件抽取相比，中文事件抽取受到自然词界限缺失的影响，因此在 token
    级别而非词级别进行。为了缓解中文在 token 级别的语义限制，设计了精巧的方法将词级信息纳入以丰富 token 语义。具体而言，Lin 等人[[149](#bib.bib149)]
    提出了 Nugget Proposal Networks (NPN)，通过捕捉字符和词的结构信息和语义信息，为事件触发器标记生成混合字符表示。然而，NPN
    的事件触发器范围限制在固定大小的窗口内，使其不够灵活且受到事件触发器之间重叠的困扰。因此，Ding 等人[[150](#bib.bib150)] 提出了 Trigger-aware
    Lattice Neural Network (TLNN)，利用 Lattice-structure[[151](#bib.bib151)] 结合词和字符的语义。由于
    NPN 和 TLNN 限制每个字符只能与一个匹配的词互动，Cui 等人[[152](#bib.bib152)] 提出了一个异质图，配备了两种类型的节点（词/字符）和三种类型的边，以最大限度地保留词-字符互动。
- en: 'TABLE II: Summary statistics for the datasets. (Doc denotes the number of documents
    in dataset, Sen denotes the number of sentences in dataset).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：数据集的总结统计。 (文档表示数据集中的文档数量，句子表示数据集中的句子数量)。
- en: '| Datasets | Doc | Sen | Event Type | Language | Related Papers |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 文档 | 句子 | 事件类型 | 语言 | 相关论文 |'
- en: '| MUC-4 | 1700 | - | 5 | - | [[115](#bib.bib115)] |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| MUC-4 | 1700 | - | 5 | - | [[115](#bib.bib115)] |'
- en: '| Google | 11,909 | - | 30 | English | [[153](#bib.bib153)] |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| Google | 11,909 | - | 30 | 英语 | [[153](#bib.bib153)] |'
- en: '| Twitter | 1,000 | - | 20 | English | [[153](#bib.bib153)] |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| Twitter | 1,000 | - | 20 | 英语 | [[153](#bib.bib153)] |'
- en: '| NO.ANN, NO.POS, NO.NEG (DCFEE) | 2,976 | - | 4 | Chinese | [[91](#bib.bib91)]
    |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| NO.ANN, NO.POS, NO.NEG (DCFEE) | 2,976 | - | 4 | 中文 | [[91](#bib.bib91)]
    |'
- en: '| ChFinAnn (Doc2EDAG) | 32,040 | - | 5 | Chinese | [[83](#bib.bib83)] |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| ChFinAnn (Doc2EDAG) | 32,040 | - | 5 | 中文 | [[83](#bib.bib83)] |'
- en: '| ACE 2005 | 599 | 18,117 | 33 | Multi-language | [[33](#bib.bib33), [75](#bib.bib75),
    [42](#bib.bib42), [80](#bib.bib80), [89](#bib.bib89), [84](#bib.bib84), [143](#bib.bib143),
    [95](#bib.bib95), [154](#bib.bib154)] |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| ACE 2005 | 599 | 18,117 | 33 | 多语言 | [[33](#bib.bib33), [75](#bib.bib75),
    [42](#bib.bib42), [80](#bib.bib80), [89](#bib.bib89), [84](#bib.bib84), [143](#bib.bib143),
    [95](#bib.bib95), [154](#bib.bib154)] |'
- en: '| TAC KBP 2015 | 360 | 12,976 | 38 | English | [[14](#bib.bib14), [78](#bib.bib78)]
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| TAC KBP 2015 | 360 | 12,976 | 38 | 英语 | [[14](#bib.bib14), [78](#bib.bib78)]
    |'
- en: '| TAC KBP 2016 | 500 | 9,042 | 18 | Multi-language | [[86](#bib.bib86)] |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| TAC KBP 2016 | 500 | 9,042 | 18 | 多语言 | [[86](#bib.bib86)] |'
- en: '| Rich ERE | 50 |  |  | English | [[155](#bib.bib155)] |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| Rich ERE | 50 |  |  | 英语 | [[155](#bib.bib155)] |'
- en: '| FSED | - | 70,852 | 100 | English | [[156](#bib.bib156)] |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| FSED | - | 70,852 | 100 | 英语 | [[156](#bib.bib156)] |'
- en: '| GNBusiness | 12,985 | 1,450,336 | - | English | [[17](#bib.bib17)] |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| GNBusiness | 12,985 | 1,450,336 | - | 英语 | [[17](#bib.bib17)] |'
- en: '| FSD | - | 2,453 | 20 | English | [[153](#bib.bib153)] |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| FSD | - | 2,453 | 20 | 英语 | [[153](#bib.bib153)] |'
- en: '| FBI dataset | - | - | 3 | English | [[157](#bib.bib157)] |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| FBI 数据集 | - | - | 3 | 英语 | [[157](#bib.bib157)] |'
- en: '| RAMS | 3,993 | - | 139 | English | [[116](#bib.bib116)] |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| RAMS | 3,993 | - | 139 | 英语 | [[116](#bib.bib116)] |'
- en: '| WIKIEVENTS | 246 | 6,132 | - | English | [[120](#bib.bib120)] |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| WIKIEVENTS | 246 | 6,132 | - | 英语 | [[120](#bib.bib120)] |'
- en: '| MAVEN | 4,480 | 49,873 | 168 | English | [[22](#bib.bib22)] [[71](#bib.bib71)]
    [[158](#bib.bib158)] |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| MAVEN | 4,480 | 49,873 | 168 | 英语 | [[22](#bib.bib22)] [[71](#bib.bib71)]
    [[158](#bib.bib158)] |'
- en: 6 Event Extraction Corpus
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 事件提取语料库
- en: The availability of labeled datasets for event extraction has become the main
    driving force behind the fast advancement. In this section, we summarize these
    datasets.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 有标注数据集的可用性已成为快速发展的主要推动力。在这一部分，我们总结了这些数据集。
- en: 6.1 Document-level
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 文档级
- en: MUC-4. MUC-4 is proposed in the fourth Message Understanding Conference [[115](#bib.bib115)].
    The dataset consists of 1,700 documents, where five types of event are annotated
    with associated role filler templates.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: MUC-4。MUC-4 是在第四届消息理解会议提出的[[115](#bib.bib115)]。该数据集包含 1,700 篇文档，其中五种类型的事件使用相关角色填充模板进行了标注。
- en: Google. Google dataset ²²2http://data.gdeltproject.org/events/index.html is
    a subset of global database of events, language and tone (GDELT) Event Database,
    event-related words retrieve documents with 30 event types containing 11,909 news
    articles.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Google。Google 数据集²²2http://data.gdeltproject.org/events/index.html 是全球事件、语言和情感
    (GDELT) 事件数据库的一个子集，事件相关词汇检索文档包含 30 种事件类型，共 11,909 篇新闻文章。
- en: Twitter. The Twitter dataset is collected from tweets published in December
    2010 applying Twitter streaming application programming interface (API), including
    20 event types with 1,000 tweets.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter。Twitter 数据集是通过 Twitter 流媒体应用程序接口 (API) 从 2010 年 12 月发布的推文中收集的，包含 20
    种事件类型，共 1,000 条推文。
- en: 'NO.ANN, NO.POS, NO.NEG (DCFEE). In paper [[91](#bib.bib91)], researchers carry
    out experiments on four types of financial events: Equity Freeze event, Equity
    Pledge event, Equity Repurchase event and Equity Overweight event. A total of
    2976 announcements have been labeled by automatically generating data. The number
    of announcements (NO.ANN) represents the number of announcements can be labeled
    automatically for each event type. The number of positive case (NO.POS) represents
    the total number of positive case mentions. On the contrary, the number of negative
    mentions (NO.NEG) represents the number of negative mentions.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: NO.ANN, NO.POS, NO.NEG (DCFEE)。在论文[[91](#bib.bib91)]中，研究人员对四种类型的金融事件进行了实验：股权冻结事件、股权质押事件、股权回购事件和股权超配事件。共标注了
    2,976 个公告，数据是通过自动生成的。公告数量 (NO.ANN) 表示每种事件类型可以自动标注的公告数量。正面案例数量 (NO.POS) 表示正面案例的总提及次数。相反，负面提及数量
    (NO.NEG) 表示负面提及的数量。
- en: 'ChFinAnn (Doc2EDAG). In [[83](#bib.bib83)], a distant supervision-based (DS-based)
    event labeling is conducted based on ten years ChFinAnn4 documents ³³3http://www.cninfo.com.cn/new/index
    and human-summarized event knowledge bases. The new Chinese event dataset includes
    32,040 documents and 5 event types: Equity Freeze, Equity Repurchase, Equity Underweight,
    Equity Overweight and Equity Pledge.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ChFinAnn（Doc2EDAG）。在[[83](#bib.bib83)]中，基于十年的ChFinAnn4文档³³3http://www.cninfo.com.cn/new/index和人工总结的事件知识库，进行了一种基于远程监督（DS-based）的事件标注。新的中文事件数据集包括32,040份文档和5种事件类型：股权冻结、股权回购、股权减持、股权增持和股权质押。
- en: RAMS. Roles Across Multiple Sentences (RAMS) is released by Eber et al. [[116](#bib.bib116)]
    for Argument-Linking task, which aims to identify event arguments of given event
    triggers from a 5-sentence window. The dataset contains 3,194 documents, where
    9,124 events are annotated from news based on an ontology of 139 event types and
    65 roles.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: RAMS。多句角色（RAMS）由Eber等人发布[[116](#bib.bib116)]，用于论证链接任务，旨在从5句窗口中识别给定事件触发器的事件论据。该数据集包含3,194份文档，其中标注了9,124个事件，这些事件基于139种事件类型和65种角色的本体从新闻中提取。
- en: WIKIEVENTS. It is released by Li et al. [[120](#bib.bib120)] as a document-level
    benchmark dataset. The dataset is collected from English Wikipedia articles which
    describe real world events.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: WIKIEVENTS。由Li等人发布[[120](#bib.bib120)]，作为文档级基准数据集。该数据集收集自描述现实世界事件的英文维基百科文章。
- en: 6.2 Sentence-level
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 句子级别
- en: Automatic Content Extraction (ACE) [[1](#bib.bib1)]. The ACE 2005 is the most
    widely-used dataset in event extraction. It contains a complete set of training
    data in English, Arabic, and Chinese for the ACE 2005 technology evaluation. The
    corpus consists of various types of data annotated for entities, relationships,
    and events by the Language Data Alliance (LDC). It includes 599 documents with
    8 event types, 33 event subtypes, and 35 argument roles ⁴⁴4https://catalog.ldc.upenn.edu/LDC2006T06.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 自动内容提取（ACE）[[1](#bib.bib1)]。ACE 2005是事件提取中使用最广泛的数据集。它包含用于ACE 2005技术评估的英文、阿拉伯文和中文的完整训练数据集。该语料库由语言数据联盟（LDC）标注了实体、关系和事件的各种数据类型。它包括599份文档，涵盖8种事件类型、33种事件子类型和35种论据角色⁴⁴4https://catalog.ldc.upenn.edu/LDC2006T06。
- en: 'Text Analysis Conference Knowledge base Filling (TAC KBP). As a standalone
    component task in KBP, the goal of TAC KBP event tracking (from 2015 to 2017)
    is to extract information about the event so that it is suitable for input into
    the knowledge base. TAC KBP 2015 ⁵⁵5https://tac.nist.gov/2015/KBP/data.html defines
    9 different event types and 38 event subtypes in English. TAC KBP 2016 ⁶⁶6https://tac.nist.gov/2016/KBP/data.html
    and TAC KBP 2017 ⁷⁷7https://tac.nist.gov/2017/KBP/data.html have corpora in three
    languages: English, Chinese, and Spanish, where they own 8 event types and 18
    event subtypes.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分析会议知识库填充（TAC KBP）。作为KBP中的一个独立组件任务，TAC KBP事件追踪（2015年至2017年）的目标是提取有关事件的信息，以便适合输入到知识库中。TAC
    KBP 2015 ⁵⁵5https://tac.nist.gov/2015/KBP/data.html定义了9种不同的事件类型和38种事件子类型。TAC KBP
    2016 ⁶⁶6https://tac.nist.gov/2016/KBP/data.html和TAC KBP 2017 ⁷⁷7https://tac.nist.gov/2017/KBP/data.html包含三种语言的语料库：英语、中文和西班牙语，其中拥有8种事件类型和18种事件子类型。
- en: Rich ERE. It extends entities, relationships, and event ontologies, and extends
    the concept of what is Taggable. Rich ERE also introduced the concept of event
    jumping to address the pervasive challenge of event co-referencing, particularly
    with regard to event references within and between documents and granularity changes
    in event arguments, paving the way for the creation of (hierarchical or nested)
    cross-document representations of events.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: Rich ERE。它扩展了实体、关系和事件本体，并扩展了可标记的概念。Rich ERE还引入了事件跳跃的概念，以应对事件共同引用的普遍挑战，特别是关于文档内和文档间的事件引用以及事件论据的粒度变化，为创建（分层或嵌套的）跨文档事件表示铺平了道路。
- en: FSED. Based on ACE 2005 and TAC KBP 2017, FSED dataset [[135](#bib.bib135)]
    is a generated dataset tailored particularly for few-shot scenario. In details,
    it contains 70,852 mentions with 19 event types and 100 event subtypes.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: FSED。基于ACE 2005和TAC KBP 2017，FSED数据集[[135](#bib.bib135)]是一个特别为少样本场景定制的生成数据集。具体而言，它包含70,852个提及，涵盖19种事件类型和100种事件子类型。
- en: GNBusiness. GNBusiness [[17](#bib.bib17)] collects news reports from Google
    Business News to describe each event from different sources. It obtains 55,618
    business articles with 13,047 news clusters in 288 batches from Oct. 17, 2018,
    to Jan. 22, 2019. The full text corpus is released as GNBusinessFull-Text ⁸⁸8https://github.com/lx865712528/ACL2019-ODEE.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: GNBusiness。GNBusiness [[17](#bib.bib17)] 从 Google Business News 收集新闻报告，以描述来自不同来源的每个事件。它从
    2018 年 10 月 17 日到 2019 年 1 月 22 日获得了 55,618 篇商业文章和 13,047 个新闻集群。完整文本语料库作为 GNBusinessFull-Text
    发布 ⁸⁸8https://github.com/lx865712528/ACL2019-ODEE。
- en: FSD. The first story detection (FSD) dataset [[153](#bib.bib153)] is a story
    detection dataset including 2,499 tweets. Researchers filter out events mentioned
    in fewer than 15 samples considering events mentioned in several samples are usually
    not important. It includes 2,453 tweets with 20 events types.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: FSD。第一个故事检测（FSD）数据集 [[153](#bib.bib153)] 是一个包含2,499条推文的故事检测数据集。研究人员过滤掉在少于15个样本中提到的事件，因为在几个样本中提到的事件通常不重要。它包括2,453条推文和20种事件类型。
- en: FBI dataset. The FBI’s city-level hate crime reports (FBI) dataset [[157](#bib.bib157)]
    is built by scraping about 370k unlabeled news articles in the “Fire and Crime”
    category of Patch. It contains two classes for classifying if there is a specific
    hate crime in the text. Furthermore, it labels the attributes of hate crime articles.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: FBI 数据集。FBI 的城市级仇恨犯罪报告（FBI）数据集 [[157](#bib.bib157)] 是通过抓取约370k未标记的新闻文章在 Patch
    的“火灾和犯罪”类别中构建的。它包含两个类别，用于分类文本中是否存在特定的仇恨犯罪。此外，它还标记了仇恨犯罪文章的属性。
- en: 'TABLE III: The notations used in evaluation metrics.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 表 III：用于评估指标的符号。
- en: '| Notations | Descriptions |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 符号 | 描述 |'
- en: '| $T$ | The reference trigger |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| $T$ | 参考触发器 |'
- en: '| $TD$ | The detected trigger |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| $TD$ | 检测到的触发器 |'
- en: '| $N_{T}$ | The actual number of triggers |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| $N_{T}$ | 实际触发器数量 |'
- en: '| $N_{TD}$ | The number of detected triggers |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| $N_{TD}$ | 检测到的触发器数量 |'
- en: '| $T_{t}$ | The true event type |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| $T_{t}$ | 真实事件类型 |'
- en: '| $TD_{t}$ | The detected event type |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| $TD_{t}$ | 检测到的事件类型 |'
- en: '| $A$ | The reference argument |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| $A$ | 参考参数 |'
- en: '| $AD$ | The detected argument |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| $AD$ | 检测到的参数 |'
- en: '| $N_{A}$ | The actual number of arguments |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| $N_{A}$ | 实际参数数量 |'
- en: '| $N_{AD}$ | The number of detected arguments |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| $N_{AD}$ | 检测到的参数数量 |'
- en: '| $A_{r}$ | The detected argument role |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| $A_{r}$ | 检测到的参数角色 |'
- en: '| $AD_{r}$ | The number of detected arguments |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| $AD_{r}$ | 检测到的参数数量 |'
- en: 'TABLE IV: Comparison of event extraction methods on ACE 2005 using entity annotations.
    We show the performance of trigger classification and argument role classification
    sub-tasks.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 表 IV：使用实体注释在 ACE 2005 上的事件提取方法比较。我们展示了触发器分类和参数角色分类子任务的性能。
- en: '| Year-Method | Neural Network | External Resource | Paradigm | Trigger Classification
    | Role Classification |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 年-方法 | 神经网络 | 外部资源 | 模式 | 触发器分类 | 角色分类 |'
- en: '| P | R | F1 | P | R | F1 |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| P | R | F1 | P | R | F1 |'
- en: '| 2008 - Ji et al. [[159](#bib.bib159)] | - | - | - | 60.2 | 76.4 | 67.3 |
    51.3 | 36.4 | 42.6 |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| 2008 - Ji 等 [[159](#bib.bib159)] | - | - | - | 60.2 | 76.4 | 67.3 | 51.3
    | 36.4 | 42.6 |'
- en: '| 2010 - Liao et al. [[160](#bib.bib160)] | - | - | - | 68.7 | 68.9 | 68.8
    | 45.1 | 44.1 | 44.6 |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 2010 - Liao 等 [[160](#bib.bib160)] | - | - | - | 68.7 | 68.9 | 68.8 | 45.1
    | 44.1 | 44.6 |'
- en: '| 2011 - Hong et al. [[161](#bib.bib161)] | - | - | - | 72.9 | 64.3 | 68.3
    | 51.6 | 45.5 | 48.4 |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| 2011 - Hong 等 [[161](#bib.bib161)] | - | - | - | 72.9 | 64.3 | 68.3 | 51.6
    | 45.5 | 48.4 |'
- en: '| 2013 - Li et al. [[38](#bib.bib38)] | - | - | - | 73.7 | 62.3 | 67.5 | 64.7
    | 44.4 | 52.7 |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 2013 - Li 等 [[38](#bib.bib38)] | - | - | - | 73.7 | 62.3 | 67.5 | 64.7 |
    44.4 | 52.7 |'
- en: '| 2015 - Nguyen et al. [[108](#bib.bib108)] | ✓ | - | - | 71.8 | 66.4 | 69.0
    | - | - | - |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| 2015 - Nguyen 等 [[108](#bib.bib108)] | ✓ | - | - | 71.8 | 66.4 | 69.0 | -
    | - | - |'
- en: '| 2015 - DMCNN [[39](#bib.bib39)] | ✓ | - | Pipeline | 75.6 | 63.6 | 69.1 |
    62.2 | 46.9 | 53.5 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 2015 - DMCNN [[39](#bib.bib39)] | ✓ | - | 流水线 | 75.6 | 63.6 | 69.1 | 62.2
    | 46.9 | 53.5 |'
- en: '| 2016 - JRNN [[40](#bib.bib40)] | ✓ | - | Joint | 66.0 | 73.0 | 69.3 | 54.2
    | 56.7 | 55.4 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 2016 - JRNN [[40](#bib.bib40)] | ✓ | - | 联合 | 66.0 | 73.0 | 69.3 | 54.2 |
    56.7 | 55.4 |'
- en: '| 2016 - JOINTEVENTENTIT [[13](#bib.bib13)] | - | - | Joint | 75.1 | 63.3 |
    68.7 | 70.6 | 36.9 | 48.4 |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 2016 - JOINTEVENTENTIT [[13](#bib.bib13)] | - | - | 联合 | 75.1 | 63.3 | 68.7
    | 70.6 | 36.9 | 48.4 |'
- en: '| 2016 - NC-CNN [[102](#bib.bib102)] | ✓ | - | - | - | - | 71.3 | - | - | -
    |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 2016 - NC-CNN [[102](#bib.bib102)] | ✓ | - | - | - | - | 71.3 | - | - | -
    |'
- en: '| 2016 - HNN [[109](#bib.bib109)] | ✓ | - | - | 84.6 | 64.9 | 73.4 | - | -
    | - |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 2016 - HNN [[109](#bib.bib109)] | ✓ | - | - | 84.6 | 64.9 | 73.4 | - | -
    | - |'
- en: '| 2016 - BDLSTM-TNNs [[100](#bib.bib100)] | ✓ | - | Joint | 75.3 | 63.4 | 68.9
    | 62.9 | 47.5 | 54.1 |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 2016 - BDLSTM-TNNs [[100](#bib.bib100)] | ✓ | - | 联合 | 75.3 | 63.4 | 68.9
    | 62.9 | 47.5 | 54.1 |'
- en: '| 2017 - DMCNN-MIL [[70](#bib.bib70)] | ✓ | ✓ | Joint | 75.5 | 66.0 | 70.5
    | 62.8 | 50.1 | 55.7 |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 2017 - DMCNN-MIL [[70](#bib.bib70)] | ✓ | ✓ | 联合 | 75.5 | 66.0 | 70.5 | 62.8
    | 50.1 | 55.7 |'
- en: '| - 2018 - DEEB-RNN [[93](#bib.bib93)] | ✓ | - | Pipeline | 72.3 | 75.8 | 74
    | - | - | - |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| - 2018 - DEEB-RNN [[93](#bib.bib93)] | ✓ | - | 流水线 | 72.3 | 75.8 | 74 | -
    | - | - |'
- en: '| 2018 - SELF [[94](#bib.bib94)] | ✓ | - | Pipeline | 71.3 | 74.7 | 73.0 |
    - | - | - |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| 2018 - SELF [[94](#bib.bib94)] | ✓ | - | 流水线 | 71.3 | 74.7 | 73.0 | - | -
    | - |'
- en: '| 2018 - GMLATT [[143](#bib.bib143)] | ✓ | - | Joint | 78.9 | 66.9 | 72.4 |
    - | - | - |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 2018 - GMLATT [[143](#bib.bib143)] | ✓ | - | 联合 | 78.9 | 66.9 | 72.4 | -
    | - | - |'
- en: '| 2018 - Zeng et al. [[92](#bib.bib92)] | ✓ | ✓ | Pipeline | 85.3 | 79.9 |
    82.5 | 41.9 | 34.6 | 37.9 |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 2018 - Zeng 等人 [[92](#bib.bib92)] | ✓ | ✓ | 流水线 | 85.3 | 79.9 | 82.5 | 41.9
    | 34.6 | 37.9 |'
- en: '| 2019 - Liu et al.[[162](#bib.bib162)] | ✓ | - | Joint | 62.5 | 35.7 | 45.4
    | - | - | - |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 2019 - Liu 等人 [[162](#bib.bib162)] | ✓ | - | 联合 | 62.5 | 35.7 | 45.4 | -
    | - | - |'
- en: '| 2019 - GAIL-ELMo [[84](#bib.bib84)] | ✓ | - | Joint | 74.8 | 69.4 | 72.0
    | 61.6 | 45.7 | 52.4 |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 2019 - GAIL-ELMo [[84](#bib.bib84)] | ✓ | - | 联合 | 74.8 | 69.4 | 72.0 | 61.6
    | 45.7 | 52.4 |'
- en: '| 2019 - HMEAE [[86](#bib.bib86)] | ✓ | - | Joint | - | - | - | 62.2 | 56.6
    | 59.3 |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 2019 - HMEAE [[86](#bib.bib86)] | ✓ | - | 联合 | - | - | - | 62.2 | 56.6 |
    59.3 |'
- en: '| 2019 - JointTransition [[58](#bib.bib58)] | ✓ | - | Joint | 74.4 | 73.2 |
    73.8 | 55.7 | 51.1 | 53.3 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 2019 - JointTransition [[58](#bib.bib58)] | ✓ | - | 联合 | 74.4 | 73.2 | 73.8
    | 55.7 | 51.1 | 53.3 |'
- en: '| 2019 - PLMEE [[37](#bib.bib37)] | ✓ | - | Joint | 81.0 | 80.4 | 80.7 | 62.3
    | 54.2 | 58.0 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 2019 - PLMEE [[37](#bib.bib37)] | ✓ | - | 联合 | 81.0 | 80.4 | 80.7 | 62.3
    | 54.2 | 58.0 |'
- en: '| 2021-Li et al. [[163](#bib.bib163)] | ✓ | - | - | - | - | 71.1 | - | - |
    53.7 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 2021 - Li 等人 [[163](#bib.bib163)] | ✓ | - | - | - | - | 71.1 | - | - | 53.7
    |'
- en: '| 2021-GATE (En2ZH) [[33](#bib.bib33)] | ✓ | - | Joint | - | - | - | - | -
    | 63.2 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 2021 - GATE (En2ZH) [[33](#bib.bib33)] | ✓ | - | 联合 | - | - | - | - | - |
    63.2 |'
- en: '| 2021-CasEE [[15](#bib.bib15)] | ✓ | - | Joint | 77.9 | 78.5 | 78.2 | 71.3
    | 71.5 | 71.4 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 2021 - CasEE [[15](#bib.bib15)] | ✓ | - | 联合 | 77.9 | 78.5 | 78.2 | 71.3
    | 71.5 | 71.4 |'
- en: 'TABLE V: Comparison of event extraction methods on ACE 2005 without using entity
    annotations. Even Text2Event model does not use token annotations. We show the
    performance of trigger classification and argument role classification sub-tasks.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 表 V：在不使用实体注释的情况下对 ACE 2005 上事件抽取方法的比较。即使是 Text2Event 模型也没有使用令牌注释。我们展示了触发分类和论元角色分类子任务的表现。
- en: '| Year-Method | Neural Network | External Resource | Paradigm | Trigger Classification
    | Role Classification |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 年份-方法 | 神经网络 | 外部资源 | 模式 | 触发分类 | 角色分类 |'
- en: '| P | R | F1 | P | R | F1 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| P | R | F1 | P | R | F1 |'
- en: '| 2016 - Liu et al. [[69](#bib.bib69)] | ✓ | ✓ | Joint | 77.6 | 65.2 | 70.7
    | - | - | - |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 2016 - Liu 等人 [[69](#bib.bib69)] | ✓ | ✓ | 联合 | 77.6 | 65.2 | 70.7 | - |
    - | - |'
- en: '| 2016 - Huang et al.[[155](#bib.bib155)] | ✓ | ✓ | Joint | 80.7 | 50.1 | 61.8
    | 51.9 | 39.4 | 44.8 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 2016 - Huang 等人 [[155](#bib.bib155)] | ✓ | ✓ | 联合 | 80.7 | 50.1 | 61.8 |
    51.9 | 39.4 | 44.8 |'
- en: '| 2016 - RBPB [[98](#bib.bib98)] | ✓ | - | Pipeline | 70.3 | 67.5 | 68.9 |
    54.1 | 53.5 | 53.8 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 2016 - RBPB [[98](#bib.bib98)] | ✓ | - | 流水线 | 70.3 | 67.5 | 68.9 | 54.1
    | 53.5 | 53.8 |'
- en: '| 2017 - Liu et al. [[97](#bib.bib97)] | ✓ | - | Pipeline | 78.0 | 66.3 | 71.7
    | - | - | - |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 2017 - Liu 等人 [[97](#bib.bib97)] | ✓ | - | 流水线 | 78.0 | 66.3 | 71.7 | - |
    - | - |'
- en: '| 2018 - DEEB-RNN [[93](#bib.bib93)] | ✓ | - | Pipeline | 72.3 | 75.8 | 74
    | - | - | - |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| 2018 - DEEB-RNN [[93](#bib.bib93)] | ✓ | - | 流水线 | 72.3 | 75.8 | 74 | - |
    - | - |'
- en: '| 2018 - SELF [[94](#bib.bib94)] | ✓ | - | Pipeline | 71.3 | 74.7 | 73.0 |
    - | - | - |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 2018 - SELF [[94](#bib.bib94)] | ✓ | - | 流水线 | 71.3 | 74.7 | 73.0 | - | -
    | - |'
- en: '| 2018 - GMLATT [[143](#bib.bib143)] | ✓ | - | Joint | 78.9 | 66.9 | 72.4 |
    - | - | - |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 2018 - GMLATT [[143](#bib.bib143)] | ✓ | - | 联合 | 78.9 | 66.9 | 72.4 | -
    | - | - |'
- en: '| 2019 - Joint3EE [[88](#bib.bib88)] | ✓ | - | Joint | 68.0 | 71.8 | 69.8 |
    52.1 | 52.1 | 52.1 |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 2019 - Joint3EE [[88](#bib.bib88)] | ✓ | - | 联合 | 68.0 | 71.8 | 69.8 | 52.1
    | 52.1 | 52.1 |'
- en: '| 2019 - Chen et al.[[81](#bib.bib81)] | ✓ | - | Joint | 66.7 | 74.7 | 70.5
    | 44.3 | 40.7 | 42.4 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| 2019 - Chen 等人 [[81](#bib.bib81)] | ✓ | - | 联合 | 66.7 | 74.7 | 70.5 | 44.3
    | 40.7 | 42.4 |'
- en: '| 2019 - DYGIE++ [[85](#bib.bib85)] | ✓ | - | Joint | - | - | 69.7 | - | -
    | 48.8 |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| 2019 - DYGIE++ [[85](#bib.bib85)] | ✓ | - | 联合 | - | - | 69.7 | - | - | 48.8
    |'
- en: '| 2020 - Chen et al. [[81](#bib.bib81)] | ✓ | - | Pipeline | 66.7 | 74.7 |
    70.5 | 44.3 | 40.7 | 42.4 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 2020 - Chen 等人 [[81](#bib.bib81)] | ✓ | - | 流水线 | 66.7 | 74.7 | 70.5 | 44.3
    | 40.7 | 42.4 |'
- en: '| 2020 - MQAEE [[42](#bib.bib42)] | ✓ | - | Pipeline | - | - | 73.8 | - | -
    | 55.0 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 2020 - MQAEE [[42](#bib.bib42)] | ✓ | - | 流水线 | - | - | 73.8 | - | - | 55.0
    |'
- en: '| 2020 - Du et al. [[41](#bib.bib41)] | ✓ | - | Pipeline | 71.1 | 73.7 | 72.3
    | 56.7 | 50.2 | 53.3 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 2020 - Du 等人 [[41](#bib.bib41)] | ✓ | - | 流水线 | 71.1 | 73.7 | 72.3 | 56.7
    | 50.2 | 53.3 |'
- en: '| 2021-Text2Event [[43](#bib.bib43)] | ✓ | - | Joint | 69.6 | 74.4 | 71.9 |
    52.5 | 55.2 | 53.8 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 2021 - Text2Event [[43](#bib.bib43)] | ✓ | - | 联合 | 69.6 | 74.4 | 71.9 |
    52.5 | 55.2 | 53.8 |'
- en: 7 Metrics
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 指标
- en: For the four sub-tasks [[15](#bib.bib15), [37](#bib.bib37), [164](#bib.bib164),
    [100](#bib.bib100)] defined in event extraction, three metrics including Precision
    (P), Recall (R), and F1 are used to measure the performance.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 对于事件提取中定义的四个子任务 [[15](#bib.bib15), [37](#bib.bib37), [164](#bib.bib164), [100](#bib.bib100)]，使用包括精确度（P）、召回率（R）和F1在内的三个度量来衡量性能。
- en: 'Here, we denote an Indicator function $I(boolean)$: $I(True)=$1 and $I(False)=0$.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '在这里，我们表示指示函数 $I(boolean)$: $I(True)=$1 和 $I(False)=0$。'
- en: '1\. Trigger Identification (TI): a trigger is correctly identified if its span
    offsets exactly match a reference trigger. The corresponding metrics include:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 触发器识别（TI）：如果触发器的跨度偏移量完全匹配参考触发器，则该触发器被正确识别。相关的度量指标包括：
- en: '|  | $\footnotesize P_{TI}=\frac{\sum{I(TD=T\wedge TD_{L}=T_{L}\wedge TD_{R}=T_{R})}}{N_{TD}},$
    |  | (1) |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '|  | $\footnotesize P_{TI}=\frac{\sum{I(TD=T\wedge TD_{L}=T_{L}\wedge TD_{R}=T_{R})}}{N_{TD}},$
    |  | (1) |'
- en: '|  | $\footnotesize R_{TI}=\frac{\sum{I(TD=T\wedge TD_{L}=T_{L}\wedge TD_{R}=T_{R})}}{N_{T}},$
    |  | (2) |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '|  | $\footnotesize R_{TI}=\frac{\sum{I(TD=T\wedge TD_{L}=T_{L}\wedge TD_{R}=T_{R})}}{N_{T}},$
    |  | (2) |'
- en: '|  | $\footnotesize F1_{TI}=\frac{2*P_{TI}*R_{TI}}{(P_{TI}+R_{TI})},$ |  |
    (3) |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '|  | $\footnotesize F1_{TI}=\frac{2*P_{TI}*R_{TI}}{(P_{TI}+R_{TI})},$ |  |
    (3) |'
- en: where $TD$ is the detected trigger, $TD_{L}$ and $TD_{R}$ are the left and right
    boundaries of $TD$, $T$ is the reference trigger, $T_{L}$ and $T_{R}$ are the
    left and right boundaries of $T$, $N_{TD}$ and $N_{T}$ denotes the number of detected
    triggers and the actual number of triggers.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $TD$ 是检测到的触发器，$TD_{L}$ 和 $TD_{R}$ 是 $TD$ 的左右边界，$T$ 是参考触发器，$T_{L}$ 和 $T_{R}$
    是 $T$ 的左右边界，$N_{TD}$ 和 $N_{T}$ 分别表示检测到的触发器数量和实际触发器数量。
- en: '2\. Trigger Classification (TC): a trigger is correctly classified if its span
    offsets and event subtype exactly match a reference trigger. The corresponding
    metrics include:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 触发器分类（TC）：如果触发器的跨度偏移量和事件子类型完全匹配参考触发器，则该触发器被正确分类。相关的度量指标包括：
- en: '|  | $\footnotesize P_{TC}=\frac{\sum{I(TD=T\wedge TD_{t}=T_{t}\wedge TD_{L}=T_{L}\wedge
    TD_{R}=T_{R})}}{N_{TD}},$ |  | (4) |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '|  | $\footnotesize P_{TC}=\frac{\sum{I(TD=T\wedge TD_{t}=T_{t}\wedge TD_{L}=T_{L}\wedge
    TD_{R}=T_{R})}}{N_{TD}},$ |  | (4) |'
- en: '|  | $\footnotesize R_{TC}=\frac{\sum{I(TD=T\wedge TD_{t}=T_{t}\wedge TD_{L}=T_{L}\wedge
    TD_{R}=T_{R})}}{N_{T}},$ |  | (5) |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '|  | $\footnotesize R_{TC}=\frac{\sum{I(TD=T\wedge TD_{t}=T_{t}\wedge TD_{L}=T_{L}\wedge
    TD_{R}=T_{R})}}{N_{T}},$ |  | (5) |'
- en: '|  | $\footnotesize F1_{TC}=\frac{2*P_{TC}*R_{TC}}{(P_{TC}+R_{TC})},$ |  |
    (6) |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '|  | $\footnotesize F1_{TC}=\frac{2*P_{TC}*R_{TC}}{(P_{TC}+R_{TC})},$ |  |
    (6) |'
- en: where $TD_{type}$ and $T_{type}$ denote the detected event type and the true
    event type.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $TD_{type}$ 和 $T_{type}$ 分别表示检测到的事件类型和真实事件类型。
- en: '3\. Argument Identification (AI): an argument is correctly identified if its
    span offsets and corresponding event subtype exactly match a reference argument.
    The corresponding metrics include:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 参数识别（AI）：如果参数的跨度偏移量和对应的事件子类型完全匹配参考参数，则该参数被正确识别。相关的度量指标包括：
- en: '|  | $\footnotesize P_{AI}=\frac{\sum{I(AD=A\wedge TD_{t}=T_{t}\wedge AD_{L}=A_{L}\wedge
    AD_{R}=A_{R})}}{N_{AD}},$ |  | (7) |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '|  | $\footnotesize P_{AI}=\frac{\sum{I(AD=A\wedge TD_{t}=T_{t}\wedge AD_{L}=A_{L}\wedge
    AD_{R}=A_{R})}}{N_{AD}},$ |  | (7) |'
- en: '|  | $\footnotesize R_{AI}=\frac{\sum{I(AD=A\wedge TD_{t}=T_{t}\wedge AD_{L}=A_{L}\wedge
    AD_{R}=A_{R})}}{N_{A}},$ |  | (8) |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '|  | $\footnotesize R_{AI}=\frac{\sum{I(AD=A\wedge TD_{t}=T_{t}\wedge AD_{L}=A_{L}\wedge
    AD_{R}=A_{R})}}{N_{A}},$ |  | (8) |'
- en: '|  | $\footnotesize F1_{AI}=\frac{2*P_{AI}*R_{AI}}{(P_{AI}+R_{AI})},$ |  |
    (9) |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '|  | $\footnotesize F1_{AI}=\frac{2*P_{AI}*R_{AI}}{(P_{AI}+R_{AI})},$ |  |
    (9) |'
- en: where $AD$ is the detected argument, $AD_{L}$ and $AD_{R}$ are the left and
    right boundaries of $AD$, $A$ is the reference argument, $A_{L}$ and $A_{R}$ are
    the left and right boundaries of $A$, $N_{AD}$ and $N_{A}$ denotes the number
    of detected arguments and the actual number of arguments.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $AD$ 是检测到的参数，$AD_{L}$ 和 $AD_{R}$ 是 $AD$ 的左右边界，$A$ 是参考参数，$A_{L}$ 和 $A_{R}$
    是 $A$ 的左右边界，$N_{AD}$ 和 $N_{A}$ 分别表示检测到的参数数量和实际参数数量。
- en: '4\. Argument Classification (AC): an argument is correctly classified if its
    span offsets, corresponding event subtype, and argument role exactly match a reference
    argument. Its corresponding metrics include:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 参数分类（AC）：如果参数的跨度偏移量、对应的事件子类型和参数角色完全匹配参考参数，则该参数被正确分类。其相关的度量指标包括：
- en: '|  | $\footnotesize\begin{array}[]{l}\text{P}_{AC}=\frac{\sum I\left(AD=A\wedge
    TD_{t}=T_{t}\wedge AD_{r}=A_{r}\wedge AD_{L}=A_{L}\wedge AD_{R}=A_{R}\right)}{N_{AD}},\end{array}$
    |  | (10) |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '|  | $\footnotesize\begin{array}[]{l}\text{P}_{AC}=\frac{\sum I\left(AD=A\wedge
    TD_{t}=T_{t}\wedge AD_{r}=A_{r}\wedge AD_{L}=A_{L}\wedge AD_{R}=A_{R}\right)}{N_{AD}},\end{array}$
    |  | (10) |'
- en: '|  | $\footnotesize\begin{array}[]{l}\operatorname{R}_{AC}=\frac{\sum I\left(AD=A\wedge
    TD_{\text{t }}=T_{\text{t }}\wedge AD_{\text{r}}=A_{\text{r}}\wedge AD_{L}=A_{L}\wedge
    AD_{R}=A_{R}\right)}{N_{A}},\end{array}$ |  | (11) |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '|  | $\footnotesize\begin{array}[]{l}\operatorname{R}_{AC}=\frac{\sum I\left(AD=A\wedge
    TD_{\text{t }}=T_{\text{t }}\wedge AD_{\text{r}}=A_{\text{r}}\wedge AD_{L}=A_{L}\wedge
    AD_{R}=A_{R}\right)}{N_{A}},\end{array}$ |  | (11) |'
- en: '|  | $\footnotesize F1_{AC}=\frac{2*P_{AC}*R_{AC}}{(P_{AC}+R_{AC})},$ |  |
    (12) |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '|  | $\footnotesize F1_{AC}=\frac{2*P_{AC}*R_{AC}}{(P_{AC}+R_{AC})},$ |  |
    (12) |'
- en: where $AD_{r}$ and $A_{r}$ denote the detected argument role and the true argument
    role.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$AD_{r}$和$A_{r}$分别表示检测到的论元角色和真实的论元角色。
- en: 8 Quantitative Results
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 定量结果
- en: 'This section mainly summarizes existing event extraction work and compares
    performance on the ACE 2005 dataset, as shown in Table [IV](#S6.T4 "TABLE IV ‣
    6.2 Sentence-level ‣ 6 Event Extraction Corpus ‣ A Survey on Deep Learning Event
    Extraction: Approaches and Applications") and [V](#S6.T5 "TABLE V ‣ 6.2 Sentence-level
    ‣ 6 Event Extraction Corpus ‣ A Survey on Deep Learning Event Extraction: Approaches
    and Applications"). The evaluation metrics include precision, recall, and F1.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '本节主要总结了现有的事件抽取工作，并在ACE 2005数据集上比较了性能，如表[IV](#S6.T4 "TABLE IV ‣ 6.2 Sentence-level
    ‣ 6 Event Extraction Corpus ‣ A Survey on Deep Learning Event Extraction: Approaches
    and Applications")和[V](#S6.T5 "TABLE V ‣ 6.2 Sentence-level ‣ 6 Event Extraction
    Corpus ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications")所示。评估指标包括准确率、召回率和F1值。'
- en: 'In recent years, event extraction methods are primarily based on deep learning
    models. As shown in Table [IV](#S6.T4 "TABLE IV ‣ 6.2 Sentence-level ‣ 6 Event
    Extraction Corpus ‣ A Survey on Deep Learning Event Extraction: Approaches and
    Applications"), in terms of the value of F1, the deep learning-based method is
    superior to the machine learning-based method and pattern matching method in both
    event detection and argument extraction. GATE (En2ZH)⁹⁹9En2ZH means that the model
    trained on English and evaluated on Chinese. [[33](#bib.bib33)] is under single-source
    transfer from English to Chinese, which performs well on argument role classification
    task. Li et al. [[163](#bib.bib163)] propose a document-level neural event argument
    extraction model. It is applied for ACE 2005 for zero-shot event extraction seen
    all event types. We can get the validity of the event extraction method based
    on deep learning models. It may indicate that the deep learning-based method can
    better learn the dependencies among arguments in the event extraction task. In
    the deep learning-based model, the BERT-based approach performs the best, both
    in Table [IV](#S6.T4 "TABLE IV ‣ 6.2 Sentence-level ‣ 6 Event Extraction Corpus
    ‣ A Survey on Deep Learning Event Extraction: Approaches and Applications") and
    [V](#S6.T5 "TABLE V ‣ 6.2 Sentence-level ‣ 6 Event Extraction Corpus ‣ A Survey
    on Deep Learning Event Extraction: Approaches and Applications"). It shows that
    BERT can better learn the context information of the sentence and learn word representation
    according to the current text. It better learns the semantic association of words
    in the current context and helps to learn the association between arguments.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '近年来，事件抽取方法主要基于深度学习模型。如表[IV](#S6.T4 "TABLE IV ‣ 6.2 Sentence-level ‣ 6 Event
    Extraction Corpus ‣ A Survey on Deep Learning Event Extraction: Approaches and
    Applications")所示，在F1值方面，基于深度学习的方法在事件检测和论元抽取方面均优于基于机器学习的方法和模式匹配方法。GATE (En2ZH)⁹⁹9En2ZH意味着模型在英语上训练并在中文上评估。[[33](#bib.bib33)]在从英语到中文的单源转移下表现良好。Li等人[[163](#bib.bib163)]提出了一种文档级神经事件论元抽取模型，应用于ACE
    2005进行零样本事件抽取，涵盖所有事件类型。这表明基于深度学习模型的事件抽取方法具有有效性，可能表明基于深度学习的方法能够更好地学习事件抽取任务中论元之间的依赖关系。在深度学习模型中，基于BERT的方法表现最佳，无论在表[IV](#S6.T4
    "TABLE IV ‣ 6.2 Sentence-level ‣ 6 Event Extraction Corpus ‣ A Survey on Deep
    Learning Event Extraction: Approaches and Applications")还是[V](#S6.T5 "TABLE V
    ‣ 6.2 Sentence-level ‣ 6 Event Extraction Corpus ‣ A Survey on Deep Learning Event
    Extraction: Approaches and Applications")中。这表明BERT可以更好地学习句子的上下文信息，并根据当前文本学习词表示，更好地学习当前上下文中的词汇语义关联，并有助于学习论元之间的关联。'
- en: Comparing the pipeline based methods (RBPB [[98](#bib.bib98)], and DEEB-RNN
    [[93](#bib.bib93)]) with the join based methods (JRNN [[40](#bib.bib40)], and
    DBRNN [[95](#bib.bib95)]) without Transformer [[165](#bib.bib165)], it can be
    seen that the event extraction method of the joint model is better than the pipeline
    model, especially for the argument role classification task. From DMCNN [[39](#bib.bib39)],
    and DMCNN-MIL [[70](#bib.bib70)], it can be concluded that when external resources
    are used on deep learning-based methods, the effect is significantly improved
    and slightly higher than the joint model. Zeng et al. [[92](#bib.bib92)] introduce
    external resources, improving the performance of trigger classification on precision
    and F1\. Thus, it may show that increasing external knowledge is an effective
    method, but it still needs to be explored to introduce external knowledge into
    the argument extraction.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 比较基于管道的方法（RBPB [[98](#bib.bib98)]，和 DEEB-RNN [[93](#bib.bib93)]）与基于联合的方法（JRNN
    [[40](#bib.bib40)]，和 DBRNN [[95](#bib.bib95)]），在没有 Transformer [[165](#bib.bib165)]
    的情况下，可以看出联合模型的事件提取方法优于管道模型，特别是在论元角色分类任务上。从 DMCNN [[39](#bib.bib39)] 和 DMCNN-MIL
    [[70](#bib.bib70)] 可以得出，当在基于深度学习的方法中使用外部资源时，效果显著提升，并略高于联合模型。Zeng 等人 [[92](#bib.bib92)]
    引入外部资源，提高了触发分类的精度和 F1 值。因此，这可能表明增加外部知识是一种有效的方法，但仍需探索将外部知识引入论元提取中。
- en: 9 Event Extraction Applications
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 事件提取应用
- en: In this section, we introduce several event-related applications, which can
    be regarded as direct downstream tasks of event extraction. Generally, the identified
    events can be used for event graph construction [[166](#bib.bib166)], event evolution
    analysis [[167](#bib.bib167)] and other event-based NLP applications [[168](#bib.bib168)],
    such as question answering [[169](#bib.bib169), [170](#bib.bib170)] and reading
    comprehension [[171](#bib.bib171)]. Among the tasks, we focus on three widely
    researched tasks associated with events, namely script event prediction (SEP),
    event factuality identification (EFI) and event relation extraction (ERE).
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了几个与事件相关的应用，这些应用可以视为事件提取的直接下游任务。通常，识别的事件可以用于事件图构建 [[166](#bib.bib166)]、事件演变分析
    [[167](#bib.bib167)] 以及其他基于事件的 NLP 应用 [[168](#bib.bib168)]，如问答 [[169](#bib.bib169)，[170](#bib.bib170)]
    和阅读理解 [[171](#bib.bib171)]。在这些任务中，我们重点关注与事件相关的三个广泛研究的任务，即脚本事件预测（SEP）、事件真实性识别（EFI）和事件关系提取（ERE）。
- en: 9.1 Event Factuality Identification
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1 事件真实性识别
- en: 'Event factuality identification (EFI) aims to identify the degree of certainty
    about whether events actually occur or not in the real world, which can be seen
    as a downstream task of EE in event knowledge graph construction [[172](#bib.bib172)].
    Generally, event factuality can be classified into five categories [[173](#bib.bib173)]:
    certain positive (certainly happening, CT+), certain negative (certainly not happening,
    CT-), possible positive (possibly happening, PS+), possible negative (possibly
    not happening, PS-) and underspecified (events’ factuality cannot be identified,
    Uu). Therefore, an EFI model ought to be able to predict the factuality of the
    event that is PS+.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 事件真实性识别（EFI）旨在识别事件是否在现实世界中实际发生的确定性程度，这可以视为事件知识图构建中的 EE 下游任务 [[172](#bib.bib172)]。一般而言，事件真实性可以分为五类
    [[173](#bib.bib173)]：确定正面（肯定发生，CT+），确定负面（肯定不发生，CT-），可能正面（可能发生，PS+），可能负面（可能不发生，PS-）和未指定（事件真实性无法识别，Uu）。因此，EFI
    模型应能够预测事件的真实性为 PS+。
- en: Most existing EFI studies focus on the sentence-level task [[174](#bib.bib174),
    [175](#bib.bib175), [176](#bib.bib176), [177](#bib.bib177)]. The early works on
    this task mainly employ rule-based methods [[178](#bib.bib178), [173](#bib.bib173),
    [179](#bib.bib179)] or machine learning methods with manually designed features [[180](#bib.bib180),
    [181](#bib.bib181), [175](#bib.bib175), [174](#bib.bib174), [182](#bib.bib182),
    [183](#bib.bib183)]. In recent years, neural networks have been introduced into
    the EFI task, and achieve state-of-the-art performance [[176](#bib.bib176), [184](#bib.bib184),
    [185](#bib.bib185), [186](#bib.bib186), [177](#bib.bib177)], which usually adopt
    generative adversarial networks [[187](#bib.bib187)] or graph neural networks [[188](#bib.bib188)]
    to capture enriched textual information. Despite these successful efforts, sentence-level
    event factuality can easily encounter expression conflicts in texts. To this end,
    Qian et al. [[189](#bib.bib189)] propose the document-level EFI task with adversarial
    neural network. Besides, Cao et al. [[172](#bib.bib172)] further exploits the
    uncertainty of local information and the global structure within documents, and
    achieves significant improvements on document-level EFI task.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的 EFI 研究大多数集中在句子级任务上 [[174](#bib.bib174), [175](#bib.bib175), [176](#bib.bib176),
    [177](#bib.bib177)]。早期的研究主要采用基于规则的方法 [[178](#bib.bib178), [173](#bib.bib173),
    [179](#bib.bib179)] 或者使用手动设计特征的机器学习方法 [[180](#bib.bib180), [181](#bib.bib181),
    [175](#bib.bib175), [174](#bib.bib174), [182](#bib.bib182), [183](#bib.bib183)]。近年来，神经网络被引入到
    EFI 任务中，并取得了最先进的性能 [[176](#bib.bib176), [184](#bib.bib184), [185](#bib.bib185),
    [186](#bib.bib186), [177](#bib.bib177)]，这些方法通常采用生成对抗网络 [[187](#bib.bib187)] 或图神经网络 [[188](#bib.bib188)]
    来捕捉丰富的文本信息。尽管有这些成功的努力，但句子级事件事实性仍然容易在文本中遇到表达冲突。为此，Qian 等人 [[189](#bib.bib189)]
    提出了具有对抗神经网络的文档级 EFI 任务。此外，Cao 等人 [[172](#bib.bib172)] 进一步利用了文档中局部信息的不确定性和全球结构，并在文档级
    EFI 任务上取得了显著的改进。
- en: 9.2 Event Relation Extraction
  id: totrans-314
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2 事件关系提取
- en: Extracting event relations is an important yet challenging task for constructing
    event knowledge graph [[166](#bib.bib166)], which aims to detect the relations
    between the identified events, and thus can also be seen as the downstream tasks
    of event extraction. Generally, existing event relation extraction studies (ERE)
    mainly focus on three event relation types, including co-referential relation,
    causal relation and temporal relation. Since the three relation types are usually
    investigated separately and have no consistent task formulation so far, this section
    will briefly introduce the above three event relation extraction problems separately
    as different tasks. For more detailed event relation extraction reviews, we recommend
    the readers to Liu et al. [[166](#bib.bib166)].
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 提取事件关系是构建事件知识图谱的一项重要而具有挑战性的任务 [[166](#bib.bib166)]，旨在检测已识别事件之间的关系，因此也可以视为事件提取的下游任务。通常，现有的事件关系提取研究（ERE）主要集中在三种事件关系类型，包括共指关系、因果关系和时间关系。由于这三种关系类型通常是分开研究的，并且迄今为止没有一致的任务定义，本节将简要介绍这三种事件关系提取问题，作为不同的任务进行讨论。有关更详细的事件关系提取综述，我们建议读者参考
    Liu 等人 [[166](#bib.bib166)]。
- en: Event Coreference Resolution. Event coreference resolution (ECR) aims to identify
    whether the candidate events refer to the same event in the real-world, where
    those events may appear across several sentences. Existing methods [[190](#bib.bib190),
    [191](#bib.bib191)] usually formulate ECR as a classification or ranking problem,
    and mainly focus on the contextual features around the two events, such as syntactic
    features, event topic information and linguistic features [[192](#bib.bib192)].
    To enrich the clues for resolution, existing works also exploit document-level
    or topical structures [[193](#bib.bib193)], event argument information [[194](#bib.bib194),
    [195](#bib.bib195), [196](#bib.bib196), [197](#bib.bib197), [194](#bib.bib194)]
    and other event-related task information [[198](#bib.bib198), [199](#bib.bib199),
    [200](#bib.bib200)], such as event detection [[201](#bib.bib201)] and entity recognition [[202](#bib.bib202)].
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 事件共指消解。事件共指消解（ECR）的目标是确定候选事件是否指向现实世界中的同一事件，这些事件可能出现在多个句子中。现有方法[[190](#bib.bib190),
    [191](#bib.bib191)] 通常将ECR形式化为分类或排序问题，并主要关注两个事件周围的上下文特征，如句法特征、事件主题信息和语言特征[[192](#bib.bib192)]。为了丰富消解的线索，现有工作还利用文档级别或主题结构[[193](#bib.bib193)]、事件论元信息[[194](#bib.bib194),
    [195](#bib.bib195), [196](#bib.bib196), [197](#bib.bib197), [194](#bib.bib194)]
    和其他事件相关任务信息[[198](#bib.bib198), [199](#bib.bib199), [200](#bib.bib200)]，如事件检测[[201](#bib.bib201)]和实体识别[[202](#bib.bib202)]。
- en: 'Event Causal Relation Extraction. Event causal relation extraction (ECE) aims
    to identify the event causal relation [[203](#bib.bib203)] and distinguish the
    cause and effect between two events, which benefits to the real-world event evolution
    understanding and thereby promotes event detection and event prediction. According
    to the utilized evidence, the ECE methods can be manifested in two groups: 1)
    the methods exploiting internal information, which assume that the textual contexts
    contain sufficient clues for causal relation extraction, where the contextual
    features including syntactic features, lexical features, explicit causal patterns [[204](#bib.bib204),
    [205](#bib.bib205), [206](#bib.bib206)], statistic causal association [[207](#bib.bib207),
    [208](#bib.bib208), [209](#bib.bib209)], and document-level structures [[210](#bib.bib210)].
    2) the methods exploiting external information, which enhances the textual representation
    with external knowledge, such as pre-trained language model [[211](#bib.bib211)],
    and causal-related commonsense or knowledge base [[212](#bib.bib212), [213](#bib.bib213),
    [214](#bib.bib214), [215](#bib.bib215)]. There are also studies [[216](#bib.bib216),
    [217](#bib.bib217)] employing distant supervision from knowledge base to alleviate
    the data sparsity issue in ECE.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 事件因果关系提取。事件因果关系提取（ECE）的目标是识别事件因果关系[[203](#bib.bib203)]，并区分两个事件之间的因果关系，这有助于理解现实世界事件的演变，从而促进事件检测和事件预测。根据所利用的证据，ECE方法可以分为两类：1)
    利用内部信息的方法，这些方法假设文本上下文包含足够的线索用于因果关系提取，其中上下文特征包括句法特征、词汇特征、显式因果模式[[204](#bib.bib204),
    [205](#bib.bib205), [206](#bib.bib206)]、统计因果关联[[207](#bib.bib207), [208](#bib.bib208),
    [209](#bib.bib209)]，以及文档级别结构[[210](#bib.bib210)]。2) 利用外部信息的方法，这些方法通过外部知识增强文本表示，如预训练语言模型[[211](#bib.bib211)]，以及因果相关的常识或知识库[[212](#bib.bib212),
    [213](#bib.bib213), [214](#bib.bib214), [215](#bib.bib215)]。还有研究[[216](#bib.bib216),
    [217](#bib.bib217)]采用来自知识库的远程监督来缓解ECE中的数据稀疏问题。
- en: 'Event Temporal Relation Extraction. Event temporal relation extraction (ETE)
    aims to understand the temporal order among events in the texts. Most existing
    studies on ETE follow the TimeML format [[218](#bib.bib218)], which is widely
    used to markup events, time expressions and temporal relations. Generally, existing
    ETE studies can be roughly divided into three groups: 1) rules-based methods,
    which infers the temporal relation for events relying on temporal rules, such
    as syntactic analyzers [[219](#bib.bib219)], regular expression patterns over
    tokens [[220](#bib.bib220)], and other linguistic rules [[221](#bib.bib221)].
    2) machine learning-based methods, which leverages statistical temporal contextual
    features and achieve the task with statistical classifiers [[222](#bib.bib222),
    [223](#bib.bib223)]. 3) neural models, which captures temporal relations with
    neural networks, such as CNNs and LSTMs [[224](#bib.bib224), [225](#bib.bib225)].
    More external features are also considered in neural models, including dependency
    paths [[226](#bib.bib226)], domain knowledge [[227](#bib.bib227)], contextualized
    language models [[228](#bib.bib228)] and so on.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 事件时间关系提取。事件时间关系提取（ETE）旨在理解文本中事件的时间顺序。大多数现有的ETE研究遵循TimeML格式 [[218](#bib.bib218)]，该格式广泛用于标记事件、时间表达和时间关系。一般来说，现有的ETE研究可以大致分为三类：1)
    基于规则的方法，这些方法依赖于时间规则来推断事件的时间关系，如句法分析器 [[219](#bib.bib219)]、基于标记的正则表达式模式 [[220](#bib.bib220)]
    和其他语言规则 [[221](#bib.bib221)]。2) 基于机器学习的方法，这些方法利用统计时间上下文特征，通过统计分类器完成任务 [[222](#bib.bib222),
    [223](#bib.bib223)]。3) 神经模型，这些模型通过神经网络（如CNNs和LSTMs）捕捉时间关系 [[224](#bib.bib224),
    [225](#bib.bib225)]。神经模型中还考虑了更多的外部特征，包括依赖路径 [[226](#bib.bib226)]、领域知识 [[227](#bib.bib227)]、上下文化语言模型 [[228](#bib.bib228)]
    等等。
- en: 9.3 Script Event Prediction
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3 脚本事件预测
- en: Script [[229](#bib.bib229)] is a chain of ordered events describing activities
    about a protagonist, and Script Event Prediction (SEP) aims to predict the subsequent
    event of a given chain from a candidate event list. As an important task to understand
    the evolutionary patterns among events, SEP has supported various downstream applications,
    including anaphora resolution [[230](#bib.bib230)], story generation [[231](#bib.bib231)]
    and finalcial analysis [[232](#bib.bib232)]. In SEP, each event is represented
    in the form of a tuple $e=v(s,o,p)$, where $v,s,o,p$ are the event arguments respectively
    denoting the verb, subject, object and indirect-object of the event. For example,
    $e=give(waiter,bob,water)$ means that “A waiter gives bob water”. By far, the
    most widely used benchmark for SEP is NYT dataset [[233](#bib.bib233)], where
    the event chains are extracted from the New York Times (NYT) portion of the Gigaword
    corpus [[234](#bib.bib234)]. The dataset consists 140,331/10,000/10,000 event
    chains for training/validation/test. Each event chain contains 8 events and has
    5 candidate events where only one is the correct subsequent event. Next, we introduce
    the details about existing SEP works.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本 [[229](#bib.bib229)] 是描述主角活动的一系列有序事件，脚本事件预测（SEP）旨在从候选事件列表中预测给定链条的后续事件。作为理解事件间演变模式的重要任务，SEP
    支持了各种下游应用，包括指代解析 [[230](#bib.bib230)]、故事生成 [[231](#bib.bib231)] 和财务分析 [[232](#bib.bib232)]。在SEP中，每个事件以元组
    $e=v(s,o,p)$ 的形式表示，其中 $v,s,o,p$ 分别表示事件的动词、主语、宾语和间接宾语。例如，$e=give(waiter,bob,water)$
    意味着“一个服务员给 bob 水”。迄今为止，SEP 最广泛使用的基准是 NYT 数据集 [[233](#bib.bib233)]，该数据集中的事件链从Gigaword语料库的《纽约时报》（NYT）部分提取 [[234](#bib.bib234)]。该数据集包含
    140,331/10,000/10,000 个事件链用于训练/验证/测试。每个事件链包含 8 个事件，并有 5 个候选事件，其中只有一个是正确的后续事件。接下来，我们将介绍现有
    SEP 研究的详细信息。
- en: Existing SEP works could be categorized into two groups. The first line of works
    mainly focus on the event co-occurrence relation to predict the subsequent from
    three aspects. Specifically, early works [[235](#bib.bib235), [236](#bib.bib236),
    [237](#bib.bib237), [238](#bib.bib238), [233](#bib.bib233)] model the event-pair-level
    semantic relation to predict the subsequent event of the given event chain. Further,
    to alleviate semantics limitation to event chain, Lv et al. [[239](#bib.bib239)]
    regard the given event chain as a combination of several event-segments and capture
    clues from diverse event segments to facilitate the event prediction. In the following,
    researchers encode the full event-chain [[240](#bib.bib240), [241](#bib.bib241),
    [242](#bib.bib242)] to grasp semantic signals to predict subsequent event. Wang
    et al. [[242](#bib.bib242)] and Zheng et al. [[243](#bib.bib243)] also employ
    the graph structure to model the event chain. The second line of works integrate
    external knowledge to help understand the scripts, since the absence of text contexts
    makes the semantics in scripts more sparse than normal texts. Specifically, Ding
    et al. [[244](#bib.bib244)] utilize knowledge bases, Event2Mind [[245](#bib.bib245)]
    and ATlas Of MachIne Commonsens (ATOMIC) [[246](#bib.bib246)], to refine sentiment
    and intention information to enrich the semantics of the script. Further, Lv et
    al.  [[247](#bib.bib247)] incorporate event knowledge base ASER (Activities, States,
    Events and their Relations) [[248](#bib.bib248)] to provide causal and temporal
    relations between events to predict the subsequent event, achieving great success
    in this task.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的SEP工作可以分为两类。第一类工作主要集中在事件共现关系上，从三个方面预测后续事件。具体来说，早期的工作[[235](#bib.bib235),
    [236](#bib.bib236), [237](#bib.bib237), [238](#bib.bib238), [233](#bib.bib233)]对事件对级别的语义关系进行建模，以预测给定事件链的后续事件。为了缓解事件链的语义限制，Lv等人[[239](#bib.bib239)]将给定的事件链视为多个事件段的组合，并从不同的事件段中捕捉线索来促进事件预测。随后，研究人员对完整的事件链进行编码[[240](#bib.bib240),
    [241](#bib.bib241), [242](#bib.bib242)]，以把握语义信号来预测后续事件。Wang等人[[242](#bib.bib242)]和Zheng等人[[243](#bib.bib243)]也使用图结构来建模事件链。第二类工作整合外部知识以帮助理解脚本，因为缺乏文本上下文使得脚本中的语义比正常文本更为稀疏。具体而言，Ding等人[[244](#bib.bib244)]利用知识库、Event2Mind[[245](#bib.bib245)]和ATlas
    Of MachIne Commonsens (ATOMIC)[[246](#bib.bib246)]来细化情感和意图信息，从而丰富脚本的语义。进一步地，Lv等人[[247](#bib.bib247)]结合事件知识库ASER
    (Activities, States, Events and their Relations)[[248](#bib.bib248)]提供事件间的因果和时间关系，以预测后续事件，并在这一任务中取得了巨大成功。
- en: 10 Future Research Trends
  id: totrans-322
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 未来研究趋势
- en: 'Event extraction is an essential and challenging task in text mining, which
    mainly learns the structured representation of events from the relevant text describing
    the events. Event extraction is mainly divided into two sub-tasks: event detection
    and argument extraction. The core of event extraction is identifying the event-related
    words in the text and classifying them into appropriate categories. The event
    extraction method based on the deep learning model automatically extracts features
    and avoids the tedious work of designing features manually. Event extraction tasks
    are constructed as an end-to-end system, using word vectors with rich language
    features as input, to reduce the errors caused by the underlying NLP tools. Previous
    methods focus on studying effective features to capture the lexical, syntactic,
    and semantic information of candidate triggers, candidate arguments. Furthermore,
    they explore the dependence between triggers and multiple entities related to
    the same trigger, and the relationship between multiple triggers associated with
    the same entity. According to the characteristics of the event extraction and
    the current research status, we summarize the following technical challenges.'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 事件提取是文本挖掘中一个至关重要且具有挑战性的任务，主要从描述事件的相关文本中学习事件的结构化表示。事件提取主要分为两个子任务：事件检测和论元提取。事件提取的核心在于识别文本中的事件相关词，并将其分类为适当的类别。基于深度学习模型的事件提取方法自动提取特征，避免了手动设计特征的繁琐工作。事件提取任务被构建为一个端到端系统，使用具有丰富语言特征的词向量作为输入，以减少底层NLP工具带来的错误。以往的方法集中研究有效特征，以捕捉候选触发词和候选论元的词汇、句法和语义信息。此外，它们还探讨了触发词与多个与同一触发词相关的实体之间的依赖关系，以及多个触发词与同一实体相关联的关系。根据事件提取的特点和当前的研究现状，我们总结了以下技术挑战。
- en: 10.1 Challenges from Event Extraction Corpus
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1 来自事件提取语料库的挑战
- en: Event Extraction Dataset Construction. The event extraction task is complex,
    and the existing pre-training model lacks the learning of the event extraction
    task. The existing event extraction data sets have a few labeled data, and manual
    annotation of event extraction data set has a high time cost. Therefore, the construction
    of large-scale event extraction data set or the design of automatic construction
    event extraction data set is also a future research trend.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 事件抽取数据集构建。事件抽取任务复杂，现有的预训练模型在事件抽取任务上的学习能力不足。现有的事件抽取数据集标注数据稀缺，手动标注事件抽取数据集的时间成本较高。因此，大规模事件抽取数据集的构建或自动化构建事件抽取数据集的设计也是未来的研究趋势。
- en: External Resources. The data set of event extraction is small. Deep learning
    combining external resources and constructing a large-scale dataset has achieved
    good results. Due to the difficulties in constructing labeled data sets and the
    small size of data sets, it is also an urgent research direction that how to make
    better use of deep learning to extract events effectively with help of external
    resources.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 外部资源。事件抽取的数据集较小。结合外部资源的深度学习和构建大规模数据集已取得了良好的成果。由于构建标注数据集的困难以及数据集的规模较小，如何更好地利用深度学习结合外部资源有效抽取事件也是一个迫切的研究方向。
- en: Event Extraction Schema. Event extraction methods can be divided into close-domain
    event extraction methods and open-domain event extraction methods. The effect
    of event extraction methods without schema is challenging to evaluate, and template-based
    event extraction methods need to design different event schema according to different
    event types. Therefore, how to design a general event extraction schema based
    on event characteristics is an essential means to overcome the difficulty in constructing
    event extraction data set and sharing knowledge among classes.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 事件抽取模式。事件抽取方法可以分为闭域事件抽取方法和开放域事件抽取方法。没有模式的事件抽取方法的效果难以评估，而基于模板的事件抽取方法需要根据不同的事件类型设计不同的事件模式。因此，如何根据事件特征设计通用的事件抽取模式是克服事件抽取数据集构建困难和跨类知识共享的关键手段。
- en: 10.2 Challenges from Event Extraction Models
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2 事件抽取模型的挑战
- en: Dependency Learning. The event extraction method using BERT has become mainstream
    at present. However, event extraction is different from the task learned by the
    BERT model in pre-training. Argument extraction needs to consider the relationship
    between the event argument roles to extract different roles under the same event
    type. It requires the event extraction model to learn the syntactic dependencies
    of the text. Therefore, making the dependency relationship between the event arguments
    is an urgent problem to solve to comprehensively and accurately extract the arguments
    of each event type.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖学习。当前，使用BERT的事件抽取方法已成为主流。然而，事件抽取与BERT模型在预训练阶段学习的任务不同。论元抽取需要考虑事件论元角色之间的关系，以提取同一事件类型下的不同角色。这要求事件抽取模型学习文本的句法依赖关系。因此，建立事件论元之间的依赖关系是一个亟待解决的问题，以全面准确地提取每种事件类型的论元。
- en: End-to-End Learning Model. The advantage of the deep learning method based on
    the joint model over the traditional approach is the joint representation form.
    The event extraction depends on the label of entities. So this paper believes
    that establishing a end-to-end autonomous learning model based on deep learning
    is a direction worthy of research and exploration, and how to design multi-task
    and multi-federation is a major challenge.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端学习模型。基于联合模型的深度学习方法相比传统方法的优势在于联合表示形式。事件抽取依赖于实体的标签。因此，本文认为建立基于深度学习的端到端自主学习模型是一个值得研究和探索的方向，而如何设计多任务和多联合是一个重大挑战。
- en: Multi-event Extraction. According to the different granularity of event extraction,
    event extraction can be divided into sentence-level event extraction and document-level
    event extraction. There have been a lot of researches on sentence-level event
    extraction. However, the document-level event extraction is still in the exploratory
    stage, and the document-level event extraction is closer to the practical application.
    Therefore, how to design the multi-event extraction method for the text is of
    great research significance.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 多事件抽取。根据事件抽取的不同粒度，可以将事件抽取分为句子级事件抽取和文档级事件抽取。目前，句子级事件抽取的研究较多，而文档级事件抽取仍处于探索阶段，且文档级事件抽取更接近实际应用。因此，如何为文本设计多事件抽取方法具有重要的研究意义。
- en: Domain Event Extraction. The domain text often contains numerous technical terms,
    which increases the difficulty of domain event extraction [[249](#bib.bib249)].
    For example, Biomedical EE (BEE) aims to extract events capturing an interplay
    between biomedical entities [[250](#bib.bib250), [251](#bib.bib251), [252](#bib.bib252),
    [253](#bib.bib253)]. Extracting and harnessing them is beneficial for medical
    research and disease prevention [[254](#bib.bib254), [255](#bib.bib255)]. Therefore,
    how to design effective methods to understand the deep semantic information and
    context correspondence in the domain text has become an urgent problem to solve.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 领域事件抽取。领域文本通常包含大量技术术语，这增加了领域事件抽取的难度[[249](#bib.bib249)]。例如，生物医学事件抽取（BEE）旨在提取捕捉生物医学实体之间相互作用的事件[[250](#bib.bib250),
    [251](#bib.bib251), [252](#bib.bib252), [253](#bib.bib253)]。提取和利用这些事件对于医学研究和疾病预防具有重要意义[[254](#bib.bib254),
    [255](#bib.bib255)]。因此，如何设计有效的方法以理解领域文本中的深层语义信息和上下文对应关系已成为亟待解决的问题。
- en: Interpretability for Event Extraction. Event extraction includes four sub-tasks,
    and the existing event extraction often considers how to improve the accuracy
    of extraction, but there is little research on the interpretability of event extraction
    [[256](#bib.bib256)]. Due to the fact that the task of event extraction is complex,
    it is difficult to understand directly why the model divides a word into a certain
    argument role for a complex text. This requires the event extraction model to
    be interpretable in order to facilitate the manual discrimination of the predicted
    results, which is very important in the biological and medical fields [[257](#bib.bib257)].
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 事件抽取的可解释性。事件抽取包括四个子任务，现有的事件抽取研究通常关注如何提高抽取的准确性，但对事件抽取的可解释性研究较少[[256](#bib.bib256)]。由于事件抽取任务的复杂性，直接理解模型为何将某个词划分为特定的论元角色在复杂文本中较为困难。这要求事件抽取模型具有可解释性，以便于手动辨别预测结果，这在生物学和医学领域尤为重要[[257](#bib.bib257)]。
- en: 11 Conclusion
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: This paper principally introduces the existing deep learning models for event
    extraction tasks. Firstly, we introduce concepts and definitions from three aspects
    of event extraction. Then we divide the deep learning-based event extraction paradigm
    into the pipeline and joint parts and introduce them, respectively. Deep learning-based
    models enhance performance by improving the presentation learning method, model
    structure, and additional data and knowledge. Then, we introduce the datasets
    with a summary table and evaluation metrics. Furthermore, we give the quantitative
    results of the leading models in a summary table on ACE 2005 datasets. Finally,
    we summarize the possible future research trends of event extraction.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 本文主要介绍了现有的用于事件抽取任务的深度学习模型。首先，我们从事件抽取的三个方面介绍了概念和定义。然后，我们将基于深度学习的事件抽取范式分为管道部分和联合部分，并分别介绍它们。基于深度学习的模型通过改进表示学习方法、模型结构以及额外的数据和知识来提升性能。接着，我们介绍了数据集，并附上了总结表和评估指标。此外，我们在ACE
    2005数据集上的领先模型的定量结果也以总结表的形式呈现。最后，我们总结了事件抽取可能的未来研究趋势。
- en: Acknowledgment
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: The corresponding author is Jianxin Li. The authors of this paper were supported
    by the NSFC through grant No.U20B2053, 62106059 and the Academic Excellence Foundation
    of Beihang University for PhD Students. Philip S. Yu was supported by the NSF
    under grants III-1763325, III-1909323, III-2106758, and SaTC-1930941.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 通讯作者为李建新。本论文作者得到了NSFC资助（项目编号：U20B2053, 62106059）以及北航大学博士生学术优秀基金的支持。Philip S.
    Yu得到了NSF的资助（项目编号：III-1763325, III-1909323, III-2106758, SaTC-1930941）。
- en: References
  id: totrans-338
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] G. R. Doddington, A. Mitchell, M. A. Przybocki, L. A. Ramshaw, S. M. Strassel,
    and R. M. Weischedel, “The automatic content extraction (ACE) program - tasks,
    data, and evaluation,” in LREC, 2004.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] G. R. 多丁顿，A. 米切尔，M. A. 普日博基，L. A. 拉姆肖，S. M. 斯特拉瑟尔，和 R. M. 韦伯谢德，“自动内容提取（ACE）计划——任务、数据和评估，”在
    LREC，2004。'
- en: '[2] W. Zhang, X. Zhao, L. Zhao, D. Yin, and G. H. Yang, “DRL4IR: 2nd workshop
    on deep reinforcement learning for information retrieval,” in ACM SIGIR, 2021.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] W. 张，X. 赵，L. 赵，D. 尹，和 G. H. 杨，“DRL4IR：深度强化学习在信息检索中的第二次研讨会，”在 ACM SIGIR，2021。'
- en: '[3] A. Kuhnle, M. Aroca-Ouellette, A. Basu, M. Sensoy, J. Reid, and D. Zhang,
    “Reinforcement learning for information retrieval,” in ACM SIGIR, 2021.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] A. 库恩勒，M. 阿罗卡-奥埃莱特，A. 巴苏，M. 森索伊，J. 瑞德，和 D. 张，“信息检索中的强化学习，”在 ACM SIGIR，2021。'
- en: '[4] C. Liu, C. Zhou, J. Wu, H. Xie, Y. Hu, and L. Guo, “CPMF: A collective
    pairwise matrix factorization model for upcoming event recommendation,” in IJCNN,
    2017.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] C. 刘，C. 周，J. 吴，H. 谢，Y. 胡，和 L. 郭，“CPMF：一种集体成对矩阵分解模型用于即将发生事件推荐，”在 IJCNN，2017。'
- en: '[5] L. Gao, J. Wu, Z. Qiao, C. Zhou, H. Yang, and Y. Hu, “Collaborative social
    group influence for event recommendation,” in CIKM, 2016.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] L. 高，J. 吴，Z. 乔，C. 周，H. 杨，和 Y. 胡，“事件推荐的协作社交群体影响，”在 CIKM，2016。'
- en: '[6] J. L. Boyd-Graber and B. Börschinger, “What question answering can learn
    from trivia nerds,” in ACL, 2020.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] J. L. 博伊德-格雷伯 和 B. 博施辛格，“问题回答可以从琐事迷那里学到什么，”在 ACL，2020。'
- en: '[7] Q. Cao, H. Trivedi, A. Balasubramanian, and N. Balasubramanian, “Deformer:
    Decomposing pre-trained transformers for faster question answering,” in ACL, 2020.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Q. 曹，H. 特里维迪，A. 巴拉苏布拉马尼安，和 N. 巴拉苏布拉马尼安，“Deformer：分解预训练变换器以加快问题回答速度，”在 ACL，2020。'
- en: '[8] X. Wu, J. Wu, X. Fu, J. Li, P. Zhou, and X. Jiang, “Automatic knowledge
    graph construction: A report on the 2019 ICDM/ICBK contest,” in ICDM, 2019.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] X. 吴，J. 吴，X. 傅，J. 李，P. 周，和 X. 姜，“自动知识图谱构建：2019 ICDM/ICBK 竞赛报告，”在 ICDM，2019。'
- en: '[9] A. Bosselut, R. L. Bras, and Y. Choi, “Dynamic neuro-symbolic knowledge
    graph construction for zero-shot commonsense question answering,” in AAAI, 2021.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] A. 博塞卢特，R. L. 布拉斯，和 Y. 崔，“用于零样本常识问题回答的动态神经符号知识图谱构建，”在 AAAI，2021。'
- en: '[10] X. Su, S. Xue, F. Liu, J. Wu, J. Yang, C. Zhou, W. Hu, C. Paris, S. Nepal,
    D. Jin, Q. Z. Sheng, and P. S. Yu, “A comprehensive survey on community detection
    with deep learning,” CoRR, 2021.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] X. 苏，S. 薛，F. 刘，J. 吴，J. 杨，C. 周，W. 胡，C. 巴黎，S. 尼泊尔，D. 金，Q. Z. 盛，和 P. S. 于，“基于深度学习的社区检测全面调查，”CoRR，2021。'
- en: '[11] F. Liu, S. Xue, J. Wu, C. Zhou, W. Hu, C. Paris, S. Nepal, J. Yang, and
    P. S. Yu, “Deep learning for community detection: Progress, challenges and opportunities,”
    in IJCAI, 2020.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] F. 刘，S. 薛，J. 吴，C. 周，W. 胡，C. 巴黎，S. 尼泊尔，J. 杨，和 P. S. 于，“社区检测中的深度学习：进展、挑战和机遇，”在
    IJCAI，2020。'
- en: '[12] X. Ma, J. Wu, S. Xue, J. Yang, Q. Z. Sheng, and H. Xiong, “A comprehensive
    survey on graph anomaly detection with deep learning,” CoRR, 2021.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] X. 马，J. 吴，S. 薛，J. 杨，Q. Z. 盛，和 H. 熊，“基于深度学习的图异常检测全面调查，”CoRR，2021。'
- en: '[13] B. Yang and T. M. Mitchell, “Joint extraction of events and entities within
    a document context,” in NAACL HLT, 2016.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] B. 杨 和 T. M. 米切尔，“在文档上下文中联合提取事件和实体，”在 NAACL HLT，2016。'
- en: '[14] J. Ferguson, C. Lockard, D. S. Weld, and H. Hajishirzi, “Semi-supervised
    event extraction with paraphrase clusters,” in NAACL-HLT, 2018.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] J. 弗格森，C. 洛卡德，D. S. 韦尔德，和 H. 哈吉什尔齐，“具有同义句簇的半监督事件提取，”在 NAACL-HLT，2018。'
- en: '[15] J. Sheng, S. Guo, B. Yu, Q. Li, Y. Hei, L. Wang, T. Liu, and H. Xu, “Casee:
    A joint learning framework with cascade decoding for overlapping event extraction,”
    in ACL/IJCNLP, 2021.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] J. 盛，S. 郭，B. 于，Q. 李，Y. 黑，L. 王，T. 刘，和 H. 许，“Casee：用于重叠事件提取的级联解码联合学习框架，”在
    ACL/IJCNLP，2021。'
- en: '[16] M. T. Chau, D. Esteves, and J. Lehmann, “Open-domain event extraction
    and embedding for natural gas market prediction,” CoRR, 2019.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] M. T. 曹，D. 爱斯特维斯，和 J. 莱曼，“开放领域事件提取和嵌入用于天然气市场预测，”CoRR，2019。'
- en: '[17] X. Liu, H. Huang, and Y. Zhang, “Open domain event extraction using neural
    latent variable models,” in ACL, 2019.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] X. 刘，H. 黄，和 Y. 张，“使用神经潜变量模型的开放领域事件提取，”在 ACL，2019。'
- en: '[18] M. Mejri and J. Akaichi, “A survey of textual event extraction from social
    networks,” in LPKM, 2017.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] M. 梅吉里 和 J. 阿凯奇，“社交网络文本事件提取的调查，”在 LPKM，2017。'
- en: '[19] Z. Li, X. Chang, L. Yao, S. Pan, Z. Ge, and H. Zhang, “Grounding visual
    concepts for zero-shot event detection and event captioning,” in ACM SIGKDD, 2020.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Z. 李，X. 张，L. 姚，S. 潘，Z. 戈，和 H. 张，“为零样本事件检测和事件字幕生成建立视觉概念基础，”在 ACM SIGKDD，2020。'
- en: '[20] J. Liao, X. Zhao, X. Li, L. Zhang, and J. Tang, “Learning discriminative
    neural representations for event detection,” in ACM SIGIR, 2021.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] J. Liao, X. Zhao, X. Li, L. Zhang, 和 J. Tang, “学习区分性神经表示用于事件检测，”发表于 ACM
    SIGIR, 2021。'
- en: '[21] H. Lin, Y. Lu, X. Han, and L. Sun, “Cost-sensitive regularization for
    label confusion-aware event detection,” in ACL, 2019.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] H. Lin, Y. Lu, X. Han, 和 L. Sun, “针对标签混淆感知事件检测的成本敏感正则化，”发表于 ACL, 2019。'
- en: '[22] Y. Cao, H. Peng, J. Wu, Y. Dou, J. Li, and P. S. Yu, “Knowledge-preserving
    incremental social event detection via heterogeneous gnns,” in The Web Conference,
    2021.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Y. Cao, H. Peng, J. Wu, Y. Dou, J. Li, 和 P. S. Yu, “通过异质 GNNs 的知识保留增量社交事件检测，”发表于
    The Web Conference, 2021。'
- en: '[23] R. Aly, S. Remus, and C. Biemann, “Hierarchical multi-label classification
    of text with capsule networks,” in ACL, 2019.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] R. Aly, S. Remus, 和 C. Biemann, “使用胶囊网络的层次化多标签文本分类，”发表于 ACL, 2019。'
- en: '[24] I. Chalkidis, M. Fergadiotis, P. Malakasiotis, and I. Androutsopoulos,
    “Large-scale multi-label text classification on EU legislation,” in ACL, 2019.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] I. Chalkidis, M. Fergadiotis, P. Malakasiotis, 和 I. Androutsopoulos, “针对欧盟立法的大规模多标签文本分类，”发表于
    ACL, 2019。'
- en: '[25] W. Chang, H. Yu, K. Zhong, Y. Yang, and I. S. Dhillon, “Taming pretrained
    transformers for extreme multi-label text classification,” in ACM SIGKDD, 2020.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] W. Chang, H. Yu, K. Zhong, Y. Yang, 和 I. S. Dhillon, “驯化预训练变换器用于极端多标签文本分类，”发表于
    ACM SIGKDD, 2020。'
- en: '[26] X. Li, J. Feng, Y. Meng, Q. Han, F. Wu, and J. Li, “A unified MRC framework
    for named entity recognition,” in ACL, 2020.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] X. Li, J. Feng, Y. Meng, Q. Han, F. Wu, 和 J. Li, “一个统一的 MRC 框架用于命名实体识别，”发表于
    ACL, 2020。'
- en: '[27] J. Yu, B. Bohnet, and M. Poesio, “Named entity recognition as dependency
    parsing,” in ACL, 2020.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] J. Yu, B. Bohnet, 和 M. Poesio, “将命名实体识别视为依赖解析，”发表于 ACL, 2020。'
- en: '[28] B. Y. Lin, D. Lee, M. Shen, R. Moreno, X. Huang, P. Shiralkar, and X. Ren,
    “Triggerner: Learning with entity triggers as explanations for named entity recognition,”
    in ACL, 2020.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] B. Y. Lin, D. Lee, M. Shen, R. Moreno, X. Huang, P. Shiralkar, 和 X. Ren,
    “Triggerner：使用实体触发器作为命名实体识别的解释进行学习，”发表于 ACL, 2020。'
- en: '[29] R. Cao, S. Zhu, C. Yang, C. Liu, R. Ma, Y. Zhao, L. Chen, and K. Yu, “Unsupervised
    dual paraphrasing for two-stage semantic parsing,” in ACL, 2020.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] R. Cao, S. Zhu, C. Yang, C. Liu, R. Ma, Y. Zhao, L. Chen, 和 K. Yu, “无监督双重释义用于两阶段语义解析，”发表于
    ACL, 2020。'
- en: '[30] E. Stengel-Eskin, A. S. White, S. Zhang, and B. V. Durme, “Universal decompositional
    semantic parsing,” in ACL, 2020.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] E. Stengel-Eskin, A. S. White, S. Zhang, 和 B. V. Durme, “通用分解语义解析，”发表于
    ACL, 2020。'
- en: '[31] I. Abdelaziz, S. Ravishankar, P. Kapanipathi, S. Roukos, and A. G. Gray,
    “A semantic parsing and reasoning-based approach to knowledge base question answering,”
    in AAAI, 2021.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] I. Abdelaziz, S. Ravishankar, P. Kapanipathi, S. Roukos, 和 A. G. Gray,
    “基于语义解析和推理的知识库问答方法，”发表于 AAAI, 2021。'
- en: '[32] T. Chen, H. Shi, L. Liu, S. Tang, J. Shao, Z. Chen, and Y. Zhuang, “Empower
    distantly supervised relation extraction with collaborative adversarial training,”
    in AAAI, 2021.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] T. Chen, H. Shi, L. Liu, S. Tang, J. Shao, Z. Chen, 和 Y. Zhuang, “通过协同对抗训练增强远程监督关系提取，”发表于
    AAAI, 2021。'
- en: '[33] W. U. Ahmad, N. Peng, and K. Chang, “GATE: graph attention transformer
    encoder for cross-lingual relation and event extraction,” in AAAI, 2021.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] W. U. Ahmad, N. Peng, 和 K. Chang, “GATE：用于跨语言关系和事件提取的图注意力变换器编码器，”发表于 AAAI,
    2021。'
- en: '[34] K. Sun, R. Zhang, S. Mensah, Y. Mao, and X. Liu, “Progressive multi-task
    learning with controlled information flow for joint entity and relation extraction,”
    in AAAI, 2021.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] K. Sun, R. Zhang, S. Mensah, Y. Mao, 和 X. Liu, “具有控制信息流的渐进式多任务学习用于联合实体和关系提取，”发表于
    AAAI, 2021。'
- en: '[35] F. Hogenboom, F. Frasincar, U. Kaymak, F. de Jong, and E. Caron, “A survey
    of event extraction methods from text for decision support systems,” Decis. Support
    Syst., 2016.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] F. Hogenboom, F. Frasincar, U. Kaymak, F. de Jong, 和 E. Caron, “用于决策支持系统的事件提取方法综述，”Decis.
    Support Syst., 2016。'
- en: '[36] W. Xiang and B. Wang, “A survey of event extraction from text,” IEEE Access,
    2019.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] W. Xiang 和 B. Wang, “从文本中事件提取的综述，”IEEE Access, 2019。'
- en: '[37] S. Yang, D. Feng, L. Qiao, Z. Kan, and D. Li, “Exploring pre-trained language
    models for event extraction and generation,” in ACL, 2019.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] S. Yang, D. Feng, L. Qiao, Z. Kan, 和 D. Li, “探索预训练语言模型用于事件提取和生成，”发表于 ACL,
    2019。'
- en: '[38] Q. Li, H. Ji, and L. Huang, “Joint event extraction via structured prediction
    with global features,” in ACL, 2013.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Q. Li, H. Ji, 和 L. Huang, “通过结构化预测与全局特征联合事件提取，”发表于 ACL, 2013。'
- en: '[39] Y. Chen, L. Xu, K. Liu, D. Zeng, and J. Zhao, “Event extraction via dynamic
    multi-pooling convolutional neural networks,” in ACL, 2015.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Y. Chen, L. Xu, K. Liu, D. Zeng, 和 J. Zhao, “通过动态多池化卷积神经网络进行事件提取，”发表于
    ACL, 2015。'
- en: '[40] T. H. Nguyen, K. Cho, and R. Grishman, “Joint event extraction via recurrent
    neural networks,” in NAACL HLT, 2016.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] T. H. Nguyen, K. Cho, 和 R. Grishman, “通过递归神经网络的联合事件提取，” 发表在 NAACL HLT,
    2016。'
- en: '[41] X. Du and C. Cardie, “Event extraction by answering (almost) natural questions,”
    in EMNLP, 2020.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] X. Du 和 C. Cardie, “通过回答（几乎）自然问题进行事件提取，” 发表在 EMNLP, 2020。'
- en: '[42] F. Li, W. Peng, Y. Chen, Q. Wang, L. Pan, Y. Lyu, and Y. Zhu, “Event extraction
    as multi-turn question answering,” in EMNLP, 2020.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] F. Li, W. Peng, Y. Chen, Q. Wang, L. Pan, Y. Lyu, 和 Y. Zhu, “事件提取作为多轮问答，”
    发表在 EMNLP, 2020。'
- en: '[43] Y. Lu, H. Lin, J. Xu, X. Han, J. Tang, A. Li, L. Sun, M. Liao, and S. Chen,
    “Text2event: Controllable sequence-to-structure generation for end-to-end event
    extraction,” in ACL/IJCNLP, 2021.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Y. Lu, H. Lin, J. Xu, X. Han, J. Tang, A. Li, L. Sun, M. Liao, 和 S. Chen,
    “Text2event: 可控的序列到结构生成用于端到端事件提取，” 发表在 ACL/IJCNLP, 2021。'
- en: '[44] I. Hsu, K.-H. Huang, E. Boschee, S. Miller, P. Natarajan, K.-W. Chang,
    N. Peng, et al., “Degree: A data-efficient generative event extraction model,”
    CoRR, 2021.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] I. Hsu, K.-H. Huang, E. Boschee, S. Miller, P. Natarajan, K.-W. Chang,
    N. Peng 等, “Degree: 一种数据高效的生成事件提取模型，” 发表在 CoRR, 2021。'
- en: '[45] D. Mekala and J. Shang, “Contextualized weak supervision for text classification,”
    in ACL, 2020.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] D. Mekala 和 J. Shang, “文本分类的上下文化弱监督，” 发表在 ACL, 2020。'
- en: '[46] B. Guo, S. Han, X. Han, H. Huang, and T. Lu, “Label confusion learning
    to enhance text classification models,” in AAAI, 2021.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] B. Guo, S. Han, X. Han, H. Huang, 和 T. Lu, “标签混淆学习以增强文本分类模型，” 发表在 AAAI,
    2021。'
- en: '[47] S. Guo, R. Li, H. Tan, X. Li, Y. Guan, H. Zhao, and Y. Zhang, “A frame-based
    sentence representation for machine reading comprehension,” in ACL, 2020.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] S. Guo, R. Li, H. Tan, X. Li, Y. Guan, H. Zhao, 和 Y. Zhang, “用于机器阅读理解的基于框架的句子表示，”
    发表在 ACL, 2020。'
- en: '[48] B. Zheng, H. Wen, Y. Liang, N. Duan, W. Che, D. Jiang, M. Zhou, and T. Liu,
    “Document modeling with graph attention networks for multi-grained machine reading
    comprehension,” in ACL, 2020.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] B. Zheng, H. Wen, Y. Liang, N. Duan, W. Che, D. Jiang, M. Zhou, 和 T. Liu,
    “多粒度机器阅读理解的文档建模与图注意力网络，” 发表在 ACL, 2020。'
- en: '[49] S. Chen, Y. Wang, J. Liu, and Y. Wang, “Bidirectional machine reading
    comprehension for aspect sentiment triplet extraction,” in AAAI, 2021.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] S. Chen, Y. Wang, J. Liu, 和 Y. Wang, “双向机器阅读理解用于方面情感三元组提取，” 发表在 AAAI,
    2021。'
- en: '[50] W. Yuan, T. He, and X. Dai, “Improving neural question generation using
    deep linguistic representation,” in WWW, 2021.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] W. Yuan, T. He, 和 X. Dai, “利用深度语言表示改进神经问题生成，” 发表在 WWW, 2021。'
- en: '[51] L. Chen, W. Ruan, X. Liu, and J. Lu, “Seqvat: Virtual adversarial training
    for semi-supervised sequence labeling,” in ACL, 2020.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] L. Chen, W. Ruan, X. Liu, 和 J. Lu, “Seqvat: 用于半监督序列标注的虚拟对抗训练，” 发表在 ACL,
    2020。'
- en: '[52] T. Gui, J. Ye, Q. Zhang, Z. Li, Z. Fei, Y. Gong, and X. Huang, “Uncertainty-aware
    label refinement for sequence labeling,” in EMNLP, 2020.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] T. Gui, J. Ye, Q. Zhang, Z. Li, Z. Fei, Y. Gong, 和 X. Huang, “用于序列标注的不确定性感知标签精炼，”
    发表在 EMNLP, 2020。'
- en: '[53] A. Ramponi, R. van der Goot, R. Lombardo, and B. Plank, “Biomedical event
    extraction as sequence labeling,” in EMNLP, 2020.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] A. Ramponi, R. van der Goot, R. Lombardo, 和 B. Plank, “生物医学事件提取作为序列标注，”
    发表在 EMNLP, 2020。'
- en: '[54] T. Jiang, D. Wang, L. Sun, H. Yang, Z. Zhao, and F. Zhuang, “Lightxml:
    Transformer with dynamic negative sampling for high-performance extreme multi-label
    text classification,” in AAAI, 2021.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] T. Jiang, D. Wang, L. Sun, H. Yang, Z. Zhao, 和 F. Zhuang, “Lightxml: 用于高性能极端多标签文本分类的动态负采样
    Transformer，” 发表在 AAAI, 2021。'
- en: '[55] L. Xiao, X. Zhang, L. Jing, C. Huang, and M. Song, “Does head label help
    for long-tailed multi-label text classification,” in AAAI, 2021.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] L. Xiao, X. Zhang, L. Jing, C. Huang, 和 M. Song, “头标签对长尾多标签文本分类是否有帮助，”
    发表在 AAAI, 2021。'
- en: '[56] X. Liang, D. Cheng, F. Yang, Y. Luo, W. Qian, and A. Zhou, “F-HMTC: detecting
    financial events for investment decisions based on neural hierarchical multi-label
    text classification,” in IJCAI, 2020.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] X. Liang, D. Cheng, F. Yang, Y. Luo, W. Qian, 和 A. Zhou, “F-HMTC: 基于神经层次多标签文本分类的金融事件检测用于投资决策，”
    发表在 IJCAI, 2020。'
- en: '[57] A. Subburathinam, D. Lu, H. Ji, J. May, S. Chang, A. Sil, and C. R. Voss,
    “Cross-lingual structure transfer for relation and event extraction,” in EMNLP-IJCNLP,
    2019.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] A. Subburathinam, D. Lu, H. Ji, J. May, S. Chang, A. Sil, 和 C. R. Voss,
    “跨语言结构迁移用于关系和事件提取，” 发表在 EMNLP-IJCNLP, 2019。'
- en: '[58] J. Zhang, Y. Qin, Y. Zhang, M. Liu, and D. Ji, “Extracting entities and
    events as a single task using a transition-based neural model,” in IJCAI, 2019.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] J. Zhang, Y. Qin, Y. Zhang, M. Liu, 和 D. Ji, “使用基于过渡的神经模型将实体和事件提取为单一任务，”
    发表在 IJCAI, 2019。'
- en: '[59] D. Li, L. Huang, H. Ji, and J. Han, “Biomedical event extraction based
    on knowledge-driven tree-lstm,” in NAACL-HLT, 2019.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] D. Li, L. Huang, H. Ji, 和 J. Han, “基于知识驱动的树LSTM的生物医学事件提取，” 发表在 NAACL-HLT,
    2019。'
- en: '[60] J. Sheng, Q. Li, Y. Hei, S. Guo, B. Yu, L. Wang, M. He, T. Liu, and H. Xu,
    “A joint learning framework for the CCKS-2020 financial event extraction task,”
    Data Intell., 2021.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] J. Sheng, Q. Li, Y. Hei, S. Guo, B. Yu, L. Wang, M. He, T. Liu, 和 H. Xu，
    “用于 CCKS-2020 财务事件提取任务的联合学习框架”，发表于 Data Intell., 2021。'
- en: '[61] L. Huang, H. Ji, K. Cho, I. Dagan, S. Riedel, and C. R. Voss, “Zero-shot
    transfer learning for event extraction,” in ACL, 2018.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] L. Huang, H. Ji, K. Cho, I. Dagan, S. Riedel, 和 C. R. Voss， “事件提取的零样本迁移学习”，发表于
    ACL, 2018。'
- en: '[62] H. Funke, S. Breß, S. Noll, V. Markl, and J. Teubner, “Pipelined query
    processing in coprocessor environments,” in SIGMOD Conference, 2018.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] H. Funke, S. Breß, S. Noll, V. Markl, 和 J. Teubner， “协处理器环境中的管道查询处理”，发表于
    SIGMOD Conference, 2018。'
- en: '[63] M. Gasmi, O. Mosbahi, M. Khalgui, L. Gomes, and Z. Li, “R-node: New pipelined
    approach for an effective reconfigurable wireless sensor node,” IEEE Trans. Syst.
    Man Cybern. Syst., 2018.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] M. Gasmi, O. Mosbahi, M. Khalgui, L. Gomes, 和 Z. Li， “R-node：一种有效的可重构无线传感器节点的新管道方法”，发表于
    IEEE Trans. Syst. Man Cybern. Syst., 2018。'
- en: '[64] J. Devlin, M. Chang, K. Lee, and K. Toutanova, “BERT: pre-training of
    deep bidirectional transformers for language understanding,” in NAACL-HLT, 2019.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] J. Devlin, M. Chang, K. Lee, 和 K. Toutanova， “BERT：用于语言理解的深度双向变换器预训练”，发表于
    NAACL-HLT, 2019。'
- en: '[65] Y. Lin, H. Ji, F. Huang, and L. Wu, “A joint neural model for information
    extraction with global features,” in ACL, 2020.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] Y. Lin, H. Ji, F. Huang, 和 L. Wu， “一种结合全局特征的联合神经模型进行信息提取”，发表于 ACL, 2020。'
- en: '[66] M. V. Nguyen, V. D. Lai, and T. H. Nguyen, “Cross-task instance representation
    interactions and label dependencies for joint information extraction with graph
    convolutional networks,” in NAACL-HLT, 2021.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] M. V. Nguyen, V. D. Lai, 和 T. H. Nguyen， “用于联合信息提取的跨任务实例表示交互和标签依赖的图卷积网络”，发表于
    NAACL-HLT, 2021。'
- en: '[67] Z. Zhang and H. Ji, “Abstract meaning representation guided graph encoding
    and decoding for joint information extraction,” in NAACL-HLT, 2021.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] Z. Zhang 和 H. Ji， “以抽象意义表示为指导的图编码和解码用于联合信息提取”，发表于 NAACL-HLT, 2021。'
- en: '[68] Z. Zhu, S. Li, G. Zhou, and R. Xia, “Bilingual event extraction: a case
    study on trigger type determination,” in ACL, 2014.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] Z. Zhu, S. Li, G. Zhou, 和 R. Xia， “双语事件提取：以触发器类型确定为例”，发表于 ACL, 2014。'
- en: '[69] S. Liu, Y. Chen, S. He, K. Liu, and J. Zhao, “Leveraging framenet to improve
    automatic event detection,” in ACL, 2016.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] S. Liu, Y. Chen, S. He, K. Liu, 和 J. Zhao， “利用 Framenet 改进自动事件检测”，发表于
    ACL, 2016。'
- en: '[70] Y. Chen, S. Liu, X. Zhang, K. Liu, and J. Zhao, “Automatically labeled
    data generation for large scale event extraction,” in ACL, 2017.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] Y. Chen, S. Liu, X. Zhang, K. Liu, 和 J. Zhao， “大规模事件提取的自动标注数据生成”，发表于 ACL,
    2017。'
- en: '[71] Z. Wang, X. Wang, X. Han, Y. Lin, L. Hou, Z. Liu, P. Li, J. Li, and J. Zhou,
    “Cleve: Contrastive pre-training for event extraction,” CoRR, 2021.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] Z. Wang, X. Wang, X. Han, Y. Lin, L. Hou, Z. Liu, P. Li, J. Li, 和 J. Zhou，
    “Cleve：用于事件提取的对比预训练”，发表于 CoRR, 2021。'
- en: '[72] K. Wei, X. Sun, Z. Zhang, J. Zhang, G. Zhi, and L. Jin, “Trigger is not
    sufficient: Exploiting frame-aware knowledge for implicit event argument extraction,”
    in ACL-IJCNLP, 2021.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] K. Wei, X. Sun, Z. Zhang, J. Zhang, G. Zhi, 和 L. Jin， “触发器是不够的：利用框架感知知识进行隐性事件论元提取”，发表于
    ACL-IJCNLP, 2021。'
- en: '[73] R. Xu, T. Liu, L. Li, and B. Chang, “Document-level event extraction via
    heterogeneous graph-based interaction model with a tracker,” CoRR, 2021.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] R. Xu, T. Liu, L. Li, 和 B. Chang， “通过异构图交互模型和跟踪器进行文档级事件提取”，发表于 CoRR, 2021。'
- en: '[74] S. Zheng, W. Cao, W. Xu, and J. Bian, “Revisiting the evaluation of end-to-end
    event extraction,” in ACL-IJCNLP, 2021.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] S. Zheng, W. Cao, W. Xu, 和 J. Bian， “重新审视端到端事件提取的评估”，发表于 ACL-IJCNLP, 2021。'
- en: '[75] Y. Zhou, Y. Chen, J. Zhao, Y. Wu, J. Xu, and J. Li, “What the role is
    vs. what plays the role: Semi-supervised event argument extraction via dual question
    answering,” in AAAI, 2021.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] Y. Zhou, Y. Chen, J. Zhao, Y. Wu, J. Xu, 和 J. Li， “角色是什么与谁扮演角色：通过双重问答的半监督事件论元提取”，发表于
    AAAI, 2021。'
- en: '[76] X. Du, A. M. Rush, and C. Cardie, “GRIT: generative role-filler transformers
    for document-level event entity extraction,” in EACL, 2021.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] X. Du, A. M. Rush, 和 C. Cardie， “GRIT：用于文档级事件实体提取的生成角色填充变换器”，发表于 EACL,
    2021。'
- en: '[77] H. Wen, Y. Qu, H. Ji, Q. Ning, J. Han, A. Sil, H. Tong, and D. Roth, “Event
    time extraction and propagation via graph attention networks,” in NAACL-HLT, 2021.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] H. Wen, Y. Qu, H. Ji, Q. Ning, J. Han, A. Sil, H. Tong, 和 D. Roth， “通过图注意力网络进行事件时间提取和传播”，发表于
    NAACL-HLT, 2021。'
- en: '[78] P. Huang, X. Zhao, R. Takanobu, Z. Tan, and W. Xiao, “Joint event extraction
    with hierarchical policy network,” in COLING, 2020.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] P. Huang, X. Zhao, R. Takanobu, Z. Tan, 和 W. Xiao， “使用层次化策略网络的联合事件提取”，发表于
    COLING, 2020。'
- en: '[79] M. Li, A. Zareian, Q. Zeng, S. Whitehead, D. Lu, H. Ji, and S. Chang,
    “Cross-media structured common space for multimedia event extraction,” in ACL,
    2020.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] M. Li, A. Zareian, Q. Zeng, S. Whitehead, D. Lu, H. Ji, 和 S. Chang, “用于多媒体事件抽取的跨媒体结构化公共空间，”
    在 ACL，2020。'
- en: '[80] B. Min, Y. S. Chan, and L. Zhao, “Towards few-shot event mention retrieval:
    An evaluation framework and A siamese network approach,” in LREC, 2020.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] B. Min, Y. S. Chan, 和 L. Zhao, “迈向少样本事件提及检索：一个评估框架和一个孪生网络方法，” 在 LREC，2020。'
- en: '[81] Y. Chen, T. Chen, S. Ebner, A. S. White, and B. V. Durme, “Reading the
    manual: Event extraction as definition comprehension,” in NLP@EMNLP, 2020.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] Y. Chen, T. Chen, S. Ebner, A. S. White, 和 B. V. Durme, “阅读手册：将事件抽取视作定义理解，”
    在 NLP@EMNLP，2020。'
- en: '[82] S. Cui, B. Yu, T. Liu, Z. Zhang, X. Wang, and J. Shi, “Edge-enhanced graph
    convolution networks for event detection with syntactic relation,” in EMNLP (Findings),
    2020.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] S. Cui, B. Yu, T. Liu, Z. Zhang, X. Wang, 和 J. Shi, “边缘增强图卷积网络用于带有句法关系的事件检测，”
    在 EMNLP (Findings)，2020。'
- en: '[83] S. Zheng, W. Cao, W. Xu, and J. Bian, “Doc2edag: An end-to-end document-level
    framework for chinese financial event extraction,” in EMNLP-IJCNLP, 2019.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] S. Zheng, W. Cao, W. Xu, 和 J. Bian, “Doc2edag：一个用于中文金融事件抽取的端到端文档级框架，”
    在 EMNLP-IJCNLP，2019。'
- en: '[84] T. Zhang, H. Ji, and A. Sil, “Joint entity and event extraction with generative
    adversarial imitation learning,” Data Intell., no. 2, 2019.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] T. Zhang, H. Ji, 和 A. Sil, “通过生成对抗模仿学习进行实体和事件的联合抽取，” Data Intell., 第2期，2019。'
- en: '[85] D. Wadden, U. Wennberg, Y. Luan, and H. Hajishirzi, “Entity, relation,
    and event extraction with contextualized span representations,” in EMNLP-IJCNLP,
    2019.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] D. Wadden, U. Wennberg, Y. Luan, 和 H. Hajishirzi, “通过上下文化的跨度表示进行实体、关系和事件抽取，”
    在 EMNLP-IJCNLP，2019。'
- en: '[86] X. Wang, Z. Wang, X. Han, Z. Liu, J. Li, P. Li, M. Sun, J. Zhou, and X. Ren,
    “HMEAE: hierarchical modular event argument extraction,” in EMNLP-IJCNLP, 2019.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] X. Wang, Z. Wang, X. Han, Z. Liu, J. Li, P. Li, M. Sun, J. Zhou, 和 X.
    Ren, “HMEAE：层次模块化事件参数抽取，” 在 EMNLP-IJCNLP，2019。'
- en: '[87] R. Han, Q. Ning, and N. Peng, “Joint event and temporal relation extraction
    with shared representations and structured prediction,” in EMNLP-IJCNLP, 2019.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] R. Han, Q. Ning, 和 N. Peng, “联合事件和时间关系抽取，通过共享表示和结构化预测，” 在 EMNLP-IJCNLP，2019。'
- en: '[88] T. M. Nguyen and T. H. Nguyen, “One for all: Neural joint modeling of
    entities and events,” in AAAI, 2019.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] T. M. Nguyen 和 T. H. Nguyen, “一网打尽：实体和事件的神经联合建模，” 在 AAAI，2019。'
- en: '[89] Y. S. Chan, J. Fasching, H. Qiu, and B. Min, “Rapid customization for
    event extraction,” in ACL, 2019.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] Y. S. Chan, J. Fasching, H. Qiu, 和 B. Min, “事件抽取的快速定制，” 在 ACL，2019。'
- en: '[90] X. Li, F. Yin, Z. Sun, X. Li, A. Yuan, D. Chai, M. Zhou, and J. Li, “Entity-relation
    extraction as multi-turn question answering,” in ACL, 2019.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] X. Li, F. Yin, Z. Sun, X. Li, A. Yuan, D. Chai, M. Zhou, 和 J. Li, “将实体-关系抽取视作多轮问答，”
    在 ACL，2019。'
- en: '[91] H. Yang, Y. Chen, K. Liu, Y. Xiao, and J. Zhao, “DCFEE: A document-level
    chinese financial event extraction system based on automatically labeled training
    data,” in ACL, 2018.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] H. Yang, Y. Chen, K. Liu, Y. Xiao, 和 J. Zhao, “DCFEE：一个基于自动标注训练数据的文档级中文金融事件抽取系统，”
    在 ACL，2018。'
- en: '[92] Y. Zeng, Y. Feng, R. Ma, Z. Wang, R. Yan, C. Shi, and D. Zhao, “Scale
    up event extraction learning via automatic training data generation,” in AAAI,
    2018.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] Y. Zeng, Y. Feng, R. Ma, Z. Wang, R. Yan, C. Shi, 和 D. Zhao, “通过自动训练数据生成提升事件抽取学习的规模，”
    在 AAAI，2018。'
- en: '[93] Y. Zhao, X. Jin, Y. Wang, and X. Cheng, “Document embedding enhanced event
    detection with hierarchical and supervised attention,” in ACL, 2018.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] Y. Zhao, X. Jin, Y. Wang, 和 X. Cheng, “文档嵌入增强的事件检测，结合层次和监督注意力，” 在 ACL，2018。'
- en: '[94] Y. Hong, W. Zhou, J. Zhang, Q. Zhu, and G. Zhou, “Self-regulation: Employing
    a generative adversarial network to improve event detection,” in ACL, 2018.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] Y. Hong, W. Zhou, J. Zhang, Q. Zhu, 和 G. Zhou, “自我调节：利用生成对抗网络改进事件检测，”
    在 ACL，2018。'
- en: '[95] L. Sha, F. Qian, B. Chang, and Z. Sui, “Jointly extracting event triggers
    and arguments by dependency-bridge RNN and tensor-based argument interaction,”
    in AAAI, 2018.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] L. Sha, F. Qian, B. Chang, 和 Z. Sui, “通过依赖桥RNN和基于张量的参数交互共同抽取事件触发词和参数，”
    在 AAAI，2018。'
- en: '[96] X. Liu, Z. Luo, and H. Huang, “Jointly multiple events extraction via
    attention-based graph information aggregation,” in EMNLP, 2018.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] X. Liu, Z. Luo, 和 H. Huang, “通过基于注意力的图信息聚合进行联合多事件抽取，” 在 EMNLP，2018。'
- en: '[97] S. Liu, Y. Chen, K. Liu, and J. Zhao, “Exploiting argument information
    to improve event detection via supervised attention mechanisms,” in ACL, 2017.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] S. Liu, Y. Chen, K. Liu, 和 J. Zhao, “利用论元信息通过监督注意机制提升事件检测，” 在 ACL，2017。'
- en: '[98] L. Sha, J. Liu, C. Lin, S. Li, B. Chang, and Z. Sui, “RBPB: regularization-based
    pattern balancing method for event extraction,” in ACL, 2016.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] L. Sha, J. Liu, C. Lin, S. Li, B. Chang 和 Z. Sui，“RBPB：基于正则化的模式平衡方法用于事件抽取”，发表于
    ACL，2016。'
- en: '[99] Y. Zeng, H. Yang, Y. Feng, Z. Wang, and D. Zhao, “A convolution bilstm
    neural network model for chinese event extraction,” in NLPCC, 2016.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] Y. Zeng, H. Yang, Y. Feng, Z. Wang 和 D. Zhao，“一种用于中文事件抽取的卷积 BiLSTM 神经网络模型”，发表于
    NLPCC，2016。'
- en: '[100] Y. Chen, S. Liu, S. He, K. Liu, and J. Zhao, “Event extraction via bidirectional
    long short-term memory tensor neural networks,” in CCL, 2016.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] Y. Chen, S. Liu, S. He, K. Liu 和 J. Zhao，“通过双向长短期记忆张量神经网络进行事件抽取”，发表于
    CCL，2016。'
- en: '[101] Z. Zhang, W. Xu, and Q. Chen, “Joint event extraction based on skip-window
    convolutional neural networks,” in NLPCC, 2016, 2016.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] Z. Zhang, W. Xu 和 Q. Chen，“基于跳跃窗口卷积神经网络的联合事件抽取”，发表于 NLPCC，2016，2016。'
- en: '[102] T. H. Nguyen and R. Grishman, “Modeling skip-grams for event detection
    with convolutional neural networks,” in EMNLP, 2016.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] T. H. Nguyen 和 R. Grishman，“使用卷积神经网络建模跳跃词组用于事件检测”，发表于 EMNLP，2016。'
- en: '[103] Y. Hei, R. Yang, H. Peng, L. Wang, X. Xu, J. Liu, H. Liu, J. Xu, and
    L. Sun, “HAWK: rapid android malware detection through heterogeneous graph attention
    networks,” CoRR, 2021.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] Y. Hei, R. Yang, H. Peng, L. Wang, X. Xu, J. Liu, H. Liu, J. Xu 和 L.
    Sun，“HAWK：通过异构图注意网络快速检测安卓恶意软件”，CoRR，2021。'
- en: '[104] Q. Sun, J. Li, H. Peng, J. Wu, Y. Ning, P. S. Yu, and L. He, “SUGAR:
    subgraph neural network with reinforcement pooling and self-supervised mutual
    information mechanism,” in WWW, 2021.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] Q. Sun, J. Li, H. Peng, J. Wu, Y. Ning, P. S. Yu 和 L. He，“SUGAR：带有强化池化和自监督互信息机制的子图神经网络”，发表于
    WWW，2021。'
- en: '[105] Q. Sun, J. Li, H. Peng, J. Wu, X. Fu, C. Ji, and P. S. Yu, “Graph structure
    learning with variational information bottleneck,” in AAAI, 2022.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] Q. Sun, J. Li, H. Peng, J. Wu, X. Fu, C. Ji 和 P. S. Yu，“具有变分信息瓶颈的图结构学习”，发表于
    AAAI，2022。'
- en: '[106] J. Liu, Y. Chen, K. Liu, W. Bi, and X. Liu, “Event extraction as machine
    reading comprehension,” in EMNLP, 2020, 2020.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] J. Liu, Y. Chen, K. Liu, W. Bi 和 X. Liu，“将事件抽取视为机器阅读理解”，发表于 EMNLP，2020，2020。'
- en: '[107] Q. Li, S. Guo, J. Wu, J. Li, J. Sheng, L. Wang, X. Dong, and H. Peng,
    “Event extraction by associating event types and argument roles,” CoRR, 2021.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] Q. Li, S. Guo, J. Wu, J. Li, J. Sheng, L. Wang, X. Dong 和 H. Peng，“通过关联事件类型和论元角色进行事件抽取”，CoRR，2021。'
- en: '[108] T. H. Nguyen and R. Grishman, “Event detection and domain adaptation
    with convolutional neural networks,” in ACL, 2015.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] T. H. Nguyen 和 R. Grishman，“使用卷积神经网络进行事件检测和领域适应”，发表于 ACL，2015。'
- en: '[109] X. Feng, L. Huang, D. Tang, H. Ji, B. Qin, and T. Liu, “A language-independent
    neural network for event detection,” in ACL, 2016.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] X. Feng, L. Huang, D. Tang, H. Ji, B. Qin 和 T. Liu，“一种用于事件检测的语言无关神经网络”，发表于
    ACL，2016。'
- en: '[110] T. H. Nguyen and R. Grishman, “Graph convolutional networks with argument-aware
    pooling for event detection,” in AAAI, 2018.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] T. H. Nguyen 和 R. Grishman，“带有论元感知池化的图卷积网络用于事件检测”，发表于 AAAI，2018。'
- en: '[111] L. Yao, C. Mao, and Y. Luo, “Graph convolutional networks for text classification,”
    in AAAI, 2019.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] L. Yao, C. Mao 和 Y. Luo，“用于文本分类的图卷积网络”，发表于 AAAI，2019。'
- en: '[112] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and
    L. Zettlemoyer, “Deep contextualized word representations,” in NAACL-HLT, 2018.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee 和 L.
    Zettlemoyer，“深度上下文化词表示”，发表于 NAACL-HLT，2018。'
- en: '[113] X. Du and C. Cardie, “Document-level event role filler extraction using
    multi-granularity contextualized encoding,” in ACL, 2020.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] X. Du 和 C. Cardie，“使用多粒度上下文化编码的文档级事件角色填充抽取”，发表于 ACL，2020。'
- en: '[114] X. Du, A. Rush, and C. Cardie, “GRIT: Generative role-filler transformers
    for document-level event entity extraction,” in ACL, 2021.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] X. Du, A. Rush 和 C. Cardie，“GRIT：用于文档级事件实体抽取的生成角色填充变换器”，发表于 ACL，2021。'
- en: '[115] Fourth Message Uunderstanding Conference (MUC-4): Proceedings of a Conference
    Held in McLean, Virginia, June 16-18, 1992, 1992.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] 第四届信息理解会议（MUC-4）：1992年6月16日至18日在弗吉尼亚州麦克莱恩举行的会议论文集，1992。'
- en: '[116] S. Ebner, P. Xia, R. Culkin, K. Rawlins, and B. Van Durme, “Multi-sentence
    argument linking,” in ACL, 2020.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] S. Ebner, P. Xia, R. Culkin, K. Rawlins 和 B. Van Durme，“多句子论元链接”，发表于
    ACL，2020。'
- en: '[117] Z. Zhang, X. Kong, Z. Liu, X. Ma, and E. Hovy, “A two-step approach for
    implicit event argument detection,” in ACL, 2020.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] Z. Zhang, X. Kong, Z. Liu, X. Ma 和 E. Hovy，“一种隐式事件论元检测的两步方法”，发表于 ACL，2020。'
- en: '[118] H. Yang, Y. Chen, K. Liu, Y. Xiao, and J. Zhao, “DCFEE: A document-level
    Chinese financial event extraction system based on automatically labeled training
    data,” in ACL, 2018.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] H. Yang, Y. Chen, K. Liu, Y. Xiao 和 J. Zhao，“DCFEE：基于自动标注训练数据的文档级中文金融事件抽取系统”，发表于
    ACL，2018。'
- en: '[119] K.-H. Huang and N. Peng, “Document-level event extraction with efficient
    end-to-end learning of cross-event dependencies,” in Proceedings of the Third
    Workshop on Narrative Understanding, 2021.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] K.-H. Huang 和 N. Peng，“文档级事件抽取与高效的端到端跨事件依赖学习”，发表于《第三届叙事理解研讨会》，2021年。'
- en: '[120] S. Li, H. Ji, and J. Han, “Document-level event argument extraction by
    conditional generation,” in ACL, 2021.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] S. Li, H. Ji 和 J. Han，“通过条件生成进行文档级事件参数抽取”，发表于 ACL，2021年。'
- en: '[121] H. Yang, D. Sui, Y. Chen, K. Liu, J. Zhao, and T. Wang, “Document-level
    event extraction via parallel prediction networks,” in ACL-IJCNLP, 2021.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] H. Yang, D. Sui, Y. Chen, K. Liu, J. Zhao 和 T. Wang，“通过并行预测网络进行文档级事件抽取”，发表于
    ACL-IJCNLP，2021年。'
- en: '[122] Y. Huang and W. Jia, “Exploring sentence community for document-level
    event extraction,” in EMNLP, 2021.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] Y. Huang 和 W. Jia，“探索句子社区进行文档级事件抽取”，发表于 EMNLP，2021年。'
- en: '[123] X. Du, A. Rush, and C. Cardie, “Template filling with generative transformers,”
    in ACL, 2021.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] X. Du, A. Rush 和 C. Cardie，“使用生成式变换器的模板填充”，发表于 ACL，2021年。'
- en: '[124] L. Huang and H. Ji, “Semi-supervised new event type induction and event
    detection,” in EMNLP, 2020.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] L. Huang 和 H. Ji，“半监督新事件类型引导与事件检测”，发表于 EMNLP，2020年。'
- en: '[125] O. Vinyals, C. Blundell, T. Lillicrap, D. Wierstra, et al., “Matching
    networks for one shot learning,” Advances in neural information processing systems,
    2016.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] O. Vinyals, C. Blundell, T. Lillicrap, D. Wierstra 等，“用于一次学习的匹配网络”，发表于《神经信息处理系统进展》，2016年。'
- en: '[126] C. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning for
    fast adaptation of deep networks,” in International Conference on Machine Learning,
    PMLR, 2017.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] C. Finn, P. Abbeel 和 S. Levine，“面向深度网络快速适应的模型无关元学习”，发表于国际机器学习会议，PMLR，2017年。'
- en: '[127] J. Sheng, S. Guo, Z. Chen, J. Yue, L. Wang, T. Liu, and H. Xu, “Adaptive
    attentional network for few-shot knowledge graph completion,” in EMNLP, 2020.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] J. Sheng, S. Guo, Z. Chen, J. Yue, L. Wang, T. Liu 和 H. Xu，“面向少样本知识图谱补全的自适应注意力网络”，发表于
    EMNLP，2020年。'
- en: '[128] Z. Ye and Z. Ling, “Multi-level matching and aggregation network for
    few-shot relation classification,” in ACL, 2019.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] Z. Ye 和 Z. Ling，“用于少样本关系分类的多层次匹配与聚合网络”，发表于 ACL，2019年。'
- en: '[129] V. D. Lai, F. Dernoncourt, and T. H. Nguyen, “Exploiting the matching
    information in the support set for few shot event classification,” Advances in
    Knowledge Discovery and Data Mining, 2020.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] V. D. Lai, F. Dernoncourt 和 T. H. Nguyen，“利用支持集中的匹配信息进行少样本事件分类”，发表于《知识发现与数据挖掘进展》，2020年。'
- en: '[130] V. D. Lai, F. Dernoncourt, and T. H. Nguyen, “Extensively matching for
    few-shot learning event detection,” CoRR, 2020.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] V. D. Lai, F. Dernoncourt 和 T. H. Nguyen，“广泛匹配以进行少样本学习事件检测”，发表于 CoRR，2020年。'
- en: '[131] S. Shen, T. Wu, G. Qi, Y. Li, G. Haffari, and S. Bi, “Adaptive knowledge-enhanced
    bayesian meta-learning for few-shot event detection,” in ACL/IJCNLP, Findings
    of ACL, 2021.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] S. Shen, T. Wu, G. Qi, Y. Li, G. Haffari 和 S. Bi，“面向少样本事件检测的自适应知识增强贝叶斯元学习”，发表于
    ACL/IJCNLP，ACL 发现，2021年。'
- en: '[132] V. Lai, F. Dernoncourt, and T. H. Nguyen, “Learning prototype representations
    across few-shot tasks for event detection,” in EMNLP, 2021.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] V. Lai, F. Dernoncourt 和 T. H. Nguyen，“跨少样本任务学习原型表示以进行事件检测”，发表于 EMNLP，2021年。'
- en: '[133] J. Zheng, F. Cai, W. Chen, W. Lei, and H. Chen, “Taxonomy-aware learning
    for few-shot event detection,” in WWW, 2021.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] J. Zheng, F. Cai, W. Chen, W. Lei 和 H. Chen，“面向分类的少样本事件检测的分类体系学习”，发表于
    WWW，2021年。'
- en: '[134] V. D. Lai, M. V. Nguyen, T. H. Nguyen, and F. Dernoncourt, “Graph learning
    regularization and transfer learning for few-shot event detection,” in ACM SIGIR,
    2021.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] V. D. Lai, M. V. Nguyen, T. H. Nguyen 和 F. Dernoncourt，“图学习正则化与迁移学习在少样本事件检测中的应用”，发表于
    ACM SIGIR，2021年。'
- en: '[135] S. Deng, N. Zhang, J. Kang, Y. Zhang, W. Zhang, and H. Chen, “Meta-learning
    with dynamic-memory-based prototypical network for few-shot event detection,”
    in WSDM, 2020.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] S. Deng, N. Zhang, J. Kang, Y. Zhang, W. Zhang 和 H. Chen，“基于动态记忆的原型网络的元学习用于少样本事件检测”，发表于
    WSDM，2020年。'
- en: '[136] X. Cong, S. Cui, B. Yu, T. Liu, Y. Wang, and B. Wang, “Few-shot event
    detection with prototypical amortized conditional random field,” CoRR, 2020.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] X. Cong, S. Cui, B. Yu, T. Liu, Y. Wang 和 B. Wang，“基于原型的摊销条件随机场的少样本事件检测”，发表于
    CoRR，2020年。'
- en: '[137] J. Chen, H. Lin, X. Han, and L. Sun, “Honey or poison? solving the trigger
    curse in few-shot event detection via causal intervention,” in EMNLP, 2021.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] J. Chen, H. Lin, X. Han 和 L. Sun，“蜜糖还是毒药？通过因果干预解决少样本事件检测中的触发器诅咒”，发表于
    EMNLP，2021年。'
- en: '[138] Q. Lyu, H. Zhang, E. Sulem, and D. Roth, “Zero-shot event extraction
    via transfer learning: Challenges and insights,” in ACL/IJCNLP, 2021.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] Q. Lyu, H. Zhang, E. Sulem 和 D. Roth，“通过迁移学习进行零样本事件抽取：挑战与见解”，发表于 ACL/IJCNLP，2021年。'
- en: '[139] M. B. Ring et al., “Continual learning in reinforcement environments,”
    1994.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] M. B. Ring 等，“强化学习环境中的持续学习”，1994年。'
- en: '[140] S. Thrun, “Lifelong learning algorithms,” in Learning to learn, 1998.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] S. Thrun，“终身学习算法”，收录于《学习如何学习》，1998年。'
- en: '[141] P. Cao, Y. Chen, J. Zhao, and T. Wang, “Incremental event detection via
    knowledge consolidation networks,” in EMNLP, 2020.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] P. Cao，Y. Chen，J. Zhao 和 T. Wang，“通过知识整合网络的增量事件检测”，收录于EMNLP，2020年。'
- en: '[142] A. Hsi, Y. Yang, J. G. Carbonell, and R. Xu, “Leveraging multilingual
    training for limited resource event extraction,” in COLING, 2016.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] A. Hsi，Y. Yang，J. G. Carbonell 和 R. Xu，“利用多语言训练进行有限资源事件提取”，收录于COLING，2016年。'
- en: '[143] J. Liu, Y. Chen, K. Liu, and J. Zhao, “Event detection via gated multilingual
    attention mechanism,” in AAAI, 2018.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] J. Liu，Y. Chen，K. Liu 和 J. Zhao，“通过门控多语言注意机制进行事件检测”，收录于AAAI，2018年。'
- en: '[144] Z. Chen and H. Ji, “Language specific issue and feature exploration in
    Chinese event extraction,” in HLT-NAACL (Short Papers), 2009.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] Z. Chen 和 H. Ji，“中文事件提取中的语言特定问题与特征探索”，收录于HLT-NAACL（短篇论文），2009年。'
- en: '[145] P. Li, G. Zhou, Q. Zhu, and L. Hou, “Employing compositional semantics
    and discourse consistency in Chinese event extraction,” in EMNLP-CoNLL, 2012.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] P. Li，G. Zhou，Q. Zhu 和 L. Hou，“在中文事件提取中利用组合语义和话语一致性”，收录于EMNLP-CoNLL，2012年。'
- en: '[146] B. Qin, Y. Zhao, X. Ding, T. Liu, and G. Zhai, “Event type recognition
    based on trigger expansion,” Tsinghua Science & Technology, 2010.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] B. Qin，Y. Zhao，X. Ding，T. Liu 和 G. Zhai，“基于触发器扩展的事件类型识别”，《清华科学与技术》，2010年。'
- en: '[147] P. Li and G. Zhou, “Employing morphological structures and sememes for
    Chinese event extraction,” in COLING, 2012.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] P. Li 和 G. Zhou，“利用形态结构和语义单元进行中文事件提取”，收录于COLING，2012年。'
- en: '[148] N. Xu, H. Xie, and D. Zhao, “A novel joint framework for multiple Chinese
    events extraction,” in CNCL, 2020.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] N. Xu，H. Xie 和 D. Zhao，“一种用于多重中文事件提取的新型联合框架”，收录于CNCL，2020年。'
- en: '[149] H. Lin, Y. Lu, X. Han, and L. Sun, “Nugget proposal networks for Chinese
    event detection,” in ACL, 2018.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] H. Lin，Y. Lu，X. Han 和 L. Sun，“用于中文事件检测的Nugget提案网络”，收录于ACL，2018年。'
- en: '[150] N. Ding, Z. Li, Z. Liu, H. Zheng, and Z. Lin, “Event detection with trigger-aware
    lattice neural network,” in EMNLP-IJCNLP, 2019.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] N. Ding，Z. Li，Z. Liu，H. Zheng 和 Z. Lin，“基于触发器感知的格状神经网络进行事件检测”，收录于EMNLP-IJCNLP，2019年。'
- en: '[151] Y. Zhang and J. Yang, “Chinese NER using lattice LSTM,” in ACL, (Melbourne,
    Australia), 2018.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] Y. Zhang 和 J. Yang，“使用格状LSTM的中文NER”，收录于ACL（澳大利亚墨尔本），2018年。'
- en: '[152] S. Cui, B. Yu, X. Cong, T. Liu, Q. Li, and J. Shi, “Label enhanced event
    detection with heterogeneous graph attention networks,” ArXiv, 2020.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] S. Cui，B. Yu，X. Cong，T. Liu，Q. Li 和 J. Shi，“基于异质图注意网络的标签增强事件检测”，ArXiv，2020年。'
- en: '[153] S. Petrovic, M. Osborne, R. McCreadie, C. Macdonald, I. Ounis, and L. Shrimpton,
    “Can twitter replace newswire for breaking news?,” in ICWSM, 2013.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] S. Petrovic，M. Osborne，R. McCreadie，C. Macdonald，I. Ounis 和 L. Shrimpton，“Twitter能否替代新闻线以获取突发新闻？”，收录于ICWSM，2013年。'
- en: '[154] V. Lai, M. Van Nguyen, H. Kaufman, and T. H. Nguyen, “Event extraction
    from historical texts: A new dataset for black rebellions,” in ACL-IJCNLP, 2021.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] V. Lai，M. Van Nguyen，H. Kaufman 和 T. H. Nguyen，“从历史文本中提取事件：一个关于黑人民族起义的新数据集”，收录于ACL-IJCNLP，2021年。'
- en: '[155] L. Huang, T. Cassidy, X. Feng, H. Ji, C. R. Voss, J. Han, and A. Sil,
    “Liberal event extraction and event schema induction,” in ACL, 2016.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] L. Huang，T. Cassidy，X. Feng，H. Ji，C. R. Voss，J. Han 和 A. Sil，“自由事件提取和事件模式引导”，收录于ACL，2016年。'
- en: '[156] S. Deng, N. Zhang, J. Kang, Y. Zhang, W. Zhang, and H. Chen, “Meta-learning
    with dynamic-memory-based prototypical network for few-shot event detection,”
    in WSDM, 2020.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] S. Deng，N. Zhang，J. Kang，Y. Zhang，W. Zhang 和 H. Chen，“基于动态记忆原型网络的元学习用于小样本事件检测”，收录于WSDM，2020年。'
- en: '[157] A. M. Davani, L. Yeh, M. Atari, B. Kennedy, G. Portillo-Wightman, E. Gonzalez,
    N. Delong, R. Bhatia, A. Mirinjian, X. Ren, and M. Dehghani, “Reporting the unreported:
    Event extraction for analyzing the local representation of hate crimes,” in EMNLP-IJCNLP,
    2019.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] A. M. Davani，L. Yeh，M. Atari，B. Kennedy，G. Portillo-Wightman，E. Gonzalez，N.
    Delong，R. Bhatia，A. Mirinjian，X. Ren 和 M. Dehghani，“报道未被报道的事件：分析仇恨犯罪地方表现的事件提取”，收录于EMNLP-IJCNLP，2019年。'
- en: '[158] X. Wang, Z. Wang, X. Han, W. Jiang, R. Han, Z. Liu, J. Li, P. Li, Y. Lin,
    and J. Zhou, “Maven: A massive general domain event detection dataset,” CoRR,
    2020.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] X. Wang，Z. Wang，X. Han，W. Jiang，R. Han，Z. Liu，J. Li，P. Li，Y. Lin 和 J.
    Zhou，“Maven：一个大规模的通用领域事件检测数据集”，CoRR，2020年。'
- en: '[159] H. Ji and R. Grishman, “Refining event extraction through cross-document
    inference,” in ACL, 2008.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[159] H. Ji 和 R. Grishman，“通过跨文档推理精炼事件提取”，收录于ACL，2008年。'
- en: '[160] S. Liao and R. Grishman, “Using document level cross-event inference
    to improve event extraction,” in ACL, 2010.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[160] S. Liao 和 R. Grishman，“利用文档级跨事件推理来改善事件提取，” 在 ACL，2010。'
- en: '[161] Y. Hong, J. Zhang, B. Ma, J. Yao, G. Zhou, and Q. Zhu, “Using cross-entity
    inference to improve event extraction,” in ACL, 2011.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[161] Y. Hong, J. Zhang, B. Ma, J. Yao, G. Zhou, 和 Q. Zhu，“利用跨实体推理来改善事件提取，”
    在 ACL，2011。'
- en: '[162] J. Liu, Y. Chen, K. Liu, and J. Zhao, “Neural cross-lingual event detection
    with minimal parallel resources,” in EMNLP-IJCNLP, 2019.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[162] J. Liu, Y. Chen, K. Liu, 和 J. Zhao，“基于最小平行资源的神经跨语言事件检测，” 在 EMNLP-IJCNLP，2019。'
- en: '[163] S. Li, H. Ji, and J. Han, “Document-level event argument extraction by
    conditional generation,” in NAACL-HLT, 2021.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[163] S. Li, H. Ji, 和 J. Han，“基于条件生成的文档级事件参数提取，” 在 NAACL-HLT，2021。'
- en: '[164] W. Li, D. Cheng, L. He, Y. Wang, and X. Jin, “Joint event extraction
    based on hierarchical event schemas from framenet,” IEEE Access, 2019.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[164] W. Li, D. Cheng, L. He, Y. Wang, 和 X. Jin，“基于从 framenet 中的层次事件模式的联合事件提取，”
    IEEE Access，2019。'
- en: '[165] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    L. Kaiser, and I. Polosukhin, “Attention is all you need,” in NeurIPS, 2017.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[165] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    L. Kaiser, 和 I. Polosukhin，“注意力机制才是你所需要的，” 在 NeurIPS，2017。'
- en: '[166] K. Liu, Y. Chen, J. Liu, X. Zuo, and J. Zhao, “Extracting events and
    their relations from texts: A survey on recent research progress and challenges,”
    AI Open, 2020.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[166] K. Liu, Y. Chen, J. Liu, X. Zuo, 和 J. Zhao，“从文本中提取事件及其关系：最近研究进展和挑战的调查，”
    AI Open，2020。'
- en: '[167] X. Ding, Z. Li, T. Liu, and K. Liao, “ELG: an event logic graph,” CoRR,
    2019.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[167] X. Ding, Z. Li, T. Liu, 和 K. Liao，“ELG：事件逻辑图，” CoRR，2019。'
- en: '[168] J. Liu, L. Min, and X. Huang, “An overview of event extraction and its
    applications,” CoRR, 2021.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[168] J. Liu, L. Min, 和 X. Huang，“事件提取及其应用概述，” CoRR，2021。'
- en: '[169] T. S. Costa, S. Gottschalk, and E. Demidova, “Event-qa: A dataset for
    event-centric question answering over knowledge graphs,” in CIKM, 2020.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[169] T. S. Costa, S. Gottschalk, 和 E. Demidova，“Event-qa：一个用于知识图谱中以事件为中心的问题回答的数据集，”
    在 CIKM，2020。'
- en: '[170] J. Wang, A. Jatowt, M. Färber, and M. Yoshikawa, “Answering event-related
    questions over long-term news article archives,” in ECIR, Lecture Notes in Computer
    Science, 2020.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[170] J. Wang, A. Jatowt, M. Färber, 和 M. Yoshikawa，“回答长期新闻文章档案中的事件相关问题，” 在
    ECIR，计算机科学讲义，2020。'
- en: '[171] R. Han, I. Hsu, J. Sun, J. Baylon, Q. Ning, D. Roth, and N. Peng, “ESTER:
    A machine reading comprehension dataset for reasoning about event semantic relations,”
    in EMNLP, 2021.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[171] R. Han, I. Hsu, J. Sun, J. Baylon, Q. Ning, D. Roth, 和 N. Peng，“ESTER：用于推理事件语义关系的机器阅读理解数据集，”
    在 EMNLP，2021。'
- en: '[172] P. Cao, Y. Chen, Y. Yang, K. Liu, and J. Zhao, “Uncertain local-to-global
    networks for document-level event factuality identification,” in EMNLP, 2021.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[172] P. Cao, Y. Chen, Y. Yang, K. Liu, 和 J. Zhao，“不确定的局部到全球网络用于文档级事件事实性识别，”
    在 EMNLP，2021。'
- en: '[173] J. Pustejovsky and R. Saurí, “A factuality profiler for eventualities
    in text,” 2008.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[173] J. Pustejovsky 和 R. Saurí，“文本中事件的事实性分析器，” 2008。'
- en: '[174] R. Saurí and J. Pustejovsky, “Are you sure that this happened? assessing
    the factuality degree of events in text,” Comput. Linguistics, 2012.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[174] R. Saurí 和 J. Pustejovsky，“你确定这发生了吗？评估文本中事件的事实性程度，” 计算语言学，2012。'
- en: '[175] M. de Marneffe, C. D. Manning, and C. Potts, “Did it happen? the pragmatic
    complexity of veridicality assessment,” Comput. Linguistics, 2012.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[175] M. de Marneffe, C. D. Manning, 和 C. Potts，“它发生了吗？真实性评估的实用复杂性，” 计算语言学，2012。'
- en: '[176] R. Rudinger, A. S. White, and B. V. Durme, “Neural models of factuality,”
    in NAACL-HLT, 2018.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[176] R. Rudinger, A. S. White, 和 B. V. Durme，“事实性神经模型，” 在 NAACL-HLT，2018。'
- en: '[177] A. P. B. Veyseh, T. H. Nguyen, and D. Dou, “Graph based neural networks
    for event factuality prediction using syntactic and semantic structures,” in ACL,
    2019.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[177] A. P. B. Veyseh, T. H. Nguyen, 和 D. Dou，“基于图的神经网络用于事件事实性预测，结合句法和语义结构，”
    在 ACL，2019。'
- en: '[178] R. Nairn, C. Condoravdi, and L. Karttunen, “Computing relative polarity
    for textual inference,” in Proceedings of the Fifth International Workshop on
    Inference in Computational Semantics (ICoS-5), 2006.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[178] R. Nairn, C. Condoravdi, 和 L. Karttunen，“计算文本推理的相对极性，” 在第五届国际计算语义学推理研讨会（ICoS-5）论文集，2006。'
- en: '[179] A. Lotan, A. Stern, and I. Dagan, “Truthteller: Annotating predicate
    truth,” in NAACL-HLT, 2013.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[179] A. Lotan, A. Stern, 和 I. Dagan，“Truthteller：谓词真实性标注，” 在 NAACL-HLT，2013。'
- en: '[180] M. T. Diab, L. S. Levin, T. Mitamura, O. Rambow, V. Prabhakaran, and
    W. Guo, “Committed belief annotation and tagging,” in LAW, 2009.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[180] M. T. Diab, L. S. Levin, T. Mitamura, O. Rambow, V. Prabhakaran, 和 W.
    Guo，“承诺信念标注与标记，” 在 LAW，2009。'
- en: '[181] V. Prabhakaran, O. Rambow, and M. T. Diab, “Automatic committed belief
    tagging,” in COLING, 2010.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[181] V. Prabhakaran, O. Rambow, 和 M. T. Diab，“自动承诺信念标记，”发表于 COLING, 2010。'
- en: '[182] K. Lee, Y. Artzi, Y. Choi, and L. Zettlemoyer, “Event detection and factuality
    assessment with non-expert supervision,” in EMNLP, 2015.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[182] K. Lee, Y. Artzi, Y. Choi, 和 L. Zettlemoyer，“在非专家监督下的事件检测和事实性评估，”发表于
    EMNLP, 2015。'
- en: '[183] Z. Qian, P. Li, and Q. Zhu, “A two-step approach for event factuality
    identification,” in IALP, 2015.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[183] Z. Qian, P. Li, 和 Q. Zhu，“一种两步法用于事件事实性识别，”发表于 IALP, 2015。'
- en: '[184] Z. Qian, P. Li, Y. Zhang, G. Zhou, and Q. Zhu, “Event factuality identification
    via generative adversarial networks with auxiliary classification,” in IJCAI,
    2018.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[184] Z. Qian, P. Li, Y. Zhang, G. Zhou, 和 Q. Zhu，“通过生成对抗网络和辅助分类进行事件事实性识别，”发表于
    IJCAI, 2018。'
- en: '[185] J. Sheng, B. Zou, Z. Gong, Y. Hong, and G. Zhou, “Chinese event factuality
    detection,” in NLPCC, Lecture Notes in Computer Science, 2019.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[185] J. Sheng, B. Zou, Z. Gong, Y. Hong, 和 G. Zhou，“中文事件事实性检测，”发表于 NLPCC,
    Lecture Notes in Computer Science, 2019。'
- en: '[186] R. Huang, B. Zou, H. Wang, P. Li, and G. Zhou, “Event factuality detection
    in discourse,” in NLPCC, Lecture Notes in Computer Science, 2019.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[186] R. Huang, B. Zou, H. Wang, P. Li, 和 G. Zhou，“话语中的事件事实性检测，”发表于 NLPCC,
    Lecture Notes in Computer Science, 2019。'
- en: '[187] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
    S. Ozair, A. C. Courville, and Y. Bengio, “Generative adversarial nets,” in NeurIPS,
    2014.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[187] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
    S. Ozair, A. C. Courville, 和 Y. Bengio，“生成对抗网络，”发表于 NeurIPS, 2014。'
- en: '[188] T. N. Kipf and M. Welling, “Semi-supervised classification with graph
    convolutional networks,” in ICLR, 2017.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[188] T. N. Kipf 和 M. Welling，“基于图卷积网络的半监督分类，”发表于 ICLR, 2017。'
- en: '[189] Z. Qian, P. Li, Q. Zhu, and G. Zhou, “Document-level event factuality
    identification via adversarial neural network,” in NAACL-HLT, 2019.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[189] Z. Qian, P. Li, Q. Zhu, 和 G. Zhou，“通过对抗神经网络进行文档级事件事实性识别，”发表于 NAACL-HLT,
    2019。'
- en: '[190] A. Cybulska and P. Vossen, “Translating granularity of event slots into
    features for event coreference resolution.,” in EVENTS@HLP-NAACL, 2015.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[190] A. Cybulska 和 P. Vossen，“将事件槽的粒度转化为事件共指解析的特征，”发表于 EVENTS@HLP-NAACL, 2015。'
- en: '[191] J. Lu and V. Ng, “Learning antecedent structures for event coreference
    resolution,” in ICMLA, 2017.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[191] J. Lu 和 V. Ng，“学习事件共指解析的前体结构，”发表于 ICMLA, 2017。'
- en: '[192] C. A. Bejan and S. M. Harabagiu, “Unsupervised event coreference resolution
    with rich linguistic features,” in ACL, 2010.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[192] C. A. Bejan 和 S. M. Harabagiu，“使用丰富的语言特征进行无监督事件共指解析，”发表于 ACL, 2010。'
- en: '[193] P. K. Choubey and R. Huang, “Improving event coreference resolution by
    modeling correlations between event coreference chains and document topic structures,”
    in ACL, 2018.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[193] P. K. Choubey 和 R. Huang，“通过建模事件共指链和文档主题结构之间的相关性来改进事件共指解析，”发表于 ACL, 2018。'
- en: '[194] Y. J. Huang, J. Lu, S. Kurohashi, and V. Ng, “Improving event coreference
    resolution by learning argument compatibility from unlabeled data,” in ACL, 2019.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[194] Y. J. Huang, J. Lu, S. Kurohashi, 和 V. Ng，“通过从未标记数据中学习论证兼容性来改进事件共指解析，”发表于
    ACL, 2019。'
- en: '[195] Z. Chen, H. Ji, and R. M. Haralick, “A pairwise event coreference model,
    feature impact and evaluation for event coreference resolution,” in Proceedings
    of the workshop on events in emerging text types, 2009.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[195] Z. Chen, H. Ji, 和 R. M. Haralick，“一对一事件共指模型、特征影响和事件共指解析的评估，”发表于 Emergent
    Text Types Events Workshop, 2009。'
- en: '[196] Z. Chen and H. Ji, “Graph-based event coreference resolution,” in Graph-based
    Methods for Natural Language Processing (TextGraphs-4), 2009.'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[196] Z. Chen 和 H. Ji，“基于图的事件共指解析，”发表于 Graph-based Methods for Natural Language
    Processing (TextGraphs-4), 2009。'
- en: '[197] P. K. Choubey and R. Huang, “Event coreference resolution by iteratively
    unfolding inter-dependencies among events,” CoRR, 2017.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[197] P. K. Choubey 和 R. Huang，“通过迭代展开事件间依赖关系进行事件共指解析，”发表于 CoRR, 2017。'
- en: '[198] C. Chen and V. Ng, “Joint inference over a lightly supervised information
    extraction pipeline: Towards event coreference resolution for resource-scarce
    languages,” in AAAI, 2016.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[198] C. Chen 和 V. Ng，“轻度监督信息提取管道的联合推理：针对资源匮乏语言的事件共指解析，”发表于 AAAI, 2016。'
- en: '[199] J. Lu, D. Venugopal, V. Gogate, and V. Ng, “Joint inference for event
    coreference resolution,” in COLING, 2016.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[199] J. Lu, D. Venugopal, V. Gogate, 和 V. Ng，“事件共指解析的联合推理，”发表于 COLING, 2016。'
- en: '[200] J. Lu and V. Ng, “Joint learning for event coreference resolution,” in
    ACL, 2017.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[200] J. Lu 和 V. Ng，“事件共指解析的联合学习，”发表于 ACL, 2017。'
- en: '[201] J. Araki and T. Mitamura, “Joint event trigger identification and event
    coreference resolution with structured perceptron,” in EMNLP, 2015.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[201] J. Araki 和 T. Mitamura，“使用结构感知机进行事件触发器识别和事件共指解析的联合，”发表于 EMNLP, 2015。'
- en: '[202] S. Barhom, V. Shwartz, A. Eirew, M. Bugert, N. Reimers, and I. Dagan,
    “Revisiting joint modeling of cross-document entity and event coreference resolution,”
    CoRR, 2019.'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[202] S. Barhom, V. Shwartz, A. Eirew, M. Bugert, N. Reimers, 和 I. Dagan，“重新审视跨文档实体和事件共指解析的联合建模，”
    CoRR，2019。'
- en: '[203] P. Mirza, “Extracting temporal and causal relations between events,”
    CoRR, 2016.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[203] P. Mirza，“提取事件之间的时间和因果关系，” CoRR，2016。'
- en: '[204] M. Riaz and R. Girju, “Another look at causality: Discovering scenario-specific
    contingency relationships with no supervision,” in 2010 IEEE Fourth International
    Conference on Semantic Computing, 2010.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[204] M. Riaz 和 R. Girju，“另一种因果关系的视角：发现无监督的情境特定偶然关系，” 在 2010 IEEE 第四届国际语义计算会议，2010。'
- en: '[205] M. Riaz and R. Girju, “Toward a better understanding of causality between
    verbal events: Extraction and analysis of the causal power of verb-verb associations,”
    in SIGDIAL Conference, 2013.'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[205] M. Riaz 和 R. Girju，“更好地理解动词事件之间的因果关系：动词-动词关联因果力的提取和分析，” 在 SIGDIAL 会议，2013。'
- en: '[206] C. Hashimoto, K. Torisawa, J. Kloetzer, M. Sano, I. Varga, J.-H. Oh,
    and Y. Kidawara, “Toward future scenario generation: Extracting event causality
    exploiting semantic relation, context, and association features,” in ACL, 2014.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[206] C. Hashimoto, K. Torisawa, J. Kloetzer, M. Sano, I. Varga, J.-H. Oh,
    和 Y. Kidawara，“迈向未来情境生成：利用语义关系、上下文和关联特征提取事件因果关系，” 在 ACL，2014。'
- en: '[207] P. Mirza and S. Tonelli, “An analysis of causality between events and
    its relation to temporal information,” in COLING, 2014.'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[207] P. Mirza 和 S. Tonelli，“事件之间因果关系及其与时间信息的关系分析，” 在 COLING，2014。'
- en: '[208] P. Mirza and S. Tonelli, “Catena: Causal and temporal relation extraction
    from natural language texts,” in COLING, 2016.'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[208] P. Mirza 和 S. Tonelli，“Catena：从自然语言文本中提取因果和时间关系，” 在 COLING，2016。'
- en: '[209] Z. Hu and M. Walker, “Inferring narrative causality between event pairs
    in films,” in SIGDIAL Conference, 2017.'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[209] Z. Hu 和 M. Walker，“推断影片中事件对之间的叙事因果关系，” 在 SIGDIAL 会议，2017。'
- en: '[210] L. Gao, P. K. Choubey, and R. Huang, “Modeling document-level causal
    structures for event causal relation identification,” in ACL, 2019.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[210] L. Gao, P. K. Choubey, 和 R. Huang，“文档级因果结构建模用于事件因果关系识别，” 在 ACL，2019。'
- en: '[211] K. Kadowaki, R. Iida, K. Torisawa, J.-H. Oh, and J. Kloetzer, “Event
    causality recognition exploiting multiple annotators’ judgments and background
    knowledge,” in EMNLP-IJCNLP, 2019.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[211] K. Kadowaki, R. Iida, K. Torisawa, J.-H. Oh, 和 J. Kloetzer，“利用多重注释者的判断和背景知识进行事件因果关系识别，”
    在 EMNLP-IJCNLP，2019。'
- en: '[212] H. Rashkin, M. Sap, E. Allaway, N. A. Smith, and Y. Choi, “Event2mind:
    Commonsense inference on events, intents, and reactions,” CoRR, 2018.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[212] H. Rashkin, M. Sap, E. Allaway, N. A. Smith, 和 Y. Choi，“Event2mind：关于事件、意图和反应的常识推理，”
    CoRR，2018。'
- en: '[213] N. Mostafazadeh, A. Kalyanpur, L. Moon, D. Buchanan, L. Berkowitz, O. Biran,
    and J. Chu-Carroll, “Glucose: Generalized and contextualized story explanations,”
    CoRR, 2020.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[213] N. Mostafazadeh, A. Kalyanpur, L. Moon, D. Buchanan, L. Berkowitz, O.
    Biran, 和 J. Chu-Carroll，“Glucose：广义和情境化的故事解释，” CoRR，2020。'
- en: '[214] J. Liu, Y. Chen, and J. Zhao, “Knowledge enhanced event causality identification
    with mention masking generalizations.,” in IJCAI, 2020.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[214] J. Liu, Y. Chen, 和 J. Zhao，“知识增强的事件因果关系识别与提及掩蔽泛化，” 在 IJCAI，2020。'
- en: '[215] P. Cao, X. Zuo, Y. Chen, K. Liu, J. Zhao, Y. Chen, and W. Peng, “Knowledge-enriched
    event causality identification via latent structure induction networks,” in ACL/IJCNLP,
    2021.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[215] P. Cao, X. Zuo, Y. Chen, K. Liu, J. Zhao, Y. Chen, 和 W. Peng，“通过潜在结构诱导网络进行知识丰富的事件因果关系识别，”
    在 ACL/IJCNLP，2021。'
- en: '[216] M. Riaz and R. Girju, “Recognizing causality in verb-noun pairs via noun
    and verb semantics,” in EACL, 2014.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[216] M. Riaz 和 R. Girju，“通过名词和动词语义识别动词-名词对中的因果关系，” 在 EACL，2014。'
- en: '[217] X. Zuo, Y. Chen, K. Liu, and J. Zhao, “KnowDis: Knowledge enhanced data
    augmentation for event causality detection via distant supervision,” in COLING,
    2020.'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[217] X. Zuo, Y. Chen, K. Liu, 和 J. Zhao，“KnowDis：通过远程监督进行事件因果关系检测的知识增强数据扩充，”
    在 COLING，2020。'
- en: '[218] J. Pustejovsky, J. M. Castano, R. Ingria, R. Sauri, R. J. Gaizauskas,
    A. Setzer, G. Katz, and D. R. Radev, “Timeml: Robust specification of event and
    temporal expressions in text.,” New directions in question answering, 2003.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[218] J. Pustejovsky, J. M. Castano, R. Ingria, R. Sauri, R. J. Gaizauskas,
    A. Setzer, G. Katz, 和 D. R. Radev，“Timeml：文本中事件和时间表达的鲁棒规范，” 新的问答方向，2003。'
- en: '[219] C. Hagège and X. Tannier, “Xrce-t: Xip temporal module for tempeval campaign.,”
    in SemEval, 2007.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[219] C. Hagège 和 X. Tannier，“Xrce-t：Xip 时间模块用于 tempeval 活动，” 在 SemEval，2007。'
- en: '[220] A. Chang and C. D. Manning, “Sutime: Evaluation in tempeval-3,” in SemEval,
    2013.'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[220] A. Chang 和 C. D. Manning，“Sutime：在 tempeval-3 中的评估，” 在 SemEval，2013。'
- en: '[221] N. Chambers, T. Cassidy, B. McDowell, and S. Bethard, “Dense event ordering
    with a multi-pass architecture,” TACL, 2014.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[221] N. Chambers、T. Cassidy、B. McDowell 和 S. Bethard， “使用多通道架构进行密集事件排序”，发表于
    TACL，2014年。'
- en: '[222] I. Mani, M. Verhagen, B. Wellner, C. M. Lee, and J. Pustejovsky, “Machine
    learning of temporal relations,” in ACL, 2006.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[222] I. Mani、M. Verhagen、B. Wellner、C. M. Lee 和 J. Pustejovsky， “时间关系的机器学习”，发表于
    ACL，2006年。'
- en: '[223] Q. Ning, Z. Feng, and D. Roth, “A structured learning approach to temporal
    relation extraction,” CoRR, 2019.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[223] Q. Ning、Z. Feng 和 D. Roth， “一种结构化学习方法用于时间关系提取”，发表于 CoRR，2019年。'
- en: '[224] D. Dligach, T. Miller, C. Lin, S. Bethard, and G. Savova, “Neural temporal
    relation extraction,” in ACL (Short Papers), 2017.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[224] D. Dligach、T. Miller、C. Lin、S. Bethard 和 G. Savova， “神经时间关系提取”，发表于 ACL（短论文），2017年。'
- en: '[225] J. Tourille, O. Ferret, A. Neveol, and X. Tannier, “Neural architecture
    for temporal relation extraction: A bi-lstm approach for detecting narrative containers,”
    in ACL, 2017.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[225] J. Tourille、O. Ferret、A. Neveol 和 X. Tannier， “用于时间关系提取的神经架构：一种双向 LSTM
    方法用于检测叙事容器”，发表于 ACL，2017年。'
- en: '[226] F. Cheng and Y. Miyao, “Classifying temporal relations by bidirectional
    lstm over dependency paths,” in ACL (Short Papers), 2017.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[226] F. Cheng 和 Y. Miyao， “通过双向 LSTM 对依赖路径进行时间关系分类”，发表于 ACL（短论文），2017年。'
- en: '[227] R. Han, Y. Zhou, and N. Peng, “Domain knowledge empowered structured
    neural net for end-to-end event temporal relation extraction,” CoRR, 2020.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[227] R. Han、Y. Zhou 和 N. Peng， “领域知识赋能的结构化神经网络用于端到端事件时间关系提取”，发表于 CoRR，2020年。'
- en: '[228] H. Ross, J. Cai, and B. Min, “Exploring contextualized neural language
    models for temporal dependency parsing,” CoRR, 2020.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[228] H. Ross、J. Cai 和 B. Min， “探索上下文化神经语言模型用于时间依赖解析”，发表于 CoRR，2020年。'
- en: '[229] R. C. Schank and R. P. Abelson, “Scripts, plans, goals, and understanding,”
    1988.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[229] R. C. Schank 和 R. P. Abelson， “脚本、计划、目标与理解”，1988年。'
- en: '[230] D. Bean and E. Riloff, “Unsupervised learning of contextual role knowledge
    for coreference resolution,” in HLT-NAACL, 2004.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[230] D. Bean 和 E. Riloff， “用于共指消解的上下文角色知识的无监督学习”，发表于 HLT-NAACL，2004年。'
- en: '[231] S. Chaturvedi, H. Peng, and D. Roth, “Story comprehension for predicting
    what happens next,” in EMNLP, 2017.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[231] S. Chaturvedi、H. Peng 和 D. Roth， “故事理解用于预测接下来会发生什么”，发表于 EMNLP，2017年。'
- en: '[232] Y. Yang, Z. Wei, Q. Chen, and L. Wu, “Using external knowledge for financial
    event prediction based on graph neural networks,” CIKM, 2019.'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[232] Y. Yang、Z. Wei、Q. Chen 和 L. Wu， “基于图神经网络的金融事件预测使用外部知识”，发表于 CIKM，2019年。'
- en: '[233] M. Granroth-Wilding and S. Clark, “What happens next? event prediction
    using a compositional neural network model,” in AAAI, 2016.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[233] M. Granroth-Wilding 和 S. Clark， “接下来会发生什么？使用组合神经网络模型进行事件预测”，发表于 AAAI，2016年。'
- en: '[234] G. David and C. Cieri, “Graff david and christopher cieri,” in Philadelphia:
    Linguistic Data Consortium, 2003.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[234] G. David 和 C. Cieri， “Graff david 和 christopher cieri”，发表于费城：语言数据联盟，2003年。'
- en: '[235] N. Chambers and D. Jurafsky, “Unsupervised learning of narrative event
    chains,” in ACL, 2008.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[235] N. Chambers 和 D. Jurafsky， “叙事事件链的无监督学习”，发表于 ACL，2008年。'
- en: '[236] B. Jans, S. Bethard, I. Vulić, and M. F. Moens, “Skip n-grams and ranking
    functions for predicting script events,” in ACL, 2012.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[236] B. Jans、S. Bethard、I. Vulić 和 M. F. Moens， “跳过 n-gram 和排序函数用于预测脚本事件”，发表于
    ACL，2012年。'
- en: '[237] K. Pichotta and R. Mooney, “Statistical script learning with multi-argument
    events,” in ACL, 2014.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[237] K. Pichotta 和 R. Mooney， “使用多参数事件的统计脚本学习”，发表于 ACL，2014年。'
- en: '[238] R. Rudinger, P. Rastogi, F. Ferraro, and B. Van Durme, “Script induction
    as language modeling,” in EMNLP, 2015.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[238] R. Rudinger、P. Rastogi、F. Ferraro 和 B. Van Durme， “脚本诱导作为语言建模”，发表于 EMNLP，2015年。'
- en: '[239] S. Lv, W. Qian, L. Huang, J. Han, and S. Hu, “Sam-net: Integrating event-level
    and chain-level attentions to predict what happens next,” in AAAI, 2019.'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[239] S. Lv、W. Qian、L. Huang、J. Han 和 S. Hu， “Sam-net：整合事件级和链级注意力以预测接下来会发生什么”，发表于
    AAAI，2019年。'
- en: '[240] K. Pichotta and R. Mooney, “Learning statistical scripts with lstm recurrent
    neural networks,” in AAAI, 2016.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[240] K. Pichotta 和 R. Mooney， “使用 LSTM 递归神经网络学习统计脚本”，发表于 AAAI，2016年。'
- en: '[241] Z. Wang, Y. Zhang, and C.-Y. Chang, “Integrating order information and
    event relation for script event prediction,” in EMNLP, 2017.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[241] Z. Wang、Y. Zhang 和 C.-Y. Chang， “整合顺序信息和事件关系用于脚本事件预测”，发表于 EMNLP，2017年。'
- en: '[242] L. Wang, J. Yue, S. Guo, J. Sheng, Q. Mao, Z. Chen, S. Zhong, and C. Li,
    “Multi-level connection enhanced representation learning for script event prediction,”
    WWW, 2021.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[242] L. Wang、J. Yue、S. Guo、J. Sheng、Q. Mao、Z. Chen、S. Zhong 和 C. Li， “多级连接增强的表示学习用于脚本事件预测”，发表于
    WWW，2021年。'
- en: '[243] J. Zheng, F. Cai, Y. Ling, and H. Chen, “Heterogeneous graph neural networks
    to predict what happen next,” in COLING, 2020.'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[243] J. Zheng, F. Cai, Y. Ling, 和 H. Chen, “异质图神经网络预测接下来会发生什么，” 在 COLING,
    2020年。'
- en: '[244] X. Ding, K. Liao, T. Liu, Z. Li, and J. Duan, “Event representation learning
    enhanced with external commonsense knowledge,” in EMNLP-IJCNLP, 2019.'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[244] X. Ding, K. Liao, T. Liu, Z. Li, 和 J. Duan, “通过外部常识知识增强事件表示学习，” 在 EMNLP-IJCNLP,
    2019年。'
- en: '[245] H. Rashkin, M. Sap, E. Allaway, N. A. Smith, and Y. Choi, “Event2Mind:
    Commonsense inference on events, intents, and reactions,” in ACL, 2018.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[245] H. Rashkin, M. Sap, E. Allaway, N. A. Smith, 和 Y. Choi, “Event2Mind:
    事件、意图和反应的常识推理，” 在 ACL, 2018年。'
- en: '[246] M. Sap, R. L. Bras, E. Allaway, C. Bhagavatula, N. Lourie, H. Rashkin,
    B. Roof, N. A. Smith, and Y. Choi, “Atomic: An atlas of machine commonsense for
    if-then reasoning,” ArXiv, 2019.'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[246] M. Sap, R. L. Bras, E. Allaway, C. Bhagavatula, N. Lourie, H. Rashkin,
    B. Roof, N. A. Smith, 和 Y. Choi, “Atomic: 一种用于 if-then 推理的机器常识图谱，” ArXiv, 2019年。'
- en: '[247] S. Lv, F. Zhu, and S. Hu, “Integrating external event knowledge for script
    learning,” in COLING, 2020.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[247] S. Lv, F. Zhu, 和 S. Hu, “整合外部事件知识进行脚本学习，” 在 COLING, 2020年。'
- en: '[248] H. Zhang, X. Liu, H. Pan, Y. Song, and C. Leung, “Aser: A large-scale
    eventuality knowledge graph,” WWW, 2020.'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[248] H. Zhang, X. Liu, H. Pan, Y. Song, 和 C. Leung, “Aser: 大规模事件知识图谱，” WWW,
    2020年。'
- en: '[249] K. Huang, M. Yang, and N. Peng, “Biomedical event extraction on graph
    edge-conditioned attention networks with hierarchical knowledge graphs,” in EMNLP,
    Findings of ACL, 2020.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[249] K. Huang, M. Yang, 和 N. Peng, “基于图边缘条件注意网络和层次知识图谱的生物医学事件提取，” 在 EMNLP,
    ACL 发现, 2020年。'
- en: '[250] J. A. Vanegas, S. Matos, F. A. González, and J. L. Oliveira, “An overview
    of biomolecular event extraction from scientific documents,” Comput. Math. Methods
    Medicine, 2015.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[250] J. A. Vanegas, S. Matos, F. A. González, 和 J. L. Oliveira, “从科学文献中提取生物分子事件的概述，”
    Comput. Math. Methods Medicine, 2015年。'
- en: '[251] J. Björne and T. Salakoski, “Generalizing biomedical event extraction,”
    in BioNLP@ACL (Shared Task), 2011.'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[251] J. Björne 和 T. Salakoski, “生物医学事件提取的泛化，” 在 BioNLP@ACL (共享任务), 2011年。'
- en: '[252] N. Chambers, T. Cassidy, B. McDowell, and S. Bethard, “Dense event ordering
    with a multi-pass architecture,” Trans. Assoc. Comput. Linguistics, 2014.'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[252] N. Chambers, T. Cassidy, B. McDowell, 和 S. Bethard, “使用多遍架构的密集事件排序，”
    Trans. Assoc. Comput. Linguistics, 2014年。'
- en: '[253] J. Björne and T. Salakoski, “Biomedical event extraction using convolutional
    neural networks and dependency parsing,” in BioNLP, 2018.'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[253] J. Björne 和 T. Salakoski, “使用卷积神经网络和依赖解析进行生物医学事件提取，” 在 BioNLP, 2018年。'
- en: '[254] L. Li, Y. Liu, and M. Qin, “Extracting biomedical events with parallel
    multi-pooling convolutional neural networks,” IEEE ACM Trans. Comput. Biol. Bioinform.,
    no. 2, 2020.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[254] L. Li, Y. Liu, 和 M. Qin, “使用并行多池卷积神经网络提取生物医学事件，” IEEE ACM Trans. Comput.
    Biol. Bioinform., 第2期, 2020年。'
- en: '[255] H. Trieu, T. T. Tran, A. D. Nguyen, A. Nguyen, M. Miwa, and S. Ananiadou,
    “Deepeventmine: end-to-end neural nested event extraction from biomedical texts,”
    Bioinform., no. 19, 2020.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[255] H. Trieu, T. T. Tran, A. D. Nguyen, A. Nguyen, M. Miwa, 和 S. Ananiadou,
    “Deepeventmine: 从生物医学文本中进行端到端神经嵌套事件提取，” Bioinform., 第19期, 2020年。'
- en: '[256] Z. Tang, G. Hahn-Powell, and M. Surdeanu, “Exploring interpretability
    in event extraction: Multitask learning of a neural event classifier and an explanation
    decoder,” in ACL, 2020.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[256] Z. Tang, G. Hahn-Powell, 和 M. Surdeanu, “探索事件提取中的可解释性：神经事件分类器和解释解码器的多任务学习，”
    在 ACL, 2020年。'
- en: '[257] G. Frisoni, G. Moro, and A. Carbonaro, “A survey on event extraction
    for natural language understanding: Riding the biomedical literature wave,” IEEE
    Access, 2021.'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[257] G. Frisoni, G. Moro, 和 A. Carbonaro, “关于自然语言理解中事件提取的调查：驾驭生物医学文献的浪潮，”
    IEEE Access, 2021年。'
- en: '| ![[Uncaptioned image]](img/823b0b8549860eb8ea3e66fb25d363e5.png) | Qian Li
    is currently pursuing the Ph.D. degree with the School of Computer Science and
    Engineering, and Beijing Advanced Innovation Center for Big Data and Brain Computing
    in Beihang University. Her research interests include knowledge graph and information
    extraction. |'
  id: totrans-596
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图片]](img/823b0b8549860eb8ea3e66fb25d363e5.png) | Qian Li 目前在北京航空航天大学计算机科学与工程学院及北京大数据与脑计算高级创新中心攻读博士学位。她的研究兴趣包括知识图谱和信息提取。
    |'
- en: '| ![[Uncaptioned image]](img/4ecedda64eb1c5a3536dcaa38b876ff0.png) | Jianxin
    Li is currently a Professor with the School of Computer Science and Engineering,
    and Beijing Advanced Innovation Center for Big Data and Brain Computing in Beihang
    University. His current research interests include social networks, machine learning,
    big data, and trustworthy computing. Dr. Li has published research papers in top-tier
    journals and conferences, including the IEEE TKDE, TDSC, Journal of Artificial
    Intelligence Research (JAIR), Association for Computing Machinery Transactions
    on Information Systems (ACM TOIS), ACM Transactions on Knowledge Discovery from
    Data (TKDD), Knowledge Discovery and Data Mining (KDD), Association for the Advancement
    of Artificial Intelligence (AAAI), and The International Conference of World Wide
    Web (WWW). |'
  id: totrans-597
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/4ecedda64eb1c5a3536dcaa38b876ff0.png) | 李建新目前是北京航空航天大学计算机科学与工程学院及北京先进创新中心大数据与脑计算的教授。他当前的研究兴趣包括社交网络、机器学习、大数据和可信计算。李博士在顶级期刊和会议上发表了研究论文，包括IEEE
    TKDE、TDSC、《人工智能研究期刊》（JAIR）、《计算机协会信息系统事务》（ACM TOIS）、ACM《知识发现与数据挖掘事务》（TKDD）、知识发现与数据挖掘（KDD）、《人工智能促进协会》（AAAI）以及《万维网国际会议》（WWW）。
    |'
- en: '| ![[Uncaptioned image]](img/300d846e7ef3527db673225e186f3e4e.png) | Jiawei
    Sheng is currently pursuing the Ph.D. degree in the Institute of Information Engineering,
    Chinese Academy of Sciences. His current research interests include Information
    Extraction, Knowledge Graph Embedding and Knowledge Acquisition. |'
  id: totrans-598
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/300d846e7ef3527db673225e186f3e4e.png) | 尚佳伟目前在中国科学院信息工程研究所攻读博士学位。他当前的研究兴趣包括信息抽取、知识图谱嵌入和知识获取。
    |'
- en: '| ![[Uncaptioned image]](img/b88a056ac81796a364fb6b989d993c5c.png) | Shiyao
    Cui is currently pursuing the Ph.D. degree in the Institute of Information Engineering,
    Chinese Academy of Sciences. Her current research interests include Event Extraction,
    Event Relation Identification and Script Event Prediction. |'
  id: totrans-599
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/b88a056ac81796a364fb6b989d993c5c.png) | 崔诗瑶目前在中国科学院信息工程研究所攻读博士学位。她当前的研究兴趣包括事件抽取、事件关系识别和脚本事件预测。
    |'
- en: '| ![[Uncaptioned image]](img/d14b580f6365d9231f97712446464d93.png) | Jia Wu
    received the Ph.D. degree in computer science from the University of Technology
    Sydney, Ultimo, NSW, Australia. Dr Wu is currently an Australian Research Council
    Discovery Early Career Researcher Award (ARC DECRA) Fellow in the School of Computing,
    Macquarie University, Sydney, Australia. His current research interests include
    data mining and machine learning. Since 2009, he has published 100+ refereed journal
    and conference papers, including IEEE TPAMI, IEEE TKDE, IEEE TNNLS, IEEE TMM,
    ACM TKDD, Neural Information Processing Systems (NIPS), WWW, and ACM’s Special
    Interest Group on Knowledge Discovery and Data Mining (ACM SIGKDD). |'
  id: totrans-600
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/d14b580f6365d9231f97712446464d93.png) | 贾武在澳大利亚新南威尔士州悉尼科技大学获得了计算机科学博士学位。贾博士目前是澳大利亚研究理事会发现早期职业研究员奖（ARC
    DECRA）获得者，现任职于澳大利亚悉尼麦考瑞大学计算机学院。他当前的研究兴趣包括数据挖掘和机器学习。自2009年以来，他已发表了100多篇经审稿的期刊和会议论文，包括IEEE
    TPAMI、IEEE TKDE、IEEE TNNLS、IEEE TMM、ACM TKDD、Neural Information Processing Systems（NIPS）、WWW以及ACM知识发现与数据挖掘特别兴趣小组（ACM
    SIGKDD）。 |'
- en: '| ![[Uncaptioned image]](img/ec1f229aca96ebf51dd2593ca793fffe.png) | Yiming
    Hei is currently pursuing the Ph.D. degree in the School of Cyber Science and
    Technology, Beihang University. His research interests include Graph Embedding,
    Information Extraction and Application Security. |'
  id: totrans-601
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/ec1f229aca96ebf51dd2593ca793fffe.png) | 何一鸣目前在北京航空航天大学网络科学与技术学院攻读博士学位。他的研究兴趣包括图嵌入、信息抽取和应用安全。
    |'
- en: '| ![[Uncaptioned image]](img/a02734b6f865d140fde9cd6e4dfeb71e.png) | Hao Peng
    is currently an Assistant Professor at the School of Cyber Science and Technology,
    and Beijing Advanced Innovation Center for BigData and Brain Computing in Beihang
    University. His research interests include representation learning, machine learning
    and graph mining. |'
  id: totrans-602
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/a02734b6f865d140fde9cd6e4dfeb71e.png) | 彭浩目前是北京航空航天大学网络科学与技术学院及北京先进创新中心大数据与脑计算的助理教授。他的研究兴趣包括表示学习、机器学习和图挖掘。
    |'
- en: '| ![[Uncaptioned image]](img/e96bb2a8ab7d5c096327bbe58e1ab863.png) | Shu Guo
    received Ph.D. degree from the Institute of Information Engineering, Chinese Academy
    of Sciences. She is currently working at the National Computer Network Emergency
    Response Technical Team/Coordination Center of China. Her research interests include
    Knowledge Graph Embedding, Knowledge Acquisition and Web Mining. |'
  id: totrans-603
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图片]](img/e96bb2a8ab7d5c096327bbe58e1ab863.png) | Shu Guo获得了中国科学院信息工程研究所的博士学位。她目前在中国国家计算机网络应急技术处理协调中心工作。她的研究兴趣包括知识图谱嵌入、知识获取和网络挖掘。
    |'
- en: '| ![[Uncaptioned image]](img/a4707415ea98235dbb19e577eb9ee060.png) | Lihong
    Wang is currently a Professor with the National Computer Network Emergency Response
    Technical Team/Coordination Center of China. Her current research interests include
    information security, cloud computing, big data mining and analytics, information
    retrieval, and data mining. |'
  id: totrans-604
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图片]](img/a4707415ea98235dbb19e577eb9ee060.png) | Lihong Wang目前是中国国家计算机网络应急技术处理协调中心的教授。她目前的研究兴趣包括信息安全、云计算、大数据挖掘与分析、信息检索和数据挖掘。
    |'
- en: '| ![[Uncaptioned image]](img/b6a5d92f6efc5ce8a5f151321ef8232b.png) | Amin Beheshti
    is the Director of AI-enabled Processes (AIP) Research Centre and the head of
    the Data Analytics Research Lab, Department of Computing, Macquarie University.
    He is also a Senior Lecturer in Data Science at Macquarie University and an Adjunct
    Academic in Computer Science at UNSW Sydney. Amin completed his Ph.D. and Postdoc
    in Computer Science and Engineering in UNSW Sydney and held a Master and Bachelor
    in Computer Science both with First Class Honours. |'
  id: totrans-605
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图片]](img/b6a5d92f6efc5ce8a5f151321ef8232b.png) | Amin Beheshti是人工智能驱动过程（AIP）研究中心的主任，也是麦考瑞大学计算系数据分析研究实验室的负责人。他同时也是麦考瑞大学数据科学的高级讲师和UNSW悉尼大学计算机科学的兼职学术人员。Amin在UNSW悉尼大学完成了计算机科学与工程的博士学位和博士后研究，并在计算机科学领域获得了一等荣誉的硕士和学士学位。
    |'
- en: '| ![[Uncaptioned image]](img/9d1ab7a34eda5556b62479e475df34b3.png) | Philip
    S. Yu is a Distinguished Professor and the Wexler Chair in Information Technology
    at the Department of Computer Science, University of Illinois at Chicago and also
    holds the Wexler Chair in Information Technology. Before joining UIC, he was at
    the IBM Watson Research Center. He is a Fellow of the ACM and IEEE. Dr. Yu was
    the Editor-in-Chiefs of ACM Transactions on Knowledge Discovery from Data (2011-2017)
    and IEEE Transactions on Knowledge and Data Engineering (2001-2004). |'
  id: totrans-606
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图片]](img/9d1ab7a34eda5556b62479e475df34b3.png) | Philip S. Yu是伊利诺伊大学芝加哥分校计算机科学系的杰出教授及Wexler信息技术讲席教授，同时担任Wexler信息技术讲席教授。在加入UIC之前，他曾在IBM
    Watson研究中心工作。他是ACM和IEEE的会士。Yu博士曾担任ACM《数据知识发现交易》（2011-2017）和IEEE《知识与数据工程交易》（2001-2004）的主编。
    |'
