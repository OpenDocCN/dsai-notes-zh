- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 20:02:33'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2002.05786] Deep Learning for Financial Applications : A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2002.05786](https://ar5iv.labs.arxiv.org/html/2002.05786)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Deep Learning for Financial Applications : A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ahmet Murat Ozbayoglu Mehmet Ugur Gudelek Omer Berat Sezer Department of Computer
    Engineering, TOBB University of Economics and Technology, Ankara, Turkey
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Computational intelligence in finance has been a very popular topic for both
    academia and financial industry in the last few decades. Numerous studies have
    been published resulting in various models. Meanwhile, within the [Machine Learning
    (ML)](#glo.main.ml) field, [Deep Learning (DL)](#glo.main.dl) started getting
    a lot of attention recently, mostly due to its outperformance over the classical
    models. Lots of different implementations of [DL](#glo.main.dl) exist today, and
    the broad interest is continuing. Finance is one particular area where [DL](#glo.main.dl)
    models started getting traction, however, the playfield is wide open, a lot of
    research opportunities still exist. In this paper, we tried to provide a state-of-the-art
    snapshot of the developed [DL](#glo.main.dl) models for financial applications,
    as of today. We not only categorized the works according to their intended subfield
    in finance but also analyzed them based on their [DL](#glo.main.dl) models. In
    addition, we also aimed at identifying possible future implementations and highlighted
    the pathway for the ongoing research within the field.
  prefs: []
  type: TYPE_NORMAL
- en: 'keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: deep learning , finance , computational intelligence , machine learning , financial
    applications , algorithmic trading , portfolio management , risk assesment , fraud
    detection
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Stock market forecasting, algorithmic trading, credit risk assessment, portfolio
    allocation, asset pricing and derivatives market are among the areas where [ML](#glo.main.ml)
    researchers focused on developing models that can provide real-time working solutions
    for the financial industry. Hence, a lot of publications and implementations exist
    in the literature.
  prefs: []
  type: TYPE_NORMAL
- en: However, within the [ML](#glo.main.ml) field, [DL](#glo.main.dl) is an emerging
    area with a rising interest every year. As a result, an increasing number of [DL](#glo.main.dl)
    models for finance started appearing in conferences and journals. Our focus in
    this paper is to present different implementations of the developed financial
    [DL](#glo.main.dl) models in such a way that the researchers and practitioners
    that are interested in the topic can decide which path they should take.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this paper, we tried to provide answers to the following research questions:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What financial application areas are of interest to [DL](#glo.main.dl) community?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How mature is the existing research in each of these application areas?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the areas that have promising potentials from an academic/industrial
    research perspective?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which [DL](#glo.main.dl) models are preferred (and more successful) in different
    applications?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do [DL](#glo.main.dl) models pare against traditional soft computing / [ML](#glo.main.ml)
    techniques?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the future direction for [DL](#glo.main.dl) research in Finance?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Our focus was solely on [DL](#glo.main.dl) implementations for financial applications.
    A substantial portion of the computational intelligence for finance research is
    devoted to financial time series forecasting. However, we preferred to concentrate
    on those studies in a separate survey paper [[1](#bib.bib1)] in order to be able
    to pinpoint other, less covered application areas. Meanwhile, we decided to include
    algorithmic trading studies with [DL](#glo.main.dl) based trading strategies which
    may or may not have an embedded time series forecasting component.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our search methodology, we surveyed and carefully reviewed the studies
    that came to our attention from the following sources: ScienceDirect, ACM Digital
    Library, Google Scholar, arXiv.org, ResearchGate, Google keyword search for DL
    and finance'
  prefs: []
  type: TYPE_NORMAL
- en: The range of our survey spanned not only journals and conferences, but also
    Masters and PhD theses, book chapters, arXiv papers and noteworthy technical papers
    that came up in Google searches. Furthermore, we only chose the articles that
    were written in English. It is worth to mention that we encountered a few studies
    that were written in a different language, but had English abstracts. However,
    for overall consistency, we decided not to include those studies in our survey.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the papers in this survey used the term “deep learning" in their model
    description and they were published in the last 5 years. However, we also included
    some older papers that implemented deep learning models even though they were
    not called “deep learning" models at their time of publication. Some examples
    for such models include [Recurrent Neural Network (RNN)](#glo.main.rnn), Jordan-Elman
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: To best of our knowledge, this will be the first comprehensive “deep learning
    for financial applications" survey paper. As will be introduced in the next section,
    a lot of [ML](#glo.main.ml) surveys exist for different areas of finance, however,
    no study has concentrated on [DL](#glo.main.dl) implementations. We genuinely
    believe our study will highlight the major advancements in the field and provide
    a roadway for the intended researchers that would like to develop [DL](#glo.main.dl)
    models for different financial application areas.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the paper is structured as follows. After this brief introduction,
    in Section [2](#S2 "2 Machine Learning in Finance ‣ Deep Learning for Financial
    Applications : A Survey"), the existing surveys that are focused on [ML](#glo.main.ml)
    and soft computing studies for financial applications are presented. In Section [3](#S3
    "3 Deep Learning ‣ Deep Learning for Financial Applications : A Survey"), we will
    provide the basic working [DL](#glo.main.dl) models that are used in finance,
    i.e. [Convolutional Neural Network (CNN)](#glo.main.cnn), [Long-Short Term Memory
    (LSTM)](#glo.main.lstm), etc. Section [4](#S4 "4 Financial Applications ‣ Deep
    Learning for Financial Applications : A Survey") will focus on the implementation
    areas of the [DL](#glo.main.dl) models in finance. Some of these include algorithmic
    trading, credit risk assessment, portfolio allocation, asset pricing, fraud detection
    and derivatives market. After briefly stating the problem definition in each subsection,
    [DL](#glo.main.dl) implementations of each associated problem will be given.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Section [5](#S5 "5 Current Snaphot of DL research for Financial Applications
    ‣ Deep Learning for Financial Applications : A Survey"), these studies will be
    compared and some overall statistical results will be presented including histograms
    about the yearly distribution of different subfields, models, publication types,
    etc. These statistics will not only demonstrate the current state for the field
    but also will show which areas are mature, which areas still have opportunities
    and which areas are getting accelerated attention. Section [6](#S6 "6 Discussion
    and Open Issues ‣ Deep Learning for Financial Applications : A Survey") will have
    discussions about what has been done in the field so far and where the industry
    is going. The chapter will also include the achievements and expectations of both
    academia and the industry. Also, open areas and recommended research topics will
    be mentioned. Finally, in Section [7](#S7 "7 Conclusions ‣ Deep Learning for Financial
    Applications : A Survey"), we will summarize the findings and conclude.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Machine Learning in Finance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finance has always been one of the most studied application areas for [ML](#glo.main.ml),
    starting as early as 40 years ago. So far, thousands of research papers were published
    in various fields within finance, and the overall interest does not seem to diminish
    anytime soon. Even though this survey paper is solely focused on [DL](#glo.main.dl)
    implementations, we wanted to provide the audience with some insights about previous
    [ML](#glo.main.ml) studies by citing the related surveys within the last 20 years.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of [ML](#glo.main.ml) surveys and books with a general perspective
    such that they do not concentrate on any particular implementation area. The following
    survey papers fall into that category. Bahrammirzaee et al. [[2](#bib.bib2)] compared
    [Artificial Neural Networks (ANNs)](#glo.main.ann), Expert Systems and Hybrid
    models for various financial applications. Zhang et al. [[3](#bib.bib3)] reviewed
    the data mining techniques including [Genetic Algorithm (GA)](#glo.main.ga), rule-based
    systems, [Neural Networks (NNs)](#glo.main.nn) preferred in different financial
    application areas. Similarly, Mochn et al. [[4](#bib.bib4)] also provided insights
    about financial implementations based on soft computing techniques like fuzzy
    logic, probabilistic reasoning and [NNs](#glo.main.nn). Even though Pulakkazhy
    et al. [[5](#bib.bib5)] focused particularly on data mining models in banking
    applications, they still had a span of several subtopics within the field. Meanwhile,
    Mullainathan et al. [[6](#bib.bib6)] studied the [ML](#glo.main.ml) implementations
    from a high level and econometric point of view. Likewise, Gai et al. [[7](#bib.bib7)]
    reviewed the Fintech studies and implementations not only from an [ML](#glo.main.ml)
    perspective but in general. The publications in [[8](#bib.bib8), [9](#bib.bib9),
    [10](#bib.bib10), [11](#bib.bib11)] constitute some of the books that cover the
    implementations of soft computing models in finance.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, there are some survey papers that are also not application area-specific
    but rather focused on particular [ML](#glo.main.ml) techniques. One of those soft
    computing techniques is the family of [Evolutionary Algorithms (EAs)](#glo.main.ea),
    i.e. [GA](#glo.main.ga), [Particle Swarm Optimization (PSO)](#glo.main.pso), etc.
    commonly used in financial optimization implementations like Portfolio Selection.
    Chen et al. [[12](#bib.bib12)] wrote a book covering [GAs](#glo.main.ga) and [Genetic
    Programming (GP)](#glo.main.gp) in Computational Finance. Later, Castillo et al.
    [[13](#bib.bib13)], Ponsich et al. [[14](#bib.bib14)], Aguilar-Rivera et al. [[15](#bib.bib15)]
    extensively surveyed [Multiobjective Evolutionary Algorithms (MOEAs)](#glo.main.moea)
    on portfolio optimization and other various financial applications.
  prefs: []
  type: TYPE_NORMAL
- en: Since [ANNs](#glo.main.ann) were quite popular among researchers, a number of
    survey papers were just dedicated to them. Wong et al. [[16](#bib.bib16)] covered
    early implementations of [ANNs](#glo.main.ann) in finance. Li et al. [[17](#bib.bib17)]
    reviewed implementations of [ANNs](#glo.main.ann) for stock price forecasting
    and some other financial applications. Lately, Elmsili et al. [[18](#bib.bib18)]
    contained [ANN](#glo.main.ann) applications in economics and management research
    in their survey.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, LeBaron [[19](#bib.bib19)] covered the studies focused on agent-based
    computational finance. Meanwhile, Chalup et al. [[20](#bib.bib20)] wrote a book
    chapter on kernel methods in financial applications which includes models like
    [Principal Component Analysis (PCA)](#glo.main.pca), [Support Vector Machine (SVM)](#glo.main.svm).
  prefs: []
  type: TYPE_NORMAL
- en: 'And then, there are application-specific survey papers that single out particular
    financial areas which are quite useful and informative for researchers that already
    know what they are looking for. These papers will be covered in the appropriate
    subsections of Section [4](#S4 "4 Financial Applications ‣ Deep Learning for Financial
    Applications : A Survey") during problem description. In the next section, brief
    working structures of the [DL](#glo.main.dl) models used in the financial applications
    will be given.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Deep Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Deep Learning is a particular type of [ML](#glo.main.ml) that consists of multiple
    [ANN](#glo.main.ann) layers. It provides high-level abstraction for data modelling
    [[21](#bib.bib21)]. In the literature, different [DL](#glo.main.dl) models exist:
    [Deep Multilayer Perceptron (DMLP)](#glo.main.dmlp), [CNN](#glo.main.cnn), [RNN](#glo.main.rnn),
    [LSTM](#glo.main.lstm), [Restricted Boltzmann Machines (RBMs)](#glo.main.rbm),
    [Deep Belief Networks (DBNs)](#glo.main.dbn), and [Autoencoders (AEs)](#glo.main.ae).'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Deep Multi Layer Perceptron (DMLP)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the literature, [DMLP](#glo.main.dmlp) was the first proposed [ANN](#glo.main.ann)
    model of its kind. [DMLP](#glo.main.dmlp) networks consist of input, output and
    hidden layers just like an ordinary [Multilayer Perceptron (MLP)](#glo.main.mlp);
    however, the number of layers in [DMLP](#glo.main.dmlp) is more than [MLP](#glo.main.mlp).
    Each neuron in every layer has input (x), weight (w) and bias (b) terms. An output
    of a neuron in the neural network is illustrated in Equation [1](#S3.E1 "In 3.1
    Deep Multi Layer Perceptron (DMLP) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey"). In addition, each neuron has a nonlinear activation
    function which produces the output of that neuron through accumulating weighted
    inputs from the neurons in the preceding layer. Sigmoid [[22](#bib.bib22)], hyperbolic
    tangent [[23](#bib.bib23)], [Rectified Linear Unit (ReLU)](#glo.main.relu) [[24](#bib.bib24)],
    leaky [ReLU](#glo.main.relu) [[25](#bib.bib25)], swish [[26](#bib.bib26)], and
    softmax[[27](#bib.bib27)] are among the most preferred nonlinear activation functions
    in the literature.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $y_{i}=\sigma(\sum\limits_{i}W_{i}x_{i}+b_{i})$ |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: 'With multi-layer deep [ANNs](#glo.main.ann), more efficient classification
    and regression performances are achieved when compared against shallow nets. [DMLPs](#glo.main.dmlp)’
    learning process is implemented through backpropagation. The amount of the output
    error in the output layer neurons is also reflected back to the neurons in the
    previous layers. In [DMLP](#glo.main.dmlp), [Stochastic Gradient Descent (SGD)](#glo.main.sgd)
    method is (mostly) used for the optimization of learning (to update the weights
    of the connections between the layers). In Figure [1](#S3.F1 "Figure 1 ‣ 3.1 Deep
    Multi Layer Perceptron (DMLP) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey"), a [DMLP](#glo.main.dmlp) model, the layers, the neurons
    in layers, the weights between the neurons are shown.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bca6b34e192bb2c27b558e692f5a6161.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Deep Multi Layer Neural Network Forward Pass and Backpropagation
    [[21](#bib.bib21)]'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Convolutional Neural Networks (CNNs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[CNN](#glo.main.cnn) is a type of [Deep Neural Network (DNN)](#glo.main.dnn)
    that is mostly used for image classification, image recognition problems. In its
    methodology, the whole image is scanned with filters. In the literature, 1x1,
    3x3 and 5x5 filter sizes are mostly used. In most of the [CNN](#glo.main.cnn)
    architectures, there are different types of layers: convolutional, pooling (average
    or maximum), fully connected layers. [CNN](#glo.main.cnn) consists of convolutional
    layers based on the convolutional operation. Figure [2](#S3.F2 "Figure 2 ‣ 3.2
    Convolutional Neural Networks (CNNs) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey") shows the generalized CNN architecture that has different
    layers: convolutional, subsampling (pooling), fully connected layers.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e81a5865dacc7ebfc1317ec9d38672f7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Generalized Convolutional Neural Network Architecture'
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Recurrent Neural Network (RNN)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the literature, [RNN](#glo.main.rnn) has been mostly used on sequential data
    such as time-series data, audio and speech data, language. It consists of [RNN](#glo.main.rnn)
    units that are structured consecutively. Unlike feed-forward networks, [RNNs](#glo.main.rnn)
    use internal memory to process the incoming inputs. [RNNs](#glo.main.rnn) are
    used in the analysis of the time series data in various fields (handwriting recognition,
    speech recognition, etc).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different types of [RNN](#glo.main.rnn) structures: one to many,
    many to one, many to many. Generally, [RNN](#glo.main.rnn) processes the input
    sequence series one by one at a time, during its operation. Units in the hidden
    layer hold information about the history of the input in the "state vector" [[21](#bib.bib21)].
    [RNNs](#glo.main.rnn) can be trained using the [Backpropagation Through Time (BPTT)](#glo.main.bptt)
    method. Using [BPTT](#glo.main.bptt), the differentiation of the loss at any time
    $t$ has reflected the weights of the network at the previous time. Training of
    [RNNs](#glo.main.rnn) are more difficult than [Feedforward Neural Networks (FFNNs)](#glo.main.ffnn)
    and the training period of [RNNs](#glo.main.rnn) takes longer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Figure [3](#S3.F3 "Figure 3 ‣ 3.3 Recurrent Neural Network (RNN) ‣ 3 Deep
    Learning ‣ Deep Learning for Financial Applications : A Survey"), the information
    flow in the [RNN](#glo.main.rnn)’s hidden layer is divided into discrete times.
    The status of the node S at different times of $t$ is shown as $s_{t}$, the input
    value $x$ at different times is $x_{t}$, and the output value $o$ at different
    times is shown as $o_{t}$. The parameter values ($U,W,V$) are always used in the
    same step.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a1434138f07a0e4895fafb2fed35ceed.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: RNN cell through time[[21](#bib.bib21)]'
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Long Short Term Memory (LSTM)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[LSTM](#glo.main.lstm) network [[28](#bib.bib28)] is a different type of [DL](#glo.main.dl)
    network specifically intended for sequential data analysis. The advantage of [LSTM](#glo.main.lstm)
    networks lies in the fact that both short term and long term values in the network
    can be remembered. Therefore, [LSTM](#glo.main.lstm) networks are mostly used
    for sequential data analysis (automatic speech recognition, language translation,
    handwritten character recognition, time-series data forecasting, etc.) by [DL](#glo.main.dl)
    researchers. [LSTM](#glo.main.lstm) networks consist of [LSTM](#glo.main.lstm)
    units. [LSTM](#glo.main.lstm) unit is composed of cells having input, output and
    forget gates. These three gates regulate the information flow. With these features,
    each cell remembers the desired values over arbitrary time intervals. [LSTM](#glo.main.lstm)
    cells combine to form layers of neural networks. Figure [4](#S3.F4 "Figure 4 ‣
    3.4 Long Short Term Memory (LSTM) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey") illustrates the basic LSTM unit ($\sigma_{g}$: sigmoid
    function, $tanh$: hyperbolic tangent function, $X$: multiplication, $+$: addition).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4b01c5ab4ad302759f9ccac3414f8203.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Basic LSTM Unit [[28](#bib.bib28)]'
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 Restricted Boltzmann Machines (RBMs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[RBM](#glo.main.rbm) is a different type of [ANN](#glo.main.ann) model that
    can learn the probability distribution of the input set [[29](#bib.bib29)]. [RBMs](#glo.main.rbm)
    are mostly used for dimensionality reduction, classification, and feature learning.
    [RBM](#glo.main.rbm) is a bipartite, undirected graphical model that consists
    of two layers; visible and hidden layer. The units in the layer are not connected
    to each other. Each cell is a computational point that processes the input. Each
    unit makes stochastic decisions about whether transmitting the input data or not.
    The inputs are multiplied by specific weights, certain threshold values (bias)
    are added to the input values, then the calculated values are passed through an
    activation function. In the reconstruction stage, the results in the outputs re-enter
    the network as the input, then they exit from the visible layer as the output.
    The values of the previous input and the values after the processes are compared.
    The purpose of the comparison is to reduce the difference. The learning is performed
    multiple times on the network [[29](#bib.bib29)]. [RBM](#glo.main.rbm) is a two-layer,
    bipartite, and undirected graphical model that consists of two layers; visible
    and hidden layers (Figure [5](#S3.F5 "Figure 5 ‣ 3.5 Restricted Boltzmann Machines
    (RBMs) ‣ 3 Deep Learning ‣ Deep Learning for Financial Applications : A Survey")).
    The layers are not connected among themselves. The disadvantage of [RBM](#glo.main.rbm)
    is its tricky training. “[RBMs](#glo.main.rbm) are tricky because although there
    are good estimators of the log-likelihood gradient, there are no known cheap ways
    of estimating the log-likelihood itself" [[30](#bib.bib30)].'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c7056e0cb889c2297ccf9c13c0d89daf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: RBM Visible and Hidden Layers [[29](#bib.bib29)]'
  prefs: []
  type: TYPE_NORMAL
- en: 3.6 Deep Belief Networks (DBNs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[DBN](#glo.main.dbn) is a type of [ANN](#glo.main.ann) that consists of a stack
    of [RBM](#glo.main.rbm) layers. [DBN](#glo.main.dbn) is a probabilistic generative
    model that consists of latent variables. [DBNs](#glo.main.dbn) are used for finding
    independent and discriminative features in the input set using an unsupervised
    approach. [DBN](#glo.main.dbn) can learn to reconstruct the input set in a probabilistic
    way during the training process. Then the layers on the network begin to detect
    the discriminative features. After the learning step, supervised learning is carried
    out to perform for the classification [[31](#bib.bib31)]. Figure [6](#S3.F6 "Figure
    6 ‣ 3.6 Deep Belief Networks (DBNs) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey") illustrates the [DBN](#glo.main.dbn) structure.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1540c07d0250f8dc646cc0eec03a3997.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Deep Belief Network [[29](#bib.bib29)]'
  prefs: []
  type: TYPE_NORMAL
- en: 3.7 Autoencoders (AEs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[AE](#glo.main.ae) networks are commonly used in [DL](#glo.main.dl) models,
    wherein they remap the inputs (features) such that the inputs are more representative
    for the classification. In other words, [AE](#glo.main.ae) networks perform an
    unsupervised feature learning process. A representation of a data set is learned
    by reducing the dimensionality with an [AE](#glo.main.ae). In the literature,
    [AEs](#glo.main.ae) have been used for feature extraction and dimensionality reduction
    [[27](#bib.bib27), [32](#bib.bib32)]. The architecture of an [AE](#glo.main.ae)
    has similarities with that of a [FFNN](#glo.main.ffnn). It consists of an input
    layer, output layer and one (or more) hidden layer that connects them together.
    The number of nodes in the input layer and the number of nodes in the output layer
    are equal to each other in [AEs](#glo.main.ae), and they have a symmetrical structure.
    [AEs](#glo.main.ae) contain two components: encoder and decoder.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The advantages of the usage of [AE](#glo.main.ae) are dimensionality reduction
    and feature learning. However, reducing dimensions and feature extraction in [AE](#glo.main.ae)
    cause some drawbacks. Focusing on minimizing the loss of the data relationship
    in the code of [AE](#glo.main.ae) causes the loss of some significant data relationship.
    This may be a drawback of [AE](#glo.main.ae) [[33](#bib.bib33)]. Figure [7](#S3.F7
    "Figure 7 ‣ 3.7 Autoencoders (AEs) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey") shows the basic [AE](#glo.main.ae) structure.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d64512a2f54396a4c514698d209a63f4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Basic Autoencoder Structure'
  prefs: []
  type: TYPE_NORMAL
- en: 3.8 Other Deep Structures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The [DL](#glo.main.dl) models are not limited to the ones mentioned in the previous
    subsections. Some of the other well-known structures that exist in the literature
    are [Deep Reinforcement Learning (DRL)](#glo.main.drl), [Generative Adversarial
    Networks (GANs)](#glo.main.gan) , Capsule Networks, [Deep Gaussian Processes (DGPs)](#glo.main.dgp)
    . Meanwhile, to the best of our knowledge, we have not encountered any noteworthy
    academic or industrial publication on financial applications using these models
    so far, with the exception of [DRL](#glo.main.drl) which started getting attention
    lately. However, that does not imply that these models do not fit well with the
    financial domain. On the contrary, they offer great potentials for researchers
    and practitioners participating in finance and deep learning community who are
    willing to go the extra mile to come up with novel solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Since research for model developments in [DL](#glo.main.dl) is ongoing, new
    structures keep on coming. However, the aforementioned models currently cover
    almost all of the published work. Next section will provide details about the
    implementation areas along with the preferred [DL](#glo.main.dl) models.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Financial Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a lot of financial applications of soft computing in the literature.
    [DL](#glo.main.dl) has been studied in most of them, although, some opportunities
    still exist in a number of fields.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this section, we categorized the implementation areas and presented
    them in separate subsections. Besides, in each subsection we tabulated the representative
    features of the relevant studies in order to provide as much information as possible
    in the limited space.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, the readers should note that there were some overlaps between different
    implementation areas for some papers. There were two main reasons for that: In
    some papers, multiple problems were addressed separately, for e.g. text mining
    was studied for feature extraction, then algorithmic trading was implemented.
    For some other cases, the paper might fit directly into multiple implementation
    areas due to the survey structure, for e.g. cryptocurrency portfolio management.
    In such cases we included the papers in all of the relevant subsections creating
    some overlaps.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the existing study areas can be grouped as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Algorithmic Trading
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Algorithmic trading (or Algo-trading) is defined as buy-sell decisions made
    solely by algorithmic models. These decisions can be based on some simple rules,
    mathematical models, optimized processes, or as in the case of machine/deep learning,
    highly complex function approximation techniques. With the introduction of electronic
    online trading platforms and frameworks, algorithmic trading took over the finance
    industry in the last two decades. As a result, Algo-trading models based on [DL](#glo.main.dl)
    also started getting attention.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the Algo-trading applications are coupled with price prediction models
    for market timing purposes. As a result, a majority of the price or trend forecasting
    models that trigger buy-sell signals based on their prediction are also considered
    as Algo-trading systems. However, there are also some studies that propose stand-alone
    Algo-trading models focused on the dynamics of the transaction itself by optimizing
    trading parameters such as bid-ask spread, analysis of limit order book, position-sizing,
    etc. [High Frequency Trading (HFT)](#glo.main.hft) researchers are particularly
    interested in this area. Hence, [DL](#glo.main.dl) models also started appearing
    in [HFT](#glo.main.hft) studies.
  prefs: []
  type: TYPE_NORMAL
- en: Before diving into the [DL](#glo.main.dl) implementations, it would be beneficial
    to briefly mention about the existing [ML](#glo.main.ml) surveys on Algo-trading.
    Hu et al. [[34](#bib.bib34)] reviewed the implementations of various [EAs](#glo.main.ea)
    on Algorithmic Trading Models. Since financial time series forecasting is highly
    coupled with algorithmic trading, there are a number of [ML](#glo.main.ml) survey
    papers focused on Algo-trading models based on forecasting. The interested readers
    can refer to [[1](#bib.bib1)] for more information.
  prefs: []
  type: TYPE_NORMAL
- en: 'As far as the [DL](#glo.main.dl) research is concerned, Table LABEL:table:algorithmic_trading_1,
    Table LABEL:table:algorithmic_trading_2, and Table LABEL:table:algorithmic_trading_3
    present the past and current status of algo-trading studies based on [DL](#glo.main.dl)
    models. The papers are distributed to these tables as follows: Table LABEL:table:algorithmic_trading_1
    has the particular algorithmic trading implementations that are embedded with
    time series forecasting models, whereas Table LABEL:table:algorithmic_trading_2
    is focused on classification based (Buy-sell Signal, or Trend Detection) algo-trading
    models. Finally, Table LABEL:table:algorithmic_trading_3 presents stand-alone
    studies or other algorithmic trading models (pairs trading, arbitrage, etc) that
    do not fit into the above clustering criteria.'
  prefs: []
  type: TYPE_NORMAL
- en: Most of the Algo-trading studies were concentrated on the prediction of stock
    or index prices. Meanwhile, [LSTM](#glo.main.lstm) was the most preferred [DL](#glo.main.dl)
    model in these implementations. In [[35](#bib.bib35)], market microstructures
    based trade indicators were used as the input into [RNN](#glo.main.rnn) with Graves
    [LSTM](#glo.main.lstm) to perform the price prediction for algorithmic stock trading.
    Bao et al. [[36](#bib.bib36)] used technical indicators as the input into [Wavelet
    Transforms (WT)](#glo.main.wt), [LSTM](#glo.main.lstm) and [Stacked Autoencoders
    (SAEs)](#glo.main.sae) for the forecasting of stock prices. In [[37](#bib.bib37)],
    [CNN](#glo.main.cnn) and [LSTM](#glo.main.lstm) model structures were implemented
    together ([CNN](#glo.main.cnn) was used for stock selection, [LSTM](#glo.main.lstm)
    was used for price prediction).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Algo-trading Applications Embedded with Time Series Forecasting Models'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Environment |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[35](#bib.bib35)] | GarantiBank in [BIST](#glo.main.bist), Turkey | 2016
    | [OCHLV](#glo.main.ochlv), Spread, Volatility, Turnover, etc. | [PLR](#glo.main.plr),
    Graves [LSTM](#glo.main.lstm) | [MSE](#glo.main.mse), [RMSE](#glo.main.rmse),
    [MAE](#glo.main.mae), [RSE](#glo.main.rse), Correlation R-square | Spark |'
  prefs: []
  type: TYPE_TB
- en: '| [[36](#bib.bib36)] | [CSI](#glo.main.csi) 300, Nifty50, [HSI](#glo.main.hsi),
    Nikkei 225, [S&P500](#glo.main.sp500), [DJIA](#glo.main.djia) | 2010-2016 | [OCHLV](#glo.main.ochlv),
    Technical Indicators | [WT](#glo.main.wt), Stacked autoencoders, [LSTM](#glo.main.lstm)
    | [MAPE](#glo.main.mape), Correlation coefficient, [THEIL-U](#glo.main.theil-u)
    | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[37](#bib.bib37)] | Chinese Stocks | 2007-2017 | [OCHLV](#glo.main.ochlv)
    | [CNN](#glo.main.cnn) + [LSTM](#glo.main.lstm) | Annualized Return, Mxm Retracement
    | Python |'
  prefs: []
  type: TYPE_TB
- en: '| [[38](#bib.bib38)] | 50 stocks from [NYSE](#glo.main.nyse) | 2007-2016 |
    Price data | [SFM](#glo.main.sfm) | [MSE](#glo.main.mse) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[39](#bib.bib39)] | The LOB of 5 stocks of Finnish Stock Market | 2010 |
    FI-2010 dataset: bid/ask and volume | [WMTR](#glo.main.wmtr), [MDA](#glo.main.mda)
    | Accuracy, Precision, Recall, F1-Score | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[40](#bib.bib40)] | 300 stocks from [SZSE](#glo.main.szse), Commodity |
    2014-2015 | Price data | [FDDR](#glo.main.fddr), [DNN](#glo.main.dnn) +[RL](#glo.main.rl)
    | Profit, return, [SR](#glo.main.sr), profit-loss curves | Keras |'
  prefs: []
  type: TYPE_TB
- en: '| [[41](#bib.bib41)] | [S&P500](#glo.main.sp500) Index | 1989-2005 | Price
    data, Volume | [LSTM](#glo.main.lstm) | Return, [STD](#glo.main.std), [SR](#glo.main.sr),
    Accuracy | Python, TensorFlow, Keras, R, H2O |'
  prefs: []
  type: TYPE_TB
- en: '| [[42](#bib.bib42)] | Stock of National Bank of Greece (ETE). | 2009-2014
    | [FTSE](#glo.main.ftse) 100, [DJIA](#glo.main.djia), GDAX, [NIKKEI](#glo.main.nikkei)
    225, EUR/USD, Gold | [GASVR](#glo.main.gasvr), [LSTM](#glo.main.lstm) | Return,
    volatility, [SR](#glo.main.sr), Accuracy | Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[43](#bib.bib43)] | Chinese stock-IF-IH-IC contract | 2016-2017 | Decisions
    for price change | [MODRL](#glo.main.modrl) +[LSTM](#glo.main.lstm) | Profit and
    loss, [SR](#glo.main.sr) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[44](#bib.bib44)] | Singapore Stock Market Index | 2010-2017 | [OCHL](#glo.main.ochl)
    of last 10 days of Index | [DNN](#glo.main.dnn) | [RMSE](#glo.main.rmse), [MAPE](#glo.main.mape),
    Profit, [SR](#glo.main.sr) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[45](#bib.bib45)] | GBP/USD | 2017 | Price data | Reinforcement Learning
    + [LSTM](#glo.main.lstm) + [NES](#glo.main.nes) | [SR](#glo.main.sr), downside
    deviation ratio, total profit | Python, Keras, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[46](#bib.bib46)] | Commodity, FX future, [ETF](#glo.main.etf) | 1991-2014
    | Price Data | [DNN](#glo.main.dnn) | [SR](#glo.main.sr), capability ratio, return
    | C++, Python |'
  prefs: []
  type: TYPE_TB
- en: '| [[47](#bib.bib47)] | USD/GBP, [S&P500](#glo.main.sp500), [FTSE](#glo.main.ftse)
    100, oil, gold | 2016 | Price data | [AE](#glo.main.ae) + [CNN](#glo.main.cnn)
    | [SR](#glo.main.sr), % volatility, avg return/trans, rate of return | H2O |'
  prefs: []
  type: TYPE_TB
- en: '| [[48](#bib.bib48)] | Bitcoin, Dash, Ripple, Monero, Litecoin, Dogecoin, Nxt,
    Namecoin | 2014-2017 | MA, BOLL, the CRIX returns, Euribor interest rates, [OCHLV](#glo.main.ochlv)
    | [LSTM](#glo.main.lstm), [RNN](#glo.main.rnn), [MLP](#glo.main.mlp) | Accuracy,
    F1-measure | Python, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[49](#bib.bib49)] | [S&P500](#glo.main.sp500), [KOSPI](#glo.main.kospi),
    [HSI](#glo.main.hsi), and EuroStoxx50 | 1987-2017 | 200-days stock price | Deep
    Q-Learning, [DNN](#glo.main.dnn) | Total profit, Correlation | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[50](#bib.bib50)] | Stocks in the [S&P500](#glo.main.sp500) | 1990-2015
    | Price data | [DNN](#glo.main.dnn), [GBT](#glo.main.gbt), [RF](#glo.main.rf)
    | Mean return, [MDD](#glo.main.mdd), Calmar ratio | H2O |'
  prefs: []
  type: TYPE_TB
- en: '| [[51](#bib.bib51)] | Fundamental and Technical Data, Economic Data | - |
    Fundamental , technical and market information | [CNN](#glo.main.cnn) | - | -
    |'
  prefs: []
  type: TYPE_TB
- en: Using a different model, Zhang et. al. [[38](#bib.bib38)] proposed a novel [State
    Frequency Memory (SFM)](#glo.main.sfm) recurrent network for stock price prediction
    with multiple frequency trading patterns and achieved better prediction and trading
    performances. In an [HFT](#glo.main.hft) trading system, Tran et al. [[39](#bib.bib39)]
    developed a [DL](#glo.main.dl) model that implements price change forecasting
    through mid-price prediction using high-frequency limit order book data with tensor
    representation. In [[40](#bib.bib40)], the authors used [Fuzzy Deep Direct Reinforcement
    Learning (FDDR)](#glo.main.fddr) for stock price prediction and trading signal
    generation.
  prefs: []
  type: TYPE_NORMAL
- en: For index prediction, the following studies are noteworthy. In [[41](#bib.bib41)],
    the price prediction of S&P500 index using [LSTM](#glo.main.lstm) was implemented.
    Mourelatos et al. [[42](#bib.bib42)] compared the performance of [LSTM](#glo.main.lstm)
    and [](#glo.main.gasvr)[GA](#glo.main.ga) with a [SVR](#glo.main.svr) (GASVR)
    for Greek Stock Exchange Index prediction. Si et al. [[43](#bib.bib43)] implemented
    Chinese intraday futures market trading model with [DRL](#glo.main.drl) and [LSTM](#glo.main.lstm).
    Yong et al. [[44](#bib.bib44)] used feed-forward [DNN](#glo.main.dnn) method and
    [Open,Close,High, Low (OCHL)](#glo.main.ochl) of the time series index data to
    predict Singapore Stock Market index data.
  prefs: []
  type: TYPE_NORMAL
- en: Forex or cryptocurrency trading was implemented in some studies. In [[45](#bib.bib45)],
    agent inspired trading using deep (recurrent) reinforcement learning and [LSTM](#glo.main.lstm)
    was implemented and tested on the trading of GBP/USD. In [[46](#bib.bib46)], feedforward
    deep [MLP](#glo.main.mlp) was implemented for the prediction of commodities and
    FX trading prices. Korczak et al. [[47](#bib.bib47)] implemented a forex trading
    (GBP/PLN) model using several different input parameters on a multi-agent-based
    trading environment. One of the agents was using [CNN](#glo.main.cnn) as the prediction
    model and outperformed all other models.
  prefs: []
  type: TYPE_NORMAL
- en: On the cryptocurrency side, Spilak et al. [[48](#bib.bib48)] used several cryptocurrencies
    (Bitcoin, Dash, Ripple, Monero, Litecoin, Dogecoin, Nxt, Namecoin) to construct
    a dynamic portfolio using [LSTM](#glo.main.lstm), [RNN](#glo.main.rnn), [MLP](#glo.main.mlp)
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a versatile study, Jeong et al. [[49](#bib.bib49)] combined deep Q-learning
    and [DNN](#glo.main.dnn) to implement price forecasting and they intended to solve
    three separate problems: Increasing profit in a market, prediction of the number
    of shares to trade, and preventing overfitting with insufficient financial data.'
  prefs: []
  type: TYPE_NORMAL
- en: In [[52](#bib.bib52)], technical analysis indicator’s ([Relative Strength Index
    (RSI)](#glo.main.rsi)) buy & sell limits were optimized with [GA](#glo.main.ga)
    which was used for buy-sell signals. After optimization, [DMLP](#glo.main.dmlp)
    was also used for function approximation. In [[53](#bib.bib53)], the authors combined
    deep [Fully Connected Neural Network (FNN)](#glo.main.fnn) with a selective trade
    strategy unit to predict the next price. In [[54](#bib.bib54)], the crossover
    and [Moving Average Convergence and Divergence (MACD)](#glo.main.macd) signals
    were used to predict the trend of the Dow 30 stocks’ prices. Sirignano et al.
    [[55](#bib.bib55)] proposed a novel method that used limit order book flow and
    history information for the determination of the stock movements using [LSTM](#glo.main.lstm)
    model. Tsantekidis et al. [[56](#bib.bib56)] also used limit order book time series
    data and [LSTM](#glo.main.lstm) method for the trend prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Several studies focused on utilizing [CNN](#glo.main.cnn) based models due to
    their success in image classification problems. However, in order to do that,
    the financial input data needed to be transformed into images which required some
    creative preprocessing. Gudelek et al. [[57](#bib.bib57)] converted time series
    of price data to 2-dimensional images using technical analysis and classified
    them with deep [CNN](#glo.main.cnn). Similarly, Sezer et al. [[58](#bib.bib58)]
    also proposed a novel technique that converts financial time series data that
    consisted of technical analysis indicator outputs to 2-dimensional images and
    classified these images using [CNN](#glo.main.cnn) to determine the trading signals.
    In [[59](#bib.bib59)], candlestick chart graphs were converted into 2-dimensional
    images. Then, unsupervised convolutional [AE](#glo.main.ae) was fed with the images
    to implement portfolio construction. Tsantekidis et al. [[60](#bib.bib60)] proposed
    a novel method that used the last 100 entries from the limit order book to create
    a 2-dimensional image for the stock price prediction using [CNN](#glo.main.cnn)
    method. In [[61](#bib.bib61)], an innovative method was proposed that uses [CNN](#glo.main.cnn)
    with correlated features combined together to predict the trend of the stocks
    prices. Finally, Sezer et al. [[62](#bib.bib62)] directly used bar chart images
    as inputs to [CNN](#glo.main.cnn) and predicted if the image class was Buy, Hold
    or Sell, hence a corresponding Algo-trading model was developed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: Classification (Buy-sell Signal, or Trend Detection) Based Algo-trading
    Models'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Environment |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[52](#bib.bib52)] | Stocks in Dow30 | 1997-2017 | [RSI](#glo.main.rsi) |
    [DMLP](#glo.main.dmlp) with genetic algorithm | Annualized return | Spark MLlib,
    Java |'
  prefs: []
  type: TYPE_TB
- en: '| [[53](#bib.bib53)] | [SPY](#glo.main.spy)  [ETF](#glo.main.etf), 10 stocks
    from [S&P500](#glo.main.sp500) | 2014-2016 | Price data | [FFNN](#glo.main.ffnn)
    | Cumulative gain | MatConvNet, Matlab |'
  prefs: []
  type: TYPE_TB
- en: '| [[54](#bib.bib54)] | Dow30 stocks | 2012-2016 | Close data and several technical
    indicators | [LSTM](#glo.main.lstm) | Accuracy | Python, Keras, Tensorflow, [TALIB](#glo.main.talib)
    |'
  prefs: []
  type: TYPE_TB
- en: '| [[55](#bib.bib55)] | High-frequency record of all orders | 2014-2017 | Price
    data, record of all orders, transactions | [LSTM](#glo.main.lstm) | Accuracy |
    - |'
  prefs: []
  type: TYPE_TB
- en: '| [[56](#bib.bib56)] | Nasdaq Nordic (Kesko Oyj, Outokumpu Oyj, Sampo, Rautaruukki,
    Wartsila Oyj) | 2010 | Price and volume data in [LOB](#glo.main.lob) | [LSTM](#glo.main.lstm)
    | Precision, Recall, F1-score, Cohen’s k | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[57](#bib.bib57)] | 17 [ETFs](#glo.main.etf) | 2000-2016 | Price data, technical
    indicators | [CNN](#glo.main.cnn) | Accuracy, [MSE](#glo.main.mse), Profit, [AUROC](#glo.main.auroc)
    | Keras, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[58](#bib.bib58)] | Stocks in Dow30 and 9 Top Volume [ETFs](#glo.main.etf)
    | 1997-2017 | Price data, technical indicators | [CNN](#glo.main.cnn) with feature
    imaging | Recall, precision, F1-score, annualized return | Python, Keras, Tensorflow,
    Java |'
  prefs: []
  type: TYPE_TB
- en: '| [[59](#bib.bib59)] | [FTSE](#glo.main.ftse) 100 | 2000-2017 | Price data
    | [CAE](#glo.main.cae) | [TR](#glo.main.tr), [SR](#glo.main.sr), [MDD](#glo.main.mdd),
    mean return | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[60](#bib.bib60)] | Nasdaq Nordic (Kesko Oyj, Outokumpu Oyj, Sampo, Rautaruukki,
    Wartsila Oyj) | 2010 | Price, Volume data, 10 orders of the [LOB](#glo.main.lob)
    | [CNN](#glo.main.cnn) | Precision, Recall, F1-score, Cohen’s k | Theano, Scikit
    learn, Python |'
  prefs: []
  type: TYPE_TB
- en: '| [[61](#bib.bib61)] | Borsa Istanbul 100 Stocks | 2011-2015 | 75 technical
    indicators and [OCHLV](#glo.main.ochlv) | [CNN](#glo.main.cnn) | Accuracy | Keras
    |'
  prefs: []
  type: TYPE_TB
- en: '| [[62](#bib.bib62)] | [ETFs](#glo.main.etf) and Dow30 | 1997-2007 | Price
    data | [CNN](#glo.main.cnn) with feature imaging | Annualized return | Keras,
    Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[63](#bib.bib63)] | 8 experimental assets from bond/derivative market |
    - | Asset prices data | [RL](#glo.main.rl), [DNN](#glo.main.dnn), Genetic Algorithm
    | Learning and genetic algorithm error | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[64](#bib.bib64)] | 10 stocks from [S&P500](#glo.main.sp500) | - | Stock
    Prices | [TDNN](#glo.main.tdnn), [RNN](#glo.main.rnn), [PNN](#glo.main.pnn) |
    Missed opportunities, false alarms ratio | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[65](#bib.bib65)] | London Stock Exchange | 2007-2008 | Limit order book
    state, trades, buy/sell orders, order deletions | [CNN](#glo.main.cnn) | Accuracy,
    kappa | Caffe |'
  prefs: []
  type: TYPE_TB
- en: '| [[66](#bib.bib66)] | Cryptocurrencies, Bitcoin | 2014-2017 | Price data |
    [CNN](#glo.main.cnn), [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm) | Accumulative
    portfolio value, [MDD](#glo.main.mdd), [SR](#glo.main.sr) | - |'
  prefs: []
  type: TYPE_TB
- en: Serrano et al. [[63](#bib.bib63)] proposed a novel method called “GoldAI Sachs”
    Asset Banker Reinforcement Learning Algorithm for algorithmic trading. The proposed
    method used a random neural network, [GP](#glo.main.gp), and [Reinforcement Learning
    (RL)](#glo.main.rl) to generate the trading signals. Saad et al. [[64](#bib.bib64)]
    compared [Timedelay Neural Network (TDNN)](#glo.main.tdnn), [RNN](#glo.main.rnn)
    and [Probabilistic Neural Network (PNN)](#glo.main.pnn) for trend detection using
    10 stocks from S&P500\. In [[65](#bib.bib65)], [HFT](#glo.main.hft) microstructures
    forecasting with [CNN](#glo.main.cnn) method was performed. In [[66](#bib.bib66)],
    cryptocurrency portfolio management based on three different proposed models (basic
    [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm) and [CNN](#glo.main.cnn)) was implemented.
  prefs: []
  type: TYPE_NORMAL
- en: Tino et al. [[67](#bib.bib67)] used [The Deutscher Aktienindex (DAX)](#glo.main.dax),
    [London Financial Times Stock Exchange Index (FTSE)](#glo.main.ftse) 100, call
    and put options prices to predict the changes with Markov models and used the
    financial time series data to predict volatility changes with [RNN](#glo.main.rnn).
    Meanwhile, Chen et al. [[68](#bib.bib68)] proposed a method that uses a filterbank
    [CNN](#glo.main.cnn) Algorithm on 15x15 volatility times series converted synthetic
    images. In the study, the financial domain knowledge and filterbank mechanism
    were combined to determine the trading signals. Bari et al. [[69](#bib.bib69)]
    used text mining to extract information from the tweets and financial news and
    used [LSTM](#glo.main.lstm), [RNN](#glo.main.rnn), [Gated-Recurrent Unit (GRU)](#glo.main.gru)
    for the generation of the trading signals. Dixon et al. [[70](#bib.bib70)] used
    [RNN](#glo.main.rnn) for the sequence classification of the limit order book to
    predict a next event price-flip.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: Stand-alone and/or Other Algorithmic Models'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Environment |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[67](#bib.bib67)] | [DAX](#glo.main.dax), [FTSE](#glo.main.ftse) 100, call/put
    options | 1991-1998 | Price data | Markov model, [RNN](#glo.main.rnn) | Ewa-measure,
    iv, daily profits’ mean and std | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[68](#bib.bib68)] | Taiwan Stock Index Futures, Mini Index Futures | 2012-2014
    | Price data to image | Visualization method + [CNN](#glo.main.cnn) | Accumulated
    profits,accuracy | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[69](#bib.bib69)] | Energy-Sector/ Company-Centric Tweets in [S&P500](#glo.main.sp500)
    | 2015-2016 | Text and Price data | [LSTM](#glo.main.lstm), [RNN](#glo.main.rnn),
    [GRU](#glo.main.gru) | Return, [SR](#glo.main.sr), precision, recall, accuracy
    | Python, Tweepy API |'
  prefs: []
  type: TYPE_TB
- en: '| [[70](#bib.bib70)] | [CME](#glo.main.cme) FIX message | 2016 | Limit order
    book, time-stamp, price data | [RNN](#glo.main.rnn) | Precision, recall, F1-measure
    | Python, TensorFlow, R |'
  prefs: []
  type: TYPE_TB
- en: '| [[71](#bib.bib71)] | Taiwan stock index futures (TAIFEX) | 2017 | Price data
    | Agent based [RL](#glo.main.rl) with [CNN](#glo.main.cnn) pre-trained | Accuracy
    | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[72](#bib.bib72)] | Stocks from [S&P500](#glo.main.sp500) | 2010-2016 |
    [OCHLV](#glo.main.ochlv) | [DCNL](#glo.main.dcnl) | [PCC](#glo.main.pcc), [DTW](#glo.main.dtw),
    [VWL](#glo.main.vwl) | Pytorch |'
  prefs: []
  type: TYPE_TB
- en: '| [[73](#bib.bib73)] | News from NowNews, AppleDaily, LTN, MoneyDJ for 18 stocks
    | 2013-2014 | Text, Sentiment | [DNN](#glo.main.dnn) | Return | Python, Tensorflow
    |'
  prefs: []
  type: TYPE_TB
- en: '| [[74](#bib.bib74)] | 489 stocks from [S&P500](#glo.main.sp500) and [NASDAQ](#glo.main.nasdaq)-100
    | 2014-2015 | Limit Order Book | Spatial neural network | Cross entropy error
    | NVIDIA’s cuDNN |'
  prefs: []
  type: TYPE_TB
- en: '| [[75](#bib.bib75)] | Experimental dataset | - | Price data | [DRL](#glo.main.drl)
    with [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm), [GRU](#glo.main.gru), [MLP](#glo.main.mlp)
    | Mean profit | Python |'
  prefs: []
  type: TYPE_TB
- en: Chen et al. [[71](#bib.bib71)] used 1-dimensional [CNN](#glo.main.cnn) with
    an agent-based [RL](#glo.main.rl) algorithm on the Taiwan stock index futures
    (TAIFEX) dataset. Wang et al. [[72](#bib.bib72)] proposed a Deep Co-investment
    Network Learning (DeepCNL) method that used convolutional and [RNN](#glo.main.rnn)
    layers. The investment pattern was determined using the extracted Rise-Fall trends.
    Day et al. [[73](#bib.bib73)] used financial sentiment analysis using text mining
    and [DNN](#glo.main.dnn) for stock algorithmic trading. Sirignano et al. [[74](#bib.bib74)]
    proposed a “spatial neural network” model that used limit order book and spatial
    features for algorithmic trading. Their model estimates the best bid-ask prices
    using bid, ask prices in the limit order book. Gao et al. [[75](#bib.bib75)] used
    [GRU](#glo.main.gru), [LSTM](#glo.main.lstm) units, [CNN](#glo.main.cnn), and
    [MLP](#glo.main.mlp) to model Q values for the implementation of the [DRL](#glo.main.drl)
    method.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Risk Assessment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another study area that has been of interest to [DL](#glo.main.dl) researchers
    is Risk Assessment which identifies the “riskiness" of any given asset, firm,
    person, product, bank, etc. Several different versions of this general problem
    exist, such as bankruptcy prediction, credit scoring, credit evaluation, loan/insurance
    underwriting, bond rating, loan application, consumer credit determination, corporate
    credit rating, mortgage choice decision, financial distress prediction, business
    failure prediction. Correctly identifying the risk status in such cases is crucial,
    since asset pricing is highly dependent on these risk assessment measures. The
    mortgage crisis based on improper risk assessment of [Credit Default Swaps (CDS)](#glo.main.cds)
    between financial institutions caused the real-estate bubble to burst in 2008
    and resulted in the Great Recession [[76](#bib.bib76)].
  prefs: []
  type: TYPE_NORMAL
- en: The majority of the risk assessment studies concentrate on credit scoring and
    bank distress classification. However, there are also a few papers covering mortgage
    default possibility, risky transaction detection or crisis forecasting. Meanwhile,
    there are some anomaly detection studies for risk assessment, most of which also
    fall under the "Fraud Detection" category which will be covered in the next subsection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: Credit Scoring or Classification Studies'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[77](#bib.bib77)] | The XR 14 [CDS](#glo.main.cds) contracts | 2016 | Recovery
    rate, spreads, sector and region | [DBN](#glo.main.dbn) +[RBM](#glo.main.rbm)
    | [AUROC](#glo.main.auroc), [FN](#glo.main.fn), [FP](#glo.main.fp), Accuracy |
    WEKA |'
  prefs: []
  type: TYPE_TB
- en: '| [[78](#bib.bib78)] | German, Japanese credit datasets | - | Personal financial
    variables | [SVM](#glo.main.svm) + [DBN](#glo.main.dbn) | Weighted-accuracy, [TP](#glo.main.tp),
    [TN](#glo.main.tn) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[79](#bib.bib79)] | Credit data from Kaggle | - | Personal financial variables
    | [DNN](#glo.main.dnn) | Accuracy, [TP](#glo.main.tp), [TN](#glo.main.tn), G-mean
    | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[80](#bib.bib80)] | Australian, German credit data | - | Personal financial
    variables | [GP](#glo.main.gp) + [AE](#glo.main.ae) as Boosted [DNN](#glo.main.dnn)
    | [FP](#glo.main.fp) | Python, Scikit-learn |'
  prefs: []
  type: TYPE_TB
- en: '| [[81](#bib.bib81)] | German, Australian credit dataset | - | Personal financial
    variables | [DCNN](#glo.main.dcnn), [MLP](#glo.main.mlp) | Accuracy, False/Missed
    alarm | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[82](#bib.bib82)] | Consumer credit data from Chinese finance company |
    - | Relief algorithm chose the 50 most important features | [CNN](#glo.main.cnn)
    + Relief | [AUROC](#glo.main.auroc), K-s statistic, Accuracy | Keras |'
  prefs: []
  type: TYPE_TB
- en: '| [[83](#bib.bib83)] | Credit approval dataset by UCI Machine Learning repo
    | - | UCI credit approval dataset | Rectifier, Tanh, Maxout [DL](#glo.main.dl)
    | - | AWS EC2, H2O, R |'
  prefs: []
  type: TYPE_TB
- en: Before going into the details about specific [DL](#glo.main.dl) implementations,
    it is worthwhile to mention the existing [ML](#glo.main.ml) surveys on the topic.
    Kirkos et al. [[84](#bib.bib84)], Ravi et al. [[85](#bib.bib85)], Fethi et al.
    [[86](#bib.bib86)] reviewed the bank performance assessment studies based on [Artificial
    Intelligence (AI)](#glo.main.ai) and [ML](#glo.main.ml) models. Lahsasna et al.
    [[87](#bib.bib87)], Chen et al.[[88](#bib.bib88)] surveyed the credit scoring
    and credit risk assessment studies based on soft computing techniques whereas
    Marques et. al. [[89](#bib.bib89)] focused only on [Evolutionary Computation (EC)](#glo.main.ec)
    Models for credit scoring implementations. Meanwhile, Kumar et al. [[90](#bib.bib90)],
    Verikas et al. [[91](#bib.bib91)] reviewed [ML](#glo.main.ml) implementations
    of bankruptcy prediction studies. Similarly, Sun et al. [[92](#bib.bib92)] provided
    a comprehensive survey about research on financial distress and corporate failures.
    Apart from these reviews, for assessing overall risk, Lin et al. [[93](#bib.bib93)]
    surveyed the financial crisis prediction studies based on [ML](#glo.main.ml) models.
  prefs: []
  type: TYPE_NORMAL
- en: Since risk assessment is becoming vital for survival in today’s financial world,
    a lot of researchers turned their attention to [DL](#glo.main.dl) for higher accuracy.
    Table LABEL:table:risk_assesment_1, Table LABEL:table:risk_assesment_2 provide
    snapshot information about the different risk assessment studies implemented using
    various [DL](#glo.main.dl) models.
  prefs: []
  type: TYPE_NORMAL
- en: For credit score classification (Table LABEL:table:risk_assesment_1), Luo et
    al. [[77](#bib.bib77)], used [CDS](#glo.main.cds) data for Corporate Credit rating
    and corresponding credit classification (A,B or C). Among the tested models, [DBN](#glo.main.dbn)
    with [RBM](#glo.main.rbm) performed the best. This implementation was probably
    the first study to implement Credit rating with [DBN](#glo.main.dbn). Similarly,
    in [[78](#bib.bib78)], a cascaded hybrid model of [DBN](#glo.main.dbn), Backpropagation
    and [SVM](#glo.main.svm) for credit classification was implemented and good performance
    results (the accuracy was above 80-90 %) were achieved. In [[79](#bib.bib79)],
    credit risk classification was achieved by using an ensemble of deep [MLP](#glo.main.mlp)
    networks each using subspaces of the whole space by k-means (using minority class
    in each, but only a partial subspace of the majority class). The data imbalance
    problem was handled by using multiple subspaces for each classifier, where each
    of them had all the positive (minor) instances, but a subsample of negative (majority)
    instances, finally they used an ensemble of deep [MLPs](#glo.main.mlp) combining
    each subspace model. In [[80](#bib.bib80)], credit scoring was performed using
    a [SAE](#glo.main.sae) network and [GP](#glo.main.gp) model to create credit assessment
    rules in order to generate good or bad credit cases. In another study, Neagoe
    et. al. [[81](#bib.bib81)] classified credit scores using various [DMLP](#glo.main.dmlp)
    and deep [CNN](#glo.main.cnn) networks. In a different study [[82](#bib.bib82)],
    consumer credit scoring classification was implemented with a 2-D representation
    of the input consumer data through transforming the data into a 2-D pixel matrix.
    Then the resulting images were used as the training and test data for [CNN](#glo.main.cnn).
    2-D pixel matrix representation of the consumer data was adapted by using [CNN](#glo.main.cnn)
    for image classification. This was the first implementation of credit scoring
    using [CNN](#glo.main.cnn). Niimi [[83](#bib.bib83)] used UCI credit approval
    dataset ¹¹1https://archive.ics.uci.edu/ml/datasets.html to compare [DL](#glo.main.dl),
    [SVM](#glo.main.svm), [Logistic Regression (LR)](#glo.main.lr), [Random Forest
    (RF)](#glo.main.rf), [eXtreme Gradient Boosting (XGBoost)](#glo.main.xgboost)
    and provided information about credit fraud and credit approval applications;
    then experimented with the credit approval problem with several models. Various
    models were compared for credit approval classification. Also, some introduction
    about credit fraud detection was provided.
  prefs: []
  type: TYPE_NORMAL
- en: Financial distress prediction for banks and corporates are studied extensively
    (Table LABEL:table:risk_assesment_2). In [[94](#bib.bib94)], a hybrid [DBN](#glo.main.dbn)
    with [SVM](#glo.main.svm) was used for financial distress prediction to identify
    whether the firm was in trouble or not, whereas bank risk classification was studied
    in [[95](#bib.bib95)]. In [[96](#bib.bib96)], news semantics were extracted by
    the word sequence learning and associated events were labeled with the bank stress,
    then from the formed semantic vector representation, the bank stress was determined
    and classified against a threshold. Prediction and semantic meaning extraction
    were integrated in a neat way. In another study [[97](#bib.bib97)], text mining
    was again used for identifying the bank distress by extracting the data from financial
    news and then using a [Deep Feed Forward Network (DFFN)](#glo.main.dffn) on semantic
    sentence vectors extracted from word embeddings to classify if there was an event
    or not. Similarly, Cerchiello et al. [[98](#bib.bib98)] used text mining from
    the financial news to classify bank distress. Malik et al. [[99](#bib.bib99)]
    evaluated the bank stress by first predicting the bank’s performance through an
    [LSTM](#glo.main.lstm) network, then Backpropagation network was used for finding
    the bank stress level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: Financial Distress, Bankruptcy, Bank Risk, Mortgage Risk, Crisis Forecasting
    Studies'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[94](#bib.bib94)] | 966 french firms | - | Financial ratios | [RBM](#glo.main.rbm)
    +[SVM](#glo.main.svm) | Precision, Recall | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[95](#bib.bib95)] | 883 [BHC](#glo.main.bhc) from EDGAR | 2006-2017 | Tokens,
    weighted sentiment polarity, leverage and [ROA](#glo.main.roa) | [CNN](#glo.main.cnn),
    [LSTM](#glo.main.lstm), [SVM](#glo.main.svm), [RF](#glo.main.rf) | Accuracy, Precision,
    Recall, F1-score | Keras, Python, Scikit-learn |'
  prefs: []
  type: TYPE_TB
- en: '| [[96](#bib.bib96)] | The event data set for large European banks, news articles
    from Reuters | 2007-2014 | Word, sentence | [DNN](#glo.main.dnn) +[NLP](#glo.main.nlp)
    preprocess | Relative usefulness, F1-score | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[97](#bib.bib97)] | Event dataset on European banks, news from Reuters |
    2007-2014 | Text, sentence | Sentence vector + [DFFN](#glo.main.dffn) | Usefulness,
    F1-score, [AUROC](#glo.main.auroc) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[98](#bib.bib98)] | News from Reuters, fundamental data | 2007-2014 | Financial
    ratios and news text | doc2vec + [NN](#glo.main.nn) | Relative usefulness | Doc2vec
    |'
  prefs: []
  type: TYPE_TB
- en: '| [[99](#bib.bib99)] | Macro/Micro economic variables, Bank characteristics/performance
    variables from [BHC](#glo.main.bhc) | 1976-2017 | Macro economic variables and
    bank performances | [CGAN](#glo.main.cgan), [MVN](#glo.main.mvn), [MV-t](#glo.main.mv-t),
    [LSTM](#glo.main.lstm), [VAR](#glo.main.var), [FE-QAR](#glo.main.fe-qar) | [RMSE](#glo.main.rmse),
    Log likelihood, Loan loss rate | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[100](#bib.bib100)] | Financial statements of French companies | 2002-2006
    | Financial ratios | [DBN](#glo.main.dbn) | Recall, Precision, F1-score, [FP](#glo.main.fp),
    [FN](#glo.main.fn) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[101](#bib.bib101)] | Stock returns of American publicly-traded companies
    from [CRSP](#glo.main.crsp) | 2001-2011 | Price data | [DBN](#glo.main.dbn) |
    Accuracy | Python, Theano |'
  prefs: []
  type: TYPE_TB
- en: '| [[102](#bib.bib102)] | Financial statements of several companies from Japanese
    stock market | 2002-2016 | Financial ratios | [CNN](#glo.main.cnn) | F1-score,
    [AUROC](#glo.main.auroc) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[103](#bib.bib103)] | Mortgage dataset with local and national economic
    factors | 1995-2014 | Mortgage related features | [ANN](#glo.main.ann) | Negative
    average log-likelihood | AWS |'
  prefs: []
  type: TYPE_TB
- en: '| [[104](#bib.bib104)] | Mortgage data from Norwegian financial service group,
    DNB | 2012-2016 | Personal financial variables | [CNN](#glo.main.cnn) | Accuracy,
    Sensitivity, Specificity, [AUROC](#glo.main.auroc) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[105](#bib.bib105)] | Private brokerage company’s real data of risky transactions
    | - | 250 features: order details, etc. | [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm)
    | F1-Score | Keras, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[106](#bib.bib106)] | Several datasets combined to create a new one | 1996-2017
    | Index data, 10-year Bond yield, exchange rates, | Logit, [CART](#glo.main.cart),
    [RF](#glo.main.rf), [SVM](#glo.main.svm), [NN](#glo.main.nn), [XGBoost](#glo.main.xgboost),
    [DNN](#glo.main.dnn) | [AUROC](#glo.main.auroc), [KS](#glo.main.ks), [G-mean](#glo.main.g-mean),
    likelihood ratio, [DP](#glo.main.dpower), [BA](#glo.main.ba), [WBA](#glo.main.wba)
    | R |'
  prefs: []
  type: TYPE_TB
- en: There are also a number of research papers that were focused on bankruptcy or
    corporate default prediction. Ribeiro et al. [[100](#bib.bib100)] implemented
    bankruptcy prediction with [DBN](#glo.main.dbn). The results of [DBN](#glo.main.dbn)
    were compared with [SVM](#glo.main.svm) and [RBM](#glo.main.rbm). Yeh et al. [[101](#bib.bib101)]
    used the stock returns of default and solvent companies as inputs to [RBM](#glo.main.rbm)
    used as [SAE](#glo.main.sae), then the output of [RBM](#glo.main.rbm) was used
    as input to [DBN](#glo.main.dbn) to predict if the company was solvent or default.
    The results were compared with an [SVM](#glo.main.svm) model and the [DBN](#glo.main.dbn)
    model outperformed [SVM](#glo.main.svm). Hosaka et al. [[102](#bib.bib102)] tried
    a different approach by converting the financial data to the image to use [CNN](#glo.main.cnn)
    for bankruptcy prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'The remaining implementations of risk assessment are as follows: Sirignano
    et al. [[103](#bib.bib103)] used the mortgage application data of 20 years for
    identifying the mortgage risk using various parameters. They also performed a
    lot of analyses relating different factors that affected the mortgage payment
    structure. The authors also analyzed the prepayment and delinquency behavior in
    their assessment. For another mortgage risk assessment application, Kvamme et
    al. [[104](#bib.bib104)] used [CNN](#glo.main.cnn) and [RF](#glo.main.rf) models
    to predict whether a customer would default on its mortgage or not. In a different
    study, Abroyan et al. [[105](#bib.bib105)] used [CNN](#glo.main.cnn) and [LSTM](#glo.main.lstm)
    networks to classify if a transaction performed on the stock market (trade) was
    risky or not and high accuracy was achieved. Finally, Chatzis et al. [[106](#bib.bib106)]
    developed several [ML](#glo.main.ml) and [DL](#glo.main.dl) models for detecting
    events that caused the stock market to crash. [DL](#glo.main.dl) models had good
    classification (detecting crisis or not) performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Fraud Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Financial fraud is one of the areas where the governments and authorities are
    desperately trying to find a permanent solution. Several different financial fraud
    cases exist such as credit card fraud, money laundering, consumer credit fraud,
    tax evasion, bank fraud, insurance claim fraud. This is one of the most extensively
    studied areas of finance for [ML](#glo.main.ml) research and several survey papers
    were published accordingly. At different times, Kirkos et al. [[107](#bib.bib107)],
    Yue et al. [[108](#bib.bib108)], Wang et al. [[109](#bib.bib109)], Phua et al.
    [[110](#bib.bib110)], Ngai et al. [[111](#bib.bib111)], Sharma et al. [[112](#bib.bib112)],
    West et al. [[113](#bib.bib113)] all reviewed the accounting and financial fraud
    detection studies based on soft computing and data mining techniques.
  prefs: []
  type: TYPE_NORMAL
- en: These type of studies mostly can be considered as anomaly detection and are
    generally classification problems. Table LABEL:table:fraud_detection presents
    different fraud detection studies based on [DL](#glo.main.dl) models.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of studies focused on identifying credit card fraud. Heryadi
    et al. [[114](#bib.bib114)] developed several [DL](#glo.main.dl) models for credit
    card fraud detection for Indonesian banks. They also analyzed the effects of the
    data imbalance between fraud and nonfraud data. In more recent studies, Roy et
    al. [[115](#bib.bib115)] used [LSTM](#glo.main.lstm) model for the credit card
    fraud detection, whereas in [[116](#bib.bib116)], the authors implemented [MLP](#glo.main.mlp)
    networks to classify if a credit card transaction was fraudulent or not. Sohony
    et al. [[117](#bib.bib117)] used an ensemble of [FFNN](#glo.main.ffnn) for the
    detection of card fraud. Jurgovsky et al. [[118](#bib.bib118)] used [LSTM](#glo.main.lstm)
    for detecting credit card fraud from credit card transaction sequences. They compared
    their results with [RF](#glo.main.rf).
  prefs: []
  type: TYPE_NORMAL
- en: Paula et al. [[119](#bib.bib119)] used deep [AE](#glo.main.ae) to implement
    anomaly detection to identify the financial fraud and money laundering for Brazilian
    companies on export tax claims. In a similar study, Gomes et al. [[120](#bib.bib120)]
    proposed an anomaly detection model that identified the anomalies in parliamentary
    expenditure spending in Brazilian elections using also deep [AE](#glo.main.ae).
  prefs: []
  type: TYPE_NORMAL
- en: Wang et al. [[121](#bib.bib121)] used text mining and [DNN](#glo.main.dnn) models
    for the detection of automobile insurance fraud. Longfei et al. [[122](#bib.bib122)]
    developed [DNN](#glo.main.dnn) models to detect online payment transaction fraud.
    Costa et al. [[123](#bib.bib123)] used character sequences in financial transactions
    and the responses from the other side to detect if the transaction was fraud or
    not with [LSTM](#glo.main.lstm). Goumagias et al. [[124](#bib.bib124)] used deep
    Q-learning ([RL](#glo.main.rl)) to predict the risk-averse firms’ tax evasion
    behaviours. Finally, they provided suggestions for the states to maximize their
    tax revenues accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6: Fraud Detection Studies'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[114](#bib.bib114)] | Debit card transactions by a local Indonesia bank
    | 2016-2017 | Financial transaction amount on several time periods | [CNN](#glo.main.cnn),
    Stacked-[LSTM](#glo.main.lstm), [CNN](#glo.main.cnn)-[LSTM](#glo.main.lstm) |
    [AUROC](#glo.main.auroc) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[115](#bib.bib115)] | Credit card transactions from retail banking | 2017
    | Transaction variables and several derived features | [LSTM](#glo.main.lstm),
    [GRU](#glo.main.gru) | Accuracy | Keras |'
  prefs: []
  type: TYPE_TB
- en: '| [[116](#bib.bib116)] | Card purchases’ transactions | 2014-2015 | Probability
    of fraud per currency/origin country, other fraud related features | [ANN](#glo.main.ann)
    | [AUROC](#glo.main.auroc) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[117](#bib.bib117)] | Transactions made with credit cards by European cardholders
    | 2013 | Personal financial variables to [PCA](#glo.main.pca) | [ANN](#glo.main.ann),
    [RF](#glo.main.rf) | Recall, Precision, Accuracy | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[118](#bib.bib118)] | Credit-card transactions | 2015 | Transaction and
    bank features | [LSTM](#glo.main.lstm) | [AUROC](#glo.main.auroc) | Keras, Scikit-learn
    |'
  prefs: []
  type: TYPE_TB
- en: '| [[119](#bib.bib119)] | Databases of foreign trade of the Secretariat of Federal
    Revenue of Brazil | 2014 | 8 Features: Foreign Trade, Tax, Transactions, Employees,
    Invoices, etc | [AE](#glo.main.ae) | [MSE](#glo.main.mse) | H2O, R |'
  prefs: []
  type: TYPE_TB
- en: '| [[120](#bib.bib120)] | Chamber of Deputies open data, Companies data from
    Secretariat of Federal Revenue of Brazil | 2009-2017 | 21 features: Brazilian
    State expense, party name, Type of expense, etc. | Deep Autoencoders | [MSE](#glo.main.mse),
    [RMSE](#glo.main.rmse) | H2O, R |'
  prefs: []
  type: TYPE_TB
- en: '| [[121](#bib.bib121)] | Real-world data for automobile insurance company labeled
    as fradulent | - | Car, insurance and accident related features | [DNN](#glo.main.dnn)
    + [LDA](#glo.main.lda) | [TP](#glo.main.tp), [FP](#glo.main.fp), Accuracy, Precision,
    F1-score | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[122](#bib.bib122)] | Transactions from a giant online payment platform
    | 2006 | Personal financial variables | [GBDT](#glo.main.gbdt) +[DNN](#glo.main.dnn)
    | [AUROC](#glo.main.auroc) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[123](#bib.bib123)] | Financial transactions | - | Transaction data | [LSTM](#glo.main.lstm)
    | t-SNE | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[124](#bib.bib124)] | Empirical data from Greek firms | - | - | [DQL](#glo.main.dql)
    | Revenue | Torch |'
  prefs: []
  type: TYPE_TB
- en: 4.4 Portfolio Management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Portfolio Management is the process of choosing various assets within the portfolio
    for a predetermined period. As seen in other financial applications, slightly
    different versions of this problem exist, even though the underlying motivation
    is the same. In general, Portfolio Management covers the following closely related
    areas: Portfolio Optimization, Portfolio Selection, Portfolio Allocation. Sometimes,
    these terms are used interchangeably. Li et al. [[125](#bib.bib125)] reviewed
    the online portfolio selection studies using various rule-based or [ML](#glo.main.ml)
    models.'
  prefs: []
  type: TYPE_NORMAL
- en: Portfolio Management is actually an optimization problem, identifying the best
    possible course-of-action for selecting the best-performing assets for a given
    period. As a result, there are a lot of [EA](#glo.main.ea) models that were developed
    for this purpose. Metaxiotis et al. [[126](#bib.bib126)] surveyed the [MOEAs](#glo.main.moea)
    implemented solely on the portfolio optimization problem.
  prefs: []
  type: TYPE_NORMAL
- en: However, some [DL](#glo.main.dl) researchers managed to configure it as a learning
    model and obtained superior performances. Since Robo-advisory for portfolio management
    is on the rise, these [DL](#glo.main.dl) implementations have the potential to
    have a far greater impact on the financial industry in the near future. Table LABEL:table:portfolio_management
    presents the portfolio management [DL](#glo.main.dl) models and summarizes their
    achievements.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of stock selection implementations. Takeuchi et al. [[127](#bib.bib127)]
    classified the stocks in two classes, low momentum and high momentum depending
    on their expected return. They used a deep [RBM](#glo.main.rbm) encoder-classifier
    network and achieved high returns. Similarly, in [[128](#bib.bib128)], stocks
    were evaluated against their benchmark index to classify if they would outperform
    or underperform using [DMLP](#glo.main.dmlp), then based on the predictions, adjusted
    the portfolio allocation weights for the stocks for enhanced indexing. In [[129](#bib.bib129)],
    an [ML](#glo.main.ml) framework including [DMLP](#glo.main.dmlp) was constructed
    and the stock selection problem was implemented.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7: Portfolio Management Studies'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[66](#bib.bib66)] | Cryptocurrencies, Bitcoin | 2014-2017 | Price data |
    [CNN](#glo.main.cnn), [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm) | Accumulative
    portfolio value, [MDD](#glo.main.mdd), [SR](#glo.main.sr) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[127](#bib.bib127)] | Stocks from [NYSE](#glo.main.nyse), [AMEX](#glo.main.amex),
    [NASDAQ](#glo.main.nasdaq) | 1965-2009 | Price data | Autoencoder + [RBM](#glo.main.rbm)
    | Accuracy, confusion matrix | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[128](#bib.bib128)] | 20 stocks from [S&P500](#glo.main.sp500) | 2012-2015
    | Technical indicators | [MLP](#glo.main.mlp) | Accuracy | Python, Scikit Learn,
    Keras, Theano |'
  prefs: []
  type: TYPE_TB
- en: '| [[129](#bib.bib129)] | Chinese stock data | 2012-2013 | Technical, fundamental
    data | Logistic Regression, [RF](#glo.main.rf), [DNN](#glo.main.dnn) | [AUC](#glo.main.auc),
    accuracy, precision, recall, f1, tpr, fpr | Keras, Tensorflow, Python, Scikit
    learn |'
  prefs: []
  type: TYPE_TB
- en: '| [[130](#bib.bib130)] | Top 5 companies in [S&P500](#glo.main.sp500) | - |
    Price data and Financial ratios | [LSTM](#glo.main.lstm), Auto-encoding, Smart
    indexing | [CAGR](#glo.main.cagr) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[131](#bib.bib131)] | [IBB](#glo.main.ibb) biotechnology index, stocks |
    2012-2016 | Price data | Auto-encoding, Calibrating, Validating, Verifying | Returns
    | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[132](#bib.bib132)] | Taiwans stock market | - | Price data | Elman [RNN](#glo.main.rnn)
    | [MSE](#glo.main.mse), return | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[133](#bib.bib133)] | FOREX (EUR/USD, etc), Gold | 2013 | Price data | Evolino
    [RNN](#glo.main.rnn) | Return | Python |'
  prefs: []
  type: TYPE_TB
- en: '| [[134](#bib.bib134)] | Stocks in [NYSE](#glo.main.nyse), [AMEX](#glo.main.amex),
    [NASDAQ](#glo.main.nasdaq), [TAQ](#glo.main.taq) intraday trade | 1993-2017 |
    Price, 15 firm characteristics | [LSTM](#glo.main.lstm) +[MLP](#glo.main.mlp)
    | Monthly return, [SR](#glo.main.sr) | Python,Keras, Tensorflow in AWS |'
  prefs: []
  type: TYPE_TB
- en: '| [[135](#bib.bib135)] | [S&P500](#glo.main.sp500) | 1985-2006 | monthly and
    daily log-returns | [DBN](#glo.main.dbn) +[MLP](#glo.main.mlp) | Validation, Test
    Error | Theano, Python, Matlab |'
  prefs: []
  type: TYPE_TB
- en: '| [[136](#bib.bib136)] | 10 stocks in [S&P500](#glo.main.sp500) | 1997-2016
    | [OCHLV](#glo.main.ochlv), Price data | [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm),
    [GRU](#glo.main.gru) | Accuracy, Monthly return | Keras, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[137](#bib.bib137)] | Analyst reports on the [TSE](#glo.main.tse) and Osaka
    Exchange | 2016-2018 | Text | [LSTM](#glo.main.lstm), [CNN](#glo.main.cnn), [Bi-LSTM](#glo.main.bi-lstm)
    | Accuracy, [R²](#glo.main.r-sq) | R, Python, MeCab |'
  prefs: []
  type: TYPE_TB
- en: '| [[138](#bib.bib138)] | Stocks from Chinese/American stock market | 2015-2018
    | [OCHLV](#glo.main.ochlv), Fundamental data | [DDPG](#glo.main.ddpg), [PPO](#glo.main.ppo)
    | [SR](#glo.main.sr), [MDD](#glo.main.mdd) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[139](#bib.bib139)] | Hedge fund monthly return data | 1996-2015 | Return,
    [SR](#glo.main.sr), [STD](#glo.main.std), Skewness, Kurtosis, Omega ratio, Fund
    alpha | [DNN](#glo.main.dnn) | Sharpe ratio, Annual return, Cum. return | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[140](#bib.bib140)] | 12 most-volumed cryptocurrency | 2015-2016 | Price
    data | [CNN](#glo.main.cnn) + [RL](#glo.main.rl) | [SR](#glo.main.sr), portfolio
    value, [MDD](#glo.main.mdd) | - |'
  prefs: []
  type: TYPE_TB
- en: Portfolio selection and smart indexing were the main focuses of [[130](#bib.bib130)]
    and [[131](#bib.bib131)] using [AE](#glo.main.ae) and [LSTM](#glo.main.lstm) networks.
    Lin et al. [[132](#bib.bib132)] used the Elman network for optimal portfolio selection
    by predicting the stock returns for t+1 and then constructing the optimum portfolio
    according to the returns. Meanwhile, Maknickiene et al. [[141](#bib.bib141)] used
    Evolino [RNN](#glo.main.rnn) for portfolio selection and return prediction accordingly.
    The selected portfolio components (stocks) were orthogonal in nature.
  prefs: []
  type: TYPE_NORMAL
- en: In [[134](#bib.bib134)], through predicting the next month’s return, top to
    be performed portfolios were constructed and good monthly returns were achieved
    with [LSTM](#glo.main.lstm) and [LSTM](#glo.main.lstm)-[MLP](#glo.main.mlp) combined
    [DL](#glo.main.dl) models. Similarly, Batres et al. [[135](#bib.bib135)] combined
    [DBN](#glo.main.dbn) and [MLP](#glo.main.mlp) for constructing a stock portfolio
    by predicting each stock’s monthly log-return and choosing the only stocks that
    were expected to perform better than the performance of the median stock. Lee
    et al. [[136](#bib.bib136)] compared 3 [RNN](#glo.main.rnn) models (S-[RNN](#glo.main.rnn),
    [LSTM](#glo.main.lstm), [GRU](#glo.main.gru)) for stock price prediction and then
    constructed a threshold-based portfolio with selecting the stocks according to
    the predictions. With a different approach, Iwasaki et al. [[137](#bib.bib137)]
    used the analyst reports for sentiment analyses through text mining and word embeddings
    and used the sentiment features as inputs to [Deep Feedforward Neural Network
    (DFNN)](#glo.main.dfnn) model for the stock price prediction. Then different portfolio
    selections were implemented based on the projected stock returns.
  prefs: []
  type: TYPE_NORMAL
- en: '[DRL](#glo.main.drl) was selected as the main [DL](#glo.main.dl) model for
    [[138](#bib.bib138)]. Liang et al. [[138](#bib.bib138)] used [DRL](#glo.main.drl)
    for portfolio allocation by adjusting the stocks weights using various [RL](#glo.main.rl)
    models. Chen et al. [[139](#bib.bib139)] compared different [ML](#glo.main.ml)
    models (including [DFFN](#glo.main.dffn)) for hedge fund return prediction and
    hedge fund selection. [DL](#glo.main.dl) and [RF](#glo.main.rf) models had the
    best performance.'
  prefs: []
  type: TYPE_NORMAL
- en: Cryptocurrency portfolio management also started getting attention from [DL](#glo.main.dl)
    researchers. In [[140](#bib.bib140)], portfolio management (allocation and adjustment
    of weights) was implemented by [CNN](#glo.main.cnn) and [DRL](#glo.main.drl) on
    selected cryptocurrencies. Similarly, Jiang et al. [[66](#bib.bib66)] implemented
    cryptocurrency portfolio management (allocation) based on 3 different proposed
    models, namely [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm) and [CNN](#glo.main.cnn).
  prefs: []
  type: TYPE_NORMAL
- en: 4.5 Asset Pricing and Derivatives Market (options, futures, forward contracts)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Accurate pricing or valuation of an asset is a fundamental study area in finance.
    There are a vast number of [ML](#glo.main.ml) models developed for banks, corporates,
    real estate, derivative products, etc. However, [DL](#glo.main.dl) has not been
    applied to this particular field and there are some possible implementation areas
    that [DL](#glo.main.dl) models can assist the asset pricing researchers or valuation
    experts. There were only a handful of studies that we were able to pinpoint within
    the [DL](#glo.main.dl) and finance community. There are vast opportunities in
    this field for future studies and publications.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, financial models based on derivative products is quite common. Options
    pricing, hedging strategy development, financial engineering with options, futures,
    forward contracts are among some of the studies that can benefit from developing
    [DL](#glo.main.dl) models. Some recent studies indicate that researchers started
    showing interest in [DL](#glo.main.dl) models that can provide solutions to this
    complex and challenging field. Table LABEL:table:derivatives_market summarizes
    these studies with their intended purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 8: Asset Pricing and Derivatives Market Studies'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Der.Type | Data Set | Period | Feature Set | Method | Performance
    Criteria | Env. |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[137](#bib.bib137)] | Stock exchange | Analyst reports on the [TSE](#glo.main.tse)
    and Osaka Exchange | 2016-2018 | Text | [LSTM](#glo.main.lstm), [CNN](#glo.main.cnn),
    [Bi-LSTM](#glo.main.bi-lstm) | Accuracy, [R²](#glo.main.r-sq) | R, Python, MeCab
    |'
  prefs: []
  type: TYPE_TB
- en: '| [[142](#bib.bib142)] | Options | Simulated a range of call option prices
    | - | Price data, option strike/maturity, dividend/risk free rates, volatility
    | [DNN](#glo.main.dnn) | [RMSE](#glo.main.rmse), the average percentage pricing
    error | Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[143](#bib.bib143)] | Futures, Options | [TAIEX](#glo.main.taiex) Options
    | 2017 | [OCHLV](#glo.main.ochlv), fundamental analysis, option price | [MLP](#glo.main.mlp),
    [MLP](#glo.main.mlp) with Black scholes | [RMSE](#glo.main.rmse), [MAE](#glo.main.mae),
    [MAPE](#glo.main.mape) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[144](#bib.bib144)] | Equity returns | Returns in [NYSE](#glo.main.nyse),
    [AMEX](#glo.main.amex), [NASDAQ](#glo.main.nasdaq) | 1975-2017 | 57 firm characteristics
    | Fama-French n-factor model [DL](#glo.main.dl) | [R²](#glo.main.r-sq),[RMSE](#glo.main.rmse)
    | Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: Iwasaki et al. [[137](#bib.bib137)] used a [DFNN](#glo.main.dfnn) model and
    the analyst reports for sentiment analyses to predict the stock prices. Different
    portfolio selection approaches were implemented after the prediction of the stock
    prices. Culkin et al. [[142](#bib.bib142)] proposed a novel method that used feedforward
    [DNN](#glo.main.dnn) model to predict option prices by comparing their results
    with Black & Scholes option pricing formula. Similarly, Hsu et al. [[143](#bib.bib143)]
    proposed a novel method that predicted TAIEX option prices using bid-ask spreads
    and Black & Scholes option price model parameters with 3-layer [DMLP](#glo.main.dmlp).
    In [[144](#bib.bib144)], characteristic features such as Asset growth, Industry
    momentum, Market equity, Market Beta, etc. were used as inputs to a Fama-French
    n-factor model [DL](#glo.main.dl) to predict US equity returns in [National Association
    of Securities Dealers Automated Quotations (NASDAQ)](#glo.main.nasdaq), [American
    Stock Exchange (AMEX)](#glo.main.amex), [New York Stock Exchange (NYSE)](#glo.main.nyse)
    indices.
  prefs: []
  type: TYPE_NORMAL
- en: 4.6 Cryptocurrency and Blockchain Studies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the last few years, cryptocurrencies have been the talk of the town due to
    their incredible price gain and loss within short periods. Even though price forecasting
    dominates the area of interest, some other studies also exist, such as cryptocurrency
    Algo-trading models.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, Blockchain is a new technology that provides a distributed decentralized
    ledger system that fits well with the cryptocurrency world. As a matter of fact,
    cryptocurrency and blockchain are highly coupled, even though blockchain technology
    has a much wider span for various implementation possibilities that need to be
    studied. It is still in its early development phase, hence there is a lot of hype
    in its potentials.
  prefs: []
  type: TYPE_NORMAL
- en: Some [DL](#glo.main.dl) models have already appeared about cryptocurrency studies,
    mostly price prediction or trading systems. However, still there is a lack of
    studies for blockchain research within the [DL](#glo.main.dl) community. Given
    the attention that the underlying technology has attracted, there is a great chance
    that some new studies will start appearing in the near future. Table LABEL:table:cryptocurrency_and_blockchain
    tabulates the studies for the cryptocurrency and blockchain research.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 9: Cryptocurrency and Blockchain Studies'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[48](#bib.bib48)] | Bitcoin, Dash, Ripple, Monero, Litecoin, Dogecoin, Nxt,
    Namecoin | 2014-2017 | [MA](#glo.main.ma), [BOLL](#glo.main.boll), the [CRIX](#glo.main.crix)
    daily returns, Euribor interest rates, [OCHLV](#glo.main.ochlv) of EURO/UK, EURO/USD,
    US/JPY | [LSTM](#glo.main.lstm), [RNN](#glo.main.rnn), [MLP](#glo.main.mlp) |
    Accuracy, F1-measure | Python, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[66](#bib.bib66)] | Cryptocurrencies, Bitcoin | 2014-2017 | Price data |
    [CNN](#glo.main.cnn) | Accumulative portfolio value, [MDD](#glo.main.mdd), [SR](#glo.main.sr)
    | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[140](#bib.bib140)] | 12 most-volumed cryptocurrency | 2015-2016 | Price
    data | [CNN](#glo.main.cnn) + [RL](#glo.main.rl) | [SR](#glo.main.sr), portfolio
    value, [MDD](#glo.main.mdd) |  |'
  prefs: []
  type: TYPE_TB
- en: '| [[145](#bib.bib145)] | Bitcoin data | 2010-2017 | Hash value, bitcoin address,
    public/private key, digital signature, etc. | Takagi–Sugeno Fuzzy cognitive maps
    | Analytical hierarchy process | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[146](#bib.bib146)] | Bitcoin data | 2012, 2013, 2016 | TransactionId, input/output
    Addresses, timestamp | Graph embedding using heuristic, laplacian eigen-map, deep
    [AE](#glo.main.ae) | F1-score | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[147](#bib.bib147)] | Bitcoin, Litecoin, StockTwits | 2015-2018 | [OCHLV](#glo.main.ochlv),
    technical indicators, sentiment analysis | [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm),
    State Frequency Model | [MSE](#glo.main.mse) | Keras, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[148](#bib.bib148)] | Bitcoin | 2013-2016 | Price data | Bayesian optimized
    [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm) | Sensitivity, specificity, precision,
    accuracy, [RMSE](#glo.main.rmse) | Keras, Python, Hyperas |'
  prefs: []
  type: TYPE_TB
- en: 'Chen et al. [[145](#bib.bib145)] proposed a blockchain transaction traceability
    algorithm using Takagi-Sugeno fuzzy cognitive map and 3-layer [DMLP](#glo.main.dmlp).
    Bitcoin data (Hash value, bitcoin address, public/private key, digital signature,
    etc.) was used as the dataset. Nan et al. [[146](#bib.bib146)] proposed a method
    for bitcoin mixing detection that consisted of different stages: Constructing
    the Bitcoin transaction graph, implementing node embedding, detecting outliers
    through [AE](#glo.main.ae). Lopes et al. [[147](#bib.bib147)] combined the opinion
    market and price prediction for cryptocurrency trading. Text mining combined with
    2 models, [CNN](#glo.main.cnn) and [LSTM](#glo.main.lstm) were used to extract
    the opinion. Bitcoin, Litecoin, StockTwits were used as the dataset. [Open,Close,High,
    Low, Volume (OCHLV)](#glo.main.ochlv) of prices, technical indicators, and sentiment
    analysis were used as the feature set.'
  prefs: []
  type: TYPE_NORMAL
- en: In another study, Jiang et al. [[66](#bib.bib66)] presented a financial-model-free
    [RL](#glo.main.rl) framework for the Cryptocurrency portfolio management that
    was based on 3 different proposed models, basic [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm)
    and [CNN](#glo.main.cnn). In [[140](#bib.bib140)], portfolio management was implemented
    by [CNN](#glo.main.cnn) and [DRL](#glo.main.drl) on 12 most-volumed cryptocurrencies.
    Bitcoin, Ethereum, Bitcoin Cash and Digital Cash were used as the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, Spilak et al. [[48](#bib.bib48)] used 8 cryptocurrencies (Bitcoin,
    Dash, Ripple, Monero, Litecoin, Dogecoin, Nxt, Namecoin) to construct a dynamic
    portfolio using [LSTM](#glo.main.lstm), [RNN](#glo.main.rnn), [MLP](#glo.main.mlp)
    methods. McNally et al. [[148](#bib.bib148)] compared Bayesian optimized [RNN](#glo.main.rnn),
    [LSTM](#glo.main.lstm) and [Autoregressive Integrated Moving Average (ARIMA)](#glo.main.arima)
    to predict the bitcoin price direction. Sensitivity, specificity, precision, accuracy,
    [Root Mean Square Error (RMSE)](#glo.main.rmse) were used as the performance metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 4.7 Financial Sentiment Analysis and Behavioral Finance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the most important components of behavioral finance is emotion or investor
    sentiment. Lately, advancements in text mining techniques opened up the possibilities
    for successful sentiment extraction through social media feeds. There is a growing
    interest in Financial Sentiment Analysis, especially for trend forecasting and
    Algo-trading model development. Kearney et al. [[149](#bib.bib149)] surveyed [ML](#glo.main.ml)-based
    financial sentiment analysis studies that use textual data.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays there is broad interest in the sentiment analysis for financial forecasting
    research using [DL](#glo.main.dl) models. Table LABEL:table:financial_sentiment_analysis
    provides information about the sentiment analysis studies that are focused on
    financial forecasting and based on text mining.
  prefs: []
  type: TYPE_NORMAL
- en: In [[150](#bib.bib150)], technical analysis ([MACD](#glo.main.macd), [Moving
    Average (MA)](#glo.main.ma), [Directional Movement Index (DMI)](#glo.main.dmi),
    [Exponential Moving Average (EMA)](#glo.main.ema), [Triple Exponential Moving
    Average (TEMA)](#glo.main.tema), Momentum, [RSI](#glo.main.rsi), [Commodity Channel
    Index (CCI)](#glo.main.cci), Stochastic Oscillator, [Price of Change (ROC)](#glo.main.roc))
    and sentiment analysis (using social media) were used to predict the price of
    stocks. Shi et al. [[151](#bib.bib151)] proposed a method that visually interpreted
    text-based [DL](#glo.main.dl) models in predicting the stock price movements.
    They used the financial news from Reuters and Bloomberg. In [[152](#bib.bib152)],
    text mining and word embeddings were used to extract information from the financial
    news from Reuters and Bloomberg to predict the stock price movements. In addition,
    in [[153](#bib.bib153)], the prices of index data and emotional data from text
    posts were used to predict the stock opening price of the next day. Zhongshengz
    [[154](#bib.bib154)] performed classification and stock price prediction using
    text and price data. Das et al. [[155](#bib.bib155)] used Twitter sentiment data
    and stock price data to predict the prices of Google, Microsoft and Apple stocks.
  prefs: []
  type: TYPE_NORMAL
- en: Prosky et al. [[156](#bib.bib156)] performed sentiment, mood prediction using
    news from Reuters and used these sentiments for price prediction. Li et al. [[157](#bib.bib157)]
    used sentiment classification (neutral, positive, negative) for the stock open
    or close price prediction with [LSTM](#glo.main.lstm) (various models). They compared
    their results with [SVM](#glo.main.svm) and achieved higher overall performance.
    Iwasaki et al. [[137](#bib.bib137)] used analyst reports for sentiment analysis
    through text mining and word embeddings. They used the sentiment features as inputs
    to [DFNN](#glo.main.dfnn) model for stock price prediction. Finally, different
    portfolio selections were implemented based on the projected stock returns.
  prefs: []
  type: TYPE_NORMAL
- en: In a different study, Huang et al. [[158](#bib.bib158)] used several models
    including [Hidden Markov Model (HMM)](#glo.main.hmm), [DMLP](#glo.main.dmlp) and
    [CNN](#glo.main.cnn) using Twitter moods along with the financial price data for
    prediction of the next day’s move (up or down). [CNN](#glo.main.cnn) achieved
    the best result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 10: Financial Sentiment Studies coupled with Text Mining for Forecasting'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[137](#bib.bib137)] | Analyst reports on the [TSE](#glo.main.tse) and Osaka
    Exchange | 2016-2018 | Text | [LSTM](#glo.main.lstm), [CNN](#glo.main.cnn), [Bi-LSTM](#glo.main.bi-lstm)
    | Accuracy, [R²](#glo.main.r-sq) | R, Python, MeCab |'
  prefs: []
  type: TYPE_TB
- en: '| [[150](#bib.bib150)] | Sina Weibo, Stock market records | 2012-2015 | Technical
    indicators, sentences | [DRSE](#glo.main.drse) | F1-score, precision, recall,
    accuracy, [AUROC](#glo.main.auroc) | Python |'
  prefs: []
  type: TYPE_TB
- en: '| [[151](#bib.bib151)] | News from Reuters and Bloomberg for [S&P500](#glo.main.sp500)
    stocks | 2006-2015 | Financial news, price data | DeepClue | Accuracy | Dynet
    software |'
  prefs: []
  type: TYPE_TB
- en: '| [[152](#bib.bib152)] | News from Reuters and Bloomberg, Historical stock
    security data | 2006-2013 | News, price data | [DNN](#glo.main.dnn) | Accuracy
    | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[153](#bib.bib153)] | [SCI](#glo.main.sci) prices | 2008-2015 | [OCHL](#glo.main.ochl)
    of change rate, price | Emotional Analysis + [LSTM](#glo.main.lstm) | [MSE](#glo.main.mse)
    | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[154](#bib.bib154)] | [SCI](#glo.main.sci) prices | 2013-2016 | Text data
    and Price data | [LSTM](#glo.main.lstm) | Accuracy, F1-Measure | Python, Keras
    |'
  prefs: []
  type: TYPE_TB
- en: '| [[155](#bib.bib155)] | Stocks of Google, Microsoft and Apple | 2016-2017
    | Twitter sentiment and stock prices | [RNN](#glo.main.rnn) | - | Spark, Flume,Twitter
    API, |'
  prefs: []
  type: TYPE_TB
- en: '| [[156](#bib.bib156)] | 30 [DJIA](#glo.main.djia) stocks, [S&P500](#glo.main.sp500),
    [DJI](#glo.main.dji), news from Reuters | 2002-2016 | Price data and features
    from news articles | [LSTM](#glo.main.lstm), [NN](#glo.main.nn), [CNN](#glo.main.cnn)
    and word2vec | Accuracy | VADER |'
  prefs: []
  type: TYPE_TB
- en: '| [[157](#bib.bib157)] | Stocks of [CSI](#glo.main.csi) 300 index, [OCHLV](#glo.main.ochlv)
    of [CSI](#glo.main.csi) 300 index | 2009-2014 | Sentiment Posts, Price data |
    Naive Bayes + [LSTM](#glo.main.lstm) | Precision, Recall, F1-score, Accuracy |
    Python, Keras |'
  prefs: []
  type: TYPE_TB
- en: '| [[158](#bib.bib158)] | [S&P500](#glo.main.sp500), [NYSE](#glo.main.nyse)
    Composite, [DJIA](#glo.main.djia), [NASDAQ](#glo.main.nasdaq) Composite | 2009-2011
    | Twitter moods, index data | [DNN](#glo.main.dnn), [CNN](#glo.main.cnn) | Error
    rate | Keras, Theano |'
  prefs: []
  type: TYPE_TB
- en: Even though financial sentiment is highly coupled with text mining, we decided
    to represent those two topics in different subsections. The main reason for such
    a choice is not only the existence of some financial sentiment studies which do
    not directly depend on financial textual data (like [[158](#bib.bib158)]) but
    also the existence of some financial text mining studies that are not automatically
    used for sentiment analysis which will be covered in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 4.8 Financial Text Mining
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the rapid spreading of social media and real-time streaming news/tweets,
    instant text-based information retrieval became available for financial model
    development. As a result, financial text mining studies became very popular in
    recent years. Even though some of these studies are directly interested in the
    sentiment analysis through crowdsourcing, there are a lot of implementations that
    are interested in the content retrieval of news, financial statements, disclosures,
    etc. through analyzing the text context. There are a few [ML](#glo.main.ml) surveys
    focused on text mining and news analytics. Among the noteworthy studies of such,
    Mitra et al. [[159](#bib.bib159)] edited a book on news analytics in finance,
    whereas Li et al. [[160](#bib.bib160)], Loughran et al. [[161](#bib.bib161)],
    Kumar et al. [[162](#bib.bib162)] surveyed the studies of textual analysis of
    financial documents, news and corporate disclosures. It is worth to mention that
    there are also some studies [[163](#bib.bib163), [164](#bib.bib164)] of text mining
    for financial prediction models.
  prefs: []
  type: TYPE_NORMAL
- en: Previous section was focused on [DL](#glo.main.dl) models using sentiment analysis
    specifically tailored for the financial forecasting implementations, whereas this
    section will include [DL](#glo.main.dl) studies that have text Mining without
    Sentiment Analysis for Forecasting (Table LABEL:table:financial_text_mining_1),
    financial sentiment analysis coupled with text mining without forecasting intent
    (Table LABEL:table:financial_text_mining_2) and finally other text mining implementations
    (Table LABEL:table:financial_text_mining_3), respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Huynh et al. [[165](#bib.bib165)] used the financial news from Reuters, Bloomberg
    and stock prices data to predict the stock movements in the future. In [[166](#bib.bib166)],
    different event-types on Chinese companies are classified based on a novel event-type
    pattern classification algorithm. Besides, the stock prices were predicted using
    additional inputs. Kraus et al. [[167](#bib.bib167)] implemented [LSTM](#glo.main.lstm)
    with transfer learning using text mining through financial news and stock market
    data. Dang et al. [[168](#bib.bib168)] used Stock2Vec and [Two-stream GRU (TGRU)](#glo.main.tgru)
    models to generate the input data from the financial news and stock prices for
    the classification of stock prices.
  prefs: []
  type: TYPE_NORMAL
- en: In [[169](#bib.bib169)], events were detected from Reuters and Bloomberg news
    through text mining. The extracted information was used for price prediction and
    stock trading through the [CNN](#glo.main.cnn) model. Vargas et al. [[170](#bib.bib170)]
    used text mining and price prediction together for intraday directional movement
    estimation. Akita et al. [[171](#bib.bib171)] implemented a method that used text
    mining and price prediction together for forecasting prices. Verma et al. [[172](#bib.bib172)]
    combined news data with financial data to classify the stock price movement. Bari
    et al. [[69](#bib.bib69)] used text mining for extracting information from the
    tweets and news. In the method, time series models were used for stock trade signal
    generation. In [[173](#bib.bib173)], a method that performed information fusion
    from news and social media sources was proposed to predict the trend of the stocks.
  prefs: []
  type: TYPE_NORMAL
- en: In [[174](#bib.bib174)], social media news were used to predict the index price
    and the index direction with [RNN](#glo.main.rnn)-Boost through [Latent Dirichlet
    Allocation (LDA)](#glo.main.lda) features. Hu et al. [[175](#bib.bib175)] proposed
    a novel method that used text mining techniques and Hybrid Attention Networks
    based on the financial news for forecasting the trend of stocks. Li et al. [[176](#bib.bib176)]
    implemented intraday stock price direction classification using the financial
    news and stocks prices. In [[177](#bib.bib177)], financial news data and word
    embedding with Word2vec were implemented to create the inputs for [Recurrent CNN
    (RCNN)](#glo.main.rcnn) to predict the stock price.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 11: Text Mining Studies without Sentiment Analysis for Forecasting'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[69](#bib.bib69)] | Energy-Sector/ Company-Centric Tweets in [S&P500](#glo.main.sp500)
    | 2015-2016 | Text and Price data |  | Return, [SR](#glo.main.sr), precision,
    recall, accuracy | Python, Tweepy API |'
  prefs: []
  type: TYPE_TB
- en: '| [[165](#bib.bib165)] | News from Reuters, Bloomberg | 2006-2013 | Financial
    news, price data | [Bi-GRU](#glo.main.bi-gru) | Accuracy | Python, Keras |'
  prefs: []
  type: TYPE_TB
- en: '| [[166](#bib.bib166)] | News from Sina.com, ACE2005 Chinese corpus | 2012-2016
    | A set of news text | Their unique algorithm | Precision, Recall, F1-score |
    - |'
  prefs: []
  type: TYPE_TB
- en: '| [[167](#bib.bib167)] | [CDAX](#glo.main.cdax) stock market data | 2010-2013
    | Financial news, stock market data | [LSTM](#glo.main.lstm) | [MSE](#glo.main.mse),
    [RMSE](#glo.main.rmse), [MAE](#glo.main.mae), Accuracy, [AUC](#glo.main.auc) |
    TensorFlow, Theano, Python, Scikit-Learn |'
  prefs: []
  type: TYPE_TB
- en: '| [[168](#bib.bib168)] | Apple, Airbus, Amazon news from Reuters, Bloomberg,
    [S&P500](#glo.main.sp500) stock prices | 2006-2013 | Price data, news, technical
    indicators | [TGRU](#glo.main.tgru), stock2vec | Accuracy, precision, [AUROC](#glo.main.auroc)
    | Keras, Python |'
  prefs: []
  type: TYPE_TB
- en: '| [[169](#bib.bib169)] | [S&P500](#glo.main.sp500) Index, 15 stocks in [S&P500](#glo.main.sp500)
    | 2006-2013 | News from Reuters and Bloomberg | [CNN](#glo.main.cnn) | Accuracy,
    [MCC](#glo.main.mcc) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[170](#bib.bib170)] | [S&P500](#glo.main.sp500) index news from Reuters
    | 2006-2013 | Financial news titles, Technical indicators | SI-RCNN ([LSTM](#glo.main.lstm)
    + [CNN](#glo.main.cnn)) | Accuracy | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[171](#bib.bib171)] | 10 stocks in Nikkei 225 and news | 2001-2008 | Textual
    information and Stock prices | Paragraph Vector + [LSTM](#glo.main.lstm) | Profit
    | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[172](#bib.bib172)] | [NIFTY](#glo.main.nifty) 50 Index, [NIFTY](#glo.main.nifty)
    Bank/Auto/IT/Energy Index, News | 2013-2017 | Index data, news | [LSTM](#glo.main.lstm)
    | [MCC](#glo.main.mcc), Accuracy | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[173](#bib.bib173)] | Price data, index data, news, social media data |
    2015 | Price data, news from articles and social media | Coupled matrix and tensor
    | Accuracy, [MCC](#glo.main.mcc) | Jieba |'
  prefs: []
  type: TYPE_TB
- en: '| [[174](#bib.bib174)] | [HS](#glo.main.hs) 300 | 2015-2017 | Social media
    news, price data | [RNN](#glo.main.rnn)-Boost with [LDA](#glo.main.lda) | Accuracy,
    [MAE](#glo.main.mae), [MAPE](#glo.main.mape), [RMSE](#glo.main.rmse) | Python,
    Scikit-learn |'
  prefs: []
  type: TYPE_TB
- en: '| [[175](#bib.bib175)] | News and Chinese stock data | 2014-2017 | Selected
    words in a news | [HAN](#glo.main.han) | Accuracy, Annual return | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[176](#bib.bib176)] | News, stock prices from Hong Kong Stock Exchange |
    2001 | Price data and [TF-IDF](#glo.main.tfidf) from news | [ELM](#glo.main.elm),
    [DLR](#glo.main.dlr), [PCA](#glo.main.pca), [BELM](#glo.main.belm), [KELM](#glo.main.kelm),
    [NN](#glo.main.nn) | Accuracy | Matlab |'
  prefs: []
  type: TYPE_TB
- en: '| [[177](#bib.bib177)] | [TWSE](#glo.main.twse) index, 4 stocks in [TWSE](#glo.main.twse)
    | 2001-2017 | Technical indicators, Price data, News | [CNN](#glo.main.cnn) +
    [LSTM](#glo.main.lstm) | [RMSE](#glo.main.rmse), Profit | Keras, Python, [TALIB](#glo.main.talib)
    |'
  prefs: []
  type: TYPE_TB
- en: '| [[178](#bib.bib178)] | Stock of Tsugami Corporation | 2013 | Price data |
    [LSTM](#glo.main.lstm) | [RMSE](#glo.main.rmse) | Keras, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[179](#bib.bib179)] | News, Nikkei Stock Average and 10-Nikkei companies
    | 1999-2008 | news, [MACD](#glo.main.macd) | [RNN](#glo.main.rnn), [RBM](#glo.main.rbm)
    +[DBN](#glo.main.dbn) | Accuracy, P-value | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[180](#bib.bib180)] | ISMIS 2017 Data Mining Competition dataset | - | Expert
    identifier, classes | [LSTM](#glo.main.lstm) + [GRU](#glo.main.gru) + [FFNN](#glo.main.ffnn)
    | Accuracy | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[181](#bib.bib181)] | Reuters, Bloomberg News, [S&P500](#glo.main.sp500)
    price | 2006-2013 | News and sentences | [LSTM](#glo.main.lstm) | Accuracy | -
    |'
  prefs: []
  type: TYPE_TB
- en: '| [[182](#bib.bib182)] | APPL from [S&P500](#glo.main.sp500) and news from
    Reuters | 2011-2017 | Input news, [OCHLV](#glo.main.ochlv), Technical indicators
    | [CNN](#glo.main.cnn) + [LSTM](#glo.main.lstm), [CNN](#glo.main.cnn) +[SVM](#glo.main.svm)
    | Accuracy, F1-score | Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[183](#bib.bib183)] | Nikkei225, [S&P500](#glo.main.sp500), news from Reuters
    and Bloomberg | 2001-2013 | Stock price data and news | [DGM](#glo.main.dgm) |
    Accuracy, [MCC](#glo.main.mcc), %profit | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[184](#bib.bib184)] | Stocks from [S&P500](#glo.main.sp500) | 2006-2013
    | Text (news) and Price data | [LAR](#glo.main.lar) +News, [RF](#glo.main.rf)
    +News | [MAPE](#glo.main.mape), [RMSE](#glo.main.rmse) | - |'
  prefs: []
  type: TYPE_TB
- en: Minami et al. [[178](#bib.bib178)] proposed a method that predicted the stock
    price with corporate action event information and macro-economic index data using
    [LSTM](#glo.main.lstm). In [[179](#bib.bib179)], a novel method that used a combination
    of [RBM](#glo.main.rbm), [DBN](#glo.main.dbn) and word embeddings to create word
    vectors for [RNN](#glo.main.rnn)-[RBM](#glo.main.rbm)-[DBN](#glo.main.dbn) network
    was proposed to predict the stock prices. Buczkowski et al. [[180](#bib.bib180)]
    proposed a novel method that used expert recommendations, ensemble of [GRU](#glo.main.gru)
    and [LSTM](#glo.main.lstm) for prediction of the prices.
  prefs: []
  type: TYPE_NORMAL
- en: In [[181](#bib.bib181)] a novel method that used character-based neural language
    model using financial news and [LSTM](#glo.main.lstm) was proposed. Liu et al.
    [[182](#bib.bib182)] proposed a method that used word embeddings with word2Vec,
    technical analysis features and stock prices for price prediction. In [[183](#bib.bib183)],
    [Deep Neural Generative Model (DGM)](#glo.main.dgm) with news articles using Paragraph
    Vector algorithm was used for creation of the input vector to predict the stock
    prices. In [[184](#bib.bib184)], the stock price data and word embeddings were
    used for stock price prediction. The results showed that the extracted information
    from embedding news improves the performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 12: Financial Sentiment Studies coupled with Text Mining without Forecasting'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[95](#bib.bib95)] | 883 [BHC](#glo.main.bhc) from EDGAR | 2006-2017 | Tokens,
    weighted sentiment polarity, leverage and [ROA](#glo.main.roa) | [CNN](#glo.main.cnn),
    [LSTM](#glo.main.lstm), [SVM](#glo.main.svm), Random Forest | Accuracy, Precision,
    Recall, F1-score | Keras, Python, Scikit-learn |'
  prefs: []
  type: TYPE_TB
- en: '| [[185](#bib.bib185)] | SemEval-2017 dataset, financial text, news, stock
    market data | 2017 | Sentiments in Tweets, News headlines | Ensemble [SVR](#glo.main.svr),
    [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm), [GRU](#glo.main.gru) | Cosine similarity
    score, agreement score, class score | Python, Keras, Scikit Learn |'
  prefs: []
  type: TYPE_TB
- en: '| [[186](#bib.bib186)] | Financial news from Reuters | 2006-2015 | Word vector,
    Lexical and Contextual input | Targeted dependency tree [LSTM](#glo.main.lstm)
    | Cumulative abnormal return | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[187](#bib.bib187)] | Stock sentiment analysis from StockTwits | 2015 |
    StockTwits messages | [LSTM](#glo.main.lstm), Doc2Vec, [CNN](#glo.main.cnn) |
    Accuracy, precision, recall, f-measure, [AUC](#glo.main.auc) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[188](#bib.bib188)] | Sina Weibo, Stock market records | 2012-2015 | Technical
    indicators, sentences | [DRSE](#glo.main.drse) | F1-score, precision, recall,
    accuracy, [AUROC](#glo.main.auroc) | Python |'
  prefs: []
  type: TYPE_TB
- en: '| [[189](#bib.bib189)] | News from NowNews, AppleDaily, LTN, MoneyDJ for 18
    stocks | 2013-2014 | Text, Sentiment |  | Return | Python, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[190](#bib.bib190)] | StockTwits | 2008-2016 | Sentences, StockTwits messages
    | [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm), [GRU](#glo.main.gru) | [MCC](#glo.main.mcc),
    [WSURT](#glo.main.wsurt) | Keras, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[191](#bib.bib191)] | Financial statements of Japan companies | - | Sentences,
    text | [DNN](#glo.main.dnn) | Precision, recall, f-score | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[192](#bib.bib192)] | Twitter posts, news headlines | - | Sentences, text
    | [Deep-FASP](#glo.main.deep-fasp) | Accuracy, [MSE](#glo.main.mse), [R²](#glo.main.r-sq)
    | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[193](#bib.bib193)] | Forums data | 2004-2013 | Sentences and keywords |
    Recursive neural tensor networks | Precision, recall, f-measure | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[194](#bib.bib194)] | News from Financial Times related US stocks | - |
    Sentiment of news headlines | [SVR](#glo.main.svr), Bidirectional [LSTM](#glo.main.lstm)
    | Cosine similarity | Python, Scikit Learn, Keras, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: 'Akhtar et al. [[185](#bib.bib185)] compared [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm)
    and [GRU](#glo.main.gru) based [DL](#glo.main.dl) models against [MLP](#glo.main.mlp)
    for financial sentiment analysis. Rawte et al. [[95](#bib.bib95)] tried to solve
    three separate problems using [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm), [SVM](#glo.main.svm),
    [RF](#glo.main.rf): Bank risk classification, sentiment analysis and [Return on
    Assets (ROA)](#glo.main.roa) regression.'
  prefs: []
  type: TYPE_NORMAL
- en: Chang et al. [[186](#bib.bib186)] implemented the estimation of information
    content polarity (negative/positive effect) with text mining, word vector, lexical,
    contextual input and various [LSTM](#glo.main.lstm) models. They used the financial
    news from Reuters.
  prefs: []
  type: TYPE_NORMAL
- en: Jangid et al. [[187](#bib.bib187)] proposed a novel method that is a combination
    of [LSTM](#glo.main.lstm) and [CNN](#glo.main.cnn) for word embedding and sentiment
    analysis using [Bidirectional LSTM (Bi-LSTM)](#glo.main.bi-lstm) for aspect extraction.
    The proposed method used multichannel [CNN](#glo.main.cnn) for financial sentiment
    analysis. Shijia et al. [[188](#bib.bib188)] used an attention-based [LSTM](#glo.main.lstm)
    for the financial sentiment analysis using news headlines and microblog messages.
    Sohangir et al. [[189](#bib.bib189)] used [LSTM](#glo.main.lstm), doc2vec, [CNN](#glo.main.cnn)
    and stock market opinions posted in StockTwits for sentiment analysis. Mahmoudi
    et al. [[190](#bib.bib190)] extracted tweets from StockTwits to identify the user
    sentiment. In the evaluation approach, they also used emojis for the sentiment
    analysis. Kitamori et al. [[191](#bib.bib191)] extracted the sentiments from financial
    news and used [DNN](#glo.main.dnn) to classify positive and negative news.
  prefs: []
  type: TYPE_NORMAL
- en: In [[192](#bib.bib192)], the sentiment/aspect prediction was implemented using
    an ensemble of [LSTM](#glo.main.lstm), [CNN](#glo.main.cnn) and [GRU](#glo.main.gru)
    networks. In a different study, Li et al. [[193](#bib.bib193)] proposed a [DL](#glo.main.dl)
    based sentiment analysis method using [RNN](#glo.main.rnn) to identify the top
    sellers in the underground economy. Moore et al. [[194](#bib.bib194)] used text
    mining techniques for sentiment analysis from the financial news.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 13: Other Text Mining Studies'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[73](#bib.bib73)] | News from NowNews, AppleDaily, LTN, MoneyDJ for 18 stocks
    | 2013-2014 | Text, Sentiment |  | Return | Python, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: '| [[96](#bib.bib96)] | The event data set for large European banks, news articles
    from Reuters | 2007-2014 | Word, sentence | [DNN](#glo.main.dnn) +[NLP](#glo.main.nlp)
    preprocess | Relative usefulness, F1-score | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[97](#bib.bib97)] | Event dataset on European banks, news from Reuters |
    2007-2014 | Text, sentence | Sentence vector + [DFFN](#glo.main.dffn) | Usefulness,
    F1-score, [AUROC](#glo.main.auroc) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[98](#bib.bib98)] | News from Reuters, fundamental data | 2007-2014 | Financial
    ratios and news text | doc2vec + [NN](#glo.main.nn) | Relative usefulness | Doc2vec
    |'
  prefs: []
  type: TYPE_TB
- en: '| [[121](#bib.bib121)] | Real-world data for automobile insurance company labeled
    as fradulent | - | Car, insurance and accident related features | [DNN](#glo.main.dnn)
    + [LDA](#glo.main.lda) | [TP](#glo.main.tp), [FP](#glo.main.fp), Accuracy, Precision,
    F1-score | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[123](#bib.bib123)] | Financial transactions | - | Transaction data | [LSTM](#glo.main.lstm)
    | t-SNE | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[195](#bib.bib195)] | Taiwan’s National Pension Insurance | 2008-2014 |
    Insured’s id, area-code, gender, etc. | [RNN](#glo.main.rnn) | Accuracy, total
    error | Python |'
  prefs: []
  type: TYPE_TB
- en: '| [[196](#bib.bib196)] | StockTwits | 2015-2016 | Sentences, StockTwits messages
    | Doc2vec, [CNN](#glo.main.cnn) | Accuracy, precision, recall, f-measure, [AUC](#glo.main.auc)
    | Python, Tensorflow |'
  prefs: []
  type: TYPE_TB
- en: In [[195](#bib.bib195)], individual social security payment types (paid, unpaid,
    repaid, transferred) were classified and predicted using [LSTM](#glo.main.lstm),
    [HMM](#glo.main.hmm) and [SVM](#glo.main.svm). Sohangir et al. [[196](#bib.bib196)]
    used two neural network models (doc2Vec, [CNN](#glo.main.cnn)) to find the top
    authors in StockTwits messages and to classify the authors as expert or non-expert
    for author classification purposes.
  prefs: []
  type: TYPE_NORMAL
- en: In [[123](#bib.bib123)], the character sequences in financial transactions and
    the responses from the other side was used to detect if the transaction was fraud
    or not with [LSTM](#glo.main.lstm). Wang et al. [[121](#bib.bib121)] used text
    mining and [DNN](#glo.main.dnn) models to detect automobile insurance fraud.
  prefs: []
  type: TYPE_NORMAL
- en: In [[96](#bib.bib96)], the news semantics were extracted by the word sequence
    learning, bank stress was determined and classified with the associated events.
    Day et al. [[73](#bib.bib73)] used financial sentiment analysis using text mining
    and [DNN](#glo.main.dnn) for stock algorithmic trading.
  prefs: []
  type: TYPE_NORMAL
- en: Cerchiello et al. [[98](#bib.bib98)] used the fundamental data and text mining
    from the financial news (Reuters) to classify the bank distress. In [[97](#bib.bib97)],
    the bank distress was identified by extracting the data from the financial news
    through text mining. The proposed method used [DFNN](#glo.main.dfnn) on semantic
    sentence vectors to classify if there was an event or not.
  prefs: []
  type: TYPE_NORMAL
- en: 4.9 Theoretical or Conceptual Studies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There were a number of research papers that were either focused on the theoretical
    concepts of finance or the conceptual designs without model implementation phases;
    however they still provided valuable information, so we decided to include them
    in our survey. In Table LABEL:table:theory_or_conceptual_study, these studies
    were tabulated according to their topic of interest.
  prefs: []
  type: TYPE_NORMAL
- en: In [[197](#bib.bib197)], the connection between deep [AEs](#glo.main.ae) and
    [Singular Value Decomposition (SVD)](#glo.main.svd) were discussed and compared
    using stocks from [iShares Nasdaq Biotechnology ETF (IBB)](#glo.main.ibb) index
    and the stock of Amgen Inc. Bouchti et al. [[198](#bib.bib198)] explained the
    details of [DRL](#glo.main.drl) and mentioned that [DRL](#glo.main.drl) could
    be used for fraud detection/risk management in banking.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 14: Other - Theoretical or Conceptual Studies'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | SubTopic | IsTimeSeries? | Data Set | Period | Feature Set | Method
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[197](#bib.bib197)] | Analysis of [AE](#glo.main.ae), [SVD](#glo.main.svd)
    | Yes | Selected stocks from the [IBB](#glo.main.ibb) index and stock of Amgen
    Inc. | 2012-2014 | Price data | [AE](#glo.main.ae), [SVD](#glo.main.svd) |'
  prefs: []
  type: TYPE_TB
- en: '| [[198](#bib.bib198)] | Fraud Detection in Banking | No | Risk Management
    / Fraud Detection | - | - | [DRL](#glo.main.drl) |'
  prefs: []
  type: TYPE_TB
- en: 4.10 Other Financial Applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, there were some research papers which did not fit into any of the previously
    covered topics. Their data set and intended output were different than most of
    the other studies focused in this survey. These studies include social security
    payment classification, bank telemarketing success prediction, hardware solutions
    for faster financial transaction processing, etc. There were some anomaly detection
    implementations like tax evasion, money laundering that could have been included
    in this group; however we decided to cover them in a different subsection, fraud
    detection. Table LABEL:table:other_financial_applications shows all these aforementioned
    studies with their differences.
  prefs: []
  type: TYPE_NORMAL
- en: Dixon et al. [[199](#bib.bib199)] used Intel Xeon Phi to speedup the price movement
    direction prediction problem using [DFFN](#glo.main.dffn). The main contribution
    of the study was the increase in the speed of processing. Alberg et al. [[200](#bib.bib200)]
    used several company financials data (fundamental data) and price together to
    predict the next period’s company financials data. Kim et al. [[201](#bib.bib201)]
    used [CNN](#glo.main.cnn) for predicting the success of bank telemarketing. In
    their study, they used the phone calls of the bank marketing data and 16 finance-related
    attributes. Lee et al. [[202](#bib.bib202)] used technical indicators and patent
    information to estimate the revenue and profit for the corporates using [RBM](#glo.main.rbm)
    based [DBN](#glo.main.dbn), [FFNN](#glo.main.ffnn) and [Support Vector Regressor
    (SVR)](#glo.main.svr).
  prefs: []
  type: TYPE_NORMAL
- en: 'Ying et al.[[195](#bib.bib195)] classified and predicted individual social
    security payment types (paid, unpaid, repaid, transferred) using [LSTM](#glo.main.lstm),
    [HMM](#glo.main.hmm) and [SVM](#glo.main.svm). Li et al. [[193](#bib.bib193)]
    proposed a deep learning-based sentiment analysis method to identify the top sellers
    in the underground economy. Jeong et al. [[49](#bib.bib49)] combined deep Q-learning
    and deep [NN](#glo.main.nn) to implement a model to solve three separate problems:
    Increasing profit in a market, prediction of the number of shares to trade, and
    preventing overfitting with insufficient financial data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 15: Other Financial Applications'
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Subtopic | Data Set | Period | Feature Set | Method | Performance
    Criteria | Env. |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [[49](#bib.bib49)] | Improving trading decisions | [S&P500](#glo.main.sp500),
    [KOSPI](#glo.main.kospi), [HSI](#glo.main.hsi), and EuroStoxx50 | 1987-2017 |
    200-days stock price | Deep Q-Learning and [DNN](#glo.main.dnn) | Total profit,
    Correlation | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[193](#bib.bib193)] | Identifying Top Sellers In Underground Economy | Forums
    data | 2004-2013 | Sentences and keywords | Recursive neural tensor networks |
    Precision, recall, f-measure | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[195](#bib.bib195)] | Predicting Social Ins. Payment Behavior | Taiwan’s
    National Pension Insurance | 2008-2014 | Insured’s id, area-code, gender, etc.
    | [RNN](#glo.main.rnn) | Accuracy, total error | Python |'
  prefs: []
  type: TYPE_TB
- en: '| [[199](#bib.bib199)] | Speedup | 45 [CME](#glo.main.cme) listed commodity
    and FX futures | 1991-2014 | Price data | [DNN](#glo.main.dnn) | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[200](#bib.bib200)] | Forecasting Fundamentals | Stocks in [NYSE](#glo.main.nyse),
    [NASDAQ](#glo.main.nasdaq) or [AMEX](#glo.main.amex) exchanges | 1970-2017 | 16
    fundamental features from balance sheet | [MLP](#glo.main.mlp), [LFM](#glo.main.lfm)
    | [MSE](#glo.main.mse), Compount annual return, [SR](#glo.main.sr) | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[201](#bib.bib201)] | Predicting Bank Telemarketing | Phone calls of bank
    marketing data | 2008-2010 | 16 finance-related attributes | [CNN](#glo.main.cnn)
    | Accuracy | - |'
  prefs: []
  type: TYPE_TB
- en: '| [[202](#bib.bib202)] | Corporate Performance Prediction | 22 pharmaceutical
    companies data in US stock market | 2000-2015 | 11 financial and 4 patent indicator
    | [RBM](#glo.main.rbm), [DBN](#glo.main.dbn) | [RMSE](#glo.main.rmse), profit
    | - |'
  prefs: []
  type: TYPE_TB
- en: 5 Current Snaphot of DL research for Financial Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the survey, we reviewed 144 papers from various financial application areas.
    Each paper is analyzed according to its topic, publication type, problem type,
    method, dataset, feature set and performance criteria. Due to space limitations,
    we will only provide the general summary statistics indicating the current state
    of the [DL](#glo.main.dl) for finance research.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d428e2485102c834a76e9ef0b12952b3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: The histogram of Publication Count in Topics'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c0a9e8fd4673b41048aa63a17ff95c23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: The histogram of Publication Count in Years'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7b972b8054a9d666d3d375b6e3c0732b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: The histogram of Publication Count in Model Types'
  prefs: []
  type: TYPE_NORMAL
- en: 'First and foremost, we clustered the various topics within the financial applications
    research and presented them in Figure [8](#S5.F8 "Figure 8 ‣ 5 Current Snaphot
    of DL research for Financial Applications ‣ Deep Learning for Financial Applications
    : A Survey"). A quick glance at the figure shows us financial text mining and
    algorithmic trading are the top two fields that the researchers most worked on
    followed by risk assessment, sentiment analysis, portfolio management and fraud
    detection, respectively. The results indicate most of the papers were published
    within the last 3 years implying the domain is very hot and actively studied.
    We can also observe these phenomena by analyzing Figure [9](#S5.F9 "Figure 9 ‣
    5 Current Snaphot of DL research for Financial Applications ‣ Deep Learning for
    Financial Applications : A Survey"). Also, it is worth to mention that the few
    papers that were published before 2013 all used [RNN](#glo.main.rnn) based models.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When the papers were clustered by the [DL](#glo.main.dl) model type as presented
    in Figure [10](#S5.F10 "Figure 10 ‣ 5 Current Snaphot of DL research for Financial
    Applications ‣ Deep Learning for Financial Applications : A Survey"), we observe
    the dominance of [RNN](#glo.main.rnn), [DMLP](#glo.main.dmlp) and [CNN](#glo.main.cnn)
    over the remaining models, which might be expected, since these models are the
    most commonly preferred ones in general [DL](#glo.main.dl) implementations. Meanwhile,
    [RNN](#glo.main.rnn) is a general umbrella model which has several versions including
    [LSTM](#glo.main.lstm), [GRU](#glo.main.gru), etc. Within the [RNN](#glo.main.rnn)
    choice, most of the models actually belonged to [LSTM](#glo.main.lstm), which
    is very popular in time series forecasting or regression problems. It is also
    used quite often in algorithmic trading. More than 70% of the [RNN](#glo.main.rnn)
    papers consisted of [LSTM](#glo.main.lstm) models.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5966438dc2f50136be994d9463bd1cf3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Wordcloud of most-used Software, Frameworks, Environments'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [11](#S5.F11 "Figure 11 ‣ 5 Current Snaphot of DL research for Financial
    Applications ‣ Deep Learning for Financial Applications : A Survey") presents
    the commonly used software and frameworks for [DL](#glo.main.dl) model implementations
    through Wordcloud whereas Figure [12](#S5.F12 "Figure 12 ‣ 5 Current Snaphot of
    DL research for Financial Applications ‣ Deep Learning for Financial Applications
    : A Survey") provides the details about the development environments. The left
    chart (Figure [12(a)](#S5.F12.sf1 "In Figure 12 ‣ 5 Current Snaphot of DL research
    for Financial Applications ‣ Deep Learning for Financial Applications : A Survey"))
    presents the high level view where Python had the lion’s share with 80% over R
    (with 10%) and the other languages. The chart on the right (Figure [12(b)](#S5.F12.sf2
    "In Figure 12 ‣ 5 Current Snaphot of DL research for Financial Applications ‣
    Deep Learning for Financial Applications : A Survey")) provides the details about
    how the developers are using Python through different libraries and frameworks.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/72dc30ccea468eb98033cc1c7c518b88.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Preferred Development Environments
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e7a8e5fe7df1363d3c791c14accf61db.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Preferred Python Libraries
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12: Distribution of Preferred Environments'
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, [DMLP](#glo.main.dmlp) generally fits well for classification problems;
    hence it is a common choice for most of the financial application areas. However,
    since it is a natural extension of its shallow counterpart [MLP](#glo.main.mlp),
    it has a longer history than the other [DL](#glo.main.dl) models.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/95dc707d30367cadb3681c7fc289c93a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Top Journals - corresponding numbers next to the bar graph are representing
    the impact factor of the journals'
  prefs: []
  type: TYPE_NORMAL
- en: '[CNN](#glo.main.cnn) started getting more attention lately since most of the
    implementations appeared within the last 3 years. Careful analysis of [CNN](#glo.main.cnn)
    papers indicates that a recent trend of representing financial data with a 2-D
    image view in order to utilize [CNN](#glo.main.cnn) is growing. Hence [CNN](#glo.main.cnn)
    based models might overpass the other models in the future. It actually passed
    [DMLP](#glo.main.dmlp) for the last 3 years.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The top journals are tabulated in Fig [13](#S5.F13 "Figure 13 ‣ 5 Current Snaphot
    of DL research for Financial Applications ‣ Deep Learning for Financial Applications
    : A Survey"). The journals with the most published papers in the last 3 years
    include Expert Systems with Applications, Decision Support Systems, Applied Soft
    Computing, Neurocomputing, Knowledge-based Systems and European Journal of Operational
    Research.'
  prefs: []
  type: TYPE_NORMAL
- en: 6 Discussion and Open Issues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After reviewing all the publications based on the selected criteria explained
    in the previous section, we wanted to provide our findings of the current state-of-the-art
    situation. Our discussions are categorized by the [DL](#glo.main.dl) models and
    implementation topics.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Discussions on DL Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is possible to claim that [LSTM](#glo.main.lstm) is the dominant [DL](#glo.main.dl)
    model that is preferred by most researchers, due to its well-established structure
    for financial time series data forecasting. Most of the financial implementations
    have time-varying data representations requiring regression-type approaches which
    fits very well for [LSTM](#glo.main.lstm) and its derivatives due to their easy
    adaptations to the problems. As long as the temporal nature of the financial data
    remains, [LSTM](#glo.main.lstm) and its related family models will maintain their
    popularities.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, [CNN](#glo.main.cnn) based models started getting more traction among
    researchers in the last two years. Unlike [LSTM](#glo.main.lstm), [CNN](#glo.main.cnn)
    works better for classification problems and is more suitable for either non-time
    varying or static data representations. However, since most financial data is
    time-varying, under normal circumstances, [CNN](#glo.main.cnn) is not the natural
    choice for financial applications. However, in some independent studies, the researchers
    performed an innovative transformation of 1-D time-varying financial data into
    2-D mostly stationary image-like data to be able to utilize the power of [CNN](#glo.main.cnn)
    through adaptive filtering and implicit dimensionality reduction. This novel approach
    seems working remarkably well in complex financial patterns regardless of the
    application area. In the future, more examples of such implementations might be
    more common; only time will tell.
  prefs: []
  type: TYPE_NORMAL
- en: Another model that has a rising interest is [DRL](#glo.main.drl) based implementations;
    in particular, the ones coupled with agent-based modelling. Even though algorithmic
    trading is the most preferred implementation area for such models, it is possible
    to develop the working structures for any problem type.
  prefs: []
  type: TYPE_NORMAL
- en: Careful analyses of the reviews indicate in most of the papers hybrid models
    are preferred over native models for better accomplishments. A lot of researchers
    configure the topologies and network parameters for achieving higher performance.
    However, there is also the danger of creating more complex hybrid models that
    are not easy to build, and their interpretation also might be difficult.
  prefs: []
  type: TYPE_NORMAL
- en: 'Through the performance evaluation results, it is possible to claim that in
    general terms, [DL](#glo.main.dl) models outperform [ML](#glo.main.ml) counterparts
    when working on the same problems. [DL](#glo.main.dl) problems also have the advantage
    of being able to work on larger amount of data. With the growing expansion of
    open-source [DL](#glo.main.dl) libraries and frameworks (Figure [11](#S5.F11 "Figure
    11 ‣ 5 Current Snaphot of DL research for Financial Applications ‣ Deep Learning
    for Financial Applications : A Survey")), [DL](#glo.main.dl) model building and
    development process is easier than ever. And this phenomena is also supported
    by the increasing interest in adapting [DL](#glo.main.dl) models into all areas
    of finance which can be observed from Figure [9](#S5.F9 "Figure 9 ‣ 5 Current
    Snaphot of DL research for Financial Applications ‣ Deep Learning for Financial
    Applications : A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Also it is worth to mention that, besides the outperformance of [DL](#glo.main.dl)
    models over [ML](#glo.main.ml), the performance evaluation results are improving
    every year relatively, even though it is very difficult to explicitly quantifty
    the amount of improvement. The improvements are most notable in trend prediction
    based algo-trading implementations and text-mining studies due to deeper and/or
    more versatile networks and new innovative model developments. This is also reflected
    through the increasing number of published papers year over year.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Discussions on Implementation Areas
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Price/trend prediction and Algo-trading models have the most interest among
    all financial applications that use [DL](#glo.main.dl) models in their implementations.
    Risk assessment and portfolio management have always been popular within the [ML](#glo.main.ml)
    community, and it looks like this is also valid for [DL](#glo.main.dl) researchers.
  prefs: []
  type: TYPE_NORMAL
- en: Even though broad interest in [DL](#glo.main.dl) models is on the rise, financial
    text mining is particularly getting more attention than most of the other financial
    applications. The streaming flow of financial news, tweets, statements, blogs
    opened up a whole new world for the financial community allowing them to build
    better and more versatile prediction and evaluation models integrating numerical
    and textual data. Meanwhile, the general approach nowadays is to combine text
    mining with financial sentiment analysis. With that, it is reasonable to assume
    higher performance will be achieved. A lot of researchers started working on that
    particular application area. It is quite probable that the next generation of
    outperforming implementations will be based on models that can successfully integrate
    text mining with quantified numerical data.
  prefs: []
  type: TYPE_NORMAL
- en: These days, one other hot area within the [DL](#glo.main.dl) research is the
    cryptocurrencies. We can also include blockchain research to that, even though
    it is not necessarily directly related to cryptocurrencies, but generally used
    together in most implementations. Cryptocurrency price prediction has the most
    attraction within the field, but since the topic is fairly new, more studies and
    implementations will probably keep pouring in due to the high expectations and
    promising rewards.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Open Issues and Future Work
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When we try to extrapolate the current state of research and the achieved accomplishments
    into the future, a few areas of interests stand out. We will try to elaborate
    on them and provide a pathway for what can be done or needs to be done within
    the following few years. We will try to sort out our opinions by analyzing them
    through the model development and research topic point of view.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1 Model Development Perspective
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We have already mentioned the growing attention on the adaptation of 2-D [CNN](#glo.main.cnn)
    implementations for various financial application areas. This particular technique
    looks promising and provides opportunities. It would be beneficial to further
    explore the possibilities using that approach in different problems. The playfield
    is still wide open.
  prefs: []
  type: TYPE_NORMAL
- en: Graph [CNN](#glo.main.cnn) is another model that is closely related but still
    showing some discrepancies. It has not been used much, only one study was published
    that relates graph-[CNN](#glo.main.cnn) with financial applications. However,
    versatile transformations of financial data into graphs, integrating sentiment
    analysis through graph representations and constructing different models can create
    opportunities for researchers to build better performing financial applications.
  prefs: []
  type: TYPE_NORMAL
- en: There are also recently developed [DL](#glo.main.dl) models, like [GAN](#glo.main.gan),
    Capsule networks, etc. that can also provide viable alternatives to existing implementations.
    They have started showing up in various non-financial studies, however to the
    best of our knowledge, no known implementation of such kind for financial applications
    exists. It might open up a new window of opportunities for financial researchers
    and practitioners. In addition to such new models, innovative paradigms like transfer
    learning, one-shot learning can be tested within the environment.
  prefs: []
  type: TYPE_NORMAL
- en: Since financial text mining is overtaking the other topics in an accelerated
    fashion, new data models like Stock2Vec [[168](#bib.bib168)] can be enhanced for
    better and more representative models. In addition, [Natural Language Processing
    (NLP)](#glo.main.nlp) based ensemble models or more integration of data semantics
    into the picture can increase the accuracy of the existing models.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, according to our observations, hybrid models are preferred more over
    the native or standalone models in most studies. This trend will likely continue,
    however, researchers need to introduce more versatile, sometimes unconventional
    models for better results. Hybrid models integrating various simple [DL](#glo.main.dl)
    layers like cascaded [CNN](#glo.main.cnn)-[LSTM](#glo.main.lstm) blocks can have
    better outcomes since ensembling spatial and temporal information together in
    a novel way might be an important milestone for researchers seeking for "alpha"
    in their models.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.2 Implementation Perspective
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As far as the application areas are concerned, the usual suspects, algorithmic
    trading, portfolio management and risk assessment will probably continue on their
    dominance within the financial research arena in the foreseeable future. Meanwhile,
    some new shining stars started getting more attention, not only because they represent
    fairly new research opportunities, but also their forecasted impact on the financial
    world is noteworthy.
  prefs: []
  type: TYPE_NORMAL
- en: Cryptocurrencies and blockchain technology are among these new research areas.
    Hence, it is worthwhile to explore the possibilities that these new fields will
    bring. It will be a while before any of these technologies become widely accepted
    industry standard, however, that is the sole reason why it provides a great opportunity
    for the researchers to shape the future of the financial world with new innovative
    models and hoping that the rest of the world will follow their footsteps.
  prefs: []
  type: TYPE_NORMAL
- en: Another area that can benefit from more innovative models is portfolio management.
    Robo-advisory systems are on the rise throughout the world and these systems depend
    on high performing automated decision support systems. Since [DL](#glo.main.dl)
    models fit well to that description, it would be logical to assume the utilization
    of [DL](#glo.main.dl) implementations will increase in the coming years. As such,
    the corresponding quant funds will be very interested in the achievements that
    the [DL](#glo.main.dl) researchers can offer for the financial community. This
    might require integrating learning and optimization models together for better-performing
    systems. Hence, ensemble models that can successfully mix [EC](#glo.main.ec) and
    [DL](#glo.main.dl) components might be what the industry is anticipating for the
    immediate future. This might also result in new research opportunities.
  prefs: []
  type: TYPE_NORMAL
- en: Yet, one other research area that is generally avoided by soft computing and
    [DL](#glo.main.dl) researchers is the financial derivatives market. Even though
    there are many different products that exist on the market, the corresponding
    [DL](#glo.main.dl) research is very scarce. However, for professionals working
    in the finance industry, these products actually provide incredible flexibilities
    ranging from hedging their investments to implementing leveraged transactions
    with minimized risk. Even though, opportunities exist for [DL](#glo.main.dl) researchers,
    there was not a broad interest in the topic, since there are only a handful of
    studies for the derivatives market. Option strategy optimization, futures trading,
    option pricing, arbitrage trading can be among the areas that might benefit from
    [DL](#glo.main.dl) research.
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis, text mining, risk adjusted asset pricing are some of the
    other implementation areas that attract researchers but not yet fully utilized.
    It is quite probable we will see more papers in these fields in the near future.
  prefs: []
  type: TYPE_NORMAL
- en: Last, but not least, [HFT](#glo.main.hft) is one area that has not benefitted
    from the advancements in [ML](#glo.main.ml) research to its full potential yet.
    Since [HFT](#glo.main.hft) requires lightning-fast transaction processing, the
    statistical learning model that is embedded into such trading systems must not
    introduce any extra latency to the existing system. This necessitates careful
    planning and modelling of such models. For that purpose, [DL](#glo.main.dl) models
    embedded within the [Graphic Processing Unit (GPU)](#glo.main.gpu) or [Field Programmable
    Gate Array (FPGA)](#glo.main.fpga) based hardware solutions can be studied. The
    hardware aspects of [DL](#glo.main.dl) implementations are generally omitted in
    almost all studies, but as stated above, there might be opportunities also in
    that field.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.3 Suggestions for Future Research
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Careful analyses of Figures [8](#S5.F8 "Figure 8 ‣ 5 Current Snaphot of DL
    research for Financial Applications ‣ Deep Learning for Financial Applications
    : A Survey") and [9](#S5.F9 "Figure 9 ‣ 5 Current Snaphot of DL research for Financial
    Applications ‣ Deep Learning for Financial Applications : A Survey") indicate
    the rising overall appetite for applied [DL](#glo.main.dl) research for finance.
    Even though the interest is broad, some areas like cryptocurrency and block chain
    studies might get more attention compared to other areas.'
  prefs: []
  type: TYPE_NORMAL
- en: With respect to the promising outlook in text mining and financial sentiment
    analysis, we believe behavioral finance is also a fairly untouched research area
    that hides a lot of opportunities within. There is a lack of research work published
    on behavioral finance using [DL](#glo.main.dl) models. This might be mainly due
    to the difficulties of quantifying the inputs and outputs of behavioral finance
    research to be used with [DL](#glo.main.dl) models. However, new advancements
    in text mining, [NLP](#glo.main.nlp), semantics combined with agent-based computational
    finance can open up huge opportunities in that field. We would encourage researchers
    to look further into this for a possible implementation area as it currently seems
    to be wide open for new studies.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4 Responses to our Initial Research Questions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At this point, since we gathered and processed all the information we need,
    we are ready to provide answers to our initially stated research questions. The
    questions and our corresponding answers according to our survey are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What financial application areas are of interest to [DL](#glo.main.dl) community?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Response: Financial text mining, Algo-trading, risk assessments, sentiment
    analysis, portfolio management and fraud detection are among the most studied
    areas of finance research. (Please check Figure [8](#S5.F8 "Figure 8 ‣ 5 Current
    Snaphot of DL research for Financial Applications ‣ Deep Learning for Financial
    Applications : A Survey"))'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How mature is the existing research in each of these application areas?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Response: Even though [DL](#glo.main.dl) models already had better achievements
    compared to traditional counterparts in almost all areas, the overall interest
    is still on the rise in all research areas.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the areas that have promising potentials from an academic/industrial
    research perspective?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Response: Cryptocurrencies, blockchain, behavioral finance, [HFT](#glo.main.hft)
    and derivatives market have promising potentials for research.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which [DL](#glo.main.dl) models are preferred (and more successful) in different
    applications?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Response: [RNN](#glo.main.rnn) based models (in particular [LSTM](#glo.main.lstm)),
    [CNN](#glo.main.cnn) and [DMLP](#glo.main.dmlp) have been used extensively in
    implementations. From what we have encountered, [LSTM](#glo.main.lstm) is more
    successful and preferred in time-series forecasting, whereas [DMLP](#glo.main.dmlp)
    and [CNN](#glo.main.cnn) are better suited to applications requiring classification.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do [DL](#glo.main.dl) models pare against traditional soft computing / [ML](#glo.main.ml)
    techniques?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Response: In most of the studies, [DL](#glo.main.dl) models performed better
    than their [ML](#glo.main.ml) counterparts. There were a few occasions where [ML](#glo.main.ml)
    had comparable or even better solutions, however the general tendency is the outperformance
    of the [DL](#glo.main.dl) methods.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the future direction for [DL](#glo.main.dl) research in Finance?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Response: Hybrid models based on Spatio-temporal data representations, [NLP](#glo.main.nlp),
    semantics and text mining-based models might become more important in the near
    future.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 7 Conclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The financial industry and academia have started realizing the potentials of
    [DL](#glo.main.dl) in various application areas. The number of research work keeps
    on increasing every year with an accelerated fashion. However, we are just in
    the early years of this new era, more studies will be implemented and new models
    will keep pouring in. In this survey, we wanted to highlight the state-of-the-art
    [DL](#glo.main.dl) research for the financial applications. We not only provided
    a snapshot of the existing research status but also tried to identify the future
    roadway for intended researchers. Our findings indicate there are incredible opportunities
    within the field and it looks like they will not disappear anytime soon. So, we
    encourage the researchers that are interested in the area to start exploring.
  prefs: []
  type: TYPE_NORMAL
- en: 8 Acknowledgement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work is supported by the Scientific and Technological Research Council
    of Turkey (TUBITAK) grant no 215E248.
  prefs: []
  type: TYPE_NORMAL
- en: Glossary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AE
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoder
  prefs: []
  type: TYPE_NORMAL
- en: AI
  prefs: []
  type: TYPE_NORMAL
- en: Artificial Intelligence
  prefs: []
  type: TYPE_NORMAL
- en: AMEX
  prefs: []
  type: TYPE_NORMAL
- en: American Stock Exchange
  prefs: []
  type: TYPE_NORMAL
- en: ANN
  prefs: []
  type: TYPE_NORMAL
- en: Artificial Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: ARIMA
  prefs: []
  type: TYPE_NORMAL
- en: Autoregressive Integrated Moving Average
  prefs: []
  type: TYPE_NORMAL
- en: AUC
  prefs: []
  type: TYPE_NORMAL
- en: Area Under the Curve
  prefs: []
  type: TYPE_NORMAL
- en: AUROC
  prefs: []
  type: TYPE_NORMAL
- en: Area Under the Receiver Operating Characteristics
  prefs: []
  type: TYPE_NORMAL
- en: BA
  prefs: []
  type: TYPE_NORMAL
- en: Balanced Accuracy
  prefs: []
  type: TYPE_NORMAL
- en: BELM
  prefs: []
  type: TYPE_NORMAL
- en: Basic Extreme Learning Machine
  prefs: []
  type: TYPE_NORMAL
- en: BHC
  prefs: []
  type: TYPE_NORMAL
- en: Bank Holding Companies
  prefs: []
  type: TYPE_NORMAL
- en: Bi-GRU
  prefs: []
  type: TYPE_NORMAL
- en: Bidirectional Gated Recurrent Unit
  prefs: []
  type: TYPE_NORMAL
- en: Bi-LSTM
  prefs: []
  type: TYPE_NORMAL
- en: Bidirectional LSTM
  prefs: []
  type: TYPE_NORMAL
- en: BIST
  prefs: []
  type: TYPE_NORMAL
- en: Istanbul Stock Exchange Index
  prefs: []
  type: TYPE_NORMAL
- en: BOLL
  prefs: []
  type: TYPE_NORMAL
- en: Bollinger Band
  prefs: []
  type: TYPE_NORMAL
- en: BPTT
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation Through Time
  prefs: []
  type: TYPE_NORMAL
- en: CAE
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Autoencoder
  prefs: []
  type: TYPE_NORMAL
- en: CAGR
  prefs: []
  type: TYPE_NORMAL
- en: Compound Annual Growth Rate
  prefs: []
  type: TYPE_NORMAL
- en: CART
  prefs: []
  type: TYPE_NORMAL
- en: Classification and Regression Trees
  prefs: []
  type: TYPE_NORMAL
- en: CCI
  prefs: []
  type: TYPE_NORMAL
- en: Commodity Channel Index
  prefs: []
  type: TYPE_NORMAL
- en: CDAX
  prefs: []
  type: TYPE_NORMAL
- en: German Stock Market Index Calculated by Deutsche Börse
  prefs: []
  type: TYPE_NORMAL
- en: CDS
  prefs: []
  type: TYPE_NORMAL
- en: Credit Default Swaps
  prefs: []
  type: TYPE_NORMAL
- en: CGAN
  prefs: []
  type: TYPE_NORMAL
- en: Conditional
  prefs: []
  type: TYPE_NORMAL
- en: CME
  prefs: []
  type: TYPE_NORMAL
- en: Chicago Mercantile Exchange
  prefs: []
  type: TYPE_NORMAL
- en: CNN
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: CRIX
  prefs: []
  type: TYPE_NORMAL
- en: The Cryptocurrency Index
  prefs: []
  type: TYPE_NORMAL
- en: CRSP
  prefs: []
  type: TYPE_NORMAL
- en: Center for Research in Security Prices
  prefs: []
  type: TYPE_NORMAL
- en: CSI
  prefs: []
  type: TYPE_NORMAL
- en: China Securities Index
  prefs: []
  type: TYPE_NORMAL
- en: DAX
  prefs: []
  type: TYPE_NORMAL
- en: The Deutscher Aktienindex
  prefs: []
  type: TYPE_NORMAL
- en: DBN
  prefs: []
  type: TYPE_NORMAL
- en: Deep Belief Network
  prefs: []
  type: TYPE_NORMAL
- en: DCNL
  prefs: []
  type: TYPE_NORMAL
- en: Deep Co-investment Network Learning
  prefs: []
  type: TYPE_NORMAL
- en: DCNN
  prefs: []
  type: TYPE_NORMAL
- en: Deep Convolutional Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: DDPG
  prefs: []
  type: TYPE_NORMAL
- en: Deep Deterministic Policy Gradient
  prefs: []
  type: TYPE_NORMAL
- en: Deep-FASP
  prefs: []
  type: TYPE_NORMAL
- en: The Financial Aspect and Sentiment Prediction task with Deep neural networks
  prefs: []
  type: TYPE_NORMAL
- en: DFFN
  prefs: []
  type: TYPE_NORMAL
- en: Deep Feed Forward Network
  prefs: []
  type: TYPE_NORMAL
- en: DFNN
  prefs: []
  type: TYPE_NORMAL
- en: Deep Feedforward Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: DGM
  prefs: []
  type: TYPE_NORMAL
- en: Deep Neural Generative Model
  prefs: []
  type: TYPE_NORMAL
- en: DGP
  prefs: []
  type: TYPE_NORMAL
- en: Deep Gaussian Process
  prefs: []
  type: TYPE_NORMAL
- en: DJI
  prefs: []
  type: TYPE_NORMAL
- en: Dow Jones Index
  prefs: []
  type: TYPE_NORMAL
- en: DJIA
  prefs: []
  type: TYPE_NORMAL
- en: Dow Jones Industrial Average
  prefs: []
  type: TYPE_NORMAL
- en: DL
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning
  prefs: []
  type: TYPE_NORMAL
- en: DLR
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning Representation
  prefs: []
  type: TYPE_NORMAL
- en: DMI
  prefs: []
  type: TYPE_NORMAL
- en: Directional Movement Index
  prefs: []
  type: TYPE_NORMAL
- en: DMLP
  prefs: []
  type: TYPE_NORMAL
- en: Deep Multilayer Perceptron
  prefs: []
  type: TYPE_NORMAL
- en: DNN
  prefs: []
  type: TYPE_NORMAL
- en: Deep Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: DP
  prefs: []
  type: TYPE_NORMAL
- en: Discriminant Power
  prefs: []
  type: TYPE_NORMAL
- en: DQL
  prefs: []
  type: TYPE_NORMAL
- en: Deep Q-Learning
  prefs: []
  type: TYPE_NORMAL
- en: DRL
  prefs: []
  type: TYPE_NORMAL
- en: Deep Reinforcement Learning
  prefs: []
  type: TYPE_NORMAL
- en: DRSE
  prefs: []
  type: TYPE_NORMAL
- en: Deep Random Subspace Ensembles
  prefs: []
  type: TYPE_NORMAL
- en: DTW
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic Time Warping
  prefs: []
  type: TYPE_NORMAL
- en: EA
  prefs: []
  type: TYPE_NORMAL
- en: Evolutionary Algorithm
  prefs: []
  type: TYPE_NORMAL
- en: EC
  prefs: []
  type: TYPE_NORMAL
- en: Evolutionary Computation
  prefs: []
  type: TYPE_NORMAL
- en: ELM
  prefs: []
  type: TYPE_NORMAL
- en: Extreme Learning Machine
  prefs: []
  type: TYPE_NORMAL
- en: EMA
  prefs: []
  type: TYPE_NORMAL
- en: Exponential Moving Average
  prefs: []
  type: TYPE_NORMAL
- en: ETF
  prefs: []
  type: TYPE_NORMAL
- en: Exchange-Traded Fund
  prefs: []
  type: TYPE_NORMAL
- en: FDDR
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzy Deep Direct Reinforcement Learning
  prefs: []
  type: TYPE_NORMAL
- en: FE-QAR
  prefs: []
  type: TYPE_NORMAL
- en: Fixed Effects Quantile VAR
  prefs: []
  type: TYPE_NORMAL
- en: FFNN
  prefs: []
  type: TYPE_NORMAL
- en: Feedforward Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: FN
  prefs: []
  type: TYPE_NORMAL
- en: False Negative
  prefs: []
  type: TYPE_NORMAL
- en: FNN
  prefs: []
  type: TYPE_NORMAL
- en: Fully Connected Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: FP
  prefs: []
  type: TYPE_NORMAL
- en: False Positive
  prefs: []
  type: TYPE_NORMAL
- en: FPGA
  prefs: []
  type: TYPE_NORMAL
- en: Field Programmable Gate Array
  prefs: []
  type: TYPE_NORMAL
- en: FTSE
  prefs: []
  type: TYPE_NORMAL
- en: London Financial Times Stock Exchange Index
  prefs: []
  type: TYPE_NORMAL
- en: G-mean
  prefs: []
  type: TYPE_NORMAL
- en: Geometric Mean
  prefs: []
  type: TYPE_NORMAL
- en: GA
  prefs: []
  type: TYPE_NORMAL
- en: Genetic Algorithm
  prefs: []
  type: TYPE_NORMAL
- en: GAN
  prefs: []
  type: TYPE_NORMAL
- en: Generative Adversarial Network
  prefs: []
  type: TYPE_NORMAL
- en: GASVR
  prefs: []
  type: TYPE_NORMAL
- en: '[GA](#glo.main.ga) with a'
  prefs: []
  type: TYPE_NORMAL
- en: GBDT
  prefs: []
  type: TYPE_NORMAL
- en: Gradient-Boosted-DecisionTrees
  prefs: []
  type: TYPE_NORMAL
- en: GBT
  prefs: []
  type: TYPE_NORMAL
- en: Gradient Boosted Trees
  prefs: []
  type: TYPE_NORMAL
- en: GP
  prefs: []
  type: TYPE_NORMAL
- en: Genetic Programming
  prefs: []
  type: TYPE_NORMAL
- en: GPU
  prefs: []
  type: TYPE_NORMAL
- en: Graphic Processing Unit
  prefs: []
  type: TYPE_NORMAL
- en: GRU
  prefs: []
  type: TYPE_NORMAL
- en: Gated-Recurrent Unit
  prefs: []
  type: TYPE_NORMAL
- en: HAN
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid Attention Network
  prefs: []
  type: TYPE_NORMAL
- en: HAR
  prefs: []
  type: TYPE_NORMAL
- en: Heterogeneous Autoregressive Process
  prefs: []
  type: TYPE_NORMAL
- en: HFT
  prefs: []
  type: TYPE_NORMAL
- en: High Frequency Trading
  prefs: []
  type: TYPE_NORMAL
- en: HMM
  prefs: []
  type: TYPE_NORMAL
- en: Hidden Markov Model
  prefs: []
  type: TYPE_NORMAL
- en: HS
  prefs: []
  type: TYPE_NORMAL
- en: China Shanghai Shenzhen Stock Index
  prefs: []
  type: TYPE_NORMAL
- en: HSI
  prefs: []
  type: TYPE_NORMAL
- en: Hong Kong Hang Seng Index
  prefs: []
  type: TYPE_NORMAL
- en: IBB
  prefs: []
  type: TYPE_NORMAL
- en: iShares Nasdaq Biotechnology ETF
  prefs: []
  type: TYPE_NORMAL
- en: KELM
  prefs: []
  type: TYPE_NORMAL
- en: Kernel Extreme Learning Machine
  prefs: []
  type: TYPE_NORMAL
- en: KOSPI
  prefs: []
  type: TYPE_NORMAL
- en: The Korea Composite Stock Price Index
  prefs: []
  type: TYPE_NORMAL
- en: KS
  prefs: []
  type: TYPE_NORMAL
- en: Kolmogorov–Smirnov
  prefs: []
  type: TYPE_NORMAL
- en: LAR
  prefs: []
  type: TYPE_NORMAL
- en: Linear Auto-regression Predictor
  prefs: []
  type: TYPE_NORMAL
- en: LDA
  prefs: []
  type: TYPE_NORMAL
- en: Latent Dirichlet Allocation
  prefs: []
  type: TYPE_NORMAL
- en: LFM
  prefs: []
  type: TYPE_NORMAL
- en: Lookahead Factor Models
  prefs: []
  type: TYPE_NORMAL
- en: LOB
  prefs: []
  type: TYPE_NORMAL
- en: Limit Order Book Data
  prefs: []
  type: TYPE_NORMAL
- en: LR
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression
  prefs: []
  type: TYPE_NORMAL
- en: LSTM
  prefs: []
  type: TYPE_NORMAL
- en: Long-Short Term Memory
  prefs: []
  type: TYPE_NORMAL
- en: MA
  prefs: []
  type: TYPE_NORMAL
- en: Moving Average
  prefs: []
  type: TYPE_NORMAL
- en: MACD
  prefs: []
  type: TYPE_NORMAL
- en: Moving Average Convergence and Divergence
  prefs: []
  type: TYPE_NORMAL
- en: MAE
  prefs: []
  type: TYPE_NORMAL
- en: Mean Absolute Error
  prefs: []
  type: TYPE_NORMAL
- en: MAPE
  prefs: []
  type: TYPE_NORMAL
- en: Mean Absolute Percentage Error
  prefs: []
  type: TYPE_NORMAL
- en: MCC
  prefs: []
  type: TYPE_NORMAL
- en: Matthew Correlation Coefficient
  prefs: []
  type: TYPE_NORMAL
- en: MDA
  prefs: []
  type: TYPE_NORMAL
- en: Multilinear Discriminant Analysis
  prefs: []
  type: TYPE_NORMAL
- en: MDD
  prefs: []
  type: TYPE_NORMAL
- en: Maximum Drawdown
  prefs: []
  type: TYPE_NORMAL
- en: ML
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning
  prefs: []
  type: TYPE_NORMAL
- en: MLP
  prefs: []
  type: TYPE_NORMAL
- en: Multilayer Perceptron
  prefs: []
  type: TYPE_NORMAL
- en: MODRL
  prefs: []
  type: TYPE_NORMAL
- en: Multi-objective Deep Reinforcement Learning
  prefs: []
  type: TYPE_NORMAL
- en: MOEA
  prefs: []
  type: TYPE_NORMAL
- en: Multiobjective Evolutionary Algorithm
  prefs: []
  type: TYPE_NORMAL
- en: MSE
  prefs: []
  type: TYPE_NORMAL
- en: Mean Squared Error
  prefs: []
  type: TYPE_NORMAL
- en: MV-t
  prefs: []
  type: TYPE_NORMAL
- en: Multivariate t Distribution
  prefs: []
  type: TYPE_NORMAL
- en: MVN
  prefs: []
  type: TYPE_NORMAL
- en: Multivariate Normal Distribution
  prefs: []
  type: TYPE_NORMAL
- en: NASDAQ
  prefs: []
  type: TYPE_NORMAL
- en: National Association of Securities Dealers Automated Quotations
  prefs: []
  type: TYPE_NORMAL
- en: NES
  prefs: []
  type: TYPE_NORMAL
- en: Natural Evolution Strategies
  prefs: []
  type: TYPE_NORMAL
- en: NIFTY
  prefs: []
  type: TYPE_NORMAL
- en: National Stock Exchange of India
  prefs: []
  type: TYPE_NORMAL
- en: NIKKEI
  prefs: []
  type: TYPE_NORMAL
- en: Tokyo Nikkei Index
  prefs: []
  type: TYPE_NORMAL
- en: NLP
  prefs: []
  type: TYPE_NORMAL
- en: Natural Language Processing
  prefs: []
  type: TYPE_NORMAL
- en: NN
  prefs: []
  type: TYPE_NORMAL
- en: Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: NYSE
  prefs: []
  type: TYPE_NORMAL
- en: New York Stock Exchange
  prefs: []
  type: TYPE_NORMAL
- en: OCHL
  prefs: []
  type: TYPE_NORMAL
- en: Open,Close,High, Low
  prefs: []
  type: TYPE_NORMAL
- en: OCHLV
  prefs: []
  type: TYPE_NORMAL
- en: Open,Close,High, Low, Volume
  prefs: []
  type: TYPE_NORMAL
- en: PCA
  prefs: []
  type: TYPE_NORMAL
- en: Principal Component Analysis
  prefs: []
  type: TYPE_NORMAL
- en: PCC
  prefs: []
  type: TYPE_NORMAL
- en: Pearson’s Correlation Coefficient
  prefs: []
  type: TYPE_NORMAL
- en: PLR
  prefs: []
  type: TYPE_NORMAL
- en: Piecewise Linear Representation
  prefs: []
  type: TYPE_NORMAL
- en: PNN
  prefs: []
  type: TYPE_NORMAL
- en: Probabilistic Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: PPO
  prefs: []
  type: TYPE_NORMAL
- en: Proximal Policy Optimization
  prefs: []
  type: TYPE_NORMAL
- en: PSO
  prefs: []
  type: TYPE_NORMAL
- en: Particle Swarm Optimization
  prefs: []
  type: TYPE_NORMAL
- en: R²
  prefs: []
  type: TYPE_NORMAL
- en: Squared correlation, Non-linear regression multiple correlation
  prefs: []
  type: TYPE_NORMAL
- en: RBM
  prefs: []
  type: TYPE_NORMAL
- en: Restricted Boltzmann Machine
  prefs: []
  type: TYPE_NORMAL
- en: RCNN
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent CNN
  prefs: []
  type: TYPE_NORMAL
- en: ReLU
  prefs: []
  type: TYPE_NORMAL
- en: Rectified Linear Unit
  prefs: []
  type: TYPE_NORMAL
- en: RF
  prefs: []
  type: TYPE_NORMAL
- en: Random Forest
  prefs: []
  type: TYPE_NORMAL
- en: RL
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement Learning
  prefs: []
  type: TYPE_NORMAL
- en: RMDN
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent Mixture Density Network
  prefs: []
  type: TYPE_NORMAL
- en: RMSE
  prefs: []
  type: TYPE_NORMAL
- en: Root Mean Square Error
  prefs: []
  type: TYPE_NORMAL
- en: RNN
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: ROA
  prefs: []
  type: TYPE_NORMAL
- en: Return on Assets
  prefs: []
  type: TYPE_NORMAL
- en: ROC
  prefs: []
  type: TYPE_NORMAL
- en: Price of Change
  prefs: []
  type: TYPE_NORMAL
- en: RSE
  prefs: []
  type: TYPE_NORMAL
- en: Relative Squared Error
  prefs: []
  type: TYPE_NORMAL
- en: RSI
  prefs: []
  type: TYPE_NORMAL
- en: Relative Strength Index
  prefs: []
  type: TYPE_NORMAL
- en: SAE
  prefs: []
  type: TYPE_NORMAL
- en: Stacked Autoencoder
  prefs: []
  type: TYPE_NORMAL
- en: SCI
  prefs: []
  type: TYPE_NORMAL
- en: SSE Composite Index
  prefs: []
  type: TYPE_NORMAL
- en: SFM
  prefs: []
  type: TYPE_NORMAL
- en: State Frequency Memory
  prefs: []
  type: TYPE_NORMAL
- en: SGD
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic Gradient Descent
  prefs: []
  type: TYPE_NORMAL
- en: S&P500
  prefs: []
  type: TYPE_NORMAL
- en: Standard’s & Poor’s 500 Index
  prefs: []
  type: TYPE_NORMAL
- en: SPY
  prefs: []
  type: TYPE_NORMAL
- en: SPDR S&P 500 ETF
  prefs: []
  type: TYPE_NORMAL
- en: SR
  prefs: []
  type: TYPE_NORMAL
- en: Sharpe-ratio
  prefs: []
  type: TYPE_NORMAL
- en: STD
  prefs: []
  type: TYPE_NORMAL
- en: Standard Deviation
  prefs: []
  type: TYPE_NORMAL
- en: SVD
  prefs: []
  type: TYPE_NORMAL
- en: Singular Value Decomposition
  prefs: []
  type: TYPE_NORMAL
- en: SVM
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Machine
  prefs: []
  type: TYPE_NORMAL
- en: SVR
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Regressor
  prefs: []
  type: TYPE_NORMAL
- en: SZSE
  prefs: []
  type: TYPE_NORMAL
- en: Shenzhen Stock Exchange Composite Index
  prefs: []
  type: TYPE_NORMAL
- en: TAIEX
  prefs: []
  type: TYPE_NORMAL
- en: Taiwan Capitalization Weighted Stock Index
  prefs: []
  type: TYPE_NORMAL
- en: TALIB
  prefs: []
  type: TYPE_NORMAL
- en: Technical Analysis Library Package
  prefs: []
  type: TYPE_NORMAL
- en: TAQ
  prefs: []
  type: TYPE_NORMAL
- en: Trade and Quote
  prefs: []
  type: TYPE_NORMAL
- en: TDNN
  prefs: []
  type: TYPE_NORMAL
- en: Timedelay Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: TEMA
  prefs: []
  type: TYPE_NORMAL
- en: Triple Exponential Moving Average
  prefs: []
  type: TYPE_NORMAL
- en: TF-IDF
  prefs: []
  type: TYPE_NORMAL
- en: Term Frequency-Inverse Document Frequency
  prefs: []
  type: TYPE_NORMAL
- en: TGRU
  prefs: []
  type: TYPE_NORMAL
- en: Two-stream GRU
  prefs: []
  type: TYPE_NORMAL
- en: THEIL-U
  prefs: []
  type: TYPE_NORMAL
- en: Theil’s inequality coefficient
  prefs: []
  type: TYPE_NORMAL
- en: TN
  prefs: []
  type: TYPE_NORMAL
- en: True Negative
  prefs: []
  type: TYPE_NORMAL
- en: TP
  prefs: []
  type: TYPE_NORMAL
- en: True Positive
  prefs: []
  type: TYPE_NORMAL
- en: TR
  prefs: []
  type: TYPE_NORMAL
- en: Total Return
  prefs: []
  type: TYPE_NORMAL
- en: TSE
  prefs: []
  type: TYPE_NORMAL
- en: Tokyo Stock Exchange
  prefs: []
  type: TYPE_NORMAL
- en: TWSE
  prefs: []
  type: TYPE_NORMAL
- en: Taiwan Stock Exchange
  prefs: []
  type: TYPE_NORMAL
- en: VAR
  prefs: []
  type: TYPE_NORMAL
- en: Vector Auto Regression
  prefs: []
  type: TYPE_NORMAL
- en: VWL
  prefs: []
  type: TYPE_NORMAL
- en: WL Kernel-based Method
  prefs: []
  type: TYPE_NORMAL
- en: WBA
  prefs: []
  type: TYPE_NORMAL
- en: Weighted Balanced Accuracy
  prefs: []
  type: TYPE_NORMAL
- en: WMTR
  prefs: []
  type: TYPE_NORMAL
- en: Weighted Multichannel Time-series Regression
  prefs: []
  type: TYPE_NORMAL
- en: WSURT
  prefs: []
  type: TYPE_NORMAL
- en: Wilcoxon Sum-rank Test
  prefs: []
  type: TYPE_NORMAL
- en: WT
  prefs: []
  type: TYPE_NORMAL
- en: Wavelet Transforms
  prefs: []
  type: TYPE_NORMAL
- en: XGBoost
  prefs: []
  type: TYPE_NORMAL
- en: eXtreme Gradient Boosting
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sezer et al. [2019] Omer Berat Sezer, Mehmet Ugur Gudelek, and Ahmet Murat
    Ozbayoglu. Financial time series forecasting with deep learning : A systematic
    literature review: 2005-2019, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bahrammirzaee [2010] Arash Bahrammirzaee. A comparative survey of artificial
    intelligence applications in finance: artificial neural networks, expert system
    and hybrid intelligent systems. *Neural Computing and Applications*, 19(8):1165–1195,
    June 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang and Zhou [2004] D. Zhang and L. Zhou. Discovering golden nuggets: Data
    mining in financial application. *IEEE Transactions on Systems, Man and Cybernetics,
    Part C (Applications and Reviews)*, 34(4):513–522, November 2004.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mochón et al. [2007] Asunción Mochón, David Quintana, Yago Sáez, and Pedro Isasi
    Viñuela. Soft computing techniques applied to finance. *Applied Intelligence*,
    29:111–115, 2007.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pulakkazhy [2013] Pulakkazhy. Mining in banking and its applications: A review.
    *Journal of Computer Science*, 9(10):1252–1259, October 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mullainathan and Spiess [2017] Sendhil Mullainathan and Jann Spiess. Machine
    learning: An applied econometric approach. *Journal of Economic Perspectives*,
    31(2):87–106, May 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gai et al. [2018] Keke Gai, Meikang Qiu, and Xiaotong Sun. A survey on fintech.
    *Journal of Network and Computer Applications*, 103:262–273, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kovalerchuk and Vityaev [2000] Boris Kovalerchuk and Evgenii Vityaev. *Data
    Mining in Finance: Advances in Relational and Hybrid Methods*. Kluwer Academic
    Publishers, Norwell, MA, USA, 2000.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aliev et al. [2004] Rafik A. Aliev, Bijan Fazlollahi, and Rashad R. Aliev. Soft
    computing and its applications in business and economics. In *Studies in Fuzziness
    and Soft Computing*, 2004.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brabazon and O’Neill [2008] Anthony Brabazon and Michael O’Neill, editors. *Natural
    Computing in Computational Finance*. Springer Berlin Heidelberg, 2008.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dymowa [2011] Ludmila Dymowa. *Soft Computing in Economics and Finance*. Springer
    Berlin Heidelberg, 2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen [2002] Shu-Heng Chen, editor. *Genetic Algorithms and Genetic Programming
    in Computational Finance*. Springer US, 2002.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tapia and Coello [2007] Ma. Guadalupe Castillo Tapia and Carlos A. Coello Coello.
    Applications of multi-objective evolutionary algorithms in economics and finance:
    A survey. In *2007 IEEE Congress on Evolutionary Computation*. IEEE, September
    2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ponsich et al. [2013] Antonin Ponsich, Antonio Lopez Jaimes, and Carlos A. Coello
    Coello. A survey on multiobjective evolutionary algorithms for the solution of
    the portfolio optimization problem and other finance and economics applications.
    *IEEE Transactions on Evolutionary Computation*, 17(3):321–344, June 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aguilar-Rivera et al. [2015] Ruben Aguilar-Rivera, Manuel Valenzuela-Rendon,
    and J.J. Rodriguez-Ortiz. Genetic algorithms and darwinian approaches in financial
    applications: A survey. *Expert Systems with Applications*, 42(21):7684–7697,
    November 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wong and Selvi [1998] Bo K Wong and Yakup Selvi. Neural network applications
    in finance: A review and analysis of literature (1990–1996). *Information & Management*,
    34(3):129–139, October 1998.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li and Ma [2010] Yuhong Li and Weihua Ma. Applications of artificial neural
    networks in financial economics: A survey. In *2010 International Symposium on
    Computational Intelligence and Design*. IEEE, October 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Elmsili and Outtaj [2018] B. Elmsili and B. Outtaj. Artificial neural networks
    applications in economics and management research: An exploratory literature review.
    In *2018 4th International Conference on Optimization and Applications (ICOA)*,
    pages 1–6, April 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeBaron [2006] Blake LeBaron. Chapter 24 agent-based computational finance.
    In L. Tesfatsion and K.L. Judd, editors, *Handbook of Computational Economics*,
    volume 2 of *Handbook of Computational Economics*, pages 1187–1233\. Elsevier,
    2006.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chalup and Mitschele [2008] Stephan K. Chalup and Andreas Mitschele. Kernel
    methods in finance. In *Handbook on Information Technology in Finance*, pages
    655–687\. Springer Berlin Heidelberg, 2008.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. [2015] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning.
    *Nature*, 521(7553):436–444, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cybenko [1989] George Cybenko. Approximation by superpositions of a sigmoidal
    function. *Mathematics of control, signals and systems*, 2(4):303–314, 1989.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kalman and Kwasny [1992] Barry L Kalman and Stan C Kwasny. Why tanh: choosing
    a sigmoidal function. In *[Proceedings 1992] IJCNN International Joint Conference
    on Neural Networks*, volume 4, pages 578–581\. IEEE, 1992.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nair and Hinton [2010] Vinod Nair and Geoffrey E Hinton. Rectified linear units
    improve restricted boltzmann machines. In *Proceedings of the 27th international
    conference on machine learning (ICML-10)*, pages 807–814, 2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maas et al. [2013] Andrew L Maas, Awni Y Hannun, and Andrew Y Ng. Rectifier
    nonlinearities improve neural network acoustic models. In *Proc. icml*, volume 30,
    page 3, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ramachandran et al. [2017] Prajit Ramachandran, Barret Zoph, and Quoc V Le.
    Searching for activation functions. *arXiv preprint arXiv:1710.05941*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. [2016] Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
    *Deep Learning*. MIT Press, 2016. http://www.deeplearningbook.org.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hochreiter and Schmidhuber [1997] Sepp Hochreiter and Jürgen Schmidhuber. Long
    short-term memory. *Neural computation*, 9(8):1735–1780, 1997.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qiu et al. [2014] Xueheng Qiu, Le Zhang, Ye Ren, P. Suganthan, and Gehan Amaratunga.
    Ensemble deep learning for regression and time series forecasting. In *2014 IEEE
    Symposium on Computational Intelligence in Ensemble Learning (CIEL)*, pages 1–6,
    2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bengio [2012] Yoshua Bengio. Deep learning of representations for unsupervised
    and transfer learning. In *Proceedings of ICML workshop on unsupervised and transfer
    learning*, pages 17–36, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hinton et al. [2006] Geoffrey E. Hinton, Simon Osindero, and Yee-Whye Teh. A
    fast learning algorithm for deep belief nets. *Neural Computation*, 18(7):1527–1554,
    2006.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vincent et al. [2008] Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine
    Manzagol. Extracting and composing robust features with denoising autoencoders.
    In *Proceedings of the 25th international conference on Machine learning*, pages
    1096–1103\. ACM, 2008.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meng et al. [2017] Qinxue Meng, Daniel Catchpoole, David Skillicom, and Paul J
    Kennedy. Relational autoencoder for feature extraction. In *2017 International
    Joint Conference on Neural Networks (IJCNN)*, pages 364–371\. IEEE, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu et al. [2015] Yong Hu, Kang Liu, Xiangzhou Zhang, Lijun Su, E.W.T. Ngai,
    and Mei Liu. Application of evolutionary computation for rule discovery in stock
    algorithmic trading: A literature review. *Applied Soft Computing*, 36:534–551,
    November 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Karaoglu and Arpaci [2017] Sercan Karaoglu and Ugur Arpaci. A deep learning
    approach for optimization of systematic signal detection in financial trading
    systems with big data. *International Journal of Intelligent Systems and Applications
    in Engineering*, SpecialIssue(SpecialIssue):31–36, July 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bao et al. [2017] Wei Bao, Jun Yue, and Yulei Rao. A deep learning framework
    for financial time series using stacked autoencoders and long-short term memory.
    *PLOS ONE*, 12(7):e0180944, July 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2017] Shuanglong Liu, Chao Zhang, and Jinwen Ma. Cnn-lstm neural
    network model for quantitative strategy analysis in stock markets. In *Neural
    Information Processing*, pages 198–206\. Springer International Publishing, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2017] Liheng Zhang, Charu Aggarwal, and Guo-Jun Qi. Stock price
    prediction via discovering multi-frequency trading patterns. In *Proceedings of
    the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
    - KDD17*. ACM Press, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tran et al. [2017] Dat Thanh Tran, Martin Magris, Juho Kanniainen, Moncef Gabbouj,
    and Alexandros Iosifidis. Tensor representation in high-frequency financial data
    for price change prediction. In *2017 IEEE Symposium Series on Computational Intelligence
    (SSCI)*. IEEE, November 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deng et al. [2017] Yue Deng, Feng Bao, Youyong Kong, Zhiquan Ren, and Qionghai
    Dai. Deep direct reinforcement learning for financial signal representation and
    trading. *IEEE Transactions on Neural Networks and Learning Systems*, 28(3):653–664,
    March 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fischer and Krauss [2018] Thomas Fischer and Christopher Krauss. Deep learning
    with long short-term memory networks for financial market predictions. *European
    Journal of Operational Research*, 270(2):654–669, October 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mourelatos et al. [2018] Marios Mourelatos, Christos Alexakos, Thomas Amorgianiotis,
    and Spiridon Likothanassis. Financial indices modelling and trading utilizing
    deep learning techniques: The athens se ftse/ase large cap use case. In *2018
    Innovations in Intelligent Systems and Applications (INISTA)*. IEEE, July 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Si et al. [2017] Weiyu Si, Jinke Li, Peng Ding, and Ruonan Rao. A multi-objective
    deep reinforcement learning approach for stock index future’s intraday trading.
    In *2017 10th International Symposium on Computational Intelligence and Design
    (ISCID)*. IEEE, December 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yong et al. [2017] Bang Xiang Yong, Mohd Rozaini Abdul Rahim, and Ahmad Shahidan
    Abdullah. A stock market trading system using deep neural network. In *Communications
    in Computer and Information Science*, pages 356–364\. Springer Singapore, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu [2017] David W. Lu. Agent inspired trading using recurrent reinforcement
    learning and lstm neural networks, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dixon et al. [2016] Matthew Francis Dixon, Diego Klabjan, and Jin Hoon Bang.
    Classification-based financial markets prediction using deep neural networks.
    *SSRN Electronic Journal*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Korczak and Hernes [2017] Jerzy Korczak and Marcin Hernes. Deep learning for
    financial time series forecasting in a-trader system. In *Proceedings of the 2017
    Federated Conference on Computer Science and Information Systems*. IEEE, September
    2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spilak [2018] Bruno Spilak. Deep neural networks for cryptocurrencies price
    prediction. Master’s thesis, Humboldt-Universitat zu Berlin, Wirtschaftswissenschaftliche
    Fakultat, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jeong and Kim [2019] Gyeeun Jeong and Ha Young Kim. Improving financial trading
    decisions using deep q-learning: Predicting the number of shares, action strategies,
    and transfer learning. *Expert Systems with Applications*, 117:125–138, March
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Krauss et al. [2017] Christopher Krauss, Xuan Anh Do, and Nicolas Huck. Deep
    neural networks, gradient-boosted trees, random forests: Statistical arbitrage
    on the s&p 500. *European Journal of Operational Research*, 259(2):689–702, June
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] Google. System and method for computer managed funds to outperform benchmarks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sezer et al. [2017] Omer Berat Sezer, Murat Ozbayoglu, and Erdogan Dogdu. A
    deep neural-network based stock trading system based on evolutionary optimized
    technical analysis parameters. *Procedia Computer Science*, 114:473–480, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Navon and Keller [2017] Ariel Navon and Yosi Keller. Financial time series prediction
    using deep learning, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troiano et al. [2018] Luigi Troiano, Elena Mejuto Villa, and Vincenzo Loia.
    Replicating a trading strategy by means of lstm for financial industry applications.
    *IEEE Transactions on Industrial Informatics*, 14(7):3226–3234, July 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sirignano and Cont [2018] Justin Sirignano and Rama Cont. Universal features
    of price formation in financial markets: Perspectives from deep learning. *SSRN
    Electronic Journal*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tsantekidis et al. [2017a] Avraam Tsantekidis, Nikolaos Passalis, Anastasios
    Tefas, Juho Kanniainen, Moncef Gabbouj, and Alexandros Iosifidis. Using deep learning
    to detect price change indications in financial markets. In *2017 25th European
    Signal Processing Conference (EUSIPCO)*. IEEE, August 2017a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gudelek et al. [2017] M. Ugur Gudelek, S. Arda Boluk, and A. Murat Ozbayoglu.
    A deep learning based stock trading model with 2-d cnn trend detection. In *2017
    IEEE Symposium Series on Computational Intelligence (SSCI)*. IEEE, November 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sezer and Ozbayoglu [2018] Omer Berat Sezer and Ahmet Murat Ozbayoglu. Algorithmic
    financial trading with deep convolutional neural networks: Time series to image
    conversion approach. *Applied Soft Computing*, 70:525–538, September 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu et al. [2018a] Guosheng Hu, Yuxin Hu, Kai Yang, Zehao Yu, Flood Sung, Zhihong
    Zhang, Fei Xie, Jianguo Liu, Neil Robertson, Timpathy Hospedales, and Qiangwei
    Miemie. Deep stock representation learning: From candlestick charts to investment
    decisions. In *2018 IEEE International Conference on Acoustics, Speech and Signal
    Processing (ICASSP)*. IEEE, April 2018a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tsantekidis et al. [2017b] Avraam Tsantekidis, Nikolaos Passalis, Anastasios
    Tefas, Juho Kanniainen, Moncef Gabbouj, and Alexandros Iosifidis. Forecasting
    stock prices from the limit order book using convolutional neural networks. In
    *2017 IEEE 19th Conference on Business Informatics (CBI)*. IEEE, July 2017b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gunduz et al. [2017] Hakan Gunduz, Yusuf Yaslan, and Zehra Cataltepe. Intraday
    prediction of borsa istanbul using convolutional neural networks and feature correlations.
    *Knowledge-Based Systems*, 137:138–148, December 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sezer and Ozbayoglu [2019] Omer Berat Sezer and Ahmet Murat Ozbayoglu. Financial
    trading model with stock bar chart image time series with deep convolutional neural
    networks. *arXiv preprint arXiv:1903.04610*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Serrano [2018] Will Serrano. Fintech model: The random neural network with
    genetic algorithm. *Procedia Computer Science*, 126:537–546, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saad et al. [1998] E.W. Saad, D.V. Prokhorov, and D.C. Wunsch. Comparative study
    of stock trend prediction using time delay, recurrent and probabilistic neural
    networks. *IEEE Transactions on Neural Networks*, 9(6):1456–1470, 1998.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doering et al. [2017] Jonathan Doering, Michael Fairbank, and Sheri Markose.
    Convolutional neural networks applied to high-frequency market microstructure
    forecasting. In *2017 9th Computer Science and Electronic Engineering (CEEC)*.
    IEEE, September 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. [2017] Zhengyao Jiang, Dixing Xu, and Jinjun Liang. A deep reinforcement
    learning framework for the financial portfolio management problem. *arXiv preprint
    arXiv:1706.10059*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tino et al. [2001] P. Tino, C. Schittenkopf, and G. Dorffner. Financial volatility
    trading using recurrent neural networks. *IEEE Transactions on Neural Networks*,
    12(4):865–874, July 2001.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2018a] Yu-Ying Chen, Wei-Lun Chen, and Szu-Hao Huang. Developing
    arbitrage strategy in high-frequency pairs trading with filterbank cnn algorithm.
    In *2018 IEEE International Conference on Agents (ICA)*. IEEE, July 2018a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bari and Agah [2018] Omar A. Bari and Arvin Agah. Ensembles of text and time-series
    models for automatic generation of financial trading signals from social media
    content. *Journal of Intelligent Systems*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dixon [2017] Matthew Francis Dixon. Sequence classification of the limit order
    book using recurrent neural networks. *SSRN Electronic Journal*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2018b] Chiao-Ting Chen, An-Pin Chen, and Szu-Hao Huang. Cloning
    strategies from trading records using agent-based reinforcement learning algorithm.
    In *2018 IEEE International Conference on Agents (ICA)*. IEEE, July 2018b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2018a] Yue Wang, Chenwei Zhang, Shen Wang, Philip S. Yu, Lu Bai,
    and Lixin Cui. Deep co-investment network learning for financial assets, 2018a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Day and Lee [2016] Min-Yuh Day and Chia-Chou Lee. Deep learning for financial
    sentiment analysis on finance news providers. In *2016 IEEE/ACM International
    Conference on Advances in Social Networks Analysis and Mining (ASONAM)*. IEEE,
    August 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sirignano [2016] Justin Sirignano. Deep learning for limit order books, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao [2018] Xiang Gao. Deep reinforcement learning for time series: playing
    idealized trading games, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baily et al. [2008] Martin Neil Baily, Robert E. Litan, and Johnson Matthew
    S. The origins of the financial crisis. *Initiative on Business and Public Policy
    at Brookings, Fixing Finance Series - Paper 3*, 2008.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luo et al. [2017] Cuicui Luo, Desheng Wu, and Dexiang Wu. A deep learning approach
    for credit scoring using credit default swaps. *Engineering Applications of Artificial
    Intelligence*, 65:465–470, October 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu et al. [2018] Lean Yu, Rongtian Zhou, Ling Tang, and Rongda Chen. A dbn-based
    resampling svm ensemble learning paradigm for credit classification with imbalanced
    data. *Applied Soft Computing*, 69:192–202, August 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2017a] Ying Li, Xianghong Lin, Xiangwen Wang, Fanqi Shen, and Zuzheng
    Gong. Credit risk assessment algorithm using deep neural networks with clustering
    and merging. In *2017 13th International Conference on Computational Intelligence
    and Security (CIS)*. IEEE, December 2017a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tran et al. [2016] Khiem Tran, Thanh Duong, and Quyen Ho. Credit scoring model:
    A combination of genetic programming and deep learning. In *2016 Future Technologies
    Conference (FTC)*. IEEE, December 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neagoe et al. [2018] Victor-Emil Neagoe, Adrian-Dumitru Ciotec, and George-Sorin
    Cucu. Deep convolutional neural networks versus multilayer perceptron for financial
    prediction. In *2018 International Conference on Communications (COMM)*. IEEE,
    June 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. [2018] Bing Zhu, Wenchuan Yang, Huaxuan Wang, and Yuan Yuan. A hybrid
    deep learning model for consumer credit scoring. In *2018 International Conference
    on Artificial Intelligence and Big Data (ICAIBD)*. IEEE, May 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Niimi [2015] Ayahiko Niimi. Deep learning for credit card data analysis. In
    *2015 World Congress on Internet Security (WorldCIS)*. IEEE, October 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kirkos and Manolopoulos [2004] Efstathios Kirkos and Yannis Manolopoulos. Data
    mining in finance and accounting: A review of current research trends. In *Proceedings
    of the 1 st International Conference on Enterprise Systems and Accounting (ICESAcc*,
    pages 63–78, 2004.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ravi et al. [2008] V. Ravi, H. Kurniawan, Peter Nwee Kok Thai, and P. Ravi Kumar.
    Soft computing system for bank performance prediction. *Applied Soft Computing*,
    8(1):305–315, January 2008.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fethi and Pasiouras [2010] Meryem Duygun Fethi and Fotios Pasiouras. Assessing
    bank efficiency and performance with operational research and artificial intelligence
    techniques: A survey. *European Journal of Operational Research*, 204(2):189–198,
    July 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lahsasna et al. [2010] Adel Lahsasna, Raja Noor Ainon, and Ying Wah Teh. Credit
    scoring models using soft computing methods: A survey. *Int. Arab J. Inf. Technol.*,
    7:115–123, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. [2015] Ning Chen, Bernardete Ribeiro, and An Chen. Financial credit
    risk assessment: a recent review. *Artificial Intelligence Review*, 45(1):1–23,
    October 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marques et al. [2013] AI Marques, Vicente García, and José Salvador Sánchez.
    A literature review on the application of evolutionary computing to credit scoring.
    *Journal of the Operational Research Society*, 64(9):1384–1399, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kumar and Ravi [2007] P. Ravi Kumar and V. Ravi. Bankruptcy prediction in banks
    and firms via statistical and intelligent techniques – a review. *European Journal
    of Operational Research*, 180(1):1–28, July 2007.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Verikas et al. [2009] Antanas Verikas, Zivile Kalsyte, Marija Bacauskiene,
    and Adas Gelzinis. Hybrid and ensemble-based soft computing techniques in bankruptcy
    prediction: a survey. *Soft Computing*, 14(9):995–1010, September 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. [2014] Jie Sun, Hui Li, Qing-Hua Huang, and Kai-Yu He. Predicting
    financial distress and corporate failure: A review from the state-of-the-art definitions,
    modeling, sampling, and featuring approaches. *Knowledge-Based Systems*, 57:41–56,
    February 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. [2012] W. Lin, Y. Hu, and C. Tsai. Machine learning in financial
    crisis prediction: A survey. *IEEE Transactions on Systems, Man, and Cybernetics,
    Part C (Applications and Reviews)*, 42(4):421–436, July 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lanbouri and Achchab [2015] Zineb Lanbouri and Said Achchab. A hybrid deep
    belief network approach for financial distress prediction. In *2015 10th International
    Conference on Intelligent Systems: Theories and Applications (SITA)*. IEEE, October
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rawte et al. [2018] Vipula Rawte, Aparna Gupta, and Mohammed J. Zaki. Analysis
    of year-over-year changes in risk factors disclosure in 10-k filings. In *Proceedings
    of the Fourth International Workshop on Data Science for Macro-Modeling with Financial
    and Economic Datasets - DSMM18*. ACM Press, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ronnqvist and Sarlin [2015] Samuel Ronnqvist and Peter Sarlin. Detect & describe:
    Deep learning of bank stress in the news. In *2015 IEEE Symposium Series on Computational
    Intelligence*. IEEE, December 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ronnqvist and Sarlin [2017] Samuel Ronnqvist and Peter Sarlin. Bank distress
    in the news: Describing events through deep learning. *Neurocomputing*, 264:57–70,
    November 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cerchiello et al. [2017] Paola Cerchiello, Giancarlo Nicola, Samuel Rönnqvist,
    and Peter Sarlin. Deep learning bank distress from news and numerical financial
    data. *CoRR*, abs/1706.09627, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Malik et al. [2018] Nikhil Malik, Param Vir Singh, and Urooj Khan. Can banks
    survive the next financial crisis? an adversarial deep learning model for bank
    stress testing. *An Adversarial Deep Learning Model for Bank Stress Testing (June
    30, 2018)*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ribeiro and Lopes [2011] Bernardete Ribeiro and Noel Lopes. Deep belief networks
    for financial prediction. In *Neural Information Processing*, pages 766–773\.
    Springer Berlin Heidelberg, 2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yeh et al. [2015] Shu-Hao Yeh, Chuan-Ju Wang, and Ming-Feng Tsai. Deep belief
    networks for predicting corporate defaults. In *2015 24th Wireless and Optical
    Communication Conference (WOCC)*. IEEE, October 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hosaka [2018] Tadaaki Hosaka. Bankruptcy prediction using imaged financial ratios
    and convolutional neural networks. *Expert Systems with Applications*, September
    2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sirignano et al. [2018] Justin Sirignano, Apaar Sadhwani, and Kay Giesecke.
    Deep learning for mortgage risk. *SSRN Electronic Journal*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kvamme et al. [2018] Håvard Kvamme, Nikolai Sellereite, Kjersti Aas, and Steffen
    Sjursen. Predicting mortgage default using convolutional neural networks. *Expert
    Systems with Applications*, 102:207–217, July 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: and [2017] Narek Abroyan and. Neural networks for financial market risk classification.
    *Frontiers in Signal Processing*, 1(2), August 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chatzis et al. [2018] Sotirios P. Chatzis, Vassilis Siakoulis, Anastasios Petropoulos,
    Evangelos Stavroulakis, and Nikos Vlachogiannakis. Forecasting stock market crisis
    events using deep and statistical machine learning techniques. *Expert Systems
    with Applications*, 112:353–371, December 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kirkos et al. [2007] E Kirkos, C Spathis, and Y Manolopoulos. Data mining techniques
    for the detection of fraudulent financial statements. *Expert Systems with Applications*,
    32(4):995–1003, May 2007.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yue et al. [2007] Dianmin Yue, Xiaodan Wu, Yunfeng Wang, Yue Li, and Chao-Hsien
    Chu. A review of data mining-based financial fraud detection research. In *2007
    International Conference on Wireless Communications, Networking and Mobile Computing*.
    IEEE, September 2007.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang [2010] Shiguo Wang. A comprehensive survey of data mining-based accounting-fraud
    detection research. In *2010 International Conference on Intelligent Computation
    Technology and Automation*. IEEE, May 2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phua et al. [2010] Clifton Phua, Vincent C. S. Lee, Kate Smith-Miles, and Ross W.
    Gayler. A comprehensive survey of data mining-based fraud detection research.
    *CoRR*, abs/1009.6119, 2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ngai et al. [2011] E.W.T. Ngai, Yong Hu, Y.H. Wong, Yijun Chen, and Xin Sun.
    The application of data mining techniques in financial fraud detection: A classification
    framework and an academic review of literature. *Decision Support Systems*, 50(3):559–569,
    February 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharma and Panigrahi [2012] Anuj Sharma and Prabin Kumar Panigrahi. A review
    of financial accounting fraud detection based on data mining techniques. *International
    Journal of Computer Applications*, 39(1):37–47, February 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'West and Bhattacharya [2016] Jarrod West and Maumita Bhattacharya. Intelligent
    financial fraud detection: A comprehensive review. *Computers & Security*, 57:47–66,
    March 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heryadi and Warnars [2017] Yaya Heryadi and Harco Leslie Hendric Spits Warnars.
    Learning temporal representation of transaction amount for fraudulent transaction
    recognition using cnn, stacked lstm, and cnn-lstm. In *2017 IEEE International
    Conference on Cybernetics and Computational Intelligence (CyberneticsCom)*. IEEE,
    November 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roy et al. [2018] Abhimanyu Roy, Jingyi Sun, Robert Mahoney, Loreto Alonzi,
    Stephen Adams, and Peter Beling. Deep learning detecting fraud in credit card
    transactions. In *2018 Systems and Information Engineering Design Symposium (SIEDS)*.
    IEEE, April 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gómez et al. [2018] Jon Ander Gómez, Juan Arévalo, Roberto Paredes, and Jordi
    Nin. End-to-end neural network architecture for fraud scoring in card payments.
    *Pattern Recognition Letters*, 105:175–181, April 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sohony et al. [2018] Ishan Sohony, Rameshwar Pratap, and Ullas Nambiar. Ensemble
    learning for credit card fraud detection. In *Proceedings of the ACM India Joint
    International Conference on Data Science and Management of Data - CoDS-COMAD18*.
    ACM Press, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jurgovsky et al. [2018] Johannes Jurgovsky, Michael Granitzer, Konstantin Ziegler,
    Sylvie Calabretto, Pierre-Edouard Portier, Liyun He-Guelton, and Olivier Caelen.
    Sequence classification for credit-card fraud detection. *Expert Systems with
    Applications*, 100:234–245, June 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paula et al. [2016] Ebberth L. Paula, Marcelo Ladeira, Rommel N. Carvalho, and
    Thiago Marzagao. Deep learning anomaly detection as support fraud investigation
    in brazilian exports and anti-money laundering. In *2016 15th IEEE International
    Conference on Machine Learning and Applications (ICMLA)*. IEEE, December 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gomes et al. [2017] Thiago Alencar Gomes, Rommel Novaes Carvalho, and Ricardo Silva
    Carvalho. Identifying anomalies in parliamentary expenditures of brazilian chamber
    of deputies with deep autoencoders. In *2017 16th IEEE International Conference
    on Machine Learning and Applications (ICMLA)*. IEEE, December 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang and Xu [2018] Yibo Wang and Wei Xu. Leveraging deep learning with lda-based
    text analytics to detect automobile insurance fraud. *Decision Support Systems*,
    105:87–95, January 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. [2017b] Longfei Li, Jun Zhou, Xiaolong Li, and Tao Chen. Poster:
    Practical fraud transaction prediction. In *ACM Conference on Computer and Communications
    Security*, 2017b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: de Souza Costa and Silva [2016] Allan Inocencio de Souza Costa and Luis Silva.
    Sequence classification of the limit order book using recurrent neural networks.
    2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goumagias et al. [2018] Nikolaos D. Goumagias, Dimitrios Hristu-Varsakelis,
    and Yannis M. Assael. Using deep q-learning to understand the tax evasion behavior
    of risk-averse firms. *Expert Systems with Applications*, 101:258–270, July 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li and Hoi [2014] Bin Li and Steven C. H. Hoi. Online portfolio selection:
    A survey. *ACM Comput. Surv.*, 46(3):35:1–35:36, January 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Metaxiotis and Liagkouras [2012] K. Metaxiotis and K. Liagkouras. Multiobjective
    evolutionary algorithms for portfolio management: A comprehensive literature review.
    *Expert Systems with Applications*, 39(14):11685–11698, October 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Takeuchi [2013] Lawrence Takeuchi. Applying deep learning to enhance momentum
    trading strategies in stocks. 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grace [2017] Anthony Grace. Can deep learning techniques improve the risk adjusted
    returns from enhanced indexing investment strategies. Master’s thesis, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fu et al. [2018] XingYu Fu, JinHong Du, YiFeng Guo, MingWen Liu, Tao Dong, and
    XiuWen Duan. A machine learning framework for stock selection, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggarwal and Aggarwal [2017] Saurabh Aggarwal and Somya Aggarwal. Deep investment
    in financial markets using deep learning models. *International Journal of Computer
    Applications*, 162(2):40–43, March 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Heaton and Polson [2016] J.B. Heaton and Nick Polson. Deep learning for finance:
    Deep portfolios. *SSRN Electronic Journal*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. [2006] Chi-Ming Lin, Jih-Jeng Huang, Mitsuo Gen, and Gwo-Hshiung
    Tzeng. Recurrent neural network for dynamic portfolio selection. *Applied Mathematics
    and Computation*, 175(2):1139–1146, April 2006.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maknickienė [2014] Nijolė Maknickienė. Selection of orthogonal investment portfolio
    using evolino rnn trading model. *Procedia - Social and Behavioral Sciences*,
    110:1158–1165, January 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou [2018] Bo Zhou. Deep learning and the cross-section of stock returns:
    Neural networks combining price and fundamental information. *SSRN Electronic
    Journal*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Batres-Estrada [2015] Bilberto Batres-Estrada. Deep learning for multivariate
    financial time series. Master’s thesis, KTH, Mathematical Statistics, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee and Yoo [2018] Sang Il Lee and Seong Joon Yoo. Threshold-based portfolio:
    the role of the threshold and its applications. *The Journal of Supercomputing*,
    September 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iwasaki and Chen [2018] Hitoshi Iwasaki and Ying Chen. Topic sentiment asset
    pricing with dnn supervised learning. *SSRN Electronic Journal*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. [2018] Zhipeng Liang, Hao Chen, Junhao Zhu, Kangkang Jiang, and
    Yanran Li. Adversarial deep reinforcement learning in portfolio management, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. [2016] Jiaqi Chen, Wenbo Wu, and Michael Tindall. Hedge fund return
    prediction and fund selection: A machine-learning approach. Occasional Papers
    16-4, Federal Reserve Bank of Dallas, November 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang and Liang [2017] Zhengyao Jiang and Jinjun Liang. Cryptocurrency portfolio
    management with deep reinforcement learning. In *2017 Intelligent Systems Conference
    (IntelliSys)*. IEEE, September 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maknickiene et al. [2014] Nijole Maknickiene, Aleksandras Vytautas Rutkauskas,
    and Algirdas Maknickas. Investigation of financial market prediction by recurrent
    neural network. 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Culkin and Das [2017] Robert Culkin and Sanjiv R. Das. Machine learning in
    finance: The case of deep learning in option pricing. 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hsu et al. [2018] Pei-Ying Hsu, Chin Chou, Szu-Hao Huang, and An-Pin Chen. A
    market making quotation strategy based on dual deep learning agents for option
    pricing and bid-ask spread estimation. In *2018 IEEE International Conference
    on Agents (ICA)*. IEEE, July 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feng et al. [2018] Guanhao Feng, Nicholas G. Polson, and Jianeng Xu. Deep factor
    alpha, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen [2018] Rui-Yang Chen. A traceability chain algorithm for artificial neural
    networks using t–s fuzzy cognitive maps in blockchain. *Future Generation Computer
    Systems*, 80:198–210, March 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nan and Tao [2018] Lihao Nan and Dacheng Tao. Bitcoin mixing detection using
    deep autoencoder. In *2018 IEEE Third International Conference on Data Science
    in Cyberspace (DSC)*. IEEE, June 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lopes [2018] Gonçalo Duarte Lima Freire Lopes. Deep learning for market forecasts.
    2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: McNally et al. [2018] Sean McNally, Jason Roche, and Simon Caton. Predicting
    the price of bitcoin using machine learning. In *2018 26th Euromicro International
    Conference on Parallel, Distributed and Network-based Processing (PDP)*. IEEE,
    March 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kearney and Liu [2014] Colm Kearney and Sha Liu. Textual sentiment in finance:
    A survey of methods and models. *International Review of Financial Analysis*,
    33:171–185, May 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2018b] Qili Wang, Wei Xu, and Han Zheng. Combining the wisdom of
    crowds and technical analysis for financial market prediction using deep random
    subspace ensembles. *Neurocomputing*, 299:51–61, July 2018b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shi et al. [2018] Lei Shi, Zhiyang Teng, Le Wang, Yue Zhang, and Alexander
    Binder. Deepclue: Visual interpretation of text-based deep stock prediction. *IEEE
    Transactions on Knowledge and Data Engineering*, pages 1–1, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peng and Jiang [2016] Yangtuo Peng and Hui Jiang. Leverage financial news to
    predict stock price movements using word embeddings and deep neural networks.
    In *Proceedings of the 2016 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*. Association for Computational
    Linguistics, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhuge et al. [2017] Qun Zhuge, Lingyu Xu, and Gaowei Zhang. Lstm neural network
    with emotional analysis for prediction of stock price. 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhongshengz [2018] Zhongshengz. Measuring financial crisis index for risk warning
    through analysis of social network. Master’s thesis, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Das et al. [2018] Sushree Das, Ranjan Kumar Behera, Mukesh Kumar, and Santanu Kumar
    Rath. Real-time sentiment analysis of twitter streaming data for stock prediction.
    *Procedia Computer Science*, 132:956–964, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prosky et al. [2017] Jordan Prosky, Xingyou Song, Andrew Tan, and Michael Zhao.
    Sentiment predictability for stocks. *CoRR*, abs/1712.05785, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. [2017c] Jiahong Li, Hui Bu, and Junjie Wu. Sentiment-aware stock
    market prediction: A deep learning method. In *2017 International Conference on
    Service Systems and Service Management*. IEEE, June 2017c.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. [2016] Yifu Huang, Kai Huang, Yang Wang, Hao Zhang, Jihong Guan,
    and Shuigeng Zhou. Exploiting twitter moods to boost financial trend prediction
    based on deep network models. In *Intelligent Computing Methodologies*, pages
    449–460. Springer International Publishing, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mitra and Mitra [2012] Leela Mitra and Gautam Mitra. Applications of news analytics
    in finance: A review. In *The Handbook of News Analytics in Finance*, pages 1–39.
    John Wiley & Sons, Ltd., May 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li [2011] Feng Li. Textual analysis of corporate disclosures: A survey of the
    literature. *Journal of Accounting Literature*, 29, February 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Loughran and McDonald [2016] Tim Loughran and Bill McDonald. Textual analysis
    in accounting and finance: A survey. *Journal of Accounting Research*, 54(4):1187–1230,
    June 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kumar and Ravi [2016] B. Shravan Kumar and Vadlamani Ravi. A survey of the applications
    of text mining in financial domain. *Knowledge-Based Systems*, 114:128–147, December
    2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mittermayer and F Knolmayer [2006] Marc-André Mittermayer and Gerhard F Knolmayer.
    Text mining systems for market response to news: A survey. September 2006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nassirtoussi et al. [2014] Arman Khadjeh Nassirtoussi, Saeed Aghabozorgi, Teh Ying
    Wah, and David Chek Ling Ngo. Text mining for market prediction: A systematic
    review. *Expert Systems with Applications*, 41(16):7653–7670, November 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huynh et al. [2017] Huy D. Huynh, L. Minh Dang, and Duc Duong. A new model for
    stock price movements prediction using deep neural network. In *Proceedings of
    the Eighth International Symposium on Information and Communication Technology
    - SoICT 2017*. ACM Press, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Han et al. [2018] Songqiao Han, Xiaoling Hao, and Hailiang Huang. An event-extraction
    approach for business analysis from online chinese news. *Electronic Commerce
    Research and Applications*, 28:244–260, March 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kraus and Feuerriegel [2017] Mathias Kraus and Stefan Feuerriegel. Decision
    support from financial disclosures with deep neural networks and transfer learning.
    *Decision Support Systems*, 104:38–48, December 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dang et al. [2018] L. Minh Dang, Abolghasem Sadeghi-Niaraki, Huy D. Huynh, Kyungbok
    Min, and Hyeonjoon Moon. Deep learning approach for short-term stock trends prediction
    based on two-stream gated recurrent unit network. *IEEE Access*, pages 1–1, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ding et al. [2015] Xiao Ding, Yue Zhang, Ting Liu, and Junwen Duan. Deep learning
    for event-driven stock prediction. In *Proceedings of the 24th International Conference
    on Artificial Intelligence*, IJCAI’15, pages 2327–2333\. AAAI Press, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vargas et al. [2017] Manuel R. Vargas, Beatriz S. L. P. de Lima, and Alexandre G.
    Evsukoff. Deep learning for stock market prediction from financial news articles.
    In *2017 IEEE International Conference on Computational Intelligence and Virtual
    Environments for Measurement Systems and Applications (CIVEMSA)*. IEEE, June 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akita et al. [2016] Ryo Akita, Akira Yoshihara, Takashi Matsubara, and Kuniaki
    Uehara. Deep learning for stock prediction using numerical and textual information.
    In *2016 IEEE/ACIS 15th International Conference on Computer and Information Science
    (ICIS)*. IEEE, June 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verma et al. [2017] Ishan Verma, Lipika Dey, and Hardik Meisheri. Detecting,
    quantifying and accessing impact of news events on indian stock indices. In *Proceedings
    of the International Conference on Web Intelligence - WI17*. ACM Press, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2018] Xi Zhang, Yunjia Zhang, Senzhang Wang, Yuntao Yao, Binxing
    Fang, and Philip S. Yu. Improving stock market prediction via heterogeneous information
    fusion. *Knowledge-Based Systems*, 143:236–247, March 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2018c] Weiling Chen, Chai Kiat Yeo, Chiew Tong Lau, and Bu Sung
    Lee. Leveraging social media news to predict stock index movement using rnn-boost.
    *Data & Knowledge Engineering*, August 2018c.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu et al. [2018b] Ziniu Hu, Weiqing Liu, Jiang Bian, Xuanzhe Liu, and Tie-Yan
    Liu. Listening to chaotic whispers: A deep learning framework for news-oriented
    stock trend prediction. In *Proceedings of the Eleventh ACM International Conference
    on Web Search and Data Mining*, WSDM ’18, pages 261–269, New York, NY, USA, 2018b.
    ACM.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2018] Xiaodong Li, Jingjing Cao, and Zhaoqing Pan. Market impact
    analysis via deep learned architectures. *Neural Computing and Applications*,
    March 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee and Soo [2017] Che-Yu Lee and Von-Wun Soo. Predict stock price with financial
    news based on recurrent convolutional neural networks. In *2017 Conference on
    Technologies and Applications of Artificial Intelligence (TAAI)*. IEEE, December
    2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minami [2018] Shotaro Minami. Predicting equity price with corporate action
    events using lstm-rnn. *Journal of Mathematical Finance*, 08(01):58–63, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yoshihara et al. [2014] Akira Yoshihara, Kazuki Fujikawa, Kazuhiro Seki, and
    Kuniaki Uehara. Predicting stock market trends by recurrent deep neural networks.
    In *Lecture Notes in Computer Science*, pages 759–769\. Springer International
    Publishing, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buczkowski [2017] Przemyslaw Buczkowski. Predicting stock trends based on expert
    recommendations using gru/lstm neural networks. In *Lecture Notes in Computer
    Science*, pages 708–717\. Springer International Publishing, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'dos Santos Pinheiro and Dras [2017] Leonardo dos Santos Pinheiro and Mark Dras.
    Stock market prediction with deep learning: A character-based neural language
    model for event-based trading. In *Proceedings of the Australasian Language Technology
    Association Workshop 2017*, pages 6–15, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2018] Yang Liu, Qingguo Zeng, Huanrui Yang, and Adrian Carrio. Stock
    price movement prediction from financial news with deep learning and knowledge
    graph embedding. In *Knowledge Management and Acquisition for Intelligent Systems*,
    pages 102–113\. Springer International Publishing, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matsubara et al. [2018] Takashi Matsubara, Ryo Akita, and Kuniaki Uehara. Stock
    price prediction by deep neural generative model of news articles. *IEICE Transactions
    on Information and Systems*, E101.D(4):901–908, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nascimento and Cristo [2015] Janderson B. Nascimento and Marco Cristo. The impact
    of structured event embeddings on scalable stock forecasting models. In *Proceedings
    of the 21st Brazilian Symposium on Multimedia and the Web - WebMedia15*. ACM Press,
    2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akhtar et al. [2017] Md Shad Akhtar, Abhishek Kumar, Deepanway Ghosal, Asif
    Ekbal, and Pushpak Bhattacharyya. A multilayer perceptron based ensemble technique
    for fine-grained financial sentiment analysis. In *Proceedings of the 2017 Conference
    on Empirical Methods in Natural Language Processing*, pages 540–546\. Association
    for Computational Linguistics, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chang et al. [2016] Ching-Yun Chang, Yue Zhang, Zhiyang Teng, Zahn Bozanic,
    and Bin Ke. Measuring the information content of financial news. In *COLING*,
    2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jangid et al. [2018] Hitkul Jangid, Shivangi Singhal, Rajiv Ratn Shah, and Roger
    Zimmermann. Aspect-based financial sentiment analysis using deep learning. In
    *Companion of the The Web Conference 2018 on The Web Conference 2018 - WWW18*.
    ACM Press, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: E. et al. [2018] Shijia E., Li Yang, Mohan Zhang, and Yang Xiang. Aspect-based
    financial sentiment analysis with deep neural networks. In *Companion of the The
    Web Conference 2018 on The Web Conference 2018 - WWW18*. ACM Press, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sohangir et al. [2018] Sahar Sohangir, Dingding Wang, Anna Pomeranets, and
    Taghi M. Khoshgoftaar. Big data: Deep learning for financial sentiment analysis.
    *Journal of Big Data*, 5(1), January 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mahmoudi et al. [2018] Nader Mahmoudi, Paul Docherty, and Pablo Moscato. Deep
    neural networks understand investors better. *Decision Support Systems*, 112:23–34,
    August 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kitamori et al. [2017] Shiori Kitamori, Hiroyuki Sakai, and Hiroki Sakaji. Extraction
    of sentences concerning business performance forecast and economic forecast from
    summaries of financial statements by deep learning. In *2017 IEEE Symposium Series
    on Computational Intelligence (SSCI)*. IEEE, November 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Piao and Breslin [2018] Guangyuan Piao and John G. Breslin. Financial aspect
    and sentiment predictions with deep neural networks. In *Companion of the The
    Web Conference 2018 on The Web Conference 2018 - WWW18*. ACM Press, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li and Chen [2014] Weifeng Li and Hsinchun Chen. Identifying top sellers in
    underground economy using deep learning-based sentiment analysis. In *2014 IEEE
    Joint Intelligence and Security Informatics Conference*. IEEE, September 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Moore and Rayson [2017] Andrew Moore and Paul Rayson. Lancaster a at semeval-2017
    task 5: Evaluation metrics matter: predicting sentiment from financial news headlines.
    In *Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)*,
    pages 581–585, Vancouver, Canada, August 2017. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ying et al. [2017] Josh Jia-Ching Ying, Po-Yu Huang, Chih-Kai Chang, and Don-Lin
    Yang. A preliminary study on deep learning for predicting social insurance payment
    behavior. In *2017 IEEE International Conference on Big Data (Big Data)*. IEEE,
    December 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sohangir and Wang [2018] Sahar Sohangir and Dingding Wang. Finding expert authors
    in financial forum using deep learning methods. In *2018 Second IEEE International
    Conference on Robotic Computing (IRC)*. IEEE, January 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sokolov [2017] Vadim Sokolov. Discussion of ’deep learning for finance: deep
    portfolios’. *Applied Stochastic Models in Business and Industry*, 33(1):16–18,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bouchti et al. [2017] Abdelali El Bouchti, Ahmed Chakroun, Hassan Abbar, and
    Chafik Okar. Fraud detection in banking using deep reinforcement learning. In
    *2017 Seventh International Conference on Innovative Computing Technology (INTECH)*.
    IEEE, August 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dixon et al. [2015] Matthew Dixon, Diego Klabjan, and Jin Hoon Bang. Implementing
    deep neural networks for financial market prediction on the intel xeon phi. In
    *Proceedings of the 8th Workshop on High Performance Computational Finance - WHPCF15*.
    ACM Press, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alberg and Lipton [2017] John Alberg and Zachary Chase Lipton. Improving factor-based
    quantitative investing by forecasting company fundamentals. *CoRR*, abs/1711.04837,
    2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. [2015] Kee-Hoon Kim, Chang-Seok Lee, Sang-Muk Jo, and Sung-Bae Cho.
    Predicting the success of bank telemarketing using deep convolutional neural network.
    In *2015 7th International Conference of Soft Computing and Pattern Recognition
    (SoCPaR)*. IEEE, November 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee et al. [2017] Joonhyuck Lee, Dong Sik Jang, and Sangsung Park. Deep learning-based
    corporate performance prediction model considering technical capability. *Sustainability*,
    9(6), May 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
