- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:02:33'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:02:33
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2002.05786] Deep Learning for Financial Applications : A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2002.05786] 深度学习在金融应用中的应用：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2002.05786](https://ar5iv.labs.arxiv.org/html/2002.05786)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2002.05786](https://ar5iv.labs.arxiv.org/html/2002.05786)
- en: 'Deep Learning for Financial Applications : A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在金融应用中的应用：综述
- en: Ahmet Murat Ozbayoglu Mehmet Ugur Gudelek Omer Berat Sezer Department of Computer
    Engineering, TOBB University of Economics and Technology, Ankara, Turkey
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Ahmet Murat Ozbayoglu Mehmet Ugur Gudelek Omer Berat Sezer 土耳其安卡拉 TOBB 经济与技术大学计算机工程系
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Computational intelligence in finance has been a very popular topic for both
    academia and financial industry in the last few decades. Numerous studies have
    been published resulting in various models. Meanwhile, within the [Machine Learning
    (ML)](#glo.main.ml) field, [Deep Learning (DL)](#glo.main.dl) started getting
    a lot of attention recently, mostly due to its outperformance over the classical
    models. Lots of different implementations of [DL](#glo.main.dl) exist today, and
    the broad interest is continuing. Finance is one particular area where [DL](#glo.main.dl)
    models started getting traction, however, the playfield is wide open, a lot of
    research opportunities still exist. In this paper, we tried to provide a state-of-the-art
    snapshot of the developed [DL](#glo.main.dl) models for financial applications,
    as of today. We not only categorized the works according to their intended subfield
    in finance but also analyzed them based on their [DL](#glo.main.dl) models. In
    addition, we also aimed at identifying possible future implementations and highlighted
    the pathway for the ongoing research within the field.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几十年里，金融领域的计算智能一直是学术界和金融行业非常热门的话题。大量研究已发表，形成了各种模型。同时，在[机器学习（ML）](#glo.main.ml)领域，[深度学习（DL）](#glo.main.dl)
    最近开始受到越来越多的关注，主要是因为其在表现上超越了传统模型。今天存在许多不同的[DL](#glo.main.dl) 实现，广泛的兴趣仍在持续。金融是[DL](#glo.main.dl)
    模型开始受到关注的一个特定领域，但这个领域仍然广阔，仍有许多研究机会。在本文中，我们试图提供当前为金融应用开发的[DL](#glo.main.dl) 模型的最先进快照。我们不仅根据金融领域的子领域对工作进行了分类，还根据[DL](#glo.main.dl)
    模型对其进行了分析。此外，我们还旨在识别可能的未来实现，并突出研究领域内正在进行的研究路径。
- en: 'keywords:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: deep learning , finance , computational intelligence , machine learning , financial
    applications , algorithmic trading , portfolio management , risk assesment , fraud
    detection
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习，金融，计算智能，机器学习，金融应用，算法交易，投资组合管理，风险评估，欺诈检测
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Stock market forecasting, algorithmic trading, credit risk assessment, portfolio
    allocation, asset pricing and derivatives market are among the areas where [ML](#glo.main.ml)
    researchers focused on developing models that can provide real-time working solutions
    for the financial industry. Hence, a lot of publications and implementations exist
    in the literature.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 股票市场预测、算法交易、信用风险评估、投资组合分配、资产定价和衍生品市场是[ML](#glo.main.ml)研究人员专注于开发可以为金融行业提供实时工作解决方案的模型的领域。因此，文献中存在大量的出版物和实现。
- en: However, within the [ML](#glo.main.ml) field, [DL](#glo.main.dl) is an emerging
    area with a rising interest every year. As a result, an increasing number of [DL](#glo.main.dl)
    models for finance started appearing in conferences and journals. Our focus in
    this paper is to present different implementations of the developed financial
    [DL](#glo.main.dl) models in such a way that the researchers and practitioners
    that are interested in the topic can decide which path they should take.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在[ML](#glo.main.ml)领域，[DL](#glo.main.dl) 是一个新兴领域，每年兴趣不断上升。因此，越来越多的金融[DL](#glo.main.dl)
    模型开始出现在会议和期刊上。我们在本文中的重点是以一种方式展示不同的金融[DL](#glo.main.dl) 模型的实现，使对该主题感兴趣的研究人员和从业者能够决定他们应采取的路径。
- en: 'In this paper, we tried to provide answers to the following research questions:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们试图回答以下研究问题：
- en: '1.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1.'
- en: What financial application areas are of interest to [DL](#glo.main.dl) community?
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[DL](#glo.main.dl) 社区关注的金融应用领域有哪些？'
- en: '2.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2.'
- en: How mature is the existing research in each of these application areas?
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现有研究在这些应用领域的成熟度如何？
- en: '3.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '3.'
- en: What are the areas that have promising potentials from an academic/industrial
    research perspective?
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从学术/工业研究的角度来看，哪些领域具有有前途的潜力？
- en: '4.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '4.'
- en: Which [DL](#glo.main.dl) models are preferred (and more successful) in different
    applications?
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在不同应用中，哪些[深度学习（DL）](#glo.main.dl)模型更受青睐（且更成功）？
- en: '5.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '5.'
- en: How do [DL](#glo.main.dl) models pare against traditional soft computing / [ML](#glo.main.ml)
    techniques?
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[深度学习（DL）](#glo.main.dl)模型与传统软计算/[机器学习（ML）](#glo.main.ml)技术相比如何？'
- en: '6.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '6.'
- en: What is the future direction for [DL](#glo.main.dl) research in Finance?
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[深度学习（DL）](#glo.main.dl)在金融领域的未来发展方向是什么？'
- en: Our focus was solely on [DL](#glo.main.dl) implementations for financial applications.
    A substantial portion of the computational intelligence for finance research is
    devoted to financial time series forecasting. However, we preferred to concentrate
    on those studies in a separate survey paper [[1](#bib.bib1)] in order to be able
    to pinpoint other, less covered application areas. Meanwhile, we decided to include
    algorithmic trading studies with [DL](#glo.main.dl) based trading strategies which
    may or may not have an embedded time series forecasting component.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的重点完全放在了金融应用的[深度学习（DL）](#glo.main.dl)实现上。金融研究中的计算智能很大一部分致力于金融时间序列预测。然而，我们更倾向于将这些研究集中在另一篇调查论文[[1](#bib.bib1)]中，以便能够指出其他较少涉及的应用领域。同时，我们决定包含基于[深度学习（DL）](#glo.main.dl)的算法交易研究，这些策略可能会包含或不包含时间序列预测组件。
- en: 'For our search methodology, we surveyed and carefully reviewed the studies
    that came to our attention from the following sources: ScienceDirect, ACM Digital
    Library, Google Scholar, arXiv.org, ResearchGate, Google keyword search for DL
    and finance'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的搜索方法中，我们调查并仔细审查了以下来源中引起我们注意的研究：ScienceDirect、ACM数字图书馆、Google Scholar、arXiv.org、ResearchGate、Google关键词搜索关于DL和金融的内容。
- en: The range of our survey spanned not only journals and conferences, but also
    Masters and PhD theses, book chapters, arXiv papers and noteworthy technical papers
    that came up in Google searches. Furthermore, we only chose the articles that
    were written in English. It is worth to mention that we encountered a few studies
    that were written in a different language, but had English abstracts. However,
    for overall consistency, we decided not to include those studies in our survey.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的调查范围不仅涵盖了期刊和会议，还包括硕士和博士论文、书籍章节、arXiv论文以及在Google搜索中出现的值得注意的技术论文。此外，我们只选择了用英语撰写的文章。值得一提的是，我们遇到了一些用其他语言撰写但有英文摘要的研究。然而，为了保持整体一致性，我们决定不将这些研究纳入我们的调查。
- en: Most of the papers in this survey used the term “deep learning" in their model
    description and they were published in the last 5 years. However, we also included
    some older papers that implemented deep learning models even though they were
    not called “deep learning" models at their time of publication. Some examples
    for such models include [Recurrent Neural Network (RNN)](#glo.main.rnn), Jordan-Elman
    networks.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查中的大多数论文在其模型描述中使用了“深度学习”这一术语，并且这些论文是在过去5年内发布的。然而，我们也包括了一些较早的论文，这些论文实现了深度学习模型，尽管在其发布时并未称其为“深度学习”模型。此类模型的一些示例包括[递归神经网络（RNN）](#glo.main.rnn)和Jordan-Elman网络。
- en: To best of our knowledge, this will be the first comprehensive “deep learning
    for financial applications" survey paper. As will be introduced in the next section,
    a lot of [ML](#glo.main.ml) surveys exist for different areas of finance, however,
    no study has concentrated on [DL](#glo.main.dl) implementations. We genuinely
    believe our study will highlight the major advancements in the field and provide
    a roadway for the intended researchers that would like to develop [DL](#glo.main.dl)
    models for different financial application areas.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们了解，这将是第一篇全面的“金融应用中的深度学习”调查论文。正如在下一节中将介绍的那样，虽然存在很多针对金融不同领域的[机器学习（ML）](#glo.main.ml)调查，但没有研究专注于[深度学习（DL）](#glo.main.dl)实现。我们真心相信，我们的研究将突显该领域的重大进展，并为希望开发[深度学习（DL）](#glo.main.dl)模型用于不同金融应用领域的研究人员提供道路。
- en: 'The rest of the paper is structured as follows. After this brief introduction,
    in Section [2](#S2 "2 Machine Learning in Finance ‣ Deep Learning for Financial
    Applications : A Survey"), the existing surveys that are focused on [ML](#glo.main.ml)
    and soft computing studies for financial applications are presented. In Section [3](#S3
    "3 Deep Learning ‣ Deep Learning for Financial Applications : A Survey"), we will
    provide the basic working [DL](#glo.main.dl) models that are used in finance,
    i.e. [Convolutional Neural Network (CNN)](#glo.main.cnn), [Long-Short Term Memory
    (LSTM)](#glo.main.lstm), etc. Section [4](#S4 "4 Financial Applications ‣ Deep
    Learning for Financial Applications : A Survey") will focus on the implementation
    areas of the [DL](#glo.main.dl) models in finance. Some of these include algorithmic
    trading, credit risk assessment, portfolio allocation, asset pricing, fraud detection
    and derivatives market. After briefly stating the problem definition in each subsection,
    [DL](#glo.main.dl) implementations of each associated problem will be given.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的其余部分结构如下。在这次简要介绍之后，在第[2](#S2 "2 机器学习在金融中的应用 ‣ 财务应用的深度学习：一项调查")节中，介绍了现有的针对[ML](#glo.main.ml)和软计算在金融应用中的研究的综述。在第[3](#S3
    "3 深度学习 ‣ 财务应用的深度学习：一项调查")节中，我们将提供在金融中使用的基本[DL](#glo.main.dl)模型，例如[卷积神经网络 (CNN)](#glo.main.cnn)、[长短期记忆网络
    (LSTM)](#glo.main.lstm)等。第[4](#S4 "4 财务应用 ‣ 财务应用的深度学习：一项调查")节将关注[DL](#glo.main.dl)模型在金融中的实施领域。这些领域包括算法交易、信用风险评估、投资组合分配、资产定价、欺诈检测和衍生品市场。在每个小节简要说明问题定义后，将给出每个相关问题的[DL](#glo.main.dl)实现。
- en: 'In Section [5](#S5 "5 Current Snaphot of DL research for Financial Applications
    ‣ Deep Learning for Financial Applications : A Survey"), these studies will be
    compared and some overall statistical results will be presented including histograms
    about the yearly distribution of different subfields, models, publication types,
    etc. These statistics will not only demonstrate the current state for the field
    but also will show which areas are mature, which areas still have opportunities
    and which areas are getting accelerated attention. Section [6](#S6 "6 Discussion
    and Open Issues ‣ Deep Learning for Financial Applications : A Survey") will have
    discussions about what has been done in the field so far and where the industry
    is going. The chapter will also include the achievements and expectations of both
    academia and the industry. Also, open areas and recommended research topics will
    be mentioned. Finally, in Section [7](#S7 "7 Conclusions ‣ Deep Learning for Financial
    Applications : A Survey"), we will summarize the findings and conclude.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[5](#S5 "5 当前金融应用中深度学习研究的快照 ‣ 财务应用的深度学习：一项调查")节中，这些研究将被比较，并将展示一些整体统计结果，包括不同子领域、模型、出版类型等的年度分布直方图。这些统计数据不仅展示了该领域的当前状态，还将显示哪些领域已经成熟，哪些领域仍有机会，哪些领域正在加速关注。第[6](#S6
    "6 讨论与开放问题 ‣ 财务应用的深度学习：一项调查")节将讨论目前在该领域取得的成果以及行业的未来发展。该章节还将包括学术界和行业的成就与期望。同时，将提到开放领域和推荐的研究主题。最后，在第[7](#S7
    "7 结论 ‣ 财务应用的深度学习：一项调查")节中，我们将总结发现并得出结论。
- en: 2 Machine Learning in Finance
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 机器学习在金融中的应用
- en: Finance has always been one of the most studied application areas for [ML](#glo.main.ml),
    starting as early as 40 years ago. So far, thousands of research papers were published
    in various fields within finance, and the overall interest does not seem to diminish
    anytime soon. Even though this survey paper is solely focused on [DL](#glo.main.dl)
    implementations, we wanted to provide the audience with some insights about previous
    [ML](#glo.main.ml) studies by citing the related surveys within the last 20 years.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 金融一直是[ML](#glo.main.ml)研究最多的应用领域之一，早在40年前就开始了。到目前为止，已经在金融的各个领域发表了数千篇研究论文，总体兴趣似乎没有减少。尽管这篇综述论文专注于[DL](#glo.main.dl)实现，但我们希望通过引用过去20年的相关综述，为读者提供一些关于先前[ML](#glo.main.ml)研究的见解。
- en: There are a number of [ML](#glo.main.ml) surveys and books with a general perspective
    such that they do not concentrate on any particular implementation area. The following
    survey papers fall into that category. Bahrammirzaee et al. [[2](#bib.bib2)] compared
    [Artificial Neural Networks (ANNs)](#glo.main.ann), Expert Systems and Hybrid
    models for various financial applications. Zhang et al. [[3](#bib.bib3)] reviewed
    the data mining techniques including [Genetic Algorithm (GA)](#glo.main.ga), rule-based
    systems, [Neural Networks (NNs)](#glo.main.nn) preferred in different financial
    application areas. Similarly, Mochn et al. [[4](#bib.bib4)] also provided insights
    about financial implementations based on soft computing techniques like fuzzy
    logic, probabilistic reasoning and [NNs](#glo.main.nn). Even though Pulakkazhy
    et al. [[5](#bib.bib5)] focused particularly on data mining models in banking
    applications, they still had a span of several subtopics within the field. Meanwhile,
    Mullainathan et al. [[6](#bib.bib6)] studied the [ML](#glo.main.ml) implementations
    from a high level and econometric point of view. Likewise, Gai et al. [[7](#bib.bib7)]
    reviewed the Fintech studies and implementations not only from an [ML](#glo.main.ml)
    perspective but in general. The publications in [[8](#bib.bib8), [9](#bib.bib9),
    [10](#bib.bib10), [11](#bib.bib11)] constitute some of the books that cover the
    implementations of soft computing models in finance.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些具有一般视角的[机器学习](#glo.main.ml)调查和书籍，它们并未集中于任何特定的实现领域。以下调查论文属于这一类别。Bahrammirzaee等人[[2](#bib.bib2)]比较了[人工神经网络
    (ANNs)](#glo.main.ann)、专家系统和混合模型在各种金融应用中的表现。Zhang等人[[3](#bib.bib3)]回顾了包括[遗传算法
    (GA)](#glo.main.ga)、基于规则的系统、[神经网络 (NNs)](#glo.main.nn)在内的数据挖掘技术，这些技术在不同的金融应用领域中更受青睐。类似地，Mochn等人[[4](#bib.bib4)]也提供了关于基于软计算技术的金融实现的见解，如模糊逻辑、概率推理和[NNs](#glo.main.nn)。尽管Pulakkazhy等人[[5](#bib.bib5)]特别关注银行应用中的数据挖掘模型，但他们的研究仍涉及多个子领域。同时，Mullainathan等人[[6](#bib.bib6)]从高层次和计量经济学的角度研究了[机器学习](#glo.main.ml)的实现。Gai等人[[7](#bib.bib7)]同样从[机器学习](#glo.main.ml)及一般角度回顾了金融科技研究和实现。[[8](#bib.bib8)、[9](#bib.bib9)、[10](#bib.bib10)、[11](#bib.bib11)]中的出版物涵盖了一些关于软计算模型在金融中实现的书籍。
- en: Meanwhile, there are some survey papers that are also not application area-specific
    but rather focused on particular [ML](#glo.main.ml) techniques. One of those soft
    computing techniques is the family of [Evolutionary Algorithms (EAs)](#glo.main.ea),
    i.e. [GA](#glo.main.ga), [Particle Swarm Optimization (PSO)](#glo.main.pso), etc.
    commonly used in financial optimization implementations like Portfolio Selection.
    Chen et al. [[12](#bib.bib12)] wrote a book covering [GAs](#glo.main.ga) and [Genetic
    Programming (GP)](#glo.main.gp) in Computational Finance. Later, Castillo et al.
    [[13](#bib.bib13)], Ponsich et al. [[14](#bib.bib14)], Aguilar-Rivera et al. [[15](#bib.bib15)]
    extensively surveyed [Multiobjective Evolutionary Algorithms (MOEAs)](#glo.main.moea)
    on portfolio optimization and other various financial applications.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，还有一些调查论文也不是针对特定应用领域，而是集中于特定的[机器学习](#glo.main.ml)技术。其中一种软计算技术是[进化算法 (EAs)](#glo.main.ea)家族，即[GA](#glo.main.ga)、[粒子群优化
    (PSO)](#glo.main.pso)等，通常用于金融优化实现如投资组合选择。Chen等人[[12](#bib.bib12)]编写了一本书，涵盖了[GA](#glo.main.ga)和[遗传编程
    (GP)](#glo.main.gp)在计算金融中的应用。后来，Castillo等人[[13](#bib.bib13)]、Ponsich等人[[14](#bib.bib14)]、Aguilar-Rivera等人[[15](#bib.bib15)]广泛调查了[多目标进化算法
    (MOEAs)](#glo.main.moea)在投资组合优化和其他各种金融应用中的应用。
- en: Since [ANNs](#glo.main.ann) were quite popular among researchers, a number of
    survey papers were just dedicated to them. Wong et al. [[16](#bib.bib16)] covered
    early implementations of [ANNs](#glo.main.ann) in finance. Li et al. [[17](#bib.bib17)]
    reviewed implementations of [ANNs](#glo.main.ann) for stock price forecasting
    and some other financial applications. Lately, Elmsili et al. [[18](#bib.bib18)]
    contained [ANN](#glo.main.ann) applications in economics and management research
    in their survey.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由于[ANNs](#glo.main.ann)在研究人员中相当受欢迎，因此有许多调查论文专门讨论它们。Wong等人[[16](#bib.bib16)]介绍了[ANNs](#glo.main.ann)在金融中的早期实现。Li等人[[17](#bib.bib17)]回顾了用于股票价格预测和其他金融应用的[ANNs](#glo.main.ann)实现。最近，Elmsili等人[[18](#bib.bib18)]在其调查中包含了[ANN](#glo.main.ann)在经济学和管理研究中的应用。
- en: In addition, LeBaron [[19](#bib.bib19)] covered the studies focused on agent-based
    computational finance. Meanwhile, Chalup et al. [[20](#bib.bib20)] wrote a book
    chapter on kernel methods in financial applications which includes models like
    [Principal Component Analysis (PCA)](#glo.main.pca), [Support Vector Machine (SVM)](#glo.main.svm).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，LeBaron [[19](#bib.bib19)] 讨论了基于代理的计算金融研究。同时，Chalup 等人 [[20](#bib.bib20)]
    撰写了一章关于金融应用中的核方法的书，涵盖了像[主成分分析 (PCA)](#glo.main.pca)、[支持向量机 (SVM)](#glo.main.svm)这样的模型。
- en: 'And then, there are application-specific survey papers that single out particular
    financial areas which are quite useful and informative for researchers that already
    know what they are looking for. These papers will be covered in the appropriate
    subsections of Section [4](#S4 "4 Financial Applications ‣ Deep Learning for Financial
    Applications : A Survey") during problem description. In the next section, brief
    working structures of the [DL](#glo.main.dl) models used in the financial applications
    will be given.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，存在一些应用特定的调查论文，单独指出特定的金融领域，对于已经知道自己在寻找什么的研究人员非常有用和信息丰富。这些论文将在问题描述的第 [4](#S4
    "4 金融应用 ‣ 深度学习在金融应用中的应用：一项调查") 节的适当小节中涵盖。在下一节中，将简要介绍在金融应用中使用的 [DL](#glo.main.dl)
    模型的工作结构。
- en: 3 Deep Learning
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 深度学习
- en: 'Deep Learning is a particular type of [ML](#glo.main.ml) that consists of multiple
    [ANN](#glo.main.ann) layers. It provides high-level abstraction for data modelling
    [[21](#bib.bib21)]. In the literature, different [DL](#glo.main.dl) models exist:
    [Deep Multilayer Perceptron (DMLP)](#glo.main.dmlp), [CNN](#glo.main.cnn), [RNN](#glo.main.rnn),
    [LSTM](#glo.main.lstm), [Restricted Boltzmann Machines (RBMs)](#glo.main.rbm),
    [Deep Belief Networks (DBNs)](#glo.main.dbn), and [Autoencoders (AEs)](#glo.main.ae).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是一种特定类型的[ML](#glo.main.ml)，由多个 [ANN](#glo.main.ann) 层组成。它为数据建模提供了高级抽象 [[21](#bib.bib21)]。文献中存在不同的
    [DL](#glo.main.dl) 模型： [深度多层感知器 (DMLP)](#glo.main.dmlp)、[CNN](#glo.main.cnn)、[RNN](#glo.main.rnn)、[LSTM](#glo.main.lstm)、[限制玻尔兹曼机
    (RBMs)](#glo.main.rbm)、[深度信念网络 (DBNs)](#glo.main.dbn) 和 [自编码器 (AEs)](#glo.main.ae)。
- en: 3.1 Deep Multi Layer Perceptron (DMLP)
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 深度多层感知器 (DMLP)
- en: 'In the literature, [DMLP](#glo.main.dmlp) was the first proposed [ANN](#glo.main.ann)
    model of its kind. [DMLP](#glo.main.dmlp) networks consist of input, output and
    hidden layers just like an ordinary [Multilayer Perceptron (MLP)](#glo.main.mlp);
    however, the number of layers in [DMLP](#glo.main.dmlp) is more than [MLP](#glo.main.mlp).
    Each neuron in every layer has input (x), weight (w) and bias (b) terms. An output
    of a neuron in the neural network is illustrated in Equation [1](#S3.E1 "In 3.1
    Deep Multi Layer Perceptron (DMLP) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey"). In addition, each neuron has a nonlinear activation
    function which produces the output of that neuron through accumulating weighted
    inputs from the neurons in the preceding layer. Sigmoid [[22](#bib.bib22)], hyperbolic
    tangent [[23](#bib.bib23)], [Rectified Linear Unit (ReLU)](#glo.main.relu) [[24](#bib.bib24)],
    leaky [ReLU](#glo.main.relu) [[25](#bib.bib25)], swish [[26](#bib.bib26)], and
    softmax[[27](#bib.bib27)] are among the most preferred nonlinear activation functions
    in the literature.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 文献中，[DMLP](#glo.main.dmlp) 是首个提出的 [ANN](#glo.main.ann) 模型。[DMLP](#glo.main.dmlp)
    网络由输入层、输出层和隐藏层组成，类似于普通的[多层感知器 (MLP)](#glo.main.mlp)，然而，[DMLP](#glo.main.dmlp)
    的层数比[MLP](#glo.main.mlp) 多。每一层中的每个神经元都有输入 (x)、权重 (w) 和偏置 (b) 项。神经网络中神经元的输出如方程
    [1](#S3.E1 "在 3.1 深度多层感知器 (DMLP) ‣ 3 深度学习 ‣ 深度学习在金融应用中的应用：一项调查") 所示。此外，每个神经元都有一个非线性激活函数，通过累加来自前一层神经元的加权输入来产生该神经元的输出。Sigmoid
    [[22](#bib.bib22)]、双曲正切 [[23](#bib.bib23)]、[修正线性单元 (ReLU)](#glo.main.relu) [[24](#bib.bib24)]、泄漏
    [ReLU](#glo.main.relu) [[25](#bib.bib25)]、swish [[26](#bib.bib26)] 和 softmax[[27](#bib.bib27)]
    是文献中最常用的非线性激活函数。
- en: '|  | $y_{i}=\sigma(\sum\limits_{i}W_{i}x_{i}+b_{i})$ |  | (1) |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '|  | $y_{i}=\sigma(\sum\limits_{i}W_{i}x_{i}+b_{i})$ |  | (1) |'
- en: 'With multi-layer deep [ANNs](#glo.main.ann), more efficient classification
    and regression performances are achieved when compared against shallow nets. [DMLPs](#glo.main.dmlp)’
    learning process is implemented through backpropagation. The amount of the output
    error in the output layer neurons is also reflected back to the neurons in the
    previous layers. In [DMLP](#glo.main.dmlp), [Stochastic Gradient Descent (SGD)](#glo.main.sgd)
    method is (mostly) used for the optimization of learning (to update the weights
    of the connections between the layers). In Figure [1](#S3.F1 "Figure 1 ‣ 3.1 Deep
    Multi Layer Perceptron (DMLP) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey"), a [DMLP](#glo.main.dmlp) model, the layers, the neurons
    in layers, the weights between the neurons are shown.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '使用多层深度[ANNs](#glo.main.ann)时，与浅层网络相比，能实现更高效的分类和回归性能。[DMLPs](#glo.main.dmlp)的学习过程通过反向传播来实现。输出层神经元的输出误差量也会反馈到前面的神经元中。在[DMLP](#glo.main.dmlp)中，[随机梯度下降法
    (SGD)](#glo.main.sgd)（主要）用于优化学习（更新层间连接的权重）。图[1](#S3.F1 "Figure 1 ‣ 3.1 Deep Multi
    Layer Perceptron (DMLP) ‣ 3 Deep Learning ‣ Deep Learning for Financial Applications
    : A Survey")展示了[DMLP](#glo.main.dmlp)模型、层、层中的神经元以及神经元之间的权重。'
- en: '![Refer to caption](img/bca6b34e192bb2c27b558e692f5a6161.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/bca6b34e192bb2c27b558e692f5a6161.png)'
- en: 'Figure 1: Deep Multi Layer Neural Network Forward Pass and Backpropagation
    [[21](#bib.bib21)]'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '图1: 深度多层神经网络前向传播与反向传播[[21](#bib.bib21)]'
- en: 3.2 Convolutional Neural Networks (CNNs)
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 卷积神经网络 (CNNs)
- en: '[CNN](#glo.main.cnn) is a type of [Deep Neural Network (DNN)](#glo.main.dnn)
    that is mostly used for image classification, image recognition problems. In its
    methodology, the whole image is scanned with filters. In the literature, 1x1,
    3x3 and 5x5 filter sizes are mostly used. In most of the [CNN](#glo.main.cnn)
    architectures, there are different types of layers: convolutional, pooling (average
    or maximum), fully connected layers. [CNN](#glo.main.cnn) consists of convolutional
    layers based on the convolutional operation. Figure [2](#S3.F2 "Figure 2 ‣ 3.2
    Convolutional Neural Networks (CNNs) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey") shows the generalized CNN architecture that has different
    layers: convolutional, subsampling (pooling), fully connected layers.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[CNN](#glo.main.cnn)是一种[深度神经网络 (DNN)](#glo.main.dnn)，主要用于图像分类、图像识别问题。在其方法中，整个图像通过滤波器进行扫描。在文献中，1x1、3x3和5x5的滤波器尺寸被广泛使用。在大多数[CNN](#glo.main.cnn)架构中，有不同类型的层：卷积层、池化层（平均池化或最大池化）、全连接层。[CNN](#glo.main.cnn)由基于卷积操作的卷积层组成。图[2](#S3.F2
    "Figure 2 ‣ 3.2 Convolutional Neural Networks (CNNs) ‣ 3 Deep Learning ‣ Deep
    Learning for Financial Applications : A Survey")展示了具有不同层的广义CNN架构：卷积层、子采样层（池化层）、全连接层。'
- en: '![Refer to caption](img/e81a5865dacc7ebfc1317ec9d38672f7.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e81a5865dacc7ebfc1317ec9d38672f7.png)'
- en: 'Figure 2: Generalized Convolutional Neural Network Architecture'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '图2: 广义卷积神经网络架构'
- en: 3.3 Recurrent Neural Network (RNN)
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 循环神经网络 (RNN)
- en: In the literature, [RNN](#glo.main.rnn) has been mostly used on sequential data
    such as time-series data, audio and speech data, language. It consists of [RNN](#glo.main.rnn)
    units that are structured consecutively. Unlike feed-forward networks, [RNNs](#glo.main.rnn)
    use internal memory to process the incoming inputs. [RNNs](#glo.main.rnn) are
    used in the analysis of the time series data in various fields (handwriting recognition,
    speech recognition, etc).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 文献中，[RNN](#glo.main.rnn)主要用于处理如时间序列数据、音频和语音数据、语言等顺序数据。它由按顺序排列的[RNN](#glo.main.rnn)单元组成。与前馈网络不同，[RNNs](#glo.main.rnn)使用内部记忆处理输入数据。[RNNs](#glo.main.rnn)在各个领域的时间序列数据分析中得到应用（如手写识别、语音识别等）。
- en: 'There are different types of [RNN](#glo.main.rnn) structures: one to many,
    many to one, many to many. Generally, [RNN](#glo.main.rnn) processes the input
    sequence series one by one at a time, during its operation. Units in the hidden
    layer hold information about the history of the input in the "state vector" [[21](#bib.bib21)].
    [RNNs](#glo.main.rnn) can be trained using the [Backpropagation Through Time (BPTT)](#glo.main.bptt)
    method. Using [BPTT](#glo.main.bptt), the differentiation of the loss at any time
    $t$ has reflected the weights of the network at the previous time. Training of
    [RNNs](#glo.main.rnn) are more difficult than [Feedforward Neural Networks (FFNNs)](#glo.main.ffnn)
    and the training period of [RNNs](#glo.main.rnn) takes longer.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同类型的[RNN](#glo.main.rnn)结构：一对多、多对一、多对多。一般来说，[RNN](#glo.main.rnn)在运行过程中逐个处理输入序列。隐藏层中的单元通过“状态向量”[[21](#bib.bib21)]保存输入的历史信息。[RNNs](#glo.main.rnn)可以通过[时间反向传播（BPTT）](#glo.main.bptt)方法进行训练。使用[BPTT](#glo.main.bptt)时，任何时刻$t$的损失梯度反映了之前时间的网络权重。[RNNs](#glo.main.rnn)的训练比[前馈神经网络（FFNNs）](#glo.main.ffnn)更困难，训练时间也更长。
- en: 'In Figure [3](#S3.F3 "Figure 3 ‣ 3.3 Recurrent Neural Network (RNN) ‣ 3 Deep
    Learning ‣ Deep Learning for Financial Applications : A Survey"), the information
    flow in the [RNN](#glo.main.rnn)’s hidden layer is divided into discrete times.
    The status of the node S at different times of $t$ is shown as $s_{t}$, the input
    value $x$ at different times is $x_{t}$, and the output value $o$ at different
    times is shown as $o_{t}$. The parameter values ($U,W,V$) are always used in the
    same step.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在图[3](#S3.F3 "图3 ‣ 3.3 循环神经网络（RNN） ‣ 3 深度学习 ‣ 深度学习在金融应用中的调查")中，[RNN](#glo.main.rnn)隐藏层的信息流被划分为离散时间。节点S在不同时间$t$的状态表示为$s_{t}$，不同时间的输入值$x$为$x_{t}$，不同时间的输出值$o$表示为$o_{t}$。参数值（$U,W,V$）始终在相同步骤中使用。
- en: '![Refer to caption](img/a1434138f07a0e4895fafb2fed35ceed.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a1434138f07a0e4895fafb2fed35ceed.png)'
- en: 'Figure 3: RNN cell through time[[21](#bib.bib21)]'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：RNN单元随时间变化 [[21](#bib.bib21)]
- en: 3.4 Long Short Term Memory (LSTM)
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 长短期记忆（LSTM）
- en: '[LSTM](#glo.main.lstm) network [[28](#bib.bib28)] is a different type of [DL](#glo.main.dl)
    network specifically intended for sequential data analysis. The advantage of [LSTM](#glo.main.lstm)
    networks lies in the fact that both short term and long term values in the network
    can be remembered. Therefore, [LSTM](#glo.main.lstm) networks are mostly used
    for sequential data analysis (automatic speech recognition, language translation,
    handwritten character recognition, time-series data forecasting, etc.) by [DL](#glo.main.dl)
    researchers. [LSTM](#glo.main.lstm) networks consist of [LSTM](#glo.main.lstm)
    units. [LSTM](#glo.main.lstm) unit is composed of cells having input, output and
    forget gates. These three gates regulate the information flow. With these features,
    each cell remembers the desired values over arbitrary time intervals. [LSTM](#glo.main.lstm)
    cells combine to form layers of neural networks. Figure [4](#S3.F4 "Figure 4 ‣
    3.4 Long Short Term Memory (LSTM) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey") illustrates the basic LSTM unit ($\sigma_{g}$: sigmoid
    function, $tanh$: hyperbolic tangent function, $X$: multiplication, $+$: addition).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[LSTM](#glo.main.lstm)网络 [[28](#bib.bib28)] 是一种专门用于序列数据分析的不同类型的[DL](#glo.main.dl)网络。[LSTM](#glo.main.lstm)网络的优点在于网络中既能记住短期值，也能记住长期值。因此，[LSTM](#glo.main.lstm)网络通常用于序列数据分析（自动语音识别、语言翻译、手写字符识别、时间序列数据预测等），被[DL](#glo.main.dl)研究者广泛使用。[LSTM](#glo.main.lstm)网络由[LSTM](#glo.main.lstm)单元组成。[LSTM](#glo.main.lstm)单元由具有输入、输出和遗忘门的单元组成。这三个门调节信息流。借助这些特性，每个单元可以在任意时间间隔内记住所需的值。[LSTM](#glo.main.lstm)单元结合形成神经网络的层。图[4](#S3.F4
    "图4 ‣ 3.4 长短期记忆（LSTM） ‣ 3 深度学习 ‣ 深度学习在金融应用中的调查")展示了基本的LSTM单元（$\sigma_{g}$：Sigmoid函数，$tanh$：双曲正切函数，$X$：乘法，$+$：加法）。'
- en: '![Refer to caption](img/4b01c5ab4ad302759f9ccac3414f8203.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4b01c5ab4ad302759f9ccac3414f8203.png)'
- en: 'Figure 4: Basic LSTM Unit [[28](#bib.bib28)]'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：基本LSTM单元 [[28](#bib.bib28)]
- en: 3.5 Restricted Boltzmann Machines (RBMs)
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 受限玻尔兹曼机（RBMs）
- en: '[RBM](#glo.main.rbm) is a different type of [ANN](#glo.main.ann) model that
    can learn the probability distribution of the input set [[29](#bib.bib29)]. [RBMs](#glo.main.rbm)
    are mostly used for dimensionality reduction, classification, and feature learning.
    [RBM](#glo.main.rbm) is a bipartite, undirected graphical model that consists
    of two layers; visible and hidden layer. The units in the layer are not connected
    to each other. Each cell is a computational point that processes the input. Each
    unit makes stochastic decisions about whether transmitting the input data or not.
    The inputs are multiplied by specific weights, certain threshold values (bias)
    are added to the input values, then the calculated values are passed through an
    activation function. In the reconstruction stage, the results in the outputs re-enter
    the network as the input, then they exit from the visible layer as the output.
    The values of the previous input and the values after the processes are compared.
    The purpose of the comparison is to reduce the difference. The learning is performed
    multiple times on the network [[29](#bib.bib29)]. [RBM](#glo.main.rbm) is a two-layer,
    bipartite, and undirected graphical model that consists of two layers; visible
    and hidden layers (Figure [5](#S3.F5 "Figure 5 ‣ 3.5 Restricted Boltzmann Machines
    (RBMs) ‣ 3 Deep Learning ‣ Deep Learning for Financial Applications : A Survey")).
    The layers are not connected among themselves. The disadvantage of [RBM](#glo.main.rbm)
    is its tricky training. “[RBMs](#glo.main.rbm) are tricky because although there
    are good estimators of the log-likelihood gradient, there are no known cheap ways
    of estimating the log-likelihood itself" [[30](#bib.bib30)].'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[RBM](#glo.main.rbm) 是一种不同类型的 [ANN](#glo.main.ann) 模型，能够学习输入集合的概率分布 [[29](#bib.bib29)]。[RBM](#glo.main.rbm)
    主要用于降维、分类和特征学习。[RBM](#glo.main.rbm) 是一种二分、无向图模型，由两个层次组成：可见层和隐藏层。层中的单元彼此不连接。每个单元是一个处理输入的计算点。每个单元会随机决定是否传递输入数据。输入会乘以特定的权重，添加一定的阈值（偏差），然后通过激活函数计算结果。在重构阶段，输出的结果重新进入网络作为输入，然后从可见层作为输出退出。比较先前输入的值和处理后的值。比较的目的是减少差异。学习在网络上多次进行
    [[29](#bib.bib29)]。[RBM](#glo.main.rbm) 是一个两层的二分、无向图模型，包含可见层和隐藏层（图 [5](#S3.F5
    "图 5 ‣ 3.5 受限玻尔兹曼机（RBMs） ‣ 3 深度学习 ‣ 深度学习在金融应用中的调查")）。这些层之间没有连接。[RBM](#glo.main.rbm)
    的缺点是其训练过程复杂。“[RBM](#glo.main.rbm) 训练复杂，因为虽然对对数似然梯度有很好的估计器，但没有已知的便宜方式来估计对数似然本身”
    [[30](#bib.bib30)]。'
- en: '![Refer to caption](img/c7056e0cb889c2297ccf9c13c0d89daf.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c7056e0cb889c2297ccf9c13c0d89daf.png)'
- en: 'Figure 5: RBM Visible and Hidden Layers [[29](#bib.bib29)]'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: RBM 可见层和隐藏层 [[29](#bib.bib29)]'
- en: 3.6 Deep Belief Networks (DBNs)
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.6 深度置信网络（DBNs）
- en: '[DBN](#glo.main.dbn) is a type of [ANN](#glo.main.ann) that consists of a stack
    of [RBM](#glo.main.rbm) layers. [DBN](#glo.main.dbn) is a probabilistic generative
    model that consists of latent variables. [DBNs](#glo.main.dbn) are used for finding
    independent and discriminative features in the input set using an unsupervised
    approach. [DBN](#glo.main.dbn) can learn to reconstruct the input set in a probabilistic
    way during the training process. Then the layers on the network begin to detect
    the discriminative features. After the learning step, supervised learning is carried
    out to perform for the classification [[31](#bib.bib31)]. Figure [6](#S3.F6 "Figure
    6 ‣ 3.6 Deep Belief Networks (DBNs) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey") illustrates the [DBN](#glo.main.dbn) structure.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[DBN](#glo.main.dbn) 是一种由一系列 [RBM](#glo.main.rbm) 层组成的 [ANN](#glo.main.ann)
    模型。[DBN](#glo.main.dbn) 是一种概率生成模型，包含潜在变量。[DBN](#glo.main.dbn) 用于通过无监督的方法在输入集合中寻找独立和具有辨别性的特征。[DBN](#glo.main.dbn)
    可以在训练过程中以概率方式学习重构输入集合。然后，网络中的层开始检测辨别特征。学习步骤之后，进行监督学习以进行分类 [[31](#bib.bib31)]。图
    [6](#S3.F6 "图 6 ‣ 3.6 深度置信网络（DBNs） ‣ 3 深度学习 ‣ 深度学习在金融应用中的调查") 展示了 [DBN](#glo.main.dbn)
    结构。'
- en: '![Refer to caption](img/1540c07d0250f8dc646cc0eec03a3997.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1540c07d0250f8dc646cc0eec03a3997.png)'
- en: 'Figure 6: Deep Belief Network [[29](#bib.bib29)]'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '图 6: 深度置信网络 [[29](#bib.bib29)]'
- en: 3.7 Autoencoders (AEs)
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.7 自编码器（AEs）
- en: '[AE](#glo.main.ae) networks are commonly used in [DL](#glo.main.dl) models,
    wherein they remap the inputs (features) such that the inputs are more representative
    for the classification. In other words, [AE](#glo.main.ae) networks perform an
    unsupervised feature learning process. A representation of a data set is learned
    by reducing the dimensionality with an [AE](#glo.main.ae). In the literature,
    [AEs](#glo.main.ae) have been used for feature extraction and dimensionality reduction
    [[27](#bib.bib27), [32](#bib.bib32)]. The architecture of an [AE](#glo.main.ae)
    has similarities with that of a [FFNN](#glo.main.ffnn). It consists of an input
    layer, output layer and one (or more) hidden layer that connects them together.
    The number of nodes in the input layer and the number of nodes in the output layer
    are equal to each other in [AEs](#glo.main.ae), and they have a symmetrical structure.
    [AEs](#glo.main.ae) contain two components: encoder and decoder.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[AE](#glo.main.ae)网络通常用于[DL](#glo.main.dl)模型中，它们重新映射输入（特征），使得输入更适合分类。换句话说，[AE](#glo.main.ae)网络执行无监督特征学习过程。通过使用[AE](#glo.main.ae)减少维度来学习数据集的表示。在文献中，[AEs](#glo.main.ae)已被用于特征提取和降维[[27](#bib.bib27),
    [32](#bib.bib32)]。[AE](#glo.main.ae)的结构与[FFNN](#glo.main.ffnn)类似。它由一个输入层、一个输出层和一个（或多个）将它们连接在一起的隐藏层组成。在[AEs](#glo.main.ae)中，输入层的节点数和输出层的节点数相等，它们具有对称结构。[AEs](#glo.main.ae)包含两个组件：编码器和解码器。'
- en: 'The advantages of the usage of [AE](#glo.main.ae) are dimensionality reduction
    and feature learning. However, reducing dimensions and feature extraction in [AE](#glo.main.ae)
    cause some drawbacks. Focusing on minimizing the loss of the data relationship
    in the code of [AE](#glo.main.ae) causes the loss of some significant data relationship.
    This may be a drawback of [AE](#glo.main.ae) [[33](#bib.bib33)]. Figure [7](#S3.F7
    "Figure 7 ‣ 3.7 Autoencoders (AEs) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey") shows the basic [AE](#glo.main.ae) structure.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '使用[AE](#glo.main.ae)的优点包括降维和特征学习。然而，[AE](#glo.main.ae)中的降维和特征提取会导致一些缺点。专注于最小化[AE](#glo.main.ae)代码中数据关系的丧失，会导致一些重要数据关系的丧失。这可能是[AE](#glo.main.ae)的一个缺点[[33](#bib.bib33)]。图[7](#S3.F7
    "Figure 7 ‣ 3.7 Autoencoders (AEs) ‣ 3 Deep Learning ‣ Deep Learning for Financial
    Applications : A Survey")展示了基本的[AE](#glo.main.ae)结构。'
- en: '![Refer to caption](img/d64512a2f54396a4c514698d209a63f4.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d64512a2f54396a4c514698d209a63f4.png)'
- en: 'Figure 7: Basic Autoencoder Structure'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：基本自编码器结构
- en: 3.8 Other Deep Structures
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8 其他深度结构
- en: The [DL](#glo.main.dl) models are not limited to the ones mentioned in the previous
    subsections. Some of the other well-known structures that exist in the literature
    are [Deep Reinforcement Learning (DRL)](#glo.main.drl), [Generative Adversarial
    Networks (GANs)](#glo.main.gan) , Capsule Networks, [Deep Gaussian Processes (DGPs)](#glo.main.dgp)
    . Meanwhile, to the best of our knowledge, we have not encountered any noteworthy
    academic or industrial publication on financial applications using these models
    so far, with the exception of [DRL](#glo.main.drl) which started getting attention
    lately. However, that does not imply that these models do not fit well with the
    financial domain. On the contrary, they offer great potentials for researchers
    and practitioners participating in finance and deep learning community who are
    willing to go the extra mile to come up with novel solutions.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[DL](#glo.main.dl)模型不仅限于前面小节提到的那些。文献中存在一些其他著名的结构，如[深度强化学习（DRL）](#glo.main.drl)、[生成对抗网络（GANs）](#glo.main.gan)、胶囊网络、[深度高斯过程（DGPs）](#glo.main.dgp)。不过，据我们了解，除了[DRL](#glo.main.drl)近期受到关注外，我们尚未遇到关于使用这些模型进行财务应用的显著学术或工业出版物。然而，这并不意味着这些模型不适用于财务领域。相反，它们为参与金融和深度学习领域的研究人员和从业者提供了巨大的潜力，只要他们愿意付出额外的努力，提出新颖的解决方案。'
- en: Since research for model developments in [DL](#glo.main.dl) is ongoing, new
    structures keep on coming. However, the aforementioned models currently cover
    almost all of the published work. Next section will provide details about the
    implementation areas along with the preferred [DL](#glo.main.dl) models.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 由于[DL](#glo.main.dl)模型发展的研究仍在进行，新结构不断出现。然而，上述模型目前涵盖了几乎所有已发表的工作。下一节将详细介绍实现领域以及首选的[DL](#glo.main.dl)模型。
- en: 4 Financial Applications
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 财务应用
- en: There are a lot of financial applications of soft computing in the literature.
    [DL](#glo.main.dl) has been studied in most of them, although, some opportunities
    still exist in a number of fields.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 文献中有很多关于软计算的金融应用。虽然[深度学习（DL）](#glo.main.dl)在其中大部分被研究，但在一些领域仍然存在机会。
- en: Throughout this section, we categorized the implementation areas and presented
    them in separate subsections. Besides, in each subsection we tabulated the representative
    features of the relevant studies in order to provide as much information as possible
    in the limited space.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们对实现领域进行了分类，并在单独的子章节中展示了这些领域。此外，在每个子章节中，我们表格化了相关研究的代表性特征，以便在有限的空间内提供尽可能多的信息。
- en: 'Also, the readers should note that there were some overlaps between different
    implementation areas for some papers. There were two main reasons for that: In
    some papers, multiple problems were addressed separately, for e.g. text mining
    was studied for feature extraction, then algorithmic trading was implemented.
    For some other cases, the paper might fit directly into multiple implementation
    areas due to the survey structure, for e.g. cryptocurrency portfolio management.
    In such cases we included the papers in all of the relevant subsections creating
    some overlaps.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，读者应注意，有些论文在不同的实现领域之间存在一些重叠。这主要有两个原因：在一些论文中，多个问题被分别讨论，例如，文本挖掘用于特征提取，然后实现算法交易。在其他情况下，论文可能因调查结构直接适用于多个实现领域，例如，加密货币组合管理。在这种情况下，我们将论文包含在所有相关的子章节中，从而产生了一些重叠。
- en: 'Some of the existing study areas can be grouped as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一些现有的研究领域可以归纳如下：
- en: 4.1 Algorithmic Trading
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 算法交易
- en: Algorithmic trading (or Algo-trading) is defined as buy-sell decisions made
    solely by algorithmic models. These decisions can be based on some simple rules,
    mathematical models, optimized processes, or as in the case of machine/deep learning,
    highly complex function approximation techniques. With the introduction of electronic
    online trading platforms and frameworks, algorithmic trading took over the finance
    industry in the last two decades. As a result, Algo-trading models based on [DL](#glo.main.dl)
    also started getting attention.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 算法交易（或称算法交易）被定义为完全由算法模型做出的买卖决策。这些决策可以基于一些简单规则、数学模型、优化流程，或如机器学习/深度学习中的高度复杂的函数近似技术。随着电子在线交易平台和框架的引入，算法交易在过去二十年中主导了金融行业。因此，基于[深度学习（DL）](#glo.main.dl)的算法交易模型也开始受到关注。
- en: Most of the Algo-trading applications are coupled with price prediction models
    for market timing purposes. As a result, a majority of the price or trend forecasting
    models that trigger buy-sell signals based on their prediction are also considered
    as Algo-trading systems. However, there are also some studies that propose stand-alone
    Algo-trading models focused on the dynamics of the transaction itself by optimizing
    trading parameters such as bid-ask spread, analysis of limit order book, position-sizing,
    etc. [High Frequency Trading (HFT)](#glo.main.hft) researchers are particularly
    interested in this area. Hence, [DL](#glo.main.dl) models also started appearing
    in [HFT](#glo.main.hft) studies.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数算法交易应用都与市场时机预测模型相关联。因此，大多数基于预测触发买卖信号的价格或趋势预测模型也被视为算法交易系统。然而，也有一些研究提出了独立的算法交易模型，重点关注通过优化交易参数（如买卖价差、限价单簿分析、仓位管理等）来研究交易本身的动态。[高频交易（HFT）](#glo.main.hft)研究者对这一领域尤其感兴趣。因此，[深度学习（DL）](#glo.main.dl)模型也开始出现在[高频交易（HFT）](#glo.main.hft)研究中。
- en: Before diving into the [DL](#glo.main.dl) implementations, it would be beneficial
    to briefly mention about the existing [ML](#glo.main.ml) surveys on Algo-trading.
    Hu et al. [[34](#bib.bib34)] reviewed the implementations of various [EAs](#glo.main.ea)
    on Algorithmic Trading Models. Since financial time series forecasting is highly
    coupled with algorithmic trading, there are a number of [ML](#glo.main.ml) survey
    papers focused on Algo-trading models based on forecasting. The interested readers
    can refer to [[1](#bib.bib1)] for more information.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨[深度学习（DL）](#glo.main.dl)实现之前，简要提及现有的[机器学习（ML）](#glo.main.ml)关于算法交易的调查将会很有帮助。胡等人[[34](#bib.bib34)]
    回顾了各种[专家顾问（EAs）](#glo.main.ea)在算法交易模型中的实现。由于金融时间序列预测与算法交易高度相关，许多[机器学习（ML）](#glo.main.ml)调查论文专注于基于预测的算法交易模型。感兴趣的读者可以参考[[1](#bib.bib1)]获取更多信息。
- en: 'As far as the [DL](#glo.main.dl) research is concerned, Table LABEL:table:algorithmic_trading_1,
    Table LABEL:table:algorithmic_trading_2, and Table LABEL:table:algorithmic_trading_3
    present the past and current status of algo-trading studies based on [DL](#glo.main.dl)
    models. The papers are distributed to these tables as follows: Table LABEL:table:algorithmic_trading_1
    has the particular algorithmic trading implementations that are embedded with
    time series forecasting models, whereas Table LABEL:table:algorithmic_trading_2
    is focused on classification based (Buy-sell Signal, or Trend Detection) algo-trading
    models. Finally, Table LABEL:table:algorithmic_trading_3 presents stand-alone
    studies or other algorithmic trading models (pairs trading, arbitrage, etc) that
    do not fit into the above clustering criteria.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 就[DL](#glo.main.dl)研究而言，表 LABEL:table:algorithmic_trading_1、表 LABEL:table:algorithmic_trading_2和表 LABEL:table:algorithmic_trading_3展示了基于[DL](#glo.main.dl)模型的算法交易研究的过去和当前状态。这些论文分布在以下表格中：表 LABEL:table:algorithmic_trading_1包含嵌入时间序列预测模型的特定算法交易实现，而表 LABEL:table:algorithmic_trading_2则集中于基于分类（买卖信号或趋势检测）的算法交易模型。最后，表 LABEL:table:algorithmic_trading_3展示了独立研究或其他不符合上述分类标准的算法交易模型（配对交易、套利等）。
- en: Most of the Algo-trading studies were concentrated on the prediction of stock
    or index prices. Meanwhile, [LSTM](#glo.main.lstm) was the most preferred [DL](#glo.main.dl)
    model in these implementations. In [[35](#bib.bib35)], market microstructures
    based trade indicators were used as the input into [RNN](#glo.main.rnn) with Graves
    [LSTM](#glo.main.lstm) to perform the price prediction for algorithmic stock trading.
    Bao et al. [[36](#bib.bib36)] used technical indicators as the input into [Wavelet
    Transforms (WT)](#glo.main.wt), [LSTM](#glo.main.lstm) and [Stacked Autoencoders
    (SAEs)](#glo.main.sae) for the forecasting of stock prices. In [[37](#bib.bib37)],
    [CNN](#glo.main.cnn) and [LSTM](#glo.main.lstm) model structures were implemented
    together ([CNN](#glo.main.cnn) was used for stock selection, [LSTM](#glo.main.lstm)
    was used for price prediction).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数算法交易研究集中于股票或指数价格的预测。与此同时，[LSTM](#glo.main.lstm)是这些实施中最受欢迎的[DL](#glo.main.dl)模型。在[[35](#bib.bib35)]中，市场微观结构基于的交易指标被用作输入到[RNN](#glo.main.rnn)中，并结合Graves的[LSTM](#glo.main.lstm)进行算法股票交易的价格预测。Bao等人[[36](#bib.bib36)]使用技术指标作为输入到[Wavelet
    Transforms (WT)](#glo.main.wt)、[LSTM](#glo.main.lstm)和[Stacked Autoencoders (SAEs)](#glo.main.sae)中，以预测股票价格。在[[37](#bib.bib37)]中，[CNN](#glo.main.cnn)和[LSTM](#glo.main.lstm)模型结构一起实现（[CNN](#glo.main.cnn)用于股票选择，[LSTM](#glo.main.lstm)用于价格预测）。
- en: 'Table 1: Algo-trading Applications Embedded with Time Series Forecasting Models'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：嵌入时间序列预测模型的算法交易应用
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Environment |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: Art. | 数据集 | 期间 | 特征集 | 方法 | 绩效标准 | 环境 |
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [[35](#bib.bib35)] | GarantiBank in [BIST](#glo.main.bist), Turkey | 2016
    | [OCHLV](#glo.main.ochlv), Spread, Volatility, Turnover, etc. | [PLR](#glo.main.plr),
    Graves [LSTM](#glo.main.lstm) | [MSE](#glo.main.mse), [RMSE](#glo.main.rmse),
    [MAE](#glo.main.mae), [RSE](#glo.main.rse), Correlation R-square | Spark |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| [[35](#bib.bib35)] | 土耳其[GarantiBank](#glo.main.garanti)在[BIST](#glo.main.bist)
    | 2016 | [OCHLV](#glo.main.ochlv)、差价、波动率、成交量等 | [PLR](#glo.main.plr)、Graves [LSTM](#glo.main.lstm)
    | [MSE](#glo.main.mse)、[RMSE](#glo.main.rmse)、[MAE](#glo.main.mae)、[RSE](#glo.main.rse)、相关性R平方
    | Spark |'
- en: '| [[36](#bib.bib36)] | [CSI](#glo.main.csi) 300, Nifty50, [HSI](#glo.main.hsi),
    Nikkei 225, [S&P500](#glo.main.sp500), [DJIA](#glo.main.djia) | 2010-2016 | [OCHLV](#glo.main.ochlv),
    Technical Indicators | [WT](#glo.main.wt), Stacked autoencoders, [LSTM](#glo.main.lstm)
    | [MAPE](#glo.main.mape), Correlation coefficient, [THEIL-U](#glo.main.theil-u)
    | - |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| [[36](#bib.bib36)] | [CSI](#glo.main.csi) 300、Nifty50、[HSI](#glo.main.hsi)、日经225、[S&P500](#glo.main.sp500)、[DJIA](#glo.main.djia)
    | 2010-2016 | [OCHLV](#glo.main.ochlv)、技术指标 | [WT](#glo.main.wt)、堆叠自编码器、[LSTM](#glo.main.lstm)
    | [MAPE](#glo.main.mape)、相关系数、[THEIL-U](#glo.main.theil-u) | - |'
- en: '| [[37](#bib.bib37)] | Chinese Stocks | 2007-2017 | [OCHLV](#glo.main.ochlv)
    | [CNN](#glo.main.cnn) + [LSTM](#glo.main.lstm) | Annualized Return, Mxm Retracement
    | Python |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| [[37](#bib.bib37)] | 中国股票 | 2007-2017 | [OCHLV](#glo.main.ochlv) | [CNN](#glo.main.cnn)
    + [LSTM](#glo.main.lstm) | 年化收益、Mxm回撤 | Python |'
- en: '| [[38](#bib.bib38)] | 50 stocks from [NYSE](#glo.main.nyse) | 2007-2016 |
    Price data | [SFM](#glo.main.sfm) | [MSE](#glo.main.mse) | - |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| [[38](#bib.bib38)] | [NYSE](#glo.main.nyse)的50只股票 | 2007-2016 | 价格数据 | [SFM](#glo.main.sfm)
    | [MSE](#glo.main.mse) | - |'
- en: '| [[39](#bib.bib39)] | The LOB of 5 stocks of Finnish Stock Market | 2010 |
    FI-2010 dataset: bid/ask and volume | [WMTR](#glo.main.wmtr), [MDA](#glo.main.mda)
    | Accuracy, Precision, Recall, F1-Score | - |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| [[39](#bib.bib39)] | 芬兰股市5只股票的LOB | 2010 | FI-2010数据集：买入/卖出价和成交量 | [WMTR](#glo.main.wmtr)，[MDA](#glo.main.mda)
    | 准确性，精确度，召回率，F1分数 | - |'
- en: '| [[40](#bib.bib40)] | 300 stocks from [SZSE](#glo.main.szse), Commodity |
    2014-2015 | Price data | [FDDR](#glo.main.fddr), [DNN](#glo.main.dnn) +[RL](#glo.main.rl)
    | Profit, return, [SR](#glo.main.sr), profit-loss curves | Keras |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| [[40](#bib.bib40)] | [深交所](#glo.main.szse)的300只股票，商品 | 2014-2015 | 价格数据 |
    [FDDR](#glo.main.fddr)，[DNN](#glo.main.dnn) + [RL](#glo.main.rl) | 利润，收益，[SR](#glo.main.sr)，盈亏曲线
    | Keras |'
- en: '| [[41](#bib.bib41)] | [S&P500](#glo.main.sp500) Index | 1989-2005 | Price
    data, Volume | [LSTM](#glo.main.lstm) | Return, [STD](#glo.main.std), [SR](#glo.main.sr),
    Accuracy | Python, TensorFlow, Keras, R, H2O |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| [[41](#bib.bib41)] | [标普500](#glo.main.sp500) 指数 | 1989-2005 | 价格数据，成交量 |
    [LSTM](#glo.main.lstm) | 收益，[STD](#glo.main.std)，[SR](#glo.main.sr)，准确性 | Python，TensorFlow，Keras，R，H2O
    |'
- en: '| [[42](#bib.bib42)] | Stock of National Bank of Greece (ETE). | 2009-2014
    | [FTSE](#glo.main.ftse) 100, [DJIA](#glo.main.djia), GDAX, [NIKKEI](#glo.main.nikkei)
    225, EUR/USD, Gold | [GASVR](#glo.main.gasvr), [LSTM](#glo.main.lstm) | Return,
    volatility, [SR](#glo.main.sr), Accuracy | Tensorflow |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| [[42](#bib.bib42)] | 希腊国家银行（ETE）股票。 | 2009-2014 | [FTSE](#glo.main.ftse)
    100，[DJIA](#glo.main.djia)，GDAX，[NIKKEI](#glo.main.nikkei) 225，EUR/USD，黄金 | [GASVR](#glo.main.gasvr)，[LSTM](#glo.main.lstm)
    | 收益，波动性，[SR](#glo.main.sr)，准确性 | Tensorflow |'
- en: '| [[43](#bib.bib43)] | Chinese stock-IF-IH-IC contract | 2016-2017 | Decisions
    for price change | [MODRL](#glo.main.modrl) +[LSTM](#glo.main.lstm) | Profit and
    loss, [SR](#glo.main.sr) | - |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| [[43](#bib.bib43)] | 中国股票-IF-IH-IC合约 | 2016-2017 | 价格变动决策 | [MODRL](#glo.main.modrl)
    + [LSTM](#glo.main.lstm) | 利润与亏损，[SR](#glo.main.sr) | - |'
- en: '| [[44](#bib.bib44)] | Singapore Stock Market Index | 2010-2017 | [OCHL](#glo.main.ochl)
    of last 10 days of Index | [DNN](#glo.main.dnn) | [RMSE](#glo.main.rmse), [MAPE](#glo.main.mape),
    Profit, [SR](#glo.main.sr) | - |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| [[44](#bib.bib44)] | 新加坡股市指数 | 2010-2017 | 指数最后10天的[OCHL](#glo.main.ochl)
    | [DNN](#glo.main.dnn) | [RMSE](#glo.main.rmse)，[MAPE](#glo.main.mape)，利润，[SR](#glo.main.sr)
    | - |'
- en: '| [[45](#bib.bib45)] | GBP/USD | 2017 | Price data | Reinforcement Learning
    + [LSTM](#glo.main.lstm) + [NES](#glo.main.nes) | [SR](#glo.main.sr), downside
    deviation ratio, total profit | Python, Keras, Tensorflow |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| [[45](#bib.bib45)] | GBP/USD | 2017 | 价格数据 | 强化学习 + [LSTM](#glo.main.lstm)
    + [NES](#glo.main.nes) | [SR](#glo.main.sr)，下行偏差比率，总利润 | Python，Keras，Tensorflow
    |'
- en: '| [[46](#bib.bib46)] | Commodity, FX future, [ETF](#glo.main.etf) | 1991-2014
    | Price Data | [DNN](#glo.main.dnn) | [SR](#glo.main.sr), capability ratio, return
    | C++, Python |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| [[46](#bib.bib46)] | 商品，外汇期货，[ETF](#glo.main.etf) | 1991-2014 | 价格数据 | [DNN](#glo.main.dnn)
    | [SR](#glo.main.sr)，能力比率，收益 | C++，Python |'
- en: '| [[47](#bib.bib47)] | USD/GBP, [S&P500](#glo.main.sp500), [FTSE](#glo.main.ftse)
    100, oil, gold | 2016 | Price data | [AE](#glo.main.ae) + [CNN](#glo.main.cnn)
    | [SR](#glo.main.sr), % volatility, avg return/trans, rate of return | H2O |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| [[47](#bib.bib47)] | USD/GBP，[标普500](#glo.main.sp500)，[FTSE](#glo.main.ftse)
    100，油，黄金 | 2016 | 价格数据 | [AE](#glo.main.ae) + [CNN](#glo.main.cnn) | [SR](#glo.main.sr)，%波动性，平均收益/交易，收益率
    | H2O |'
- en: '| [[48](#bib.bib48)] | Bitcoin, Dash, Ripple, Monero, Litecoin, Dogecoin, Nxt,
    Namecoin | 2014-2017 | MA, BOLL, the CRIX returns, Euribor interest rates, [OCHLV](#glo.main.ochlv)
    | [LSTM](#glo.main.lstm), [RNN](#glo.main.rnn), [MLP](#glo.main.mlp) | Accuracy,
    F1-measure | Python, Tensorflow |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| [[48](#bib.bib48)] | 比特币，Dash，Ripple，Monero，莱特币，狗狗币，Nxt，Namecoin | 2014-2017
    | MA，BOLL，CRIX收益，Euribor利率，[OCHLV](#glo.main.ochlv) | [LSTM](#glo.main.lstm)，[RNN](#glo.main.rnn)，[MLP](#glo.main.mlp)
    | 准确性，F1-measure | Python，Tensorflow |'
- en: '| [[49](#bib.bib49)] | [S&P500](#glo.main.sp500), [KOSPI](#glo.main.kospi),
    [HSI](#glo.main.hsi), and EuroStoxx50 | 1987-2017 | 200-days stock price | Deep
    Q-Learning, [DNN](#glo.main.dnn) | Total profit, Correlation | - |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| [[49](#bib.bib49)] | [标普500](#glo.main.sp500)，[KOSPI](#glo.main.kospi)，[HSI](#glo.main.hsi)
    和 EuroStoxx50 | 1987-2017 | 200天股票价格 | 深度Q学习，[DNN](#glo.main.dnn) | 总利润，相关性 |
    - |'
- en: '| [[50](#bib.bib50)] | Stocks in the [S&P500](#glo.main.sp500) | 1990-2015
    | Price data | [DNN](#glo.main.dnn), [GBT](#glo.main.gbt), [RF](#glo.main.rf)
    | Mean return, [MDD](#glo.main.mdd), Calmar ratio | H2O |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| [[50](#bib.bib50)] | [标普500](#glo.main.sp500)中的股票 | 1990-2015 | 价格数据 | [DNN](#glo.main.dnn)，[GBT](#glo.main.gbt)，[RF](#glo.main.rf)
    | 平均收益，[MDD](#glo.main.mdd)，Calmar比率 | H2O |'
- en: '| [[51](#bib.bib51)] | Fundamental and Technical Data, Economic Data | - |
    Fundamental , technical and market information | [CNN](#glo.main.cnn) | - | -
    |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| [[51](#bib.bib51)] | 基本面和技术面数据，经济数据 | - | 基本面、技术面和市场信息 | [CNN](#glo.main.cnn)
    | - | - |'
- en: Using a different model, Zhang et. al. [[38](#bib.bib38)] proposed a novel [State
    Frequency Memory (SFM)](#glo.main.sfm) recurrent network for stock price prediction
    with multiple frequency trading patterns and achieved better prediction and trading
    performances. In an [HFT](#glo.main.hft) trading system, Tran et al. [[39](#bib.bib39)]
    developed a [DL](#glo.main.dl) model that implements price change forecasting
    through mid-price prediction using high-frequency limit order book data with tensor
    representation. In [[40](#bib.bib40)], the authors used [Fuzzy Deep Direct Reinforcement
    Learning (FDDR)](#glo.main.fddr) for stock price prediction and trading signal
    generation.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 张等人[[38](#bib.bib38)]提出了一种新型的[状态频率记忆 (SFM)](#glo.main.sfm)递归网络，用于具有多频率交易模式的股票价格预测，并实现了更好的预测和交易表现。在[高频交易
    (HFT)](#glo.main.hft)系统中，Tran等人[[39](#bib.bib39)]开发了一个[深度学习 (DL)](#glo.main.dl)模型，通过使用高频限价订单簿数据的张量表示来实现价格变化预测。在[[40](#bib.bib40)]中，作者使用了[模糊深度直接强化学习
    (FDDR)](#glo.main.fddr)进行股票价格预测和交易信号生成。
- en: For index prediction, the following studies are noteworthy. In [[41](#bib.bib41)],
    the price prediction of S&P500 index using [LSTM](#glo.main.lstm) was implemented.
    Mourelatos et al. [[42](#bib.bib42)] compared the performance of [LSTM](#glo.main.lstm)
    and [](#glo.main.gasvr)[GA](#glo.main.ga) with a [SVR](#glo.main.svr) (GASVR)
    for Greek Stock Exchange Index prediction. Si et al. [[43](#bib.bib43)] implemented
    Chinese intraday futures market trading model with [DRL](#glo.main.drl) and [LSTM](#glo.main.lstm).
    Yong et al. [[44](#bib.bib44)] used feed-forward [DNN](#glo.main.dnn) method and
    [Open,Close,High, Low (OCHL)](#glo.main.ochl) of the time series index data to
    predict Singapore Stock Market index data.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 对于指数预测，以下研究值得注意。在[[41](#bib.bib41)]中，实现了使用[LSTM](#glo.main.lstm)对S&P500指数的价格预测。Mourelatos等人[[42](#bib.bib42)]比较了[LSTM](#glo.main.lstm)和[遗传算法
    (GA)](#glo.main.ga)与[支持向量回归 (SVR)](#glo.main.svr)（GASVR）在希腊股票市场指数预测中的表现。Si等人[[43](#bib.bib43)]实施了中国日内期货市场交易模型，结合[深度强化学习
    (DRL)](#glo.main.drl)和[LSTM](#glo.main.lstm)。Yong等人[[44](#bib.bib44)]使用了前馈[DNN](#glo.main.dnn)方法和时间序列数据的[开盘、收盘、最高、最低
    (OCHL)](#glo.main.ochl)来预测新加坡股票市场指数数据。
- en: Forex or cryptocurrency trading was implemented in some studies. In [[45](#bib.bib45)],
    agent inspired trading using deep (recurrent) reinforcement learning and [LSTM](#glo.main.lstm)
    was implemented and tested on the trading of GBP/USD. In [[46](#bib.bib46)], feedforward
    deep [MLP](#glo.main.mlp) was implemented for the prediction of commodities and
    FX trading prices. Korczak et al. [[47](#bib.bib47)] implemented a forex trading
    (GBP/PLN) model using several different input parameters on a multi-agent-based
    trading environment. One of the agents was using [CNN](#glo.main.cnn) as the prediction
    model and outperformed all other models.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 外汇或加密货币交易在一些研究中也有所实现。在[[45](#bib.bib45)]中，使用深度（递归）强化学习和[LSTM](#glo.main.lstm)的代理启发交易在GBP/USD交易中得到了实施和测试。在[[46](#bib.bib46)]中，前馈深度[MLP](#glo.main.mlp)被应用于商品和外汇交易价格的预测。Korczak等人[[47](#bib.bib47)]在一个基于多代理的交易环境中使用了几种不同的输入参数来实施外汇交易（GBP/PLN）模型。其中一个代理使用了[CNN](#glo.main.cnn)作为预测模型，且优于所有其他模型。
- en: On the cryptocurrency side, Spilak et al. [[48](#bib.bib48)] used several cryptocurrencies
    (Bitcoin, Dash, Ripple, Monero, Litecoin, Dogecoin, Nxt, Namecoin) to construct
    a dynamic portfolio using [LSTM](#glo.main.lstm), [RNN](#glo.main.rnn), [MLP](#glo.main.mlp)
    methods.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在加密货币方面，Spilak等人[[48](#bib.bib48)]使用了多个加密货币（比特币、Dash、Ripple、Monero、莱特币、Dogecoin、Nxt、Namecoin）来构建一个动态投资组合，使用了[LSTM](#glo.main.lstm)、[RNN](#glo.main.rnn)和[MLP](#glo.main.mlp)方法。
- en: 'In a versatile study, Jeong et al. [[49](#bib.bib49)] combined deep Q-learning
    and [DNN](#glo.main.dnn) to implement price forecasting and they intended to solve
    three separate problems: Increasing profit in a market, prediction of the number
    of shares to trade, and preventing overfitting with insufficient financial data.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在一项多功能研究中，Jeong等人[[49](#bib.bib49)]结合了深度Q学习和[DNN](#glo.main.dnn)来实现价格预测，他们旨在解决三个独立问题：增加市场利润、预测交易股数以及防止金融数据不足引起的过拟合。
- en: In [[52](#bib.bib52)], technical analysis indicator’s ([Relative Strength Index
    (RSI)](#glo.main.rsi)) buy & sell limits were optimized with [GA](#glo.main.ga)
    which was used for buy-sell signals. After optimization, [DMLP](#glo.main.dmlp)
    was also used for function approximation. In [[53](#bib.bib53)], the authors combined
    deep [Fully Connected Neural Network (FNN)](#glo.main.fnn) with a selective trade
    strategy unit to predict the next price. In [[54](#bib.bib54)], the crossover
    and [Moving Average Convergence and Divergence (MACD)](#glo.main.macd) signals
    were used to predict the trend of the Dow 30 stocks’ prices. Sirignano et al.
    [[55](#bib.bib55)] proposed a novel method that used limit order book flow and
    history information for the determination of the stock movements using [LSTM](#glo.main.lstm)
    model. Tsantekidis et al. [[56](#bib.bib56)] also used limit order book time series
    data and [LSTM](#glo.main.lstm) method for the trend prediction.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[52](#bib.bib52)]中，技术分析指标（[相对强弱指数 (RSI)](#glo.main.rsi)）的买卖限度经过了优化，优化过程中使用了[GA](#glo.main.ga)作为买卖信号。在优化后，[DMLP](#glo.main.dmlp)也用于函数近似。在[[53](#bib.bib53)]中，作者将深度[全连接神经网络
    (FNN)](#glo.main.fnn)与选择性交易策略单元相结合，以预测下一个价格。在[[54](#bib.bib54)]中，使用了交叉点和[移动平均线趋同性与发散性
    (MACD)](#glo.main.macd)信号来预测道琼斯30支股票价格的趋势。Sirignano 等人 [[55](#bib.bib55)] 提出了一种新方法，利用限价单簿流量和历史信息来确定股票走势，使用了[LSTM](#glo.main.lstm)模型。Tsantekidis
    等人 [[56](#bib.bib56)] 也使用了限价单簿时间序列数据和[LSTM](#glo.main.lstm)方法进行趋势预测。
- en: Several studies focused on utilizing [CNN](#glo.main.cnn) based models due to
    their success in image classification problems. However, in order to do that,
    the financial input data needed to be transformed into images which required some
    creative preprocessing. Gudelek et al. [[57](#bib.bib57)] converted time series
    of price data to 2-dimensional images using technical analysis and classified
    them with deep [CNN](#glo.main.cnn). Similarly, Sezer et al. [[58](#bib.bib58)]
    also proposed a novel technique that converts financial time series data that
    consisted of technical analysis indicator outputs to 2-dimensional images and
    classified these images using [CNN](#glo.main.cnn) to determine the trading signals.
    In [[59](#bib.bib59)], candlestick chart graphs were converted into 2-dimensional
    images. Then, unsupervised convolutional [AE](#glo.main.ae) was fed with the images
    to implement portfolio construction. Tsantekidis et al. [[60](#bib.bib60)] proposed
    a novel method that used the last 100 entries from the limit order book to create
    a 2-dimensional image for the stock price prediction using [CNN](#glo.main.cnn)
    method. In [[61](#bib.bib61)], an innovative method was proposed that uses [CNN](#glo.main.cnn)
    with correlated features combined together to predict the trend of the stocks
    prices. Finally, Sezer et al. [[62](#bib.bib62)] directly used bar chart images
    as inputs to [CNN](#glo.main.cnn) and predicted if the image class was Buy, Hold
    or Sell, hence a corresponding Algo-trading model was developed.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究专注于利用基于[CNN](#glo.main.cnn)的模型，因为它们在图像分类问题中取得了成功。然而，为了实现这一点，需要将金融输入数据转换为图像，这需要一些创造性的预处理。Gudelek
    等人 [[57](#bib.bib57)] 将价格数据的时间序列转换为二维图像，使用技术分析，并用深度[CNN](#glo.main.cnn)对其进行分类。同样，Sezer
    等人 [[58](#bib.bib58)] 也提出了一种新技术，将包含技术分析指标输出的金融时间序列数据转换为二维图像，并使用[CNN](#glo.main.cnn)对这些图像进行分类，以确定交易信号。在[[59](#bib.bib59)]中，蜡烛图图表被转换为二维图像。然后，将图像输入到无监督卷积[AE](#glo.main.ae)中以实施投资组合构建。Tsantekidis
    等人 [[60](#bib.bib60)] 提出了一种新方法，使用来自限价单簿的最后100条记录创建二维图像，用于股票价格预测，使用了[CNN](#glo.main.cnn)方法。在[[61](#bib.bib61)]中，提出了一种创新方法，利用[CNN](#glo.main.cnn)与相关特征结合预测股票价格趋势。最后，Sezer
    等人 [[62](#bib.bib62)] 直接将条形图图像作为输入到[CNN](#glo.main.cnn)中，并预测图像类别是买入、持有还是卖出，从而开发了相应的算法交易模型。
- en: 'Table 2: Classification (Buy-sell Signal, or Trend Detection) Based Algo-trading
    Models'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：基于分类（买卖信号或趋势检测）的算法交易模型
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Environment |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | 数据集 | 时期 | 特征集 | 方法 | 性能标准 | 环境 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [[52](#bib.bib52)] | Stocks in Dow30 | 1997-2017 | [RSI](#glo.main.rsi) |
    [DMLP](#glo.main.dmlp) with genetic algorithm | Annualized return | Spark MLlib,
    Java |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| [[52](#bib.bib52)] | 道琼斯30支股票 | 1997-2017 | [相对强弱指数 (RSI)](#glo.main.rsi)
    | 使用遗传算法的[DMLP](#glo.main.dmlp) | 年化回报率 | Spark MLlib, Java |'
- en: '| [[53](#bib.bib53)] | [SPY](#glo.main.spy)  [ETF](#glo.main.etf), 10 stocks
    from [S&P500](#glo.main.sp500) | 2014-2016 | Price data | [FFNN](#glo.main.ffnn)
    | Cumulative gain | MatConvNet, Matlab |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| [[53](#bib.bib53)] | [SPY](#glo.main.spy) [ETF](#glo.main.etf)，来自[S&P500](#glo.main.sp500)的10只股票
    | 2014-2016 | 价格数据 | [FFNN](#glo.main.ffnn) | 累积收益 | MatConvNet, Matlab |'
- en: '| [[54](#bib.bib54)] | Dow30 stocks | 2012-2016 | Close data and several technical
    indicators | [LSTM](#glo.main.lstm) | Accuracy | Python, Keras, Tensorflow, [TALIB](#glo.main.talib)
    |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| [[54](#bib.bib54)] | Dow30股票 | 2012-2016 | 收盘数据和若干技术指标 | [LSTM](#glo.main.lstm)
    | 准确率 | Python, Keras, Tensorflow, [TALIB](#glo.main.talib) |'
- en: '| [[55](#bib.bib55)] | High-frequency record of all orders | 2014-2017 | Price
    data, record of all orders, transactions | [LSTM](#glo.main.lstm) | Accuracy |
    - |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| [[55](#bib.bib55)] | 高频记录的所有订单 | 2014-2017 | 价格数据、所有订单记录、交易 | [LSTM](#glo.main.lstm)
    | 准确率 | - |'
- en: '| [[56](#bib.bib56)] | Nasdaq Nordic (Kesko Oyj, Outokumpu Oyj, Sampo, Rautaruukki,
    Wartsila Oyj) | 2010 | Price and volume data in [LOB](#glo.main.lob) | [LSTM](#glo.main.lstm)
    | Precision, Recall, F1-score, Cohen’s k | - |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| [[56](#bib.bib56)] | 纳斯达克北欧（Kesko Oyj, Outokumpu Oyj, Sampo, Rautaruukki,
    Wartsila Oyj） | 2010 | [LOB](#glo.main.lob)中的价格和成交量数据 | [LSTM](#glo.main.lstm)
    | 精度、召回率、F1分数、Cohen’s k | - |'
- en: '| [[57](#bib.bib57)] | 17 [ETFs](#glo.main.etf) | 2000-2016 | Price data, technical
    indicators | [CNN](#glo.main.cnn) | Accuracy, [MSE](#glo.main.mse), Profit, [AUROC](#glo.main.auroc)
    | Keras, Tensorflow |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| [[57](#bib.bib57)] | 17只[ETFs](#glo.main.etf) | 2000-2016 | 价格数据、技术指标 | [CNN](#glo.main.cnn)
    | 准确率、[MSE](#glo.main.mse)、利润、[AUROC](#glo.main.auroc) | Keras, Tensorflow |'
- en: '| [[58](#bib.bib58)] | Stocks in Dow30 and 9 Top Volume [ETFs](#glo.main.etf)
    | 1997-2017 | Price data, technical indicators | [CNN](#glo.main.cnn) with feature
    imaging | Recall, precision, F1-score, annualized return | Python, Keras, Tensorflow,
    Java |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| [[58](#bib.bib58)] | Dow30中的股票和9个顶级成交量[ETFs](#glo.main.etf) | 1997-2017 |
    价格数据、技术指标 | 带有特征映射的[CNN](#glo.main.cnn) | 召回率、精度、F1分数、年化收益 | Python, Keras, Tensorflow,
    Java |'
- en: '| [[59](#bib.bib59)] | [FTSE](#glo.main.ftse) 100 | 2000-2017 | Price data
    | [CAE](#glo.main.cae) | [TR](#glo.main.tr), [SR](#glo.main.sr), [MDD](#glo.main.mdd),
    mean return | - |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| [[59](#bib.bib59)] | [FTSE](#glo.main.ftse) 100 | 2000-2017 | 价格数据 | [CAE](#glo.main.cae)
    | [TR](#glo.main.tr)、[SR](#glo.main.sr)、[MDD](#glo.main.mdd)、均值收益 | - |'
- en: '| [[60](#bib.bib60)] | Nasdaq Nordic (Kesko Oyj, Outokumpu Oyj, Sampo, Rautaruukki,
    Wartsila Oyj) | 2010 | Price, Volume data, 10 orders of the [LOB](#glo.main.lob)
    | [CNN](#glo.main.cnn) | Precision, Recall, F1-score, Cohen’s k | Theano, Scikit
    learn, Python |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| [[60](#bib.bib60)] | 纳斯达克北欧（Kesko Oyj, Outokumpu Oyj, Sampo, Rautaruukki,
    Wartsila Oyj） | 2010 | 价格、成交量数据，10个[LOB](#glo.main.lob)订单 | [CNN](#glo.main.cnn)
    | 精度、召回率、F1分数、Cohen’s k | Theano, Scikit learn, Python |'
- en: '| [[61](#bib.bib61)] | Borsa Istanbul 100 Stocks | 2011-2015 | 75 technical
    indicators and [OCHLV](#glo.main.ochlv) | [CNN](#glo.main.cnn) | Accuracy | Keras
    |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| [[61](#bib.bib61)] | 伊斯坦布尔证券交易所100只股票 | 2011-2015 | 75种技术指标和[OCHLV](#glo.main.ochlv)
    | [CNN](#glo.main.cnn) | 准确率 | Keras |'
- en: '| [[62](#bib.bib62)] | [ETFs](#glo.main.etf) and Dow30 | 1997-2007 | Price
    data | [CNN](#glo.main.cnn) with feature imaging | Annualized return | Keras,
    Tensorflow |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| [[62](#bib.bib62)] | [ETFs](#glo.main.etf)和Dow30 | 1997-2007 | 价格数据 | 带有特征映射的[CNN](#glo.main.cnn)
    | 年化收益 | Keras, Tensorflow |'
- en: '| [[63](#bib.bib63)] | 8 experimental assets from bond/derivative market |
    - | Asset prices data | [RL](#glo.main.rl), [DNN](#glo.main.dnn), Genetic Algorithm
    | Learning and genetic algorithm error | - |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| [[63](#bib.bib63)] | 8种来自债券/衍生品市场的实验资产 | - | 资产价格数据 | [RL](#glo.main.rl),
    [DNN](#glo.main.dnn), 遗传算法 | 学习和遗传算法误差 | - |'
- en: '| [[64](#bib.bib64)] | 10 stocks from [S&P500](#glo.main.sp500) | - | Stock
    Prices | [TDNN](#glo.main.tdnn), [RNN](#glo.main.rnn), [PNN](#glo.main.pnn) |
    Missed opportunities, false alarms ratio | - |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| [[64](#bib.bib64)] | 来自[S&P500](#glo.main.sp500)的10只股票 | - | 股票价格 | [TDNN](#glo.main.tdnn),
    [RNN](#glo.main.rnn), [PNN](#glo.main.pnn) | 错失机会、误报率 | - |'
- en: '| [[65](#bib.bib65)] | London Stock Exchange | 2007-2008 | Limit order book
    state, trades, buy/sell orders, order deletions | [CNN](#glo.main.cnn) | Accuracy,
    kappa | Caffe |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| [[65](#bib.bib65)] | 伦敦证券交易所 | 2007-2008 | 限价订单簿状态、交易、买/卖订单、订单删除 | [CNN](#glo.main.cnn)
    | 准确率、kappa | Caffe |'
- en: '| [[66](#bib.bib66)] | Cryptocurrencies, Bitcoin | 2014-2017 | Price data |
    [CNN](#glo.main.cnn), [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm) | Accumulative
    portfolio value, [MDD](#glo.main.mdd), [SR](#glo.main.sr) | - |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| [[66](#bib.bib66)] | 加密货币，比特币 | 2014-2017 | 价格数据 | [CNN](#glo.main.cnn)、[RNN](#glo.main.rnn)、[LSTM](#glo.main.lstm)
    | 累积投资组合价值、[MDD](#glo.main.mdd)、[SR](#glo.main.sr) | - |'
- en: Serrano et al. [[63](#bib.bib63)] proposed a novel method called “GoldAI Sachs”
    Asset Banker Reinforcement Learning Algorithm for algorithmic trading. The proposed
    method used a random neural network, [GP](#glo.main.gp), and [Reinforcement Learning
    (RL)](#glo.main.rl) to generate the trading signals. Saad et al. [[64](#bib.bib64)]
    compared [Timedelay Neural Network (TDNN)](#glo.main.tdnn), [RNN](#glo.main.rnn)
    and [Probabilistic Neural Network (PNN)](#glo.main.pnn) for trend detection using
    10 stocks from S&P500\. In [[65](#bib.bib65)], [HFT](#glo.main.hft) microstructures
    forecasting with [CNN](#glo.main.cnn) method was performed. In [[66](#bib.bib66)],
    cryptocurrency portfolio management based on three different proposed models (basic
    [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm) and [CNN](#glo.main.cnn)) was implemented.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Serrano 等人 [[63](#bib.bib63)] 提出了一个新方法，称为“GoldAI Sachs”资产银行家强化学习算法，用于算法交易。该方法使用了随机神经网络、[GP](#glo.main.gp)
    和 [强化学习 (RL)](#glo.main.rl) 来生成交易信号。Saad 等人 [[64](#bib.bib64)] 比较了 [时延神经网络 (TDNN)](#glo.main.tdnn)、[RNN](#glo.main.rnn)
    和 [概率神经网络 (PNN)](#glo.main.pnn) 在使用10只S&P500股票进行趋势检测的效果。在 [[65](#bib.bib65)] 中，进行了
    [高频交易 (HFT)](#glo.main.hft) 微观结构预测，使用了 [CNN](#glo.main.cnn) 方法。在 [[66](#bib.bib66)]
    中，基于三种不同提出的模型（基础 [RNN](#glo.main.rnn)、[LSTM](#glo.main.lstm) 和 [CNN](#glo.main.cnn)）的加密货币投资组合管理得到了实施。
- en: Tino et al. [[67](#bib.bib67)] used [The Deutscher Aktienindex (DAX)](#glo.main.dax),
    [London Financial Times Stock Exchange Index (FTSE)](#glo.main.ftse) 100, call
    and put options prices to predict the changes with Markov models and used the
    financial time series data to predict volatility changes with [RNN](#glo.main.rnn).
    Meanwhile, Chen et al. [[68](#bib.bib68)] proposed a method that uses a filterbank
    [CNN](#glo.main.cnn) Algorithm on 15x15 volatility times series converted synthetic
    images. In the study, the financial domain knowledge and filterbank mechanism
    were combined to determine the trading signals. Bari et al. [[69](#bib.bib69)]
    used text mining to extract information from the tweets and financial news and
    used [LSTM](#glo.main.lstm), [RNN](#glo.main.rnn), [Gated-Recurrent Unit (GRU)](#glo.main.gru)
    for the generation of the trading signals. Dixon et al. [[70](#bib.bib70)] used
    [RNN](#glo.main.rnn) for the sequence classification of the limit order book to
    predict a next event price-flip.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Tino 等人 [[67](#bib.bib67)] 使用了 [德国股票指数 (DAX)](#glo.main.dax)、[伦敦金融时报股票交易所指数
    (FTSE)](#glo.main.ftse) 100 的看涨和看跌期权价格，通过马尔可夫模型预测变化，并利用金融时间序列数据通过 [RNN](#glo.main.rnn)
    预测波动性变化。同时，Chen 等人 [[68](#bib.bib68)] 提出了一种方法，使用滤波器组 [CNN](#glo.main.cnn) 算法在15x15的波动率时间序列转换合成图像上进行处理。在该研究中，金融领域知识与滤波器组机制相结合，以确定交易信号。Bari
    等人 [[69](#bib.bib69)] 使用文本挖掘从推文和金融新闻中提取信息，并使用 [LSTM](#glo.main.lstm)、[RNN](#glo.main.rnn)、[门控递归单元
    (GRU)](#glo.main.gru) 生成交易信号。Dixon 等人 [[70](#bib.bib70)] 使用 [RNN](#glo.main.rnn)
    对限价单簿进行序列分类，以预测下一事件的价格波动。
- en: 'Table 3: Stand-alone and/or Other Algorithmic Models'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：独立和/或其他算法模型
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Environment |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| Art. | 数据集 | 期间 | 特征集 | 方法 | 性能标准 | 环境 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [[67](#bib.bib67)] | [DAX](#glo.main.dax), [FTSE](#glo.main.ftse) 100, call/put
    options | 1991-1998 | Price data | Markov model, [RNN](#glo.main.rnn) | Ewa-measure,
    iv, daily profits’ mean and std | - |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| [[67](#bib.bib67)] | [DAX](#glo.main.dax)、[FTSE](#glo.main.ftse) 100、看涨/看跌期权
    | 1991-1998 | 价格数据 | 马尔可夫模型、[RNN](#glo.main.rnn) | Ewa-度量、iv、每日利润的均值和标准差 | - |'
- en: '| [[68](#bib.bib68)] | Taiwan Stock Index Futures, Mini Index Futures | 2012-2014
    | Price data to image | Visualization method + [CNN](#glo.main.cnn) | Accumulated
    profits,accuracy | - |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| [[68](#bib.bib68)] | 台湾股票指数期货、迷你指数期货 | 2012-2014 | 价格数据转图像 | 可视化方法 + [CNN](#glo.main.cnn)
    | 累计利润、准确率 | - |'
- en: '| [[69](#bib.bib69)] | Energy-Sector/ Company-Centric Tweets in [S&P500](#glo.main.sp500)
    | 2015-2016 | Text and Price data | [LSTM](#glo.main.lstm), [RNN](#glo.main.rnn),
    [GRU](#glo.main.gru) | Return, [SR](#glo.main.sr), precision, recall, accuracy
    | Python, Tweepy API |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| [[69](#bib.bib69)] | [S&P500](#glo.main.sp500) 的能源部门/公司中心推文 | 2015-2016 |
    文本和价格数据 | [LSTM](#glo.main.lstm)、[RNN](#glo.main.rnn)、[GRU](#glo.main.gru) | 收益、[SR](#glo.main.sr)、精确度、召回率、准确率
    | Python、Tweepy API |'
- en: '| [[70](#bib.bib70)] | [CME](#glo.main.cme) FIX message | 2016 | Limit order
    book, time-stamp, price data | [RNN](#glo.main.rnn) | Precision, recall, F1-measure
    | Python, TensorFlow, R |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| [[70](#bib.bib70)] | [CME](#glo.main.cme) FIX 消息 | 2016 | 限价单簿、时间戳、价格数据 |
    [RNN](#glo.main.rnn) | 精确度、召回率、F1度量 | Python、TensorFlow、R |'
- en: '| [[71](#bib.bib71)] | Taiwan stock index futures (TAIFEX) | 2017 | Price data
    | Agent based [RL](#glo.main.rl) with [CNN](#glo.main.cnn) pre-trained | Accuracy
    | - |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| [[71](#bib.bib71)] | 台湾股指期货（TAIFEX） | 2017 | 价格数据 | 基于代理的[RL](#glo.main.rl)与预训练的[CNN](#glo.main.cnn)
    | 准确性 | - |'
- en: '| [[72](#bib.bib72)] | Stocks from [S&P500](#glo.main.sp500) | 2010-2016 |
    [OCHLV](#glo.main.ochlv) | [DCNL](#glo.main.dcnl) | [PCC](#glo.main.pcc), [DTW](#glo.main.dtw),
    [VWL](#glo.main.vwl) | Pytorch |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| [[72](#bib.bib72)] | 来自[S&P500](#glo.main.sp500)的股票 | 2010-2016 | [OCHLV](#glo.main.ochlv)
    | [DCNL](#glo.main.dcnl) | [PCC](#glo.main.pcc)、[DTW](#glo.main.dtw)、[VWL](#glo.main.vwl)
    | Pytorch |'
- en: '| [[73](#bib.bib73)] | News from NowNews, AppleDaily, LTN, MoneyDJ for 18 stocks
    | 2013-2014 | Text, Sentiment | [DNN](#glo.main.dnn) | Return | Python, Tensorflow
    |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| [[73](#bib.bib73)] | 来自NowNews、AppleDaily、LTN、MoneyDJ的18只股票新闻 | 2013-2014
    | 文本、情感 | [DNN](#glo.main.dnn) | 收益 | Python，Tensorflow |'
- en: '| [[74](#bib.bib74)] | 489 stocks from [S&P500](#glo.main.sp500) and [NASDAQ](#glo.main.nasdaq)-100
    | 2014-2015 | Limit Order Book | Spatial neural network | Cross entropy error
    | NVIDIA’s cuDNN |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| [[74](#bib.bib74)] | 来自[S&P500](#glo.main.sp500)和[NASDAQ](#glo.main.nasdaq)-100的489只股票
    | 2014-2015 | 限价订单簿 | 空间神经网络 | 交叉熵误差 | NVIDIA的cuDNN |'
- en: '| [[75](#bib.bib75)] | Experimental dataset | - | Price data | [DRL](#glo.main.drl)
    with [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm), [GRU](#glo.main.gru), [MLP](#glo.main.mlp)
    | Mean profit | Python |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| [[75](#bib.bib75)] | 实验数据集 | - | 价格数据 | [DRL](#glo.main.drl)与[CNN](#glo.main.cnn)、[LSTM](#glo.main.lstm)、[GRU](#glo.main.gru)、[MLP](#glo.main.mlp)
    | 平均利润 | Python |'
- en: Chen et al. [[71](#bib.bib71)] used 1-dimensional [CNN](#glo.main.cnn) with
    an agent-based [RL](#glo.main.rl) algorithm on the Taiwan stock index futures
    (TAIFEX) dataset. Wang et al. [[72](#bib.bib72)] proposed a Deep Co-investment
    Network Learning (DeepCNL) method that used convolutional and [RNN](#glo.main.rnn)
    layers. The investment pattern was determined using the extracted Rise-Fall trends.
    Day et al. [[73](#bib.bib73)] used financial sentiment analysis using text mining
    and [DNN](#glo.main.dnn) for stock algorithmic trading. Sirignano et al. [[74](#bib.bib74)]
    proposed a “spatial neural network” model that used limit order book and spatial
    features for algorithmic trading. Their model estimates the best bid-ask prices
    using bid, ask prices in the limit order book. Gao et al. [[75](#bib.bib75)] used
    [GRU](#glo.main.gru), [LSTM](#glo.main.lstm) units, [CNN](#glo.main.cnn), and
    [MLP](#glo.main.mlp) to model Q values for the implementation of the [DRL](#glo.main.drl)
    method.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 陈等人[[71](#bib.bib71)]在台湾股指期货（TAIFEX）数据集上使用了1维的[CNN](#glo.main.cnn)与基于代理的[RL](#glo.main.rl)算法。王等人[[72](#bib.bib72)]提出了一种深度共同投资网络学习（DeepCNL）方法，该方法使用了卷积层和[RNN](#glo.main.rnn)层。通过提取的涨跌趋势确定了投资模式。戴等人[[73](#bib.bib73)]使用文本挖掘和[DNN](#glo.main.dnn)进行金融情感分析用于股票算法交易。Sirignano等人[[74](#bib.bib74)]提出了一种“空间神经网络”模型，该模型使用限价订单簿和空间特征进行算法交易。他们的模型通过限价订单簿中的买入价和卖出价估计最佳的买卖价格。高等人[[75](#bib.bib75)]使用[GRU](#glo.main.gru)、[LSTM](#glo.main.lstm)单元、[CNN](#glo.main.cnn)和[MLP](#glo.main.mlp)来建模Q值，用于实现[DRL](#glo.main.drl)方法。
- en: 4.2 Risk Assessment
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 风险评估
- en: Another study area that has been of interest to [DL](#glo.main.dl) researchers
    is Risk Assessment which identifies the “riskiness" of any given asset, firm,
    person, product, bank, etc. Several different versions of this general problem
    exist, such as bankruptcy prediction, credit scoring, credit evaluation, loan/insurance
    underwriting, bond rating, loan application, consumer credit determination, corporate
    credit rating, mortgage choice decision, financial distress prediction, business
    failure prediction. Correctly identifying the risk status in such cases is crucial,
    since asset pricing is highly dependent on these risk assessment measures. The
    mortgage crisis based on improper risk assessment of [Credit Default Swaps (CDS)](#glo.main.cds)
    between financial institutions caused the real-estate bubble to burst in 2008
    and resulted in the Great Recession [[76](#bib.bib76)].
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个引起[DL](#glo.main.dl)研究者兴趣的研究领域是风险评估，它识别任何给定资产、公司、个人、产品、银行等的“风险性”。这个一般问题存在几个不同版本，如破产预测、信用评分、信用评估、贷款/保险承保、债券评级、贷款申请、消费者信用确定、公司信用评级、抵押选择决策、金融困境预测、商业失败预测。在这些情况下正确识别风险状态至关重要，因为资产定价高度依赖于这些风险评估措施。基于金融机构之间不当风险评估的[信用违约互换（CDS）](#glo.main.cds)的抵押危机导致了2008年的房地产泡沫破裂，并导致了大萧条[[76](#bib.bib76)]。
- en: The majority of the risk assessment studies concentrate on credit scoring and
    bank distress classification. However, there are also a few papers covering mortgage
    default possibility, risky transaction detection or crisis forecasting. Meanwhile,
    there are some anomaly detection studies for risk assessment, most of which also
    fall under the "Fraud Detection" category which will be covered in the next subsection.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数风险评估研究集中在信用评分和银行困境分类上。然而，也有一些论文涉及抵押贷款违约可能性、风险交易检测或危机预测。同时，也有一些针对风险评估的异常检测研究，其中大多数也属于“欺诈检测”类别，这将在下一小节中讨论。
- en: 'Table 4: Credit Scoring or Classification Studies'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：信用评分或分类研究
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | 数据集 | 时间段 | 特征集 | 方法 | 性能标准 | 环境 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [[77](#bib.bib77)] | The XR 14 [CDS](#glo.main.cds) contracts | 2016 | Recovery
    rate, spreads, sector and region | [DBN](#glo.main.dbn) +[RBM](#glo.main.rbm)
    | [AUROC](#glo.main.auroc), [FN](#glo.main.fn), [FP](#glo.main.fp), Accuracy |
    WEKA |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| [[77](#bib.bib77)] | XR 14 [CDS](#glo.main.cds) 合约 | 2016 | 回收率、利差、行业和地区
    | [DBN](#glo.main.dbn) + [RBM](#glo.main.rbm) | [AUROC](#glo.main.auroc), [FN](#glo.main.fn),
    [FP](#glo.main.fp), 准确率 | WEKA |'
- en: '| [[78](#bib.bib78)] | German, Japanese credit datasets | - | Personal financial
    variables | [SVM](#glo.main.svm) + [DBN](#glo.main.dbn) | Weighted-accuracy, [TP](#glo.main.tp),
    [TN](#glo.main.tn) | - |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| [[78](#bib.bib78)] | 德国、日语信用数据集 | - | 个人财务变量 | [SVM](#glo.main.svm) + [DBN](#glo.main.dbn)
    | 加权准确率, [TP](#glo.main.tp), [TN](#glo.main.tn) | - |'
- en: '| [[79](#bib.bib79)] | Credit data from Kaggle | - | Personal financial variables
    | [DNN](#glo.main.dnn) | Accuracy, [TP](#glo.main.tp), [TN](#glo.main.tn), G-mean
    | - |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| [[79](#bib.bib79)] | 来自Kaggle的信用数据 | - | 个人财务变量 | [DNN](#glo.main.dnn) |
    准确率, [TP](#glo.main.tp), [TN](#glo.main.tn), G-mean | - |'
- en: '| [[80](#bib.bib80)] | Australian, German credit data | - | Personal financial
    variables | [GP](#glo.main.gp) + [AE](#glo.main.ae) as Boosted [DNN](#glo.main.dnn)
    | [FP](#glo.main.fp) | Python, Scikit-learn |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| [[80](#bib.bib80)] | 澳大利亚、德国信用数据 | - | 个人财务变量 | [GP](#glo.main.gp) + [AE](#glo.main.ae)
    作为增强的 [DNN](#glo.main.dnn) | [FP](#glo.main.fp) | Python, Scikit-learn |'
- en: '| [[81](#bib.bib81)] | German, Australian credit dataset | - | Personal financial
    variables | [DCNN](#glo.main.dcnn), [MLP](#glo.main.mlp) | Accuracy, False/Missed
    alarm | - |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| [[81](#bib.bib81)] | 德国、澳大利亚信用数据集 | - | 个人财务变量 | [DCNN](#glo.main.dcnn),
    [MLP](#glo.main.mlp) | 准确率, 错误/漏报 | - |'
- en: '| [[82](#bib.bib82)] | Consumer credit data from Chinese finance company |
    - | Relief algorithm chose the 50 most important features | [CNN](#glo.main.cnn)
    + Relief | [AUROC](#glo.main.auroc), K-s statistic, Accuracy | Keras |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| [[82](#bib.bib82)] | 中国金融公司消费者信用数据 | - | Relief算法选择了50个最重要的特征 | [CNN](#glo.main.cnn)
    + Relief | [AUROC](#glo.main.auroc), K-s统计量, 准确率 | Keras |'
- en: '| [[83](#bib.bib83)] | Credit approval dataset by UCI Machine Learning repo
    | - | UCI credit approval dataset | Rectifier, Tanh, Maxout [DL](#glo.main.dl)
    | - | AWS EC2, H2O, R |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| [[83](#bib.bib83)] | UCI机器学习库中的信用审批数据集 | - | UCI信用审批数据集 | Rectifier, Tanh,
    Maxout [DL](#glo.main.dl) | - | AWS EC2, H2O, R |'
- en: Before going into the details about specific [DL](#glo.main.dl) implementations,
    it is worthwhile to mention the existing [ML](#glo.main.ml) surveys on the topic.
    Kirkos et al. [[84](#bib.bib84)], Ravi et al. [[85](#bib.bib85)], Fethi et al.
    [[86](#bib.bib86)] reviewed the bank performance assessment studies based on [Artificial
    Intelligence (AI)](#glo.main.ai) and [ML](#glo.main.ml) models. Lahsasna et al.
    [[87](#bib.bib87)], Chen et al.[[88](#bib.bib88)] surveyed the credit scoring
    and credit risk assessment studies based on soft computing techniques whereas
    Marques et. al. [[89](#bib.bib89)] focused only on [Evolutionary Computation (EC)](#glo.main.ec)
    Models for credit scoring implementations. Meanwhile, Kumar et al. [[90](#bib.bib90)],
    Verikas et al. [[91](#bib.bib91)] reviewed [ML](#glo.main.ml) implementations
    of bankruptcy prediction studies. Similarly, Sun et al. [[92](#bib.bib92)] provided
    a comprehensive survey about research on financial distress and corporate failures.
    Apart from these reviews, for assessing overall risk, Lin et al. [[93](#bib.bib93)]
    surveyed the financial crisis prediction studies based on [ML](#glo.main.ml) models.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在详细讨论具体的[深度学习（DL）](#glo.main.dl)实现之前，有必要提到现有的关于[机器学习（ML）](#glo.main.ml)的综述。Kirkos等人[[84](#bib.bib84)]、Ravi等人[[85](#bib.bib85)]、Fethi等人[[86](#bib.bib86)]回顾了基于[人工智能（AI）](#glo.main.ai)和[机器学习（ML）](#glo.main.ml)模型的银行绩效评估研究。Lahsasna等人[[87](#bib.bib87)]、Chen等人[[88](#bib.bib88)]调查了基于软计算技术的信用评分和信用风险评估研究，而Marques等人[[89](#bib.bib89)]仅关注于用于信用评分实现的[进化计算（EC）](#glo.main.ec)模型。与此同时，Kumar等人[[90](#bib.bib90)]、Verikas等人[[91](#bib.bib91)]回顾了[机器学习（ML）](#glo.main.ml)在破产预测研究中的应用。类似地，Sun等人[[92](#bib.bib92)]提供了关于金融困境和公司失败研究的综合综述。除了这些综述之外，Lin等人[[93](#bib.bib93)]调查了基于[机器学习（ML）](#glo.main.ml)模型的金融危机预测研究，以评估整体风险。
- en: Since risk assessment is becoming vital for survival in today’s financial world,
    a lot of researchers turned their attention to [DL](#glo.main.dl) for higher accuracy.
    Table LABEL:table:risk_assesment_1, Table LABEL:table:risk_assesment_2 provide
    snapshot information about the different risk assessment studies implemented using
    various [DL](#glo.main.dl) models.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 由于风险评估在当今金融世界中变得至关重要，许多研究者将注意力转向[深度学习（DL）](#glo.main.dl)以提高准确性。表 LABEL:table:risk_assesment_1
    和表 LABEL:table:risk_assesment_2 提供了使用各种[深度学习（DL）](#glo.main.dl)模型实现的不同风险评估研究的快照信息。
- en: For credit score classification (Table LABEL:table:risk_assesment_1), Luo et
    al. [[77](#bib.bib77)], used [CDS](#glo.main.cds) data for Corporate Credit rating
    and corresponding credit classification (A,B or C). Among the tested models, [DBN](#glo.main.dbn)
    with [RBM](#glo.main.rbm) performed the best. This implementation was probably
    the first study to implement Credit rating with [DBN](#glo.main.dbn). Similarly,
    in [[78](#bib.bib78)], a cascaded hybrid model of [DBN](#glo.main.dbn), Backpropagation
    and [SVM](#glo.main.svm) for credit classification was implemented and good performance
    results (the accuracy was above 80-90 %) were achieved. In [[79](#bib.bib79)],
    credit risk classification was achieved by using an ensemble of deep [MLP](#glo.main.mlp)
    networks each using subspaces of the whole space by k-means (using minority class
    in each, but only a partial subspace of the majority class). The data imbalance
    problem was handled by using multiple subspaces for each classifier, where each
    of them had all the positive (minor) instances, but a subsample of negative (majority)
    instances, finally they used an ensemble of deep [MLPs](#glo.main.mlp) combining
    each subspace model. In [[80](#bib.bib80)], credit scoring was performed using
    a [SAE](#glo.main.sae) network and [GP](#glo.main.gp) model to create credit assessment
    rules in order to generate good or bad credit cases. In another study, Neagoe
    et. al. [[81](#bib.bib81)] classified credit scores using various [DMLP](#glo.main.dmlp)
    and deep [CNN](#glo.main.cnn) networks. In a different study [[82](#bib.bib82)],
    consumer credit scoring classification was implemented with a 2-D representation
    of the input consumer data through transforming the data into a 2-D pixel matrix.
    Then the resulting images were used as the training and test data for [CNN](#glo.main.cnn).
    2-D pixel matrix representation of the consumer data was adapted by using [CNN](#glo.main.cnn)
    for image classification. This was the first implementation of credit scoring
    using [CNN](#glo.main.cnn). Niimi [[83](#bib.bib83)] used UCI credit approval
    dataset ¹¹1https://archive.ics.uci.edu/ml/datasets.html to compare [DL](#glo.main.dl),
    [SVM](#glo.main.svm), [Logistic Regression (LR)](#glo.main.lr), [Random Forest
    (RF)](#glo.main.rf), [eXtreme Gradient Boosting (XGBoost)](#glo.main.xgboost)
    and provided information about credit fraud and credit approval applications;
    then experimented with the credit approval problem with several models. Various
    models were compared for credit approval classification. Also, some introduction
    about credit fraud detection was provided.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在信用评分分类（表 LABEL:table:risk_assesment_1）中，Luo 等人 [[77](#bib.bib77)] 使用了 [CDS](#glo.main.cds)
    数据进行企业信用评级和相应的信用分类（A、B 或 C）。在测试的模型中，[DBN](#glo.main.dbn) 与 [RBM](#glo.main.rbm)
    的表现最佳。这一实现可能是第一个使用 [DBN](#glo.main.dbn) 进行信用评级的研究。类似地，在 [[78](#bib.bib78)] 中，实现了一个级联的
    [DBN](#glo.main.dbn)、反向传播和 [SVM](#glo.main.svm) 混合模型进行信用分类，取得了良好的性能结果（准确率在 80-90%
    以上）。在 [[79](#bib.bib79)] 中，通过使用深度 [MLP](#glo.main.mlp) 网络的集成来实现信用风险分类，每个网络使用整个空间的子空间（在每个子空间中使用少数类，但只使用多数类的部分子空间）。数据不平衡问题通过为每个分类器使用多个子空间来处理，每个子空间包含所有正类（少数类）实例，但只有部分负类（多数类）实例，最后，他们使用了一个深度
    [MLPs](#glo.main.mlp) 的集成，结合了每个子空间模型。在 [[80](#bib.bib80)] 中，信用评分通过使用 [SAE](#glo.main.sae)
    网络和 [GP](#glo.main.gp) 模型来创建信用评估规则，从而生成好或坏的信用案例。在另一项研究中，Neagoe 等人 [[81](#bib.bib81)]
    使用各种 [DMLP](#glo.main.dmlp) 和深度 [CNN](#glo.main.cnn) 网络对信用评分进行了分类。在另一项研究 [[82](#bib.bib82)]
    中，通过将输入消费者数据转换为二维像素矩阵来实现消费者信用评分分类。然后，使用生成的图像作为 [CNN](#glo.main.cnn) 的训练和测试数据。二维像素矩阵表示法通过使用
    [CNN](#glo.main.cnn) 进行图像分类。这是第一个使用 [CNN](#glo.main.cnn) 进行信用评分的实现。Niimi [[83](#bib.bib83)]
    使用 UCI 信用审批数据集¹¹1https://archive.ics.uci.edu/ml/datasets.html 比较了 [DL](#glo.main.dl)、[SVM](#glo.main.svm)、[Logistic
    Regression (LR)](#glo.main.lr)、[Random Forest (RF)](#glo.main.rf)、[eXtreme Gradient
    Boosting (XGBoost)](#glo.main.xgboost) 并提供了关于信用欺诈和信用审批申请的信息；随后用几个模型实验了信用审批问题。各种模型在信用审批分类中的表现进行了比较。此外，还介绍了信用欺诈检测的一些内容。
- en: Financial distress prediction for banks and corporates are studied extensively
    (Table LABEL:table:risk_assesment_2). In [[94](#bib.bib94)], a hybrid [DBN](#glo.main.dbn)
    with [SVM](#glo.main.svm) was used for financial distress prediction to identify
    whether the firm was in trouble or not, whereas bank risk classification was studied
    in [[95](#bib.bib95)]. In [[96](#bib.bib96)], news semantics were extracted by
    the word sequence learning and associated events were labeled with the bank stress,
    then from the formed semantic vector representation, the bank stress was determined
    and classified against a threshold. Prediction and semantic meaning extraction
    were integrated in a neat way. In another study [[97](#bib.bib97)], text mining
    was again used for identifying the bank distress by extracting the data from financial
    news and then using a [Deep Feed Forward Network (DFFN)](#glo.main.dffn) on semantic
    sentence vectors extracted from word embeddings to classify if there was an event
    or not. Similarly, Cerchiello et al. [[98](#bib.bib98)] used text mining from
    the financial news to classify bank distress. Malik et al. [[99](#bib.bib99)]
    evaluated the bank stress by first predicting the bank’s performance through an
    [LSTM](#glo.main.lstm) network, then Backpropagation network was used for finding
    the bank stress level.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 银行和企业的金融困境预测已被广泛研究（表 LABEL:table:risk_assesment_2）。在 [[94](#bib.bib94)] 中，使用了混合
    [DBN](#glo.main.dbn) 和 [SVM](#glo.main.svm) 进行金融困境预测，以识别公司是否遇到麻烦，而银行风险分类在 [[95](#bib.bib95)]
    中进行了研究。在 [[96](#bib.bib96)] 中，通过词序列学习提取了新闻语义，并将相关事件标记为银行压力，然后从形成的语义向量表示中，确定和分类银行压力与阈值。预测和语义意义提取以一种整洁的方式进行了整合。在另一项研究
    [[97](#bib.bib97)] 中，再次使用文本挖掘通过从金融新闻中提取数据来识别银行困境，然后在从词嵌入中提取的语义句子向量上使用 [深度前馈网络
    (DFFN)](#glo.main.dffn) 来分类是否发生了事件。类似地，Cerchiello 等人 [[98](#bib.bib98)] 使用金融新闻中的文本挖掘来分类银行困境。Malik
    等人 [[99](#bib.bib99)] 通过首先使用 [LSTM](#glo.main.lstm) 网络预测银行的表现，然后使用反向传播网络来寻找银行压力水平。
- en: 'Table 5: Financial Distress, Bankruptcy, Bank Risk, Mortgage Risk, Crisis Forecasting
    Studies'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：金融困境、破产、银行风险、抵押贷款风险、危机预测研究
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | 数据集 | 时期 | 特征集 | 方法 | 性能标准 | 环境 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [[94](#bib.bib94)] | 966 french firms | - | Financial ratios | [RBM](#glo.main.rbm)
    +[SVM](#glo.main.svm) | Precision, Recall | - |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| [[94](#bib.bib94)] | 966 家法国公司 | - | 财务比率 | [RBM](#glo.main.rbm) + [SVM](#glo.main.svm)
    | 精确度、召回率 | - |'
- en: '| [[95](#bib.bib95)] | 883 [BHC](#glo.main.bhc) from EDGAR | 2006-2017 | Tokens,
    weighted sentiment polarity, leverage and [ROA](#glo.main.roa) | [CNN](#glo.main.cnn),
    [LSTM](#glo.main.lstm), [SVM](#glo.main.svm), [RF](#glo.main.rf) | Accuracy, Precision,
    Recall, F1-score | Keras, Python, Scikit-learn |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| [[95](#bib.bib95)] | 883 [BHC](#glo.main.bhc) 来自 EDGAR | 2006-2017 | 词元、加权情感极性、杠杆和[ROA](#glo.main.roa)
    | [CNN](#glo.main.cnn)、[LSTM](#glo.main.lstm)、[SVM](#glo.main.svm)、[RF](#glo.main.rf)
    | 准确度、精确度、召回率、F1 分数 | Keras、Python、Scikit-learn |'
- en: '| [[96](#bib.bib96)] | The event data set for large European banks, news articles
    from Reuters | 2007-2014 | Word, sentence | [DNN](#glo.main.dnn) +[NLP](#glo.main.nlp)
    preprocess | Relative usefulness, F1-score | - |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| [[96](#bib.bib96)] | 大型欧洲银行的事件数据集，路透社新闻文章 | 2007-2014 | 词、句子 | [DNN](#glo.main.dnn)
    + [NLP](#glo.main.nlp) 预处理 | 相对有用性、F1 分数 | - |'
- en: '| [[97](#bib.bib97)] | Event dataset on European banks, news from Reuters |
    2007-2014 | Text, sentence | Sentence vector + [DFFN](#glo.main.dffn) | Usefulness,
    F1-score, [AUROC](#glo.main.auroc) | - |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| [[97](#bib.bib97)] | 欧洲银行事件数据集，路透社新闻 | 2007-2014 | 文本、句子 | 句子向量 + [DFFN](#glo.main.dffn)
    | 有用性、F1 分数、[AUROC](#glo.main.auroc) | - |'
- en: '| [[98](#bib.bib98)] | News from Reuters, fundamental data | 2007-2014 | Financial
    ratios and news text | doc2vec + [NN](#glo.main.nn) | Relative usefulness | Doc2vec
    |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| [[98](#bib.bib98)] | 路透社新闻、基本数据 | 2007-2014 | 财务比率和新闻文本 | doc2vec + [NN](#glo.main.nn)
    | 相对有用性 | Doc2vec |'
- en: '| [[99](#bib.bib99)] | Macro/Micro economic variables, Bank characteristics/performance
    variables from [BHC](#glo.main.bhc) | 1976-2017 | Macro economic variables and
    bank performances | [CGAN](#glo.main.cgan), [MVN](#glo.main.mvn), [MV-t](#glo.main.mv-t),
    [LSTM](#glo.main.lstm), [VAR](#glo.main.var), [FE-QAR](#glo.main.fe-qar) | [RMSE](#glo.main.rmse),
    Log likelihood, Loan loss rate | - |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| [[99](#bib.bib99)] | 宏观/微观经济变量、来自 [BHC](#glo.main.bhc) 的银行特征/绩效变量 | 1976-2017
    | 宏观经济变量和银行绩效 | [CGAN](#glo.main.cgan)、[MVN](#glo.main.mvn)、[MV-t](#glo.main.mv-t)、[LSTM](#glo.main.lstm)、[VAR](#glo.main.var)、[FE-QAR](#glo.main.fe-qar)
    | [RMSE](#glo.main.rmse)、对数似然、贷款损失率 | - |'
- en: '| [[100](#bib.bib100)] | Financial statements of French companies | 2002-2006
    | Financial ratios | [DBN](#glo.main.dbn) | Recall, Precision, F1-score, [FP](#glo.main.fp),
    [FN](#glo.main.fn) | - |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| [[100](#bib.bib100)] | 法国公司的财务报表 | 2002-2006 | 财务比率 | [DBN](#glo.main.dbn)
    | 召回率，准确率，F1-得分，[FP](#glo.main.fp)，[FN](#glo.main.fn) | - |'
- en: '| [[101](#bib.bib101)] | Stock returns of American publicly-traded companies
    from [CRSP](#glo.main.crsp) | 2001-2011 | Price data | [DBN](#glo.main.dbn) |
    Accuracy | Python, Theano |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| [[101](#bib.bib101)] | 来自[CRSP](#glo.main.crsp)的美国上市公司股票收益 | 2001-2011 |
    价格数据 | [DBN](#glo.main.dbn) | 准确率 | Python, Theano |'
- en: '| [[102](#bib.bib102)] | Financial statements of several companies from Japanese
    stock market | 2002-2016 | Financial ratios | [CNN](#glo.main.cnn) | F1-score,
    [AUROC](#glo.main.auroc) | - |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| [[102](#bib.bib102)] | 来自日本证券市场的若干公司的财务报表 | 2002-2016 | 财务比率 | [CNN](#glo.main.cnn)
    | F1-得分，[AUROC](#glo.main.auroc) | - |'
- en: '| [[103](#bib.bib103)] | Mortgage dataset with local and national economic
    factors | 1995-2014 | Mortgage related features | [ANN](#glo.main.ann) | Negative
    average log-likelihood | AWS |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| [[103](#bib.bib103)] | 包含本地和国家经济因素的抵押贷款数据集 | 1995-2014 | 与抵押贷款相关的特征 | [ANN](#glo.main.ann)
    | 负平均对数似然 | AWS |'
- en: '| [[104](#bib.bib104)] | Mortgage data from Norwegian financial service group,
    DNB | 2012-2016 | Personal financial variables | [CNN](#glo.main.cnn) | Accuracy,
    Sensitivity, Specificity, [AUROC](#glo.main.auroc) | - |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| [[104](#bib.bib104)] | 挪威金融服务集团DNB的抵押贷款数据 | 2012-2016 | 个人财务变量 | [CNN](#glo.main.cnn)
    | 准确率，灵敏度，特异性，[AUROC](#glo.main.auroc) | - |'
- en: '| [[105](#bib.bib105)] | Private brokerage company’s real data of risky transactions
    | - | 250 features: order details, etc. | [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm)
    | F1-Score | Keras, Tensorflow |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| [[105](#bib.bib105)] | 私人经纪公司关于风险交易的真实数据 | - | 250个特征：订单详情等 | [CNN](#glo.main.cnn),
    [LSTM](#glo.main.lstm) | F1-得分 | Keras, Tensorflow |'
- en: '| [[106](#bib.bib106)] | Several datasets combined to create a new one | 1996-2017
    | Index data, 10-year Bond yield, exchange rates, | Logit, [CART](#glo.main.cart),
    [RF](#glo.main.rf), [SVM](#glo.main.svm), [NN](#glo.main.nn), [XGBoost](#glo.main.xgboost),
    [DNN](#glo.main.dnn) | [AUROC](#glo.main.auroc), [KS](#glo.main.ks), [G-mean](#glo.main.g-mean),
    likelihood ratio, [DP](#glo.main.dpower), [BA](#glo.main.ba), [WBA](#glo.main.wba)
    | R |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| [[106](#bib.bib106)] | 几个数据集结合创建了一个新的数据集 | 1996-2017 | 指数数据，10年期国债收益率，汇率，
    | Logit, [CART](#glo.main.cart), [RF](#glo.main.rf), [SVM](#glo.main.svm), [NN](#glo.main.nn),
    [XGBoost](#glo.main.xgboost), [DNN](#glo.main.dnn) | [AUROC](#glo.main.auroc),
    [KS](#glo.main.ks), [G-mean](#glo.main.g-mean), 似然比, [DP](#glo.main.dpower), [BA](#glo.main.ba),
    [WBA](#glo.main.wba) | R |'
- en: There are also a number of research papers that were focused on bankruptcy or
    corporate default prediction. Ribeiro et al. [[100](#bib.bib100)] implemented
    bankruptcy prediction with [DBN](#glo.main.dbn). The results of [DBN](#glo.main.dbn)
    were compared with [SVM](#glo.main.svm) and [RBM](#glo.main.rbm). Yeh et al. [[101](#bib.bib101)]
    used the stock returns of default and solvent companies as inputs to [RBM](#glo.main.rbm)
    used as [SAE](#glo.main.sae), then the output of [RBM](#glo.main.rbm) was used
    as input to [DBN](#glo.main.dbn) to predict if the company was solvent or default.
    The results were compared with an [SVM](#glo.main.svm) model and the [DBN](#glo.main.dbn)
    model outperformed [SVM](#glo.main.svm). Hosaka et al. [[102](#bib.bib102)] tried
    a different approach by converting the financial data to the image to use [CNN](#glo.main.cnn)
    for bankruptcy prediction.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一些研究论文专注于破产或公司违约预测。 Ribeiro等人[[100](#bib.bib100)] 实施了基于[DBN](#glo.main.dbn)的破产预测。
    [DBN](#glo.main.dbn)的结果与[SVM](#glo.main.svm)和[RBM](#glo.main.rbm)进行了比较。 Yeh等人[[101](#bib.bib101)]
    使用了违约和偿付公司股票收益作为输入，以[RBM](#glo.main.rbm)作为[SAE](#glo.main.sae)使用，然后将[RBM](#glo.main.rbm)的输出作为输入传递给[DBN](#glo.main.dbn)以预测公司是否偿付。结果与[SVM](#glo.main.svm)模型进行了比较，[DBN](#glo.main.dbn)模型优于[SVM](#glo.main.svm)。
    Hosaka等人[[102](#bib.bib102)] 尝试通过将金融数据转换为图像来使用[CNN](#glo.main.cnn)进行破产预测。
- en: 'The remaining implementations of risk assessment are as follows: Sirignano
    et al. [[103](#bib.bib103)] used the mortgage application data of 20 years for
    identifying the mortgage risk using various parameters. They also performed a
    lot of analyses relating different factors that affected the mortgage payment
    structure. The authors also analyzed the prepayment and delinquency behavior in
    their assessment. For another mortgage risk assessment application, Kvamme et
    al. [[104](#bib.bib104)] used [CNN](#glo.main.cnn) and [RF](#glo.main.rf) models
    to predict whether a customer would default on its mortgage or not. In a different
    study, Abroyan et al. [[105](#bib.bib105)] used [CNN](#glo.main.cnn) and [LSTM](#glo.main.lstm)
    networks to classify if a transaction performed on the stock market (trade) was
    risky or not and high accuracy was achieved. Finally, Chatzis et al. [[106](#bib.bib106)]
    developed several [ML](#glo.main.ml) and [DL](#glo.main.dl) models for detecting
    events that caused the stock market to crash. [DL](#glo.main.dl) models had good
    classification (detecting crisis or not) performance.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 风险评估的剩余实现如下：Sirignano 等人 [[103](#bib.bib103)] 使用了 20 年的按揭申请数据，通过各种参数来识别按揭风险。他们还进行了大量分析，涉及不同因素如何影响按揭支付结构。作者还在评估中分析了提前还款和违约行为。对于另一种按揭风险评估应用，Kvamme
    等人 [[104](#bib.bib104)] 使用了 [CNN](#glo.main.cnn) 和 [RF](#glo.main.rf) 模型来预测客户是否会违约。另一项研究中，Abroyan
    等人 [[105](#bib.bib105)] 使用 [CNN](#glo.main.cnn) 和 [LSTM](#glo.main.lstm) 网络来分类股票市场上的交易（交易）是否具有风险，并取得了高准确率。最后，Chatzis
    等人 [[106](#bib.bib106)] 开发了几种 [ML](#glo.main.ml) 和 [DL](#glo.main.dl) 模型，用于检测导致股票市场崩盘的事件。[DL](#glo.main.dl)
    模型在分类（检测危机与否）方面表现良好。
- en: 4.3 Fraud Detection
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 欺诈检测
- en: Financial fraud is one of the areas where the governments and authorities are
    desperately trying to find a permanent solution. Several different financial fraud
    cases exist such as credit card fraud, money laundering, consumer credit fraud,
    tax evasion, bank fraud, insurance claim fraud. This is one of the most extensively
    studied areas of finance for [ML](#glo.main.ml) research and several survey papers
    were published accordingly. At different times, Kirkos et al. [[107](#bib.bib107)],
    Yue et al. [[108](#bib.bib108)], Wang et al. [[109](#bib.bib109)], Phua et al.
    [[110](#bib.bib110)], Ngai et al. [[111](#bib.bib111)], Sharma et al. [[112](#bib.bib112)],
    West et al. [[113](#bib.bib113)] all reviewed the accounting and financial fraud
    detection studies based on soft computing and data mining techniques.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 财务欺诈是政府和相关部门急切寻找永久解决方案的领域之一。存在多种不同的财务欺诈案件，如信用卡欺诈、洗钱、消费者信用欺诈、逃税、银行欺诈、保险索赔欺诈。这是金融领域中
    [ML](#glo.main.ml) 研究最广泛的研究领域之一，相应地发表了几篇综述论文。在不同的时间，Kirkos 等人 [[107](#bib.bib107)]、Yue
    等人 [[108](#bib.bib108)]、Wang 等人 [[109](#bib.bib109)]、Phua 等人 [[110](#bib.bib110)]、Ngai
    等人 [[111](#bib.bib111)]、Sharma 等人 [[112](#bib.bib112)] 和 West 等人 [[113](#bib.bib113)]
    都回顾了基于软计算和数据挖掘技术的会计和金融欺诈检测研究。
- en: These type of studies mostly can be considered as anomaly detection and are
    generally classification problems. Table LABEL:table:fraud_detection presents
    different fraud detection studies based on [DL](#glo.main.dl) models.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类型的研究大多可以视为异常检测，通常属于分类问题。表 LABEL:table:fraud_detection 展示了基于 [DL](#glo.main.dl)
    模型的不同欺诈检测研究。
- en: There are a number of studies focused on identifying credit card fraud. Heryadi
    et al. [[114](#bib.bib114)] developed several [DL](#glo.main.dl) models for credit
    card fraud detection for Indonesian banks. They also analyzed the effects of the
    data imbalance between fraud and nonfraud data. In more recent studies, Roy et
    al. [[115](#bib.bib115)] used [LSTM](#glo.main.lstm) model for the credit card
    fraud detection, whereas in [[116](#bib.bib116)], the authors implemented [MLP](#glo.main.mlp)
    networks to classify if a credit card transaction was fraudulent or not. Sohony
    et al. [[117](#bib.bib117)] used an ensemble of [FFNN](#glo.main.ffnn) for the
    detection of card fraud. Jurgovsky et al. [[118](#bib.bib118)] used [LSTM](#glo.main.lstm)
    for detecting credit card fraud from credit card transaction sequences. They compared
    their results with [RF](#glo.main.rf).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多研究专注于识别信用卡欺诈。Heryadi 等人 [[114](#bib.bib114)] 为印尼银行开发了多个 [DL](#glo.main.dl)
    模型用于信用卡欺诈检测。他们还分析了欺诈数据和非欺诈数据之间的数据不平衡影响。在最近的研究中，Roy 等人 [[115](#bib.bib115)] 使用了
    [LSTM](#glo.main.lstm) 模型进行信用卡欺诈检测，而在 [[116](#bib.bib116)] 中，作者实现了 [MLP](#glo.main.mlp)
    网络来分类信用卡交易是否欺诈。Sohony 等人 [[117](#bib.bib117)] 使用了 [FFNN](#glo.main.ffnn) 的集成方法来检测卡片欺诈。Jurgovsky
    等人 [[118](#bib.bib118)] 使用 [LSTM](#glo.main.lstm) 从信用卡交易序列中检测信用卡欺诈。他们将结果与 [RF](#glo.main.rf)
    进行了比较。
- en: Paula et al. [[119](#bib.bib119)] used deep [AE](#glo.main.ae) to implement
    anomaly detection to identify the financial fraud and money laundering for Brazilian
    companies on export tax claims. In a similar study, Gomes et al. [[120](#bib.bib120)]
    proposed an anomaly detection model that identified the anomalies in parliamentary
    expenditure spending in Brazilian elections using also deep [AE](#glo.main.ae).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Paula 等人 [[119](#bib.bib119)] 使用深度 [AE](#glo.main.ae) 实现异常检测，以识别巴西公司在出口税申报中的金融欺诈和洗钱。在类似的研究中，Gomes
    等人 [[120](#bib.bib120)] 提出了一个异常检测模型，利用深度 [AE](#glo.main.ae) 识别巴西选举中的议会支出中的异常。
- en: Wang et al. [[121](#bib.bib121)] used text mining and [DNN](#glo.main.dnn) models
    for the detection of automobile insurance fraud. Longfei et al. [[122](#bib.bib122)]
    developed [DNN](#glo.main.dnn) models to detect online payment transaction fraud.
    Costa et al. [[123](#bib.bib123)] used character sequences in financial transactions
    and the responses from the other side to detect if the transaction was fraud or
    not with [LSTM](#glo.main.lstm). Goumagias et al. [[124](#bib.bib124)] used deep
    Q-learning ([RL](#glo.main.rl)) to predict the risk-averse firms’ tax evasion
    behaviours. Finally, they provided suggestions for the states to maximize their
    tax revenues accordingly.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Wang 等人 [[121](#bib.bib121)] 使用文本挖掘和 [DNN](#glo.main.dnn) 模型检测汽车保险欺诈。Longfei
    等人 [[122](#bib.bib122)] 开发了 [DNN](#glo.main.dnn) 模型用于检测在线支付交易欺诈。Costa 等人 [[123](#bib.bib123)]
    使用财务交易中的字符序列及对方的响应来检测交易是否为欺诈，采用了 [LSTM](#glo.main.lstm) 模型。Goumagias 等人 [[124](#bib.bib124)]
    使用深度 Q 学习 ([RL](#glo.main.rl)) 预测规避风险的公司逃税行为。最后，他们为各州提供了相应的税收收入最大化建议。
- en: 'Table 6: Fraud Detection Studies'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '表 6: 欺诈检测研究'
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| Art. | 数据集 | 时期 | 特征集 | 方法 | 性能标准 | 环境 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [[114](#bib.bib114)] | Debit card transactions by a local Indonesia bank
    | 2016-2017 | Financial transaction amount on several time periods | [CNN](#glo.main.cnn),
    Stacked-[LSTM](#glo.main.lstm), [CNN](#glo.main.cnn)-[LSTM](#glo.main.lstm) |
    [AUROC](#glo.main.auroc) | - |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| [[114](#bib.bib114)] | 某印尼地方银行的借记卡交易 | 2016-2017 | 不同时间段的金融交易金额 | [CNN](#glo.main.cnn)、堆叠-[LSTM](#glo.main.lstm)、[CNN](#glo.main.cnn)-[LSTM](#glo.main.lstm)
    | [AUROC](#glo.main.auroc) | - |'
- en: '| [[115](#bib.bib115)] | Credit card transactions from retail banking | 2017
    | Transaction variables and several derived features | [LSTM](#glo.main.lstm),
    [GRU](#glo.main.gru) | Accuracy | Keras |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| [[115](#bib.bib115)] | 来自零售银行的信用卡交易 | 2017 | 交易变量和多个衍生特征 | [LSTM](#glo.main.lstm)、[GRU](#glo.main.gru)
    | 准确率 | Keras |'
- en: '| [[116](#bib.bib116)] | Card purchases’ transactions | 2014-2015 | Probability
    of fraud per currency/origin country, other fraud related features | [ANN](#glo.main.ann)
    | [AUROC](#glo.main.auroc) | - |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| [[116](#bib.bib116)] | 卡片购买交易 | 2014-2015 | 每种货币/原产国的欺诈概率，其他欺诈相关特征 | [ANN](#glo.main.ann)
    | [AUROC](#glo.main.auroc) | - |'
- en: '| [[117](#bib.bib117)] | Transactions made with credit cards by European cardholders
    | 2013 | Personal financial variables to [PCA](#glo.main.pca) | [ANN](#glo.main.ann),
    [RF](#glo.main.rf) | Recall, Precision, Accuracy | - |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| [[117](#bib.bib117)] | 欧洲持卡人使用信用卡的交易 | 2013 | 个人财务变量到[PCA](#glo.main.pca)
    | [ANN](#glo.main.ann), [RF](#glo.main.rf) | 召回率, 精度, 准确率 | - |'
- en: '| [[118](#bib.bib118)] | Credit-card transactions | 2015 | Transaction and
    bank features | [LSTM](#glo.main.lstm) | [AUROC](#glo.main.auroc) | Keras, Scikit-learn
    |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| [[118](#bib.bib118)] | 信用卡交易 | 2015 | 交易和银行特征 | [LSTM](#glo.main.lstm) |
    [AUROC](#glo.main.auroc) | Keras, Scikit-learn |'
- en: '| [[119](#bib.bib119)] | Databases of foreign trade of the Secretariat of Federal
    Revenue of Brazil | 2014 | 8 Features: Foreign Trade, Tax, Transactions, Employees,
    Invoices, etc | [AE](#glo.main.ae) | [MSE](#glo.main.mse) | H2O, R |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| [[119](#bib.bib119)] | 巴西联邦税务局的外贸数据库 | 2014 | 8个特征：外贸、税收、交易、员工、发票等 | [AE](#glo.main.ae)
    | [MSE](#glo.main.mse) | H2O, R |'
- en: '| [[120](#bib.bib120)] | Chamber of Deputies open data, Companies data from
    Secretariat of Federal Revenue of Brazil | 2009-2017 | 21 features: Brazilian
    State expense, party name, Type of expense, etc. | Deep Autoencoders | [MSE](#glo.main.mse),
    [RMSE](#glo.main.rmse) | H2O, R |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| [[120](#bib.bib120)] | 众议院开放数据，巴西联邦税务局的公司数据 | 2009-2017 | 21个特征：巴西州费用、党派名称、费用类型等
    | 深度自编码器 | [MSE](#glo.main.mse), [RMSE](#glo.main.rmse) | H2O, R |'
- en: '| [[121](#bib.bib121)] | Real-world data for automobile insurance company labeled
    as fradulent | - | Car, insurance and accident related features | [DNN](#glo.main.dnn)
    + [LDA](#glo.main.lda) | [TP](#glo.main.tp), [FP](#glo.main.fp), Accuracy, Precision,
    F1-score | - |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| [[121](#bib.bib121)] | 汽车保险公司标记为欺诈的真实世界数据 | - | 与汽车、保险和事故相关的特征 | [DNN](#glo.main.dnn)
    + [LDA](#glo.main.lda) | [TP](#glo.main.tp), [FP](#glo.main.fp), 准确率, 精度, F1得分
    | - |'
- en: '| [[122](#bib.bib122)] | Transactions from a giant online payment platform
    | 2006 | Personal financial variables | [GBDT](#glo.main.gbdt) +[DNN](#glo.main.dnn)
    | [AUROC](#glo.main.auroc) | - |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| [[122](#bib.bib122)] | 巨型在线支付平台的交易 | 2006 | 个人财务变量 | [GBDT](#glo.main.gbdt)
    + [DNN](#glo.main.dnn) | [AUROC](#glo.main.auroc) | - |'
- en: '| [[123](#bib.bib123)] | Financial transactions | - | Transaction data | [LSTM](#glo.main.lstm)
    | t-SNE | - |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| [[123](#bib.bib123)] | 财务交易 | - | 交易数据 | [LSTM](#glo.main.lstm) | t-SNE |
    - |'
- en: '| [[124](#bib.bib124)] | Empirical data from Greek firms | - | - | [DQL](#glo.main.dql)
    | Revenue | Torch |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| [[124](#bib.bib124)] | 希腊公司实证数据 | - | - | [DQL](#glo.main.dql) | 收入 | Torch
    |'
- en: 4.4 Portfolio Management
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 投资组合管理
- en: 'Portfolio Management is the process of choosing various assets within the portfolio
    for a predetermined period. As seen in other financial applications, slightly
    different versions of this problem exist, even though the underlying motivation
    is the same. In general, Portfolio Management covers the following closely related
    areas: Portfolio Optimization, Portfolio Selection, Portfolio Allocation. Sometimes,
    these terms are used interchangeably. Li et al. [[125](#bib.bib125)] reviewed
    the online portfolio selection studies using various rule-based or [ML](#glo.main.ml)
    models.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 投资组合管理是选择在预定期间内的各种资产的过程。如其他金融应用所示，虽然基本动机相同，但此问题存在略微不同的版本。一般来说，投资组合管理涵盖以下密切相关的领域：投资组合优化、投资组合选择、投资组合配置。有时，这些术语可以互换使用。Li等人[[125](#bib.bib125)]回顾了使用各种基于规则或[ML](#glo.main.ml)模型的在线投资组合选择研究。
- en: Portfolio Management is actually an optimization problem, identifying the best
    possible course-of-action for selecting the best-performing assets for a given
    period. As a result, there are a lot of [EA](#glo.main.ea) models that were developed
    for this purpose. Metaxiotis et al. [[126](#bib.bib126)] surveyed the [MOEAs](#glo.main.moea)
    implemented solely on the portfolio optimization problem.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 投资组合管理实际上是一个优化问题，确定选择最佳表现资产的最佳可能行动方案。因此，有许多为此目的开发的[EA](#glo.main.ea)模型。Metaxiotis等人[[126](#bib.bib126)]调查了仅针对投资组合优化问题实现的[MOEAs](#glo.main.moea)。
- en: However, some [DL](#glo.main.dl) researchers managed to configure it as a learning
    model and obtained superior performances. Since Robo-advisory for portfolio management
    is on the rise, these [DL](#glo.main.dl) implementations have the potential to
    have a far greater impact on the financial industry in the near future. Table LABEL:table:portfolio_management
    presents the portfolio management [DL](#glo.main.dl) models and summarizes their
    achievements.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一些[DL](#glo.main.dl)研究者成功地将其配置为学习模型，并取得了优越的表现。由于投资组合管理的机器人顾问正在兴起，这些[DL](#glo.main.dl)实现有可能在不久的将来对金融行业产生更大的影响。表
    LABEL:table:portfolio_management 展示了投资组合管理的[DL](#glo.main.dl)模型，并总结了它们的成就。
- en: There are a number of stock selection implementations. Takeuchi et al. [[127](#bib.bib127)]
    classified the stocks in two classes, low momentum and high momentum depending
    on their expected return. They used a deep [RBM](#glo.main.rbm) encoder-classifier
    network and achieved high returns. Similarly, in [[128](#bib.bib128)], stocks
    were evaluated against their benchmark index to classify if they would outperform
    or underperform using [DMLP](#glo.main.dmlp), then based on the predictions, adjusted
    the portfolio allocation weights for the stocks for enhanced indexing. In [[129](#bib.bib129)],
    an [ML](#glo.main.ml) framework including [DMLP](#glo.main.dmlp) was constructed
    and the stock selection problem was implemented.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多股票选择的实现方案。Takeuchi 等人 [[127](#bib.bib127)] 根据预期收益将股票分类为低动量和高动量两类。他们使用了深度[RBM](#glo.main.rbm)编码器-分类器网络，取得了高回报。同样，在
    [[128](#bib.bib128)] 中，股票与其基准指数进行比较，以判断它们是否会超越或落后，使用了[DMLP](#glo.main.dmlp)，然后根据预测调整了股票的投资组合配置权重以优化指数。在
    [[129](#bib.bib129)] 中，构建了一个包括[DMLP](#glo.main.dmlp)的[ML](#glo.main.ml)框架，并实现了股票选择问题。
- en: 'Table 7: Portfolio Management Studies'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '表 7: 投资组合管理研究'
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | 数据集 | 时间段 | 特征集 | 方法 | 性能标准 | 环境 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [[66](#bib.bib66)] | Cryptocurrencies, Bitcoin | 2014-2017 | Price data |
    [CNN](#glo.main.cnn), [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm) | Accumulative
    portfolio value, [MDD](#glo.main.mdd), [SR](#glo.main.sr) | - |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| [[66](#bib.bib66)] | 加密货币，比特币 | 2014-2017 | 价格数据 | [CNN](#glo.main.cnn)、[RNN](#glo.main.rnn)、[LSTM](#glo.main.lstm)
    | 累积投资组合价值、[MDD](#glo.main.mdd)、[SR](#glo.main.sr) | - |'
- en: '| [[127](#bib.bib127)] | Stocks from [NYSE](#glo.main.nyse), [AMEX](#glo.main.amex),
    [NASDAQ](#glo.main.nasdaq) | 1965-2009 | Price data | Autoencoder + [RBM](#glo.main.rbm)
    | Accuracy, confusion matrix | - |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| [[127](#bib.bib127)] | [NYSE](#glo.main.nyse)、[AMEX](#glo.main.amex)、[NASDAQ](#glo.main.nasdaq)的股票
    | 1965-2009 | 价格数据 | 自编码器 + [RBM](#glo.main.rbm) | 准确率、混淆矩阵 | - |'
- en: '| [[128](#bib.bib128)] | 20 stocks from [S&P500](#glo.main.sp500) | 2012-2015
    | Technical indicators | [MLP](#glo.main.mlp) | Accuracy | Python, Scikit Learn,
    Keras, Theano |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| [[128](#bib.bib128)] | 来自[S&P500](#glo.main.sp500)的20只股票 | 2012-2015 | 技术指标
    | [MLP](#glo.main.mlp) | 准确率 | Python、Scikit Learn、Keras、Theano |'
- en: '| [[129](#bib.bib129)] | Chinese stock data | 2012-2013 | Technical, fundamental
    data | Logistic Regression, [RF](#glo.main.rf), [DNN](#glo.main.dnn) | [AUC](#glo.main.auc),
    accuracy, precision, recall, f1, tpr, fpr | Keras, Tensorflow, Python, Scikit
    learn |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| [[129](#bib.bib129)] | 中国股票数据 | 2012-2013 | 技术、基本面数据 | 逻辑回归、[RF](#glo.main.rf)、[DNN](#glo.main.dnn)
    | [AUC](#glo.main.auc)、准确率、精确率、召回率、f1、tpr、fpr | Keras、Tensorflow、Python、Scikit
    learn |'
- en: '| [[130](#bib.bib130)] | Top 5 companies in [S&P500](#glo.main.sp500) | - |
    Price data and Financial ratios | [LSTM](#glo.main.lstm), Auto-encoding, Smart
    indexing | [CAGR](#glo.main.cagr) | - |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| [[130](#bib.bib130)] | [S&P500](#glo.main.sp500)前5大公司 | - | 价格数据和财务比率 | [LSTM](#glo.main.lstm)、自编码、智能索引
    | [CAGR](#glo.main.cagr) | - |'
- en: '| [[131](#bib.bib131)] | [IBB](#glo.main.ibb) biotechnology index, stocks |
    2012-2016 | Price data | Auto-encoding, Calibrating, Validating, Verifying | Returns
    | - |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| [[131](#bib.bib131)] | [IBB](#glo.main.ibb)生物技术指数、股票 | 2012-2016 | 价格数据 |
    自编码、校准、验证、核实 | 回报 | - |'
- en: '| [[132](#bib.bib132)] | Taiwans stock market | - | Price data | Elman [RNN](#glo.main.rnn)
    | [MSE](#glo.main.mse), return | - |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| [[132](#bib.bib132)] | 台湾股票市场 | - | 价格数据 | Elman [RNN](#glo.main.rnn) | [MSE](#glo.main.mse)、回报
    | - |'
- en: '| [[133](#bib.bib133)] | FOREX (EUR/USD, etc), Gold | 2013 | Price data | Evolino
    [RNN](#glo.main.rnn) | Return | Python |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| [[133](#bib.bib133)] | 外汇（EUR/USD等）、黄金 | 2013 | 价格数据 | Evolino [RNN](#glo.main.rnn)
    | 回报 | Python |'
- en: '| [[134](#bib.bib134)] | Stocks in [NYSE](#glo.main.nyse), [AMEX](#glo.main.amex),
    [NASDAQ](#glo.main.nasdaq), [TAQ](#glo.main.taq) intraday trade | 1993-2017 |
    Price, 15 firm characteristics | [LSTM](#glo.main.lstm) +[MLP](#glo.main.mlp)
    | Monthly return, [SR](#glo.main.sr) | Python,Keras, Tensorflow in AWS |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| [[134](#bib.bib134)] | [NYSE](#glo.main.nyse)，[AMEX](#glo.main.amex)，[NASDAQ](#glo.main.nasdaq)，[TAQ](#glo.main.taq)的股票日内交易
    | 1993-2017 | 价格，15种公司特征 | [LSTM](#glo.main.lstm) +[MLP](#glo.main.mlp) | 月度回报，[SR](#glo.main.sr)
    | Python, Keras, Tensorflow 在 AWS 上 |'
- en: '| [[135](#bib.bib135)] | [S&P500](#glo.main.sp500) | 1985-2006 | monthly and
    daily log-returns | [DBN](#glo.main.dbn) +[MLP](#glo.main.mlp) | Validation, Test
    Error | Theano, Python, Matlab |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| [[135](#bib.bib135)] | [S&P500](#glo.main.sp500) | 1985-2006 | 月度和每日对数收益率
    | [DBN](#glo.main.dbn) +[MLP](#glo.main.mlp) | 验证，测试误差 | Theano, Python, Matlab
    |'
- en: '| [[136](#bib.bib136)] | 10 stocks in [S&P500](#glo.main.sp500) | 1997-2016
    | [OCHLV](#glo.main.ochlv), Price data | [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm),
    [GRU](#glo.main.gru) | Accuracy, Monthly return | Keras, Tensorflow |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| [[136](#bib.bib136)] | [S&P500](#glo.main.sp500)中的10只股票 | 1997-2016 | [OCHLV](#glo.main.ochlv)，价格数据
    | [RNN](#glo.main.rnn)，[LSTM](#glo.main.lstm)，[GRU](#glo.main.gru) | 准确率，月度回报
    | Keras, Tensorflow |'
- en: '| [[137](#bib.bib137)] | Analyst reports on the [TSE](#glo.main.tse) and Osaka
    Exchange | 2016-2018 | Text | [LSTM](#glo.main.lstm), [CNN](#glo.main.cnn), [Bi-LSTM](#glo.main.bi-lstm)
    | Accuracy, [R²](#glo.main.r-sq) | R, Python, MeCab |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| [[137](#bib.bib137)] | 关于[TSE](#glo.main.tse)和大阪交易所的分析师报告 | 2016-2018 | 文本
    | [LSTM](#glo.main.lstm)，[CNN](#glo.main.cnn)，[Bi-LSTM](#glo.main.bi-lstm) | 准确率，[R²](#glo.main.r-sq)
    | R, Python, MeCab |'
- en: '| [[138](#bib.bib138)] | Stocks from Chinese/American stock market | 2015-2018
    | [OCHLV](#glo.main.ochlv), Fundamental data | [DDPG](#glo.main.ddpg), [PPO](#glo.main.ppo)
    | [SR](#glo.main.sr), [MDD](#glo.main.mdd) | - |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| [[138](#bib.bib138)] | 中国/美国股市的股票 | 2015-2018 | [OCHLV](#glo.main.ochlv)，基本面数据
    | [DDPG](#glo.main.ddpg)，[PPO](#glo.main.ppo) | [SR](#glo.main.sr)，[MDD](#glo.main.mdd)
    | - |'
- en: '| [[139](#bib.bib139)] | Hedge fund monthly return data | 1996-2015 | Return,
    [SR](#glo.main.sr), [STD](#glo.main.std), Skewness, Kurtosis, Omega ratio, Fund
    alpha | [DNN](#glo.main.dnn) | Sharpe ratio, Annual return, Cum. return | - |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| [[139](#bib.bib139)] | 对冲基金月度回报数据 | 1996-2015 | 回报，[SR](#glo.main.sr)，[STD](#glo.main.std)，偏度，峰度，Omega比率，基金阿尔法
    | [DNN](#glo.main.dnn) | Sharpe比率，年回报，累计回报 | - |'
- en: '| [[140](#bib.bib140)] | 12 most-volumed cryptocurrency | 2015-2016 | Price
    data | [CNN](#glo.main.cnn) + [RL](#glo.main.rl) | [SR](#glo.main.sr), portfolio
    value, [MDD](#glo.main.mdd) | - |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| [[140](#bib.bib140)] | 12种交易量最大的加密货币 | 2015-2016 | 价格数据 | [CNN](#glo.main.cnn)
    + [RL](#glo.main.rl) | [SR](#glo.main.sr)，投资组合价值，[MDD](#glo.main.mdd) | - |'
- en: Portfolio selection and smart indexing were the main focuses of [[130](#bib.bib130)]
    and [[131](#bib.bib131)] using [AE](#glo.main.ae) and [LSTM](#glo.main.lstm) networks.
    Lin et al. [[132](#bib.bib132)] used the Elman network for optimal portfolio selection
    by predicting the stock returns for t+1 and then constructing the optimum portfolio
    according to the returns. Meanwhile, Maknickiene et al. [[141](#bib.bib141)] used
    Evolino [RNN](#glo.main.rnn) for portfolio selection and return prediction accordingly.
    The selected portfolio components (stocks) were orthogonal in nature.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 投资组合选择和智能索引是[[130](#bib.bib130)]和[[131](#bib.bib131)]的主要关注点，这些研究使用了[AE](#glo.main.ae)和[LSTM](#glo.main.lstm)网络。Lin等人[[132](#bib.bib132)]通过预测t+1的股票回报来进行最佳投资组合选择，并根据回报构建最优投资组合。同时，Maknickiene等人[[141](#bib.bib141)]使用Evolino
    [RNN](#glo.main.rnn)进行投资组合选择和回报预测。所选投资组合成分（股票）在本质上是正交的。
- en: In [[134](#bib.bib134)], through predicting the next month’s return, top to
    be performed portfolios were constructed and good monthly returns were achieved
    with [LSTM](#glo.main.lstm) and [LSTM](#glo.main.lstm)-[MLP](#glo.main.mlp) combined
    [DL](#glo.main.dl) models. Similarly, Batres et al. [[135](#bib.bib135)] combined
    [DBN](#glo.main.dbn) and [MLP](#glo.main.mlp) for constructing a stock portfolio
    by predicting each stock’s monthly log-return and choosing the only stocks that
    were expected to perform better than the performance of the median stock. Lee
    et al. [[136](#bib.bib136)] compared 3 [RNN](#glo.main.rnn) models (S-[RNN](#glo.main.rnn),
    [LSTM](#glo.main.lstm), [GRU](#glo.main.gru)) for stock price prediction and then
    constructed a threshold-based portfolio with selecting the stocks according to
    the predictions. With a different approach, Iwasaki et al. [[137](#bib.bib137)]
    used the analyst reports for sentiment analyses through text mining and word embeddings
    and used the sentiment features as inputs to [Deep Feedforward Neural Network
    (DFNN)](#glo.main.dfnn) model for the stock price prediction. Then different portfolio
    selections were implemented based on the projected stock returns.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[134](#bib.bib134)]中，通过预测下个月的收益，构建了表现最好的投资组合，并且通过[LSTM](#glo.main.lstm)和[LSTM](#glo.main.lstm)-[MLP](#glo.main.mlp)组合的[DL](#glo.main.dl)模型实现了良好的月度回报。类似地，Batres等人[[135](#bib.bib135)]结合了[DBN](#glo.main.dbn)和[MLP](#glo.main.mlp)来通过预测每只股票的月度对数收益来构建股票投资组合，并选择那些预计表现优于中位数股票的股票。Lee等人[[136](#bib.bib136)]比较了三种[RNN](#glo.main.rnn)模型（S-[RNN](#glo.main.rnn)、[LSTM](#glo.main.lstm)、[GRU](#glo.main.gru)）用于股票价格预测，然后根据预测结果构建了基于阈值的投资组合。采用不同方法的Iwasaki等人[[137](#bib.bib137)]通过文本挖掘和词嵌入对分析师报告进行情感分析，并将情感特征作为输入用于[深度前馈神经网络（DFNN）](#glo.main.dfnn)模型进行股票价格预测。然后，根据预测的股票收益实现了不同的投资组合选择。
- en: '[DRL](#glo.main.drl) was selected as the main [DL](#glo.main.dl) model for
    [[138](#bib.bib138)]. Liang et al. [[138](#bib.bib138)] used [DRL](#glo.main.drl)
    for portfolio allocation by adjusting the stocks weights using various [RL](#glo.main.rl)
    models. Chen et al. [[139](#bib.bib139)] compared different [ML](#glo.main.ml)
    models (including [DFFN](#glo.main.dffn)) for hedge fund return prediction and
    hedge fund selection. [DL](#glo.main.dl) and [RF](#glo.main.rf) models had the
    best performance.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '[DRL](#glo.main.drl)被选为[[138](#bib.bib138)]的主要[DL](#glo.main.dl)模型。Liang等人[[138](#bib.bib138)]使用[DRL](#glo.main.drl)通过调整股票权重来进行投资组合分配，使用了各种[RL](#glo.main.rl)模型。Chen等人[[139](#bib.bib139)]比较了不同的[ML](#glo.main.ml)模型（包括[DFFN](#glo.main.dffn)）用于对冲基金收益预测和对冲基金选择。[DL](#glo.main.dl)和[RF](#glo.main.rf)模型表现最佳。'
- en: Cryptocurrency portfolio management also started getting attention from [DL](#glo.main.dl)
    researchers. In [[140](#bib.bib140)], portfolio management (allocation and adjustment
    of weights) was implemented by [CNN](#glo.main.cnn) and [DRL](#glo.main.drl) on
    selected cryptocurrencies. Similarly, Jiang et al. [[66](#bib.bib66)] implemented
    cryptocurrency portfolio management (allocation) based on 3 different proposed
    models, namely [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm) and [CNN](#glo.main.cnn).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 加密货币投资组合管理也开始受到[DL](#glo.main.dl)研究人员的关注。在[[140](#bib.bib140)]中，投资组合管理（权重分配和调整）由[CNN](#glo.main.cnn)和[DRL](#glo.main.drl)在选定的加密货币上实施。类似地，Jiang等人[[66](#bib.bib66)]基于三种不同的提出模型，即[RNN](#glo.main.rnn)、[LSTM](#glo.main.lstm)和[CNN](#glo.main.cnn)，实施了加密货币投资组合管理（分配）。
- en: 4.5 Asset Pricing and Derivatives Market (options, futures, forward contracts)
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 资产定价与衍生品市场（期权、期货、远期合约）
- en: Accurate pricing or valuation of an asset is a fundamental study area in finance.
    There are a vast number of [ML](#glo.main.ml) models developed for banks, corporates,
    real estate, derivative products, etc. However, [DL](#glo.main.dl) has not been
    applied to this particular field and there are some possible implementation areas
    that [DL](#glo.main.dl) models can assist the asset pricing researchers or valuation
    experts. There were only a handful of studies that we were able to pinpoint within
    the [DL](#glo.main.dl) and finance community. There are vast opportunities in
    this field for future studies and publications.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 准确的资产定价或估值是金融学中的一个基础研究领域。针对银行、企业、房地产、衍生品等领域，已经开发了大量的[ML](#glo.main.ml)模型。然而，[DL](#glo.main.dl)尚未应用于这一特定领域，并且存在一些可能的实施领域，[DL](#glo.main.dl)模型可以协助资产定价研究人员或估值专家。我们在[DL](#glo.main.dl)和金融界能够确定的研究仅有少数。未来在这一领域的研究和出版有着广泛的机会。
- en: Meanwhile, financial models based on derivative products is quite common. Options
    pricing, hedging strategy development, financial engineering with options, futures,
    forward contracts are among some of the studies that can benefit from developing
    [DL](#glo.main.dl) models. Some recent studies indicate that researchers started
    showing interest in [DL](#glo.main.dl) models that can provide solutions to this
    complex and challenging field. Table LABEL:table:derivatives_market summarizes
    these studies with their intended purposes.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，基于衍生产品的金融模型相当普遍。期权定价、对冲策略开发、期权、期货、远期合同的金融工程是可以从开发 [DL](#glo.main.dl) 模型中受益的一些研究。近期的一些研究表明，研究人员开始对能够为这一复杂且具有挑战性的领域提供解决方案的
    [DL](#glo.main.dl) 模型表现出兴趣。表 LABEL:table:derivatives_market 总结了这些研究及其预期目标。
- en: 'Table 8: Asset Pricing and Derivatives Market Studies'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '表 8: 资产定价与衍生品市场研究'
- en: '| Art. | Der.Type | Data Set | Period | Feature Set | Method | Performance
    Criteria | Env. |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | 类型 | 数据集 | 时间段 | 特征集 | 方法 | 绩效标准 | 环境 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| [[137](#bib.bib137)] | Stock exchange | Analyst reports on the [TSE](#glo.main.tse)
    and Osaka Exchange | 2016-2018 | Text | [LSTM](#glo.main.lstm), [CNN](#glo.main.cnn),
    [Bi-LSTM](#glo.main.bi-lstm) | Accuracy, [R²](#glo.main.r-sq) | R, Python, MeCab
    |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| [[137](#bib.bib137)] | 股票交易所 | [TSE](#glo.main.tse) 和大阪交易所的分析师报告 | 2016-2018
    | 文本 | [LSTM](#glo.main.lstm)、[CNN](#glo.main.cnn)、[Bi-LSTM](#glo.main.bi-lstm)
    | 准确度、[R²](#glo.main.r-sq) | R, Python, MeCab |'
- en: '| [[142](#bib.bib142)] | Options | Simulated a range of call option prices
    | - | Price data, option strike/maturity, dividend/risk free rates, volatility
    | [DNN](#glo.main.dnn) | [RMSE](#glo.main.rmse), the average percentage pricing
    error | Tensorflow |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| [[142](#bib.bib142)] | 期权 | 模拟了各种看涨期权价格 | - | 价格数据、期权行使价/到期日、股息/无风险利率、波动率
    | [DNN](#glo.main.dnn) | [RMSE](#glo.main.rmse)、平均百分比定价误差 | Tensorflow |'
- en: '| [[143](#bib.bib143)] | Futures, Options | [TAIEX](#glo.main.taiex) Options
    | 2017 | [OCHLV](#glo.main.ochlv), fundamental analysis, option price | [MLP](#glo.main.mlp),
    [MLP](#glo.main.mlp) with Black scholes | [RMSE](#glo.main.rmse), [MAE](#glo.main.mae),
    [MAPE](#glo.main.mape) | - |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| [[143](#bib.bib143)] | 期货、期权 | [TAIEX](#glo.main.taiex) 期权 | 2017 | [OCHLV](#glo.main.ochlv)、基本面分析、期权价格
    | [MLP](#glo.main.mlp)、[MLP](#glo.main.mlp) 与 Black-Scholes | [RMSE](#glo.main.rmse)、[MAE](#glo.main.mae)、[MAPE](#glo.main.mape)
    | - |'
- en: '| [[144](#bib.bib144)] | Equity returns | Returns in [NYSE](#glo.main.nyse),
    [AMEX](#glo.main.amex), [NASDAQ](#glo.main.nasdaq) | 1975-2017 | 57 firm characteristics
    | Fama-French n-factor model [DL](#glo.main.dl) | [R²](#glo.main.r-sq),[RMSE](#glo.main.rmse)
    | Tensorflow |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| [[144](#bib.bib144)] | 股票收益 | [NYSE](#glo.main.nyse)、[AMEX](#glo.main.amex)、[NASDAQ](#glo.main.nasdaq)
    的收益 | 1975-2017 | 57 家公司的特征 | Fama-French n-factor 模型 [DL](#glo.main.dl) | [R²](#glo.main.r-sq)、[RMSE](#glo.main.rmse)
    | Tensorflow |'
- en: Iwasaki et al. [[137](#bib.bib137)] used a [DFNN](#glo.main.dfnn) model and
    the analyst reports for sentiment analyses to predict the stock prices. Different
    portfolio selection approaches were implemented after the prediction of the stock
    prices. Culkin et al. [[142](#bib.bib142)] proposed a novel method that used feedforward
    [DNN](#glo.main.dnn) model to predict option prices by comparing their results
    with Black & Scholes option pricing formula. Similarly, Hsu et al. [[143](#bib.bib143)]
    proposed a novel method that predicted TAIEX option prices using bid-ask spreads
    and Black & Scholes option price model parameters with 3-layer [DMLP](#glo.main.dmlp).
    In [[144](#bib.bib144)], characteristic features such as Asset growth, Industry
    momentum, Market equity, Market Beta, etc. were used as inputs to a Fama-French
    n-factor model [DL](#glo.main.dl) to predict US equity returns in [National Association
    of Securities Dealers Automated Quotations (NASDAQ)](#glo.main.nasdaq), [American
    Stock Exchange (AMEX)](#glo.main.amex), [New York Stock Exchange (NYSE)](#glo.main.nyse)
    indices.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: Iwasaki 等人 [[137](#bib.bib137)] 使用了 [DFNN](#glo.main.dfnn) 模型和分析师报告进行情感分析以预测股票价格。预测股票价格后实施了不同的投资组合选择方法。Culkin
    等人 [[142](#bib.bib142)] 提出了一个新方法，利用前馈 [DNN](#glo.main.dnn) 模型通过与 Black & Scholes
    期权定价公式比较其结果来预测期权价格。类似地，Hsu 等人 [[143](#bib.bib143)] 提出了一个新方法，通过使用买卖价差和 Black &
    Scholes 期权价格模型参数，结合 3 层 [DMLP](#glo.main.dmlp)，预测 TAIEX 期权价格。在 [[144](#bib.bib144)]
    中，特征如资产增长、行业动量、市场权益、市场贝塔等被用作 Fama-French n-factor 模型 [DL](#glo.main.dl) 的输入，以预测
    [National Association of Securities Dealers Automated Quotations (NASDAQ)](#glo.main.nasdaq)、[American
    Stock Exchange (AMEX)](#glo.main.amex)、[New York Stock Exchange (NYSE)](#glo.main.nyse)
    指数的美国股票收益。
- en: 4.6 Cryptocurrency and Blockchain Studies
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 加密货币与区块链研究
- en: In the last few years, cryptocurrencies have been the talk of the town due to
    their incredible price gain and loss within short periods. Even though price forecasting
    dominates the area of interest, some other studies also exist, such as cryptocurrency
    Algo-trading models.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，由于加密货币在短时间内价格的巨大涨跌，它们成为了热门话题。尽管价格预测主导了兴趣领域，但也存在其他研究，如加密货币算法交易模型。
- en: Meanwhile, Blockchain is a new technology that provides a distributed decentralized
    ledger system that fits well with the cryptocurrency world. As a matter of fact,
    cryptocurrency and blockchain are highly coupled, even though blockchain technology
    has a much wider span for various implementation possibilities that need to be
    studied. It is still in its early development phase, hence there is a lot of hype
    in its potentials.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，区块链是一项提供分布式去中心化账本系统的新技术，这与加密货币世界非常契合。事实上，尽管区块链技术的应用范围更广，需要进一步研究，但加密货币和区块链高度耦合。区块链仍处于早期发展阶段，因此其潜力受到高度关注。
- en: Some [DL](#glo.main.dl) models have already appeared about cryptocurrency studies,
    mostly price prediction or trading systems. However, still there is a lack of
    studies for blockchain research within the [DL](#glo.main.dl) community. Given
    the attention that the underlying technology has attracted, there is a great chance
    that some new studies will start appearing in the near future. Table LABEL:table:cryptocurrency_and_blockchain
    tabulates the studies for the cryptocurrency and blockchain research.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 一些[DL](#glo.main.dl)模型已经出现在加密货币研究中，主要集中在价格预测或交易系统上。然而，[DL](#glo.main.dl)社区仍缺乏区块链研究。鉴于底层技术引起的关注，很有可能在不久的将来会出现一些新的研究。表
    LABEL:table:cryptocurrency_and_blockchain 列出了加密货币和区块链研究的相关研究。
- en: 'Table 9: Cryptocurrency and Blockchain Studies'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：加密货币与区块链研究
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | 数据集 | 时间段 | 特征集 | 方法 | 性能标准 | 环境 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [[48](#bib.bib48)] | Bitcoin, Dash, Ripple, Monero, Litecoin, Dogecoin, Nxt,
    Namecoin | 2014-2017 | [MA](#glo.main.ma), [BOLL](#glo.main.boll), the [CRIX](#glo.main.crix)
    daily returns, Euribor interest rates, [OCHLV](#glo.main.ochlv) of EURO/UK, EURO/USD,
    US/JPY | [LSTM](#glo.main.lstm), [RNN](#glo.main.rnn), [MLP](#glo.main.mlp) |
    Accuracy, F1-measure | Python, Tensorflow |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| [[48](#bib.bib48)] | 比特币，达世币，瑞波币，门罗币，莱特币，多吉币，Nxt，Namecoin | 2014-2017 | [MA](#glo.main.ma)，[BOLL](#glo.main.boll)，[CRIX](#glo.main.crix)
    日收益率，Euribor 利率，[OCHLV](#glo.main.ochlv) 的 EURO/UK，EURO/USD，US/JPY | [LSTM](#glo.main.lstm)，[RNN](#glo.main.rnn)，[MLP](#glo.main.mlp)
    | 准确性，F1测量 | Python，Tensorflow |'
- en: '| [[66](#bib.bib66)] | Cryptocurrencies, Bitcoin | 2014-2017 | Price data |
    [CNN](#glo.main.cnn) | Accumulative portfolio value, [MDD](#glo.main.mdd), [SR](#glo.main.sr)
    | - |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| [[66](#bib.bib66)] | 加密货币，比特币 | 2014-2017 | 价格数据 | [CNN](#glo.main.cnn) |
    累积投资组合价值，[MDD](#glo.main.mdd)，[SR](#glo.main.sr) | - |'
- en: '| [[140](#bib.bib140)] | 12 most-volumed cryptocurrency | 2015-2016 | Price
    data | [CNN](#glo.main.cnn) + [RL](#glo.main.rl) | [SR](#glo.main.sr), portfolio
    value, [MDD](#glo.main.mdd) |  |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| [[140](#bib.bib140)] | 12 种交易量最大的加密货币 | 2015-2016 | 价格数据 | [CNN](#glo.main.cnn)
    + [RL](#glo.main.rl) | [SR](#glo.main.sr)，投资组合价值，[MDD](#glo.main.mdd) |  |'
- en: '| [[145](#bib.bib145)] | Bitcoin data | 2010-2017 | Hash value, bitcoin address,
    public/private key, digital signature, etc. | Takagi–Sugeno Fuzzy cognitive maps
    | Analytical hierarchy process | - |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| [[145](#bib.bib145)] | 比特币数据 | 2010-2017 | 哈希值，比特币地址，公钥/私钥，数字签名等 | Takagi–Sugeno
    模糊认知图 | 分析层次过程 | - |'
- en: '| [[146](#bib.bib146)] | Bitcoin data | 2012, 2013, 2016 | TransactionId, input/output
    Addresses, timestamp | Graph embedding using heuristic, laplacian eigen-map, deep
    [AE](#glo.main.ae) | F1-score | - |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| [[146](#bib.bib146)] | 比特币数据 | 2012，2013，2016 | 交易ID，输入/输出地址，时间戳 | 使用启发式的图嵌入，拉普拉斯特征图，深度[AE](#glo.main.ae)
    | F1得分 | - |'
- en: '| [[147](#bib.bib147)] | Bitcoin, Litecoin, StockTwits | 2015-2018 | [OCHLV](#glo.main.ochlv),
    technical indicators, sentiment analysis | [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm),
    State Frequency Model | [MSE](#glo.main.mse) | Keras, Tensorflow |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| [[147](#bib.bib147)] | 比特币，莱特币，StockTwits | 2015-2018 | [OCHLV](#glo.main.ochlv)，技术指标，情感分析
    | [CNN](#glo.main.cnn)，[LSTM](#glo.main.lstm)，状态频率模型 | [MSE](#glo.main.mse) |
    Keras，Tensorflow |'
- en: '| [[148](#bib.bib148)] | Bitcoin | 2013-2016 | Price data | Bayesian optimized
    [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm) | Sensitivity, specificity, precision,
    accuracy, [RMSE](#glo.main.rmse) | Keras, Python, Hyperas |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| [[148](#bib.bib148)] | 比特币 | 2013-2016 | 价格数据 | 贝叶斯优化的 [RNN](#glo.main.rnn)、[LSTM](#glo.main.lstm)
    | 敏感性、特异性、精确度、准确性、[RMSE](#glo.main.rmse) | Keras、Python、Hyperas |'
- en: 'Chen et al. [[145](#bib.bib145)] proposed a blockchain transaction traceability
    algorithm using Takagi-Sugeno fuzzy cognitive map and 3-layer [DMLP](#glo.main.dmlp).
    Bitcoin data (Hash value, bitcoin address, public/private key, digital signature,
    etc.) was used as the dataset. Nan et al. [[146](#bib.bib146)] proposed a method
    for bitcoin mixing detection that consisted of different stages: Constructing
    the Bitcoin transaction graph, implementing node embedding, detecting outliers
    through [AE](#glo.main.ae). Lopes et al. [[147](#bib.bib147)] combined the opinion
    market and price prediction for cryptocurrency trading. Text mining combined with
    2 models, [CNN](#glo.main.cnn) and [LSTM](#glo.main.lstm) were used to extract
    the opinion. Bitcoin, Litecoin, StockTwits were used as the dataset. [Open,Close,High,
    Low, Volume (OCHLV)](#glo.main.ochlv) of prices, technical indicators, and sentiment
    analysis were used as the feature set.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: Chen 等人 [[145](#bib.bib145)] 提出了一个使用 Takagi-Sugeno 模糊认知图和 3 层 [DMLP](#glo.main.dmlp)
    的区块链交易追踪算法。比特币数据（哈希值、比特币地址、公开/私钥、数字签名等）被用作数据集。Nan 等人 [[146](#bib.bib146)] 提出了一个比特币混合检测方法，该方法包括不同阶段：构建比特币交易图，实现节点嵌入，通过
    [AE](#glo.main.ae) 检测异常值。Lopes 等人 [[147](#bib.bib147)] 结合了意见市场和加密货币交易的价格预测。结合了文本挖掘与
    2 种模型，[CNN](#glo.main.cnn) 和 [LSTM](#glo.main.lstm) 用于提取意见。比特币、莱特币、StockTwits
    被用作数据集。价格的 [开盘、收盘、最高、最低、成交量（OCHLV）](#glo.main.ochlv)、技术指标和情感分析被用作特征集。
- en: In another study, Jiang et al. [[66](#bib.bib66)] presented a financial-model-free
    [RL](#glo.main.rl) framework for the Cryptocurrency portfolio management that
    was based on 3 different proposed models, basic [RNN](#glo.main.rnn), [LSTM](#glo.main.lstm)
    and [CNN](#glo.main.cnn). In [[140](#bib.bib140)], portfolio management was implemented
    by [CNN](#glo.main.cnn) and [DRL](#glo.main.drl) on 12 most-volumed cryptocurrencies.
    Bitcoin, Ethereum, Bitcoin Cash and Digital Cash were used as the dataset.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一项研究中，Jiang 等人 [[66](#bib.bib66)] 提出了一个无金融模型的 [RL](#glo.main.rl) 框架，用于加密货币投资组合管理，该框架基于
    3 种不同的提出模型，即基本的 [RNN](#glo.main.rnn)、[LSTM](#glo.main.lstm) 和 [CNN](#glo.main.cnn)。在
    [[140](#bib.bib140)] 中，投资组合管理通过 [CNN](#glo.main.cnn) 和 [DRL](#glo.main.drl) 在
    12 种最活跃的加密货币上实现。使用了比特币、以太坊、比特币现金和数字现金作为数据集。
- en: In addition, Spilak et al. [[48](#bib.bib48)] used 8 cryptocurrencies (Bitcoin,
    Dash, Ripple, Monero, Litecoin, Dogecoin, Nxt, Namecoin) to construct a dynamic
    portfolio using [LSTM](#glo.main.lstm), [RNN](#glo.main.rnn), [MLP](#glo.main.mlp)
    methods. McNally et al. [[148](#bib.bib148)] compared Bayesian optimized [RNN](#glo.main.rnn),
    [LSTM](#glo.main.lstm) and [Autoregressive Integrated Moving Average (ARIMA)](#glo.main.arima)
    to predict the bitcoin price direction. Sensitivity, specificity, precision, accuracy,
    [Root Mean Square Error (RMSE)](#glo.main.rmse) were used as the performance metrics.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Spilak 等人 [[48](#bib.bib48)] 使用了 8 种加密货币（比特币、达世币、瑞波币、门罗币、莱特币、多吉币、Nxt、Namecoin）来构建一个动态投资组合，采用了
    [LSTM](#glo.main.lstm)、[RNN](#glo.main.rnn)、[MLP](#glo.main.mlp) 方法。McNally 等人
    [[148](#bib.bib148)] 比较了贝叶斯优化的 [RNN](#glo.main.rnn)、[LSTM](#glo.main.lstm) 和 [自回归积分滑动平均模型（ARIMA）](#glo.main.arima)
    来预测比特币价格方向。使用了敏感性、特异性、精确度、准确性、[均方根误差（RMSE）](#glo.main.rmse) 作为性能指标。
- en: 4.7 Financial Sentiment Analysis and Behavioral Finance
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7 财务情感分析与行为金融
- en: One of the most important components of behavioral finance is emotion or investor
    sentiment. Lately, advancements in text mining techniques opened up the possibilities
    for successful sentiment extraction through social media feeds. There is a growing
    interest in Financial Sentiment Analysis, especially for trend forecasting and
    Algo-trading model development. Kearney et al. [[149](#bib.bib149)] surveyed [ML](#glo.main.ml)-based
    financial sentiment analysis studies that use textual data.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 行为金融中一个重要的组成部分是情感或投资者情绪。最近，文本挖掘技术的进步为通过社交媒体信息成功提取情感打开了可能性。财务情感分析引起了越来越多的关注，特别是在趋势预测和算法交易模型开发方面。Kearney
    等人 [[149](#bib.bib149)] 调查了基于 [ML](#glo.main.ml) 的财务情感分析研究，这些研究使用了文本数据。
- en: Nowadays there is broad interest in the sentiment analysis for financial forecasting
    research using [DL](#glo.main.dl) models. Table LABEL:table:financial_sentiment_analysis
    provides information about the sentiment analysis studies that are focused on
    financial forecasting and based on text mining.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，金融预测研究中的情感分析引起了广泛关注，尤其是使用[DL](#glo.main.dl)模型。表LABEL:table:financial_sentiment_analysis提供了有关基于文本挖掘的金融预测的情感分析研究的信息。
- en: In [[150](#bib.bib150)], technical analysis ([MACD](#glo.main.macd), [Moving
    Average (MA)](#glo.main.ma), [Directional Movement Index (DMI)](#glo.main.dmi),
    [Exponential Moving Average (EMA)](#glo.main.ema), [Triple Exponential Moving
    Average (TEMA)](#glo.main.tema), Momentum, [RSI](#glo.main.rsi), [Commodity Channel
    Index (CCI)](#glo.main.cci), Stochastic Oscillator, [Price of Change (ROC)](#glo.main.roc))
    and sentiment analysis (using social media) were used to predict the price of
    stocks. Shi et al. [[151](#bib.bib151)] proposed a method that visually interpreted
    text-based [DL](#glo.main.dl) models in predicting the stock price movements.
    They used the financial news from Reuters and Bloomberg. In [[152](#bib.bib152)],
    text mining and word embeddings were used to extract information from the financial
    news from Reuters and Bloomberg to predict the stock price movements. In addition,
    in [[153](#bib.bib153)], the prices of index data and emotional data from text
    posts were used to predict the stock opening price of the next day. Zhongshengz
    [[154](#bib.bib154)] performed classification and stock price prediction using
    text and price data. Das et al. [[155](#bib.bib155)] used Twitter sentiment data
    and stock price data to predict the prices of Google, Microsoft and Apple stocks.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[150](#bib.bib150)]中，技术分析（[MACD](#glo.main.macd)、[移动平均（MA）](#glo.main.ma)、[方向运动指数（DMI）](#glo.main.dmi)、[指数移动平均（EMA）](#glo.main.ema)、[三重指数移动平均（TEMA）](#glo.main.tema)、动量、[RSI](#glo.main.rsi)、[商品通道指数（CCI）](#glo.main.cci)、随机振荡器、[变动价格（ROC）](#glo.main.roc)）和情感分析（使用社交媒体）被用于预测股票价格。Shi等人[[151](#bib.bib151)]提出了一种方法，视觉化解释了基于文本的[DL](#glo.main.dl)模型在预测股票价格变动中的作用。他们使用了路透社和彭博社的金融新闻。在[[152](#bib.bib152)]中，文本挖掘和词嵌入被用于从路透社和彭博社的金融新闻中提取信息，以预测股票价格变动。此外，在[[153](#bib.bib153)]中，使用了指数数据和来自文本帖子的情绪数据来预测次日的股票开盘价。Zhongshengz
    [[154](#bib.bib154)]使用文本和价格数据进行分类和股票价格预测。Das等人[[155](#bib.bib155)]使用Twitter情感数据和股票价格数据来预测谷歌、微软和苹果股票的价格。
- en: Prosky et al. [[156](#bib.bib156)] performed sentiment, mood prediction using
    news from Reuters and used these sentiments for price prediction. Li et al. [[157](#bib.bib157)]
    used sentiment classification (neutral, positive, negative) for the stock open
    or close price prediction with [LSTM](#glo.main.lstm) (various models). They compared
    their results with [SVM](#glo.main.svm) and achieved higher overall performance.
    Iwasaki et al. [[137](#bib.bib137)] used analyst reports for sentiment analysis
    through text mining and word embeddings. They used the sentiment features as inputs
    to [DFNN](#glo.main.dfnn) model for stock price prediction. Finally, different
    portfolio selections were implemented based on the projected stock returns.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: Prosky等人[[156](#bib.bib156)]利用路透社的新闻进行情感和情绪预测，并使用这些情感进行价格预测。Li等人[[157](#bib.bib157)]使用情感分类（中性、积极、消极）来预测股票的开盘或收盘价格，采用了[LSTM](#glo.main.lstm)（各种模型）。他们将结果与[SVM](#glo.main.svm)进行了比较，取得了更高的整体表现。Iwasaki等人[[137](#bib.bib137)]通过文本挖掘和词嵌入使用分析师报告进行情感分析。他们将情感特征作为输入用于[DFNN](#glo.main.dfnn)模型以预测股票价格。最后，根据预测的股票回报实施了不同的投资组合选择。
- en: In a different study, Huang et al. [[158](#bib.bib158)] used several models
    including [Hidden Markov Model (HMM)](#glo.main.hmm), [DMLP](#glo.main.dmlp) and
    [CNN](#glo.main.cnn) using Twitter moods along with the financial price data for
    prediction of the next day’s move (up or down). [CNN](#glo.main.cnn) achieved
    the best result.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一项研究中，Huang等人[[158](#bib.bib158)]使用了包括[隐马尔可夫模型（HMM）](#glo.main.hmm)、[DMLP](#glo.main.dmlp)和[CNN](#glo.main.cnn)在内的多种模型，结合Twitter情绪和金融价格数据来预测次日的市场走势（上涨或下跌）。[CNN](#glo.main.cnn)取得了最佳结果。
- en: 'Table 10: Financial Sentiment Studies coupled with Text Mining for Forecasting'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 表10：结合文本挖掘的金融情感研究用于预测
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | 数据集 | 期间 | 特征集 | 方法 | 性能标准 | 环境 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| [[137](#bib.bib137)] | Analyst reports on the [TSE](#glo.main.tse) and Osaka
    Exchange | 2016-2018 | Text | [LSTM](#glo.main.lstm), [CNN](#glo.main.cnn), [Bi-LSTM](#glo.main.bi-lstm)
    | Accuracy, [R²](#glo.main.r-sq) | R, Python, MeCab |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
- en: '| [[150](#bib.bib150)] | Sina Weibo, Stock market records | 2012-2015 | Technical
    indicators, sentences | [DRSE](#glo.main.drse) | F1-score, precision, recall,
    accuracy, [AUROC](#glo.main.auroc) | Python |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
- en: '| [[151](#bib.bib151)] | News from Reuters and Bloomberg for [S&P500](#glo.main.sp500)
    stocks | 2006-2015 | Financial news, price data | DeepClue | Accuracy | Dynet
    software |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
- en: '| [[152](#bib.bib152)] | News from Reuters and Bloomberg, Historical stock
    security data | 2006-2013 | News, price data | [DNN](#glo.main.dnn) | Accuracy
    | - |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
- en: '| [[153](#bib.bib153)] | [SCI](#glo.main.sci) prices | 2008-2015 | [OCHL](#glo.main.ochl)
    of change rate, price | Emotional Analysis + [LSTM](#glo.main.lstm) | [MSE](#glo.main.mse)
    | - |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
- en: '| [[154](#bib.bib154)] | [SCI](#glo.main.sci) prices | 2013-2016 | Text data
    and Price data | [LSTM](#glo.main.lstm) | Accuracy, F1-Measure | Python, Keras
    |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
- en: '| [[155](#bib.bib155)] | Stocks of Google, Microsoft and Apple | 2016-2017
    | Twitter sentiment and stock prices | [RNN](#glo.main.rnn) | - | Spark, Flume,Twitter
    API, |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
- en: '| [[156](#bib.bib156)] | 30 [DJIA](#glo.main.djia) stocks, [S&P500](#glo.main.sp500),
    [DJI](#glo.main.dji), news from Reuters | 2002-2016 | Price data and features
    from news articles | [LSTM](#glo.main.lstm), [NN](#glo.main.nn), [CNN](#glo.main.cnn)
    and word2vec | Accuracy | VADER |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
- en: '| [[157](#bib.bib157)] | Stocks of [CSI](#glo.main.csi) 300 index, [OCHLV](#glo.main.ochlv)
    of [CSI](#glo.main.csi) 300 index | 2009-2014 | Sentiment Posts, Price data |
    Naive Bayes + [LSTM](#glo.main.lstm) | Precision, Recall, F1-score, Accuracy |
    Python, Keras |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
- en: '| [[158](#bib.bib158)] | [S&P500](#glo.main.sp500), [NYSE](#glo.main.nyse)
    Composite, [DJIA](#glo.main.djia), [NASDAQ](#glo.main.nasdaq) Composite | 2009-2011
    | Twitter moods, index data | [DNN](#glo.main.dnn), [CNN](#glo.main.cnn) | Error
    rate | Keras, Theano |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
- en: Even though financial sentiment is highly coupled with text mining, we decided
    to represent those two topics in different subsections. The main reason for such
    a choice is not only the existence of some financial sentiment studies which do
    not directly depend on financial textual data (like [[158](#bib.bib158)]) but
    also the existence of some financial text mining studies that are not automatically
    used for sentiment analysis which will be covered in the next section.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: 4.8 Financial Text Mining
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the rapid spreading of social media and real-time streaming news/tweets,
    instant text-based information retrieval became available for financial model
    development. As a result, financial text mining studies became very popular in
    recent years. Even though some of these studies are directly interested in the
    sentiment analysis through crowdsourcing, there are a lot of implementations that
    are interested in the content retrieval of news, financial statements, disclosures,
    etc. through analyzing the text context. There are a few [ML](#glo.main.ml) surveys
    focused on text mining and news analytics. Among the noteworthy studies of such,
    Mitra et al. [[159](#bib.bib159)] edited a book on news analytics in finance,
    whereas Li et al. [[160](#bib.bib160)], Loughran et al. [[161](#bib.bib161)],
    Kumar et al. [[162](#bib.bib162)] surveyed the studies of textual analysis of
    financial documents, news and corporate disclosures. It is worth to mention that
    there are also some studies [[163](#bib.bib163), [164](#bib.bib164)] of text mining
    for financial prediction models.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: Previous section was focused on [DL](#glo.main.dl) models using sentiment analysis
    specifically tailored for the financial forecasting implementations, whereas this
    section will include [DL](#glo.main.dl) studies that have text Mining without
    Sentiment Analysis for Forecasting (Table LABEL:table:financial_text_mining_1),
    financial sentiment analysis coupled with text mining without forecasting intent
    (Table LABEL:table:financial_text_mining_2) and finally other text mining implementations
    (Table LABEL:table:financial_text_mining_3), respectively.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Huynh et al. [[165](#bib.bib165)] used the financial news from Reuters, Bloomberg
    and stock prices data to predict the stock movements in the future. In [[166](#bib.bib166)],
    different event-types on Chinese companies are classified based on a novel event-type
    pattern classification algorithm. Besides, the stock prices were predicted using
    additional inputs. Kraus et al. [[167](#bib.bib167)] implemented [LSTM](#glo.main.lstm)
    with transfer learning using text mining through financial news and stock market
    data. Dang et al. [[168](#bib.bib168)] used Stock2Vec and [Two-stream GRU (TGRU)](#glo.main.tgru)
    models to generate the input data from the financial news and stock prices for
    the classification of stock prices.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: In [[169](#bib.bib169)], events were detected from Reuters and Bloomberg news
    through text mining. The extracted information was used for price prediction and
    stock trading through the [CNN](#glo.main.cnn) model. Vargas et al. [[170](#bib.bib170)]
    used text mining and price prediction together for intraday directional movement
    estimation. Akita et al. [[171](#bib.bib171)] implemented a method that used text
    mining and price prediction together for forecasting prices. Verma et al. [[172](#bib.bib172)]
    combined news data with financial data to classify the stock price movement. Bari
    et al. [[69](#bib.bib69)] used text mining for extracting information from the
    tweets and news. In the method, time series models were used for stock trade signal
    generation. In [[173](#bib.bib173)], a method that performed information fusion
    from news and social media sources was proposed to predict the trend of the stocks.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: In [[174](#bib.bib174)], social media news were used to predict the index price
    and the index direction with [RNN](#glo.main.rnn)-Boost through [Latent Dirichlet
    Allocation (LDA)](#glo.main.lda) features. Hu et al. [[175](#bib.bib175)] proposed
    a novel method that used text mining techniques and Hybrid Attention Networks
    based on the financial news for forecasting the trend of stocks. Li et al. [[176](#bib.bib176)]
    implemented intraday stock price direction classification using the financial
    news and stocks prices. In [[177](#bib.bib177)], financial news data and word
    embedding with Word2vec were implemented to create the inputs for [Recurrent CNN
    (RCNN)](#glo.main.rcnn) to predict the stock price.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 11: Text Mining Studies without Sentiment Analysis for Forecasting'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
- en: '| [[69](#bib.bib69)] | Energy-Sector/ Company-Centric Tweets in [S&P500](#glo.main.sp500)
    | 2015-2016 | Text and Price data |  | Return, [SR](#glo.main.sr), precision,
    recall, accuracy | Python, Tweepy API |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
- en: '| [[165](#bib.bib165)] | News from Reuters, Bloomberg | 2006-2013 | Financial
    news, price data | [Bi-GRU](#glo.main.bi-gru) | Accuracy | Python, Keras |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
- en: '| [[166](#bib.bib166)] | News from Sina.com, ACE2005 Chinese corpus | 2012-2016
    | A set of news text | Their unique algorithm | Precision, Recall, F1-score |
    - |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
- en: '| [[167](#bib.bib167)] | [CDAX](#glo.main.cdax) stock market data | 2010-2013
    | Financial news, stock market data | [LSTM](#glo.main.lstm) | [MSE](#glo.main.mse),
    [RMSE](#glo.main.rmse), [MAE](#glo.main.mae), Accuracy, [AUC](#glo.main.auc) |
    TensorFlow, Theano, Python, Scikit-Learn |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
- en: '| [[168](#bib.bib168)] | Apple, Airbus, Amazon news from Reuters, Bloomberg,
    [S&P500](#glo.main.sp500) stock prices | 2006-2013 | Price data, news, technical
    indicators | [TGRU](#glo.main.tgru), stock2vec | Accuracy, precision, [AUROC](#glo.main.auroc)
    | Keras, Python |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
- en: '| [[169](#bib.bib169)] | [S&P500](#glo.main.sp500) Index, 15 stocks in [S&P500](#glo.main.sp500)
    | 2006-2013 | News from Reuters and Bloomberg | [CNN](#glo.main.cnn) | Accuracy,
    [MCC](#glo.main.mcc) | - |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
- en: '| [[170](#bib.bib170)] | [S&P500](#glo.main.sp500) index news from Reuters
    | 2006-2013 | Financial news titles, Technical indicators | SI-RCNN ([LSTM](#glo.main.lstm)
    + [CNN](#glo.main.cnn)) | Accuracy | - |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
- en: '| [[171](#bib.bib171)] | 10 stocks in Nikkei 225 and news | 2001-2008 | Textual
    information and Stock prices | Paragraph Vector + [LSTM](#glo.main.lstm) | Profit
    | - |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
- en: '| [[172](#bib.bib172)] | [NIFTY](#glo.main.nifty) 50 Index, [NIFTY](#glo.main.nifty)
    Bank/Auto/IT/Energy Index, News | 2013-2017 | Index data, news | [LSTM](#glo.main.lstm)
    | [MCC](#glo.main.mcc), Accuracy | - |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
- en: '| [[173](#bib.bib173)] | Price data, index data, news, social media data |
    2015 | Price data, news from articles and social media | Coupled matrix and tensor
    | Accuracy, [MCC](#glo.main.mcc) | Jieba |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
- en: '| [[174](#bib.bib174)] | [HS](#glo.main.hs) 300 | 2015-2017 | Social media
    news, price data | [RNN](#glo.main.rnn)-Boost with [LDA](#glo.main.lda) | Accuracy,
    [MAE](#glo.main.mae), [MAPE](#glo.main.mape), [RMSE](#glo.main.rmse) | Python,
    Scikit-learn |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
- en: '| [[175](#bib.bib175)] | News and Chinese stock data | 2014-2017 | Selected
    words in a news | [HAN](#glo.main.han) | Accuracy, Annual return | - |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
- en: '| [[176](#bib.bib176)] | News, stock prices from Hong Kong Stock Exchange |
    2001 | Price data and [TF-IDF](#glo.main.tfidf) from news | [ELM](#glo.main.elm),
    [DLR](#glo.main.dlr), [PCA](#glo.main.pca), [BELM](#glo.main.belm), [KELM](#glo.main.kelm),
    [NN](#glo.main.nn) | Accuracy | Matlab |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
- en: '| [[177](#bib.bib177)] | [TWSE](#glo.main.twse) index, 4 stocks in [TWSE](#glo.main.twse)
    | 2001-2017 | Technical indicators, Price data, News | [CNN](#glo.main.cnn) +
    [LSTM](#glo.main.lstm) | [RMSE](#glo.main.rmse), Profit | Keras, Python, [TALIB](#glo.main.talib)
    |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
- en: '| [[178](#bib.bib178)] | Stock of Tsugami Corporation | 2013 | Price data |
    [LSTM](#glo.main.lstm) | [RMSE](#glo.main.rmse) | Keras, Tensorflow |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
- en: '| [[179](#bib.bib179)] | News, Nikkei Stock Average and 10-Nikkei companies
    | 1999-2008 | news, [MACD](#glo.main.macd) | [RNN](#glo.main.rnn), [RBM](#glo.main.rbm)
    +[DBN](#glo.main.dbn) | Accuracy, P-value | - |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
- en: '| [[180](#bib.bib180)] | ISMIS 2017 Data Mining Competition dataset | - | Expert
    identifier, classes | [LSTM](#glo.main.lstm) + [GRU](#glo.main.gru) + [FFNN](#glo.main.ffnn)
    | Accuracy | - |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
- en: '| [[181](#bib.bib181)] | Reuters, Bloomberg News, [S&P500](#glo.main.sp500)
    price | 2006-2013 | News and sentences | [LSTM](#glo.main.lstm) | Accuracy | -
    |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
- en: '| [[182](#bib.bib182)] | APPL from [S&P500](#glo.main.sp500) and news from
    Reuters | 2011-2017 | Input news, [OCHLV](#glo.main.ochlv), Technical indicators
    | [CNN](#glo.main.cnn) + [LSTM](#glo.main.lstm), [CNN](#glo.main.cnn) +[SVM](#glo.main.svm)
    | Accuracy, F1-score | Tensorflow |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
- en: '| [[183](#bib.bib183)] | Nikkei225, [S&P500](#glo.main.sp500), news from Reuters
    and Bloomberg | 2001-2013 | Stock price data and news | [DGM](#glo.main.dgm) |
    Accuracy, [MCC](#glo.main.mcc), %profit | - |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
- en: '| [[184](#bib.bib184)] | Stocks from [S&P500](#glo.main.sp500) | 2006-2013
    | Text (news) and Price data | [LAR](#glo.main.lar) +News, [RF](#glo.main.rf)
    +News | [MAPE](#glo.main.mape), [RMSE](#glo.main.rmse) | - |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
- en: Minami et al. [[178](#bib.bib178)] proposed a method that predicted the stock
    price with corporate action event information and macro-economic index data using
    [LSTM](#glo.main.lstm). In [[179](#bib.bib179)], a novel method that used a combination
    of [RBM](#glo.main.rbm), [DBN](#glo.main.dbn) and word embeddings to create word
    vectors for [RNN](#glo.main.rnn)-[RBM](#glo.main.rbm)-[DBN](#glo.main.dbn) network
    was proposed to predict the stock prices. Buczkowski et al. [[180](#bib.bib180)]
    proposed a novel method that used expert recommendations, ensemble of [GRU](#glo.main.gru)
    and [LSTM](#glo.main.lstm) for prediction of the prices.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: In [[181](#bib.bib181)] a novel method that used character-based neural language
    model using financial news and [LSTM](#glo.main.lstm) was proposed. Liu et al.
    [[182](#bib.bib182)] proposed a method that used word embeddings with word2Vec,
    technical analysis features and stock prices for price prediction. In [[183](#bib.bib183)],
    [Deep Neural Generative Model (DGM)](#glo.main.dgm) with news articles using Paragraph
    Vector algorithm was used for creation of the input vector to predict the stock
    prices. In [[184](#bib.bib184)], the stock price data and word embeddings were
    used for stock price prediction. The results showed that the extracted information
    from embedding news improves the performance.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 12: Financial Sentiment Studies coupled with Text Mining without Forecasting'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
- en: '| [[95](#bib.bib95)] | 883 [BHC](#glo.main.bhc) from EDGAR | 2006-2017 | Tokens,
    weighted sentiment polarity, leverage and [ROA](#glo.main.roa) | [CNN](#glo.main.cnn),
    [LSTM](#glo.main.lstm), [SVM](#glo.main.svm), Random Forest | Accuracy, Precision,
    Recall, F1-score | Keras, Python, Scikit-learn |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
- en: '| [[185](#bib.bib185)] | SemEval-2017 dataset, financial text, news, stock
    market data | 2017 | Sentiments in Tweets, News headlines | Ensemble [SVR](#glo.main.svr),
    [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm), [GRU](#glo.main.gru) | Cosine similarity
    score, agreement score, class score | Python, Keras, Scikit Learn |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
- en: '| [[186](#bib.bib186)] | Financial news from Reuters | 2006-2015 | Word vector,
    Lexical and Contextual input | Targeted dependency tree [LSTM](#glo.main.lstm)
    | Cumulative abnormal return | - |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
- en: '| [[187](#bib.bib187)] | Stock sentiment analysis from StockTwits | 2015 |
    StockTwits messages | [LSTM](#glo.main.lstm), Doc2Vec, [CNN](#glo.main.cnn) |
    Accuracy, precision, recall, f-measure, [AUC](#glo.main.auc) | - |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
- en: '| [[188](#bib.bib188)] | Sina Weibo, Stock market records | 2012-2015 | Technical
    indicators, sentences | [DRSE](#glo.main.drse) | F1-score, precision, recall,
    accuracy, [AUROC](#glo.main.auroc) | Python |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
- en: '| [[189](#bib.bib189)] | News from NowNews, AppleDaily, LTN, MoneyDJ for 18
    stocks | 2013-2014 | Text, Sentiment |  | Return | Python, Tensorflow |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
- en: '| [[190](#bib.bib190)] | StockTwits | 2008-2016 | Sentences, StockTwits messages
    | [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm), [GRU](#glo.main.gru) | [MCC](#glo.main.mcc),
    [WSURT](#glo.main.wsurt) | Keras, Tensorflow |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
- en: '| [[191](#bib.bib191)] | Financial statements of Japan companies | - | Sentences,
    text | [DNN](#glo.main.dnn) | Precision, recall, f-score | - |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
- en: '| [[192](#bib.bib192)] | Twitter posts, news headlines | - | Sentences, text
    | [Deep-FASP](#glo.main.deep-fasp) | Accuracy, [MSE](#glo.main.mse), [R²](#glo.main.r-sq)
    | - |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
- en: '| [[193](#bib.bib193)] | Forums data | 2004-2013 | Sentences and keywords |
    Recursive neural tensor networks | Precision, recall, f-measure | - |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
- en: '| [[194](#bib.bib194)] | News from Financial Times related US stocks | - |
    Sentiment of news headlines | [SVR](#glo.main.svr), Bidirectional [LSTM](#glo.main.lstm)
    | Cosine similarity | Python, Scikit Learn, Keras, Tensorflow |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
- en: 'Akhtar et al. [[185](#bib.bib185)] compared [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm)
    and [GRU](#glo.main.gru) based [DL](#glo.main.dl) models against [MLP](#glo.main.mlp)
    for financial sentiment analysis. Rawte et al. [[95](#bib.bib95)] tried to solve
    three separate problems using [CNN](#glo.main.cnn), [LSTM](#glo.main.lstm), [SVM](#glo.main.svm),
    [RF](#glo.main.rf): Bank risk classification, sentiment analysis and [Return on
    Assets (ROA)](#glo.main.roa) regression.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: Chang et al. [[186](#bib.bib186)] implemented the estimation of information
    content polarity (negative/positive effect) with text mining, word vector, lexical,
    contextual input and various [LSTM](#glo.main.lstm) models. They used the financial
    news from Reuters.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: Jangid et al. [[187](#bib.bib187)] proposed a novel method that is a combination
    of [LSTM](#glo.main.lstm) and [CNN](#glo.main.cnn) for word embedding and sentiment
    analysis using [Bidirectional LSTM (Bi-LSTM)](#glo.main.bi-lstm) for aspect extraction.
    The proposed method used multichannel [CNN](#glo.main.cnn) for financial sentiment
    analysis. Shijia et al. [[188](#bib.bib188)] used an attention-based [LSTM](#glo.main.lstm)
    for the financial sentiment analysis using news headlines and microblog messages.
    Sohangir et al. [[189](#bib.bib189)] used [LSTM](#glo.main.lstm), doc2vec, [CNN](#glo.main.cnn)
    and stock market opinions posted in StockTwits for sentiment analysis. Mahmoudi
    et al. [[190](#bib.bib190)] extracted tweets from StockTwits to identify the user
    sentiment. In the evaluation approach, they also used emojis for the sentiment
    analysis. Kitamori et al. [[191](#bib.bib191)] extracted the sentiments from financial
    news and used [DNN](#glo.main.dnn) to classify positive and negative news.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: In [[192](#bib.bib192)], the sentiment/aspect prediction was implemented using
    an ensemble of [LSTM](#glo.main.lstm), [CNN](#glo.main.cnn) and [GRU](#glo.main.gru)
    networks. In a different study, Li et al. [[193](#bib.bib193)] proposed a [DL](#glo.main.dl)
    based sentiment analysis method using [RNN](#glo.main.rnn) to identify the top
    sellers in the underground economy. Moore et al. [[194](#bib.bib194)] used text
    mining techniques for sentiment analysis from the financial news.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 13: Other Text Mining Studies'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Data Set | Period | Feature Set | Method | Performance Criteria |
    Env. |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
- en: '| [[73](#bib.bib73)] | News from NowNews, AppleDaily, LTN, MoneyDJ for 18 stocks
    | 2013-2014 | Text, Sentiment |  | Return | Python, Tensorflow |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
- en: '| [[96](#bib.bib96)] | The event data set for large European banks, news articles
    from Reuters | 2007-2014 | Word, sentence | [DNN](#glo.main.dnn) +[NLP](#glo.main.nlp)
    preprocess | Relative usefulness, F1-score | - |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
- en: '| [[97](#bib.bib97)] | Event dataset on European banks, news from Reuters |
    2007-2014 | Text, sentence | Sentence vector + [DFFN](#glo.main.dffn) | Usefulness,
    F1-score, [AUROC](#glo.main.auroc) | - |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
- en: '| [[98](#bib.bib98)] | News from Reuters, fundamental data | 2007-2014 | Financial
    ratios and news text | doc2vec + [NN](#glo.main.nn) | Relative usefulness | Doc2vec
    |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
- en: '| [[121](#bib.bib121)] | Real-world data for automobile insurance company labeled
    as fradulent | - | Car, insurance and accident related features | [DNN](#glo.main.dnn)
    + [LDA](#glo.main.lda) | [TP](#glo.main.tp), [FP](#glo.main.fp), Accuracy, Precision,
    F1-score | - |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
- en: '| [[123](#bib.bib123)] | Financial transactions | - | Transaction data | [LSTM](#glo.main.lstm)
    | t-SNE | - |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
- en: '| [[195](#bib.bib195)] | Taiwan’s National Pension Insurance | 2008-2014 |
    Insured’s id, area-code, gender, etc. | [RNN](#glo.main.rnn) | Accuracy, total
    error | Python |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
- en: '| [[196](#bib.bib196)] | StockTwits | 2015-2016 | Sentences, StockTwits messages
    | Doc2vec, [CNN](#glo.main.cnn) | Accuracy, precision, recall, f-measure, [AUC](#glo.main.auc)
    | Python, Tensorflow |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
- en: In [[195](#bib.bib195)], individual social security payment types (paid, unpaid,
    repaid, transferred) were classified and predicted using [LSTM](#glo.main.lstm),
    [HMM](#glo.main.hmm) and [SVM](#glo.main.svm). Sohangir et al. [[196](#bib.bib196)]
    used two neural network models (doc2Vec, [CNN](#glo.main.cnn)) to find the top
    authors in StockTwits messages and to classify the authors as expert or non-expert
    for author classification purposes.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: In [[123](#bib.bib123)], the character sequences in financial transactions and
    the responses from the other side was used to detect if the transaction was fraud
    or not with [LSTM](#glo.main.lstm). Wang et al. [[121](#bib.bib121)] used text
    mining and [DNN](#glo.main.dnn) models to detect automobile insurance fraud.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: In [[96](#bib.bib96)], the news semantics were extracted by the word sequence
    learning, bank stress was determined and classified with the associated events.
    Day et al. [[73](#bib.bib73)] used financial sentiment analysis using text mining
    and [DNN](#glo.main.dnn) for stock algorithmic trading.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: Cerchiello et al. [[98](#bib.bib98)] used the fundamental data and text mining
    from the financial news (Reuters) to classify the bank distress. In [[97](#bib.bib97)],
    the bank distress was identified by extracting the data from the financial news
    through text mining. The proposed method used [DFNN](#glo.main.dfnn) on semantic
    sentence vectors to classify if there was an event or not.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 4.9 Theoretical or Conceptual Studies
  id: totrans-346
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There were a number of research papers that were either focused on the theoretical
    concepts of finance or the conceptual designs without model implementation phases;
    however they still provided valuable information, so we decided to include them
    in our survey. In Table LABEL:table:theory_or_conceptual_study, these studies
    were tabulated according to their topic of interest.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: In [[197](#bib.bib197)], the connection between deep [AEs](#glo.main.ae) and
    [Singular Value Decomposition (SVD)](#glo.main.svd) were discussed and compared
    using stocks from [iShares Nasdaq Biotechnology ETF (IBB)](#glo.main.ibb) index
    and the stock of Amgen Inc. Bouchti et al. [[198](#bib.bib198)] explained the
    details of [DRL](#glo.main.drl) and mentioned that [DRL](#glo.main.drl) could
    be used for fraud detection/risk management in banking.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 14: Other - Theoretical or Conceptual Studies'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | SubTopic | IsTimeSeries? | Data Set | Period | Feature Set | Method
    |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
- en: '| [[197](#bib.bib197)] | Analysis of [AE](#glo.main.ae), [SVD](#glo.main.svd)
    | Yes | Selected stocks from the [IBB](#glo.main.ibb) index and stock of Amgen
    Inc. | 2012-2014 | Price data | [AE](#glo.main.ae), [SVD](#glo.main.svd) |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
- en: '| [[198](#bib.bib198)] | Fraud Detection in Banking | No | Risk Management
    / Fraud Detection | - | - | [DRL](#glo.main.drl) |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
- en: 4.10 Other Financial Applications
  id: totrans-354
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, there were some research papers which did not fit into any of the previously
    covered topics. Their data set and intended output were different than most of
    the other studies focused in this survey. These studies include social security
    payment classification, bank telemarketing success prediction, hardware solutions
    for faster financial transaction processing, etc. There were some anomaly detection
    implementations like tax evasion, money laundering that could have been included
    in this group; however we decided to cover them in a different subsection, fraud
    detection. Table LABEL:table:other_financial_applications shows all these aforementioned
    studies with their differences.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: Dixon et al. [[199](#bib.bib199)] used Intel Xeon Phi to speedup the price movement
    direction prediction problem using [DFFN](#glo.main.dffn). The main contribution
    of the study was the increase in the speed of processing. Alberg et al. [[200](#bib.bib200)]
    used several company financials data (fundamental data) and price together to
    predict the next period’s company financials data. Kim et al. [[201](#bib.bib201)]
    used [CNN](#glo.main.cnn) for predicting the success of bank telemarketing. In
    their study, they used the phone calls of the bank marketing data and 16 finance-related
    attributes. Lee et al. [[202](#bib.bib202)] used technical indicators and patent
    information to estimate the revenue and profit for the corporates using [RBM](#glo.main.rbm)
    based [DBN](#glo.main.dbn), [FFNN](#glo.main.ffnn) and [Support Vector Regressor
    (SVR)](#glo.main.svr).
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: 'Ying et al.[[195](#bib.bib195)] classified and predicted individual social
    security payment types (paid, unpaid, repaid, transferred) using [LSTM](#glo.main.lstm),
    [HMM](#glo.main.hmm) and [SVM](#glo.main.svm). Li et al. [[193](#bib.bib193)]
    proposed a deep learning-based sentiment analysis method to identify the top sellers
    in the underground economy. Jeong et al. [[49](#bib.bib49)] combined deep Q-learning
    and deep [NN](#glo.main.nn) to implement a model to solve three separate problems:
    Increasing profit in a market, prediction of the number of shares to trade, and
    preventing overfitting with insufficient financial data.'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 15: Other Financial Applications'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '| Art. | Subtopic | Data Set | Period | Feature Set | Method | Performance
    Criteria | Env. |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
- en: '| [[49](#bib.bib49)] | Improving trading decisions | [S&P500](#glo.main.sp500),
    [KOSPI](#glo.main.kospi), [HSI](#glo.main.hsi), and EuroStoxx50 | 1987-2017 |
    200-days stock price | Deep Q-Learning and [DNN](#glo.main.dnn) | Total profit,
    Correlation | - |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
- en: '| [[193](#bib.bib193)] | Identifying Top Sellers In Underground Economy | Forums
    data | 2004-2013 | Sentences and keywords | Recursive neural tensor networks |
    Precision, recall, f-measure | - |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
- en: '| [[195](#bib.bib195)] | Predicting Social Ins. Payment Behavior | Taiwan’s
    National Pension Insurance | 2008-2014 | Insured’s id, area-code, gender, etc.
    | [RNN](#glo.main.rnn) | Accuracy, total error | Python |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
- en: '| [[199](#bib.bib199)] | Speedup | 45 [CME](#glo.main.cme) listed commodity
    and FX futures | 1991-2014 | Price data | [DNN](#glo.main.dnn) | - | - |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
- en: '| [[200](#bib.bib200)] | Forecasting Fundamentals | Stocks in [NYSE](#glo.main.nyse),
    [NASDAQ](#glo.main.nasdaq) or [AMEX](#glo.main.amex) exchanges | 1970-2017 | 16
    fundamental features from balance sheet | [MLP](#glo.main.mlp), [LFM](#glo.main.lfm)
    | [MSE](#glo.main.mse), Compount annual return, [SR](#glo.main.sr) | - |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
- en: '| [[201](#bib.bib201)] | Predicting Bank Telemarketing | Phone calls of bank
    marketing data | 2008-2010 | 16 finance-related attributes | [CNN](#glo.main.cnn)
    | Accuracy | - |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
- en: '| [[202](#bib.bib202)] | Corporate Performance Prediction | 22 pharmaceutical
    companies data in US stock market | 2000-2015 | 11 financial and 4 patent indicator
    | [RBM](#glo.main.rbm), [DBN](#glo.main.dbn) | [RMSE](#glo.main.rmse), profit
    | - |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
- en: 5 Current Snaphot of DL research for Financial Applications
  id: totrans-368
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the survey, we reviewed 144 papers from various financial application areas.
    Each paper is analyzed according to its topic, publication type, problem type,
    method, dataset, feature set and performance criteria. Due to space limitations,
    we will only provide the general summary statistics indicating the current state
    of the [DL](#glo.main.dl) for finance research.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d428e2485102c834a76e9ef0b12952b3.png)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: The histogram of Publication Count in Topics'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c0a9e8fd4673b41048aa63a17ff95c23.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: The histogram of Publication Count in Years'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7b972b8054a9d666d3d375b6e3c0732b.png)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: The histogram of Publication Count in Model Types'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: 'First and foremost, we clustered the various topics within the financial applications
    research and presented them in Figure [8](#S5.F8 "Figure 8 ‣ 5 Current Snaphot
    of DL research for Financial Applications ‣ Deep Learning for Financial Applications
    : A Survey"). A quick glance at the figure shows us financial text mining and
    algorithmic trading are the top two fields that the researchers most worked on
    followed by risk assessment, sentiment analysis, portfolio management and fraud
    detection, respectively. The results indicate most of the papers were published
    within the last 3 years implying the domain is very hot and actively studied.
    We can also observe these phenomena by analyzing Figure [9](#S5.F9 "Figure 9 ‣
    5 Current Snaphot of DL research for Financial Applications ‣ Deep Learning for
    Financial Applications : A Survey"). Also, it is worth to mention that the few
    papers that were published before 2013 all used [RNN](#glo.main.rnn) based models.'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: 'When the papers were clustered by the [DL](#glo.main.dl) model type as presented
    in Figure [10](#S5.F10 "Figure 10 ‣ 5 Current Snaphot of DL research for Financial
    Applications ‣ Deep Learning for Financial Applications : A Survey"), we observe
    the dominance of [RNN](#glo.main.rnn), [DMLP](#glo.main.dmlp) and [CNN](#glo.main.cnn)
    over the remaining models, which might be expected, since these models are the
    most commonly preferred ones in general [DL](#glo.main.dl) implementations. Meanwhile,
    [RNN](#glo.main.rnn) is a general umbrella model which has several versions including
    [LSTM](#glo.main.lstm), [GRU](#glo.main.gru), etc. Within the [RNN](#glo.main.rnn)
    choice, most of the models actually belonged to [LSTM](#glo.main.lstm), which
    is very popular in time series forecasting or regression problems. It is also
    used quite often in algorithmic trading. More than 70% of the [RNN](#glo.main.rnn)
    papers consisted of [LSTM](#glo.main.lstm) models.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5966438dc2f50136be994d9463bd1cf3.png)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Wordcloud of most-used Software, Frameworks, Environments'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [11](#S5.F11 "Figure 11 ‣ 5 Current Snaphot of DL research for Financial
    Applications ‣ Deep Learning for Financial Applications : A Survey") presents
    the commonly used software and frameworks for [DL](#glo.main.dl) model implementations
    through Wordcloud whereas Figure [12](#S5.F12 "Figure 12 ‣ 5 Current Snaphot of
    DL research for Financial Applications ‣ Deep Learning for Financial Applications
    : A Survey") provides the details about the development environments. The left
    chart (Figure [12(a)](#S5.F12.sf1 "In Figure 12 ‣ 5 Current Snaphot of DL research
    for Financial Applications ‣ Deep Learning for Financial Applications : A Survey"))
    presents the high level view where Python had the lion’s share with 80% over R
    (with 10%) and the other languages. The chart on the right (Figure [12(b)](#S5.F12.sf2
    "In Figure 12 ‣ 5 Current Snaphot of DL research for Financial Applications ‣
    Deep Learning for Financial Applications : A Survey")) provides the details about
    how the developers are using Python through different libraries and frameworks.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/72dc30ccea468eb98033cc1c7c518b88.png)'
  id: totrans-381
  prefs: []
  type: TYPE_IMG
- en: (a) Preferred Development Environments
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e7a8e5fe7df1363d3c791c14accf61db.png)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
- en: (b) Preferred Python Libraries
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12: Distribution of Preferred Environments'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, [DMLP](#glo.main.dmlp) generally fits well for classification problems;
    hence it is a common choice for most of the financial application areas. However,
    since it is a natural extension of its shallow counterpart [MLP](#glo.main.mlp),
    it has a longer history than the other [DL](#glo.main.dl) models.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/95dc707d30367cadb3681c7fc289c93a.png)'
  id: totrans-387
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Top Journals - corresponding numbers next to the bar graph are representing
    the impact factor of the journals'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: '[CNN](#glo.main.cnn) started getting more attention lately since most of the
    implementations appeared within the last 3 years. Careful analysis of [CNN](#glo.main.cnn)
    papers indicates that a recent trend of representing financial data with a 2-D
    image view in order to utilize [CNN](#glo.main.cnn) is growing. Hence [CNN](#glo.main.cnn)
    based models might overpass the other models in the future. It actually passed
    [DMLP](#glo.main.dmlp) for the last 3 years.'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: 'The top journals are tabulated in Fig [13](#S5.F13 "Figure 13 ‣ 5 Current Snaphot
    of DL research for Financial Applications ‣ Deep Learning for Financial Applications
    : A Survey"). The journals with the most published papers in the last 3 years
    include Expert Systems with Applications, Decision Support Systems, Applied Soft
    Computing, Neurocomputing, Knowledge-based Systems and European Journal of Operational
    Research.'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: 6 Discussion and Open Issues
  id: totrans-391
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After reviewing all the publications based on the selected criteria explained
    in the previous section, we wanted to provide our findings of the current state-of-the-art
    situation. Our discussions are categorized by the [DL](#glo.main.dl) models and
    implementation topics.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Discussions on DL Models
  id: totrans-393
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is possible to claim that [LSTM](#glo.main.lstm) is the dominant [DL](#glo.main.dl)
    model that is preferred by most researchers, due to its well-established structure
    for financial time series data forecasting. Most of the financial implementations
    have time-varying data representations requiring regression-type approaches which
    fits very well for [LSTM](#glo.main.lstm) and its derivatives due to their easy
    adaptations to the problems. As long as the temporal nature of the financial data
    remains, [LSTM](#glo.main.lstm) and its related family models will maintain their
    popularities.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, [CNN](#glo.main.cnn) based models started getting more traction among
    researchers in the last two years. Unlike [LSTM](#glo.main.lstm), [CNN](#glo.main.cnn)
    works better for classification problems and is more suitable for either non-time
    varying or static data representations. However, since most financial data is
    time-varying, under normal circumstances, [CNN](#glo.main.cnn) is not the natural
    choice for financial applications. However, in some independent studies, the researchers
    performed an innovative transformation of 1-D time-varying financial data into
    2-D mostly stationary image-like data to be able to utilize the power of [CNN](#glo.main.cnn)
    through adaptive filtering and implicit dimensionality reduction. This novel approach
    seems working remarkably well in complex financial patterns regardless of the
    application area. In the future, more examples of such implementations might be
    more common; only time will tell.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: Another model that has a rising interest is [DRL](#glo.main.drl) based implementations;
    in particular, the ones coupled with agent-based modelling. Even though algorithmic
    trading is the most preferred implementation area for such models, it is possible
    to develop the working structures for any problem type.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: Careful analyses of the reviews indicate in most of the papers hybrid models
    are preferred over native models for better accomplishments. A lot of researchers
    configure the topologies and network parameters for achieving higher performance.
    However, there is also the danger of creating more complex hybrid models that
    are not easy to build, and their interpretation also might be difficult.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: 'Through the performance evaluation results, it is possible to claim that in
    general terms, [DL](#glo.main.dl) models outperform [ML](#glo.main.ml) counterparts
    when working on the same problems. [DL](#glo.main.dl) problems also have the advantage
    of being able to work on larger amount of data. With the growing expansion of
    open-source [DL](#glo.main.dl) libraries and frameworks (Figure [11](#S5.F11 "Figure
    11 ‣ 5 Current Snaphot of DL research for Financial Applications ‣ Deep Learning
    for Financial Applications : A Survey")), [DL](#glo.main.dl) model building and
    development process is easier than ever. And this phenomena is also supported
    by the increasing interest in adapting [DL](#glo.main.dl) models into all areas
    of finance which can be observed from Figure [9](#S5.F9 "Figure 9 ‣ 5 Current
    Snaphot of DL research for Financial Applications ‣ Deep Learning for Financial
    Applications : A Survey").'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: Also it is worth to mention that, besides the outperformance of [DL](#glo.main.dl)
    models over [ML](#glo.main.ml), the performance evaluation results are improving
    every year relatively, even though it is very difficult to explicitly quantifty
    the amount of improvement. The improvements are most notable in trend prediction
    based algo-trading implementations and text-mining studies due to deeper and/or
    more versatile networks and new innovative model developments. This is also reflected
    through the increasing number of published papers year over year.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Discussions on Implementation Areas
  id: totrans-400
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Price/trend prediction and Algo-trading models have the most interest among
    all financial applications that use [DL](#glo.main.dl) models in their implementations.
    Risk assessment and portfolio management have always been popular within the [ML](#glo.main.ml)
    community, and it looks like this is also valid for [DL](#glo.main.dl) researchers.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: Even though broad interest in [DL](#glo.main.dl) models is on the rise, financial
    text mining is particularly getting more attention than most of the other financial
    applications. The streaming flow of financial news, tweets, statements, blogs
    opened up a whole new world for the financial community allowing them to build
    better and more versatile prediction and evaluation models integrating numerical
    and textual data. Meanwhile, the general approach nowadays is to combine text
    mining with financial sentiment analysis. With that, it is reasonable to assume
    higher performance will be achieved. A lot of researchers started working on that
    particular application area. It is quite probable that the next generation of
    outperforming implementations will be based on models that can successfully integrate
    text mining with quantified numerical data.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: These days, one other hot area within the [DL](#glo.main.dl) research is the
    cryptocurrencies. We can also include blockchain research to that, even though
    it is not necessarily directly related to cryptocurrencies, but generally used
    together in most implementations. Cryptocurrency price prediction has the most
    attraction within the field, but since the topic is fairly new, more studies and
    implementations will probably keep pouring in due to the high expectations and
    promising rewards.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Open Issues and Future Work
  id: totrans-404
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When we try to extrapolate the current state of research and the achieved accomplishments
    into the future, a few areas of interests stand out. We will try to elaborate
    on them and provide a pathway for what can be done or needs to be done within
    the following few years. We will try to sort out our opinions by analyzing them
    through the model development and research topic point of view.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1 Model Development Perspective
  id: totrans-406
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We have already mentioned the growing attention on the adaptation of 2-D [CNN](#glo.main.cnn)
    implementations for various financial application areas. This particular technique
    looks promising and provides opportunities. It would be beneficial to further
    explore the possibilities using that approach in different problems. The playfield
    is still wide open.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: Graph [CNN](#glo.main.cnn) is another model that is closely related but still
    showing some discrepancies. It has not been used much, only one study was published
    that relates graph-[CNN](#glo.main.cnn) with financial applications. However,
    versatile transformations of financial data into graphs, integrating sentiment
    analysis through graph representations and constructing different models can create
    opportunities for researchers to build better performing financial applications.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: There are also recently developed [DL](#glo.main.dl) models, like [GAN](#glo.main.gan),
    Capsule networks, etc. that can also provide viable alternatives to existing implementations.
    They have started showing up in various non-financial studies, however to the
    best of our knowledge, no known implementation of such kind for financial applications
    exists. It might open up a new window of opportunities for financial researchers
    and practitioners. In addition to such new models, innovative paradigms like transfer
    learning, one-shot learning can be tested within the environment.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: Since financial text mining is overtaking the other topics in an accelerated
    fashion, new data models like Stock2Vec [[168](#bib.bib168)] can be enhanced for
    better and more representative models. In addition, [Natural Language Processing
    (NLP)](#glo.main.nlp) based ensemble models or more integration of data semantics
    into the picture can increase the accuracy of the existing models.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: Finally, according to our observations, hybrid models are preferred more over
    the native or standalone models in most studies. This trend will likely continue,
    however, researchers need to introduce more versatile, sometimes unconventional
    models for better results. Hybrid models integrating various simple [DL](#glo.main.dl)
    layers like cascaded [CNN](#glo.main.cnn)-[LSTM](#glo.main.lstm) blocks can have
    better outcomes since ensembling spatial and temporal information together in
    a novel way might be an important milestone for researchers seeking for "alpha"
    in their models.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.2 Implementation Perspective
  id: totrans-412
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As far as the application areas are concerned, the usual suspects, algorithmic
    trading, portfolio management and risk assessment will probably continue on their
    dominance within the financial research arena in the foreseeable future. Meanwhile,
    some new shining stars started getting more attention, not only because they represent
    fairly new research opportunities, but also their forecasted impact on the financial
    world is noteworthy.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: Cryptocurrencies and blockchain technology are among these new research areas.
    Hence, it is worthwhile to explore the possibilities that these new fields will
    bring. It will be a while before any of these technologies become widely accepted
    industry standard, however, that is the sole reason why it provides a great opportunity
    for the researchers to shape the future of the financial world with new innovative
    models and hoping that the rest of the world will follow their footsteps.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: Another area that can benefit from more innovative models is portfolio management.
    Robo-advisory systems are on the rise throughout the world and these systems depend
    on high performing automated decision support systems. Since [DL](#glo.main.dl)
    models fit well to that description, it would be logical to assume the utilization
    of [DL](#glo.main.dl) implementations will increase in the coming years. As such,
    the corresponding quant funds will be very interested in the achievements that
    the [DL](#glo.main.dl) researchers can offer for the financial community. This
    might require integrating learning and optimization models together for better-performing
    systems. Hence, ensemble models that can successfully mix [EC](#glo.main.ec) and
    [DL](#glo.main.dl) components might be what the industry is anticipating for the
    immediate future. This might also result in new research opportunities.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: Yet, one other research area that is generally avoided by soft computing and
    [DL](#glo.main.dl) researchers is the financial derivatives market. Even though
    there are many different products that exist on the market, the corresponding
    [DL](#glo.main.dl) research is very scarce. However, for professionals working
    in the finance industry, these products actually provide incredible flexibilities
    ranging from hedging their investments to implementing leveraged transactions
    with minimized risk. Even though, opportunities exist for [DL](#glo.main.dl) researchers,
    there was not a broad interest in the topic, since there are only a handful of
    studies for the derivatives market. Option strategy optimization, futures trading,
    option pricing, arbitrage trading can be among the areas that might benefit from
    [DL](#glo.main.dl) research.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis, text mining, risk adjusted asset pricing are some of the
    other implementation areas that attract researchers but not yet fully utilized.
    It is quite probable we will see more papers in these fields in the near future.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: Last, but not least, [HFT](#glo.main.hft) is one area that has not benefitted
    from the advancements in [ML](#glo.main.ml) research to its full potential yet.
    Since [HFT](#glo.main.hft) requires lightning-fast transaction processing, the
    statistical learning model that is embedded into such trading systems must not
    introduce any extra latency to the existing system. This necessitates careful
    planning and modelling of such models. For that purpose, [DL](#glo.main.dl) models
    embedded within the [Graphic Processing Unit (GPU)](#glo.main.gpu) or [Field Programmable
    Gate Array (FPGA)](#glo.main.fpga) based hardware solutions can be studied. The
    hardware aspects of [DL](#glo.main.dl) implementations are generally omitted in
    almost all studies, but as stated above, there might be opportunities also in
    that field.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.3 Suggestions for Future Research
  id: totrans-419
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Careful analyses of Figures [8](#S5.F8 "Figure 8 ‣ 5 Current Snaphot of DL
    research for Financial Applications ‣ Deep Learning for Financial Applications
    : A Survey") and [9](#S5.F9 "Figure 9 ‣ 5 Current Snaphot of DL research for Financial
    Applications ‣ Deep Learning for Financial Applications : A Survey") indicate
    the rising overall appetite for applied [DL](#glo.main.dl) research for finance.
    Even though the interest is broad, some areas like cryptocurrency and block chain
    studies might get more attention compared to other areas.'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: With respect to the promising outlook in text mining and financial sentiment
    analysis, we believe behavioral finance is also a fairly untouched research area
    that hides a lot of opportunities within. There is a lack of research work published
    on behavioral finance using [DL](#glo.main.dl) models. This might be mainly due
    to the difficulties of quantifying the inputs and outputs of behavioral finance
    research to be used with [DL](#glo.main.dl) models. However, new advancements
    in text mining, [NLP](#glo.main.nlp), semantics combined with agent-based computational
    finance can open up huge opportunities in that field. We would encourage researchers
    to look further into this for a possible implementation area as it currently seems
    to be wide open for new studies.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: 6.4 Responses to our Initial Research Questions
  id: totrans-422
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At this point, since we gathered and processed all the information we need,
    we are ready to provide answers to our initially stated research questions. The
    questions and our corresponding answers according to our survey are as follows:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What financial application areas are of interest to [DL](#glo.main.dl) community?
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Response: Financial text mining, Algo-trading, risk assessments, sentiment
    analysis, portfolio management and fraud detection are among the most studied
    areas of finance research. (Please check Figure [8](#S5.F8 "Figure 8 ‣ 5 Current
    Snaphot of DL research for Financial Applications ‣ Deep Learning for Financial
    Applications : A Survey"))'
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How mature is the existing research in each of these application areas?
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Response: Even though [DL](#glo.main.dl) models already had better achievements
    compared to traditional counterparts in almost all areas, the overall interest
    is still on the rise in all research areas.'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the areas that have promising potentials from an academic/industrial
    research perspective?
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Response: Cryptocurrencies, blockchain, behavioral finance, [HFT](#glo.main.hft)
    and derivatives market have promising potentials for research.'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which [DL](#glo.main.dl) models are preferred (and more successful) in different
    applications?
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Response: [RNN](#glo.main.rnn) based models (in particular [LSTM](#glo.main.lstm)),
    [CNN](#glo.main.cnn) and [DMLP](#glo.main.dmlp) have been used extensively in
    implementations. From what we have encountered, [LSTM](#glo.main.lstm) is more
    successful and preferred in time-series forecasting, whereas [DMLP](#glo.main.dmlp)
    and [CNN](#glo.main.cnn) are better suited to applications requiring classification.'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do [DL](#glo.main.dl) models pare against traditional soft computing / [ML](#glo.main.ml)
    techniques?
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Response: In most of the studies, [DL](#glo.main.dl) models performed better
    than their [ML](#glo.main.ml) counterparts. There were a few occasions where [ML](#glo.main.ml)
    had comparable or even better solutions, however the general tendency is the outperformance
    of the [DL](#glo.main.dl) methods.'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '6.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the future direction for [DL](#glo.main.dl) research in Finance?
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Response: Hybrid models based on Spatio-temporal data representations, [NLP](#glo.main.nlp),
    semantics and text mining-based models might become more important in the near
    future.'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 7 Conclusions
  id: totrans-442
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The financial industry and academia have started realizing the potentials of
    [DL](#glo.main.dl) in various application areas. The number of research work keeps
    on increasing every year with an accelerated fashion. However, we are just in
    the early years of this new era, more studies will be implemented and new models
    will keep pouring in. In this survey, we wanted to highlight the state-of-the-art
    [DL](#glo.main.dl) research for the financial applications. We not only provided
    a snapshot of the existing research status but also tried to identify the future
    roadway for intended researchers. Our findings indicate there are incredible opportunities
    within the field and it looks like they will not disappear anytime soon. So, we
    encourage the researchers that are interested in the area to start exploring.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: 8 Acknowledgement
  id: totrans-444
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work is supported by the Scientific and Technological Research Council
    of Turkey (TUBITAK) grant no 215E248.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: Glossary
  id: totrans-446
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AE
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoder
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: AI
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: Artificial Intelligence
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: AMEX
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: American Stock Exchange
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: ANN
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: Artificial Neural Network
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: ARIMA
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: Autoregressive Integrated Moving Average
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: AUC
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: Area Under the Curve
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
- en: AUROC
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: Area Under the Receiver Operating Characteristics
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
- en: BA
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: Balanced Accuracy
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: BELM
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: Basic Extreme Learning Machine
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: BHC
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
- en: Bank Holding Companies
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: Bi-GRU
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: Bidirectional Gated Recurrent Unit
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: Bi-LSTM
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: Bidirectional LSTM
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: BIST
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: Istanbul Stock Exchange Index
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: BOLL
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: Bollinger Band
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
- en: BPTT
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation Through Time
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: CAE
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Autoencoder
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
- en: CAGR
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: Compound Annual Growth Rate
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: CART
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: Classification and Regression Trees
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: CCI
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: Commodity Channel Index
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: CDAX
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: German Stock Market Index Calculated by Deutsche Börse
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
- en: CDS
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
- en: Credit Default Swaps
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: CGAN
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: Conditional
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: CME
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
- en: Chicago Mercantile Exchange
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: CNN
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Neural Network
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: CRIX
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: The Cryptocurrency Index
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
- en: CRSP
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: Center for Research in Security Prices
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
- en: CSI
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: China Securities Index
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: DAX
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: The Deutscher Aktienindex
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: DBN
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
- en: Deep Belief Network
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: DCNL
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: Deep Co-investment Network Learning
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
- en: DCNN
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
- en: Deep Convolutional Neural Network
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
- en: DDPG
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
- en: Deep Deterministic Policy Gradient
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
- en: Deep-FASP
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
- en: The Financial Aspect and Sentiment Prediction task with Deep neural networks
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
- en: DFFN
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
- en: Deep Feed Forward Network
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
- en: DFNN
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
- en: Deep Feedforward Neural Network
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
- en: DGM
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
- en: Deep Neural Generative Model
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
- en: DGP
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
- en: Deep Gaussian Process
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
- en: DJI
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
- en: Dow Jones Index
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
- en: DJIA
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
- en: Dow Jones Industrial Average
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
- en: DL
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
- en: DLR
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning Representation
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
- en: DMI
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
- en: Directional Movement Index
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
- en: DMLP
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
- en: Deep Multilayer Perceptron
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
- en: DNN
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
- en: Deep Neural Network
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
- en: DP
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
- en: Discriminant Power
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
- en: DQL
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
- en: Deep Q-Learning
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
- en: DRL
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
- en: Deep Reinforcement Learning
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
- en: DRSE
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
- en: Deep Random Subspace Ensembles
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
- en: DTW
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic Time Warping
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
- en: EA
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
- en: Evolutionary Algorithm
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
- en: EC
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
- en: Evolutionary Computation
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
- en: ELM
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
- en: Extreme Learning Machine
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
- en: EMA
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
- en: Exponential Moving Average
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
- en: ETF
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
- en: Exchange-Traded Fund
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
- en: FDDR
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzy Deep Direct Reinforcement Learning
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
- en: FE-QAR
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
- en: Fixed Effects Quantile VAR
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
- en: FFNN
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
- en: Feedforward Neural Network
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
- en: FN
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
- en: False Negative
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
- en: FNN
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
- en: Fully Connected Neural Network
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
- en: FP
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
- en: False Positive
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
- en: FPGA
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
- en: Field Programmable Gate Array
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
- en: FTSE
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
- en: London Financial Times Stock Exchange Index
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
- en: G-mean
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
- en: Geometric Mean
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
- en: GA
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
- en: Genetic Algorithm
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
- en: GAN
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
- en: Generative Adversarial Network
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
- en: GASVR
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
- en: '[GA](#glo.main.ga) with a'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
- en: GBDT
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
- en: Gradient-Boosted-DecisionTrees
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
- en: GBT
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
- en: Gradient Boosted Trees
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
- en: GP
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
- en: Genetic Programming
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
- en: GPU
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
- en: Graphic Processing Unit
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
- en: GRU
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
- en: Gated-Recurrent Unit
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
- en: HAN
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid Attention Network
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
- en: HAR
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
- en: Heterogeneous Autoregressive Process
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
- en: HFT
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
- en: High Frequency Trading
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
- en: HMM
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
- en: Hidden Markov Model
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
- en: HS
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
- en: China Shanghai Shenzhen Stock Index
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
- en: HSI
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
- en: Hong Kong Hang Seng Index
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
- en: IBB
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
- en: iShares Nasdaq Biotechnology ETF
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
- en: KELM
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
- en: Kernel Extreme Learning Machine
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
- en: KOSPI
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
- en: The Korea Composite Stock Price Index
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
- en: KS
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
- en: Kolmogorov–Smirnov
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
- en: LAR
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
- en: Linear Auto-regression Predictor
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
- en: LDA
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
- en: Latent Dirichlet Allocation
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
- en: LFM
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
- en: Lookahead Factor Models
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
- en: LOB
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
- en: Limit Order Book Data
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
- en: LR
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
- en: LSTM
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
- en: Long-Short Term Memory
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
- en: MA
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
- en: Moving Average
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
- en: MACD
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
- en: Moving Average Convergence and Divergence
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
- en: MAE
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
- en: Mean Absolute Error
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
- en: MAPE
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
- en: Mean Absolute Percentage Error
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
- en: MCC
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
- en: Matthew Correlation Coefficient
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
- en: MDA
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
- en: Multilinear Discriminant Analysis
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
- en: MDD
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
- en: Maximum Drawdown
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
- en: ML
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
- en: MLP
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
- en: Multilayer Perceptron
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
- en: MODRL
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
- en: Multi-objective Deep Reinforcement Learning
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
- en: MOEA
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
- en: Multiobjective Evolutionary Algorithm
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
- en: MSE
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
- en: Mean Squared Error
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
- en: MV-t
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
- en: Multivariate t Distribution
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
- en: MVN
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
- en: Multivariate Normal Distribution
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
- en: NASDAQ
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
- en: National Association of Securities Dealers Automated Quotations
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
- en: NES
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
- en: Natural Evolution Strategies
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
- en: NIFTY
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
- en: National Stock Exchange of India
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
- en: NIKKEI
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
- en: Tokyo Nikkei Index
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
- en: NLP
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
- en: Natural Language Processing
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
- en: NN
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
- en: Neural Network
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
- en: NYSE
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
- en: New York Stock Exchange
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
- en: OCHL
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
- en: Open,Close,High, Low
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
- en: OCHLV
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
- en: Open,Close,High, Low, Volume
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
- en: PCA
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
- en: Principal Component Analysis
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
- en: PCC
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
- en: Pearson’s Correlation Coefficient
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
- en: PLR
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
- en: Piecewise Linear Representation
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
- en: PNN
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
- en: Probabilistic Neural Network
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
- en: PPO
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
- en: Proximal Policy Optimization
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
- en: PSO
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
- en: Particle Swarm Optimization
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
- en: R²
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
- en: Squared correlation, Non-linear regression multiple correlation
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
- en: RBM
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
- en: Restricted Boltzmann Machine
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
- en: RCNN
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent CNN
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
- en: ReLU
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
- en: Rectified Linear Unit
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
- en: RF
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
- en: Random Forest
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
- en: RL
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement Learning
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
- en: RMDN
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent Mixture Density Network
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
- en: RMSE
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
- en: Root Mean Square Error
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
- en: RNN
  id: totrans-695
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent Neural Network
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
- en: ROA
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
- en: Return on Assets
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
- en: ROC
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
- en: Price of Change
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
- en: RSE
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
- en: Relative Squared Error
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
- en: RSI
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
- en: Relative Strength Index
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
- en: SAE
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
- en: Stacked Autoencoder
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
- en: SCI
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
- en: SSE Composite Index
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
- en: SFM
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
- en: State Frequency Memory
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
- en: SGD
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic Gradient Descent
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
- en: S&P500
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
- en: Standard’s & Poor’s 500 Index
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
- en: SPY
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
- en: SPDR S&P 500 ETF
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
- en: SR
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
- en: Sharpe-ratio
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
- en: STD
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
- en: Standard Deviation
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
- en: SVD
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
- en: Singular Value Decomposition
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
- en: SVM
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Machine
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
- en: SVR
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Regressor
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
- en: SZSE
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
- en: Shenzhen Stock Exchange Composite Index
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
- en: TAIEX
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
- en: Taiwan Capitalization Weighted Stock Index
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
- en: TALIB
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
- en: Technical Analysis Library Package
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
- en: TAQ
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
- en: Trade and Quote
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
- en: TDNN
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
- en: Timedelay Neural Network
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
- en: TEMA
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
- en: Triple Exponential Moving Average
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
- en: TF-IDF
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
- en: Term Frequency-Inverse Document Frequency
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
- en: TGRU
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
- en: Two-stream GRU
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
- en: THEIL-U
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
- en: Theil’s inequality coefficient
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
- en: TN
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
- en: True Negative
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
- en: TP
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
- en: True Positive
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
- en: TR
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
- en: Total Return
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
- en: TSE
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
- en: Tokyo Stock Exchange
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
- en: TWSE
  id: totrans-753
  prefs: []
  type: TYPE_NORMAL
- en: Taiwan Stock Exchange
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
- en: VAR
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
- en: Vector Auto Regression
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
- en: VWL
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
- en: WL Kernel-based Method
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
- en: WBA
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
- en: Weighted Balanced Accuracy
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
- en: WMTR
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
- en: Weighted Multichannel Time-series Regression
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
- en: WSURT
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
- en: Wilcoxon Sum-rank Test
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
- en: WT
  id: totrans-765
  prefs: []
  type: TYPE_NORMAL
- en: Wavelet Transforms
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
- en: XGBoost
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
- en: eXtreme Gradient Boosting
  id: totrans-768
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-769
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sezer et al. [2019] Omer Berat Sezer, Mehmet Ugur Gudelek, and Ahmet Murat
    Ozbayoglu. Financial time series forecasting with deep learning : A systematic
    literature review: 2005-2019, 2019.'
  id: totrans-770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bahrammirzaee [2010] Arash Bahrammirzaee. A comparative survey of artificial
    intelligence applications in finance: artificial neural networks, expert system
    and hybrid intelligent systems. *Neural Computing and Applications*, 19(8):1165–1195,
    June 2010.'
  id: totrans-771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang and Zhou [2004] D. Zhang and L. Zhou. Discovering golden nuggets: Data
    mining in financial application. *IEEE Transactions on Systems, Man and Cybernetics,
    Part C (Applications and Reviews)*, 34(4):513–522, November 2004.'
  id: totrans-772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mochón et al. [2007] Asunción Mochón, David Quintana, Yago Sáez, and Pedro Isasi
    Viñuela. Soft computing techniques applied to finance. *Applied Intelligence*,
    29:111–115, 2007.
  id: totrans-773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pulakkazhy [2013] Pulakkazhy. Mining in banking and its applications: A review.
    *Journal of Computer Science*, 9(10):1252–1259, October 2013.'
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mullainathan and Spiess [2017] Sendhil Mullainathan and Jann Spiess. Machine
    learning: An applied econometric approach. *Journal of Economic Perspectives*,
    31(2):87–106, May 2017.'
  id: totrans-775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gai et al. [2018] Keke Gai, Meikang Qiu, and Xiaotong Sun. A survey on fintech.
    *Journal of Network and Computer Applications*, 103:262–273, 2018.
  id: totrans-776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kovalerchuk and Vityaev [2000] Boris Kovalerchuk and Evgenii Vityaev. *Data
    Mining in Finance: Advances in Relational and Hybrid Methods*. Kluwer Academic
    Publishers, Norwell, MA, USA, 2000.'
  id: totrans-777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aliev et al. [2004] Rafik A. Aliev, Bijan Fazlollahi, and Rashad R. Aliev. Soft
    computing and its applications in business and economics. In *Studies in Fuzziness
    and Soft Computing*, 2004.
  id: totrans-778
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brabazon and O’Neill [2008] Anthony Brabazon and Michael O’Neill, editors. *Natural
    Computing in Computational Finance*. Springer Berlin Heidelberg, 2008.
  id: totrans-779
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dymowa [2011] Ludmila Dymowa. *Soft Computing in Economics and Finance*. Springer
    Berlin Heidelberg, 2011.
  id: totrans-780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen [2002] Shu-Heng Chen, editor. *Genetic Algorithms and Genetic Programming
    in Computational Finance*. Springer US, 2002.
  id: totrans-781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tapia and Coello [2007] Ma. Guadalupe Castillo Tapia and Carlos A. Coello Coello.
    Applications of multi-objective evolutionary algorithms in economics and finance:
    A survey. In *2007 IEEE Congress on Evolutionary Computation*. IEEE, September
    2007.'
  id: totrans-782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ponsich et al. [2013] Antonin Ponsich, Antonio Lopez Jaimes, and Carlos A. Coello
    Coello. A survey on multiobjective evolutionary algorithms for the solution of
    the portfolio optimization problem and other finance and economics applications.
    *IEEE Transactions on Evolutionary Computation*, 17(3):321–344, June 2013.
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aguilar-Rivera et al. [2015] Ruben Aguilar-Rivera, Manuel Valenzuela-Rendon,
    and J.J. Rodriguez-Ortiz. Genetic algorithms and darwinian approaches in financial
    applications: A survey. *Expert Systems with Applications*, 42(21):7684–7697,
    November 2015.'
  id: totrans-784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wong and Selvi [1998] Bo K Wong and Yakup Selvi. Neural network applications
    in finance: A review and analysis of literature (1990–1996). *Information & Management*,
    34(3):129–139, October 1998.'
  id: totrans-785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li and Ma [2010] Yuhong Li and Weihua Ma. Applications of artificial neural
    networks in financial economics: A survey. In *2010 International Symposium on
    Computational Intelligence and Design*. IEEE, October 2010.'
  id: totrans-786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Elmsili and Outtaj [2018] B. Elmsili and B. Outtaj. Artificial neural networks
    applications in economics and management research: An exploratory literature review.
    In *2018 4th International Conference on Optimization and Applications (ICOA)*,
    pages 1–6, April 2018.'
  id: totrans-787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeBaron [2006] Blake LeBaron. Chapter 24 agent-based computational finance.
    In L. Tesfatsion and K.L. Judd, editors, *Handbook of Computational Economics*,
    volume 2 of *Handbook of Computational Economics*, pages 1187–1233\. Elsevier,
    2006.
  id: totrans-788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chalup and Mitschele [2008] Stephan K. Chalup and Andreas Mitschele. Kernel
    methods in finance. In *Handbook on Information Technology in Finance*, pages
    655–687\. Springer Berlin Heidelberg, 2008.
  id: totrans-789
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. [2015] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning.
    *Nature*, 521(7553):436–444, 2015.
  id: totrans-790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cybenko [1989] George Cybenko. Approximation by superpositions of a sigmoidal
    function. *Mathematics of control, signals and systems*, 2(4):303–314, 1989.
  id: totrans-791
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kalman and Kwasny [1992] Barry L Kalman and Stan C Kwasny. Why tanh: choosing
    a sigmoidal function. In *[Proceedings 1992] IJCNN International Joint Conference
    on Neural Networks*, volume 4, pages 578–581\. IEEE, 1992.'
  id: totrans-792
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nair and Hinton [2010] Vinod Nair and Geoffrey E Hinton. Rectified linear units
    improve restricted boltzmann machines. In *Proceedings of the 27th international
    conference on machine learning (ICML-10)*, pages 807–814, 2010.
  id: totrans-793
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maas et al. [2013] Andrew L Maas, Awni Y Hannun, and Andrew Y Ng. Rectifier
    nonlinearities improve neural network acoustic models. In *Proc. icml*, volume 30,
    page 3, 2013.
  id: totrans-794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ramachandran et al. [2017] Prajit Ramachandran, Barret Zoph, and Quoc V Le.
    Searching for activation functions. *arXiv preprint arXiv:1710.05941*, 2017.
  id: totrans-795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. [2016] Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
    *Deep Learning*. MIT Press, 2016. http://www.deeplearningbook.org.
  id: totrans-796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hochreiter and Schmidhuber [1997] Sepp Hochreiter and Jürgen Schmidhuber. Long
    short-term memory. *Neural computation*, 9(8):1735–1780, 1997.
  id: totrans-797
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qiu et al. [2014] Xueheng Qiu, Le Zhang, Ye Ren, P. Suganthan, and Gehan Amaratunga.
    Ensemble deep learning for regression and time series forecasting. In *2014 IEEE
    Symposium on Computational Intelligence in Ensemble Learning (CIEL)*, pages 1–6,
    2014.
  id: totrans-798
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bengio [2012] Yoshua Bengio. Deep learning of representations for unsupervised
    and transfer learning. In *Proceedings of ICML workshop on unsupervised and transfer
    learning*, pages 17–36, 2012.
  id: totrans-799
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hinton et al. [2006] Geoffrey E. Hinton, Simon Osindero, and Yee-Whye Teh. A
    fast learning algorithm for deep belief nets. *Neural Computation*, 18(7):1527–1554,
    2006.
  id: totrans-800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vincent et al. [2008] Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine
    Manzagol. Extracting and composing robust features with denoising autoencoders.
    In *Proceedings of the 25th international conference on Machine learning*, pages
    1096–1103\. ACM, 2008.
  id: totrans-801
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meng et al. [2017] Qinxue Meng, Daniel Catchpoole, David Skillicom, and Paul J
    Kennedy. Relational autoencoder for feature extraction. In *2017 International
    Joint Conference on Neural Networks (IJCNN)*, pages 364–371\. IEEE, 2017.
  id: totrans-802
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu et al. [2015] Yong Hu, Kang Liu, Xiangzhou Zhang, Lijun Su, E.W.T. Ngai,
    and Mei Liu. Application of evolutionary computation for rule discovery in stock
    algorithmic trading: A literature review. *Applied Soft Computing*, 36:534–551,
    November 2015.'
  id: totrans-803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Karaoglu and Arpaci [2017] Sercan Karaoglu and Ugur Arpaci. A deep learning
    approach for optimization of systematic signal detection in financial trading
    systems with big data. *International Journal of Intelligent Systems and Applications
    in Engineering*, SpecialIssue(SpecialIssue):31–36, July 2017.
  id: totrans-804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bao et al. [2017] Wei Bao, Jun Yue, and Yulei Rao. A deep learning framework
    for financial time series using stacked autoencoders and long-short term memory.
    *PLOS ONE*, 12(7):e0180944, July 2017.
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2017] Shuanglong Liu, Chao Zhang, and Jinwen Ma. Cnn-lstm neural
    network model for quantitative strategy analysis in stock markets. In *Neural
    Information Processing*, pages 198–206\. Springer International Publishing, 2017.
  id: totrans-806
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2017] Liheng Zhang, Charu Aggarwal, and Guo-Jun Qi. Stock price
    prediction via discovering multi-frequency trading patterns. In *Proceedings of
    the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
    - KDD17*. ACM Press, 2017.
  id: totrans-807
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tran et al. [2017] Dat Thanh Tran, Martin Magris, Juho Kanniainen, Moncef Gabbouj,
    and Alexandros Iosifidis. Tensor representation in high-frequency financial data
    for price change prediction. In *2017 IEEE Symposium Series on Computational Intelligence
    (SSCI)*. IEEE, November 2017.
  id: totrans-808
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deng et al. [2017] Yue Deng, Feng Bao, Youyong Kong, Zhiquan Ren, and Qionghai
    Dai. Deep direct reinforcement learning for financial signal representation and
    trading. *IEEE Transactions on Neural Networks and Learning Systems*, 28(3):653–664,
    March 2017.
  id: totrans-809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fischer and Krauss [2018] Thomas Fischer and Christopher Krauss. Deep learning
    with long short-term memory networks for financial market predictions. *European
    Journal of Operational Research*, 270(2):654–669, October 2018.
  id: totrans-810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mourelatos et al. [2018] Marios Mourelatos, Christos Alexakos, Thomas Amorgianiotis,
    and Spiridon Likothanassis. Financial indices modelling and trading utilizing
    deep learning techniques: The athens se ftse/ase large cap use case. In *2018
    Innovations in Intelligent Systems and Applications (INISTA)*. IEEE, July 2018.'
  id: totrans-811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Si et al. [2017] Weiyu Si, Jinke Li, Peng Ding, and Ruonan Rao. A multi-objective
    deep reinforcement learning approach for stock index future’s intraday trading.
    In *2017 10th International Symposium on Computational Intelligence and Design
    (ISCID)*. IEEE, December 2017.
  id: totrans-812
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yong et al. [2017] Bang Xiang Yong, Mohd Rozaini Abdul Rahim, and Ahmad Shahidan
    Abdullah. A stock market trading system using deep neural network. In *Communications
    in Computer and Information Science*, pages 356–364\. Springer Singapore, 2017.
  id: totrans-813
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu [2017] David W. Lu. Agent inspired trading using recurrent reinforcement
    learning and lstm neural networks, 2017.
  id: totrans-814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dixon et al. [2016] Matthew Francis Dixon, Diego Klabjan, and Jin Hoon Bang.
    Classification-based financial markets prediction using deep neural networks.
    *SSRN Electronic Journal*, 2016.
  id: totrans-815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Korczak and Hernes [2017] Jerzy Korczak and Marcin Hernes. Deep learning for
    financial time series forecasting in a-trader system. In *Proceedings of the 2017
    Federated Conference on Computer Science and Information Systems*. IEEE, September
    2017.
  id: totrans-816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spilak [2018] Bruno Spilak. Deep neural networks for cryptocurrencies price
    prediction. Master’s thesis, Humboldt-Universitat zu Berlin, Wirtschaftswissenschaftliche
    Fakultat, 2018.
  id: totrans-817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jeong and Kim [2019] Gyeeun Jeong and Ha Young Kim. Improving financial trading
    decisions using deep q-learning: Predicting the number of shares, action strategies,
    and transfer learning. *Expert Systems with Applications*, 117:125–138, March
    2019.'
  id: totrans-818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Krauss et al. [2017] Christopher Krauss, Xuan Anh Do, and Nicolas Huck. Deep
    neural networks, gradient-boosted trees, random forests: Statistical arbitrage
    on the s&p 500. *European Journal of Operational Research*, 259(2):689–702, June
    2017.'
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] Google. System and method for computer managed funds to outperform benchmarks.'
  id: totrans-820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sezer et al. [2017] Omer Berat Sezer, Murat Ozbayoglu, and Erdogan Dogdu. A
    deep neural-network based stock trading system based on evolutionary optimized
    technical analysis parameters. *Procedia Computer Science*, 114:473–480, 2017.
  id: totrans-821
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Navon and Keller [2017] Ariel Navon and Yosi Keller. Financial time series prediction
    using deep learning, 2017.
  id: totrans-822
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troiano et al. [2018] Luigi Troiano, Elena Mejuto Villa, and Vincenzo Loia.
    Replicating a trading strategy by means of lstm for financial industry applications.
    *IEEE Transactions on Industrial Informatics*, 14(7):3226–3234, July 2018.
  id: totrans-823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sirignano and Cont [2018] Justin Sirignano and Rama Cont. Universal features
    of price formation in financial markets: Perspectives from deep learning. *SSRN
    Electronic Journal*, 2018.'
  id: totrans-824
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tsantekidis et al. [2017a] Avraam Tsantekidis, Nikolaos Passalis, Anastasios
    Tefas, Juho Kanniainen, Moncef Gabbouj, and Alexandros Iosifidis. Using deep learning
    to detect price change indications in financial markets. In *2017 25th European
    Signal Processing Conference (EUSIPCO)*. IEEE, August 2017a.
  id: totrans-825
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gudelek et al. [2017] M. Ugur Gudelek, S. Arda Boluk, and A. Murat Ozbayoglu.
    A deep learning based stock trading model with 2-d cnn trend detection. In *2017
    IEEE Symposium Series on Computational Intelligence (SSCI)*. IEEE, November 2017.
  id: totrans-826
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sezer and Ozbayoglu [2018] Omer Berat Sezer and Ahmet Murat Ozbayoglu. Algorithmic
    financial trading with deep convolutional neural networks: Time series to image
    conversion approach. *Applied Soft Computing*, 70:525–538, September 2018.'
  id: totrans-827
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu et al. [2018a] Guosheng Hu, Yuxin Hu, Kai Yang, Zehao Yu, Flood Sung, Zhihong
    Zhang, Fei Xie, Jianguo Liu, Neil Robertson, Timpathy Hospedales, and Qiangwei
    Miemie. Deep stock representation learning: From candlestick charts to investment
    decisions. In *2018 IEEE International Conference on Acoustics, Speech and Signal
    Processing (ICASSP)*. IEEE, April 2018a.'
  id: totrans-828
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tsantekidis et al. [2017b] Avraam Tsantekidis, Nikolaos Passalis, Anastasios
    Tefas, Juho Kanniainen, Moncef Gabbouj, and Alexandros Iosifidis. Forecasting
    stock prices from the limit order book using convolutional neural networks. In
    *2017 IEEE 19th Conference on Business Informatics (CBI)*. IEEE, July 2017b.
  id: totrans-829
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gunduz et al. [2017] Hakan Gunduz, Yusuf Yaslan, and Zehra Cataltepe. Intraday
    prediction of borsa istanbul using convolutional neural networks and feature correlations.
    *Knowledge-Based Systems*, 137:138–148, December 2017.
  id: totrans-830
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sezer and Ozbayoglu [2019] Omer Berat Sezer and Ahmet Murat Ozbayoglu. Financial
    trading model with stock bar chart image time series with deep convolutional neural
    networks. *arXiv preprint arXiv:1903.04610*, 2019.
  id: totrans-831
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Serrano [2018] Will Serrano. Fintech model: The random neural network with
    genetic algorithm. *Procedia Computer Science*, 126:537–546, 2018.'
  id: totrans-832
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saad et al. [1998] E.W. Saad, D.V. Prokhorov, and D.C. Wunsch. Comparative study
    of stock trend prediction using time delay, recurrent and probabilistic neural
    networks. *IEEE Transactions on Neural Networks*, 9(6):1456–1470, 1998.
  id: totrans-833
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doering et al. [2017] Jonathan Doering, Michael Fairbank, and Sheri Markose.
    Convolutional neural networks applied to high-frequency market microstructure
    forecasting. In *2017 9th Computer Science and Electronic Engineering (CEEC)*.
    IEEE, September 2017.
  id: totrans-834
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. [2017] Zhengyao Jiang, Dixing Xu, and Jinjun Liang. A deep reinforcement
    learning framework for the financial portfolio management problem. *arXiv preprint
    arXiv:1706.10059*, 2017.
  id: totrans-835
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tino et al. [2001] P. Tino, C. Schittenkopf, and G. Dorffner. Financial volatility
    trading using recurrent neural networks. *IEEE Transactions on Neural Networks*,
    12(4):865–874, July 2001.
  id: totrans-836
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2018a] Yu-Ying Chen, Wei-Lun Chen, and Szu-Hao Huang. Developing
    arbitrage strategy in high-frequency pairs trading with filterbank cnn algorithm.
    In *2018 IEEE International Conference on Agents (ICA)*. IEEE, July 2018a.
  id: totrans-837
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bari and Agah [2018] Omar A. Bari and Arvin Agah. Ensembles of text and time-series
    models for automatic generation of financial trading signals from social media
    content. *Journal of Intelligent Systems*, 2018.
  id: totrans-838
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dixon [2017] Matthew Francis Dixon. Sequence classification of the limit order
    book using recurrent neural networks. *SSRN Electronic Journal*, 2017.
  id: totrans-839
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2018b] Chiao-Ting Chen, An-Pin Chen, and Szu-Hao Huang. Cloning
    strategies from trading records using agent-based reinforcement learning algorithm.
    In *2018 IEEE International Conference on Agents (ICA)*. IEEE, July 2018b.
  id: totrans-840
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2018a] Yue Wang, Chenwei Zhang, Shen Wang, Philip S. Yu, Lu Bai,
    and Lixin Cui. Deep co-investment network learning for financial assets, 2018a.
  id: totrans-841
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Day and Lee [2016] Min-Yuh Day and Chia-Chou Lee. Deep learning for financial
    sentiment analysis on finance news providers. In *2016 IEEE/ACM International
    Conference on Advances in Social Networks Analysis and Mining (ASONAM)*. IEEE,
    August 2016.
  id: totrans-842
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sirignano [2016] Justin Sirignano. Deep learning for limit order books, 2016.
  id: totrans-843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao [2018] Xiang Gao. Deep reinforcement learning for time series: playing
    idealized trading games, 2018.'
  id: totrans-844
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baily et al. [2008] Martin Neil Baily, Robert E. Litan, and Johnson Matthew
    S. The origins of the financial crisis. *Initiative on Business and Public Policy
    at Brookings, Fixing Finance Series - Paper 3*, 2008.
  id: totrans-845
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luo et al. [2017] Cuicui Luo, Desheng Wu, and Dexiang Wu. A deep learning approach
    for credit scoring using credit default swaps. *Engineering Applications of Artificial
    Intelligence*, 65:465–470, October 2017.
  id: totrans-846
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu et al. [2018] Lean Yu, Rongtian Zhou, Ling Tang, and Rongda Chen. A dbn-based
    resampling svm ensemble learning paradigm for credit classification with imbalanced
    data. *Applied Soft Computing*, 69:192–202, August 2018.
  id: totrans-847
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2017a] Ying Li, Xianghong Lin, Xiangwen Wang, Fanqi Shen, and Zuzheng
    Gong. Credit risk assessment algorithm using deep neural networks with clustering
    and merging. In *2017 13th International Conference on Computational Intelligence
    and Security (CIS)*. IEEE, December 2017a.
  id: totrans-848
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tran et al. [2016] Khiem Tran, Thanh Duong, and Quyen Ho. Credit scoring model:
    A combination of genetic programming and deep learning. In *2016 Future Technologies
    Conference (FTC)*. IEEE, December 2016.'
  id: totrans-849
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neagoe et al. [2018] Victor-Emil Neagoe, Adrian-Dumitru Ciotec, and George-Sorin
    Cucu. Deep convolutional neural networks versus multilayer perceptron for financial
    prediction. In *2018 International Conference on Communications (COMM)*. IEEE,
    June 2018.
  id: totrans-850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. [2018] Bing Zhu, Wenchuan Yang, Huaxuan Wang, and Yuan Yuan. A hybrid
    deep learning model for consumer credit scoring. In *2018 International Conference
    on Artificial Intelligence and Big Data (ICAIBD)*. IEEE, May 2018.
  id: totrans-851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Niimi [2015] Ayahiko Niimi. Deep learning for credit card data analysis. In
    *2015 World Congress on Internet Security (WorldCIS)*. IEEE, October 2015.
  id: totrans-852
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kirkos and Manolopoulos [2004] Efstathios Kirkos and Yannis Manolopoulos. Data
    mining in finance and accounting: A review of current research trends. In *Proceedings
    of the 1 st International Conference on Enterprise Systems and Accounting (ICESAcc*,
    pages 63–78, 2004.'
  id: totrans-853
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ravi et al. [2008] V. Ravi, H. Kurniawan, Peter Nwee Kok Thai, and P. Ravi Kumar.
    Soft computing system for bank performance prediction. *Applied Soft Computing*,
    8(1):305–315, January 2008.
  id: totrans-854
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fethi and Pasiouras [2010] Meryem Duygun Fethi and Fotios Pasiouras. Assessing
    bank efficiency and performance with operational research and artificial intelligence
    techniques: A survey. *European Journal of Operational Research*, 204(2):189–198,
    July 2010.'
  id: totrans-855
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lahsasna et al. [2010] Adel Lahsasna, Raja Noor Ainon, and Ying Wah Teh. Credit
    scoring models using soft computing methods: A survey. *Int. Arab J. Inf. Technol.*,
    7:115–123, 2010.'
  id: totrans-856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. [2015] Ning Chen, Bernardete Ribeiro, and An Chen. Financial credit
    risk assessment: a recent review. *Artificial Intelligence Review*, 45(1):1–23,
    October 2015.'
  id: totrans-857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marques et al. [2013] AI Marques, Vicente García, and José Salvador Sánchez.
    A literature review on the application of evolutionary computing to credit scoring.
    *Journal of the Operational Research Society*, 64(9):1384–1399, 2013.
  id: totrans-858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kumar and Ravi [2007] P. Ravi Kumar and V. Ravi. Bankruptcy prediction in banks
    and firms via statistical and intelligent techniques – a review. *European Journal
    of Operational Research*, 180(1):1–28, July 2007.
  id: totrans-859
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Verikas et al. [2009] Antanas Verikas, Zivile Kalsyte, Marija Bacauskiene,
    and Adas Gelzinis. Hybrid and ensemble-based soft computing techniques in bankruptcy
    prediction: a survey. *Soft Computing*, 14(9):995–1010, September 2009.'
  id: totrans-860
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. [2014] Jie Sun, Hui Li, Qing-Hua Huang, and Kai-Yu He. Predicting
    financial distress and corporate failure: A review from the state-of-the-art definitions,
    modeling, sampling, and featuring approaches. *Knowledge-Based Systems*, 57:41–56,
    February 2014.'
  id: totrans-861
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. [2012] W. Lin, Y. Hu, and C. Tsai. Machine learning in financial
    crisis prediction: A survey. *IEEE Transactions on Systems, Man, and Cybernetics,
    Part C (Applications and Reviews)*, 42(4):421–436, July 2012.'
  id: totrans-862
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lanbouri and Achchab [2015] Zineb Lanbouri and Said Achchab. A hybrid deep
    belief network approach for financial distress prediction. In *2015 10th International
    Conference on Intelligent Systems: Theories and Applications (SITA)*. IEEE, October
    2015.'
  id: totrans-863
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rawte et al. [2018] Vipula Rawte, Aparna Gupta, and Mohammed J. Zaki. Analysis
    of year-over-year changes in risk factors disclosure in 10-k filings. In *Proceedings
    of the Fourth International Workshop on Data Science for Macro-Modeling with Financial
    and Economic Datasets - DSMM18*. ACM Press, 2018.
  id: totrans-864
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ronnqvist and Sarlin [2015] Samuel Ronnqvist and Peter Sarlin. Detect & describe:
    Deep learning of bank stress in the news. In *2015 IEEE Symposium Series on Computational
    Intelligence*. IEEE, December 2015.'
  id: totrans-865
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ronnqvist and Sarlin [2017] Samuel Ronnqvist and Peter Sarlin. Bank distress
    in the news: Describing events through deep learning. *Neurocomputing*, 264:57–70,
    November 2017.'
  id: totrans-866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cerchiello et al. [2017] Paola Cerchiello, Giancarlo Nicola, Samuel Rönnqvist,
    and Peter Sarlin. Deep learning bank distress from news and numerical financial
    data. *CoRR*, abs/1706.09627, 2017.
  id: totrans-867
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Malik et al. [2018] Nikhil Malik, Param Vir Singh, and Urooj Khan. Can banks
    survive the next financial crisis? an adversarial deep learning model for bank
    stress testing. *An Adversarial Deep Learning Model for Bank Stress Testing (June
    30, 2018)*, 2018.
  id: totrans-868
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ribeiro and Lopes [2011] Bernardete Ribeiro and Noel Lopes. Deep belief networks
    for financial prediction. In *Neural Information Processing*, pages 766–773\.
    Springer Berlin Heidelberg, 2011.
  id: totrans-869
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yeh et al. [2015] Shu-Hao Yeh, Chuan-Ju Wang, and Ming-Feng Tsai. Deep belief
    networks for predicting corporate defaults. In *2015 24th Wireless and Optical
    Communication Conference (WOCC)*. IEEE, October 2015.
  id: totrans-870
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hosaka [2018] Tadaaki Hosaka. Bankruptcy prediction using imaged financial ratios
    and convolutional neural networks. *Expert Systems with Applications*, September
    2018.
  id: totrans-871
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sirignano et al. [2018] Justin Sirignano, Apaar Sadhwani, and Kay Giesecke.
    Deep learning for mortgage risk. *SSRN Electronic Journal*, 2018.
  id: totrans-872
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kvamme et al. [2018] Håvard Kvamme, Nikolai Sellereite, Kjersti Aas, and Steffen
    Sjursen. Predicting mortgage default using convolutional neural networks. *Expert
    Systems with Applications*, 102:207–217, July 2018.
  id: totrans-873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: and [2017] Narek Abroyan and. Neural networks for financial market risk classification.
    *Frontiers in Signal Processing*, 1(2), August 2017.
  id: totrans-874
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chatzis et al. [2018] Sotirios P. Chatzis, Vassilis Siakoulis, Anastasios Petropoulos,
    Evangelos Stavroulakis, and Nikos Vlachogiannakis. Forecasting stock market crisis
    events using deep and statistical machine learning techniques. *Expert Systems
    with Applications*, 112:353–371, December 2018.
  id: totrans-875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kirkos et al. [2007] E Kirkos, C Spathis, and Y Manolopoulos. Data mining techniques
    for the detection of fraudulent financial statements. *Expert Systems with Applications*,
    32(4):995–1003, May 2007.
  id: totrans-876
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yue et al. [2007] Dianmin Yue, Xiaodan Wu, Yunfeng Wang, Yue Li, and Chao-Hsien
    Chu. A review of data mining-based financial fraud detection research. In *2007
    International Conference on Wireless Communications, Networking and Mobile Computing*.
    IEEE, September 2007.
  id: totrans-877
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang [2010] Shiguo Wang. A comprehensive survey of data mining-based accounting-fraud
    detection research. In *2010 International Conference on Intelligent Computation
    Technology and Automation*. IEEE, May 2010.
  id: totrans-878
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phua et al. [2010] Clifton Phua, Vincent C. S. Lee, Kate Smith-Miles, and Ross W.
    Gayler. A comprehensive survey of data mining-based fraud detection research.
    *CoRR*, abs/1009.6119, 2010.
  id: totrans-879
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ngai et al. [2011] E.W.T. Ngai, Yong Hu, Y.H. Wong, Yijun Chen, and Xin Sun.
    The application of data mining techniques in financial fraud detection: A classification
    framework and an academic review of literature. *Decision Support Systems*, 50(3):559–569,
    February 2011.'
  id: totrans-880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharma and Panigrahi [2012] Anuj Sharma and Prabin Kumar Panigrahi. A review
    of financial accounting fraud detection based on data mining techniques. *International
    Journal of Computer Applications*, 39(1):37–47, February 2012.
  id: totrans-881
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'West and Bhattacharya [2016] Jarrod West and Maumita Bhattacharya. Intelligent
    financial fraud detection: A comprehensive review. *Computers & Security*, 57:47–66,
    March 2016.'
  id: totrans-882
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heryadi and Warnars [2017] Yaya Heryadi and Harco Leslie Hendric Spits Warnars.
    Learning temporal representation of transaction amount for fraudulent transaction
    recognition using cnn, stacked lstm, and cnn-lstm. In *2017 IEEE International
    Conference on Cybernetics and Computational Intelligence (CyberneticsCom)*. IEEE,
    November 2017.
  id: totrans-883
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roy et al. [2018] Abhimanyu Roy, Jingyi Sun, Robert Mahoney, Loreto Alonzi,
    Stephen Adams, and Peter Beling. Deep learning detecting fraud in credit card
    transactions. In *2018 Systems and Information Engineering Design Symposium (SIEDS)*.
    IEEE, April 2018.
  id: totrans-884
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gómez et al. [2018] Jon Ander Gómez, Juan Arévalo, Roberto Paredes, and Jordi
    Nin. End-to-end neural network architecture for fraud scoring in card payments.
    *Pattern Recognition Letters*, 105:175–181, April 2018.
  id: totrans-885
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sohony et al. [2018] Ishan Sohony, Rameshwar Pratap, and Ullas Nambiar. Ensemble
    learning for credit card fraud detection. In *Proceedings of the ACM India Joint
    International Conference on Data Science and Management of Data - CoDS-COMAD18*.
    ACM Press, 2018.
  id: totrans-886
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jurgovsky et al. [2018] Johannes Jurgovsky, Michael Granitzer, Konstantin Ziegler,
    Sylvie Calabretto, Pierre-Edouard Portier, Liyun He-Guelton, and Olivier Caelen.
    Sequence classification for credit-card fraud detection. *Expert Systems with
    Applications*, 100:234–245, June 2018.
  id: totrans-887
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paula et al. [2016] Ebberth L. Paula, Marcelo Ladeira, Rommel N. Carvalho, and
    Thiago Marzagao. Deep learning anomaly detection as support fraud investigation
    in brazilian exports and anti-money laundering. In *2016 15th IEEE International
    Conference on Machine Learning and Applications (ICMLA)*. IEEE, December 2016.
  id: totrans-888
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gomes et al. [2017] Thiago Alencar Gomes, Rommel Novaes Carvalho, and Ricardo Silva
    Carvalho. Identifying anomalies in parliamentary expenditures of brazilian chamber
    of deputies with deep autoencoders. In *2017 16th IEEE International Conference
    on Machine Learning and Applications (ICMLA)*. IEEE, December 2017.
  id: totrans-889
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang and Xu [2018] Yibo Wang and Wei Xu. Leveraging deep learning with lda-based
    text analytics to detect automobile insurance fraud. *Decision Support Systems*,
    105:87–95, January 2018.
  id: totrans-890
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. [2017b] Longfei Li, Jun Zhou, Xiaolong Li, and Tao Chen. Poster:
    Practical fraud transaction prediction. In *ACM Conference on Computer and Communications
    Security*, 2017b.'
  id: totrans-891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: de Souza Costa and Silva [2016] Allan Inocencio de Souza Costa and Luis Silva.
    Sequence classification of the limit order book using recurrent neural networks.
    2016.
  id: totrans-892
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goumagias et al. [2018] Nikolaos D. Goumagias, Dimitrios Hristu-Varsakelis,
    and Yannis M. Assael. Using deep q-learning to understand the tax evasion behavior
    of risk-averse firms. *Expert Systems with Applications*, 101:258–270, July 2018.
  id: totrans-893
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li and Hoi [2014] Bin Li and Steven C. H. Hoi. Online portfolio selection:
    A survey. *ACM Comput. Surv.*, 46(3):35:1–35:36, January 2014.'
  id: totrans-894
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Metaxiotis and Liagkouras [2012] K. Metaxiotis and K. Liagkouras. Multiobjective
    evolutionary algorithms for portfolio management: A comprehensive literature review.
    *Expert Systems with Applications*, 39(14):11685–11698, October 2012.'
  id: totrans-895
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Takeuchi [2013] Lawrence Takeuchi. Applying deep learning to enhance momentum
    trading strategies in stocks. 2013.
  id: totrans-896
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grace [2017] Anthony Grace. Can deep learning techniques improve the risk adjusted
    returns from enhanced indexing investment strategies. Master’s thesis, 2017.
  id: totrans-897
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fu et al. [2018] XingYu Fu, JinHong Du, YiFeng Guo, MingWen Liu, Tao Dong, and
    XiuWen Duan. A machine learning framework for stock selection, 2018.
  id: totrans-898
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggarwal and Aggarwal [2017] Saurabh Aggarwal and Somya Aggarwal. Deep investment
    in financial markets using deep learning models. *International Journal of Computer
    Applications*, 162(2):40–43, March 2017.
  id: totrans-899
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Heaton and Polson [2016] J.B. Heaton and Nick Polson. Deep learning for finance:
    Deep portfolios. *SSRN Electronic Journal*, 2016.'
  id: totrans-900
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. [2006] Chi-Ming Lin, Jih-Jeng Huang, Mitsuo Gen, and Gwo-Hshiung
    Tzeng. Recurrent neural network for dynamic portfolio selection. *Applied Mathematics
    and Computation*, 175(2):1139–1146, April 2006.
  id: totrans-901
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maknickienė [2014] Nijolė Maknickienė. Selection of orthogonal investment portfolio
    using evolino rnn trading model. *Procedia - Social and Behavioral Sciences*,
    110:1158–1165, January 2014.
  id: totrans-902
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou [2018] Bo Zhou. Deep learning and the cross-section of stock returns:
    Neural networks combining price and fundamental information. *SSRN Electronic
    Journal*, 2018.'
  id: totrans-903
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Batres-Estrada [2015] Bilberto Batres-Estrada. Deep learning for multivariate
    financial time series. Master’s thesis, KTH, Mathematical Statistics, 2015.
  id: totrans-904
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee and Yoo [2018] Sang Il Lee and Seong Joon Yoo. Threshold-based portfolio:
    the role of the threshold and its applications. *The Journal of Supercomputing*,
    September 2018.'
  id: totrans-905
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iwasaki and Chen [2018] Hitoshi Iwasaki and Ying Chen. Topic sentiment asset
    pricing with dnn supervised learning. *SSRN Electronic Journal*, 2018.
  id: totrans-906
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. [2018] Zhipeng Liang, Hao Chen, Junhao Zhu, Kangkang Jiang, and
    Yanran Li. Adversarial deep reinforcement learning in portfolio management, 2018.
  id: totrans-907
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. [2016] Jiaqi Chen, Wenbo Wu, and Michael Tindall. Hedge fund return
    prediction and fund selection: A machine-learning approach. Occasional Papers
    16-4, Federal Reserve Bank of Dallas, November 2016.'
  id: totrans-908
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang and Liang [2017] Zhengyao Jiang and Jinjun Liang. Cryptocurrency portfolio
    management with deep reinforcement learning. In *2017 Intelligent Systems Conference
    (IntelliSys)*. IEEE, September 2017.
  id: totrans-909
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maknickiene et al. [2014] Nijole Maknickiene, Aleksandras Vytautas Rutkauskas,
    and Algirdas Maknickas. Investigation of financial market prediction by recurrent
    neural network. 2014.
  id: totrans-910
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Culkin and Das [2017] Robert Culkin and Sanjiv R. Das. Machine learning in
    finance: The case of deep learning in option pricing. 2017.'
  id: totrans-911
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hsu et al. [2018] Pei-Ying Hsu, Chin Chou, Szu-Hao Huang, and An-Pin Chen. A
    market making quotation strategy based on dual deep learning agents for option
    pricing and bid-ask spread estimation. In *2018 IEEE International Conference
    on Agents (ICA)*. IEEE, July 2018.
  id: totrans-912
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feng et al. [2018] Guanhao Feng, Nicholas G. Polson, and Jianeng Xu. Deep factor
    alpha, 2018.
  id: totrans-913
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen [2018] Rui-Yang Chen. A traceability chain algorithm for artificial neural
    networks using t–s fuzzy cognitive maps in blockchain. *Future Generation Computer
    Systems*, 80:198–210, March 2018.
  id: totrans-914
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nan and Tao [2018] Lihao Nan and Dacheng Tao. Bitcoin mixing detection using
    deep autoencoder. In *2018 IEEE Third International Conference on Data Science
    in Cyberspace (DSC)*. IEEE, June 2018.
  id: totrans-915
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lopes [2018] Gonçalo Duarte Lima Freire Lopes. Deep learning for market forecasts.
    2018.
  id: totrans-916
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: McNally et al. [2018] Sean McNally, Jason Roche, and Simon Caton. Predicting
    the price of bitcoin using machine learning. In *2018 26th Euromicro International
    Conference on Parallel, Distributed and Network-based Processing (PDP)*. IEEE,
    March 2018.
  id: totrans-917
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kearney and Liu [2014] Colm Kearney and Sha Liu. Textual sentiment in finance:
    A survey of methods and models. *International Review of Financial Analysis*,
    33:171–185, May 2014.'
  id: totrans-918
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2018b] Qili Wang, Wei Xu, and Han Zheng. Combining the wisdom of
    crowds and technical analysis for financial market prediction using deep random
    subspace ensembles. *Neurocomputing*, 299:51–61, July 2018b.
  id: totrans-919
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shi et al. [2018] Lei Shi, Zhiyang Teng, Le Wang, Yue Zhang, and Alexander
    Binder. Deepclue: Visual interpretation of text-based deep stock prediction. *IEEE
    Transactions on Knowledge and Data Engineering*, pages 1–1, 2018.'
  id: totrans-920
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peng and Jiang [2016] Yangtuo Peng and Hui Jiang. Leverage financial news to
    predict stock price movements using word embeddings and deep neural networks.
    In *Proceedings of the 2016 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*. Association for Computational
    Linguistics, 2016.'
  id: totrans-921
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhuge et al. [2017] Qun Zhuge, Lingyu Xu, and Gaowei Zhang. Lstm neural network
    with emotional analysis for prediction of stock price. 2017.
  id: totrans-922
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhongshengz [2018] Zhongshengz. Measuring financial crisis index for risk warning
    through analysis of social network. Master’s thesis, 2018.
  id: totrans-923
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Das et al. [2018] Sushree Das, Ranjan Kumar Behera, Mukesh Kumar, and Santanu Kumar
    Rath. Real-time sentiment analysis of twitter streaming data for stock prediction.
    *Procedia Computer Science*, 132:956–964, 2018.
  id: totrans-924
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prosky et al. [2017] Jordan Prosky, Xingyou Song, Andrew Tan, and Michael Zhao.
    Sentiment predictability for stocks. *CoRR*, abs/1712.05785, 2017.
  id: totrans-925
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. [2017c] Jiahong Li, Hui Bu, and Junjie Wu. Sentiment-aware stock
    market prediction: A deep learning method. In *2017 International Conference on
    Service Systems and Service Management*. IEEE, June 2017c.'
  id: totrans-926
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. [2016] Yifu Huang, Kai Huang, Yang Wang, Hao Zhang, Jihong Guan,
    and Shuigeng Zhou. Exploiting twitter moods to boost financial trend prediction
    based on deep network models. In *Intelligent Computing Methodologies*, pages
    449–460. Springer International Publishing, 2016.
  id: totrans-927
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mitra and Mitra [2012] Leela Mitra and Gautam Mitra. Applications of news analytics
    in finance: A review. In *The Handbook of News Analytics in Finance*, pages 1–39.
    John Wiley & Sons, Ltd., May 2012.'
  id: totrans-928
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li [2011] Feng Li. Textual analysis of corporate disclosures: A survey of the
    literature. *Journal of Accounting Literature*, 29, February 2011.'
  id: totrans-929
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Loughran and McDonald [2016] Tim Loughran and Bill McDonald. Textual analysis
    in accounting and finance: A survey. *Journal of Accounting Research*, 54(4):1187–1230,
    June 2016.'
  id: totrans-930
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kumar and Ravi [2016] B. Shravan Kumar and Vadlamani Ravi. A survey of the applications
    of text mining in financial domain. *Knowledge-Based Systems*, 114:128–147, December
    2016.
  id: totrans-931
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mittermayer and F Knolmayer [2006] Marc-André Mittermayer and Gerhard F Knolmayer.
    Text mining systems for market response to news: A survey. September 2006.'
  id: totrans-932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nassirtoussi et al. [2014] Arman Khadjeh Nassirtoussi, Saeed Aghabozorgi, Teh Ying
    Wah, and David Chek Ling Ngo. Text mining for market prediction: A systematic
    review. *Expert Systems with Applications*, 41(16):7653–7670, November 2014.'
  id: totrans-933
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huynh et al. [2017] Huy D. Huynh, L. Minh Dang, and Duc Duong. A new model for
    stock price movements prediction using deep neural network. In *Proceedings of
    the Eighth International Symposium on Information and Communication Technology
    - SoICT 2017*. ACM Press, 2017.
  id: totrans-934
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Han et al. [2018] Songqiao Han, Xiaoling Hao, and Hailiang Huang. An event-extraction
    approach for business analysis from online chinese news. *Electronic Commerce
    Research and Applications*, 28:244–260, March 2018.
  id: totrans-935
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kraus and Feuerriegel [2017] Mathias Kraus and Stefan Feuerriegel. Decision
    support from financial disclosures with deep neural networks and transfer learning.
    *Decision Support Systems*, 104:38–48, December 2017.
  id: totrans-936
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dang et al. [2018] L. Minh Dang, Abolghasem Sadeghi-Niaraki, Huy D. Huynh, Kyungbok
    Min, and Hyeonjoon Moon. Deep learning approach for short-term stock trends prediction
    based on two-stream gated recurrent unit network. *IEEE Access*, pages 1–1, 2018.
  id: totrans-937
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ding et al. [2015] Xiao Ding, Yue Zhang, Ting Liu, and Junwen Duan. Deep learning
    for event-driven stock prediction. In *Proceedings of the 24th International Conference
    on Artificial Intelligence*, IJCAI’15, pages 2327–2333\. AAAI Press, 2015.
  id: totrans-938
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vargas et al. [2017] Manuel R. Vargas, Beatriz S. L. P. de Lima, and Alexandre G.
    Evsukoff. Deep learning for stock market prediction from financial news articles.
    In *2017 IEEE International Conference on Computational Intelligence and Virtual
    Environments for Measurement Systems and Applications (CIVEMSA)*. IEEE, June 2017.
  id: totrans-939
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akita et al. [2016] Ryo Akita, Akira Yoshihara, Takashi Matsubara, and Kuniaki
    Uehara. Deep learning for stock prediction using numerical and textual information.
    In *2016 IEEE/ACIS 15th International Conference on Computer and Information Science
    (ICIS)*. IEEE, June 2016.
  id: totrans-940
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verma et al. [2017] Ishan Verma, Lipika Dey, and Hardik Meisheri. Detecting,
    quantifying and accessing impact of news events on indian stock indices. In *Proceedings
    of the International Conference on Web Intelligence - WI17*. ACM Press, 2017.
  id: totrans-941
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2018] Xi Zhang, Yunjia Zhang, Senzhang Wang, Yuntao Yao, Binxing
    Fang, and Philip S. Yu. Improving stock market prediction via heterogeneous information
    fusion. *Knowledge-Based Systems*, 143:236–247, March 2018.
  id: totrans-942
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2018c] Weiling Chen, Chai Kiat Yeo, Chiew Tong Lau, and Bu Sung
    Lee. Leveraging social media news to predict stock index movement using rnn-boost.
    *Data & Knowledge Engineering*, August 2018c.
  id: totrans-943
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu et al. [2018b] Ziniu Hu, Weiqing Liu, Jiang Bian, Xuanzhe Liu, and Tie-Yan
    Liu. Listening to chaotic whispers: A deep learning framework for news-oriented
    stock trend prediction. In *Proceedings of the Eleventh ACM International Conference
    on Web Search and Data Mining*, WSDM ’18, pages 261–269, New York, NY, USA, 2018b.
    ACM.'
  id: totrans-944
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2018] Xiaodong Li, Jingjing Cao, and Zhaoqing Pan. Market impact
    analysis via deep learned architectures. *Neural Computing and Applications*,
    March 2018.
  id: totrans-945
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee and Soo [2017] Che-Yu Lee and Von-Wun Soo. Predict stock price with financial
    news based on recurrent convolutional neural networks. In *2017 Conference on
    Technologies and Applications of Artificial Intelligence (TAAI)*. IEEE, December
    2017.
  id: totrans-946
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minami [2018] Shotaro Minami. Predicting equity price with corporate action
    events using lstm-rnn. *Journal of Mathematical Finance*, 08(01):58–63, 2018.
  id: totrans-947
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yoshihara et al. [2014] Akira Yoshihara, Kazuki Fujikawa, Kazuhiro Seki, and
    Kuniaki Uehara. Predicting stock market trends by recurrent deep neural networks.
    In *Lecture Notes in Computer Science*, pages 759–769\. Springer International
    Publishing, 2014.
  id: totrans-948
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buczkowski [2017] Przemyslaw Buczkowski. Predicting stock trends based on expert
    recommendations using gru/lstm neural networks. In *Lecture Notes in Computer
    Science*, pages 708–717\. Springer International Publishing, 2017.
  id: totrans-949
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'dos Santos Pinheiro and Dras [2017] Leonardo dos Santos Pinheiro and Mark Dras.
    Stock market prediction with deep learning: A character-based neural language
    model for event-based trading. In *Proceedings of the Australasian Language Technology
    Association Workshop 2017*, pages 6–15, 2017.'
  id: totrans-950
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2018] Yang Liu, Qingguo Zeng, Huanrui Yang, and Adrian Carrio. Stock
    price movement prediction from financial news with deep learning and knowledge
    graph embedding. In *Knowledge Management and Acquisition for Intelligent Systems*,
    pages 102–113\. Springer International Publishing, 2018.
  id: totrans-951
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matsubara et al. [2018] Takashi Matsubara, Ryo Akita, and Kuniaki Uehara. Stock
    price prediction by deep neural generative model of news articles. *IEICE Transactions
    on Information and Systems*, E101.D(4):901–908, 2018.
  id: totrans-952
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nascimento and Cristo [2015] Janderson B. Nascimento and Marco Cristo. The impact
    of structured event embeddings on scalable stock forecasting models. In *Proceedings
    of the 21st Brazilian Symposium on Multimedia and the Web - WebMedia15*. ACM Press,
    2015.
  id: totrans-953
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akhtar et al. [2017] Md Shad Akhtar, Abhishek Kumar, Deepanway Ghosal, Asif
    Ekbal, and Pushpak Bhattacharyya. A multilayer perceptron based ensemble technique
    for fine-grained financial sentiment analysis. In *Proceedings of the 2017 Conference
    on Empirical Methods in Natural Language Processing*, pages 540–546\. Association
    for Computational Linguistics, 2017.
  id: totrans-954
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chang et al. [2016] Ching-Yun Chang, Yue Zhang, Zhiyang Teng, Zahn Bozanic,
    and Bin Ke. Measuring the information content of financial news. In *COLING*,
    2016.
  id: totrans-955
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jangid et al. [2018] Hitkul Jangid, Shivangi Singhal, Rajiv Ratn Shah, and Roger
    Zimmermann. Aspect-based financial sentiment analysis using deep learning. In
    *Companion of the The Web Conference 2018 on The Web Conference 2018 - WWW18*.
    ACM Press, 2018.
  id: totrans-956
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: E. et al. [2018] Shijia E., Li Yang, Mohan Zhang, and Yang Xiang. Aspect-based
    financial sentiment analysis with deep neural networks. In *Companion of the The
    Web Conference 2018 on The Web Conference 2018 - WWW18*. ACM Press, 2018.
  id: totrans-957
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sohangir et al. [2018] Sahar Sohangir, Dingding Wang, Anna Pomeranets, and
    Taghi M. Khoshgoftaar. Big data: Deep learning for financial sentiment analysis.
    *Journal of Big Data*, 5(1), January 2018.'
  id: totrans-958
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mahmoudi et al. [2018] Nader Mahmoudi, Paul Docherty, and Pablo Moscato. Deep
    neural networks understand investors better. *Decision Support Systems*, 112:23–34,
    August 2018.
  id: totrans-959
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kitamori et al. [2017] Shiori Kitamori, Hiroyuki Sakai, and Hiroki Sakaji. Extraction
    of sentences concerning business performance forecast and economic forecast from
    summaries of financial statements by deep learning. In *2017 IEEE Symposium Series
    on Computational Intelligence (SSCI)*. IEEE, November 2017.
  id: totrans-960
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Piao and Breslin [2018] Guangyuan Piao and John G. Breslin. Financial aspect
    and sentiment predictions with deep neural networks. In *Companion of the The
    Web Conference 2018 on The Web Conference 2018 - WWW18*. ACM Press, 2018.
  id: totrans-961
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li and Chen [2014] Weifeng Li and Hsinchun Chen. Identifying top sellers in
    underground economy using deep learning-based sentiment analysis. In *2014 IEEE
    Joint Intelligence and Security Informatics Conference*. IEEE, September 2014.
  id: totrans-962
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Moore and Rayson [2017] Andrew Moore and Paul Rayson. Lancaster a at semeval-2017
    task 5: Evaluation metrics matter: predicting sentiment from financial news headlines.
    In *Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)*,
    pages 581–585, Vancouver, Canada, August 2017. Association for Computational Linguistics.'
  id: totrans-963
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ying et al. [2017] Josh Jia-Ching Ying, Po-Yu Huang, Chih-Kai Chang, and Don-Lin
    Yang. A preliminary study on deep learning for predicting social insurance payment
    behavior. In *2017 IEEE International Conference on Big Data (Big Data)*. IEEE,
    December 2017.
  id: totrans-964
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sohangir and Wang [2018] Sahar Sohangir and Dingding Wang. Finding expert authors
    in financial forum using deep learning methods. In *2018 Second IEEE International
    Conference on Robotic Computing (IRC)*. IEEE, January 2018.
  id: totrans-965
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sokolov [2017] Vadim Sokolov. Discussion of ’deep learning for finance: deep
    portfolios’. *Applied Stochastic Models in Business and Industry*, 33(1):16–18,
    2017.'
  id: totrans-966
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bouchti et al. [2017] Abdelali El Bouchti, Ahmed Chakroun, Hassan Abbar, and
    Chafik Okar. Fraud detection in banking using deep reinforcement learning. In
    *2017 Seventh International Conference on Innovative Computing Technology (INTECH)*.
    IEEE, August 2017.
  id: totrans-967
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dixon et al. [2015] Matthew Dixon, Diego Klabjan, and Jin Hoon Bang. Implementing
    deep neural networks for financial market prediction on the intel xeon phi. In
    *Proceedings of the 8th Workshop on High Performance Computational Finance - WHPCF15*.
    ACM Press, 2015.
  id: totrans-968
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alberg and Lipton [2017] John Alberg and Zachary Chase Lipton. Improving factor-based
    quantitative investing by forecasting company fundamentals. *CoRR*, abs/1711.04837,
    2017.
  id: totrans-969
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. [2015] Kee-Hoon Kim, Chang-Seok Lee, Sang-Muk Jo, and Sung-Bae Cho.
    Predicting the success of bank telemarketing using deep convolutional neural network.
    In *2015 7th International Conference of Soft Computing and Pattern Recognition
    (SoCPaR)*. IEEE, November 2015.
  id: totrans-970
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee et al. [2017] Joonhyuck Lee, Dong Sik Jang, and Sangsung Park. Deep learning-based
    corporate performance prediction model considering technical capability. *Sustainability*,
    9(6), May 2017.
  id: totrans-971
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
