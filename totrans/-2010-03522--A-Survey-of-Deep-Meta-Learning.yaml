- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:58:56'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:58:56
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2010.03522] A Survey of Deep Meta-Learning'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2010.03522] 深度元学习综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2010.03522](https://ar5iv.labs.arxiv.org/html/2010.03522)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2010.03522](https://ar5iv.labs.arxiv.org/html/2010.03522)
- en: ∎
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ∎
- en: '¹¹institutetext: M. Huisman ²²institutetext: J.N. van Rijn ³³institutetext:
    A. Plaat ⁴⁴institutetext: Leiden Institute of Advanced Computer Science'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹¹机构文本：M. Huisman ²²机构文本：J.N. van Rijn ³³机构文本：A. Plaat ⁴⁴机构文本：莱顿高级计算机科学研究所
- en: Niels Bohrweg 1, 2333CA Leiden, The Netherlands
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 荷兰莱顿市 Niels Bohrweg 1, 2333CA
- en: '⁴⁴email: m.huisman@liacs.leidenuniv.nl'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴⁴电子邮件：m.huisman@liacs.leidenuniv.nl
- en: A Survey of Deep Meta-Learning
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度元学习综述
- en: Mike Huisman    Jan N. van Rijn    Aske Plaat
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Mike Huisman    Jan N. van Rijn    Aske Plaat
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep neural networks can achieve great successes when presented with large data
    sets and sufficient computational resources. However, their ability to learn new
    concepts quickly is limited. Meta-learning is one approach to address this issue,
    by enabling the network to learn how to learn. The field of Deep Meta-Learning
    advances at great speed, but lacks a unified, in-depth overview of current techniques.
    With this work, we aim to bridge this gap. After providing the reader with a theoretical
    foundation, we investigate and summarize key methods, which are categorized into
    i) metric-, ii) model-, and iii) optimization-based techniques. In addition, we
    identify the main open challenges, such as performance evaluations on heterogeneous
    benchmarks, and reduction of the computational costs of meta-learning.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络在处理大数据集和充足计算资源时能取得巨大成功。然而，它们快速学习新概念的能力有限。元学习是一种解决这一问题的方法，通过使网络学习如何学习。深度元学习领域发展迅速，但缺乏统一的、深入的当前技术概述。我们旨在弥补这一空白。在为读者提供理论基础后，我们研究并总结了关键方法，这些方法分为
    i) 度量、ii) 模型 和 iii) 优化 基础技术。此外，我们还识别了主要的开放挑战，例如在异构基准上的性能评估和减少元学习的计算成本。
- en: 'Keywords:'
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Meta-learning Learning to learn Few-shot learning Transfer learning Deep learning
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 元学习 学习如何学习 少样本学习 迁移学习 深度学习
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: In recent years, deep learning techniques have achieved remarkable successes
    on various tasks, including game-playing (Mnih et al., [2013](#bib.bib54); Silver
    et al., [2016](#bib.bib73)), image recognition (Krizhevsky et al., [2012](#bib.bib41);
    He et al., [2015](#bib.bib29)), machine translation (Wu et al., [2016](#bib.bib90)),
    and automatic classification in biomedical domains (Goceri, [2019a](#bib.bib19);
    Goceri and Karakas, [2020](#bib.bib22); Iqbal et al., [2020](#bib.bib36), [2019b](#bib.bib35),
    [2019a](#bib.bib34)). Despite these advances and recent solutions (Goceri, [2019b](#bib.bib20),
    [2020](#bib.bib21)), ample challenges remain to be solved, such as the large amounts
    of data and training that are needed to achieve good performance. These requirements
    severely constrain the ability of deep neural networks to learn new concepts quickly,
    one of the defining aspects of human intelligence (Jankowski et al., [2011](#bib.bib37);
    Lake et al., [2017](#bib.bib43)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度学习技术在各种任务上取得了显著成功，包括游戏（Mnih 等，[2013](#bib.bib54)；Silver 等，[2016](#bib.bib73)）、图像识别（Krizhevsky
    等，[2012](#bib.bib41)；He 等，[2015](#bib.bib29)）、机器翻译（Wu 等，[2016](#bib.bib90)）以及生物医学领域的自动分类（Goceri，[2019a](#bib.bib19)；Goceri
    和 Karakas，[2020](#bib.bib22)；Iqbal 等，[2020](#bib.bib36)，[2019b](#bib.bib35)，[2019a](#bib.bib34)）。尽管取得了这些进展和近期解决方案（Goceri，[2019b](#bib.bib20)，[2020](#bib.bib21)），但仍然存在许多挑战需要解决，例如达到良好性能所需的大量数据和训练。这些要求严重限制了深度神经网络快速学习新概念的能力，这是人类智能的一个定义特征（Jankowski
    等，[2011](#bib.bib37)；Lake 等，[2017](#bib.bib43)）。
- en: 'Meta-learning has been suggested as one strategy to overcome this challenge
    (Naik and Mammone, [1992](#bib.bib57); Schmidhuber, [1987](#bib.bib69); Thrun,
    [1998](#bib.bib79)). The key idea is that meta-learning agents improve their learning
    ability over time, or equivalently, learn to learn. The learning process is primarily
    concerned with tasks (set of observations) and takes place at two different levels:
    an inner- and an outer-level. At the inner-level, a new task is presented, and
    the agent tries to quickly learn the associated concepts from the training observations.
    This quick adaptation is facilitated by knowledge that it has accumulated across
    earlier tasks at the outer-level. Thus, whereas the inner-level concerns a single
    task, the outer-level concerns a multitude of tasks.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 元学习被提出作为克服这一挑战的策略之一（Naik 和 Mammone, [1992](#bib.bib57); Schmidhuber, [1987](#bib.bib69);
    Thrun, [1998](#bib.bib79)）。核心思想是，元学习代理在时间上提升其学习能力，或者说，学会学习。学习过程主要涉及任务（观察集），并在两个不同的层次上进行：内部层次和外部层次。在内部层次上，会呈现一个新任务，代理试图迅速从训练观察中学习相关概念。这种快速适应是通过在外部层次上积累的先前任务知识来促进的。因此，虽然内部层次涉及单个任务，但外部层次涉及多个任务。
- en: '![Refer to caption](img/ca316fbc5c2bcb1c70128f139fdef950.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ca316fbc5c2bcb1c70128f139fdef950.png)'
- en: 'Figure 1: The accuracy scores of the covered techniques on 1-shot miniImageNet
    classification. The used feature extraction backbone is displayed on the x-axis.
    As one can see, there is a strong relationship between the network complexity
    and the classification performance.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：涵盖技术在 1-shot miniImageNet 分类中的准确度分数。使用的特征提取骨干在 x 轴上显示。可以看到，网络复杂性与分类性能之间存在强关系。
- en: Historically, the term meta-learning has been used with various scopes. In its
    broadest sense, it encapsulates all systems that leverage prior learning experience
    in order to learn new tasks more quickly (Vanschoren, [2018](#bib.bib82)). This
    broad notion includes more traditional algorithm selection and hyperparameter
    optimization techniques for Machine Learning (Brazdil et al., [2008](#bib.bib8)).
    In this work, however, we focus on a subset of the meta-learning field which develops
    meta-learning procedures to learn a good inductive bias for (deep) neural networks.¹¹1Here,
    inductive bias refers to the assumptions of a model which guide predictions on
    unseen data (Mitchell, [1980](#bib.bib53)). Henceforth, we use the term Deep Meta-Learning
    to refer to this subfield of meta-learning.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 历史上，“元学习”一词在不同的范围内使用过。在最广泛的意义上，它包含了所有利用先前学习经验来更快地学习新任务的系统（Vanschoren, [2018](#bib.bib82)）。这个广泛的概念包括了传统的算法选择和机器学习（Brazdil
    et al., [2008](#bib.bib8)）的超参数优化技术。然而，在这项工作中，我们关注的是元学习领域的一个子集，该子集开发了元学习程序以为（深度）神经网络学习一个好的归纳偏差¹¹1这里，归纳偏差指的是模型对未见数据的预测所依据的假设（Mitchell,
    [1980](#bib.bib53)）。从此，我们使用“深度元学习”一词来指代元学习的这个子领域。
- en: The field of Deep Meta-Learning is advancing at a quick pace, while it lacks
    a coherent, unifying overview, providing detailed insights into the key techniques.
    Vanschoren ([2018](#bib.bib82)) has surveyed meta-learning techniques, where meta-learning
    was used in the broad sense, limiting its account of Deep Meta-Learning techniques.
    Also, many exciting developments in deep meta-learning have happened after the
    survey was published. A more recent survey by Hospedales et al. ([2020](#bib.bib32))
    adopts the same notion of deep meta-learning as we do, but aims to give a broad
    overview, omitting technical details of the various techniques.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 深度元学习领域正在快速发展，但缺乏一致的、统一的概述，提供了对关键技术的详细见解。Vanschoren ([2018](#bib.bib82)) 调查了元学习技术，其中元学习被广泛使用，限制了对深度元学习技术的描述。此外，许多令人兴奋的深度元学习发展发生在调查发布之后。Hospedales
    等人 ([2020](#bib.bib32)) 的更近期调查采用了与我们相同的深度元学习概念，但旨在提供广泛的概述，省略了各种技术的细节。
- en: We attempt to fill this gap by providing detailed explications of contemporary
    Deep Meta-Learning techniques, using a unified notation. More specifically, we
    cover modern techniques in the field for supervised and reinforcement learning,
    that have achieved state-of-the-art performance, obtained popularity in the field,
    and presented novel ideas. Extra attention is paid to MAML (Finn et al., [2017](#bib.bib14)),
    and related techniques, because of their impact on the field. We show how the
    techniques relate to each other, detail their strengths and weaknesses, identify
    current challenges, and provide an overview of promising future research directions.
    One of the observations that we make is that the network complexity is highly
    related to the few-shot classification performance (see [Figure 1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ A Survey of Deep Meta-Learning")). One might expect that
    in a few-shot setting, where only a few examples are available to learn from,
    the number of network parameters should be kept small to prevent overfitting.
    Clearly, the figure shows that this does not hold, as techniques that use larger
    backbones tend to achieve better performance. One important factor might be that
    due to the large number of tasks that have been seen by the network, we are in
    a setting where similarly large amounts of observations have been evaluated. This
    result suggests that the size of the network should be taken into account when
    comparing algorithms.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们试图通过提供对当代深度元学习技术的详细解释来填补这一空白，使用统一的符号表示法。更具体地说，我们涵盖了在监督学习和强化学习领域取得了最先进性能、获得了领域内关注并提出了新颖思想的现代技术。特别关注MAML（Finn等，[2017](#bib.bib14)）及相关技术，因为它们对该领域的影响。我们展示了这些技术之间的关系，详细说明了它们的优缺点，识别了当前的挑战，并提供了有前景的未来研究方向的概述。我们的一项观察是，网络复杂度与少样本分类性能高度相关（见[图1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ A Survey of Deep Meta-Learning")）。可以预期，在少样本设置中，由于仅有少量示例可供学习，网络参数的数量应该保持较小以防止过拟合。显然，图中显示这并不成立，因为使用较大骨干网的技术往往能取得更好的性能。一个重要因素可能是由于网络已经看到的大量任务，我们处于一个类似地评估了大量观察的设置中。这一结果表明，在比较算法时应考虑网络的大小。
- en: 'This work can serve as an educational introduction to the field of Deep Meta-Learning,
    and as reference material for experienced researchers in the field. Throughout,
    we will adopt the taxonomy used by Vinyals ([2017](#bib.bib85)), which identifies
    three categories of Deep Meta-Learning approaches: i) metric-based, ii) model-based,
    and iii) optimization-based meta-learning techniques.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作可以作为深度元学习领域的教育性介绍，并作为该领域经验丰富的研究者的参考材料。在整个过程中，我们将采用Vinyals（[2017](#bib.bib85)）使用的分类法，该分类法将深度元学习方法分为三类：i)
    基于度量的方法，ii) 基于模型的方法，和 iii) 基于优化的方法。
- en: The remainder of this work is structured as follows. Section 2 builds a common
    foundation on which we will base our overview of Deep Meta-Learning techniques.
    Sections 3, 4, and 5 cover the main metric-, model-, and optimization-based meta-learning
    techniques, respectively. Section 6 provides a helicopter view of the field and
    summarizes the key challenges and open questions. [Table 1](#S1.T1 "Table 1 ‣
    1 Introduction ‣ A Survey of Deep Meta-Learning") gives an overview of notation
    that we will use throughout this paper.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的剩余部分结构如下。第2节构建了一个共同的基础，我们将在此基础上概述深度元学习技术。第3、4和5节分别涵盖主要的度量、模型和优化基础的元学习技术。第6节提供了该领域的总体视角，总结了关键挑战和开放问题。[表1](#S1.T1
    "Table 1 ‣ 1 Introduction ‣ A Survey of Deep Meta-Learning")概述了我们将在本文中使用的符号表示法。
- en: '| Expression | Meaning |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 表达式 | 含义 |'
- en: '| Meta-learning | Learning to learn |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 元学习 | 学会学习 |'
- en: '| $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$ |
    A task consisting of a labeled support and query set |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$ |
    由标记的支持集和查询集组成的任务 |'
- en: '| Support set | The train set $D^{tr}_{\mathcal{T}_{j}}$ associated with a
    task $\mathcal{T}_{j}$ |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 支持集 | 任务$\mathcal{T}_{j}$相关的训练集$D^{tr}_{\mathcal{T}_{j}}$ |'
- en: '| Query set | The test set $D^{test}_{\mathcal{T}_{j}}$ associated with a task
    $\mathcal{T}_{j}$ |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 查询集 | 任务$\mathcal{T}_{j}$相关的测试集$D^{test}_{\mathcal{T}_{j}}$ |'
- en: '| $\boldsymbol{x}_{i}$ | Example input vector $i$ in the support set |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{x}_{i}$ | 支持集中第$i$个示例输入向量 |'
- en: '| $y_{i}$ | (One-hot encoded) label of example input $\boldsymbol{x}_{i}$ from
    the support set |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| $y_{i}$ | 支持集中示例输入$\boldsymbol{x}_{i}$的（独热编码）标签 |'
- en: '| $k$ | Number of examples per class in the support set |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| $k$ | 支持集每类的样本数量 |'
- en: '| $N$ | Number of classes in the support and query sets of a task |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| $N$ | 任务的支持集和查询集中的类别数 |'
- en: '| $\boldsymbol{x}$ | Input in the query set |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{x}$ | 查询集中的输入 |'
- en: '| $y$ | A (one-hot encoded) label for input $\boldsymbol{x}$ |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| $y$ | 输入 $\boldsymbol{x}$ 的（独热编码）标签 |'
- en: '| $(f/g/h)_{\circ}$ | Neural network function with parameters $\circ$ |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| $(f/g/h)_{\circ}$ | 带有参数 $\circ$ 的神经网络函数 |'
- en: '| Inner-level | At the level of a single task |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 内层级别 | 在单个任务的层级 |'
- en: '| Outer-level | At the meta-level: across tasks |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 外层级别 | 在元级别：跨任务 |'
- en: '| Fast weights | A term used in the literature to denote task-specific parameters
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 快速权重 | 文献中用于表示任务特定参数的术语'
- en: '| Base-learner | Learner that works at the inner-level |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 基础学习者 | 在内层级别工作的学习者 |'
- en: '| Meta-learner | Learner that operates at the outer-level |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 元学习者 | 在外层级别操作的学习者 |'
- en: '| $\boldsymbol{\theta}$ | The parameters of the base-learner network |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{\theta}$ | 基础学习网络的参数 |'
- en: '| $\mathcal{L}_{D}$ | Loss function with respect to task/dataset $D$ |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{L}_{D}$ | 关于任务/数据集 $D$ 的损失函数 |'
- en: '| Input embedding | Penultimate layer representation of the input |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 输入嵌入 | 输入的倒数第二层表示 |'
- en: '| Task embedding | An internal representation of a task in a network/system
    |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 任务嵌入 | 网络/系统中任务的内部表示 |'
- en: '| SL | Supervised Learning |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| SL | 监督学习 |'
- en: '| RL | Reinforcement Learning |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| RL | 强化学习 |'
- en: 'Table 1: Some notation and meaning, which we use throughout this paper.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：我们在本文中使用的一些符号和含义。
- en: 2 Foundation
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 基础
- en: In this section, we build the necessary foundation for investigating Deep Meta-Learning
    techniques in a consistent manner. To begin with, we contrast regular learning
    and meta-learning. Afterwards, we briefly discuss how Deep Meta-Learning relates
    to different fields, what the usual training and evaluation procedure looks like,
    and which benchmarks are often used for this purpose. We finish this section by
    describing the context and some applications of the meta-learning field.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们为以一致的方式研究深度元学习技术建立了必要的基础。首先，我们对比了常规学习和元学习。随后，我们简要讨论了深度元学习如何与不同领域相关，通常的训练和评估过程是怎样的，以及通常使用哪些基准。我们通过描述元学习领域的背景和一些应用来结束本节。
- en: 2.1 The Meta Abstraction
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 元抽象
- en: In this subsection, we contrast base-level (regular) learning and meta-learning
    for two different paradigms, i.e., supervised and reinforcement learning.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一小节中，我们对比了两种不同范式的基础级（常规）学习和元学习，即监督学习和强化学习。
- en: 2.1.1 Regular Supervised Learning
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.1 常规监督学习
- en: 'In supervised learning, we wish to learn a function $f_{\boldsymbol{\theta}}:X\rightarrow
    Y$ that learns to map inputs $\boldsymbol{x}_{i}\in X$ to their corresponding
    outputs $y_{i}\in Y$. Here, $\boldsymbol{\theta}$ are model parameters (e.g. weights
    in a neural network) that determine the function’s behavior. To learn these parameters,
    we are given a data set of $m$ observations: $D=\{(\boldsymbol{x}_{i},y_{i})\}_{i=1}^{m}$.
    Thus, given a data set $\mathcal{D}$, learning boils down to finding the correct
    setting for $\boldsymbol{\theta}$ that minimizes an empirical loss function $\mathcal{L}_{D}$,
    which must capture how the model is performing, such that appropriate adjustments
    to its parameters can be made. In short, we wish to find'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，我们希望学习一个函数 $f_{\boldsymbol{\theta}}:X\rightarrow Y$，该函数学习将输入 $\boldsymbol{x}_{i}\in
    X$ 映射到其对应的输出 $y_{i}\in Y$。这里，$\boldsymbol{\theta}$ 是决定函数行为的模型参数（例如，神经网络中的权重）。为了学习这些参数，我们提供了一个包含
    $m$ 个观测值的数据集：$D=\{(\boldsymbol{x}_{i},y_{i})\}_{i=1}^{m}$。因此，给定数据集 $\mathcal{D}$，学习的关键在于找到使经验损失函数
    $\mathcal{L}_{D}$ 最小化的正确设置，这必须捕捉模型的表现，以便对其参数进行适当的调整。简而言之，我们希望找到
- en: '|  | $\displaystyle\boldsymbol{\theta}_{SL}:=\operatorname*{arg\,min}_{\boldsymbol{\theta}}\,\mathcal{L}_{D}(\boldsymbol{\theta}),$
    |  | (1) |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\theta}_{SL}:=\operatorname*{arg\,min}_{\boldsymbol{\theta}}\,\mathcal{L}_{D}(\boldsymbol{\theta}),$
    |  | (1) |'
- en: where $SL$ stands for “supervised learning". Note that this objective is specific
    to data set $\mathcal{D}$, meaning that our model $f_{\boldsymbol{\theta}}$ may
    not generalize to examples outside of $\mathcal{D}$. To measure generalization,
    one could evaluate the performance on a separate test data set, which contains
    unseen examples. A popular way to do this is through cross-validation, where one
    repeatedly creates train and test splits $D^{tr},D^{test}\subset D$ and uses these
    to train and evaluate a model respectively (Hastie et al., [2009](#bib.bib28)).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$SL$代表“监督学习”。请注意，这个目标是特定于数据集$\mathcal{D}$的，这意味着我们的模型$f_{\boldsymbol{\theta}}$可能无法推广到$\mathcal{D}$之外的示例。为了衡量泛化能力，可以在一个包含未见示例的独立测试数据集上评估性能。一种常用的方法是通过交叉验证，在交叉验证中，一次又一次地创建训练和测试划分$D^{tr},D^{test}\subset
    D$，并分别使用这些划分来训练和评估模型（Hastie等，[2009](#bib.bib28)）。
- en: Finding globally optimal parameters $\boldsymbol{\theta}_{SL}$ is often computationally
    infeasible. We can, however, approximate them, guided by pre-defined meta-knowledge
    $\omega$ (Hospedales et al., [2020](#bib.bib32)), which includes, e.g., the initial
    model parameters $\boldsymbol{\theta}$, choice of optimizer, and learning rate
    schedule. As such, we approximate
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找全局最优参数$\boldsymbol{\theta}_{SL}$通常在计算上是不可行的。然而，我们可以在预定义的元知识$\omega$（Hospedales等，[2020](#bib.bib32)）的指导下进行近似，其中包括例如初始模型参数$\boldsymbol{\theta}$、优化器选择和学习率计划。因此，我们进行近似。
- en: '|  | $\displaystyle\boldsymbol{\theta}_{SL}\approx g_{\omega}(D,\mathcal{L}_{D}),$
    |  | (2) |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\theta}_{SL}\approx g_{\omega}(D,\mathcal{L}_{D}),$
    |  | (2) |'
- en: where $g_{\omega}$ is an optimization procedure that uses pre-defined meta-knowledge
    $\omega$, data set $\mathcal{D}$, and loss function $\mathcal{L}_{D}$, to produce
    updated weights $g_{\omega}(D,\mathcal{L}_{D})$ that (presumably) perform well
    on $\mathcal{D}$.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$g_{\omega}$是一个优化过程，使用预定义的元知识$\omega$、数据集$\mathcal{D}$和损失函数$\mathcal{L}_{D}$，来产生更新的权重$g_{\omega}(D,\mathcal{L}_{D})$，这些权重（大概）在$\mathcal{D}$上表现良好。
- en: 2.1.2 Supervised Meta-Learning
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.2 监督式元学习
- en: In contrast, supervised meta-learning does not assume that any meta-knowledge
    $\omega$ is given, or pre-defined. Instead, the goal of meta-learning is to find
    the best $\omega$, such that our (regular) base-learner can learn new tasks (data
    sets) as quickly as possible. Thus, whereas supervised regular learning involves
    one data set, supervised meta-learning involves a group of data sets. The goal
    is to learn meta-knowledge $\omega$ such that our model can learn many different
    tasks well. Thus, our model is learning to learn.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，监督式元学习并不假设任何元知识$\omega$是给定的或预定义的。相反，元学习的目标是找到最佳的$\omega$，使得我们的（常规）基础学习器可以尽可能快速地学习新任务（数据集）。因此，虽然监督式常规学习涉及一个数据集，监督式元学习则涉及一组数据集。目标是学习元知识$\omega$，使我们的模型能够很好地学习许多不同的任务。因此，我们的模型是在学习如何学习。
- en: More formally, we have a probability distribution of tasks $p(\mathcal{T})$
    and wish to find optimal meta-knowledge
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地，我们有一个任务的概率分布$p(\mathcal{T})$，并希望找到最佳的元知识
- en: '|  | $\displaystyle\omega^{*}:=\operatorname*{arg\,min}_{\omega}\,\underbrace{\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}}_{\textrm{Outer-level}}[\underbrace{\mathcal{L}_{\mathcal{T}_{j}}(g_{\omega}(\mathcal{T}_{j},\mathcal{L}_{\mathcal{T}_{j}}))}_{\textrm{Inner-level}}].$
    |  | (3) |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\omega^{*}:=\operatorname*{arg\,min}_{\omega}\,\underbrace{\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}}_{\textrm{外部层级}}[\underbrace{\mathcal{L}_{\mathcal{T}_{j}}(g_{\omega}(\mathcal{T}_{j},\mathcal{L}_{\mathcal{T}_{j}}))}_{\textrm{内部层级}}].$
    |  | (3) |'
- en: 'Here, the inner-level concerns task-specific learning, while the outer-level
    concerns multiple tasks. One can now easily see why this is meta-learning: we
    learn $\omega$, which allows for quick learning of tasks $\mathcal{T}_{j}$ at
    the inner-level. Hence, we are learning to learn.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，内部层级关注特定任务的学习，而外部层级关注多个任务。现在可以很容易看出这就是元学习的原因：我们学习$\omega$，它使得在内部层级上能够快速学习任务$\mathcal{T}_{j}$。因此，我们正在学习如何学习。
- en: 2.1.3 Regular Reinforcement Learning
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.3 正则化强化学习
- en: In reinforcement learning, we have an agent that learns from experience. That
    is, it interacts with an environment, modeled by a Markov Decision Process (MDP)
    $M=(S,A,P,r,p_{0},\gamma,T)$. Here, $S$ is the set of states, $A$ the set of actions,
    $P$ the transition probability distribution defining $P(s_{t+1}|s_{t},a_{t})$,
    $r:S\times A\rightarrow\mathbb{R}$ the reward function, $p_{0}$ the probability
    distribution over initial states, $\gamma\in[0,1]$ the discount factor, and $T$
    the time horizon (maximum number of time steps) (Sutton and Barto, [2018](#bib.bib77);
    Duan et al., [2016](#bib.bib11)).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习中，我们有一个从经验中学习的智能体。即，它与环境互动，该环境由马尔可夫决策过程（MDP）$M=(S,A,P,r,p_{0},\gamma,T)$建模。在这里，$S$是状态集合，$A$是动作集合，$P$是定义$P(s_{t+1}|s_{t},a_{t})$的转移概率分布，$r:S\times
    A\rightarrow\mathbb{R}$是奖励函数，$p_{0}$是初始状态的概率分布，$\gamma\in[0,1]$是折扣因子，$T$是时间范围（最大时间步数）（Sutton和Barto，[2018](#bib.bib77)；Duan等，[2016](#bib.bib11)）。
- en: At every time step $t$, the agent finds itself in state $s_{t}$, in which the
    agent performs an action $a_{t}$, computed by a policy function $\pi_{\boldsymbol{\theta}}$
    (i.e., $a_{t}=\pi_{\boldsymbol{\theta}}(s_{t})$), which is parameterized by weights
    $\boldsymbol{\theta}$. In turn, it receives a reward $r_{t}=r(s_{t},\pi_{\boldsymbol{\theta}}(s_{t}))\in\mathbb{R}$
    and a new state $s_{t+1}$. This process of interactions continues until a termination
    criterion is met (e.g. fixed time horizon $T$ reached). The goal of the agent
    is to learn how to act in order to maximize its expected reward. The reinforcement
    learning (RL) goal is to find
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时间步$t$，智能体发现自己处于状态$s_{t}$，此时智能体执行动作$a_{t}$，由策略函数$\pi_{\boldsymbol{\theta}}$计算（即$a_{t}=\pi_{\boldsymbol{\theta}}(s_{t})$），该函数由权重$\boldsymbol{\theta}$参数化。接着，它获得奖励$r_{t}=r(s_{t},\pi_{\boldsymbol{\theta}}(s_{t}))\in\mathbb{R}$和新状态$s_{t+1}$。这种交互过程继续，直到满足终止标准（例如，达到固定的时间范围$T$）。智能体的目标是学习如何行动，以最大化其期望奖励。强化学习（RL）的目标是找到
- en: '|  | $\displaystyle\boldsymbol{\theta}_{RL}:=\operatorname*{arg\,min}_{\boldsymbol{\theta}}\,\mathbb{E}_{\mbox{traj}}\sum_{t=0}^{T}\gamma^{t}r(s_{t},\pi_{\boldsymbol{\theta}}(s_{t})),$
    |  | (4) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\theta}_{RL}:=\operatorname*{arg\,min}_{\boldsymbol{\theta}}\,\mathbb{E}_{\mbox{traj}}\sum_{t=0}^{T}\gamma^{t}r(s_{t},\pi_{\boldsymbol{\theta}}(s_{t})),$
    |  | (4) |'
- en: where we take the expectation over the possible trajectories $\mbox{traj}=(s_{0},\pi_{\boldsymbol{\theta}}(s_{0}),\allowbreak\ldots
    s_{T},\pi_{\boldsymbol{\theta}}(s_{T}))$ due to the random nature of MDPs (Duan
    et al., [2016](#bib.bib11)). Note that $\gamma$ is a hyperparameter that can prioritize
    short- or long-term rewards by decreasing or increasing it, respectively.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在此我们对可能的轨迹$\mbox{traj}=(s_{0},\pi_{\boldsymbol{\theta}}(s_{0}),\allowbreak\ldots
    s_{T},\pi_{\boldsymbol{\theta}}(s_{T}))$进行期望计算，原因是MDP的随机性质（Duan等， [2016](#bib.bib11)）。注意，$\gamma$是一个超参数，通过降低或增加它，可以优先考虑短期或长期奖励。
- en: Also in the case of reinforcement learning it is often infeasible to find the
    global optimum $\boldsymbol{\theta}_{RL}$, and thus we settle for approximations.
    In short, given a learning method $\omega$, we approximate
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习的情况下，通常很难找到全局最优解$\boldsymbol{\theta}_{RL}$，因此我们只能满足于近似解。简而言之，给定学习方法$\omega$，我们近似
- en: '|  | $\displaystyle\boldsymbol{\theta}_{RL}\approx g_{\omega}(\mathcal{T}_{j},\mathcal{L}_{\mathcal{T}_{j}}),$
    |  | (5) |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\theta}_{RL}\approx g_{\omega}(\mathcal{T}_{j},\mathcal{L}_{\mathcal{T}_{j}}),$
    |  | (5) |'
- en: where again $\mathcal{T}_{j}$ is the given MDP, and $g_{\omega}$ is the optimization
    algorithm, guided by pre-defined meta-knowledge $\omega$.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，$\mathcal{T}_{j}$是给定的MDP，而$g_{\omega}$是优化算法，由预定义的元知识$\omega$指导。
- en: Note that in a Markov Decision Process (MDP), the agent knows the state at any
    given time step $t$. When this is not the case, it becomes a Partially Observable
    Markov Decision Process (POMDP), where the agent receives only observations $O$,
    and uses these to update its belief with regard to the state it is in (Sutton
    and Barto, [2018](#bib.bib77)).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在马尔可夫决策过程（MDP）中，智能体知道在任何给定时间步$t$的状态。当情况不是这样时，它就变成了部分可观测马尔可夫决策过程（POMDP），其中智能体仅接收观察$O$，并利用这些观察来更新其关于所处状态的信念（Sutton和Barto，[2018](#bib.bib77)）。
- en: 2.1.4 Meta Reinforcement Learning
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.4 元强化学习
- en: The meta abstraction has as its object a group of tasks, or Markov Decision
    Processes (MDPs) in the case of reinforcement learning. Thus, instead of maximizing
    the expected reward on a single MDP, the meta reinforcement learning objective
    is to maximize the expected reward over various MDPs, by learning meta-knowledge
    $\omega$. Here, the MDPs are sampled from some distribution $p(\mathcal{T})$.
    So, we wish to find a set of parameters
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 元抽象的对象是一组任务，或者在强化学习的情况下，是马尔可夫决策过程（MDPs）。因此，元强化学习的目标是通过学习元知识**$\omega$**，在多个MDP上最大化期望奖励，而不是在单一MDP上最大化期望奖励。在这里，MDPs是从某个分布$p(\mathcal{T})$中采样的。因此，我们希望找到一组参数
- en: '|  | $\displaystyle\boldsymbol{\omega}^{*}:=\operatorname*{arg\,min}_{\boldsymbol{\omega}}\,\underbrace{\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}}_{\textrm{Outer-level}}\left[\underbrace{\mathbb{E}_{traj}\sum_{t=0}^{T}\gamma^{t}r(s_{t},\pi_{g_{\omega}(\mathcal{T}_{j},\mathcal{L}_{\mathcal{T}_{j}})}(s_{t}))}_{\textrm{Inner-level}}\right].$
    |  | (6) |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\omega}^{*}:=\operatorname*{arg\,min}_{\boldsymbol{\omega}}\,\underbrace{\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}}_{\textrm{外层}}\left[\underbrace{\mathbb{E}_{traj}\sum_{t=0}^{T}\gamma^{t}r(s_{t},\pi_{g_{\omega}(\mathcal{T}_{j},\mathcal{L}_{\mathcal{T}_{j}})}(s_{t}))}_{\textrm{内层}}\right].$
    |  | (6) |'
- en: 2.1.5 Contrast with other Fields
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.5 与其他领域的对比
- en: Now that we have provided a formal basis for our discussion for both supervised
    and reinforcement meta-learning, it is time to contrast meta-learning briefly
    with two related areas of machine learning that also have the goal to improve
    the speed of learning. We will start with transfer learning.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为监督学习和强化学习的元学习提供了正式的基础，是时候简要地将元学习与两个相关的机器学习领域进行对比，这些领域也旨在提高学习速度。我们将从迁移学习开始。
- en: Transfer Learning In Transfer Learning, one tries to transfer knowledge of previous
    tasks to new, unseen tasks (Pan and Yang, [2009](#bib.bib61); Taylor and Stone,
    [2009](#bib.bib78)), which can be challenging when the new task comes from a different
    distribution than the one used for training Iqbal et al. ([2018](#bib.bib33)).
    The distinction between Transfer Learning and Meta-Learning has become more opaque
    over time. A key property of meta-learning techniques, however, is their meta-objective,
    which explicitly aims to optimize performance across a distribution over tasks
    (as seen in previous sections by taking the expected loss over a distribution
    of tasks). This objective need not always be present in Transfer Learning techniques,
    e.g., when one pre-trains a model on a large data set, and fine-tunes the learned
    weights on a smaller data set.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习 在迁移学习中，人们尝试将以前任务的知识转移到新的、未见过的任务中（Pan and Yang, [2009](#bib.bib61); Taylor
    and Stone, [2009](#bib.bib78)），当新任务来自不同于训练所用分布时，这可能会很具挑战性（Iqbal et al., [2018](#bib.bib33)）。然而，迁移学习与元学习之间的区别随着时间的推移变得更加模糊。元学习技术的一个关键特性是它们的元目标，明确旨在优化在任务分布上的表现（如在前面章节中通过在任务分布上的期望损失来实现）。这一目标不一定总是存在于迁移学习技术中，例如，当一个模型在大数据集上预训练，然后在较小的数据集上微调学到的权重时。
- en: Multi-task learning Another, closely related field, is that of multi-task learning.
    In multi-task learning, a model is jointly trained to perform well on multiple
    fixed tasks (Hospedales et al., [2020](#bib.bib32)). Meta-learning, in contrast,
    aims to find a model that can learn new (previously unseen) tasks quickly. This
    difference is illustrated in [footnote 2](#footnote2 "footnote 2 ‣ Figure 2 ‣
    2.1.5 Contrast with other Fields ‣ 2.1 The Meta Abstraction ‣ 2 Foundation ‣ A
    Survey of Deep Meta-Learning").
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务学习 另一个密切相关的领域是多任务学习。在多任务学习中，一个模型被联合训练，以在多个固定任务上表现良好（Hospedales et al., [2020](#bib.bib32)）。相比之下，元学习旨在找到一个能够快速学习新（先前未见）任务的模型。这一差异在
    [脚注 2](#footnote2 "脚注 2 ‣ 图 2 ‣ 2.1.5 与其他领域的对比 ‣ 2.1 元抽象 ‣ 2 基础 ‣ 深度元学习综述") 中有所说明。
- en: '![Refer to caption](img/4568d4795fab33dad1833f70976aac19.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4568d4795fab33dad1833f70976aac19.png)'
- en: 'Figure 2: The difference between multi-task learning and meta-learning²²2Adapted
    from [https://meta-world.github.io/](https://meta-world.github.io/).'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：多任务学习与元学习的区别²²2改编自 [https://meta-world.github.io/](https://meta-world.github.io/)。
- en: 2.2 The Meta-Setup
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 元设置
- en: 'In the previous section, we have described the learning objectives for (meta)
    supervised and reinforcement learning. We will now describe the general setting
    that can be used to achieve these objectives. In general, one optimizes a meta-objective
    by using various tasks, which are data sets in the context of supervised learning,
    and (Partially Observable) Markov Decision Processes in the case of reinforcement
    learning. This is done in three stages: the i) meta-train stage, ii) meta-validation
    stage, and iii) meta-test stage, each of which is associated with a set of tasks.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们描述了（元）监督学习和强化学习的学习目标。现在我们将描述可以用来实现这些目标的一般设置。一般而言，人们通过使用各种任务来优化一个元目标，这些任务在监督学习的背景下是数据集，而在强化学习的情况下则是（部分可观察的）马尔可夫决策过程。这分为三个阶段进行：i)
    元训练阶段，ii) 元验证阶段，iii) 元测试阶段，每个阶段都与一组任务相关联。
- en: First, in the meta-train stage, the meta-learning algorithm is applied to the
    meta-train tasks. Second, the meta-validation tasks can then be used to evaluate
    the performance on unseen tasks, which were not used for training. Effectively,
    this measures the meta-generalization ability of the trained network, which serves
    as feedback to tune, e.g., hyper-parameters of the meta-learning algorithm. Third,
    the meta-test tasks are used to give a final performance estimate of the meta-learning
    technique.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在元训练阶段，元学习算法应用于元训练任务。其次，元验证任务可以用来评估在未见任务上的表现，这些任务未用于训练。有效地，这衡量了训练网络的元泛化能力，并作为反馈来调整，例如，元学习算法的超参数。第三，元测试任务用于给出元学习技术的最终性能估计。
- en: '![Refer to caption](img/ae59762e05066ec6a749fbe7d1395145.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ae59762e05066ec6a749fbe7d1395145.png)'
- en: 'Figure 3: Illustration of $N$-way, $k$-shot classification, where $N=5$, and
    $k=1$. Meta-validation tasks are not displayed. Adapted from Ravi and Larochelle
    ([2017](#bib.bib65)).'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：$N$-way、$k$-shot 分类的示意图，其中 $N=5$，$k=1$。未显示元验证任务。改编自 Ravi 和 Larochelle ([2017](#bib.bib65))。
- en: 2.2.1 $N$-way, $k$-shot Learning
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1 $N$-way、$k$-shot 学习
- en: A frequently used instantiation of this general meta-setup is called $N$-way,
    $k$-shot classification (see [Figure 3](#S2.F3 "Figure 3 ‣ 2.2 The Meta-Setup
    ‣ 2 Foundation ‣ A Survey of Deep Meta-Learning")). This setup is also divided
    into the three stages—meta-train, meta-validation, and meta-test—which are used
    for meta-learning, meta-learner hyperparameter optimization, and evaluation, respectively.
    Each stage has a corresponding set of disjoint labels, i.e., $L^{tr},L^{val},L^{test}\subset
    Y$, such that $L^{tr}\cap L^{val}=\emptyset,L^{tr}\cap L^{test}=\emptyset$, and
    $L^{val}\cap L^{test}=\emptyset$. In a given stage $s$, tasks/episodes $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$
    are obtained by sampling examples $(\boldsymbol{x}_{i},y_{i})$ from the full data
    set $\mathcal{D}$, such that every $y_{i}\in L^{s}$. Note that this requires access
    to a data set $\mathcal{D}$. The sampling process is guided by the $N$-way, $k$-shot
    principle, which states that every training data set $D^{tr}_{\mathcal{T}_{j}}$
    should contain exactly $N$ classes and $k$ examples per class, implying that $|D^{tr}_{\mathcal{T}_{j}}|=N\cdot
    k$. Furthermore, the true labels of examples in the test set $D_{\mathcal{T}_{j}}^{test}$
    must be present in the train set $D^{tr}_{\mathcal{T}_{j}}$ of a given task $\mathcal{T}_{j}$.
    $D^{tr}_{\mathcal{T}{j}}$ acts as a support set, literally supporting classification
    decisions on the query set $D^{test}_{\mathcal{T}_{j}}$. Importantly, note that
    with this terminology, the query set (or test set) of a task is actually used
    during the meta-training phase. Furthermore, the fact that the labels across stages
    are disjoint ensures that we test the ability of a model to learn new concepts.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常用的这种通用元设置的实例被称为 $N$-way, $k$-shot 分类（见 [图 3](#S2.F3 "Figure 3 ‣ 2.2 The Meta-Setup
    ‣ 2 Foundation ‣ A Survey of Deep Meta-Learning")）。该设置也分为三个阶段——元训练、元验证和元测试，分别用于元学习、元学习器超参数优化和评估。每个阶段都有一组对应的互不重叠的标签，即
    $L^{tr},L^{val},L^{test}\subset Y$，使得 $L^{tr}\cap L^{val}=\emptyset,L^{tr}\cap
    L^{test}=\emptyset$ 和 $L^{val}\cap L^{test}=\emptyset$。在给定的阶段 $s$ 中，通过从完整数据集 $\mathcal{D}$
    中抽样例 $(\boldsymbol{x}_{i},y_{i})$ 得到任务/剧集 $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$，使得每个
    $y_{i}\in L^{s}$。请注意，这需要访问数据集 $\mathcal{D}$。抽样过程由 $N$-way, $k$-shot 原则指导，该原则规定每个训练数据集
    $D^{tr}_{\mathcal{T}_{j}}$ 应包含恰好 $N$ 类和每类 $k$ 个示例，这意味着 $|D^{tr}_{\mathcal{T}_{j}}|=N\cdot
    k$。此外，测试集 $D_{\mathcal{T}_{j}}^{test}$ 中示例的真实标签必须存在于给定任务 $\mathcal{T}_{j}$ 的训练集
    $D^{tr}_{\mathcal{T}_{j}}$ 中。$D^{tr}_{\mathcal{T}_{j}}$ 充当支持集，实际上支持对查询集 $D^{test}_{\mathcal{T}_{j}}$
    的分类决策。重要的是，要注意根据这一术语，任务的查询集（或测试集）实际上在元训练阶段被使用。此外，各阶段标签的互不重叠确保了我们测试模型学习新概念的能力。
- en: The meta-learning objective in the training phase is to minimize the loss function
    of the model predictions on the query sets, conditioned on the support sets. As
    such, for a given task $\mathcal{T}_{j}$, the model ‘sees’ the support set, and
    extracts information from the support set to guide its predictions on the query
    set. By applying this procedure to different episodes/tasks $\mathcal{T}_{j}$,
    the model will slowly accumulate meta-knowledge $\omega$, which can ultimately
    speed up learning on new tasks.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 训练阶段的元学习目标是最小化模型在查询集上的预测损失函数，条件是支持集的存在。因此，对于给定任务 $\mathcal{T}_{j}$，模型“看到”支持集，并从支持集中提取信息以指导其对查询集的预测。通过将这一过程应用于不同的剧集/任务
    $\mathcal{T}_{j}$，模型将慢慢积累元知识 $\omega$，这可以*最终*加速对新任务的学习。
- en: The easiest way to achieve this is by doing this with regular neural networks,
    but as was pointed out by various authors (see, e.g., Finn et al. ([2017](#bib.bib14)))
    more sophisticated architectures will vastly outperform such networks. In the
    remainder of this work, we will review such architectures.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这一点的最简单方法是使用常规神经网络，但正如各种作者所指出的（见例如 Finn 等人 ([2017](#bib.bib14))），更复杂的架构将远远优于这种网络。在本文的其余部分，我们将回顾这些架构。
- en: At the meta-validation and meta-test stages, or evaluation phases, the learned
    meta-information in $\omega$ is fixed. The model is, however, still allowed to
    make task-specific updates to its parameters $\boldsymbol{\theta}$ (which implies
    that it is learning). After task-specific updates, we can evaluate the performance
    on the test sets. In this way, we test how well a technique performs at meta-learning.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在元验证和元测试阶段，或评估阶段，学习到的元信息 $\omega$ 是固定的。然而，模型仍然允许对其参数 $\boldsymbol{\theta}$ 进行特定任务的更新（这意味着它在学习）。在任务特定更新之后，我们可以评估在测试集上的性能。通过这种方式，我们测试技术在元学习中的表现如何。
- en: $N$-way, $k$-shot classification is often performed for small values of $k$
    (since we want our models to learn new concepts quickly, i.e., from few examples).
    In that case, one can refer to it as few-shot learning.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: $N$-way, $k$-shot 分类通常在 $k$ 的小值下进行（因为我们希望模型能够快速学习新概念，即从少量示例中学习）。在这种情况下，可以称之为小样本学习。
- en: 2.2.2 Common Benchmarks
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2 常见基准
- en: Here, we briefly describe some benchmarks that can be used to evaluate meta-learning
    algorithms.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们简要描述了一些可以用于评估元学习算法的基准。
- en: •
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Omniglot (Lake et al., [2011](#bib.bib42)): This data set presents an image
    recognition task. Each image corresponds to one out of 1 623 characters from 50
    different alphabets. Every character was drawn by 20 people. Note that in this
    case, the characters are the classes/labels.'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Omniglot (Lake et al., [2011](#bib.bib42))：该数据集提供了一个图像识别任务。每张图像对应于 50 种不同字母表中的
    1 623 个字符中的一个。每个字符由 20 个人绘制。注意，在这种情况下，字符即为类别/标签。
- en: •
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'ImageNet (Deng et al., [2009](#bib.bib10)): This is the largest image classification
    data set, containing more than 20K classes and over 14 million colored images.
    miniImageNet is a mini variant of the large ImageNet data set (Deng et al., [2009](#bib.bib10))
    for image classification, proposed by Vinyals et al. ([2016](#bib.bib86)) to reduce
    the engineering efforts to run experiments. The mini data set contains 60 000
    colored images of size $84\times 84$. There are a total of 100 classes present,
    each accorded by 600 examples. tieredImageNet (Ren et al., [2018](#bib.bib66))
    is another variation of the large ImageNet data set. It is similar to miniImageNet,
    but contains a hierarchical structure. That is, there are 34 classes, each with
    its own sub-classes.'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ImageNet (Deng et al., [2009](#bib.bib10))：这是最大的图像分类数据集，包含超过 20K 个类别和超过 1,400
    万张彩色图像。miniImageNet 是大规模 ImageNet 数据集 (Deng et al., [2009](#bib.bib10)) 的一个迷你变体，由
    Vinyals et al. ([2016](#bib.bib86)) 提出，用于减少实验的工程工作量。这个迷你数据集包含 60 000 张大小为 $84\times
    84$ 的彩色图像。总共有 100 个类别，每个类别有 600 个样本。tieredImageNet (Ren et al., [2018](#bib.bib66))
    是大规模 ImageNet 数据集的另一个变体。它类似于 miniImageNet，但包含层次结构。也就是说，共有 34 个类别，每个类别都有自己的子类别。
- en: •
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'CIFAR-10 and CIFAR-100 (Krizhevsky, [2009](#bib.bib40)): Two other image recognition
    data sets. Each one contains 60K RGB images of size $32\times 32$. CIFAR-10 and
    CIFAR-100 contain 10 and 100 classes respectively, with a uniform number of examples
    per class (6 000 and 600 respectively). Every class in CIFAR-100 also has a super-class,
    of which there are 20 in the full data set. Many variants of the CIFAR data sets
    can be sampled, giving rise to e.g. CIFAR-FS (Bertinetto et al., [2019](#bib.bib7))
    and FC-100 (Oreshkin et al., [2018](#bib.bib60)).'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CIFAR-10 和 CIFAR-100 (Krizhevsky, [2009](#bib.bib40))：另外两个图像识别数据集。每个数据集包含 60K
    张大小为 $32\times 32$ 的 RGB 图像。CIFAR-10 和 CIFAR-100 分别包含 10 类和 100 类，每类的样本数量均匀（分别为
    6 000 和 600）。CIFAR-100 中的每个类别也有一个超级类别，整个数据集中共有 20 个超级类别。CIFAR 数据集的许多变体可以被采样，例如
    CIFAR-FS (Bertinetto et al., [2019](#bib.bib7)) 和 FC-100 (Oreshkin et al., [2018](#bib.bib60))。
- en: •
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'CUB-200-2011 (Wah et al., [2011](#bib.bib88)): The CUB-200-2011 data set contains
    roughly 12K RGB images of birds from 200 species. Every image has some labeled
    attributes (e.g. crown color, tail shape).'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CUB-200-2011 (Wah et al., [2011](#bib.bib88))：CUB-200-2011 数据集包含大约 12K 张来自 200
    个物种的鸟类 RGB 图像。每张图像都有一些标注的属性（例如：头冠颜色、尾巴形状）。
- en: •
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'MNIST (LeCun et al., [2010](#bib.bib44)): MNIST presents a hand-written digit
    recognition task, containing ten classes (for digits 0 through 9). In total, the
    data set is split into a 60K train and 10K test gray scale images of hand-written
    digits.'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MNIST (LeCun et al., [2010](#bib.bib44))：MNIST 提供了一个手写数字识别任务，包含十个类别（0 到 9 的数字）。总的来说，数据集被分为
    60K 张训练图像和 10K 张测试图像，这些图像都是手写数字的灰度图像。
- en: •
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Meta-Dataset (Triantafillou et al., [2020](#bib.bib81)): This data set comprises
    several other data sets such as Omniglot (Lake et al., [2011](#bib.bib42)), CUB-200
    (Wah et al., [2011](#bib.bib88)), ImageNet (Deng et al., [2009](#bib.bib10)),
    and more (Triantafillou et al., [2020](#bib.bib81)). An episode is then constructed
    by sampling a data set (e.g. Omniglot) and selecting a subset of labels to create
    train and test splits as before. In this way, broader generalization is enforced
    since the tasks are more distant from each other.'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Meta-Dataset (Triantafillou et al., [2020](#bib.bib81))：该数据集包含了多个其他数据集，例如 Omniglot
    (Lake et al., [2011](#bib.bib42))、CUB-200 (Wah et al., [2011](#bib.bib88))、ImageNet
    (Deng et al., [2009](#bib.bib10)) 等 (Triantafillou et al., [2020](#bib.bib81))。然后通过采样一个数据集（例如
    Omniglot）并选择一个标签子集来构建一个实验，创建训练和测试分割。通过这种方式，强制执行更广泛的泛化，因为任务彼此之间距离较远。
- en: •
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Meta-world (Yu et al., [2019](#bib.bib94)): A meta reinforcement learning data
    set, containing 50 robotic manipulation tasks (control a robot arm to achieve
    some pre-defined goal, e.g. unlocking a door, or playing soccer). It was specifically
    designed to cover a broad range of tasks, such that meaningful generalization
    can be measured (Yu et al., [2019](#bib.bib94)).'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Meta-world（Yu et al., [2019](#bib.bib94)）：一个元强化学习数据集，包含50个机器人操作任务（控制机器人手臂完成某些预定义目标，例如开门或踢足球）。它被特别设计来涵盖广泛的任务，以便能够测量有意义的泛化（Yu
    et al., [2019](#bib.bib94)）。
- en: '![Refer to caption](img/eaaece9b5514435edc56d41a28809dc2.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/eaaece9b5514435edc56d41a28809dc2.png)'
- en: 'Figure 4: Learning continuous robotic control tasks is an important application
    of Deep Meta-Learning techniques. Image taken from (Yu et al., [2019](#bib.bib94)).'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：学习连续的机器人控制任务是深度元学习技术的重要应用。图片取自（Yu et al., [2019](#bib.bib94)）。
- en: 2.2.3 Some Applications of Meta-Learning
  id: totrans-113
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.3 元学习的一些应用
- en: Deep neural networks have achieved remarkable results on various tasks including
    image recognition, text processing, game playing, and robotics (Silver et al.,
    [2016](#bib.bib73); Mnih et al., [2013](#bib.bib54); Wu et al., [2016](#bib.bib90)),
    but their success depends on the amount of available data (Sun et al., [2017](#bib.bib75))
    and computing resources. Deep meta-learning reduces this dependency by allowing
    deep neural networks to learn new concepts quickly. As a result, meta-learning
    widens the applicability of deep learning techniques to many application domains.
    Such areas include few-shot image classification (Finn et al., [2017](#bib.bib14);
    Snell et al., [2017](#bib.bib74); Ravi and Larochelle, [2017](#bib.bib65)), robotic
    control policy learning (Gupta et al., [2018](#bib.bib25); Nagabandi et al., [2019](#bib.bib56))
    (see [Figure 4](#S2.F4 "Figure 4 ‣ 2.2.2 Common Benchmarks ‣ 2.2 The Meta-Setup
    ‣ 2 Foundation ‣ A Survey of Deep Meta-Learning")), hyperparameter optimization
    (Antoniou et al., [2019](#bib.bib3); Schmidhuber et al., [1997](#bib.bib71)),
    meta-learning learning rules (Bengio et al., [1991](#bib.bib6), [1997](#bib.bib5);
    Miconi et al., [2018](#bib.bib50), [2019](#bib.bib51)), abstract reasoning (Barrett
    et al., [2018](#bib.bib4)), and many more. For a larger overview of applications,
    we refer interested readers to Hospedales et al. ([2020](#bib.bib32)).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络在图像识别、文本处理、游戏玩法和机器人技术等各种任务上取得了显著成果（Silver et al., [2016](#bib.bib73);
    Mnih et al., [2013](#bib.bib54); Wu et al., [2016](#bib.bib90)），但它们的成功依赖于可用数据量（Sun
    et al., [2017](#bib.bib75)）和计算资源。深度元学习通过使深度神经网络能够快速学习新概念，从而减少了这种依赖。因此，元学习扩大了深度学习技术在许多应用领域的适用性。这些领域包括少样本图像分类（Finn
    et al., [2017](#bib.bib14); Snell et al., [2017](#bib.bib74); Ravi and Larochelle,
    [2017](#bib.bib65)）、机器人控制策略学习（Gupta et al., [2018](#bib.bib25); Nagabandi et al.,
    [2019](#bib.bib56)）（见[图 4](#S2.F4 "图 4 ‣ 2.2.2 常见基准 ‣ 2.2 元设置 ‣ 2 基础 ‣ 深度元学习调查")）、超参数优化（Antoniou
    et al., [2019](#bib.bib3); Schmidhuber et al., [1997](#bib.bib71)）、元学习学习规则（Bengio
    et al., [1991](#bib.bib6), [1997](#bib.bib5); Miconi et al., [2018](#bib.bib50),
    [2019](#bib.bib51)）、抽象推理（Barrett et al., [2018](#bib.bib4)）等。有关更多应用的概述，我们建议感兴趣的读者参考
    Hospedales et al.（[2020](#bib.bib32)）。
- en: 2.3 The Meta-Learning Field
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 元学习领域
- en: 'As mentioned in the introduction, meta-learning is a broad area of research,
    as it encapsulates all techniques that leverage prior learning experience to learn
    new tasks more quickly (Vanschoren, [2018](#bib.bib82)). We can classify two distinct
    communities in the field with a different focus: i) algorithm selection and hyperparameter
    optimization for machine learning techniques, and ii) search for inductive bias
    in deep neural networks. We will refer to these communities as group i) and group
    ii) respectively. Now, we will give a brief description of the first field, and
    a historical overview of the second.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如引言中所提到的，元学习是一个广泛的研究领域，因为它包含了所有利用先前学习经验来更快地学习新任务的技术（Vanschoren, [2018](#bib.bib82)）。我们可以在这一领域中分类两个不同的群体，其关注点不同：i)
    机器学习技术的算法选择和超参数优化，ii) 深度神经网络中的归纳偏置搜索。我们将这两个群体分别称为群体 i) 和群体 ii)。现在，我们将简要描述第一个领域，并对第二个领域进行历史概述。
- en: Group i) uses a more traditional approach, to select a suitable machine learning
    algorithm and hyperparameters for a new data set $\mathcal{D}$ (Peng et al., [2002](#bib.bib62)).
    This selection can for example be made by leveraging prior model evaluations on
    various data sets $D^{\prime}$, and by using the model which achieved the best
    performance on the most similar data set (Vanschoren, [2018](#bib.bib82)). Such
    traditional approaches require (large) databases of prior model evaluations, for
    many different algorithms. This has led to initiatives such as OpenML (Vanschoren
    et al., [2014](#bib.bib83)), where researchers can share such information. The
    usage of these systems would limit the freedom in picking the neural network architecture
    as they would be constrained to using architectures that have been evaluated beforehand.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 组 i) 使用了更传统的方法来为新的数据集 $\mathcal{D}$ 选择合适的机器学习算法和超参数 (Peng et al., [2002](#bib.bib62))。例如，这种选择可以通过利用在不同数据集
    $D^{\prime}$ 上的先前模型评估来完成，并使用在最相似的数据集上表现最佳的模型 (Vanschoren, [2018](#bib.bib82))。这种传统方法需要（大规模）先前模型评估数据库，涵盖许多不同的算法。这导致了如
    OpenML (Vanschoren et al., [2014](#bib.bib83)) 等举措，研究人员可以共享这些信息。这些系统的使用将限制选择神经网络架构的自由，因为它们将被约束于使用已被预先评估的架构。
- en: In contrast, group ii) adopts the view of a self-improving (neural) agent, which
    improves its learning ability over time by finding a good inductive bias (a set
    of assumptions that guide predictions). We now present a brief historical overview
    of developments in this field of Deep Meta-Learning, based on Hospedales et al.
    ([2020](#bib.bib32)).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，组 ii) 采用了自我改进（神经）代理的观点，这种代理通过寻找合适的归纳偏置（指导预测的假设集合）来随着时间的推移提高其学习能力。我们现在基于
    Hospedales 等人的工作 ([2020](#bib.bib32))，简要介绍深度元学习领域的发展历史。
- en: Pioneering work was done by Schmidhuber ([1987](#bib.bib69)) and Hinton and
    Plaut ([1987](#bib.bib30)). Schmidhuber developed a theory of self-referential
    learning, where the weights of a neural network can serve as input to the model
    itself, which then predicts updates (Schmidhuber, [1987](#bib.bib69), [1993](#bib.bib70)).
    In that same year, Hinton and Plaut ([1987](#bib.bib30)) proposed to use two weights
    per neural network connection, i.e., slow and fast weights, which serve as long-
    and short-term memory respectively. Later came the idea of meta-learning learning
    rules (Bengio et al., [1991](#bib.bib6), [1997](#bib.bib5)). Meta-learning techniques
    that use gradient-descent and backpropagation were proposed by Hochreiter et al.
    ([2001](#bib.bib31)) and Younger et al. ([2001](#bib.bib93)). These two works
    have been pivotal to the current field of Deep Meta-Learning, as the majority
    of techniques rely on backpropagation, as we will see on our journey of contemporary
    Deep Meta-Learning techniques.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 开创性的工作由 Schmidhuber ([1987](#bib.bib69)) 和 Hinton 与 Plaut ([1987](#bib.bib30))
    完成。Schmidhuber 发展了自我参考学习理论，其中神经网络的权重可以作为模型自身的输入，然后预测更新 (Schmidhuber, [1987](#bib.bib69),
    [1993](#bib.bib70))。同年，Hinton 和 Plaut ([1987](#bib.bib30)) 提出了对每个神经网络连接使用两个权重，即慢权重和快权重，分别用于长期和短期记忆。随后提出了元学习规则的概念
    (Bengio et al., [1991](#bib.bib6), [1997](#bib.bib5))。Hochreiter et al. ([2001](#bib.bib31))
    和 Younger et al. ([2001](#bib.bib93)) 提出了使用梯度下降和反向传播的元学习技术。这两个工作对当前深度元学习领域至关重要，因为大多数技术依赖于反向传播，正如我们在现代深度元学习技术的探索中将看到的那样。
- en: 2.4 Overview of the rest of this Work
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 本工作其余部分的概述
- en: In the remainder of this work, we will look in more detail at individual meta-learning
    methods. As indicated before, the techniques can be grouped into three main categories
    (Vinyals, [2017](#bib.bib85)), namely i) metric-, ii) model-, and iii) optimization-based
    methods. We will discuss them in that order.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在本工作的其余部分，我们将更详细地研究个别的元学习方法。如前所述，这些技术可以分为三大类 (Vinyals, [2017](#bib.bib85))，即
    i)  基于度量的方法，ii) 基于模型的方法，以及 iii) 基于优化的方法。我们将按此顺序讨论这些方法。
- en: To help give an overview of the methods, we draw your attention to the following
    tables. [Table 2](#S2.T2 "Table 2 ‣ 2.4 Overview of the rest of this Work ‣ 2
    Foundation ‣ A Survey of Deep Meta-Learning") summarizes the three categories
    and provides key ideas, and strengths of the approaches. The terms and technical
    details are explained more fully in the remainder of this paper. [Table 3](#S2.T3
    "Table 3 ‣ 2.4 Overview of the rest of this Work ‣ 2 Foundation ‣ A Survey of
    Deep Meta-Learning") contains an overview of all techniques that are discussed
    further on.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助概述这些方法，我们引起你对以下表格的注意。[表 2](#S2.T2 "Table 2 ‣ 2.4 Overview of the rest of
    this Work ‣ 2 Foundation ‣ A Survey of Deep Meta-Learning")总结了三类方法并提供了关键思想和优势。这些术语和技术细节在本文的其余部分进行了更详细的解释。[表
    3](#S2.T3 "Table 3 ‣ 2.4 Overview of the rest of this Work ‣ 2 Foundation ‣ A
    Survey of Deep Meta-Learning")包含了所有进一步讨论的技术的概述。
- en: '|  | Metric | Model | Optimization |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '|  | 度量 | 模型 | 优化 |'
- en: '| Key idea | Input similarity | Internal task representation | Optimize for
    fast adaptation |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 关键思想 | 输入相似性 | 内部任务表示 | 针对快速适应的优化 |'
- en: '| Strength | Simple and effective | Flexible | More robust generalizability
    |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 优势 | 简单且有效 | 灵活 | 更强的鲁棒性 |'
- en: '| $p_{\boldsymbol{\theta}}(Y&#124;\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})$
    | $\sum\limits_{(\boldsymbol{x}_{i},y_{i})\in D^{tr}_{\mathcal{T}_{j}}}k_{\boldsymbol{\theta}}(\boldsymbol{x},\boldsymbol{x}_{i})y_{i}$
    | $f_{\boldsymbol{\theta}}(\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})$ | $f_{g_{\boldsymbol{\varphi}(\boldsymbol{\theta},D_{\mathcal{T}_{j}}^{tr},\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}})}}(\boldsymbol{x})$
    |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| $p_{\boldsymbol{\theta}}(Y\mid\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})$ |
    $\sum\limits_{(\boldsymbol{x}_{i},y_{i})\in D^{tr}_{\mathcal{T}_{j}}}k_{\boldsymbol{\theta}}(\boldsymbol{x},\boldsymbol{x}_{i})y_{i}$
    | $f_{\boldsymbol{\theta}}(\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})$ | $f_{g_{\boldsymbol{\varphi}(\boldsymbol{\theta},D_{\mathcal{T}_{j}}^{tr},\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}})}}(\boldsymbol{x})$
    |'
- en: 'Table 2: High-level overview of the three Deep Meta-Learning categories, i.e.,
    i) metric-, ii) model-, and iii) optimization-based techniques, and their main
    strengths and weaknesses. Recall that $\mathcal{T}_{j}$ is a task, $D^{tr}_{\mathcal{T}_{j}}$
    the corresponding support set, $k_{\boldsymbol{\theta}}(\boldsymbol{x},\boldsymbol{x}_{i})$
    a kernel function returning the similarity between the two inputs $\boldsymbol{x}$
    and $\boldsymbol{x}_{i}$, $y_{i}$ are true labels for known inputs $\boldsymbol{x}_{i}$,
    $\theta$ are base-learner parameters, and $g_{\boldsymbol{\varphi}}$ is a (learned)
    optimizer with parameters $\boldsymbol{\varphi}$.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：深度元学习的三大类技术的高级概述，即 i) 基于度量，ii) 基于模型，以及 iii) 基于优化的技术及其主要优势和劣势。回忆一下，$\mathcal{T}_{j}$
    是任务，$D^{tr}_{\mathcal{T}_{j}}$ 是相应的支持集，$k_{\boldsymbol{\theta}}(\boldsymbol{x},\boldsymbol{x}_{i})$
    是一个内核函数，返回两个输入 $\boldsymbol{x}$ 和 $\boldsymbol{x}_{i}$ 之间的相似度，$y_{i}$ 是已知输入 $\boldsymbol{x}_{i}$
    的真实标签，$\theta$ 是基础学习器参数，$g_{\boldsymbol{\varphi}}$ 是具有参数 $\boldsymbol{\varphi}$
    的（学习）优化器。
- en: '| Name | RL | Key idea | Bench. |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | RL | 关键思想 | 基准 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Metric-based |  | Input similarity | - |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 基于度量的 |  | 输入相似性 | - |'
- en: '|   Siamese networks | ✗ | Two-input, shared-weight, class identity network
    | 1, 8 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '|   孪生网络 | ✗ | 两输入，共享权重，类别身份网络 | 1, 8 |'
- en: '|   Matching networks | ✗ | Learn input embeddings for cosine-similarity weighted
    predictions | 1, 2 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '|   匹配网络 | ✗ | 学习用于余弦相似度加权预测的输入嵌入 | 1, 2 |'
- en: '|   Prototypical networks | ✗ | Input embeddings for class prototype clustering
    | 1, 2, 7 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|   原型网络 | ✗ | 用于类别原型聚类的输入嵌入 | 1, 2, 7 |'
- en: '|   Relation networks | ✗ | Learn input embeddings and similarity metric |
    1, 2, 7 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '|   关系网络 | ✗ | 学习输入嵌入和相似度度量 | 1, 2, 7 |'
- en: '|   ARC | ✗ | LSTM-based input fusion through interleaved glimpses | 1, 2 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '|   ARC | ✗ | 基于LSTM的输入融合，通过交错的瞥视 | 1, 2 |'
- en: '|   GNN | ✗ | Propagate label information to unlabeled inputs in a graph |
    1, 2 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '|   图神经网络 | ✗ | 在图中传播标签信息到未标记的输入 | 1, 2 |'
- en: '| Model-based |  | Internal and stateful latent task representations | - |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 基于模型的 |  | 内部和状态性潜在任务表示 | - |'
- en: '|   Reccurrent ml. | ✓ | Deploy Recurrent networks on RL problems | - |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '|   循环机器学习 | ✓ | 在强化学习问题上部署循环网络 | - |'
- en: '|   MANNs | ✗ | External short-term memory module for fast learning | 1 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '|   MANNs | ✗ | 外部短期记忆模块用于快速学习 | 1 |'
- en: '|   Meta networks | ✓ | Fast reparameterization of base-learner by distinct
    meta-learner | 1, 2 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '|   元网络 | ✓ | 通过不同的元学习器快速重新参数化基础学习器 | 1, 2 |'
- en: '|   SNAIL | ✓ | Attention mechanism coupled with temporal convolutions | 1,
    2 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '|   SNAIL | ✓ | 结合时间卷积的注意力机制 | 1, 2 |'
- en: '|   CNP | ✗ | Condition predictive model on embedded contextual task data |
    1, 8 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|   条件神经过程 | ✗ | 基于嵌入上下文任务数据的条件预测模型 | 1, 8 |'
- en: '|   Neural stat. | ✗ | Similarity between latent task embeddings | 1, 8 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '|   神经统计 | ✗ | 潜在任务嵌入之间的相似性 | 1, 8 |'
- en: '| Opt.-based |  | Optimize for fast task-specific adaptation | - |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 基于优化 |  | 针对快速任务特定适应进行优化 | - |'
- en: '|   LSTM optimizer | ✗ | RNN proposing weight updates for base-leaner | 6,
    8 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '|   LSTM 优化器 | ✗ | RNN 提议基础学习者的权重更新 | 6, 8 |'
- en: '|   LSTM ml. | ✓ | Embed base-learner parameters in cell state of LSTM | 2
    |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|   LSTM ml. | ✓ | 将基础学习者参数嵌入 LSTM 的单元状态中 | 2 |'
- en: '|   RL optimizer | ✗ | View optimization as RL problem | 4, 6 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '|   RL 优化器 | ✗ | 将优化视为 RL 问题 | 4, 6 |'
- en: '|   MAML | ✓ | Learn initialization weights $\boldsymbol{\theta}$ for fast
    adaptation | 1, 2 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '|   MAML | ✓ | 学习初始化权重 $\boldsymbol{\theta}$ 以实现快速适应 | 1, 2 |'
- en: '|   iMAML | ✓ | Approx. higher-order gradients, independent of optimization
    path | 1, 2 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '|   iMAML | ✓ | 近似高阶梯度，与优化路径无关 | 1, 2 |'
- en: '|   Meta-SGD | ✓ | Learn both the initialization and updates | 1, 2 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|   Meta-SGD | ✓ | 学习初始化和更新 | 1, 2 |'
- en: '|   Reptile | ✓ | Move initialization towards task-specific updated weights
    | 1, 2 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '|   Reptile | ✓ | 将初始化移动到任务特定的更新权重 | 1, 2 |'
- en: '|   LEO | ✗ | Optimize in lower-dimensional latent parameter space | 2, 3 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '|   LEO | ✗ | 在低维潜在参数空间中进行优化 | 2, 3 |'
- en: '|   Online MAML | ✗ | Accumulate task data for MAML-like training | 4, 8 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '|   在线 MAML | ✗ | 收集任务数据以进行类似 MAML 的训练 | 4, 8 |'
- en: '|   LLAMA | ✗ | Maintain probability distribution over post-update parameters
    $\boldsymbol{\theta}^{\prime}_{j}$ | 2 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '|   LLAMA | ✗ | 维持更新后参数 $\boldsymbol{\theta}^{\prime}_{j}$ 的概率分布 | 2 |'
- en: '|   PLATIPUS | ✗ | Learn a probability distribution over weight initializations
    $\boldsymbol{\theta}$ | - |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|   PLATIPUS | ✗ | 学习权重初始化的概率分布 $\boldsymbol{\theta}$ | - |'
- en: '|   BMAML | ✓ | Learn multiple initializations $\boldsymbol{\Theta}$, jointly
    optimized by SVGD | 2 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|   BMAML | ✓ | 学习多个初始化 $\boldsymbol{\Theta}$，由 SVGD 联合优化 | 2 |'
- en: '|   Diff. solvers | ✗ | Learn input embeddings for simple base-learners | 1,
    2, 3, 4, 5 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '|   差分解算器 | ✗ | 学习简单基础学习者的输入嵌入 | 1, 2, 3, 4, 5 |'
- en: 'Table 3: Overview of the discussed Deep Meta-Learning techniques. The table
    is partitioned into three sections, i.e., metric-, model-, and optimization-based
    techniques. All methods in one section adhere to the key idea of its corresponding
    category, which is mentioned in bold font. The columns RL and Bench show whether
    the techniques are applicable to reinforcement learning settings and the used
    benchmarks for testing the performance of the techniques. Note that all techniques
    are applicable to supervised learning, with the exception of RMLs. The benchmark
    column displays which benchmarks from [Section 2.2.2](#S2.SS2.SSS2 "2.2.2 Common
    Benchmarks ‣ 2.2 The Meta-Setup ‣ 2 Foundation ‣ A Survey of Deep Meta-Learning")
    were used in the paper proposing the technique. The used coding scheme for this
    column is the following. 1: Omniglot, 2: miniImageNet, 3: tieredImageNet, 4: CIFAR-100,
    5: CIFAR-FS, 6: CIFAR-10, 7: CUB, 8: MNIST, “-": used other evaluation method
    that are non-standard in Deep Meta-Learning and thus not covered in [Section 2.2.2](#S2.SS2.SSS2
    "2.2.2 Common Benchmarks ‣ 2.2 The Meta-Setup ‣ 2 Foundation ‣ A Survey of Deep
    Meta-Learning"). Used abbreviations: “opt.": optimization, “diff.": differentiable,
    “bench.": benchmarks.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3：讨论的深度元学习技术概述。该表分为三个部分，即基于度量、基于模型和基于优化的技术。每个部分中的所有方法都遵循其对应类别的核心思想，该思想以粗体字体表示。列
    RL 和 Bench 显示这些技术是否适用于强化学习设置，以及用于测试技术性能的基准。请注意，所有技术都适用于监督学习，RMLs 除外。基准列显示了提出该技术的论文中使用的基准，这些基准来自
    [第 2.2.2 节](#S2.SS2.SSS2 "2.2.2 Common Benchmarks ‣ 2.2 The Meta-Setup ‣ 2 Foundation
    ‣ A Survey of Deep Meta-Learning")。该列使用的编码方案如下。1: Omniglot, 2: miniImageNet, 3:
    tieredImageNet, 4: CIFAR-100, 5: CIFAR-FS, 6: CIFAR-10, 7: CUB, 8: MNIST, “-":
    使用了其他在深度元学习中非标准的评估方法，因此未包含在 [第 2.2.2 节](#S2.SS2.SSS2 "2.2.2 Common Benchmarks
    ‣ 2.2 The Meta-Setup ‣ 2 Foundation ‣ A Survey of Deep Meta-Learning") 中。使用的缩写：“opt.":
    优化，“diff.": 可微分，“bench.": 基准。'
- en: 3 Metric-based Meta-Learning
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 基于度量的元学习
- en: At a high level, the goal of metric-based techniques is to acquire—among others—meta-knowledge
    $\omega$ in the form of a good feature space that can be used for various new
    tasks. In the context of neural networks, this feature space coincides with the
    weights $\boldsymbol{\theta}$ of the networks. Then, new tasks can be learned
    by comparing new inputs to example inputs (of which we know the labels) in the
    meta-learned feature space. The higher the similarity between a new input and
    an example, the more likely it is that the new input will have the same label
    as the example input.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次看，基于度量的技术的目标是获得—除了其他之外—以良好的特征空间形式呈现的元知识 $\omega$，该特征空间可用于各种新任务。在神经网络的背景下，这个特征空间与网络的权重
    $\boldsymbol{\theta}$ 一致。然后，可以通过在元学习的特征空间中将新输入与示例输入（我们知道标签的）进行比较来学习新任务。新输入与示例的相似性越高，新输入具有与示例输入相同标签的可能性就越大。
- en: Metric-based techniques are a form of meta-learning as they leverage their prior
    learning experience (meta-learned feature space) to ‘learn’ new tasks more quickly.
    Here, ‘learn’ is used in a non-standard way since metric-based techniques do not
    make any network changes when presented with new tasks, as they rely solely on
    input comparisons in the already meta-learned feature space. These input comparisons
    are a form of non-parametric learning, i.e., new task information is not absorbed
    into the network parameters.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 基于度量的技术是一种元学习形式，因为它们利用其先前的学习经验（元学习的特征空间）来“更快地学习”新任务。在这里，“学习”以一种非标准的方式使用，因为基于度量的技术在面对新任务时不会对网络进行任何更改，因为它们仅依赖于在已经元学习的特征空间中的输入比较。这些输入比较是一种非参数学习，即，新任务信息不会被吸收到网络参数中。
- en: More formally, metric-based learning techniques aim to learn a similarity kernel,
    or equivalently, attention mechanism $k_{\boldsymbol{\theta}}$ (parameterized
    by $\boldsymbol{\theta}$), that takes two inputs $\boldsymbol{x}_{1}$ and $\boldsymbol{x}_{2}$,
    and outputs their similarity score. Larger scores indicate larger similarity.
    Class predictions for new inputs $\boldsymbol{x}$ can then be made by comparing
    $\boldsymbol{x}$ to example inputs $\boldsymbol{x}_{i}$, of which we know the
    true labels $y_{i}$. The underlying idea being that the larger the similarity
    between $\boldsymbol{x}$ and $\boldsymbol{x}_{i}$, the more likely it becomes
    that $\boldsymbol{x}$ also has label $y_{i}$.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，基于度量的学习技术旨在学习一个相似性核，或等效地，注意机制 $k_{\boldsymbol{\theta}}$（由 $\boldsymbol{\theta}$
    参数化），它接受两个输入 $\boldsymbol{x}_{1}$ 和 $\boldsymbol{x}_{2}$，并输出它们的相似性评分。较大的评分表示更大的相似性。对于新的输入
    $\boldsymbol{x}$，可以通过将 $\boldsymbol{x}$ 与已知真实标签 $y_{i}$ 的示例输入 $\boldsymbol{x}_{i}$
    进行比较来做出类别预测。基本思想是，$\boldsymbol{x}$ 和 $\boldsymbol{x}_{i}$ 之间的相似性越大，$\boldsymbol{x}$
    也具有标签 $y_{i}$ 的可能性就越大。
- en: Given a task $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$
    and an unseen input vector $\boldsymbol{x}\in D^{test}_{\mathcal{T}_{j}}$, a probability
    distribution over classes $Y$ is computed/predicted as a weighted combination
    of labels from the support set $D^{tr}_{\mathcal{T}_{j}}$, using similarity kernel
    $k_{\boldsymbol{\theta}}$, i.e.,
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个任务 $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$
    和一个未见过的输入向量 $\boldsymbol{x}\in D^{test}_{\mathcal{T}_{j}}$，通过使用相似性核 $k_{\boldsymbol{\theta}}$
    计算/预测类别 $Y$ 的概率分布，作为来自支持集 $D^{tr}_{\mathcal{T}_{j}}$ 的标签的加权组合，即，
- en: '|  | $\displaystyle p_{\boldsymbol{\theta}}(Y&#124;\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})=\sum_{(\boldsymbol{x}_{i},y_{i})\in
    D^{tr}_{\mathcal{T}_{j}}}k_{\boldsymbol{\theta}}(\boldsymbol{x},\boldsymbol{x}_{i})y_{i}.$
    |  | (7) |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle p_{\boldsymbol{\theta}}(Y\mid\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})=\sum_{(\boldsymbol{x}_{i},y_{i})\in
    D^{tr}_{\mathcal{T}_{j}}}k_{\boldsymbol{\theta}}(\boldsymbol{x},\boldsymbol{x}_{i})y_{i}.$
    |  | (7) |'
- en: Importantly, the labels $y_{i}$ are assumed to be one-hot encoded, meaning that
    they are represented by zero vectors with a ‘1’ on the position of the true class.
    For example, suppose there are five classes in total, and our example $\boldsymbol{x}_{1}$
    has true class 4\. Then, the one-hot encoded label is $y_{1}=[0,0,0,1,0]$. Note
    that the probability distribution $p_{\boldsymbol{\theta}}(Y|\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})$
    over classes is a vector of size $|Y|$, in which the $i$-th entry corresponds
    to the probability that input $\boldsymbol{x}$ has class $Y_{i}$ (given the support
    set). The predicted class is thus $\hat{y}=\operatorname*{arg\,max}_{i=1,2,\ldots,|Y|}p_{\boldsymbol{\theta}}(Y|\boldsymbol{x},S)_{i}$,
    where $p_{\boldsymbol{\theta}}(Y|\boldsymbol{x},S)_{i}$ is the computed probability
    that input $\boldsymbol{x}$ has class $Y_{i}$.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，标签 $y_{i}$ 被假定为一热编码，这意味着它们由零向量表示，在真实类别的位置上标有‘1’。例如，假设总共有五个类别，并且我们的示例 $\boldsymbol{x}_{1}$
    的真实类别为 4。然后，一热编码标签是 $y_{1}=[0,0,0,1,0]$。注意，类别的概率分布 $p_{\boldsymbol{\theta}}(Y|\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})$
    是一个大小为 $|Y|$ 的向量，其中第 $i$ 项对应于输入 $\boldsymbol{x}$ 属于类别 $Y_{i}$ 的概率（给定支持集）。因此，预测的类别是
    $\hat{y}=\operatorname*{arg\,max}_{i=1,2,\ldots,|Y|}p_{\boldsymbol{\theta}}(Y|\boldsymbol{x},S)_{i}$，其中
    $p_{\boldsymbol{\theta}}(Y|\boldsymbol{x},S)_{i}$ 是计算出的输入 $\boldsymbol{x}$ 属于类别
    $Y_{i}$ 的概率。
- en: '![Refer to caption](img/22659e97f0aef48dcab2243557a019e6.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/22659e97f0aef48dcab2243557a019e6.png)'
- en: 'Figure 5: Illustration of our metric-based example. The blue vector represents
    the new input from the query set, whereas the red vectors are inputs from the
    support set which can be used to guide our prediction for the new input.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：我们基于度量的示例说明。蓝色向量表示来自查询集的新输入，而红色向量是来自支持集的输入，可用于指导我们对新输入的预测。
- en: 3.1 Example
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 示例
- en: Suppose that we are given a task $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$.
    Furthermore, suppose that $D^{tr}_{\mathcal{T}_{j}}=\{([0,-4],1),([-2,-4],2),([-2,4],3),([6,0],4)\}$,
    where a tuple denotes a pair $(\boldsymbol{x}_{i},y_{i})$. For simplicity, the
    example will not use an embedding function, which maps example inputs onto an
    (more informative) embedding space. Our query set only contains one example $D^{test}_{\mathcal{T}_{j}}=\{([4,0.5],y)\}$.
    Then, the goal is to predict the correct label for new input $[4,0.5]$ using only
    examples in $D^{tr}_{\mathcal{T}_{j}}$. The problem is visualized in [Figure 5](#S3.F5
    "Figure 5 ‣ 3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning"), where
    red vectors correspond to example inputs from our support set. The blue vector
    is the new input that needs to be classified. Intuitively, this new input is most
    similar to the vector $[6,0]$, which means that we expect the label for the new
    input to be the same as that for $[6,0]$, i.e., $4$.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们给定了一个任务 $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$。进一步假设
    $D^{tr}_{\mathcal{T}_{j}}=\{([0,-4],1),([-2,-4],2),([-2,4],3),([6,0],4)\}$，其中一个元组表示一对
    $(\boldsymbol{x}_{i},y_{i})$。为简便起见，本例不使用嵌入函数，该函数将示例输入映射到一个（更具信息量的）嵌入空间。我们的查询集仅包含一个示例
    $D^{test}_{\mathcal{T}_{j}}=\{([4,0.5],y)\}$。然后，目标是仅使用 $D^{tr}_{\mathcal{T}_{j}}$
    中的示例来预测新输入 $[4,0.5]$ 的正确标签。这个问题在[图 5](#S3.F5 "Figure 5 ‣ 3 Metric-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning")中进行了可视化，其中红色向量对应于我们的支持集中的示例输入。蓝色向量是需要分类的新输入。直观上，这个新输入最类似于向量
    $[6,0]$，这意味着我们期望新输入的标签与 $[6,0]$ 的标签相同，即 $4$。
- en: Suppose we use a fixed similarity kernel, namely the cosine similarity, i.e.,
    $k(\boldsymbol{x},\boldsymbol{x}_{i})=\frac{\boldsymbol{x}\cdot\boldsymbol{x}_{i}^{T}}{||\boldsymbol{x}||\cdot||\boldsymbol{x}_{i}||}$,
    where $||\boldsymbol{v}||$ denotes the length of vector $\boldsymbol{v}$, i.e.,
    $||\boldsymbol{v}||=\sqrt{(\sum_{n}v_{n}^{2})}$. Here, $v_{n}$ denotes the $n$-th
    element of placeholder vector $\boldsymbol{v}$ (substitute $\boldsymbol{v}$ by
    $\boldsymbol{x}$ or $\boldsymbol{x}_{i}$). We can now compute the cosine similarity
    between the new input $[4,0.5]$ and every example input $\boldsymbol{x}_{i}$,
    as done in [Table 4](#S3.T4 "Table 4 ‣ 3.1 Example ‣ 3 Metric-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning"), where we used the facts that $||\boldsymbol{x}||=||\,[4,0.5]\,||=\sqrt{4^{2}+0.5^{2}}\approx
    4.03$, and $\frac{\boldsymbol{x}}{||\boldsymbol{x}||}\approx\frac{[4,0.5]}{4.03}=[0.99,0.12]$.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们使用固定的相似性核，即余弦相似度，即 $k(\boldsymbol{x},\boldsymbol{x}_{i})=\frac{\boldsymbol{x}\cdot\boldsymbol{x}_{i}^{T}}{||\boldsymbol{x}||\cdot||\boldsymbol{x}_{i}||}$，其中
    $||\boldsymbol{v}||$ 表示向量 $\boldsymbol{v}$ 的长度，即 $||\boldsymbol{v}||=\sqrt{(\sum_{n}v_{n}^{2})}$。这里，$v_{n}$
    表示占位符向量 $\boldsymbol{v}$ 的第 $n$ 个元素（用 $\boldsymbol{x}$ 或 $\boldsymbol{x}_{i}$
    替代 $\boldsymbol{v}$）。我们现在可以计算新输入 $[4,0.5]$ 和每个示例输入 $\boldsymbol{x}_{i}$ 之间的余弦相似度，如在
    [表4](#S3.T4 "Table 4 ‣ 3.1 Example ‣ 3 Metric-based Meta-Learning ‣ A Survey of
    Deep Meta-Learning") 中所做的，我们使用了 $||\boldsymbol{x}||=||\,[4,0.5]\,||=\sqrt{4^{2}+0.5^{2}}\approx
    4.03$，以及 $\frac{\boldsymbol{x}}{||\boldsymbol{x}||}\approx\frac{[4,0.5]}{4.03}=[0.99,0.12]$。
- en: From this table and [Equation 7](#S3.E7 "7 ‣ 3 Metric-based Meta-Learning ‣
    A Survey of Deep Meta-Learning"), it follows that the predicted probability distribution
    $p_{\boldsymbol{\theta}}(Y|\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})=-0.12y_{1}-0.58y_{2}-0.37y_{3}+0.99y_{4}=-0.12[1,0,0,0]-0.58[0,1,0,0]-0.37[0,0,1,0]+0.99[0,0,0,1]=\allowbreak[-0.12,\allowbreak-0.58,\allowbreak-0.37,\allowbreak
    0.99]$. Note that this is not really a probability distribution. That would require
    normalization such that every element is at least $0$ and the sum of all elements
    is $1$. For the sake of this example, we do not perform this normalization, as
    it is clear that class 4 (the class of the most similar example input $[6,0]$)
    will be predicted.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 从此表和 [公式7](#S3.E7 "7 ‣ 3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning")
    中可以得出，预测的概率分布 $p_{\boldsymbol{\theta}}(Y|\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})=-0.12y_{1}-0.58y_{2}-0.37y_{3}+0.99y_{4}=-0.12[1,0,0,0]-0.58[0,1,0,0]-0.37[0,0,1,0]+0.99[0,0,0,1]=\allowbreak[-0.12,\allowbreak-0.58,\allowbreak-0.37,\allowbreak
    0.99]$。注意，这实际上不是一个概率分布。真正的概率分布需要归一化，使得每个元素至少为 $0$，并且所有元素的和为 $1$。为了这个例子，我们不进行这种归一化，因为显然类
    4（最相似的示例输入 $[6,0]$ 的类别）将被预测出来。
- en: '| $\boldsymbol{x}_{i}$ | $y_{i}$ | $&#124;&#124;\boldsymbol{x}_{i}&#124;&#124;$
    | $\frac{\boldsymbol{x}_{i}}{&#124;&#124;\boldsymbol{x}_{i}&#124;&#124;}$ | $\frac{\boldsymbol{x}_{i}}{&#124;&#124;\boldsymbol{x}_{i}&#124;&#124;}\cdot\frac{\boldsymbol{x}}{&#124;&#124;\boldsymbol{x}&#124;&#124;}$
    |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{x}_{i}$ | $y_{i}$ | $&#124;&#124;\boldsymbol{x}_{i}&#124;&#124;$
    | $\frac{\boldsymbol{x}_{i}}{&#124;&#124;\boldsymbol{x}_{i}&#124;&#124;}$ | $\frac{\boldsymbol{x}_{i}}{&#124;&#124;\boldsymbol{x}_{i}&#124;&#124;}\cdot\frac{\boldsymbol{x}}{&#124;&#124;\boldsymbol{x}&#124;&#124;}$
    |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| $[0,-4]$ | $[1,0,0,0]$ | $4$ | $[0,-1]$ | $-0.12$ |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| $[0,-4]$ | $[1,0,0,0]$ | $4$ | $[0,-1]$ | $-0.12$ |'
- en: '| $[-2,-4]$ | $[0,1,0,0]$ | $4.47$ | $[-0.48,-0.89]$ | $-0.58$ |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| $[-2,-4]$ | $[0,1,0,0]$ | $4.47$ | $[-0.48,-0.89]$ | $-0.58$ |'
- en: '| $[-2,4]$ | $[0,0,1,0]$ | $4.47$ | $[-0.48,0.89]$ | $-0.37$ |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| $[-2,4]$ | $[0,0,1,0]$ | $4.47$ | $[-0.48,0.89]$ | $-0.37$ |'
- en: '| $[6,0]$ | $[0,0,0,1]$ | $6$ | $[1,0]$ | $0.99$ |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| $[6,0]$ | $[0,0,0,1]$ | $6$ | $[1,0]$ | $0.99$ |'
- en: 'Table 4: Example showing pair-wise input comparisons. Numbers were rounded
    to two decimals.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：示例展示了成对输入比较。数字已四舍五入到小数点后两位。
- en: One may wonder why such techniques are meta-learners, for we could take any
    single data set $\mathcal{D}$ and use pair-wise comparisons to compute predictions.
    At the outer-level, metric-based meta-learners are trained on a distribution of
    different tasks, in order to learn (among others) a good input embedding function.
    This embedding function facilitates inner-level learning, which is achieved through
    pair-wise comparisons. As such, one learns an embedding function across tasks
    to facilitate task-specific learning, which is equivalent to “learning to learn",
    or meta-learning.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 人们可能会疑惑为何这些技术是元学习者，因为我们可以采用任何单一数据集 $\mathcal{D}$ 并使用成对比较来计算预测。在外层，基于度量的元学习者在不同任务的分布上进行训练，以学习（其中之一）一个良好的输入嵌入函数。这个嵌入函数促进了内层学习，这通过成对比较来实现。因此，人们在任务之间学习一个嵌入函数，以促进特定任务的学习，这等同于“学习如何学习”，或称为元学习。
- en: After this introduction to metric-based methods, we will now cover some key
    metric-based techniques.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍了基于度量的方法之后，我们现在将覆盖一些关键的基于度量的技术。
- en: 3.2 Siamese Neural Networks
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 孪生神经网络
- en: A Siamese neural network (Koch et al., [2015](#bib.bib39)) consists of two neural
    networks $f_{\boldsymbol{\theta}}$ that share the same weights $\boldsymbol{\theta}$.
    Siamese neural networks take two inputs $\boldsymbol{x}_{1},\boldsymbol{x}_{2}$,
    and compute two hidden states $f_{\boldsymbol{\theta}}(\boldsymbol{x}_{1}),f_{\boldsymbol{\theta}}(\boldsymbol{x}_{2})$,
    corresponding to the activation patterns in the final hidden layers. These hidden
    states are fed into a distance layer, which computes a distance vector $\boldsymbol{d}=|f_{\boldsymbol{\theta}}(\boldsymbol{x}_{1})-f_{\boldsymbol{\theta}}(\boldsymbol{x}_{2})|$,
    where $d_{i}$ is the absolute distance between the $i$-th elements of $f_{\boldsymbol{\theta}}(\boldsymbol{x}_{1})$
    and $f_{\boldsymbol{\theta}}(\boldsymbol{x}_{2})$. From this distance vector,
    the similarity between $\boldsymbol{x}_{1},\boldsymbol{x}_{2}$ is computed as
    $\sigma(\boldsymbol{\alpha}^{T}\boldsymbol{d})$, where $\sigma$ is the sigmoid
    function (with output range [0,1]), and $\boldsymbol{\alpha}$ is a vector of free
    weighting parameters, determining the importance of each $d_{i}$. This network
    structure can be seen in [Figure 6](#S3.F6 "Figure 6 ‣ 3.2 Siamese Neural Networks
    ‣ 3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning").
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 孪生神经网络（Koch et al., [2015](#bib.bib39)）由两个共享相同权重$\boldsymbol{\theta}$的神经网络$f_{\boldsymbol{\theta}}$组成。孪生神经网络接受两个输入$\boldsymbol{x}_{1},\boldsymbol{x}_{2}$，并计算两个隐藏状态$f_{\boldsymbol{\theta}}(\boldsymbol{x}_{1})$和$f_{\boldsymbol{\theta}}(\boldsymbol{x}_{2})$，这两个隐藏状态对应于最终隐藏层中的激活模式。这些隐藏状态被输入到一个距离层，该层计算一个距离向量$\boldsymbol{d}=|f_{\boldsymbol{\theta}}(\boldsymbol{x}_{1})-f_{\boldsymbol{\theta}}(\boldsymbol{x}_{2})|$，其中$d_{i}$是$f_{\boldsymbol{\theta}}(\boldsymbol{x}_{1})$和$f_{\boldsymbol{\theta}}(\boldsymbol{x}_{2})$第$i$个元素之间的绝对距离。从这个距离向量中，$\boldsymbol{x}_{1},\boldsymbol{x}_{2}$之间的相似性被计算为$\sigma(\boldsymbol{\alpha}^{T}\boldsymbol{d})$，其中$\sigma$是sigmoid函数（输出范围为[0,1]），而$\boldsymbol{\alpha}$是一个自由加权参数向量，决定每个$d_{i}$的重要性。这种网络结构可以在[图6](#S3.F6
    "图6 ‣ 3.2 孪生神经网络 ‣ 3 基于度量的元学习 ‣ 深度元学习综述")中看到。
- en: '![Refer to caption](img/f2c31e6145b713e7cef5dfea9941367d.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明](img/f2c31e6145b713e7cef5dfea9941367d.png)'
- en: 'Figure 6: Example of a Siamese neural network. Source: Koch et al. ([2015](#bib.bib39)).'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：孪生神经网络示例。来源：Koch et al. ([2015](#bib.bib39))。
- en: Koch et al. ([2015](#bib.bib39)) applied this technique to few-shot image recognition
    in two stages. In the first stage, they train the twin network on an image verification
    task, where the goal is to output whether two input images $\boldsymbol{x}_{1}$
    and $\boldsymbol{x}_{2}$ have the same class. The network is thus stimulated to
    learn discriminative features. In the second stage, where the model is confronted
    with a new task, the network leverages its prior learning experience. That is,
    given a task $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$,
    and previously unseen input $\boldsymbol{x}\in D^{test}_{\mathcal{T}_{j}}$, the
    predicted class $\hat{y}$ is equal to the label $y_{i}$ of the example $(\boldsymbol{x}_{i},y_{i})\in
    D^{tr}_{\mathcal{T}_{j}}$ which yields the highest similarity score to $\boldsymbol{x}$.
    In contrast to other techniques mentioned further in this section, Siamese neural
    networks do not directly optimize for good performance across tasks (consisting
    of support and query sets). However, they do leverage learned knowledge from the
    verification task to learn new tasks quickly.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Koch et al. ([2015](#bib.bib39))将这种技术应用于少样本图像识别，分为两个阶段。在第一个阶段，他们在图像验证任务上训练双胞胎网络，目标是输出两个输入图像$\boldsymbol{x}_{1}$和$\boldsymbol{x}_{2}$是否属于同一类别。因此，网络被刺激去学习辨别特征。在第二个阶段，当模型面对新任务时，网络利用其之前的学习经验。也就是说，给定任务$\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$和之前未见过的输入$\boldsymbol{x}\in
    D^{test}_{\mathcal{T}_{j}}$，预测类别$\hat{y}$等于与$\boldsymbol{x}$相似度得分最高的示例$(\boldsymbol{x}_{i},y_{i})\in
    D^{tr}_{\mathcal{T}_{j}}$的标签$y_{i}$。与本节后面提到的其他技术相比，孪生神经网络并不直接优化跨任务（包括支持集和查询集）的性能。然而，它们确实利用从验证任务中学到的知识来快速学习新任务。
- en: In summary, Siamese neural networks are a simple and elegant approach to perform
    few-shot learning. However, they are not readily applicable outside the supervised
    learning setting.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，孪生神经网络是一种简单而优雅的少样本学习方法。然而，它们在监督学习之外的应用并不容易。
- en: 3.3 Matching Networks
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 匹配网络
- en: 'Matching networks (Vinyals et al., [2016](#bib.bib86)) build upon the idea
    that underlies Siamese neural networks (Koch et al., [2015](#bib.bib39)). That
    is, they leverage pair-wise comparisons between the given support set $D^{tr}_{\mathcal{T}_{j}}=\{(\boldsymbol{x}_{i},y_{i})\}_{i=1}^{m}$
    (for a task $\mathcal{T}_{j}$), and new inputs $\boldsymbol{x}\in D^{test}_{\mathcal{T}_{j}}$
    from the query set which we want to classify. However, instead of assigning the
    class $y_{i}$ of the most similar example input $\boldsymbol{x}_{i}$, matching
    networks use a weighted combination of all example labels $y_{i}$ in the support
    set, based on the similarity of inputs $\boldsymbol{x}_{i}$ to new input $\boldsymbol{x}$.
    More specifically, predictions are computed as follows: $\hat{y}=\sum_{i=1}^{m}a(\boldsymbol{x},\boldsymbol{x}_{i})y_{i}$,
    where $a$ is a non-parametric (non-trainable) attention mechanism, or similarity
    kernel. This classification process is shown in [Figure 7](#S3.F7 "Figure 7 ‣
    3.3 Matching Networks ‣ 3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning").
    In this figure, the input to $f_{\boldsymbol{\theta}}$ has to be classified, using
    the support set $D^{tr}_{\mathcal{T}_{j}}$ (input to $g_{\boldsymbol{\theta}}$).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配网络（Vinyals et al., [2016](#bib.bib86)）建立在底层的孪生神经网络（Koch et al., [2015](#bib.bib39)）的思想之上。也就是说，它们利用给定支持集
    $D^{tr}_{\mathcal{T}_{j}}=\{(\boldsymbol{x}_{i},y_{i})\}_{i=1}^{m}$（针对任务 $\mathcal{T}_{j}$）和我们希望分类的新输入
    $\boldsymbol{x}\in D^{test}_{\mathcal{T}_{j}}$ 之间的成对比较。然而，匹配网络不是分配最相似示例输入 $\boldsymbol{x}_{i}$
    的类别 $y_{i}$，而是根据输入 $\boldsymbol{x}_{i}$ 与新输入 $\boldsymbol{x}$ 的相似性，使用支持集中所有示例标签
    $y_{i}$ 的加权组合。更具体地说，预测计算如下：$\hat{y}=\sum_{i=1}^{m}a(\boldsymbol{x},\boldsymbol{x}_{i})y_{i}$，其中
    $a$ 是非参数（不可训练的）注意力机制或相似性核。这个分类过程如 [Figure 7](#S3.F7 "Figure 7 ‣ 3.3 Matching Networks
    ‣ 3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning") 中所示。在这个图中，$f_{\boldsymbol{\theta}}$
    的输入需要进行分类，使用支持集 $D^{tr}_{\mathcal{T}_{j}}$（即 $g_{\boldsymbol{\theta}}$ 的输入）。
- en: '![Refer to caption](img/df9584b383ad21a47c607276883631e0.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/df9584b383ad21a47c607276883631e0.png)'
- en: 'Figure 7: Architecture of matching networks. Source: Vinyals et al. ([2016](#bib.bib86)).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7: 匹配网络的架构。来源: Vinyals et al. ([2016](#bib.bib86))。'
- en: The attention that is used consists of a softmax over the cosine similarity
    $c$ between the input representations, i.e.,
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的注意力机制包括对输入表示之间的余弦相似度 $c$ 进行的 softmax 操作，即，
- en: '|  | $\displaystyle a(\boldsymbol{x},\boldsymbol{x}_{i})=\frac{e^{c(f_{\boldsymbol{\phi}}(\boldsymbol{x}),g_{\boldsymbol{\varphi}}(\boldsymbol{x}_{i}))}}{\sum_{j=1}^{m}e^{c(f_{\boldsymbol{\phi}}(\boldsymbol{x}),g_{\boldsymbol{\varphi}}(\boldsymbol{x}_{j}))}},$
    |  | (8) |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle a(\boldsymbol{x},\boldsymbol{x}_{i})=\frac{e^{c(f_{\boldsymbol{\phi}}(\boldsymbol{x}),g_{\boldsymbol{\varphi}}(\boldsymbol{x}_{i}))}}{\sum_{j=1}^{m}e^{c(f_{\boldsymbol{\phi}}(\boldsymbol{x}),g_{\boldsymbol{\varphi}}(\boldsymbol{x}_{j}))}},$
    |  | (8) |'
- en: where $f_{\boldsymbol{\phi}}$ and $g_{\boldsymbol{\varphi}}$ are neural networks,
    parameterized by $\boldsymbol{\phi}$ and $\boldsymbol{\varphi}$, that map raw
    inputs to a (lower-dimensional) latent vector, which corresponds to the output
    of the final hidden layer of a neural network. As such, the neural networks act
    as embedding functions. The larger the cosine similarity between the embeddings
    of $\boldsymbol{x}$ and $\boldsymbol{x}_{i}$, the larger $a(\boldsymbol{x},\boldsymbol{x}_{i})$,
    and thus the influence of label $y_{i}$ on the predicted label $\hat{y}$ for input
    $\boldsymbol{x}$.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $f_{\boldsymbol{\phi}}$ 和 $g_{\boldsymbol{\varphi}}$ 是由 $\boldsymbol{\phi}$
    和 $\boldsymbol{\varphi}$ 参数化的神经网络，这些网络将原始输入映射到（低维）潜在向量，该向量对应于神经网络最终隐藏层的输出。因此，神经网络充当了嵌入函数。$\boldsymbol{x}$
    和 $\boldsymbol{x}_{i}$ 的嵌入之间的余弦相似度越大，$a(\boldsymbol{x},\boldsymbol{x}_{i})$ 就越大，从而标签
    $y_{i}$ 对输入 $\boldsymbol{x}$ 的预测标签 $\hat{y}$ 的影响也越大。
- en: Vinyals et al. ([2016](#bib.bib86)) propose two main choices for the embedding
    functions. The first is to use a single neural network, granting us $\boldsymbol{\theta}=\boldsymbol{\phi}=\boldsymbol{\varphi}$
    and thus $f_{\boldsymbol{\phi}}=g_{\boldsymbol{\varphi}}$. This setup is the default
    form of matching networks, as shown in [Figure 7](#S3.F7 "Figure 7 ‣ 3.3 Matching
    Networks ‣ 3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning"). The
    second choice is to make $f_{\boldsymbol{\phi}}$ and $g_{\boldsymbol{\varphi}}$
    dependent on the support set $D^{tr}_{\mathcal{T}_{j}}$ using Long Short-Term
    Memory networks (LSTMs). In that case, $f_{\boldsymbol{\phi}}$ is represented
    by an attention LSTM, and $g_{\boldsymbol{\varphi}}$ by a bidirectional one. This
    choice for embedding functions is called Full Context Embeddings (FCE), and yielded
    an accuracy improvement of roughly 2% on miniImageNet compared to the regular
    matching networks, indicating that task-specific embeddings can aid the classification
    of new data points from the same distribution.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Vinyals 等（[2016](#bib.bib86)）提出了两种主要的嵌入函数选择。第一种是使用单个神经网络，从而得到 $\boldsymbol{\theta}=\boldsymbol{\phi}=\boldsymbol{\varphi}$，因此
    $f_{\boldsymbol{\phi}}=g_{\boldsymbol{\varphi}}$。这种设置是匹配网络的默认形式，如 [图 7](#S3.F7
    "图 7 ‣ 3.3 匹配网络 ‣ 3 度量基础元学习 ‣ 深度元学习综述") 所示。第二种选择是使 $f_{\boldsymbol{\phi}}$ 和 $g_{\boldsymbol{\varphi}}$
    依赖于支持集 $D^{tr}_{\mathcal{T}_{j}}$，使用长短期记忆网络（LSTMs）。在这种情况下，$f_{\boldsymbol{\phi}}$
    由注意力 LSTM 表示，而 $g_{\boldsymbol{\varphi}}$ 由双向 LSTM 表示。这种嵌入函数的选择称为全上下文嵌入（FCE），在
    miniImageNet 上相较于常规匹配网络提高了大约 2% 的准确性，表明任务特定的嵌入可以帮助分类来自相同分布的新数据点。
- en: Matching networks learn a good feature space across tasks for making pair-wise
    comparisons between inputs. In contrast to Siamese neural networks (Koch et al.,
    [2015](#bib.bib39)), this feature space (given by weights $\boldsymbol{\theta}$)
    is learned across tasks, instead of on a distinct verification task.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配网络通过在任务间学习良好的特征空间，以进行输入间的配对比较。与 Siamese 神经网络（Koch 等， [2015](#bib.bib39)）不同，这个特征空间（由权重
    $\boldsymbol{\theta}$ 给出）是在任务间学习的，而不是在一个独立的验证任务上。
- en: In summary, matching networks are an elegant and simple approach to metric-based
    meta-learning. However, these networks are not readily applicable outside of supervised
    learning settings and suffer from performance degradation when label distributions
    are biased (Vinyals et al., [2016](#bib.bib86)).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，匹配网络是一种优雅且简单的度量基础元学习方法。然而，这些网络在监督学习以外的场景中不易应用，并且当标签分布存在偏差时，其性能会下降（Vinyals
    等， [2016](#bib.bib86)）。
- en: 3.4 Prototypical Networks
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 原型网络
- en: Just like matching networks (Vinyals et al., [2016](#bib.bib86)), prototypical
    networks (Snell et al., [2017](#bib.bib74)) base their class predictions on the
    entire support set $D^{tr}_{\mathcal{T}_{j}}$. However, instead of computing the
    similarity between new inputs and examples in the support set, prototypical networks
    only compare new inputs to class prototypes (centroids), which are single vector
    representations of classes in some embedding space. Since there are fewer (or
    equal) class prototypes than the number of examples in the support set, the amount
    of required pair-wise comparisons decreases, saving computational costs.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 就像匹配网络（Vinyals 等， [2016](#bib.bib86)）一样，原型网络（Snell 等， [2017](#bib.bib74)）将其类别预测基于整个支持集
    $D^{tr}_{\mathcal{T}_{j}}$。然而，原型网络并不计算新输入与支持集中的示例之间的相似性，而是仅将新输入与类原型（质心）进行比较，这些原型是在某个嵌入空间中表示类别的单一向量表示。由于类别原型的数量少于或等于支持集中的示例数量，因此所需的配对比较数量减少，从而节省了计算成本。
- en: '![Refer to caption](img/6881ca7cac3123681382e7f415cc8c45.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6881ca7cac3123681382e7f415cc8c45.png)'
- en: 'Figure 8: Prototypical networks for the case of few-shot learning. The $\boldsymbol{c}_{k}$
    are class prototypes for class $k$ which are computed by averaging the representations
    of inputs (colored circles) in the support set. Note that the representation space
    is partitioned into three disjoint areas, where each area corresponds to one class.
    The class with the closest prototype to the new input $\boldsymbol{x}$ in the
    query set is then given as prediction. Source: Snell et al. ([2017](#bib.bib74)).'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：在少样本学习的情况下，原型网络。$\boldsymbol{c}_{k}$ 是类别 $k$ 的类原型，通过对支持集中的输入表示（彩色圆圈）进行平均计算得到。请注意，表示空间被划分为三个不重叠的区域，每个区域对应一个类别。然后，与查询集中新的输入
    $\boldsymbol{x}$ 最近的原型类别将作为预测结果。来源：Snell 等（[2017](#bib.bib74)）。
- en: The underlying idea of class prototypes is that for a task $\mathcal{T}_{j}$,
    there exists an embedding function that maps the support set onto a space where
    class instances cluster nicely around the corresponding class prototypes (Snell
    et al., [2017](#bib.bib74)). Then, for a new input $\boldsymbol{x}$, the class
    of the prototype nearest to that input will be predicted. As such, prototypical
    networks perform nearest centroid/prototype classification in a meta-learned embedding
    space. This is visualized in [Figure 8](#S3.F8 "Figure 8 ‣ 3.4 Prototypical Networks
    ‣ 3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning").
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 类别原型的基本思想是，对于任务 $\mathcal{T}_{j}$，存在一个嵌入函数将支持集映射到一个空间，其中类别实例围绕相应的类别原型良好地聚集（Snell
    等人，[2017](#bib.bib74)）。然后，对于新的输入 $\boldsymbol{x}$，将预测与该输入最近的原型的类别。因此，原型网络在元学习的嵌入空间中执行最近中心/原型分类。这在
    [图 8](#S3.F8 "Figure 8 ‣ 3.4 Prototypical Networks ‣ 3 Metric-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning") 中进行了可视化。
- en: More formally, given a distance function $d:X\times X\rightarrow[0,+\infty)$
    (e.g. Euclidean distance) and embedding function $f_{\boldsymbol{\theta}}$, parameterized
    by $\boldsymbol{\theta}$, prototypical networks compute class probabilities $p_{\boldsymbol{\theta}}(Y|\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})$
    as follows
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，给定一个距离函数 $d:X\times X\rightarrow[0,+\infty)$（例如欧几里得距离）和由参数 $\boldsymbol{\theta}$
    参数化的嵌入函数 $f_{\boldsymbol{\theta}}$，原型网络计算类概率 $p_{\boldsymbol{\theta}}(Y|\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})$
    如下所示。
- en: '|  | $\displaystyle p_{\boldsymbol{\theta}}(y=k&#124;\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})=\frac{exp[-d(f_{\theta}(\boldsymbol{x}),\boldsymbol{c}_{k})]}{\sum_{y_{i}}exp[-d(f_{\theta}(\boldsymbol{x}),\boldsymbol{c}_{y_{i}})]},$
    |  | (9) |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle p_{\boldsymbol{\theta}}(y=k&#124;\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})=\frac{exp[-d(f_{\theta}(\boldsymbol{x}),\boldsymbol{c}_{k})]}{\sum_{y_{i}}exp[-d(f_{\theta}(\boldsymbol{x}),\boldsymbol{c}_{y_{i}})]},$
    |  | (9) |'
- en: where $\boldsymbol{c}_{k}$ is the prototype/centroid for class $k$ and $y_{i}$
    are the classes in the support set $D^{tr}_{\mathcal{T}_{j}}$. Here, a class prototype
    for class $k$ is defined as the average of all vectors $\boldsymbol{x}_{i}$ in
    the support set such that $y_{i}=k$. Thus, classes with prototypes that are nearer
    to the new input $\boldsymbol{x}$ obtain larger probability scores.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\boldsymbol{c}_{k}$ 是类别 $k$ 的原型/中心点，而 $y_{i}$ 是支持集 $D^{tr}_{\mathcal{T}_{j}}$
    中的类别。在这里，类别 $k$ 的类别原型定义为支持集中所有向量 $\boldsymbol{x}_{i}$ 的平均值，使得 $y_{i}=k$。因此，与新输入
    $\boldsymbol{x}$ 更接近的类别原型获得更大的概率分数。
- en: Snell et al. ([2017](#bib.bib74)) found that the squared Euclidean distance
    function as $d$ gave rise to the best performance. With that distance function,
    prototypical networks can be seen as linear models. To see this, note that $-d(f_{\theta}(\boldsymbol{x}),\boldsymbol{c}_{k})=-||f_{\theta}(\boldsymbol{x})-\boldsymbol{c}_{k}||^{2}=-f_{\theta}(\boldsymbol{x})^{T}f_{\theta}(\boldsymbol{x})+2\boldsymbol{c}_{k}^{T}f_{\theta}(\boldsymbol{x})-\boldsymbol{c}_{k}^{T}\boldsymbol{c}_{k}$.
    The first term does not depend on the class $k$, and does thus not affect the
    classification decision. The remainder can be written as $\boldsymbol{w}_{k}^{T}f_{\theta}(\boldsymbol{x})+\boldsymbol{b}_{k}$,
    where $\boldsymbol{w}_{k}=2\boldsymbol{c}_{k}$ and $\boldsymbol{b}_{k}=-\boldsymbol{c}_{k}^{T}\boldsymbol{c}_{k}$.
    Note that this is linear in the output of network $f_{\theta}$, not linear in
    the input of the network $\boldsymbol{x}$. Also, Snell et al. ([2017](#bib.bib74))
    show that prototypical networks (coupled with Euclidean distance) are equivalent
    to matching networks in one-shot learning settings, as every example in the support
    set will be its prototype.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: Snell 等人（[2017](#bib.bib74)）发现，平方欧几里得距离函数作为 $d$ 使得性能最佳。使用这种距离函数，原型网络可以被视为线性模型。要看这一点，请注意
    $-d(f_{\theta}(\boldsymbol{x}),\boldsymbol{c}_{k})=-||f_{\theta}(\boldsymbol{x})-\boldsymbol{c}_{k}||^{2}=-f_{\theta}(\boldsymbol{x})^{T}f_{\theta}(\boldsymbol{x})+2\boldsymbol{c}_{k}^{T}f_{\theta}(\boldsymbol{x})-\boldsymbol{c}_{k}^{T}\boldsymbol{c}_{k}$。第一项不依赖于类别
    $k$，因此不会影响分类决策。其余部分可以写成 $\boldsymbol{w}_{k}^{T}f_{\theta}(\boldsymbol{x})+\boldsymbol{b}_{k}$，其中
    $\boldsymbol{w}_{k}=2\boldsymbol{c}_{k}$ 和 $\boldsymbol{b}_{k}=-\boldsymbol{c}_{k}^{T}\boldsymbol{c}_{k}$。请注意，这在网络
    $f_{\theta}$ 的输出中是线性的，而不是在网络输入 $\boldsymbol{x}$ 中线性的。此外，Snell 等人（[2017](#bib.bib74)）表明，原型网络（与欧几里得距离结合）在单次学习设置中等同于匹配网络，因为支持集中的每个示例将成为其原型。
- en: In short, prototypical networks save computational costs by reducing the required
    number of pair-wise comparisons between new inputs and the support set, by adopting
    the concept of class prototypes. Additionally, prototypical networks were found
    to outperform matching networks (Vinyals et al., [2016](#bib.bib86)) in 5-way,
    $k$-shot learning for $k=1,5$ on Omniglot (Lake et al., [2011](#bib.bib42)) and
    miniImageNet (Vinyals et al., [2016](#bib.bib86)), even though they do not use
    complex task-specific embedding functions. Despite these advantages, prototypical
    networks are not readily applicable outside of supervised learning settings.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，原型网络通过采用类别原型的概念，减少了新输入与支持集之间所需的成对比较，从而节省了计算成本。此外，原型网络在 Omniglot（Lake et
    al., [2011](#bib.bib42)）和 miniImageNet（Vinyals et al., [2016](#bib.bib86)）上的 5-way,
    $k$-shot 学习中，在 $k=1,5$ 的情况下表现优于匹配网络（Vinyals et al., [2016](#bib.bib86)），即使它们没有使用复杂的任务特定嵌入函数。尽管有这些优点，原型网络在监督学习环境之外并不容易应用。
- en: 3.5 Relation Networks
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 关系网络
- en: '![Refer to caption](img/8f3ce9ffbfb29735d26ed8d594647627.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8f3ce9ffbfb29735d26ed8d594647627.png)'
- en: 'Figure 9: Relation network architecture. First, the embedding network $f_{\boldsymbol{\varphi}}$
    embeds all inputs from the support set $D^{tr}_{\mathcal{T}_{j}}$ (the five example
    inputs on the left), and the query input (below the $f_{\boldsymbol{\varphi}}$
    block). All support set embeddings $f_{\boldsymbol{\varphi}}(\boldsymbol{x}_{i})$
    are then concatenated to the query embedding $f_{\boldsymbol{\varphi}}(\boldsymbol{x})$.
    These concatenated embeddings are passed into a relation network $g_{\boldsymbol{\phi}}$,
    which computes a relation score for every pair $(\boldsymbol{x}_{i},\boldsymbol{x})$.
    The class of the input $\boldsymbol{x}_{i}$ that yields the largest relation score
    $g_{\boldsymbol{\phi}}([f_{\boldsymbol{\varphi}}(\boldsymbol{x}),f_{\boldsymbol{\varphi}}(\boldsymbol{x}_{i})])$
    is then predicted. Source: Sung et al. ([2018](#bib.bib76)).'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：关系网络架构。首先，嵌入网络 $f_{\boldsymbol{\varphi}}$ 将来自支持集 $D^{tr}_{\mathcal{T}_{j}}$
    的所有输入（左侧的五个示例输入）以及查询输入（在 $f_{\boldsymbol{\varphi}}$ 块下方）进行嵌入。然后，将所有支持集嵌入 $f_{\boldsymbol{\varphi}}(\boldsymbol{x}_{i})$
    连接到查询嵌入 $f_{\boldsymbol{\varphi}}(\boldsymbol{x})$。这些连接的嵌入被输入到关系网络 $g_{\boldsymbol{\phi}}$
    中，该网络计算每对 $(\boldsymbol{x}_{i},\boldsymbol{x})$ 的关系分数。然后，预测产生最大关系分数 $g_{\boldsymbol{\phi}}([f_{\boldsymbol{\varphi}}(\boldsymbol{x}),f_{\boldsymbol{\varphi}}(\boldsymbol{x}_{i})])$
    的输入 $\boldsymbol{x}_{i}$ 的类别。来源：Sung et al. ([2018](#bib.bib76))。
- en: 'In contrast to previously discussed metric-based techniques, Relation networks
    (Sung et al., [2018](#bib.bib76)) employ a trainable similarity metric, instead
    of a pre-defined one (e.g. cosine similarity as used in matching networks (Vinyals
    et al., [2016](#bib.bib86))). More specifically, matching networks consist of
    two chained, neural network modules: the embedding network/module $f_{\boldsymbol{\varphi}}$
    which is responsible for embedding inputs, and the relation network $g_{\boldsymbol{\phi}}$
    which computes similarity scores between new inputs $\boldsymbol{x}$ and example
    inputs $\boldsymbol{x}_{i}$ of which we know the labels. A classification decision
    is then made by picking the class of the example input which yields the largest
    relation score (or similarity). Note that Relation networks thus do not use the
    idea of class prototypes, and simply compare new inputs $\boldsymbol{x}$ to all
    example inputs $\boldsymbol{x}_{i}$ in the support set, as done by, e.g., matching
    networks (Vinyals et al., [2016](#bib.bib86)).'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前讨论的基于度量的技术不同，关系网络（Sung et al., [2018](#bib.bib76)）使用一个可训练的相似性度量，而不是预定义的度量（例如，匹配网络（Vinyals
    et al., [2016](#bib.bib86)）中使用的余弦相似性）。更具体地说，匹配网络由两个串联的神经网络模块组成：嵌入网络/模块 $f_{\boldsymbol{\varphi}}$，负责对输入进行嵌入，以及关系网络
    $g_{\boldsymbol{\phi}}$，计算新输入 $\boldsymbol{x}$ 和我们已知标签的示例输入 $\boldsymbol{x}_{i}$
    之间的相似性分数。然后，通过选择示例输入中产生最大关系分数（或相似性）的类别来做出分类决策。请注意，关系网络因此不使用类别原型的概念，而是简单地将新输入 $\boldsymbol{x}$
    与支持集中的所有示例输入 $\boldsymbol{x}_{i}$ 进行比较，如匹配网络（Vinyals et al., [2016](#bib.bib86)）所做的那样。
- en: More formally, we are given a support set $D^{tr}_{\mathcal{T}_{j}}$ with some
    examples $(\boldsymbol{x}_{i},y_{i})$, and a new (previously unseen) input $\boldsymbol{x}$.
    Then, for every combination $(\boldsymbol{x},\boldsymbol{x}_{i})$, the Relation
    network produces a concatenated embedding $[f_{\boldsymbol{\varphi}}(\boldsymbol{x}),f_{\boldsymbol{\varphi}}(\boldsymbol{x}_{i})]$,
    which is vector obtained by concatenating the respective embeddings of $\boldsymbol{x}$
    and $\boldsymbol{x}_{i}$. This concatenated embedding is then fed into the relation
    module $g_{\boldsymbol{\phi}}$. Finally, $g_{\boldsymbol{\phi}}$ computes the
    relation score between $\boldsymbol{x}$ and $\boldsymbol{x}_{i}$ as
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，我们给定一个支持集 $D^{tr}_{\mathcal{T}_{j}}$，其中包含一些示例 $(\boldsymbol{x}_{i},y_{i})$，以及一个新的（之前未见过的）输入
    $\boldsymbol{x}$。然后，对于每一个组合 $(\boldsymbol{x},\boldsymbol{x}_{i})$，关系网络产生一个拼接的嵌入
    $[f_{\boldsymbol{\varphi}}(\boldsymbol{x}),f_{\boldsymbol{\varphi}}(\boldsymbol{x}_{i})]$，这是通过拼接
    $\boldsymbol{x}$ 和 $\boldsymbol{x}_{i}$ 的相应嵌入获得的向量。这个拼接的嵌入然后被送入关系模块 $g_{\boldsymbol{\phi}}$。最后，$g_{\boldsymbol{\phi}}$
    计算 $\boldsymbol{x}$ 和 $\boldsymbol{x}_{i}$ 之间的关系得分。
- en: '|  | $\displaystyle r_{i}=g_{\boldsymbol{\phi}}([f_{\boldsymbol{\varphi}}(\boldsymbol{x}),f_{\boldsymbol{\varphi}}(\boldsymbol{x}_{i})]).$
    |  | (10) |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle r_{i}=g_{\boldsymbol{\phi}}([f_{\boldsymbol{\varphi}}(\boldsymbol{x}),f_{\boldsymbol{\varphi}}(\boldsymbol{x}_{i})]).$
    |  | (10) |'
- en: The predicted class is then $\hat{y}=y_{\operatorname*{arg\,max}_{i}r_{i}}$.
    This entire process is shown in [Figure 9](#S3.F9 "Figure 9 ‣ 3.5 Relation Networks
    ‣ 3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning"). Remarkably
    enough, Relation networks use the Mean-Squared Error (MSE) of the relation scores,
    rather than the more standard cross-entropy loss. The MSE is then propagated backwards
    through the entire architecture ([Figure 9](#S3.F9 "Figure 9 ‣ 3.5 Relation Networks
    ‣ 3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning")).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 预测的类别是 $\hat{y}=y_{\operatorname*{arg\,max}_{i}r_{i}}$。整个过程如[图 9](#S3.F9 "Figure
    9 ‣ 3.5 Relation Networks ‣ 3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning")所示。值得注意的是，关系网络使用的是关系得分的均方误差（MSE），而不是更标准的交叉熵损失。然后，MSE通过整个架构向后传播（[图
    9](#S3.F9 "Figure 9 ‣ 3.5 Relation Networks ‣ 3 Metric-based Meta-Learning ‣ A
    Survey of Deep Meta-Learning")）。
- en: The key advantage of Relation networks is their expressive power, induced by
    the usage of a trainable similarity function. This expressivity makes this technique
    very powerful. As a result, it yields better performance than previously discussed
    techniques that use a fixed similarity metric.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 关系网络的关键优势在于其表达能力，这是由可训练相似性函数的使用所引起的。这种表达能力使得这一技术非常强大。因此，它比使用固定相似性度量的之前讨论的技术具有更好的性能。
- en: 3.6 Graph Neural Networks
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.6 图神经网络
- en: 'Graph neural networks (Garcia and Bruna, [2017](#bib.bib17)) use a more general
    and flexible approach than previously discussed techniques for $N$-way, $k$-shot
    classification. As such, graph neural networks subsume Siamese (Koch et al., [2015](#bib.bib39))
    and prototypical networks (Snell et al., [2017](#bib.bib74)). The graph neural
    network approach represents each task $\mathcal{T}_{j}$ as a fully-connected graph
    $G=(V,E)$, where $V$ is a set of nodes/vertices and $E$ a set of edges connecting
    nodes. In this graph, nodes $\boldsymbol{v}_{i}$ correspond to input embeddings
    $f_{\boldsymbol{\theta}}(\boldsymbol{x}_{i})$, concatenated with their one-hot
    encoded labels $y_{i}$, i.e., $\boldsymbol{v}_{i}=[f_{\boldsymbol{\theta}}(\boldsymbol{x}_{i}),y_{i}]$.
    For inputs $\boldsymbol{x}$ from the query set (for which we do not have the labels),
    a uniform prior over all $N$ possible labels is used: $y=[\frac{1}{N},\ldots,\frac{1}{N}]$.
    Thus, each node contains an input and label section. Edges are weighted links
    that connect these nodes.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图神经网络（Garcia 和 Bruna，[2017](#bib.bib17)）使用比之前讨论的技术更通用和灵活的方法进行 $N$-way，$k$-shot
    分类。因此，图神经网络包含了 Siamese（Koch 等，[2015](#bib.bib39)）和原型网络（Snell 等，[2017](#bib.bib74)）。图神经网络方法将每个任务
    $\mathcal{T}_{j}$ 表示为一个完全连接的图 $G=(V,E)$，其中 $V$ 是节点/顶点的集合，$E$ 是连接节点的边的集合。在这个图中，节点
    $\boldsymbol{v}_{i}$ 对应于输入嵌入 $f_{\boldsymbol{\theta}}(\boldsymbol{x}_{i})$，并与其一热编码标签
    $y_{i}$ 连接，即 $\boldsymbol{v}_{i}=[f_{\boldsymbol{\theta}}(\boldsymbol{x}_{i}),y_{i}]$。对于来自查询集的输入
    $\boldsymbol{x}$（我们没有标签），使用所有 $N$ 个可能标签的均匀先验：$y=[\frac{1}{N},\ldots,\frac{1}{N}]$。因此，每个节点包含输入和标签部分。边是连接这些节点的加权链接。
- en: The graph neural network then propagates information in the graph using a number
    of local operators. The underlying idea is that label information can be transmitted
    from nodes of which we do have the labels, to nodes for which we have to predict
    labels. Which local operators are used, is out of scope for this paper, and the
    reader is referred to Garcia and Bruna ([2017](#bib.bib17)) for details.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 图神经网络使用一系列局部操作符在图中传播信息。其基本思想是标签信息可以从我们已知标签的节点传递到我们需要预测标签的节点。具体使用哪些局部操作符超出了本文的范围，读者可以参考
    Garcia 和 Bruna ([2017](#bib.bib17)) 以获取详细信息。
- en: By exposing the graph neural network to various tasks $\mathcal{T}_{j}$, the
    propagation mechanism can be altered to improve the flow of label information
    in such a way that predictions become more accurate. As such, in addition to learning
    a good input representation function $f_{\boldsymbol{\theta}}$, graph neural networks
    also learn to propagate label information from labeled examples to unlabeled inputs.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将图神经网络暴露于各种任务 $\mathcal{T}_{j}$，可以改变传播机制，从而改善标签信息的流动，使得预测变得更加准确。因此，除了学习一个好的输入表示函数
    $f_{\boldsymbol{\theta}}$，图神经网络还学习如何将标签信息从有标签的示例传播到无标签的输入。
- en: Graph neural networks achieve good performance in few-shot settings (Garcia
    and Bruna, [2017](#bib.bib17)) and are also applicable in semi-supervised and
    active learning settings.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图神经网络在少样本设置中表现良好 (Garcia 和 Bruna, [2017](#bib.bib17))，并且在半监督和主动学习设置中也适用。
- en: 3.7 Attentive Recurrent Comparators (ARCs)
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.7 注意力递归比较器（ARCs）
- en: '![Refer to caption](img/f7d7db0a5f26fccb6bdd349ffc0eb745.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f7d7db0a5f26fccb6bdd349ffc0eb745.png)'
- en: 'Figure 10: Processing in an attentive recurrent comparator. At every time step,
    the model takes a glimpse of a part of an image and incorporates this information
    into the hidden state $h_{t}$. The final hidden state after taking various glimpses
    of a pair of images is then used to compute a class similarity score. Source:
    Shyam et al. ([2017](#bib.bib72)).'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：在注意力递归比较器中的处理。每个时间步骤，模型会扫描图像的一部分，并将这些信息融入隐藏状态 $h_{t}$。在对一对图像进行各种扫描后，最终的隐藏状态用于计算类别相似性分数。来源：Shyam
    等人 ([2017](#bib.bib72))。
- en: Attentive recurrent comparators (ARCs) (Shyam et al., [2017](#bib.bib72)) differ
    from previously discussed techniques as they do not compare inputs as a whole,
    but by parts. This approach is inspired by how humans would make a decision concerning
    the similarity of objects. That is, we shift our attention from one object to
    the other, and move back and forth to take glimpses of different parts of both
    objects. In this way, information of two objects is fused from the beginning,
    whereas other techniques (e.g., matching networks (Vinyals et al., [2016](#bib.bib86))
    and graph neural networks (Garcia and Bruna, [2017](#bib.bib17))) only combine
    information at the end (after embedding both images) (Shyam et al., [2017](#bib.bib72)).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力递归比较器（ARCs）(Shyam 等人, [2017](#bib.bib72)) 与之前讨论的技术不同，它们不是整体比较输入，而是按部分进行比较。这种方法受到人类如何判断物体相似性的启发。也就是说，我们将注意力从一个物体转移到另一个物体，并来回移动以扫描两个物体的不同部分。这样，两物体的信息从一开始就被融合，而其他技术（例如，匹配网络（Vinyals
    等人, [2016](#bib.bib86)）和图神经网络（Garcia 和 Bruna, [2017](#bib.bib17)））只在最后（在嵌入两个图像后）合并信息
    (Shyam 等人, [2017](#bib.bib72))。
- en: 'Given two inputs $\boldsymbol{x}_{i}$ and $\boldsymbol{x}$, we feed them in
    interleaved fashion repeatedly into a recurrent neural network (controller): $\boldsymbol{x}_{i},\boldsymbol{x},\ldots,\boldsymbol{x}_{i},\boldsymbol{x}$.
    Thus, the image at time step $t$ is given by $I_{t}=\boldsymbol{x}_{i}$ if $t$
    is even else $\boldsymbol{x}$. Then, at each time step $t$, the attention mechanism
    focuses on a square region of the current image: $G_{t}=attend(I_{t},\Omega_{t})$,
    where $\Omega_{t}=W_{g}h_{t-1}$ are attention parameters, which are computed from
    the previous hidden state $h_{t-1}$. The next hidden state $h_{t+1}=\mbox{RNN}(G_{t},h_{t-1})$
    is given by the glimpse at time t, i.e., $G_{t}$, and the previous hidden state
    $h_{t-1}$. The entire sequence consists of $g$ glimpses per image. After this
    sequence is fed into the recurrent neural network (indicated by RNN($\circ$)),
    the final hidden state $h_{2g}$ is used as combined representation of $\boldsymbol{x}_{i}$
    relative to $\boldsymbol{x}$. This process is summarized in [Figure 10](#S3.F10
    "Figure 10 ‣ 3.7 Attentive Recurrent Comparators (ARCs) ‣ 3 Metric-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning"). Classification decisions can then be made
    by feeding the combined representations into a classifier. Optionally, the combined
    representations can be processed by bi-directional LSTMs before passing them to
    the classifier.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 给定两个输入 $\boldsymbol{x}_{i}$ 和 $\boldsymbol{x}$，我们将它们交替输入到递归神经网络（控制器）中：$\boldsymbol{x}_{i},\boldsymbol{x},\ldots,\boldsymbol{x}_{i},\boldsymbol{x}$。因此，当时间步
    $t$ 为偶数时，图像 $I_{t}$ 由 $\boldsymbol{x}_{i}$ 给出，否则由 $\boldsymbol{x}$ 给出。然后，在每个时间步
    $t$，注意力机制集中于当前图像的一个方形区域：$G_{t}=attend(I_{t},\Omega_{t})$，其中 $\Omega_{t}=W_{g}h_{t-1}$
    是注意力参数，从之前的隐藏状态 $h_{t-1}$ 计算得出。下一个隐藏状态 $h_{t+1}=\mbox{RNN}(G_{t},h_{t-1})$ 是由时间步
    $t$ 的一瞥 $G_{t}$ 和之前的隐藏状态 $h_{t-1}$ 组成的。整个序列由每张图像 $g$ 次一瞥组成。将这个序列输入到递归神经网络中（由 RNN($\circ$)
    指示），最终的隐藏状态 $h_{2g}$ 被用作相对于 $\boldsymbol{x}$ 的 $\boldsymbol{x}_{i}$ 的组合表示。这个过程总结在
    [图10](#S3.F10 "Figure 10 ‣ 3.7 Attentive Recurrent Comparators (ARCs) ‣ 3 Metric-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning") 中。然后，可以通过将组合表示输入到分类器中来做出分类决策。可选地，可以先通过双向
    LSTM 处理组合表示，然后再将其传递给分类器。
- en: The attention approach is biologically inspired, and biologically plausible.
    A downside of attentive recurrent comparators is the higher computational cost,
    while the performance is often not better than less biologically plausible techniques,
    such as graph neural networks (Garcia and Bruna, [2017](#bib.bib17)).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力方法具有生物学上的灵感，且生物学上是合理的。注意力递归比较器的一个缺点是计算成本较高，而性能通常不如一些生物学上不太合理的方法，例如图神经网络（Garcia
    and Bruna, [2017](#bib.bib17)）。
- en: 3.8 Metric-based Techniques, in conclusion
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8 基于度量的方法，总结
- en: In this section, we have seen various metric-based techniques. The metric-based
    techniques meta-learn an informative feature space that can be used to compute
    class predictions based on input similarity scores. [Figure 11](#S3.F11 "Figure
    11 ‣ 3.8 Metric-based Techniques, in conclusion ‣ 3 Metric-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning") shows the relationships between the various
    metric-based techniques that we have covered.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们已经看到各种基于度量的方法。这些基于度量的方法通过元学习一个信息特征空间，该空间可以用来基于输入相似性评分计算类别预测。[图11](#S3.F11
    "Figure 11 ‣ 3.8 Metric-based Techniques, in conclusion ‣ 3 Metric-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning") 显示了我们所涵盖的各种基于度量的方法之间的关系。
- en: As we can see, Siamese networks (Koch et al., [2015](#bib.bib39)) mark the beginning
    of metric-based, deep meta-learning techniques in few-shot learning settings.
    They are the first to use the idea of predicting classes by comparing inputs from
    the support and query sets. This idea was generalized in graph neural networks
    (GNNs) (Hamilton et al., [2017](#bib.bib26); Garcia and Bruna, [2017](#bib.bib17))
    where the information flow between support and query inputs is parametric and
    thus more flexible. Matching networks (Vinyals et al., [2016](#bib.bib86)) are
    directly inspired by Siamese networks as they use the same core idea (comparing
    inputs for making predictions), but directly train in the few-shot setting and
    use cosine similarity as a similarity function. Thus, the auxiliary, binary classification
    task used by Siamese networks is left out, and matching networks directly train
    on tasks. Prototypical networks (Snell et al., [2017](#bib.bib74)) increase the
    robustness of input comparisons by comparing every query set input with a class
    prototype instead of individual support set examples. This reduces the number
    of required input comparisons for a single query input to $N$ instead of $k\cdot
    N$. Relation networks (Sung et al., [2018](#bib.bib76)) replace the fixed, pre-defined
    similarity metrics used in matching and prototypical networks by a neural network,
    which allows for learning a domain-specific similarity function. Lastly, attentive
    recurrent comparators (Shyam et al., [2017](#bib.bib72)) take a more biologically
    plausible approach by not comparing entire inputs but by taking multiple interleaved
    glimpses at various parts of the inputs that are being compared.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，Siamese 网络（Koch et al., [2015](#bib.bib39)）标志着在少样本学习设置中，基于度量的深度元学习技术的开始。它们是首个通过比较支持集和查询集的输入来预测类别的。这一思想在图神经网络（GNNs）（Hamilton
    et al., [2017](#bib.bib26); Garcia 和 Bruna, [2017](#bib.bib17)）中得到了推广，其中支持输入和查询输入之间的信息流是参数化的，因此更加灵活。匹配网络（Vinyals
    et al., [2016](#bib.bib86)）直接受到Siamese网络的启发，因为它们使用相同的核心思想（比较输入以进行预测），但直接在少样本设置中进行训练，并使用余弦相似度作为相似性函数。因此，Siamese网络使用的辅助二分类任务被省略，匹配网络直接在任务上进行训练。原型网络（Snell
    et al., [2017](#bib.bib74)）通过将每个查询集输入与类原型进行比较而不是单独的支持集示例，增加了输入比较的鲁棒性。这将单个查询输入所需的输入比较数量减少为$N$而不是$k\cdot
    N$。关系网络（Sung et al., [2018](#bib.bib76)）用神经网络替代了匹配网络和原型网络中使用的固定预定义相似性度量，这允许学习特定领域的相似性函数。最后，关注型递归比较器（Shyam
    et al., [2017](#bib.bib72)）采用了一种更符合生物学的方式，通过对输入的不同部分进行多次交错的快速观察，而不是比较整个输入。
- en: Key advantages of these metric-based techniques are that i) the underlying idea
    of similarity-based predictions is conceptually simple, and ii) they can be fast
    at test-time when tasks are small, as the networks do not need to make task-specific
    adjustments. However, when tasks at meta-test time become more distant from the
    tasks that were used at meta-train time, metric-learning techniques are unable
    to absorb new task information into the network weights. Consequently, performance
    may degrade.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这些基于度量的技术的主要优点是：i）相似性预测的基本思想概念上很简单，ii）当任务较小时，它们在测试时可以很快，因为网络不需要进行任务特定的调整。然而，当元测试时的任务与元训练时使用的任务差距较大时，度量学习技术无法将新的任务信息吸收到网络权重中。因此，性能可能会下降。
- en: Furthermore, when tasks become larger, pair-wise comparisons may become prohibitively
    expensive. Lastly, most metric-based techniques rely on the presence of labeled
    examples, which make them inapplicable outside of supervised learning settings.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当任务变得更大时，成对比较可能变得过于昂贵。最后，大多数基于度量的技术依赖于标记示例，这使得它们在监督学习环境之外不可用。
- en: '![Refer to caption](img/80ef5c438ab941b1cbbf2e91d063fe01.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/80ef5c438ab941b1cbbf2e91d063fe01.png)'
- en: 'Figure 11: The relationships between the covered metric-based meta-learning
    techniques.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：覆盖的基于度量的元学习技术之间的关系。
- en: 4 Model-based Meta-Learning
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 基于模型的元学习
- en: A different approach to Deep Meta-Learning is the model-based approach. On a
    high level, model-based techniques rely upon an adaptive, internal state, in contrast
    to metric-based techniques, which generally use a fixed neural network at test-time.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 一种不同的深度元学习方法是基于模型的方法。从高层次来看，基于模型的技术依赖于自适应的内部状态，而与基于度量的技术不同，后者通常在测试时使用固定的神经网络。
- en: More specifically, model-based techniques maintain a stateful, internal representation
    of a task. When presented with a task, a model-based neural network processes
    the support set in a sequential fashion. At every time step, an input enters and
    alters the internal state of the model. Thus, the internal state can capture relevant
    task-specific information, which can be used to make predictions for new inputs.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，基于模型的技术维持任务的有状态内部表示。当面对一个任务时，基于模型的神经网络以顺序方式处理支持集。在每个时间步，输入进入并改变模型的内部状态。因此，内部状态可以捕捉相关的任务特定信息，这些信息可用于对新输入进行预测。
- en: Because the predictions are based on internal dynamics that are hidden from
    the outside, model-based techniques are also called black-boxes. Information from
    previous inputs must be remembered, which is why model-based techniques have a
    memory component, either in- or externally.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 因为预测基于对外部隐藏的内部动态，基于模型的技术也被称为黑箱。必须记住来自先前输入的信息，这就是为什么基于模型的技术有一个记忆组件，无论是内部还是外部。
- en: Recall that the mechanics of metric-based techniques were limited to pair-wise
    input comparisons. This is not the case for model-based techniques, where the
    human designer has the freedom to choose the internal dynamics of the algorithm.
    As a result, model-based techniques are not restricted to meta-learning good feature
    spaces, as they can also learn internal dynamics, used to process and predict
    input data of tasks.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，基于度量的方法的机制仅限于成对输入比较。对于基于模型的技术情况则不同，人为设计师可以自由选择算法的内部动态。因此，基于模型的技术不局限于元学习良好的特征空间，因为它们还可以学习内部动态，用于处理和预测任务的输入数据。
- en: More formally, given a support set $D^{tr}_{\mathcal{T}_{j}}$ corresponding
    to task $\mathcal{T}_{j}$, model-based techniques compute a class probability
    distribution for a new input $\boldsymbol{x}$ as
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，给定对应于任务 $\mathcal{T}_{j}$ 的支持集 $D^{tr}_{\mathcal{T}_{j}}$，基于模型的技术计算新输入
    $\boldsymbol{x}$ 的类别概率分布为
- en: '|  | $\displaystyle p_{\boldsymbol{\theta}}(Y&#124;\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})=f_{\boldsymbol{\theta}}(\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}}),$
    |  | (11) |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle p_{\boldsymbol{\theta}}(Y&#124;\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})=f_{\boldsymbol{\theta}}(\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}}),$
    |  | (11) |'
- en: where $f$ represents the black-box neural network model, and $\boldsymbol{\theta}$
    its parameters.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $f$ 代表黑箱神经网络模型，$\boldsymbol{\theta}$ 为其参数。
- en: 4.1 Example
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 示例
- en: 'Using the same example as in Section [3](#S3 "3 Metric-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning"), suppose we are given a task support set $D^{tr}_{\mathcal{T}_{j}}=\{([0,-4],1),([-2,-4],2),([-2,4],3),([6,0],4)\}$,
    where a tuple denotes a pair $(\boldsymbol{x}_{i},y_{i})$. Furthermore, suppose
    our query set only contains one example $D^{test}_{\mathcal{T}_{j}}=\{([4,0.5],4)\}$.
    This problem has been visualized in [Figure 5](#S3.F5 "Figure 5 ‣ 3 Metric-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning") (in Section [3](#S3 "3 Metric-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning")). For the sake of the example,
    we do not use an input embedding function: our model will operate on the raw inputs
    of $D^{tr}_{\mathcal{T}_{j}}$ and $D^{test}_{\mathcal{T}_{j}}$. As an internal
    state, our model uses an external memory matrix $M\in\mathbb{R}^{4\times(2+1)}$,
    with four rows (one for each example in our support set), and three columns (the
    dimensionality of input vectors, plus one dimension for the correct label). Our
    model proceeds to process the support set sequentially, reading the examples from
    $D^{tr}_{\mathcal{T}_{j}}$ one by one, and by storing the $i$-th example in the
    $i$-th row of the memory module. After processing the support set, the memory
    matrix contains all examples, and as such, serves as internal task representation.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 使用与第[3](#S3 "3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning")节相同的例子，假设我们给定了任务支持集
    $D^{tr}_{\mathcal{T}_{j}}=\{([0,-4],1),([-2,-4],2),([-2,4],3),([6,0],4)\}$，其中一个元组表示一对
    $(\boldsymbol{x}_{i},y_{i})$。进一步假设我们的查询集仅包含一个例子 $D^{test}_{\mathcal{T}_{j}}=\{([4,0.5],4)\}$。这个问题在[图5](#S3.F5
    "Figure 5 ‣ 3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning")（第[3](#S3
    "3 Metric-based Meta-Learning ‣ A Survey of Deep Meta-Learning")节）中得到了可视化。为了举例说明，我们不使用输入嵌入函数：我们的模型将对
    $D^{tr}_{\mathcal{T}_{j}}$ 和 $D^{test}_{\mathcal{T}_{j}}$ 的原始输入进行操作。作为内部状态，我们的模型使用外部记忆矩阵
    $M\in\mathbb{R}^{4\times(2+1)}$，具有四行（每个示例一行），和三列（输入向量的维度，加上一维正确标签）。我们的模型按顺序处理支持集，从
    $D^{tr}_{\mathcal{T}_{j}}$ 中逐一读取示例，并将第 $i$ 个示例存储在记忆模块的第 $i$ 行。处理完支持集后，记忆矩阵包含所有示例，并且作为内部任务表示。
- en: Given the new input $[4,0.5]$, our model could use many different techniques
    to make a prediction based on this representation. For simplicity, assume that
    it computes the dot product between $\boldsymbol{x}$, and every memory $M(i)$
    (the 2-D vector in the $i$-th row of $M$, ignoring the correct label), and predicts
    the class of the input which yields the largest dot product. This would produce
    scores $-2,-10,-6,$ and $24$ for the examples in $D^{tr}_{\mathcal{T}_{j}}$ respectively.
    Since the last example $[6,0]$ yields the largest dot product, we predict that
    class, i.e., $4$.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 给定新的输入 $[4,0.5]$，我们的模型可以使用许多不同的技术基于此表示进行预测。为简化起见，假设它计算 $\boldsymbol{x}$ 与每个记忆
    $M(i)$（$M$ 的第 $i$ 行中的二维向量，忽略正确标签）之间的点积，并预测点积最大的输入类别。这将为 $D^{tr}_{\mathcal{T}_{j}}$
    中的示例分别产生 $-2,-10,-6,$ 和 $24$ 的分数。由于最后一个示例 $[6,0]$ 产生了最大的点积，我们预测这个类别，即 $4$。
- en: Note that this example could be seen as a metric-based technique where the dot
    product is used as a similarity function. However, the reason that this technique
    is model-based is that it stores the entire task inside a memory module. This
    example was deliberately easy for illustrative purposes. More advanced and successful
    techniques have been proposed, which we will now cover.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这个例子可以被视为一种基于度量的技术，其中点积被用作相似度函数。然而，这种技术之所以是基于模型的原因在于它将整个任务存储在一个记忆模块中。这个例子被故意设计得简单以便于说明。已经提出了更先进和成功的技术，我们将现在介绍这些技术。
- en: 4.2 Recurrent Meta-Learners
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 递归元学习器
- en: Recurrent meta-learners (Duan et al., [2016](#bib.bib11); Wang et al., [2016](#bib.bib89))
    are, as the name suggests, meta-learners based on recurrent neural networks. The
    recurrent network serves as dynamic task embedding storage. These recurrent meta-learners
    were specifically proposed for reinforcement learning problems, hence we will
    explain them in that setting.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 递归元学习器（Duan et al., [2016](#bib.bib11); Wang et al., [2016](#bib.bib89)）顾名思义，是基于递归神经网络的元学习器。递归网络作为动态任务嵌入存储。这些递归元学习器专门针对强化学习问题提出，因此我们将在该背景下进行解释。
- en: The recurrence is implemented by e.g. an LSTM (Wang et al., [2016](#bib.bib89))
    or a GRU (Duan et al., [2016](#bib.bib11)). The internal dynamics of the chosen
    Recurrent Neural Network (RNN) allows for fast adaptation to new tasks, while
    the algorithm used to train the recurrent net gradually accumulates knowledge
    about the task structure, where each task is modelled as an episode (or set of
    episodes).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 递归是通过例如 LSTM（Wang et al., [2016](#bib.bib89)）或 GRU（Duan et al., [2016](#bib.bib11)）来实现的。所选递归神经网络（RNN）的内部动态允许快速适应新任务，而用于训练递归网络的算法逐渐积累对任务结构的知识，其中每个任务被建模为一个情节（或一组情节）。
- en: The idea of recurrent meta-learners is quite simple. That is, given a task $\mathcal{T}_{j}$,
    we simply feed the (potentially processed) environment variables $[s_{t+1},a_{t},r_{t},d_{t}]$
    (see [Section 2.1.3](#S2.SS1.SSS3 "2.1.3 Regular Reinforcement Learning ‣ 2.1
    The Meta Abstraction ‣ 2 Foundation ‣ A Survey of Deep Meta-Learning")) into an
    RNN at every time step $t$. Recall that $s,a,r,d$ denote the state, action, reward,
    and termination flag respectively. At every time step $t$, the RNN outputs an
    action and a hidden state. Conditioned on its hidden state $h_{t}$, the network
    outputs an action $a_{t}$. The goal is to maximize the expected reward in each
    trial. See [Figure 12](#S4.F12 "Figure 12 ‣ 4.2 Recurrent Meta-Learners ‣ 4 Model-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning") for a visual depiction. From
    this figure, it also becomes clear why these techniques are model-based. That
    is, they embed information from previously seen inputs in the hidden state.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 递归元学习器的理念非常简单。即给定一个任务 $\mathcal{T}_{j}$，我们只需将（可能处理过的）环境变量 $[s_{t+1},a_{t},r_{t},d_{t}]$（见
    [第2.1.3节](#S2.SS1.SSS3 "2.1.3 常规强化学习 ‣ 2.1 元抽象 ‣ 2 基础 ‣ 深度元学习调查")）输入到每个时间步 $t$
    的 RNN 中。回忆一下，$s,a,r,d$ 分别表示状态、动作、奖励和终止标志。在每个时间步 $t$，RNN 输出一个动作和一个隐藏状态。在其隐藏状态 $h_{t}$
    的条件下，网络输出一个动作 $a_{t}$。目标是在每次试验中最大化预期奖励。参见 [图12](#S4.F12 "图 12 ‣ 4.2 递归元学习器 ‣ 4
    基于模型的元学习 ‣ 深度元学习调查") 的可视化描述。从这个图中也可以清楚地看到为什么这些技术是基于模型的。也就是说，它们将之前见过的输入的信息嵌入到隐藏状态中。
- en: '![Refer to caption](img/4a3b50d9e177eb99c26cdc65270bd7db.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/4a3b50d9e177eb99c26cdc65270bd7db.png)'
- en: 'Figure 12: Workflow of recurrent meta-learners in reinforcement learning contexts.
    As mentioned in [Section 2.1.3](#S2.SS1.SSS3 "2.1.3 Regular Reinforcement Learning
    ‣ 2.1 The Meta Abstraction ‣ 2 Foundation ‣ A Survey of Deep Meta-Learning"),
    $s_{t},r_{t},$ and $d_{t}$ denote the state, reward, and termination flag at time
    step $t$. $h_{t}$ refers to the hidden state at time $t$. Source: Duan et al.
    ([2016](#bib.bib11)).'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：在强化学习背景下的递归元学习者的工作流程。如[第2.1.3节](#S2.SS1.SSS3 "2.1.3 常规强化学习 ‣ 2.1 元抽象 ‣ 2
    基础 ‣ 深度元学习综述")中提到，$s_{t},r_{t},$ 和 $d_{t}$ 分别表示时间步 $t$ 的状态、奖励和终止标志。$h_{t}$ 指的是时间
    $t$ 的隐藏状态。来源：Duan等 ([2016](#bib.bib11))。
- en: Recurrent meta-learners have shown to perform almost as well as asymptotically
    optimal algorithms on simple reinforcement learning tasks (Wang et al., [2016](#bib.bib89);
    Duan et al., [2016](#bib.bib11)). However, their performance degrades in more
    complex settings, where temporal dependencies can span a longer horizon. Making
    recurrent meta-learners better at such complex tasks is a direction for future
    research.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 递归元学习者在简单的强化学习任务中表现几乎与渐近最优算法相当（Wang等，[2016](#bib.bib89)；Duan等，[2016](#bib.bib11)）。然而，在更复杂的环境中，其性能会下降，因为时间依赖关系可能跨越较长的时间范围。使递归元学习者在这些复杂任务中表现更好是未来研究的方向。
- en: 4.3 Memory-Augmented Neural Networks (MANNs)
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 记忆增强神经网络 (MANNs)
- en: The key idea of memory-augmented neural networks (MANNs) (Santoro et al., [2016](#bib.bib68))
    is to enable neural networks to learn quickly with the help of an external memory.
    The main controller (the recurrent neural network interacting with the memory)
    then gradually accumulates knowledge across tasks, while the external memory allows
    for quick task-specific adaptation. For this, Santoro et al. ([2016](#bib.bib68))
    used Neural Turing Machines (Graves et al., [2014](#bib.bib24)). Here, the controller
    is parameterized by $\boldsymbol{\theta}$ and acts as the long-term memory of
    the memory-augmented neural network, while the external memory module is the short-term
    memory.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆增强神经网络 (MANNs) 的关键思想是通过外部记忆帮助神经网络快速学习。主要控制器（与记忆交互的递归神经网络）逐渐在任务间积累知识，而外部记忆则允许快速的任务特定适应。为此，Santoro等
    ([2016](#bib.bib68)) 使用了神经图灵机 (Graves等，[2014](#bib.bib24))。这里，控制器由 $\boldsymbol{\theta}$
    参数化，并作为记忆增强神经网络的长期记忆，而外部记忆模块则是短期记忆。
- en: The workflow of memory-augmented neural networks is displayed in [Figure 13](#S4.F13
    "Figure 13 ‣ 4.3 Memory-Augmented Neural Networks (MANNs) ‣ 4 Model-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning"). Note that the data from a task is processed
    as a sequence, i.e., data are fed into the network one by one. The support set
    is fed into the memory-augmented neural network first. Afterwards, the query set
    is processed. During the meta-train phase, training tasks can be fed into the
    network in arbitrary order. At time step $t$, the model receives input $\boldsymbol{x}_{t}$
    with the label of the previous input, i.e., $y_{t-1}$. This was done to prevent
    the network from mapping class labels directly to the output (Santoro et al.,
    [2016](#bib.bib68)).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆增强神经网络的工作流程显示在[图13](#S4.F13 "图13 ‣ 4.3 记忆增强神经网络 (MANNs) ‣ 4 基于模型的元学习 ‣ 深度元学习综述")中。请注意，任务的数据被处理为序列，即数据一个接一个地输入到网络中。支持集首先被输入到记忆增强神经网络中。然后处理查询集。在元训练阶段，训练任务可以以任意顺序输入到网络中。在时间步
    $t$，模型接收带有前一个输入标签的输入 $\boldsymbol{x}_{t}$，即 $y_{t-1}$。这样做是为了防止网络将类别标签直接映射到输出（Santoro等，[2016](#bib.bib68)）。
- en: '![Refer to caption](img/6b4af1929e04789ef50728d500885d16.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/6b4af1929e04789ef50728d500885d16.png)'
- en: '-'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '-'
- en: 'Figure 13: Workflow of memory-augmented neural networks. Here, an episode corresponds
    to a given task $\mathcal{T}_{j}$. After every episode, the order of labels, classes,
    and samples should be shuffled to minimize dependence on arbitrarily assigned
    orders. Source: Santoro et al. ([2016](#bib.bib68)).'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图13：记忆增强神经网络的工作流程。在这里，一个回合对应于一个给定的任务 $\mathcal{T}_{j}$。每个回合后，标签、类别和样本的顺序应被打乱，以最小化对任意分配顺序的依赖。来源：Santoro等
    ([2016](#bib.bib68))。
- en: '![Refer to caption](img/f5a1bd2a29edfedc346bfc5a2976895a.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/f5a1bd2a29edfedc346bfc5a2976895a.png)'
- en: 'Figure 14: Controller-memory interaction in memory-augmented neural networks.
    Source: Santoro et al. ([2016](#bib.bib68)).'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：记忆增强神经网络中的控制器-记忆交互。来源：Santoro等 ([2016](#bib.bib68))。
- en: The interaction between the controller and memory is visualized in [Figure 14](#S4.F14
    "Figure 14 ‣ 4.3 Memory-Augmented Neural Networks (MANNs) ‣ 4 Model-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning"). The idea is that the external memory module,
    containing representations of previously seen inputs, can be used to make predictions
    for new inputs. In short, previously obtained knowledge is leveraged to aid the
    classification of new inputs. Note that neural networks also attempt to do this,
    however, their prior knowledge is slowly accumulated into the network weights,
    while an external memory module can directly store such information.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器与记忆之间的交互在[图 14](#S4.F14 "Figure 14 ‣ 4.3 Memory-Augmented Neural Networks
    (MANNs) ‣ 4 Model-based Meta-Learning ‣ A Survey of Deep Meta-Learning")中进行了可视化。其思想是，包含之前见过的输入表示的外部记忆模块可以用于对新输入进行预测。简而言之，利用之前获得的知识来帮助对新输入进行分类。请注意，神经网络也尝试做到这一点，但它们的先验知识是慢慢积累到网络权重中的，而外部记忆模块可以直接存储这些信息。
- en: Given an input $\boldsymbol{x}_{t}$ at time $t$, the controller generates a
    key $\boldsymbol{k}_{t}$, which can be stored in memory matrix $M$ and can be
    used to retrieve previous representations from memory matrix $M$. When reading
    from memory, the aim is to produce a linear combination of stored keys in memory
    matrix $M$, giving greater weight to those which have a larger cosine similarity
    with the current key $\boldsymbol{k}_{t}$. More specifically, a read vector $\boldsymbol{w}^{r}_{t}$
    is created, in which each entry $i$ denotes the cosine similarity between key
    $\boldsymbol{k}_{t}$ and the memory (from a previous input) stored in row $i$,
    i.e., $M_{t}(i)$. Then, the representation $\boldsymbol{r}_{t}=\sum_{i}w_{t}^{r}(i)M(i)$
    is retrieved, which is simply a linear combination of all keys (i.e., rows) in
    memory matrix $M$.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 给定在时间$t$的输入$\boldsymbol{x}_{t}$，控制器生成一个键$\boldsymbol{k}_{t}$，该键可以存储在记忆矩阵$M$中，并可用于从记忆矩阵$M$中检索之前的表示。在从记忆中读取时，目标是产生存储在记忆矩阵$M$中的键的线性组合，给那些与当前键$\boldsymbol{k}_{t}$具有更大余弦相似度的键赋予更大的权重。更具体地说，创建一个读取向量$\boldsymbol{w}^{r}_{t}$，其中每个条目$i$表示键$\boldsymbol{k}_{t}$与存储在第$i$行的记忆（来自之前的输入）之间的余弦相似度，即$M_{t}(i)$。然后，检索表示$\boldsymbol{r}_{t}=\sum_{i}w_{t}^{r}(i)M(i)$，这只是记忆矩阵$M$中所有键（即行）的线性组合。
- en: Predictions are made as follows. Given an input $\boldsymbol{x}_{t}$, memory-augmented
    neural networks use the external memory to compute the corresponding representation
    $\boldsymbol{r}_{t}$, which could be fed into a softmax layer, resulting in class
    probabilities. Across tasks, memory-augmented neural networks learn a good input
    embedding function $f_{\boldsymbol{\theta}}$ and classifier weights, which can
    be exploited when presented with new tasks.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 预测如下进行。给定输入$\boldsymbol{x}_{t}$，记忆增强神经网络使用外部记忆计算相应的表示$\boldsymbol{r}_{t}$，该表示可以输入到softmax层中，得到类别概率。在各种任务中，记忆增强神经网络学习到一个好的输入嵌入函数$f_{\boldsymbol{\theta}}$和分类器权重，这些可以在面对新任务时加以利用。
- en: 'To write input representations to memory, Santoro et al. ([2016](#bib.bib68))
    propose a new mechanism called Least Recently Used Access (LRUA). LRUA either
    writes to the least, or most recently used memory location. In the former case,
    it preserves recent memories, and in the latter it updates recently obtained information.
    The writing mechanism works by keeping track of how often every memory location
    is accessed in a usage vector $\boldsymbol{w}_{t}^{u}$, which is updated at every
    time step according to the following update rule: $\boldsymbol{w}_{t}^{u}:=\gamma\boldsymbol{w}^{u}_{t-1}+\boldsymbol{w}_{t}^{r}+\boldsymbol{w}_{t}^{w}$,
    where superscripts $u,w$ and $r$ refer to usage, write and read vectors, respectively.
    In words, the previous usage vector is decayed (using parameter $\gamma$), while
    current reads ($\boldsymbol{w}_{t}^{r}$) and writes ($\boldsymbol{w}_{t}^{w}$)
    are added to the usage. Let $n$ be the total number of reads to memory, and $\ell
    u(n)$ ($\ell u$ for ‘least used’) be the $n$-th smallest value in the usage vector
    $\boldsymbol{w}^{u}_{t}$. Then, the least-used weights are defined as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将输入表示写入记忆，Santoro 等人 ([2016](#bib.bib68)) 提出了一个新的机制，称为“最近最少使用访问”（LRUA）。LRUA
    要么写入最近最少使用的位置，要么写入最近使用的位置。在前一种情况下，它保留了最近的记忆；在后一种情况下，它更新了最近获得的信息。该写入机制通过在使用向量 $\boldsymbol{w}_{t}^{u}$
    中跟踪每个记忆位置的访问频率来工作，该向量根据以下更新规则在每个时间步骤中更新：$\boldsymbol{w}_{t}^{u}:=\gamma\boldsymbol{w}^{u}_{t-1}+\boldsymbol{w}_{t}^{r}+\boldsymbol{w}_{t}^{w}$，其中上标
    $u,w$ 和 $r$ 分别指使用、写入和读取向量。用语言来说，之前的使用向量会衰减（使用参数 $\gamma$），同时当前的读取（$\boldsymbol{w}_{t}^{r}$）和写入（$\boldsymbol{w}_{t}^{w}$）被添加到使用向量中。设
    $n$ 为对记忆的读取总数，$\ell u(n)$（$\ell u$ 代表“最少使用”）为使用向量 $\boldsymbol{w}^{u}_{t}$ 中第
    $n$ 小的值。那么，最少使用的权重定义如下：
- en: '|  | $\boldsymbol{w}^{\ell u}_{t}(i)=\begin{cases}0&amp;\text{if $w^{u}_{t}(i)>\ell
    u(n)$}\\ 1&amp;else\end{cases}.$ |  |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{w}^{\ell u}_{t}(i)=\begin{cases}0&\text{如果 $w^{u}_{t}(i)>\ell
    u(n)$}\\ 1&\text{否则}\end{cases}.$ |  |'
- en: 'Then, the write vector $\boldsymbol{w}_{t}^{w}$ is computed as $\boldsymbol{w}^{w}_{t}=\sigma(\alpha)\boldsymbol{w}^{r}_{t-1}+(1-\sigma(\alpha))\boldsymbol{w}^{\ell
    u}_{t-1}$, where $\alpha$ is a parameter that interpolates between the two weight
    vectors. As such, if $\sigma(\alpha)=1$, we write to the most recently used memory,
    whereas when $\sigma(\alpha)=0$, we write to the least recently used memory locations.
    Finally, writing is performed as follows: $M_{t}(i):=M_{t-1}(i)+w_{t}^{w}(i)\boldsymbol{k}_{t}$,
    for all $i$.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，写入向量 $\boldsymbol{w}_{t}^{w}$ 计算为 $\boldsymbol{w}^{w}_{t}=\sigma(\alpha)\boldsymbol{w}^{r}_{t-1}+(1-\sigma(\alpha))\boldsymbol{w}^{\ell
    u}_{t-1}$，其中 $\alpha$ 是一个在两个权重向量之间插值的参数。因此，如果 $\sigma(\alpha)=1$，我们写入最近使用的记忆；而当
    $\sigma(\alpha)=0$ 时，我们写入最少使用的记忆位置。最后，写入的操作如下：$M_{t}(i):=M_{t-1}(i)+w_{t}^{w}(i)\boldsymbol{k}_{t}$，对所有
    $i$。
- en: In summary, memory-augmented neural networks (Santoro et al., [2016](#bib.bib68))
    combine external memory and a neural network to achieve meta-learning. The interaction
    between a controller, with long-term memory parameters $\boldsymbol{\theta}$,
    and memory $M$, may also be interesting for studying human meta-learning (Santoro
    et al., [2016](#bib.bib68)). In contrast to many metric-based techniques, this
    model-based technique is applicable to both classification and regression problems.
    A downside of this approach is the architectural complexity.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 总结而言，记忆增强神经网络（Santoro 等人，[2016](#bib.bib68)）结合了外部记忆和神经网络以实现元学习。一个具有长期记忆参数 $\boldsymbol{\theta}$
    的控制器与记忆 $M$ 之间的互动，也可能对研究人类元学习有趣（Santoro 等人，[2016](#bib.bib68)）。与许多基于度量的技术相比，这种基于模型的技术适用于分类和回归问题。这种方法的一个缺点是架构复杂性。
- en: 4.4 Meta Networks
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 Meta网络
- en: '![Refer to caption](img/84a56d9bf1098190499723add9a8bb61.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/84a56d9bf1098190499723add9a8bb61.png)'
- en: 'Figure 15: Architecture of a Meta Network. Source: Munkhdalai and Yu ([2017](#bib.bib55)).'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图15：Meta网络的架构。来源：Munkhdalai 和 Yu ([2017](#bib.bib55))。
- en: Meta networks are divided into two distinct subsystems (consisting of neural
    networks), i.e., the base- and meta-learner (whereas in memory-augmented neural
    networks the base- and meta-components are intertwined). The base-learner is responsible
    for performing tasks, and for providing the meta-learner with meta-information,
    such as loss gradients. The meta-learner can then compute fast task-specific weights
    for itself and the base-learner, such that it can perform better on the given
    task $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$.
    This workflow is depicted in [Figure 15](#S4.F15 "Figure 15 ‣ 4.4 Meta Networks
    ‣ 4 Model-based Meta-Learning ‣ A Survey of Deep Meta-Learning").
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 元网络被划分为两个不同的子系统（由神经网络组成），即基本学习器和元学习器（而在记忆增强型神经网络中，基本组件和元组件是交织在一起的）。基本学习器负责执行任务，并向元学习器提供元信息，如损失梯度。然后，元学习器可以为自己和基本学习器计算任务特定的快速权重，以便在给定任务
    $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$ 上表现更好。这个工作流程如[图
    15](#S4.F15 "Figure 15 ‣ 4.4 Meta Networks ‣ 4 Model-based Meta-Learning ‣ A Survey
    of Deep Meta-Learning")所示。
- en: The meta-learner consists of neural networks $u_{\boldsymbol{\phi}},m_{\boldsymbol{\varphi}}$,
    and $d_{\boldsymbol{\psi}}$. Network $u_{\boldsymbol{\phi}}$ is used as input
    representation function. Networks $d_{\boldsymbol{\psi}}$ and $m_{\boldsymbol{\varphi}}$
    are used to compute task-specific weights $\boldsymbol{\phi}^{*}$ and example-level
    fast weights $\boldsymbol{\theta}^{*}$. Lastly, $b_{\boldsymbol{\theta}}$ is the
    base-learner which performs input predictions. Note that we used the term fast-weights
    throughout, which refers to task- or input-specific versions of slow (initial)
    weights.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 元学习器由神经网络 $u_{\boldsymbol{\phi}},m_{\boldsymbol{\varphi}}$ 和 $d_{\boldsymbol{\psi}}$
    组成。网络 $u_{\boldsymbol{\phi}}$ 用作输入表示函数。网络 $d_{\boldsymbol{\psi}}$ 和 $m_{\boldsymbol{\varphi}}$
    用于计算任务特定的权重 $\boldsymbol{\phi}^{*}$ 和示例级快速权重 $\boldsymbol{\theta}^{*}$。最后，$b_{\boldsymbol{\theta}}$
    是基本学习器，负责执行输入预测。请注意，我们在整个过程中使用了“快速权重”一词，指的是任务或输入特定的慢（初始）权重版本。
- en: In similar fashion to memory-augmented neural networks (Santoro et al., [2016](#bib.bib68)),
    meta networks (Munkhdalai and Yu, [2017](#bib.bib55)) also leverage the idea of
    an external memory module. However, meta networks use the memory for a different
    purpose. The memory stores for each observation $\boldsymbol{x}_{i}$ in the support
    set two components, i.e., its representation $\boldsymbol{r}_{i}$ and the fast
    weights $\boldsymbol{\theta}_{i}^{*}$. These are then used to compute a attention-based
    representation and fast weights for new inputs, respectively.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 与记忆增强型神经网络（Santoro 等，[2016](#bib.bib68)）类似，元网络（Munkhdalai 和 Yu，[2017](#bib.bib55)）也利用了外部记忆模块的思想。然而，元网络将内存用于不同的目的。内存为支持集中的每个观察
    $\boldsymbol{x}_{i}$ 存储两个组件，即其表示 $\boldsymbol{r}_{i}$ 和快速权重 $\boldsymbol{\theta}_{i}^{*}$。这些组件随后用于计算基于注意力的表示和新输入的快速权重。
- en: Algorithm 1 Meta networks, by Munkhdalai and Yu ([2017](#bib.bib55))
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 元网络，作者：Munkhdalai 和 Yu ([2017](#bib.bib55))
- en: 1:Sample $S=\{(\boldsymbol{x}_{i},y_{i})\backsim D^{tr}_{\mathcal{T}_{j}}\}_{i=1}^{T}$
    from the support set2:for $(\boldsymbol{x}_{i},y_{i})\in S$ do3:     $\mathcal{L}_{i}=\mbox{error}(u_{\boldsymbol{\phi}}(\boldsymbol{x}_{i}),y_{i})$4:end for5:$\boldsymbol{\phi}^{*}=d_{\boldsymbol{\psi}}(\{\nabla_{\boldsymbol{\phi}}\mathcal{L}_{i}\}_{i=1}^{T})$6:for $(\boldsymbol{x}_{i},y_{i})\in
    D^{tr}_{\mathcal{T}_{j}}$ do7:     $\mathcal{L}_{i}=\mbox{error}(b_{\boldsymbol{\theta}}(\boldsymbol{x}_{i}),y_{i})$8:     $\boldsymbol{\theta}_{i}^{*}=m_{\boldsymbol{\varphi}}(\nabla_{\boldsymbol{\theta}}\mathcal{L}_{i})$9:     Store
    $\boldsymbol{\theta}_{i}^{*}$ in $i$-th position of example-level weight memory
    $M$10:     $\boldsymbol{r}_{i}=u_{\boldsymbol{\phi},\boldsymbol{\phi}^{*}}(\boldsymbol{x}_{i})$11:     Store
    $\boldsymbol{r}_{i}$ in $i$-th position of representation memory $R$12:end for13:$\mathcal{L}_{task}=0$14:for $(\boldsymbol{x},y)\in
    D^{test}_{\mathcal{T}_{j}}$ do15:     $\boldsymbol{r}=u_{\boldsymbol{\phi},\boldsymbol{\phi}^{*}}(\boldsymbol{x})$16:     $\boldsymbol{a}=\mbox{attention}(R,\boldsymbol{r})$
    $\triangleright$ $a_{k}$ is the cosine similarity between $\boldsymbol{r}$ and
    $R(k)$17:     $\boldsymbol{\theta}^{*}=\mbox{softmax}(\boldsymbol{a})^{T}M$18:     $\mathcal{L}_{task}=\mathcal{L}_{task}+\mbox{error}(b_{\boldsymbol{\theta},\boldsymbol{\theta}^{*}}(\boldsymbol{x}),y)$19:end for20:Update
    $\Theta=\{\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{\psi},\boldsymbol{\varphi}\}$
    using $\nabla_{\Theta}\mathcal{L}_{task}$
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 从支持集采样$S=\{(\boldsymbol{x}_{i},y_{i})\backsim D^{tr}_{\mathcal{T}_{j}}\}_{i=1}^{T}$：2：对 $(\boldsymbol{x}_{i},y_{i})\in
    S$ 执行3：     $\mathcal{L}_{i}=\mbox{error}(u_{\boldsymbol{\phi}}(\boldsymbol{x}_{i}),y_{i})$4：结束 for5：$\boldsymbol{\phi}^{*}=d_{\boldsymbol{\psi}}(\{\nabla_{\boldsymbol{\phi}}\mathcal{L}_{i}\}_{i=1}^{T})$6：对 $(\boldsymbol{x}_{i},y_{i})\in
    D^{tr}_{\mathcal{T}_{j}}$ 执行7：     $\mathcal{L}_{i}=\mbox{error}(b_{\boldsymbol{\theta}}(\boldsymbol{x}_{i}),y_{i})$8：     $\boldsymbol{\theta}_{i}^{*}=m_{\boldsymbol{\varphi}}(\nabla_{\boldsymbol{\theta}}\mathcal{L}_{i})$9：     将
    $\boldsymbol{\theta}_{i}^{*}$ 存储在第 $i$ 个位置的示例级权重记忆 $M$ 中10：     $\boldsymbol{r}_{i}=u_{\boldsymbol{\phi},\boldsymbol{\phi}^{*}}(\boldsymbol{x}_{i})$11：     将
    $\boldsymbol{r}_{i}$ 存储在第 $i$ 个位置的表示记忆 $R$ 中12：结束 for13：$\mathcal{L}_{task}=0$14：对 $(\boldsymbol{x},y)\in
    D^{test}_{\mathcal{T}_{j}}$ 执行15：     $\boldsymbol{r}=u_{\boldsymbol{\phi},\boldsymbol{\phi}^{*}}(\boldsymbol{x})$16：     $\boldsymbol{a}=\mbox{attention}(R,\boldsymbol{r})$
    $\triangleright$ $a_{k}$ 是 $\boldsymbol{r}$ 和 $R(k)$ 之间的余弦相似度17：     $\boldsymbol{\theta}^{*}=\mbox{softmax}(\boldsymbol{a})^{T}M$18：     $\mathcal{L}_{task}=\mathcal{L}_{task}+\mbox{error}(b_{\boldsymbol{\theta},\boldsymbol{\theta}^{*}}(\boldsymbol{x}),y)$19：结束 for20：使用
    $\nabla_{\Theta}\mathcal{L}_{task}$ 更新 $\Theta=\{\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{\psi},\boldsymbol{\varphi}\}$
- en: The pseudocode for meta networks is displayed in [Algorithm 1](#alg1 "Algorithm
    1 ‣ 4.4 Meta Networks ‣ 4 Model-based Meta-Learning ‣ A Survey of Deep Meta-Learning").
    First, a sample of the support set is created (line 1), which is used to compute
    task-specific weights $\boldsymbol{\phi}^{*}$ for the representation network $u_{\boldsymbol{\phi}}$
    (lines 2-5). Note that $u_{\boldsymbol{\phi}}$ has two tasks, i) it should compute
    a representation for inputs $(\boldsymbol{x}_{i}$ (line 10 and 15), and ii) it
    needs to make predictions for inputs $(\boldsymbol{x}_{i}$, in order to compute
    a loss (line 3). To achieve both goals, a conventional neural network can be used
    that makes class predictions. The states of the final hidden layer are then used
    as representations. Typically, the cross entropy is calculated over the predictions
    of representation network $u_{\boldsymbol{\phi}}$. When there are multiple examples
    per class in the support set, an alternative is to use a contrastive loss function
    (Munkhdalai and Yu, [2017](#bib.bib55)).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 元网络的伪代码展示在[算法 1](#alg1 "Algorithm 1 ‣ 4.4 Meta Networks ‣ 4 Model-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning")中。首先，创建一个支持集的样本（第1行），用于计算表示网络 $u_{\boldsymbol{\phi}}$
    的任务特定权重 $\boldsymbol{\phi}^{*}$（第2-5行）。注意，$u_{\boldsymbol{\phi}}$ 有两个任务：i）它应为输入
    $(\boldsymbol{x}_{i}$ 计算表示（第10行和15行），ii）它需要对输入 $(\boldsymbol{x}_{i}$ 进行预测，以计算损失（第3行）。为了实现这两个目标，可以使用传统的神经网络来进行分类预测。最终隐藏层的状态随后被用作表示。通常，计算表示网络
    $u_{\boldsymbol{\phi}}$ 的预测的交叉熵。当支持集中每个类别有多个示例时，可以选择使用对比损失函数（Munkhdalai 和 Yu，[2017](#bib.bib55)）。
- en: Then, meta networks iterate over every example $(\boldsymbol{x}_{i},y_{i})$
    in the support set $D^{tr}_{\mathcal{T}_{j}}$. The base-learner $b_{\boldsymbol{\theta}}$
    attempts to make class predictions for these examples, resulting in loss values
    $\mathcal{L}_{i}$ (line 7-8). The gradients of these losses are used to compute
    fast weights $\boldsymbol{\theta}^{*}$ for example $i$ (line 8), which are then
    stored in the $i$-th row of memory matrix $M$ (line 9). Additionally, input representations
    $\boldsymbol{r}_{i}$ are computed and stored in memory matrix $R$ (lines 10-11).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，元网络遍历支持集 $D^{tr}_{\mathcal{T}_{j}}$ 中的每个示例 $(\boldsymbol{x}_{i},y_{i})$。基本学习器
    $b_{\boldsymbol{\theta}}$ 尝试对这些示例进行类别预测，结果生成损失值 $\mathcal{L}_{i}$（第7-8行）。这些损失的梯度用于计算示例
    $i$ 的快权重 $\boldsymbol{\theta}^{*}$（第8行），然后存储在内存矩阵 $M$ 的第 $i$ 行（第9行）。此外，输入表示 $\boldsymbol{r}_{i}$
    被计算并存储在内存矩阵 $R$ 中（第10-11行）。
- en: Now, meta networks are ready to address the query set $D^{test}_{\mathcal{T}_{j}}$.
    They iterate over every example $(\boldsymbol{x},y)$, and compute a representation
    $\boldsymbol{r}$ of it (line 15). This representation is matched against the representations
    of the support set, which are stored in memory matrix $R$. This matching gives
    us a similarity vector $\boldsymbol{a}$, where every entry $k$ denotes the similarity
    between input representation $\boldsymbol{r}$ and the $k$-th row in memory matrix
    R, i.e., $R(k)$ (line 16). A softmax over this similarity vector is performed
    to normalize the entries. The resulting vector is used to compute a linear combination
    of weights that were generated for inputs in the support set (line 17). These
    weights $\boldsymbol{\theta}^{*}$ are specific for input $\boldsymbol{x}$ in the
    query set and can be used by the base-learner $b$ to make predictions for that
    input (line 18). The observed error is added to the task loss. After the entire
    query set is processed, all involved parameters can be updated using backpropagation
    (line 20).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，元网络已准备好处理查询集 $D^{test}_{\mathcal{T}_{j}}$。它们遍历每个示例 $(\boldsymbol{x},y)$，并计算其表示
    $\boldsymbol{r}$（第15行）。该表示与存储在内存矩阵 $R$ 中的支持集的表示进行匹配。这种匹配生成了一个相似度向量 $\boldsymbol{a}$，其中每个条目
    $k$ 表示输入表示 $\boldsymbol{r}$ 与内存矩阵 $R$ 中第 $k$ 行的相似度，即 $R(k)$（第16行）。对该相似度向量进行 softmax
    以归一化条目。结果向量用于计算对支持集输入生成的权重的线性组合（第17行）。这些权重 $\boldsymbol{\theta}^{*}$ 对查询集中输入 $\boldsymbol{x}$
    是特定的，可以被基本学习器 $b$ 用于对该输入进行预测（第18行）。观察到的错误被添加到任务损失中。处理完所有查询集后，可以使用反向传播更新所有相关参数（第20行）。
- en: '![Refer to caption](img/864ab7d009d7fb5f840ea950043e2260.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/864ab7d009d7fb5f840ea950043e2260.png)'
- en: 'Figure 16: Layer augmentation setup used to combine slow and fast weights.
    Source: Munkhdalai and Yu ([2017](#bib.bib55)).'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图16：用于结合慢权重和快权重的层级增强设置。来源：Munkhdalai 和 Yu ([2017](#bib.bib55))。
- en: Note that some neural networks use both slow- and fast-weights at the same time.
    Munkhdalai and Yu ([2017](#bib.bib55)) use a so-called augmentation setup for
    this, as depicted in [Figure 16](#S4.F16 "Figure 16 ‣ 4.4 Meta Networks ‣ 4 Model-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning").
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，一些神经网络同时使用慢权重和快权重。Munkhdalai 和 Yu ([2017](#bib.bib55)) 使用了一种所谓的增强设置，如[图16](#S4.F16
    "Figure 16 ‣ 4.4 Meta Networks ‣ 4 Model-based Meta-Learning ‣ A Survey of Deep
    Meta-Learning")所示。
- en: In short, meta networks rely on a reparameterization of the meta- and base-learner
    for every task. Despite the flexibility and applicability to both supervised and
    reinforcement learning settings, the approach is quite complex. It consists of
    many components, each with its own set of parameters, which can be a burden on
    memory usage and computation time. Additionally, finding the correct architecture
    for all the involved components can be time-consuming.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，元网络依赖于每个任务的元学习器和基本学习器的重新参数化。尽管该方法对监督学习和强化学习环境具有灵活性和适用性，但其复杂性相当高。它由许多组件组成，每个组件都有自己的一套参数，这可能会对内存使用和计算时间造成负担。此外，找到所有相关组件的正确架构可能会耗费时间。
- en: 4.5 Simple Neural Attentive Meta-Learner (SNAIL)
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 简单神经注意力元学习器 (SNAIL)
- en: Instead of an external memory matrix, SNAIL (Mishra et al., [2018](#bib.bib52))
    relies on a special model architecture to serve as memory. Mishra et al. ([2018](#bib.bib52))
    argue that it is not possible to use Recurrent Neural Networks for this, as they
    have limited memory capacity, and cannot pinpoint specific prior experiences (Mishra
    et al., [2018](#bib.bib52)). Hence, SNAIL uses a different architecture, consisting
    of 1D temporal convolutions (Oord et al., [2016](#bib.bib59)) and a soft attention
    mechanism (Vaswani et al., [2017](#bib.bib84)). The temporal convolutions allow
    for ‘high bandwidth’ memory access, and the attention mechanism allows one to
    pinpoint specific experiences. [Figure 17](#S4.F17 "Figure 17 ‣ 4.5 Simple Neural
    Attentive Meta-Learner (SNAIL) ‣ 4 Model-based Meta-Learning ‣ A Survey of Deep
    Meta-Learning") visualizes the architecture and workflow of SNAIL for supervised
    learning problems. From this figure, it becomes clear why this technique is model-based.
    That is, model outputs are based upon the internal state, computed from earlier
    inputs.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: SNAIL（Mishra 等，[2018](#bib.bib52)）不是依赖外部记忆矩阵，而是依靠一种特殊的模型架构来充当记忆。Mishra 等人（[2018](#bib.bib52)）认为，使用递归神经网络是不可能的，因为它们的记忆容量有限，无法精确定位特定的先前经验（Mishra
    等人，[2018](#bib.bib52)）。因此，SNAIL 使用了不同的架构，包括 1D 时间卷积（Oord 等人，[2016](#bib.bib59)）和软注意机制（Vaswani
    等人，[2017](#bib.bib84)）。时间卷积允许“高带宽”记忆访问，注意机制则允许精准定位特定经验。[图 17](#S4.F17 "Figure
    17 ‣ 4.5 Simple Neural Attentive Meta-Learner (SNAIL) ‣ 4 Model-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning") 可视化了 SNAIL 在监督学习问题中的架构和工作流程。从此图中，可以清楚地看出为什么这种技术是基于模型的。也就是说，模型输出基于内部状态，该状态是从早期输入中计算得出的。
- en: '![Refer to caption](img/0e70d5ca0687b28bd747f46f182d1d17.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/0e70d5ca0687b28bd747f46f182d1d17.png)'
- en: 'Figure 17: Architecture and workflow of SNAIL for supervised and reinforcement
    learning settings. The input layer is red. Temporal Convolution blocks are orange;
    attention blocks are green. Source: Mishra et al. ([2018](#bib.bib52)).'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17：SNAIL 在监督和强化学习设置中的架构和工作流程。输入层为红色。时间卷积块为橙色；注意块为绿色。来源：Mishra 等人（[2018](#bib.bib52)）。
- en: SNAIL consists of three building blocks. The first is the DenseBlock, which
    applies a single 1D convolution to the input, and concatenates (in the feature/horizontal
    direction) the result. The second is a TCBlock, which is simply a series of DenseBlocks
    with exponentially increasing dilation rate of the temporal convolutions (Mishra
    et al., [2018](#bib.bib52)). Note that the dilation is nothing but the temporal
    distance between two nodes in a network. For example, if we use a dilation of
    2, a node at position $p$ in layer $L$ will receive the activation from node $p-2$
    from layer $L-1$. The third block is the AttentionBlock, which learns to focus
    on the important parts of prior experience.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: SNAIL 由三个构建块组成。第一个是 DenseBlock，它对输入应用单一的 1D 卷积，并在特征/水平方向上连接结果。第二个是 TCBlock，它实际上是一系列具有指数增加的时间卷积膨胀率的
    DenseBlocks（Mishra 等，[2018](#bib.bib52)）。请注意，膨胀率仅仅是网络中两个节点之间的时间距离。例如，如果使用膨胀率 2，则在层
    $L$ 中位置为 $p$ 的节点将接收来自层 $L-1$ 中位置为 $p-2$ 的节点的激活。第三个块是 AttentionBlock，它学习专注于先前经验中的重要部分。
- en: In similar fashion to memory-augmented neural networks (Santoro et al., [2016](#bib.bib68))
    ([Section 4.3](#S4.SS3 "4.3 Memory-Augmented Neural Networks (MANNs) ‣ 4 Model-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning")), SNAIL also processes task data
    in sequence, as shown in [Figure 17](#S4.F17 "Figure 17 ‣ 4.5 Simple Neural Attentive
    Meta-Learner (SNAIL) ‣ 4 Model-based Meta-Learning ‣ A Survey of Deep Meta-Learning").
    However, the input at time $t$ is accompanied by the label at time $t$, instead
    of $t-1$ (as was the case for memory-augmented neural networks). SNAIL learns
    internal dynamics from seeing various tasks so that it can make good predictions
    on the query set, conditioned upon the support set.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于记忆增强神经网络（Santoro 等人，[2016](#bib.bib68)）（[第 4.3 节](#S4.SS3 "4.3 Memory-Augmented
    Neural Networks (MANNs) ‣ 4 Model-based Meta-Learning ‣ A Survey of Deep Meta-Learning")），SNAIL
    也按顺序处理任务数据，如 [图 17](#S4.F17 "Figure 17 ‣ 4.5 Simple Neural Attentive Meta-Learner
    (SNAIL) ‣ 4 Model-based Meta-Learning ‣ A Survey of Deep Meta-Learning") 所示。然而，时间
    $t$ 的输入伴随着时间 $t$ 的标签，而不是 $t-1$（如记忆增强神经网络中的情况）。SNAIL 从看到各种任务中学习内部动态，以便在支持集的条件下对查询集进行良好的预测。
- en: A key advantage of SNAIL is that it can be applied to both supervised and reinforcement
    learning tasks. In addition, it achieves good performance compared to previously
    discussed techniques. A downside of SNAIL is that finding the correct architecture
    of TCBlocks and DenseBlocks can be time-consuming.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: SNAIL 的一个关键优势是它可以应用于监督学习和强化学习任务。此外，与之前讨论的技术相比，它的性能表现良好。SNAIL 的一个缺点是找到 TCBlocks
    和 DenseBlocks 的正确架构可能会耗时。
- en: 4.6 Conditional Neural Processes (CNPs)
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 条件神经过程（CNPs）
- en: '![Refer to caption](img/30b0da4cb14b733fa0c813e306fc4b37.png)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/30b0da4cb14b733fa0c813e306fc4b37.png)'
- en: 'Figure 18: Schematic view of how conditional neural processes work. Here, $h$
    denotes a network outputting a representation for a observation, $a$ denotes an
    aggregation function for these representations, and $g$ denotes a neural network
    that makes predictions for unlabelled observations, based on the aggregated representation.
    Source: Garnelo et al. ([2018](#bib.bib18)).'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18：条件神经过程如何工作的示意图。在这里，$h$ 表示输出观察表示的网络，$a$ 表示这些表示的聚合函数，$g$ 表示根据聚合表示对未标记观察进行预测的神经网络。来源：Garnelo
    等人（[2018](#bib.bib18)）。
- en: In contrast to previous techniques, a conditional neural process (CNP) (Garnelo
    et al., [2018](#bib.bib18)) does not rely on an external memory module. Instead,
    it aggregates the support set into a single aggregated latent representation.
    The general architecture is shown in [Figure 18](#S4.F18 "Figure 18 ‣ 4.6 Conditional
    Neural Processes (CNPs) ‣ 4 Model-based Meta-Learning ‣ A Survey of Deep Meta-Learning").
    As we can see, the conditional neural process operates in three phases on task
    $\mathcal{T}_{j}$. First, it observes the support set $D^{tr}_{\mathcal{T}_{j}}$,
    including the ground-truth outputs $y_{i}$. Examples $(\boldsymbol{x}_{i},y_{i})\in
    D^{tr}_{\mathcal{T}_{j}}$ are embedded using a neural network $h_{\boldsymbol{\theta}}$
    into representations $\boldsymbol{r}_{i}$. Second, these representations are aggregated
    using operator $a$ to produce a single representation $\boldsymbol{r}$ of $D^{tr}_{\mathcal{T}_{j}}$
    (hence it is model-based). Third, a neural network $g_{\boldsymbol{\phi}}$ processes
    this single representation $\boldsymbol{r}$, new inputs $\boldsymbol{x}$, and
    produces predictions $\hat{y}$.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 与以前的技术相比，条件神经过程（CNP）（Garnelo 等， [2018](#bib.bib18)）不依赖于外部记忆模块。相反，它将支持集汇聚成一个单一的聚合潜在表示。一般架构见
    [图 18](#S4.F18 "Figure 18 ‣ 4.6 Conditional Neural Processes (CNPs) ‣ 4 Model-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning")。如我们所见，条件神经过程在任务 $\mathcal{T}_{j}$
    上分为三个阶段。首先，它观察支持集 $D^{tr}_{\mathcal{T}_{j}}$，包括真实输出 $y_{i}$。样本 $(\boldsymbol{x}_{i},y_{i})\in
    D^{tr}_{\mathcal{T}_{j}}$ 使用神经网络 $h_{\boldsymbol{\theta}}$ 嵌入为表示 $\boldsymbol{r}_{i}$。第二，这些表示通过运算符
    $a$ 聚合成 $D^{tr}_{\mathcal{T}_{j}}$ 的单一表示 $\boldsymbol{r}$（因此它是基于模型的）。第三，神经网络 $g_{\boldsymbol{\phi}}$
    处理这个单一表示 $\boldsymbol{r}$、新的输入 $\boldsymbol{x}$，并产生预测 $\hat{y}$。
- en: Let the entire conditional neural process model be denoted by $Q_{\boldsymbol{\Theta}}$,
    where $\Theta$ is a set of all involved parameters $\{\boldsymbol{\theta},\boldsymbol{\phi}\}$.
    The training process is different compared to other techniques. Let $\boldsymbol{x}_{\mathcal{T}_{j}}$
    and $\boldsymbol{y}_{\mathcal{T}_{j}}$ denote all inputs and corresponding outputs
    in $D_{\mathcal{T}_{j}}^{tr}$. Then, the first $\ell\backsim U(0,\ldots,k\cdot
    N-1)$ examples in $D^{tr}_{\mathcal{T}_{j}}$ are used as a conditioning set $D^{c}_{\mathcal{T}_{j}}$
    (effectively splitting the support set in a true training set and a validation
    set). Given a value of $\ell$, the goal is to maximize the log likelihood (or
    minimize the negative log likelihood) of the labels $\boldsymbol{y}_{\mathcal{T}_{j}}$
    in the entire support set $D^{tr}_{\mathcal{T}_{j}}$
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 让整个条件神经过程模型记作 $Q_{\boldsymbol{\Theta}}$，其中 $\Theta$ 是所有相关参数的集合 $\{\boldsymbol{\theta},\boldsymbol{\phi}\}$。训练过程与其他技术有所不同。令
    $\boldsymbol{x}_{\mathcal{T}_{j}}$ 和 $\boldsymbol{y}_{\mathcal{T}_{j}}$ 表示 $D_{\mathcal{T}_{j}}^{tr}$
    中的所有输入和相应的输出。那么，$D^{tr}_{\mathcal{T}_{j}}$ 中前 $\ell\backsim U(0,\ldots,k\cdot
    N-1)$ 个样本被用作条件集 $D^{c}_{\mathcal{T}_{j}}$（有效地将支持集拆分为真实训练集和验证集）。给定 $\ell$ 的值，目标是最大化标签
    $\boldsymbol{y}_{\mathcal{T}_{j}}$ 在整个支持集 $D^{tr}_{\mathcal{T}_{j}}$ 上的对数似然（或最小化负对数似然）。
- en: '|  | $\displaystyle\mathcal{L}(\boldsymbol{\Theta})=-\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}\left[\mathbb{E}_{\ell\backsim U(0,\ldots,k\cdot N-1)}\left(Q_{\boldsymbol{\Theta}}(\boldsymbol{y}_{\mathcal{T}_{j}}&#124;D^{c}_{\mathcal{T}_{j}},\boldsymbol{x}_{\mathcal{T}_{j}})\right)\right].$
    |  | (12) |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}(\boldsymbol{\Theta})=-\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}\left[\mathbb{E}_{\ell\backsim U(0,\ldots,k\cdot N-1)}\left(Q_{\boldsymbol{\Theta}}(\boldsymbol{y}_{\mathcal{T}_{j}}&#124;D^{c}_{\mathcal{T}_{j}},\boldsymbol{x}_{\mathcal{T}_{j}})\right)\right].$
    |  | (12) |'
- en: Conditional neural processes are trained by repeatedly sampling various tasks
    and values of $\ell$, and propagating the observed loss backwards.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 条件神经过程通过反复采样各种任务和 $\ell$ 的值，并将观察到的损失反向传播来进行训练。
- en: In summary, conditional neural processes use compact representations of previously
    seen inputs to aid the classification of new observations. Despite its simplicity
    and elegance, a disadvantage of this technique is that it is often outperformed
    in few-shot settings by other techniques such as matching networks (Vinyals et al.,
    [2016](#bib.bib86)) (see [Section 3.3](#S3.SS3 "3.3 Matching Networks ‣ 3 Metric-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning")).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 总结而言，条件神经过程使用以前见过的输入的紧凑表示来帮助分类新的观察值。尽管其简单性和优雅性，这种技术的一个缺点是它在少样本设置中常常被其他技术如匹配网络（Vinyals
    等，[2016](#bib.bib86)）所超越（见[第 3.3 节](#S3.SS3 "3.3 匹配网络 ‣ 3 基于度量的元学习 ‣ 深度元学习综述")）。
- en: 4.7 Neural Statistician
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7 神经统计学家
- en: '![Refer to caption](img/be20c3ce838655cef75e5af094b0d6bd.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/be20c3ce838655cef75e5af094b0d6bd.png)'
- en: 'Figure 19: Neural statistician architecture. Edges are neural networks. All
    incoming inputs to a node are concatenated.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19：神经统计学家架构。边缘是神经网络。所有输入节点的输入都被连接在一起。
- en: A neural statistician (Edwards and Storkey, [2017](#bib.bib12)) differs from
    earlier approaches as it learns to compute summary statistics, or meta-features,
    of data sets in an unsupervised manner. These latent embeddings (making the approach
    model-based) can then later be used for making predictions. Despite the broad
    applicability of the model, we discuss it in the context of Deep Meta-Learning.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 神经统计学家（Edwards 和 Storkey，[2017](#bib.bib12)）不同于早期的方法，它通过无监督的方式学习计算数据集的汇总统计量或元特征。这些潜在的嵌入（使得方法是基于模型的）随后可以用于进行预测。尽管该模型具有广泛的适用性，我们在深度元学习的背景下讨论它。
- en: A neural statistician performs both learning and inference. In the learning
    phase, the model attempts to produce generative models $\hat{P}_{i}$ for every
    data set $D_{i}$. The key assumption that is made by Edwards and Storkey ([2017](#bib.bib12))
    is that there exists a generative process $P_{i}$, which conditioned on a latent
    context vector $\boldsymbol{c}_{i}$, can produce data set $D_{i}$. At inference
    time, the goal is to infer a (posterior) probability distribution over the context
    $q(\boldsymbol{c}|D)$.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 神经统计学家同时执行学习和推断。在学习阶段，该模型尝试为每个数据集 $D_{i}$ 生成生成模型 $\hat{P}_{i}$。Edwards 和 Storkey（[2017](#bib.bib12)）所做的关键假设是存在一个生成过程
    $P_{i}$，在潜在上下文向量 $\boldsymbol{c}_{i}$ 的条件下，可以生成数据集 $D_{i}$。在推断时，目标是推断上下文 $q(\boldsymbol{c}|D)$
    的（后验）概率分布。
- en: 'The model uses a variational autoencoder, which consists of an encoder and
    decoder. The encoder is responsible for producing a distribution over latent vectors
    $\boldsymbol{z}$: $q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\phi})$, where
    $\boldsymbol{x}$ is an input vector, and $\boldsymbol{\phi}$ are the encoder parameters.
    The encoded input $\boldsymbol{z}$, which is often of lower dimensionality than
    the original input $\boldsymbol{x}$, can then be decoded by the decoder $p(\boldsymbol{x}|\boldsymbol{z};\boldsymbol{\theta})$.
    Here, $\boldsymbol{\theta}$ are the parameters of the decoder. To capture more
    complex patterns in data sets, the model uses multiple latent layers $\boldsymbol{z}_{1},\ldots,\boldsymbol{z}_{L}$,
    as shown in [Figure 19](#S4.F19 "Figure 19 ‣ 4.7 Neural Statistician ‣ 4 Model-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning"). Given this architecture, the
    posterior over $c$ and $\boldsymbol{z}_{1},..,\boldsymbol{z}_{L}$ (shorthand $\boldsymbol{z}_{1:L}$)
    is given by'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型使用了变分自编码器，它由编码器和解码器组成。编码器负责生成潜在向量 $\boldsymbol{z}$ 的分布：$q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\phi})$，其中
    $\boldsymbol{x}$ 是输入向量，$\boldsymbol{\phi}$ 是编码器参数。编码后的输入 $\boldsymbol{z}$ 通常比原始输入
    $\boldsymbol{x}$ 维度更低，然后可以通过解码器 $p(\boldsymbol{x}|\boldsymbol{z};\boldsymbol{\theta})$
    解码。在这里，$\boldsymbol{\theta}$ 是解码器的参数。为了捕捉数据集中的复杂模式，模型使用了多个潜在层 $\boldsymbol{z}_{1},\ldots,\boldsymbol{z}_{L}$，如
    [图 19](#S4.F19 "Figure 19 ‣ 4.7 Neural Statistician ‣ 4 Model-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning") 所示。根据这一架构，$c$ 和 $\boldsymbol{z}_{1},\ldots,\boldsymbol{z}_{L}$（简写为
    $\boldsymbol{z}_{1:L}$）的后验分布为
- en: '|  | $\displaystyle q(\boldsymbol{c},\boldsymbol{z}_{1:L}&#124;D;\boldsymbol{\phi})=q(\boldsymbol{c}&#124;D;\boldsymbol{\phi})\prod_{\boldsymbol{x}\in
    D}q(z_{L}&#124;\boldsymbol{x},\boldsymbol{c};\boldsymbol{\phi})\prod_{i=1}^{L-1}q(\boldsymbol{z}_{i}&#124;\boldsymbol{z}_{i+1},\boldsymbol{x},\boldsymbol{c};\boldsymbol{\phi}).$
    |  | (13) |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle q(\boldsymbol{c},\boldsymbol{z}_{1:L}\mid D;\boldsymbol{\phi})=q(\boldsymbol{c}\mid
    D;\boldsymbol{\phi})\prod_{\boldsymbol{x}\in D}q(z_{L}\mid \boldsymbol{x},\boldsymbol{c};\boldsymbol{\phi})\prod_{i=1}^{L-1}q(\boldsymbol{z}_{i}\mid
    \boldsymbol{z}_{i+1},\boldsymbol{x},\boldsymbol{c};\boldsymbol{\phi}).$ |  | (13)
    |'
- en: The neural statistician is trained to minimize a three-component loss function,
    consisting of the reconstruction loss (how well it models the data), context loss
    (how well the inferred context $q(\boldsymbol{c}|D;\boldsymbol{\phi})$ corresponds
    to the prior $P(\boldsymbol{c})$, and latent loss (how well the inferred latent
    variables $\boldsymbol{z}_{i}$ are modelled).
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 神经统计学家被训练以最小化一个由三个组件组成的损失函数，包括重建损失（模型对数据的拟合程度）、上下文损失（推断的上下文 $q(\boldsymbol{c}|D;\boldsymbol{\phi})$
    与先验 $P(\boldsymbol{c})$ 的对应程度）和潜在损失（推断的潜在变量 $\boldsymbol{z}_{i}$ 的建模程度）。
- en: This model can be applied to $N$-way, few-shot learning as follows. Construct
    $N$ data sets for every of the $N$ classes, such that one data set contains only
    examples of the same class. Then, the neural statistician is provided with a new
    input $\boldsymbol{x}$, and has to predict its class. It computes a context posterior
    $N_{\boldsymbol{x}}=q(\boldsymbol{c}|\boldsymbol{x};\boldsymbol{\phi})$ depending
    on new input $\boldsymbol{x}$. In similar fashion, context posteriors are computed
    for all of the data sets $N_{i}=q(\boldsymbol{c}|D_{i};\boldsymbol{\phi})$. Lastly,
    it assigns the label $i$ such that the difference between $N_{i}$ and $N_{\boldsymbol{x}}$
    is minimal.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型可以应用于 $N$-way、少样本学习。为每个 $N$ 类构造 $N$ 个数据集，使得每个数据集仅包含同一类别的示例。然后，将新的输入 $\boldsymbol{x}$
    提供给神经统计学家，并预测其类别。它计算一个上下文后验 $N_{\boldsymbol{x}}=q(\boldsymbol{c}|\boldsymbol{x};\boldsymbol{\phi})$，依赖于新的输入
    $\boldsymbol{x}$。类似地，为所有数据集计算上下文后验 $N_{i}=q(\boldsymbol{c}|D_{i};\boldsymbol{\phi})$。最后，它分配标签
    $i$，使得 $N_{i}$ 与 $N_{\boldsymbol{x}}$ 之间的差异最小。
- en: In summary, the neural statistician (Edwards and Storkey, [2017](#bib.bib12))
    allows for quick learning on new tasks through data set modeling. Additionally,
    it is applicable to both supervised and unsupervised settings. A downside is that
    the approach requires many data sets to achieve good performance (Edwards and
    Storkey, [2017](#bib.bib12)).
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，神经统计学家（Edwards 和 Storkey，[2017](#bib.bib12)）通过数据集建模实现了对新任务的快速学习。此外，它适用于监督和无监督设置。一个缺点是这种方法需要大量数据集才能取得良好的性能（Edwards
    和 Storkey，[2017](#bib.bib12)）。
- en: 4.8 Model-based Techniques, in conclusion
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.8 基于模型的技术，总结
- en: In this section, we have discussed various model-based techniques. Despite apparent
    differences, they all build on the notion of task internalization. That is, tasks
    are processed and represented in the state of the model-based system. This state
    can then be used to make predictions. [Figure 20](#S4.F20 "Figure 20 ‣ 4.8 Model-based
    Techniques, in conclusion ‣ 4 Model-based Meta-Learning ‣ A Survey of Deep Meta-Learning")
    displays the relationships between the covered model-based techniques.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了各种模型基础技术。尽管存在明显的差异，它们都基于任务内化的概念。即，任务在模型基础系统的状态中被处理和表示。然后，可以利用这个状态进行预测。[图
    20](#S4.F20 "Figure 20 ‣ 4.8 Model-based Techniques, in conclusion ‣ 4 Model-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning") 显示了所涵盖的模型基础技术之间的关系。
- en: Memory-augmented neural networks (MANNs) (Santoro et al., [2016](#bib.bib68))
    mark the beginning of the deep model-based meta-learning techniques. They use
    the idea of feeding the entire support set in sequential fashion into the model
    and then making predictions for the query set inputs using the internal state
    of the model. Such a model-based approach, where inputs sequentially enter the
    model was also taken by recurrent meta-learners (Duan et al., [2016](#bib.bib11);
    Wang et al., [2016](#bib.bib89)) in the reinforcement learning setting. Meta networks
    (Munkhdalai and Yu, [2017](#bib.bib55)) also use a large black-box solution but
    generate task-specific weights for every task that is encountered. SNAIL (Mishra
    et al., [2018](#bib.bib52)) tries to improve the memory capacity and ability to
    pinpoint memories, which is limited in recurrent neural networks, by using attention
    mechanisms coupled with special temporal layers. Lastly, the neural statistician
    and conditional neural process (CPN) are two techniques that try to learn the
    meta-features of data sets in an end-to-end fashion. The neural statistician uses
    the distance between meta-features to make class predictions, while the conditional
    neural process conditions classifiers on these features.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆增强型神经网络（MANNs）（Santoro 等，[2016](#bib.bib68)）标志着深度模型基础元学习技术的开始。它们采用将整个支持集按顺序输入模型的理念，然后利用模型的内部状态对查询集输入进行预测。这样的模型基础方法，也被递归元学习者（Duan
    等，[2016](#bib.bib11); Wang 等，[2016](#bib.bib89)）在强化学习环境中采用。元网络（Munkhdalai 和 Yu，[2017](#bib.bib55)）也使用了一个大型黑箱解决方案，但为每个遇到的任务生成特定的任务权重。SNAIL（Mishra
    等，[2018](#bib.bib52)）试图通过使用注意力机制结合特殊的时间层来提高记忆容量和记忆定位能力，这在递归神经网络中有限。最后，神经统计学家和条件神经过程（CPN）是两种尝试以端到端方式学习数据集元特征的技术。神经统计学家利用元特征之间的距离来进行分类预测，而条件神经过程则在这些特征上对分类器进行条件化。
- en: Advantages of model-based approaches include the flexibility of the internal
    dynamics of the systems, and their broader applicability compared to most metric-based
    techniques. However, model-based techniques are often outperformed by metric-based
    techniques in supervised settings (e.g. graph neural networks (Garcia and Bruna,
    [2017](#bib.bib17)); [Section 3.6](#S3.SS6 "3.6 Graph Neural Networks ‣ 3 Metric-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning")), may not perform well when presented
    with larger data sets (Hospedales et al., [2020](#bib.bib32)), and generalize
    less well to more distant tasks than optimization-based techniques (Finn and Levine,
    [2018](#bib.bib13)). We discuss this optimization-based approach next.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 模型基础方法的优点包括系统内部动态的灵活性以及相较于大多数基于度量的方法的更广泛适用性。然而，模型基础技术在监督设置中通常不如基于度量的技术表现出色（例如图神经网络（Garcia
    和 Bruna，[2017](#bib.bib17)）；[第 3.6 节](#S3.SS6 "3.6 Graph Neural Networks ‣ 3 Metric-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning")），在面对更大的数据集时可能表现不佳（Hospedales
    等，[2020](#bib.bib32)），并且相比基于优化的技术对更远任务的泛化能力较差（Finn 和 Levine，[2018](#bib.bib13)）。我们接下来讨论基于优化的方法。
- en: '![Refer to caption](img/7ea06c59d07346ffc62bc41d061b1502.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7ea06c59d07346ffc62bc41d061b1502.png)'
- en: 'Figure 20: The relationships between the covered model-based meta-learning
    techniques. The neural statistician and conditional neural process (CNP) form
    an island in the model-based approaches.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 图 20：涵盖的模型基础元学习技术之间的关系。神经统计学家和条件神经过程（CNP）在模型基础方法中形成了一个独立的领域。
- en: 5 Optimization-based Meta-Learning
  id: totrans-313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 基于优化的元学习
- en: Optimization-based techniques adopt a different perspective on meta-learning
    than the previous two approaches. They explicitly optimize for fast learning.
    Most optimization-based techniques do so by approaching meta-learning as a bi-level
    optimization problem. At the inner-level, a base-learner makes task-specific updates
    using some optimization strategy (such as gradient descent). At the outer-level,
    the performance across tasks is optimized.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 基于优化的技术在元学习中采用了与前两种方法不同的视角。它们明确地优化以实现快速学习。大多数基于优化的技术通过将元学习视为双层优化问题来实现这一点。在内层，基础学习者使用某种优化策略（如梯度下降）进行任务特定的更新。在外层，优化跨任务的性能。
- en: More formally, given a task $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$
    with new input $\boldsymbol{x}\in D^{test}_{\mathcal{T}_{j}}$ and base-learner
    parameters $\boldsymbol{\theta}$, optimization-based meta-learners return
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，给定一个任务 $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$，对于新的输入
    $\boldsymbol{x}\in D^{test}_{\mathcal{T}_{j}}$ 和基础学习者参数 $\boldsymbol{\theta}$，基于优化的元学习者返回
- en: '|  | $\displaystyle p(Y&#124;\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})=f_{g_{\boldsymbol{\varphi}(\boldsymbol{\theta},D_{\mathcal{T}_{j}}^{tr},\mathcal{L}_{\mathcal{T}_{j}})}}(\boldsymbol{x}),$
    |  | (14) |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle p(Y\vert\boldsymbol{x},D^{tr}_{\mathcal{T}_{j}})=f_{g_{\boldsymbol{\varphi}(\boldsymbol{\theta},D_{\mathcal{T}_{j}}^{tr},\mathcal{L}_{\mathcal{T}_{j}})}}(\boldsymbol{x}),$
    |  | (14) |'
- en: where $f$ is the base-learner, $g_{\boldsymbol{\varphi}}$ is a (learned) optimizer
    that makes task-specific updates to the base-learner parameters $\boldsymbol{\theta}$
    using the support data $D_{\mathcal{T}_{i}}^{tr}$, and loss function $\mathcal{L}_{\mathcal{T}_{j}}$.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $f$ 是基础学习者，$g_{\boldsymbol{\varphi}}$ 是一个（学习到的）优化器，它利用支持数据 $D_{\mathcal{T}_{i}}^{tr}$
    对基础学习者参数 $\boldsymbol{\theta}$ 进行任务特定的更新，以及损失函数 $\mathcal{L}_{\mathcal{T}_{j}}$。
- en: 5.1 Example
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 示例
- en: 'Suppose we are faced with a linear regression problem, where every task is
    associated with a different function $f(x)$. For this example, suppose our model
    only has two parameters: $a$ and $b$, which together form the function $\hat{f}(x)=ax+b$.
    Suppose further that our meta-training set consists of four different tasks, i.e.,
    A, B, C, and D. Then, according to the optimization-based view, we wish to find
    a single set of parameters $\{a,b\}$ from which we can quickly learn the optimal
    parameters for each of the four tasks, as displayed in [Figure 21](#S5.F21 "Figure
    21 ‣ 5.1 Example ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning").
    In fact, this is the intuition behind the popular optimization-based technique
    MAML (Finn et al., [2017](#bib.bib14)). By exposing our model to various meta-training
    tasks, we can update the parameters $a$ and $b$ to facilitate quick adaptation.'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们面临一个线性回归问题，其中每个任务与一个不同的函数 $f(x)$ 相关。以这个示例为例，假设我们的模型只有两个参数：$a$ 和 $b$，它们一起形成函数
    $\hat{f}(x)=ax+b$。进一步假设我们的元训练集包含四个不同的任务，即 A、B、C 和 D。那么，根据基于优化的观点，我们希望找到一组参数 $\{a,b\}$，从中我们可以快速学习每个四个任务的最优参数，如
    [图 21](#S5.F21 "Figure 21 ‣ 5.1 Example ‣ 5 Optimization-based Meta-Learning ‣
    A Survey of Deep Meta-Learning") 所示。实际上，这就是流行的基于优化的技术 MAML（Finn 等人，[2017](#bib.bib14)）背后的直觉。通过让我们的模型暴露于各种元训练任务中，我们可以更新参数
    $a$ 和 $b$，以便快速适应。
- en: '![Refer to caption](img/29b19f81ec1a2162509dc4b66daaa796.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/29b19f81ec1a2162509dc4b66daaa796.png)'
- en: 'Figure 21: Example of an optimization-based technique, inspired by Finn et al.
    ([2017](#bib.bib14)).'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 图 21：基于优化的技术示例，灵感来自 Finn 等人 ([2017](#bib.bib14))。
- en: We will now discuss the core optimization-based techniques in more detail.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将更详细地讨论核心的基于优化的技术。
- en: 5.2 LSTM Optimizer
  id: totrans-323
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 LSTM 优化器
- en: Standard gradient update rules have the form
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 标准梯度更新规则的形式是
- en: '|  | $\displaystyle\boldsymbol{\theta}_{t+1}:=\boldsymbol{\theta}_{t}-\alpha\nabla_{\boldsymbol{\theta}_{t}}\mathcal{L}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{t}),$
    |  | (15) |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\theta}_{t+1}:=\boldsymbol{\theta}_{t}-\alpha\nabla_{\boldsymbol{\theta}_{t}}\mathcal{L}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{t}),$
    |  | (15) |'
- en: where $\alpha$ is the learning rate, and $\mathcal{L}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{t})$
    is the loss function with respect to task $\mathcal{T}_{j}$ and network parameters
    at time $t$, i.e., $\boldsymbol{\theta}_{t}$. The key idea underlying LSTM optimizers
    (Andrychowicz et al., [2016](#bib.bib2)) is to replace the update term ($-\alpha\nabla\mathcal{L}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{t})$)
    by an update proposed by an LSTM $g$ with parameters $\boldsymbol{\varphi}$. Then,
    the new update becomes
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\alpha$ 是学习率，$\mathcal{L}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{t})$ 是相对于任务
    $\mathcal{T}_{j}$ 和时间 $t$ 的网络参数，即 $\boldsymbol{\theta}_{t}$ 的损失函数。LSTM 优化器的核心思想（Andrychowicz
    等人，[2016](#bib.bib2)）是用 LSTM $g$（具有参数 $\boldsymbol{\varphi}$）提出的更新替代更新项（$-\alpha\nabla\mathcal{L}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{t})$）。然后，新的更新变为
- en: '|  | $\displaystyle\boldsymbol{\theta}_{t+1}:=\boldsymbol{\theta}_{t}+g_{\boldsymbol{\varphi}}(\nabla_{\boldsymbol{\theta}_{t}}\mathcal{L}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{t})).$
    |  | (16) |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\theta}_{t+1}:=\boldsymbol{\theta}_{t}+g_{\boldsymbol{\varphi}}(\nabla_{\boldsymbol{\theta}_{t}}\mathcal{L}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{t})).$
    |  | (16) |'
- en: '![Refer to caption](img/bd95e843adddd89f75f4ff664e883e98.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/bd95e843adddd89f75f4ff664e883e98.png)'
- en: 'Figure 22: Workflow of the LSTM optimizer. Gradients can only propagate backwards
    through solid edges. $f_{t}$ denotes the observed loss at time step $t$. Source:
    Andrychowicz et al. ([2016](#bib.bib2)).'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 图 22：LSTM 优化器的工作流程。梯度只能通过实线边缘向后传播。$f_{t}$ 表示时间步 $t$ 的观察损失。来源：Andrychowicz 等人（[2016](#bib.bib2)）。
- en: This new update allows the optimization strategy to be tailored to a specific
    family of tasks. Note that this is meta-learning, i.e., the LSTM learns to learn.
    As such, this technique basically learns an update policy.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这一新的更新方法允许优化策略针对特定任务系列进行调整。请注意，这属于元学习，即 LSTM 学会了学习。因此，这种技术基本上学习了一种更新策略。
- en: 'The loss function used to train an LSTM optimizer is:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 用于训练 LSTM 优化器的损失函数为：
- en: '|  | $\displaystyle\mathcal{L}(\boldsymbol{\varphi})=\mathbb{E}_{\mathcal{L}_{\mathcal{T}_{j}}}\left[\sum_{t=1}^{T}w_{t}\mathcal{L}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{t})\right],$
    |  | (17) |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}(\boldsymbol{\varphi})=\mathbb{E}_{\mathcal{L}_{\mathcal{T}_{j}}}\left[\sum_{t=1}^{T}w_{t}\mathcal{L}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{t})\right],$
    |  | (17) |'
- en: where $T$ is the number of parameter updates that are made, and $w_{t}$ are
    weights indicating the importance of performance after $t$ steps. Note that generally,
    we are only interested in the final performance after $T$ steps. However, the
    authors found that the optimization procedure was better guided by equally weighting
    the performance after each gradient descent step. As is often done, second-order
    derivatives (arising from the dependency between the updated weights and the LSTM
    optimizer) were ignored due to the computational expenses associated with the
    computation thereof. This loss function is fully differentiable and thus allows
    for training an LSTM optimizer (see [Figure 22](#S5.F22 "Figure 22 ‣ 5.2 LSTM
    Optimizer ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning")).
    To prevent a parameter explosion, the same network is used for every coordinate/weight
    in the base-learner’s network, causing the update rule to be the same for every
    parameter. Of course, the updates depend on their prior values and gradients.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $T$ 是进行的参数更新次数，$w_{t}$ 是表示在 $t$ 步后性能重要性的权重。请注意，通常我们只对 $T$ 步后的最终性能感兴趣。然而，作者发现，通过对每次梯度下降步骤后的性能进行等权重，优化过程得到了更好的指导。由于计算代价，通常忽略了二阶导数（由于更新权重和
    LSTM 优化器之间的依赖关系）。该损失函数是完全可微的，因此允许训练 LSTM 优化器（见 [图 22](#S5.F22 "图 22 ‣ 5.2 LSTM
    优化器 ‣ 5 基于优化的元学习 ‣ 深度元学习的综述")）。为了防止参数爆炸，基学习器网络中的每个坐标/权重使用相同的网络，导致每个参数的更新规则相同。当然，更新依赖于它们的先前值和梯度。
- en: The key advantage of LSTM optimizers is that they can enable faster learning
    compared to hand-crafted optimizers, also on different data sets than those used
    to train the optimizer. However, Andrychowicz et al. ([2016](#bib.bib2)) did not
    apply this technique to few-shot learning. In fact, they did not apply it across
    tasks at all. Thus, it is unclear whether this technique can perform well in few-shot
    settings, where few data per class are available for training. Furthermore, the
    question remains whether it can scale to larger base-learner architectures.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM 优化器的主要优势在于，它们能够比手工制作的优化器实现更快的学习，即使在与训练优化器不同的数据集上也是如此。然而，Andrychowicz 等
    ([2016](#bib.bib2)) 并没有将这种技术应用于少样本学习。实际上，他们完全没有在任务之间应用它。因此，目前尚不清楚这种技术在少样本设置中是否表现良好，在这些设置中，每个类别的可用训练数据很少。此外，是否能够扩展到更大的基础学习器架构仍然是一个悬而未决的问题。
- en: 5.3 LSTM Meta-Learner
  id: totrans-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 LSTM 元学习器
- en: Instead of having an LSTM predict gradient updates, Ravi and Larochelle ([2017](#bib.bib65))
    embed the weights of the base-learner parameters into the cell state (long-term
    memory component) of the LSTM, giving rise to LSTM meta-learners. As such, the
    base-learner parameters $\boldsymbol{\theta}$ are literally inside the LSTM memory
    component (cell state). In this way, cell state updates correspond to base-learner
    parameter updates. This idea was inspired by the resemblance between the gradient
    and cell state update rules. Gradient updates often have the form as shown in
    [Equation 15](#S5.E15 "15 ‣ 5.2 LSTM Optimizer ‣ 5 Optimization-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning"). The LSTM cell state update rule, in contrast,
    looks as follows
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: Ravi 和 Larochelle ([2017](#bib.bib65)) 并没有让 LSTM 预测梯度更新，而是将基础学习器参数的权重嵌入到 LSTM
    的细胞状态（长期记忆组件）中，从而产生了 LSTM 元学习器。因此，基础学习器参数 $\boldsymbol{\theta}$ 实际上存在于 LSTM 内存组件（细胞状态）中。这样，细胞状态的更新对应于基础学习器参数的更新。这个想法源于梯度和细胞状态更新规则之间的相似性。梯度更新通常具有如
    [方程 15](#S5.E15 "15 ‣ 5.2 LSTM Optimizer ‣ 5 Optimization-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning") 所示的形式。相比之下，LSTM 细胞状态的更新规则如下：
- en: '|  | $\displaystyle\boldsymbol{c}_{t}:=f_{t}\odot\boldsymbol{c}_{t-1}+\alpha_{t}\odot\bar{\boldsymbol{c}}_{t},$
    |  | (18) |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{c}_{t}:=f_{t}\odot\boldsymbol{c}_{t-1}+\alpha_{t}\odot\bar{\boldsymbol{c}}_{t},$
    |  | (18) |'
- en: where $f_{t}$ is the forget gate (which determines which information should
    be forgotten) at time $t$, $\odot$ represents the element-wise product, $\boldsymbol{c}_{t}$
    is the cell state at time $t$, and $\bar{\boldsymbol{c}}_{t}$ the candidate cell
    state for time step $t$, and $\alpha_{t}$ the learning rate at time step $t$.
    Note that if $f_{t}=\boldsymbol{1}$ (vector of ones), $\alpha_{t}=\alpha$, $\boldsymbol{c}_{t-1}=\boldsymbol{\theta}_{t-1}$,
    and $\bar{\boldsymbol{c}}_{t}=-\nabla_{\boldsymbol{\theta}_{t-1}}\mathcal{L}_{\mathcal{T}_{t}}(\boldsymbol{\theta}_{t-1})$,
    this update is equivalent to the one used by gradient-descent. This similarity
    inspired Ravi and Larochelle ([2017](#bib.bib65)) to use an LSTM as meta-learner
    that learns to make updates for a base-learner, as shown in [Figure 23](#S5.F23
    "Figure 23 ‣ 5.3 LSTM Meta-Learner ‣ 5 Optimization-based Meta-Learning ‣ A Survey
    of Deep Meta-Learning").
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $f_{t}$ 是遗忘门（决定哪些信息应该被遗忘），$\odot$ 代表逐元素乘积，$\boldsymbol{c}_{t}$ 是时间 $t$ 的细胞状态，$\bar{\boldsymbol{c}}_{t}$
    是时间步 $t$ 的候选细胞状态，$\alpha_{t}$ 是时间步 $t$ 的学习率。注意，如果 $f_{t}=\boldsymbol{1}$（全为 1
    的向量），$\alpha_{t}=\alpha$，$\boldsymbol{c}_{t-1}=\boldsymbol{\theta}_{t-1}$，并且 $\bar{\boldsymbol{c}}_{t}=-\nabla_{\boldsymbol{\theta}_{t-1}}\mathcal{L}_{\mathcal{T}_{t}}(\boldsymbol{\theta}_{t-1})$，则该更新等同于梯度下降中使用的更新。这种相似性启发了
    Ravi 和 Larochelle ([2017](#bib.bib65)) 使用 LSTM 作为元学习器，用于学习对基础学习器进行更新，如 [图 23](#S5.F23
    "Figure 23 ‣ 5.3 LSTM Meta-Learner ‣ 5 Optimization-based Meta-Learning ‣ A Survey
    of Deep Meta-Learning") 所示。
- en: '![Refer to caption](img/726c41203ebfa242c77b5276bd15e98a.png)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/726c41203ebfa242c77b5276bd15e98a.png)'
- en: 'Figure 23: LSTM meta-learner computation graph. Gradients can only propagate
    backwards through solid edges. The base-learner is denoted as $M$. $(X_{t},Y_{t})$
    are training sets, whereas $(X,Y)$ is the test set. Source: Ravi and Larochelle
    ([2017](#bib.bib65)).'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '图 23: LSTM 元学习器计算图。梯度只能通过实线边向后传播。基础学习器表示为 $M$。$(X_{t},Y_{t})$ 是训练集，而 $(X,Y)$
    是测试集。来源: Ravi 和 Larochelle ([2017](#bib.bib65))。'
- en: More specifically, the cell state of the LSTM is initialized with $c_{0}=\boldsymbol{\theta}_{0}$,
    which will be adjusted by the LSTM to a good common initialization point across
    different tasks. Then, to update the weights of the base-learner for the next
    time step $t+1$, the LSTM computes $\boldsymbol{c}_{t+1}$ and sets the weights
    of the base-learner equal to that. There is thus a one-to-one correspondence between
    $\boldsymbol{c}_{t}$ and $\boldsymbol{\theta}_{t}$. The meta-learner’s learning
    rate $\alpha_{t}$ (see [Equation 18](#S5.E18 "18 ‣ 5.3 LSTM Meta-Learner ‣ 5 Optimization-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning")), is set equal to $\sigma(\boldsymbol{w}_{\alpha}\cdot[\nabla_{\theta_{t-1}}\mathcal{L}_{\mathcal{T}_{t}}(\boldsymbol{\theta}_{t-1}),\mathcal{L}_{\mathcal{T}_{t}}(\boldsymbol{\theta}_{t}),\theta_{t-1},\alpha_{t-1}]+\boldsymbol{b}_{\alpha})$,
    where $\sigma$ is the sigmoid function. Note that the output is a vector, with
    values between 0 and 1, which denote the the learning rates for the corresponding
    parameters. Furthermore, $\boldsymbol{w}_{\alpha}$ and $\boldsymbol{b}_{\alpha}$
    are trainable parameters that part of the LSTM meta-learner. In words, the learning
    rate at any time depends on the loss gradients, the loss value, the previous parameters,
    and the previous learning rate. The forget gate, $f_{t}$, determines what part
    of the cell state should be forgotten, and is computed in a similar fashion, but
    with different weights.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，LSTM 的单元状态以 $c_{0}=\boldsymbol{\theta}_{0}$ 初始化，LSTM 将其调整为不同任务中的良好共同初始化点。然后，为了更新基础学习器在下一个时间步
    $t+1$ 的权重，LSTM 计算 $\boldsymbol{c}_{t+1}$ 并将基础学习器的权重设置为该值。因此，$\boldsymbol{c}_{t}$
    和 $\boldsymbol{\theta}_{t}$ 之间存在一一对应关系。元学习器的学习率 $\alpha_{t}$（见 [Equation 18](#S5.E18
    "18 ‣ 5.3 LSTM Meta-Learner ‣ 5 Optimization-based Meta-Learning ‣ A Survey of
    Deep Meta-Learning")），设置为 $\sigma(\boldsymbol{w}_{\alpha}\cdot[\nabla_{\theta_{t-1}}\mathcal{L}_{\mathcal{T}_{t}}(\boldsymbol{\theta}_{t-1}),\mathcal{L}_{\mathcal{T}_{t}}(\boldsymbol{\theta}_{t}),\theta_{t-1},\alpha_{t-1}]+\boldsymbol{b}_{\alpha})$，其中
    $\sigma$ 是 sigmoid 函数。注意，输出是一个向量，值介于 0 和 1 之间，表示相应参数的学习率。此外，$\boldsymbol{w}_{\alpha}$
    和 $\boldsymbol{b}_{\alpha}$ 是 LSTM 元学习器的一部分可训练参数。换句话说，任何时间的学习率依赖于损失梯度、损失值、之前的参数和之前的学习率。遗忘门
    $f_{t}$ 确定应该忘记单元状态的哪些部分，并以类似的方式计算，但权重不同。
- en: To prevent an explosion of meta-learner parameters, weight-sharing is used,
    in similar fashion to LSTM optimizers proposed by Andrychowicz et al. ([2016](#bib.bib2))
    ([Section 5.2](#S5.SS2 "5.2 LSTM Optimizer ‣ 5 Optimization-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning")). This implies that the same update rule is
    applied to every weight at a given time step. The exact update, however, depends
    on the history of that specific parameter in terms of the previous learning rate,
    loss, etc. For simplicity, second-order derivatives were ignored, by assuming
    the base-learner’s loss does not depend on the cell state of the LSTM optimizer.
    Batch normalization was applied to stabilize and speed up the learning process.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止元学习器参数的爆炸，采用了类似于 Andrychowicz 等人（[2016](#bib.bib2)）提出的 LSTM 优化器的权重共享（[Section
    5.2](#S5.SS2 "5.2 LSTM Optimizer ‣ 5 Optimization-based Meta-Learning ‣ A Survey
    of Deep Meta-Learning")）。这意味着相同的更新规则应用于每个时间步的每个权重。然而，具体更新依赖于该特定参数的历史，如前面的学习率、损失等。为简化起见，忽略了二阶导数，假设基础学习器的损失不依赖于
    LSTM 优化器的单元状态。应用了批量归一化以稳定和加速学习过程。
- en: In short, LSTM optimizers can learn to optimize a base-learner by maintaining
    a one-to-one correspondence over time between the base-learner’s weights and the
    LSTM cell state. This allows the LSTM to exploit commonalities in the tasks, allowing
    for quicker optimization. However, there are simpler approaches (e.g. MAML (Finn
    et al., [2017](#bib.bib14))) that outperform this technique.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，LSTM 优化器通过在时间上保持基础学习器的权重与 LSTM 单元状态之间的一一对应关系，来学习优化基础学习器。这使得 LSTM 能够利用任务中的共性，从而实现更快的优化。然而，还有一些更简单的方法（例如
    MAML (Finn et al., [2017](#bib.bib14)））能够超越这一技术。
- en: 5.4 Reinforcement Learning Optimizer
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 强化学习优化器
- en: Li and Malik ([2018](#bib.bib46)) proposed a framework that casts optimization
    as a reinforcement learning problem. Optimization can then be performed by existing
    reinforcement learning techniques. At a high-level, an optimization algorithm
    $g$ takes as input an initial set of weights $\boldsymbol{\theta}_{0}$ and a task
    $\mathcal{T}_{j}$ with corresponding loss function $\mathcal{L}_{\mathcal{T}_{j}}$,
    and produces a sequence of new weights $\boldsymbol{\theta}_{1},\ldots,\boldsymbol{\theta}_{T}$,
    where $\boldsymbol{\theta}_{T}$ is the final solution found. On this sequence
    of proposed new weights, we can define a loss function $\mathcal{L}$ that captures
    unwanted properties (e.g. slow convergence, oscillations, etc.). The goal of learning
    an optimizer can then be formulated more precisely as follows. We wish to learn
    an optimal optimizer
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: Li 和 Malik ([2018](#bib.bib46)) 提出了一个将优化问题视为强化学习问题的框架。优化可以通过现有的强化学习技术来执行。在高层次上，优化算法
    $g$ 以初始权重集 $\boldsymbol{\theta}_{0}$ 和任务 $\mathcal{T}_{j}$ 及其相应的损失函数 $\mathcal{L}_{\mathcal{T}_{j}}$
    作为输入，产生一系列新的权重 $\boldsymbol{\theta}_{1},\ldots,\boldsymbol{\theta}_{T}$，其中 $\boldsymbol{\theta}_{T}$
    是找到的最终解决方案。在这系列建议的新权重上，我们可以定义一个损失函数 $\mathcal{L}$，捕捉不希望出现的属性（例如，收敛缓慢、振荡等）。然后，学习优化器的目标可以更精确地表述如下。我们希望学习一个最优的优化器。
- en: '|  | $\displaystyle g^{*}=argmin_{g}\,\mathbb{E}_{\mathcal{T}_{j}\backsim p(\mathcal{T}),\boldsymbol{\theta}_{0}\backsim
    p(\boldsymbol{\theta}_{0})}[\mathcal{L}(g(\mathcal{L}_{\mathcal{T}_{j}},\boldsymbol{\theta}_{0}))]$
    |  | (19) |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle g^{*}=argmin_{g}\,\mathbb{E}_{\mathcal{T}_{j}\backsim p(\mathcal{T}),\boldsymbol{\theta}_{0}\backsim
    p(\boldsymbol{\theta}_{0})}[\mathcal{L}(g(\mathcal{L}_{\mathcal{T}_{j}},\boldsymbol{\theta}_{0}))]$
    |  | (19) |'
- en: The key insight is that the optimization can be formulated as a Partially Observable
    Markov Decision Process (POMDP). Then, the state corresponds to the current set
    of weights $\boldsymbol{\theta}_{t}$, the action to the proposed update at time
    step t, i.e., $\Delta\boldsymbol{\theta}_{t}$, and the policy to the function
    that computes the update. With this formulation, the optimizer $g$ can be learned
    by existing reinforcement learning techniques. In their paper, they used a recurrent
    neural network as an optimizer. At each time step, they feed it observation features,
    which depend on the previous set of weights, loss gradients, and objective functions,
    and use guided policy search to train it.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 关键见解是，优化可以被表述为一个部分可观测的马尔可夫决策过程（POMDP）。在这种表述下，状态对应于当前的权重集 $\boldsymbol{\theta}_{t}$，动作对应于时间步
    $t$ 的建议更新，即 $\Delta\boldsymbol{\theta}_{t}$，而策略对应于计算更新的函数。通过这种表述，优化器 $g$ 可以通过现有的强化学习技术来学习。在他们的论文中，他们使用了一个递归神经网络作为优化器。在每个时间步，他们将观察特征输入给网络，这些特征依赖于之前的权重集、损失梯度和目标函数，并使用引导策略搜索进行训练。
- en: In summary, Li and Malik ([2018](#bib.bib46)) made the first step towards general
    optimization through reinforcement learning optimizers, which were shown able
    to generalize across network architectures and data sets. However, the base-learner
    architecture that was used was quite small. The question remains whether this
    approach can scale to larger architectures.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，Li 和 Malik ([2018](#bib.bib46))迈出了通过强化学习优化器进行通用优化的第一步，证明了该方法能够在网络架构和数据集之间进行泛化。然而，使用的基础学习器架构相当小。问题仍然存在，即这种方法是否可以扩展到更大的架构。
- en: 5.5 MAML
  id: totrans-349
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 MAML
- en: '![Refer to caption](img/abc051366a2bf6f47176086a7938a879.png)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/abc051366a2bf6f47176086a7938a879.png)'
- en: 'Figure 24: MAML learns an initialization point from which it can perform well
    on various tasks. Source: Finn et al. ([2017](#bib.bib14)).'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '图 24: MAML 学习一个初始化点，从该点出发能够在各种任务上表现良好。来源: Finn 等 ([2017](#bib.bib14))。'
- en: 'Model-agnostic meta-learning (MAML) (Finn et al., [2017](#bib.bib14)) uses
    a simple gradient-based inner optimization procedure (e.g. stochastic gradient
    descent), instead of more complex LSTM procedures or procedures based on reinforcement
    learning. The key idea of MAML is to explicitly optimize for fast adaptation to
    new tasks by learning a good set of initialization parameters $\boldsymbol{\theta}$.
    This is shown in [Figure 24](#S5.F24 "Figure 24 ‣ 5.5 MAML ‣ 5 Optimization-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning"): from the learned initialization
    $\boldsymbol{\theta}$, we can quickly move to the best set of parameters for task
    $\mathcal{T}_{j}$, i.e., $\boldsymbol{\theta}^{*}_{j}$ for $j=1,2,3$. The learned
    initialization can be seen as the inductive bias of the model, or simply the set
    of assumptions (encapsulated in $\boldsymbol{\theta}$) that the model makes concerning
    the overall task structure.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 无关模型的元学习（MAML）（Finn 等，[2017](#bib.bib14)）使用一种简单的基于梯度的内部优化过程（例如随机梯度下降），而不是更复杂的
    LSTM 过程或基于强化学习的过程。MAML 的关键思想是通过学习一个良好的初始化参数集 $\boldsymbol{\theta}$ 来明确优化以快速适应新任务。这在
    [图 24](#S5.F24 "Figure 24 ‣ 5.5 MAML ‣ 5 Optimization-based Meta-Learning ‣ A
    Survey of Deep Meta-Learning") 中展示：从学习到的初始化 $\boldsymbol{\theta}$，我们可以迅速移动到任务
    $\mathcal{T}_{j}$ 的最佳参数集，即 $j=1,2,3$ 的 $\boldsymbol{\theta}^{*}_{j}$。学习到的初始化可以视为模型的归纳偏置，或者简单地说是模型对整体任务结构的假设集（封装在
    $\boldsymbol{\theta}$ 中）。
- en: More formally, let $\boldsymbol{\theta}$ denote the initial model parameters
    of a model. The goal is to quickly learn new concepts, which is equivalent to
    achieving a minimal loss in few gradient update steps. The amount of gradient
    steps $s$ has to be specified upfront, such that MAML can explicitly optimize
    for achieving good performance within that number of steps. Suppose we pick only
    one gradient update step, i.e., $s=1$. Then, given a task $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$,
    gradient descent would produce updated parameters (fast weights)
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，设 $\boldsymbol{\theta}$ 表示模型的初始参数。目标是快速学习新概念，这等同于在少量梯度更新步骤中实现最小损失。梯度步骤的数量
    $s$ 必须事先指定，以便 MAML 可以明确优化以在该步骤数内实现良好性能。假设我们只选择一个梯度更新步骤，即 $s=1$。那么，给定一个任务 $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$，梯度下降将生成更新后的参数（快速权重）。
- en: '|  | $\displaystyle\boldsymbol{\theta}^{\prime}_{j}=\boldsymbol{\theta}-\alpha\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}),$
    |  | (20) |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\theta}^{\prime}_{j}=\boldsymbol{\theta}-\alpha\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}),$
    |  | (20) |'
- en: specific to task $j$. The meta-loss of quick adaptation (using $s=1$ gradient
    steps) across tasks can then be formulated as
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 特定于任务 $j$。然后，快速适应的元损失（使用 $s=1$ 梯度步骤）可以被表述为
- en: '|  | $\displaystyle\mathit{ML}:=\sum_{\mathcal{T}_{j}\backsim p(\mathcal{T})}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})=\sum_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}-\alpha\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})),$
    |  | (21) |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathit{ML}:=\sum_{\mathcal{T}_{j}\backsim p(\mathcal{T})}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})=\sum_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}-\alpha\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})),$
    |  | (21) |'
- en: where $p(\mathcal{T})$ is a probability distribution over tasks. This expression
    contains an inner gradient ($\nabla_{\boldsymbol{\theta}}\mathcal{L}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{j})$).
    As such, by optimizing this meta-loss using gradient-based techniques, we have
    to compute second-order gradients. One can easily see this in the computation
    below
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p(\mathcal{T})$ 是任务的概率分布。这个表达式包含了一个内部梯度（$\nabla_{\boldsymbol{\theta}}\mathcal{L}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{j})$）。因此，通过使用基于梯度的技术优化这个元损失，我们必须计算二阶梯度。下面的计算可以很容易地看出这一点。
- en: '|  | $\displaystyle\nabla_{\boldsymbol{\theta}}\mathit{ML}$ | $\displaystyle=\nabla_{\boldsymbol{\theta}}\sum_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})$
    |  |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\nabla_{\boldsymbol{\theta}}\mathit{ML}$ | $\displaystyle=\nabla_{\boldsymbol{\theta}}\sum_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})$
    |  |'
- en: '|  |  | $\displaystyle=\sum_{\mathcal{T}_{j}\backsim p(\mathcal{T})}\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})$
    |  |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\sum_{\mathcal{T}_{j}\backsim p(\mathcal{T})}\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})$
    |  |'
- en: '|  |  | $\displaystyle=\sum_{\mathcal{T}_{j}\backsim p(\mathcal{T})}\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\nabla_{\boldsymbol{\theta}}(\boldsymbol{\theta}^{\prime}_{j})$
    |  |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\sum_{\mathcal{T}_{j}\backsim p(\mathcal{T})}\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\nabla_{\boldsymbol{\theta}}(\boldsymbol{\theta}^{\prime}_{j})$
    |  |'
- en: '|  |  | $\displaystyle=\sum_{\mathcal{T}_{j}\backsim p(\mathcal{T})}\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})\nabla_{\boldsymbol{\theta}}(\boldsymbol{\theta}-\alpha\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}(\boldsymbol{\theta})})$
    |  |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\sum_{\mathcal{T}_{j}\backsim p(\mathcal{T})}\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})\nabla_{\boldsymbol{\theta}}(\boldsymbol{\theta}-\alpha\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}(\boldsymbol{\theta})})$
    |  |'
- en: '|  |  | $\displaystyle=\underbrace{\sum_{\mathcal{T}_{j}\backsim p(\mathcal{T})}\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})}_{\textrm{FOMAML}}(\nabla_{\boldsymbol{\theta}}\boldsymbol{\theta}-\alpha\nabla_{\boldsymbol{\theta}}^{2}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})),$
    |  | (22) |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\underbrace{\sum_{\mathcal{T}_{j}\backsim p(\mathcal{T})}\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})}_{\textrm{FOMAML}}(\nabla_{\boldsymbol{\theta}}\boldsymbol{\theta}-\alpha\nabla_{\boldsymbol{\theta}}^{2}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})),$
    |  | (22) |'
- en: where we used $\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})$
    to denote the derivative of the loss function with respect to the query set, evaluated
    at the post-update parameters $\boldsymbol{\theta}_{j}^{\prime}$. The term $\alpha\nabla_{\boldsymbol{\theta}}^{2}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})$
    contains the second-order gradients. The computation thereof is expensive in terms
    of time and memory costs, especially when the optimization trajectory is large
    (when using a larger number of gradient updates $s$ per task). Finn et al. ([2017](#bib.bib14))
    experimented with leaving out second-order gradients, by assuming $\nabla_{\boldsymbol{\theta}}\boldsymbol{\theta}^{\prime}_{j}=I$,
    giving us First Order MAML (FOMAML, see [Equation 22](#S5.E22 "22 ‣ 5.5 MAML ‣
    5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning")). They found
    that FOMAML performed reasonably similar to MAML. This means that updating the
    initialization using only first order gradients $\sum_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})$
    is roughly equal to using the full gradient expression of the meta-loss in [Equation 22](#S5.E22
    "22 ‣ 5.5 MAML ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning").
    One can extend the meta-loss to incorporate multiple gradient steps by substituting
    $\boldsymbol{\theta}_{j}^{\prime}$ by a multi-step variant.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用$\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})$来表示关于查询集的损失函数的导数，该导数在更新后的参数$\boldsymbol{\theta}_{j}^{\prime}$处进行评估。项$\alpha\nabla_{\boldsymbol{\theta}}^{2}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})$包含了二阶梯度。计算这些梯度在时间和内存成本上都很昂贵，尤其是当优化轨迹很大时（使用每个任务的更多梯度更新$s$）。Finn等人（[2017](#bib.bib14)）通过假设$\nabla_{\boldsymbol{\theta}}\boldsymbol{\theta}^{\prime}_{j}=I$，实验性地忽略了二阶梯度，得到了**一阶MAML（FOMAML，参见[方程式22](#S5.E22
    "22 ‣ 5.5 MAML ‣ 5 基于优化的元学习 ‣ 深度元学习概述")）**。他们发现FOMAML的表现与MAML相似。这意味着仅使用一阶梯度$\sum_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})$来更新初始化与使用[方程式22](#S5.E22
    "22 ‣ 5.5 MAML ‣ 5 基于优化的元学习 ‣ 深度元学习概述")中的完整梯度表达式大致相等。可以通过将$\boldsymbol{\theta}_{j}^{\prime}$替换为多步变体来扩展元损失。
- en: MAML is trained as follows. The initialization weights $\boldsymbol{\theta}$
    are updated by continuously sampling a batch of $m$ tasks $B=\{\mathcal{T}_{j}\backsim
    p(\mathcal{T})\}_{i=1}^{m}$. Then, for every task $\mathcal{T}_{j}\in B$, an inner
    update is performed to obtain $\boldsymbol{\theta}_{j}^{\prime}$, in turn granting
    an observed loss $\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})$.
    These losses across a batch of tasks are used in the outer update
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: MAML的训练如下进行。初始化权重$\boldsymbol{\theta}$通过不断采样一个包含$m$个任务的批次$B=\{\mathcal{T}_{j}\backsim
    p(\mathcal{T})\}_{i=1}^{m}$进行更新。然后，对于每个任务$\mathcal{T}_{j}\in B$，执行一次内部更新以获得$\boldsymbol{\theta}_{j}^{\prime}$，从而得到观察到的损失$\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})$。这些批次任务中的损失被用在外部更新中。
- en: '|  | $\displaystyle\boldsymbol{\theta}:=\boldsymbol{\theta}-\beta\nabla_{\boldsymbol{\theta}}\sum_{\mathcal{T}_{j}\in
    B}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime}).$
    |  | (23) |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\theta}:=\boldsymbol{\theta}-\beta\nabla_{\boldsymbol{\theta}}\sum_{\mathcal{T}_{j}\in
    B}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime}).$
    |  | (23) |'
- en: The complete training procedure of MAML is displayed in [Algorithm 2](#alg2
    "Algorithm 2 ‣ 5.5 MAML ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep
    Meta-Learning"). At test-time, when presented with a new task $\mathcal{T}_{j}$,
    the model is initialized with $\boldsymbol{\theta}$, and performs a number of
    gradient updates on the task data. Note that the algorithm for FOMAML is equivalent
    to [Algorithm 2](#alg2 "Algorithm 2 ‣ 5.5 MAML ‣ 5 Optimization-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning"), except for the fact that the update on line
    8 is done differently. That is, FOMAML updates the initialization with the rule
    $\boldsymbol{\theta}=\boldsymbol{\theta}-\beta\sum_{\mathcal{T}_{j}\backsim p(\mathcal{T})}\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})$.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: MAML的完整训练过程展示在[算法 2](#alg2 "Algorithm 2 ‣ 5.5 MAML ‣ 5 Optimization-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning")中。在测试时，当遇到新任务$\mathcal{T}_{j}$时，模型会用$\boldsymbol{\theta}$进行初始化，并对任务数据执行若干次梯度更新。需要注意的是，FOMAML的算法等同于[算法
    2](#alg2 "Algorithm 2 ‣ 5.5 MAML ‣ 5 Optimization-based Meta-Learning ‣ A Survey
    of Deep Meta-Learning")，只不过第8行的更新方式有所不同。也就是说，FOMAML使用规则$\boldsymbol{\theta}=\boldsymbol{\theta}-\beta\sum_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})$来更新初始化。
- en: Algorithm 2 One-step MAML for supervised learning, by Finn et al. ([2017](#bib.bib14))
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 2 由Finn等人提出的用于监督学习的一步MAML（[2017](#bib.bib14)）
- en: 1:Randomly initialize $\boldsymbol{\theta}$2:while not done do3:     Sample
    batch of $J$ tasks $B=\mathcal{T}_{1},\ldots,\mathcal{T}_{J}\backsim p(\mathcal{T})$4:     for $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})\in
    B$ do5:         Compute $\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})$6:         Compute
    $\boldsymbol{\theta}_{j}^{\prime}=\boldsymbol{\theta}-\alpha\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})$7:     end for8:     Update
    $\boldsymbol{\theta}=\boldsymbol{\theta}-\beta\nabla_{\boldsymbol{\theta}}\sum_{\mathcal{T}_{j}\in
    B}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})$9:end while
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '1: 随机初始化$\boldsymbol{\theta}$2: 当未完成时循环3: 采样$J$个任务批次$B=\mathcal{T}_{1},\ldots,\mathcal{T}_{J}\backsim
    p(\mathcal{T})$4: 对于$\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})\in
    B$5: 计算$\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})$6:
    计算$\boldsymbol{\theta}_{j}^{\prime}=\boldsymbol{\theta}-\alpha\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})$7:
    结束循环8: 更新$\boldsymbol{\theta}=\boldsymbol{\theta}-\beta\nabla_{\boldsymbol{\theta}}\sum_{\mathcal{T}_{j}\in
    B}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})$9:
    循环结束'
- en: Antoniou et al. ([2019](#bib.bib3)), in response to MAML, proposed many technical
    improvements that can improve training stability, performance, and generalization
    ability. Improvements include i) updating the initialization $\boldsymbol{\theta}$
    after every inner update step (instead of after all steps are done) to increase
    gradient propagation, ii) using second-order gradients only after 50 epochs to
    increase the training speed, iii) learning layer-wise learning rates to improve
    flexibility, iv) annealing the meta-learning rate $\beta$ over time, and v) some
    Batch Normalization tweaks (keep running statistics instead of batch-specific
    ones, and using per-step biases).
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: Antoniou等人（[2019](#bib.bib3)）针对MAML提出了许多技术改进，以提高训练稳定性、性能和泛化能力。这些改进包括：i) 在每次内部更新步骤后更新初始化$\boldsymbol{\theta}$（而不是在所有步骤完成后），以增加梯度传播；ii)
    仅在50个epochs之后使用二阶梯度，以提高训练速度；iii) 学习逐层学习率以提高灵活性；iv) 随时间衰减元学习率$\beta$；v) 一些批量归一化的调整（保持运行统计而不是批量特定的统计，使用每步偏置）。
- en: MAML has obtained great attention within the field of Deep Meta-Learning, perhaps
    due to its i) simplicity (only requires two hyperparameters), ii) general applicability,
    and iii) strong performance. A downside of MAML, as mentioned above, is that it
    can be quite expensive in terms of running time and memory to optimize a base-learner
    for every task and compute higher-order derivatives from the optimization trajectories.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: MAML在深度元学习领域受到了极大的关注，这可能是由于其i) 简单性（仅需两个超参数），ii) 广泛适用性，以及iii) 强大的性能。MAML的一个缺点，如前所述，是它在优化每个任务的基础学习器以及计算优化轨迹中的高阶导数时，可能在运行时间和内存方面比较昂贵。
- en: 5.6 iMAML
  id: totrans-371
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6 iMAML
- en: Instead of ignoring higher-order derivatives (as done by FOMAML), which potentially
    decreases the performance compared to regular MAML, iMAML (Rajeswaran et al.,
    [2019](#bib.bib64)) approximates these derivatives in a way that is less memory-consuming.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: iMAML (Rajeswaran 等人, [2019](#bib.bib64)) 通过一种内存消耗较少的方式来近似这些导数，而不是像 FOMAML 那样忽略高阶导数，这可能会降低与常规
    MAML 的性能比较。
- en: Let $\mathcal{A}$ denote an inner optimization algorithm (e.g., stochastic gradient
    descent), which takes a support set $D^{tr}_{\mathcal{T}_{j}}$ corresponding to
    task $\mathcal{T}_{j}$ and initial model weights $\boldsymbol{\theta}$, and produces
    new weights $\boldsymbol{\theta}^{\prime}_{j}=\mathcal{A}(\boldsymbol{\theta},D^{tr}_{\mathcal{T}_{j}})$.
    MAML has to compute the derivative
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 设 $\mathcal{A}$ 表示一个内层优化算法（例如，随机梯度下降），它接受一个与任务 $\mathcal{T}_{j}$ 对应的支持集 $D^{tr}_{\mathcal{T}_{j}}$
    和初始模型权重 $\boldsymbol{\theta}$，并生成新的权重 $\boldsymbol{\theta}^{\prime}_{j}=\mathcal{A}(\boldsymbol{\theta},D^{tr}_{\mathcal{T}_{j}})$。MAML
    需要计算导数
- en: '|  | $\displaystyle\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})=\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}^{\prime}(\boldsymbol{\theta}^{\prime}_{j})\nabla_{\boldsymbol{\theta}}(\boldsymbol{\theta}^{\prime}_{j}),$
    |  | (24) |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})=\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}^{\prime}(\boldsymbol{\theta}^{\prime}_{j})\nabla_{\boldsymbol{\theta}}(\boldsymbol{\theta}^{\prime}_{j}),$
    |  | (24) |'
- en: where $D^{test}_{\mathcal{T}_{j}}$ is the query set corresponding to task $\mathcal{T}_{j}$.
    This equation is a simple result of applying the chain rule. Importantly, note
    that $\nabla_{\boldsymbol{\theta}}(\boldsymbol{\theta}_{j}^{\prime})$ differentiates
    through $\mathcal{A}(\boldsymbol{\theta},D^{tr}_{\mathcal{T}_{j}})$, while $\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}^{\prime}(\boldsymbol{\theta}^{\prime}_{j})$
    does not, as it represents the gradient of the loss function evaluated at $\boldsymbol{\theta}^{\prime}_{j}$.
    Rajeswaran et al. ([2019](#bib.bib64)) make use of the following lemma.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $D^{test}_{\mathcal{T}_{j}}$ 是与任务 $\mathcal{T}_{j}$ 对应的查询集。这个方程是应用链式法则的简单结果。重要的是，要注意
    $\nabla_{\boldsymbol{\theta}}(\boldsymbol{\theta}_{j}^{\prime})$ 在 $\mathcal{A}(\boldsymbol{\theta},D^{tr}_{\mathcal{T}_{j}})$
    处进行微分，而 $\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}^{\prime}(\boldsymbol{\theta}^{\prime}_{j})$
    不进行，因为它表示在 $\boldsymbol{\theta}^{\prime}_{j}$ 处评估的损失函数的梯度。Rajeswaran 等人 ([2019](#bib.bib64))
    使用了以下引理。
- en: If $(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j}))$
    is invertible (i.e., $(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j}))^{-1}$
    exists), then
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 $(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j}))$
    是可逆的（即 $(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j}))^{-1}$
    存在），那么
- en: '|  | $\displaystyle\nabla_{\boldsymbol{\theta}}(\boldsymbol{\theta}_{j}^{\prime})=\left(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\right)^{-1}.$
    |  | (25) |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\nabla_{\boldsymbol{\theta}}(\boldsymbol{\theta}_{j}^{\prime})=\left(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\right)^{-1}.$
    |  | (25) |'
- en: Here, $\lambda$ is a regularization parameter. The reason for this is discussed
    below.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，$\lambda$ 是一个正则化参数。原因将在下文中讨论。
- en: Combining [Equation 24](#S5.E24 "24 ‣ 5.6 iMAML ‣ 5 Optimization-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning") and [Equation 25](#S5.E25 "25 ‣ 5.6 iMAML ‣
    5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning"), we have
    that
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 结合[方程 24](#S5.E24 "24 ‣ 5.6 iMAML ‣ 5 Optimization-based Meta-Learning ‣ A Survey
    of Deep Meta-Learning")和[方程 25](#S5.E25 "25 ‣ 5.6 iMAML ‣ 5 Optimization-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning")，我们得到
- en: '|  | $\displaystyle\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})=\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\left(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\right)^{-1}.$
    |  | (26) |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})=\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\left(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\right)^{-1}.$
    |  | (26) |'
- en: The idea is to obtain an approximate gradient vector $\boldsymbol{g}_{j}$ that
    is close to this expression, i.e., we want the difference to be small
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是获得一个接近该表达式的近似梯度向量 $\boldsymbol{g}_{j}$，即我们希望差异尽可能小
- en: '|  | $\displaystyle\boldsymbol{g}_{j}-\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\left(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\right)^{-1}=\boldsymbol{\epsilon},$
    |  | (27) |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{g}_{j}-\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\left(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\right)^{-1}=\boldsymbol{\epsilon},$
    |  | (27) |'
- en: for some small tolerance vector $\boldsymbol{\epsilon}$. If we multiply both
    sides by the inverse of the inverse factor, i.e., $\left(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\right)$,
    we get
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一些小的容差向量 $\boldsymbol{\epsilon}$，如果我们将两边都乘以逆因子的逆，即 $\left(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\right)$，我们得到
- en: '|  | $\displaystyle\boldsymbol{g}_{j}^{T}\left(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\right)\boldsymbol{g}_{j}-\boldsymbol{g}_{j}^{T}\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})=\boldsymbol{\epsilon}^{\prime},$
    |  | (28) |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{g}_{j}^{T}\left(\boldsymbol{I}+\frac{1}{\lambda}\nabla^{2}_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})\right)\boldsymbol{g}_{j}-\boldsymbol{g}_{j}^{T}\mathcal{L}^{\prime}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})=\boldsymbol{\epsilon}^{\prime},$
    |  | (28) |'
- en: where $\boldsymbol{\epsilon}^{\prime}$ absorbed the multiplication factor. We
    wish to minimize this expression for $\boldsymbol{g}_{j}$, and that can be performed
    using optimization techniques such as the conjugate gradient algorithm (Rajeswaran
    et al., [2019](#bib.bib64)). This algorithm does not need to store Hessian matrices,
    which decreases the memory cost significantly. In turn, this allows iMAML to work
    with more inner gradient update steps. Note, however, that one needs to perform
    explicit regularization in that case to avoid overfitting. The conventional MAML
    did not require this, as it uses only a few number of gradient steps (equivalent
    to an early stopping mechanism).
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\boldsymbol{\epsilon}^{\prime}$ 吸收了乘法因子。我们希望最小化这个关于 $\boldsymbol{g}_{j}$
    的表达式，这可以通过使用诸如共轭梯度算法（Rajeswaran et al., [2019](#bib.bib64)）等优化技术来实现。该算法无需存储 Hessian
    矩阵，从而显著降低了内存成本。反过来，这使得 iMAML 可以处理更多的内部梯度更新步骤。然而，需要注意的是，在这种情况下需要进行显式正则化以避免过拟合。传统的
    MAML 不需要这样做，因为它仅使用少量的梯度步骤（等同于早停机制）。
- en: At each inner loop step, iMAML computes the meta-gradient $\boldsymbol{g}_{j}$.
    After processing a batch of tasks, these gradients are averaged and used to update
    the initialization $\boldsymbol{\theta}$. Since it does not differentiate through
    the optimization process, we are free to use any other (non-differentiable) inner-optimizer.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一步内部循环中，iMAML 计算元梯度 $\boldsymbol{g}_{j}$。处理一批任务后，这些梯度会被平均并用于更新初始化参数 $\boldsymbol{\theta}$。由于它不对优化过程进行微分，我们可以自由使用任何其他（非微分）内部优化器。
- en: In summary, iMAML reduces memory costs significantly as it need not differentiate
    through the optimization trajectory, also allowing for greater flexibility in
    the choice of inner optimizer. Additionally, it can account for larger optimization
    paths. The computational costs stay roughly the same compared to MAML (Finn et al.,
    [2017](#bib.bib14)). Future work could investigate more inner optimization procedures
    (Rajeswaran et al., [2019](#bib.bib64)).
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，iMAML 显著降低了内存成本，因为它无需对优化轨迹进行微分，还允许在选择内部优化器时有更大的灵活性。此外，它还可以处理更大的优化路径。与 MAML
    相比，计算成本基本保持不变（Finn et al., [2017](#bib.bib14)）。未来的工作可以研究更多的内部优化过程（Rajeswaran et
    al., [2019](#bib.bib64)）。
- en: 5.7 Meta-SGD
  id: totrans-388
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7 Meta-SGD
- en: '![Refer to caption](img/8098ca87366f8aa3676cb1787e5800f2.png)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8098ca87366f8aa3676cb1787e5800f2.png)'
- en: 'Figure 25: Meta-SGD learning process. Source: Li et al. ([2017](#bib.bib47)).'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 图 25：Meta-SGD 学习过程。来源：Li et al. ([2017](#bib.bib47)).
- en: Meta-SGD (Li et al., [2017](#bib.bib47)), or meta-stochastic gradient descent,
    is similar to MAML (Finn et al., [2017](#bib.bib14)) ([Section 5.5](#S5.SS5 "5.5
    MAML ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning")).
    However, on top of learning an initialization, Meta-SGD also learns learning rates
    for every model parameter in $\boldsymbol{\theta}$, building on the insight that
    the optimizer can be seen as a trainable entity.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: Meta-SGD（Li et al., [2017](#bib.bib47)），即元随机梯度下降，与MAML（Finn et al., [2017](#bib.bib14)）类似（[第5.5节](#S5.SS5
    "5.5 MAML ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning")）。然而，除了学习初始化之外，Meta-SGD还学习$\boldsymbol{\theta}$中每个模型参数的学习率，基于这样的见解：优化器可以被视为一个可训练的实体。
- en: The standard SGD update rule is given in [Equation 15](#S5.E15 "15 ‣ 5.2 LSTM
    Optimizer ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning").
    The meta-SGD optimizer uses a more general update, namely
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 标准SGD更新规则在[方程 15](#S5.E15 "15 ‣ 5.2 LSTM Optimizer ‣ 5 Optimization-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning")中给出。meta-SGD优化器使用了更一般的更新，即
- en: '|  | $\displaystyle\boldsymbol{\theta}_{j}^{\prime}\leftarrow\boldsymbol{\theta}-\boldsymbol{\alpha}\odot\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}),$
    |  | (29) |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\theta}_{j}^{\prime}\leftarrow\boldsymbol{\theta}-\boldsymbol{\alpha}\odot\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}),$
    |  | (29) |'
- en: where $\odot$ is the element-wise product. Note that this means that alpha (learning
    rate) is now a vector—hence the bold font— instead of scalar, which allows for
    greater flexibility in the sense that each parameter has its own learning rate.
    The goal is to learn the initialization $\boldsymbol{\theta}$, and learning rate
    vector $\boldsymbol{\alpha}$, such that the generalization ability is as large
    as possible. More mathematically precise, the learning objective is
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\odot$表示逐元素乘积。请注意，这意味着alpha（学习率）现在是一个向量——因此使用了粗体字——而不是标量，这允许更大的灵活性，因为每个参数都有其自己的学习率。目标是学习初始化$\boldsymbol{\theta}$和学习率向量$\boldsymbol{\alpha}$，使得泛化能力尽可能大。更精确地说，学习目标是
- en: '|  | $\displaystyle min_{\boldsymbol{\alpha},\boldsymbol{\theta}}\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}[\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})]=\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}[\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}-\boldsymbol{\alpha}\odot\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D_{\mathcal{T}_{j}}^{tr}}(\boldsymbol{\theta}))],$
    |  | (30) |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle min_{\boldsymbol{\alpha},\boldsymbol{\theta}}\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}[\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}_{j}^{\prime})]=\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}[\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}-\boldsymbol{\alpha}\odot\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D_{\mathcal{T}_{j}}^{tr}}(\boldsymbol{\theta}))],$
    |  | (30) |'
- en: where we used a simple substitution for $\boldsymbol{\theta}_{j}^{\prime}$.
    $\mathcal{L}_{D_{\mathcal{T}_{j}}^{tr}}$ and $\mathcal{L}_{D_{\mathcal{T}_{j}}^{test}}$
    are the losses computed on the support and query set respectively. Note that this
    formulation stimulates generalization ability (as it includes the query set loss
    $\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}$, which can be observed during the meta-training
    phase). The learning process is visualized in [Figure 25](#S5.F25 "Figure 25 ‣
    5.7 Meta-SGD ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning").
    Note that the meta-SGD optimizer is trained to maximize generalization ability
    after only one update step. Since this learning objective has a fully differentiable
    loss function, the meta-SGD optimizer itself can be trained using standard SGD.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里对$\boldsymbol{\theta}_{j}^{\prime}$进行了简单的替换。$\mathcal{L}_{D_{\mathcal{T}_{j}}^{tr}}$和$\mathcal{L}_{D_{\mathcal{T}_{j}}^{test}}$分别是在支持集和查询集上计算的损失。请注意，这种公式刺激了泛化能力（因为它包括查询集损失$\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}$，该损失可以在元训练阶段观察到）。学习过程在[图
    25](#S5.F25 "Figure 25 ‣ 5.7 Meta-SGD ‣ 5 Optimization-based Meta-Learning ‣ A
    Survey of Deep Meta-Learning")中进行了可视化。请注意，meta-SGD优化器被训练以在仅有一步更新后最大化泛化能力。由于这个学习目标具有完全可微的损失函数，meta-SGD优化器本身可以使用标准的SGD进行训练。
- en: In summary, Meta-SGD is more expressive than MAML as it does not only learn
    an initialization but also learning rates per parameter. This, however, does come
    at the cost of an increased number of hyperparameters.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，Meta-SGD比MAML更具表现力，因为它不仅学习初始化，还学习每个参数的学习率。然而，这也带来了更多超参数的增加。
- en: 5.8 Reptile
  id: totrans-398
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8 Reptile
- en: Reptile (Nichol et al., [2018](#bib.bib58)) is another optimization-based technique
    that, like MAML (Finn et al., [2017](#bib.bib14)), solely attempts to find a good
    set of initialization parameters $\boldsymbol{\theta}$. The way in which Reptile
    attempts to find this initialization is quite different from MAML. It repeatedly
    samples a task, trains on the task, and moves the model weights towards the trained
    weights (Nichol et al., [2018](#bib.bib58)). [Algorithm 3](#alg3 "Algorithm 3
    ‣ 5.8 Reptile ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning")
    displays the pseudocode describing this simple process.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: Reptile (Nichol 等人，[2018](#bib.bib58)) 是另一种基于优化的技术，类似于 MAML (Finn 等人，[2017](#bib.bib14))，它仅尝试找到一组好的初始化参数
    $\boldsymbol{\theta}$。 Reptile 尝试找到这个初始化的方法与 MAML 有很大不同。它重复采样任务，对任务进行训练，并将模型权重移动到训练后的权重上
    (Nichol 等人，[2018](#bib.bib58))。 [算法 3](#alg3 "算法 3 ‣ 5.8 Reptile ‣ 5 基于优化的元学习
    ‣ 深度元学习综述") 显示了描述这一简单过程的伪代码。
- en: Algorithm 3 Reptile, by Nichol et al. ([2018](#bib.bib58))
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 3 Reptile，由 Nichol 等人（[2018](#bib.bib58)）
- en: 1:Initialize $\boldsymbol{\theta}$2:for $i=1,2,\ldots$ do3:     Sample task
    $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$ and corresponding
    loss function $\mathcal{L}_{\mathcal{T}_{j}}$4:     $\boldsymbol{\theta}^{\prime}_{j}=SGD(\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}},\boldsymbol{\theta},k)$
    $\triangleright$ Perform $k$ gradient update steps to get $\boldsymbol{\theta}_{j}^{\prime}$5:     $\boldsymbol{\theta}:=\boldsymbol{\theta}+\epsilon(\boldsymbol{\theta}^{\prime}_{j}-\boldsymbol{\theta})$
    $\triangleright$ Move initialization point $\boldsymbol{\theta}$ towards $\boldsymbol{\theta}_{j}^{\prime}$6:end for
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '1: 初始化 $\boldsymbol{\theta}$ 2: 对于 $i=1,2,\ldots$ 执行 3: 采样任务 $\mathcal{T}_{j}=(D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}})$
    和对应的损失函数 $\mathcal{L}_{\mathcal{T}_{j}}$ 4: $\boldsymbol{\theta}^{\prime}_{j}=SGD(\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}},\boldsymbol{\theta},k)$
    $\triangleright$ 执行 $k$ 次梯度更新步骤以获得 $\boldsymbol{\theta}_{j}^{\prime}$ 5: $\boldsymbol{\theta}:=\boldsymbol{\theta}+\epsilon(\boldsymbol{\theta}^{\prime}_{j}-\boldsymbol{\theta})$
    $\triangleright$ 将初始化点 $\boldsymbol{\theta}$ 移动到 $\boldsymbol{\theta}_{j}^{\prime}$
    6: 结束 对于'
- en: Nichol et al. ([2018](#bib.bib58)) note that it is possible to treat $(\boldsymbol{\theta}-\boldsymbol{\theta}_{j}^{\prime})/\alpha$
    as gradients, where $\alpha$ is the learning rate of the inner stochastic gradient
    descent optimizer (line 4 in the pseudocode), and to feed that into a meta-optimizer
    (e.g. Adam). Moreover, instead of sampling one task at a time, one could sample
    a batch of $n$ tasks, and move the initialization $\boldsymbol{\theta}$ towards
    the average update direction $\bar{\boldsymbol{\theta}}=\frac{1}{n}\sum_{j=1}^{n}(\boldsymbol{\theta}^{\prime}_{j}-\boldsymbol{\theta})$,
    granting the update rule $\boldsymbol{\theta}:=\boldsymbol{\theta}+\epsilon\bar{\boldsymbol{\theta}}$.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: Nichol 等人（[2018](#bib.bib58)）指出，可以将 $(\boldsymbol{\theta}-\boldsymbol{\theta}_{j}^{\prime})/\alpha$
    视为梯度，其中 $\alpha$ 是内层随机梯度下降优化器的学习率（伪代码中的第 4 行），并将其输入到元优化器（例如 Adam）中。此外，不必一次采样一个任务，而可以采样一批
    $n$ 个任务，并将初始化 $\boldsymbol{\theta}$ 移动到平均更新方向 $\bar{\boldsymbol{\theta}}=\frac{1}{n}\sum_{j=1}^{n}(\boldsymbol{\theta}^{\prime}_{j}-\boldsymbol{\theta})$，从而得到更新规则
    $\boldsymbol{\theta}:=\boldsymbol{\theta}+\epsilon\bar{\boldsymbol{\theta}}$。
- en: The intuition behind Reptile is that updating the initialization weights towards
    updated parameters will grant a good inductive bias for tasks from the same family.
    By performing Taylor expansions of the gradients of Reptile and MAML (both first-order
    and second-order), Nichol et al. ([2018](#bib.bib58)) show that the expected gradients
    differ in their direction. They argue, however, that in practice, the gradients
    of Reptile will also bring the model towards a point minimizing the expected loss
    over tasks.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: Reptile 的直觉是，通过将初始化权重更新到更新后的参数，将为来自同一类别的任务提供良好的归纳偏差。通过对 Reptile 和 MAML（包括一阶和二阶）的梯度进行泰勒展开，Nichol
    等人（[2018](#bib.bib58)）表明预期梯度在方向上有所不同。然而，他们认为在实践中，Reptile 的梯度也会将模型带到一个使任务上的预期损失最小化的点。
- en: A mathematical argument as to why Reptile works goes as follows. Let $\boldsymbol{\theta}$
    denote the initial parameters, and $\boldsymbol{\theta}^{*}_{j}$ the optimal set
    of weights for task $\mathcal{T}_{j}$. Lastly, let $d$ be the Euclidean distance
    function. Then, the goal is to minimize the distance between the initialization
    point $\boldsymbol{\theta}$ and the optimal point $\boldsymbol{\theta}^{*}_{j}$,
    i.e.,
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 解释 Reptile 工作原理的数学论证如下。设 $\boldsymbol{\theta}$ 为初始参数，$\boldsymbol{\theta}^{*}_{j}$
    为任务 $\mathcal{T}_{j}$ 的最佳权重集。最后，设 $d$ 为欧几里得距离函数。目标是最小化初始化点 $\boldsymbol{\theta}$
    和最佳点 $\boldsymbol{\theta}^{*}_{j}$ 之间的距离，即，
- en: '|  | $\displaystyle min_{\boldsymbol{\theta}}\,\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}[\frac{1}{2}d(\boldsymbol{\theta},\boldsymbol{\theta}^{*}_{j})^{2}].$
    |  | (31) |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle min_{\boldsymbol{\theta}}\,\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}[\frac{1}{2}d(\boldsymbol{\theta},\boldsymbol{\theta}^{*}_{j})^{2}].$
    |  | (31) |'
- en: The gradient of this expected distance with respect to the initialization $\boldsymbol{\theta}$
    is given by
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 该期望距离关于初始化参数$\boldsymbol{\theta}$的梯度由以下公式给出
- en: '|  | $\displaystyle\nabla_{\boldsymbol{\theta}}\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}[\frac{1}{2}d(\boldsymbol{\theta},\boldsymbol{\theta}^{*}_{j})^{2}]$
    | $\displaystyle=\mathbb{E}_{\mathcal{T}_{j}\backsim p(\mathcal{T})}[\frac{1}{2}\nabla_{\boldsymbol{\theta}}d(\boldsymbol{\theta},\boldsymbol{\theta}^{*}_{j})^{2}]$
    |  |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\nabla_{\boldsymbol{\theta}}\mathbb{E}_{\mathcal{T}_{j}\backsim
    p(\mathcal{T})}[\frac{1}{2}d(\boldsymbol{\theta},\boldsymbol{\theta}^{*}_{j})^{2}]$
    | $\displaystyle=\mathbb{E}_{\mathcal{T}_{j}\backsim p(\mathcal{T})}[\frac{1}{2}\nabla_{\boldsymbol{\theta}}d(\boldsymbol{\theta},\boldsymbol{\theta}^{*}_{j})^{2}]$
    |  |'
- en: '|  |  | $\displaystyle=\mathbb{E}_{\mathcal{T}_{j}\backsim p(\mathcal{T})}[\boldsymbol{\theta}-\boldsymbol{\theta}^{*}_{j}],$
    |  | (32) |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\mathbb{E}_{\mathcal{T}_{j}\backsim p(\mathcal{T})}[\boldsymbol{\theta}-\boldsymbol{\theta}^{*}_{j}],$
    |  | (32) |'
- en: where we used the fact that the gradient of the squared Euclidean distance between
    two points $\boldsymbol{x}_{1}$ and $\boldsymbol{x}_{2}$ is the vector $2(\boldsymbol{x}_{1}-\boldsymbol{x}_{2})$.
    Nichol et al. ([2018](#bib.bib58)) go on to argue that performing gradient descent
    on this objective would result in the following update rule
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们利用了两个点$\boldsymbol{x}_{1}$和$\boldsymbol{x}_{2}$之间的平方欧几里得距离的梯度是向量$2(\boldsymbol{x}_{1}-\boldsymbol{x}_{2})$的事实。Nichol等人
    ([2018](#bib.bib58)) 进一步论证了对该目标进行梯度下降会导致以下更新规则
- en: '|  | $\displaystyle\boldsymbol{\theta}$ | $\displaystyle=\boldsymbol{\theta}-\epsilon\nabla_{\boldsymbol{\theta}}\frac{1}{2}d(\boldsymbol{\theta},\boldsymbol{\theta}^{*}_{j})^{2}$
    |  |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\theta}$ | $\displaystyle=\boldsymbol{\theta}-\epsilon\nabla_{\boldsymbol{\theta}}\frac{1}{2}d(\boldsymbol{\theta},\boldsymbol{\theta}^{*}_{j})^{2}$
    |  |'
- en: '|  |  | $\displaystyle=\boldsymbol{\theta}-\epsilon(\boldsymbol{\theta}^{*}_{j}-\boldsymbol{\theta}).$
    |  | (33) |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\boldsymbol{\theta}-\epsilon(\boldsymbol{\theta}^{*}_{j}-\boldsymbol{\theta}).$
    |  | (33) |'
- en: Since we do not know $\boldsymbol{\theta}^{*}_{\mathcal{T}_{j}}$, one can approximate
    this by term by $k$ steps of gradient descent $SGD(\mathcal{L}_{\mathcal{T}_{j}},\boldsymbol{\theta},k)$.
    In short, Reptile can be seen as gradient descent on the distance minimization
    objective given in [Equation 31](#S5.E31 "31 ‣ 5.8 Reptile ‣ 5 Optimization-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning"). A visualization is shown in
    [Figure 26](#S5.F26 "Figure 26 ‣ 5.8 Reptile ‣ 5 Optimization-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning"). The initialization $\boldsymbol{\theta}$ is
    moving towards the optimal weights for tasks 1 and 2 in interleaved fashion (hence
    the oscillations).
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不知道$\boldsymbol{\theta}^{*}_{\mathcal{T}_{j}}$，可以通过进行$k$步梯度下降$SGD(\mathcal{L}_{\mathcal{T}_{j}},\boldsymbol{\theta},k)$来近似这一项。简而言之，Reptile可以视为对[公式 31](#S5.E31
    "31 ‣ 5.8 Reptile ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning")中给出的距离最小化目标进行的梯度下降。图示见[图 26](#S5.F26
    "Figure 26 ‣ 5.8 Reptile ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep
    Meta-Learning")。初始化参数$\boldsymbol{\theta}$在任务1和2的最优权重之间交替移动（因此出现振荡现象）。
- en: '![Refer to caption](img/8be7d9c208fc2a069218cd1e5fdf7cc2.png)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8be7d9c208fc2a069218cd1e5fdf7cc2.png)'
- en: 'Figure 26: Schematic visualization of Reptile’s learning trajectory. Here,
    $\boldsymbol{\theta}_{1}^{*}$ and $\boldsymbol{\theta}_{2}^{*}$ are the optimal
    weights for tasks $\mathcal{T}_{1}$ and $\mathcal{T}_{2}$ respectively. The initialization
    parameters $\boldsymbol{\theta}$ oscillate between these. Adapted from Nichol
    et al. ([2018](#bib.bib58)).'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '图 26: Reptile学习轨迹的示意图。在这里，$\boldsymbol{\theta}_{1}^{*}$和$\boldsymbol{\theta}_{2}^{*}$分别是任务$\mathcal{T}_{1}$和$\mathcal{T}_{2}$的最优权重。初始化参数$\boldsymbol{\theta}$在这些之间振荡。改编自Nichol等人
    ([2018](#bib.bib58))。'
- en: In conclusion, Reptile is an extremely simple meta-learning technique, which
    does not need to differentiate through the optimization trajectory like, e.g.,
    MAML (Finn et al., [2017](#bib.bib14)), saving time and memory costs. However,
    the theoretical foundation is a bit weaker due to the fact that it does not directly
    optimize for fast learning as done by MAML, and performance may be a bit worse
    than that of MAML in some settings.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，Reptile是一种极其简单的元学习技术，不需要像MAML（Finn等人，[2017](#bib.bib14)）那样通过优化轨迹进行微分，从而节省了时间和内存成本。然而，由于它不像MAML那样直接优化快速学习，其理论基础略显薄弱，在某些设置中性能可能稍逊于MAML。
- en: 5.9 Latent embedding optimization (LEO)
  id: totrans-416
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.9 潜在嵌入优化（LEO）
- en: Latent Embedding Optimization, or LEO, was proposed by Rusu et al. ([2018](#bib.bib67))
    to combat an issue of gradient-based meta-learners, such as MAML (see [Section 5.5](#S5.SS5
    "5.5 MAML ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning")),
    in few-shot settings ($N$-way, $k$-shot). These techniques operate in a high-dimensional
    parameter space using gradient information from only a few examples, which could
    lead to poor generalization.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在嵌入优化（Latent Embedding Optimization，简称 LEO）由 Rusu 等人提出（[2018](#bib.bib67)），旨在解决基于梯度的元学习器（如
    MAML，见 [第 5.5 节](#S5.SS5 "5.5 MAML ‣ 5 Optimization-based Meta-Learning ‣ A Survey
    of Deep Meta-Learning")）在少样本设置中的问题（$N$-way，$k$-shot）。这些技术在高维参数空间中运作，仅使用少量样本的梯度信息，可能导致泛化性能较差。
- en: '![Refer to caption](img/809a69e8965687f125467554cf2f691d.png)'
  id: totrans-418
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/809a69e8965687f125467554cf2f691d.png)'
- en: 'Figure 27: Workflow of LEO. adapted from Rusu et al. ([2018](#bib.bib67)).'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 图 27：LEO 的工作流程，改编自 Rusu 等人（[2018](#bib.bib67)）。
- en: LEO alleviates this issue by learning a lower-dimensional latent embedding space,
    which indirectly allows us to learn a good set of initial parameters $\boldsymbol{\theta}$.
    Additionally, the embedding space is conditioned upon tasks, allowing for more
    expressivity. In theory, LEO could find initial parameters for the entire base-learner
    network, but the authors only experimented with setting the parameters for the
    final layers.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: LEO 通过学习低维的潜在嵌入空间来缓解这一问题，这间接使我们能够学习到一组良好的初始参数 $\boldsymbol{\theta}$。此外，嵌入空间根据任务进行调整，允许更高的表达能力。理论上，LEO
    可以为整个基础学习网络找到初始参数，但作者仅对最终层的参数进行了实验。
- en: The complete workflow of LEO is shown in [Figure 27](#S5.F27 "Figure 27 ‣ 5.9
    Latent embedding optimization (LEO) ‣ 5 Optimization-based Meta-Learning ‣ A Survey
    of Deep Meta-Learning"). As we can see, given a task $\mathcal{T}_{j}$, the corresponding
    support set $D^{tr}_{\mathcal{T}_{j}}$ is fed into an encoder, which produces
    hidden codes for each example in that set. These hidden codes are paired and concatenated
    in every possible manner, granting us $(Nk)^{2}$ pairs, where $N$ is the number
    of classes in the training set, and $k$ the number of examples per class. These
    paired codes are then fed into a relation net (Sung et al., [2018](#bib.bib76))
    (see [Section 3.5](#S3.SS5 "3.5 Relation Networks ‣ 3 Metric-based Meta-Learning
    ‣ A Survey of Deep Meta-Learning")). The resulting embeddings are grouped by class,
    and parameterize a probability distribution over latent codes $\boldsymbol{z}_{n}$
    (for class $n$) in a low dimensional space $\mathcal{Z}$. More formally, let $\boldsymbol{x}^{\ell}_{n}$
    denote the $\ell$-th example of class $n$ in $D^{tr}_{\mathcal{T}_{j}}$. Then,
    the mean $\boldsymbol{\mu}^{e}_{n}$ and variance $\boldsymbol{\sigma}^{e}_{n}$
    of a Gaussian distribution over latent codes for class $n$ are computed as
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: LEO 的完整工作流程见 [图 27](#S5.F27 "Figure 27 ‣ 5.9 Latent embedding optimization (LEO)
    ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning")。如图所示，给定任务
    $\mathcal{T}_{j}$，相应的支持集 $D^{tr}_{\mathcal{T}_{j}}$ 被输入到编码器中，编码器为该集合中的每个样本生成隐藏代码。这些隐藏代码以各种可能的方式配对和拼接，产生
    $(Nk)^{2}$ 对，其中 $N$ 是训练集中类别的数量，$k$ 是每类的样本数量。这些配对的代码然后输入到关系网络（Sung 等人，[2018](#bib.bib76)）（见
    [第 3.5 节](#S3.SS5 "3.5 Relation Networks ‣ 3 Metric-based Meta-Learning ‣ A Survey
    of Deep Meta-Learning")）。生成的嵌入按类别分组，并在低维空间 $\mathcal{Z}$ 中对潜在代码 $\boldsymbol{z}_{n}$（类别
    $n$）进行概率分布参数化。更正式地，设 $\boldsymbol{x}^{\ell}_{n}$ 表示 $D^{tr}_{\mathcal{T}_{j}}$
    中类别 $n$ 的第 $\ell$ 个样本。然后，类别 $n$ 的潜在代码的均值 $\boldsymbol{\mu}^{e}_{n}$ 和方差 $\boldsymbol{\sigma}^{e}_{n}$
    计算为
- en: '|  | $\displaystyle\boldsymbol{\mu}_{n}^{e},\boldsymbol{\sigma}^{e}_{n}=\frac{1}{Nk^{2}}\sum_{\ell_{p}=1}^{k}\sum^{N}_{m=1}\sum_{\ell_{q}=1}^{k}g_{\boldsymbol{\phi}_{r}}\left(g_{\boldsymbol{\phi}_{e}}(\boldsymbol{x}^{\ell_{p}}_{n}),g_{\boldsymbol{\phi}_{e}}(\boldsymbol{x}^{\ell_{q}}_{m})\right),$
    |  | (34) |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\mu}_{n}^{e},\boldsymbol{\sigma}^{e}_{n}=\frac{1}{Nk^{2}}\sum_{\ell_{p}=1}^{k}\sum^{N}_{m=1}\sum_{\ell_{q}=1}^{k}g_{\boldsymbol{\phi}_{r}}\left(g_{\boldsymbol{\phi}_{e}}(\boldsymbol{x}^{\ell_{p}}_{n}),g_{\boldsymbol{\phi}_{e}}(\boldsymbol{x}^{\ell_{q}}_{m})\right),$
    |  | (34) |'
- en: where $\boldsymbol{\phi}_{r},\boldsymbol{\phi}_{e}$ are parameters for the relation
    net and encoder respectively. Intuitively, the three summations ensure that every
    example with class $n$ in $D^{tr}_{\mathcal{T}_{j}}$ is paired with every example
    from all classes $n$. Given $\boldsymbol{\mu}_{n}^{e}$, and $\boldsymbol{\sigma}_{n}^{e}$,
    one can sample a latent code $\boldsymbol{z}_{n}\backsim N(\boldsymbol{\mu}_{n}^{e},diag(\boldsymbol{\sigma}_{n}^{e2}))$
    for class $n$, which serves as latent embedding of the task training data.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\boldsymbol{\phi}_{r},\boldsymbol{\phi}_{e}$ 分别是关系网络和编码器的参数。直观上，三个求和确保 $D^{tr}_{\mathcal{T}_{j}}$
    中的每个类别 $n$ 的示例都与所有类别 $n$ 的示例配对。给定 $\boldsymbol{\mu}_{n}^{e}$ 和 $\boldsymbol{\sigma}_{n}^{e}$，可以为类别
    $n$ 采样潜在代码 $\boldsymbol{z}_{n}\backsim N(\boldsymbol{\mu}_{n}^{e},diag(\boldsymbol{\sigma}_{n}^{e2}))$，这作为任务训练数据的潜在嵌入。
- en: The decoder can then generate a task-specific initialization $\boldsymbol{\theta}_{n}$
    for class $n$ as follows. First, one computes a mean and variance for a Gaussian
    distribution using the latent code
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器可以生成类别 $n$ 的任务特定初始化 $\boldsymbol{\theta}_{n}$。首先，使用潜在代码计算高斯分布的均值和方差。
- en: '|  | $\displaystyle\boldsymbol{\mu}_{n}^{d},\boldsymbol{\sigma}_{n}^{d}=g_{\boldsymbol{\phi}_{d}}(\boldsymbol{z}_{n}).$
    |  | (35) |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\mu}_{n}^{d},\boldsymbol{\sigma}_{n}^{d}=g_{\boldsymbol{\phi}_{d}}(\boldsymbol{z}_{n}).$
    |  | (35) |'
- en: These are then used to sample initialization weights $\boldsymbol{\theta}_{n}\backsim
    N(\boldsymbol{\mu}^{d}_{n},diag(\boldsymbol{\sigma}^{d2}_{n}))$. The loss from
    the generated weights can then be propagated backwards to adjust the embedding
    space. In practice, generating such a high-dimensional set of parameters from
    a low-dimensional embedding can be quite problematic. Therefore, LEO uses pre-trained
    models, and only generates weights for the final layer, which limits the expressivity
    of the model.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 这些用于采样初始化权重 $\boldsymbol{\theta}_{n}\backsim N(\boldsymbol{\mu}^{d}_{n},diag(\boldsymbol{\sigma}^{d2}_{n}))$。然后从生成的权重中得到的损失可以向后传播以调整嵌入空间。在实践中，从低维嵌入生成如此高维的参数集可能会很有问题。因此，LEO
    使用预训练模型，只生成最终层的权重，这限制了模型的表达能力。
- en: A key advantage of LEO is that it optimizes in a lower-dimensional latent embedding
    space, which aids generalization performance. However, the approach is more complex
    than e.g. MAML (Finn et al., [2017](#bib.bib14)), and its applicability is limited
    to few-shot learning settings.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: LEO 的一个关键优势是它在低维潜在嵌入空间中优化，这有助于提高泛化性能。然而，这种方法比例如 MAML (Finn 等，[2017](#bib.bib14))
    更复杂，其适用性仅限于少样本学习环境。
- en: 5.10 Online MAML (FTML)
  id: totrans-428
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.10 在线 MAML (FTML)
- en: Online MAML (Finn et al., [2019](#bib.bib16)) is an extension of MAML (Finn
    et al., [2017](#bib.bib14)) to make it applicable to online learning settings
    (Anderson, [2008](#bib.bib1)). In the online setting, we are presented with a
    sequence of tasks $\mathcal{T}_{t}$ with corresponding loss functions $\{\mathcal{L}_{\mathcal{T}_{t}}\}_{t=1}^{T}$,
    for some potentially infinite time horizon $T$. The goal is to pick a sequence
    of parameters $\{\boldsymbol{\theta}_{t}\}_{t=1}^{T}$ that performs well on the
    presented loss functions. This objective is captured by the $Regret_{T}$ over
    the entire sequence, which is defined by Finn et al. ([2019](#bib.bib16)) as follows
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 在线 MAML (Finn 等，[2019](#bib.bib16)) 是 MAML (Finn 等，[2017](#bib.bib14)) 的扩展，使其适用于在线学习环境
    (Anderson，[2008](#bib.bib1))。在在线环境中，我们会面临一个任务序列 $\mathcal{T}_{t}$ 及其对应的损失函数 $\{\mathcal{L}_{\mathcal{T}_{t}}\}_{t=1}^{T}$，时间范围可能是无限的
    $T$。目标是选择一系列参数 $\{\boldsymbol{\theta}_{t}\}_{t=1}^{T}$，使其在所呈现的损失函数上表现良好。这个目标通过
    Finn 等人 ([2019](#bib.bib16)) 定义的整个序列上的 $Regret_{T}$ 来描述
- en: '|  | $\displaystyle Regret_{T}=\sum_{t=1}^{T}\mathcal{L}_{\mathcal{T}_{t}}(\boldsymbol{\theta}_{t}^{\prime})-min_{\boldsymbol{\theta}}\sum_{t=1}^{T}\mathcal{L}_{\mathcal{T}_{t}}(\boldsymbol{\theta}^{\prime}_{t}),$
    |  | (36) |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Regret_{T}=\sum_{t=1}^{T}\mathcal{L}_{\mathcal{T}_{t}}(\boldsymbol{\theta}_{t}^{\prime})-min_{\boldsymbol{\theta}}\sum_{t=1}^{T}\mathcal{L}_{\mathcal{T}_{t}}(\boldsymbol{\theta}^{\prime}_{t}),$
    |  | (36) |'
- en: where $\boldsymbol{\theta}$ are the initial model parameters (just as MAML),
    and $\boldsymbol{\theta}_{t}^{\prime}$ are parameters resulting from a one-step
    gradient update (starting from $\boldsymbol{\theta}$) on task $t$. Here, the left
    term reflects the updated parameters chosen by the agent $(\boldsymbol{\theta}_{t})$,
    whereas the right term presents the minimum obtainable loss (in hindsight) from
    a single fixed set of parameters $\boldsymbol{\theta}$. Note that this setup assumes
    that the agent can make updates to its chosen parameters (transform its initial
    choice at time $t$ from $\boldsymbol{\theta}_{t}$ to $\boldsymbol{\theta}_{t}^{\prime}$).
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\boldsymbol{\theta}$ 是初始模型参数（与 MAML 一样），而 $\boldsymbol{\theta}_{t}^{\prime}$
    是任务 $t$ 上通过一步梯度更新（从 $\boldsymbol{\theta}$ 开始）得到的参数。在这里，左侧的项反映了由代理选择的更新参数 $(\boldsymbol{\theta}_{t})$，而右侧的项则表示从一组固定的参数
    $\boldsymbol{\theta}$ 中获得的最小可获取损失（事后）。请注意，这种设置假设代理可以对其选择的参数进行更新（将时间 $t$ 时的初始选择从
    $\boldsymbol{\theta}_{t}$ 转变为 $\boldsymbol{\theta}_{t}^{\prime}$）。
- en: Finn et al. ([2019](#bib.bib16)) propose FTML (Follow The Meta Leader), inspired
    by FTL (Follow The Leader) (Hannan, [1957](#bib.bib27); Kalai and Vempala, [2005](#bib.bib38)),
    to minimize the regret. The basic idea is to set the parameters for the next time
    step ($t+1$) equal to the best parameters in hindsight, i.e.,
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: Finn 等人 ([2019](#bib.bib16)) 提出了 FTML（Follow The Meta Leader），灵感来源于 FTL（Follow
    The Leader）（Hannan, [1957](#bib.bib27); Kalai 和 Vempala, [2005](#bib.bib38)），以最小化遗憾。基本思想是将下一时间步（$t+1$）的参数设置为事后最佳参数，即，
- en: '|  | $\displaystyle\boldsymbol{\theta}_{t+1}:=argmin_{\boldsymbol{\theta}}\sum_{k=1}^{t}\mathcal{L}_{\mathcal{T}_{k}}(\boldsymbol{\theta}_{k}^{\prime}).$
    |  | (37) |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\theta}_{t+1}:=argmin_{\boldsymbol{\theta}}\sum_{k=1}^{t}\mathcal{L}_{\mathcal{T}_{k}}(\boldsymbol{\theta}_{k}^{\prime}).$
    |  | (37) |'
- en: The gradient to perform meta-updates is then given by
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 执行元更新的梯度由下式给出
- en: '|  | $\displaystyle g_{t}(\boldsymbol{\theta}):=\nabla_{\boldsymbol{\theta}}\mathbb{E}_{\mathcal{T}_{k}\backsim
    p_{t}(\mathcal{T})}\mathcal{L}_{\mathcal{T}_{k}}(\boldsymbol{\theta}_{k}^{\prime}),$
    |  | (38) |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle g_{t}(\boldsymbol{\theta}):=\nabla_{\boldsymbol{\theta}}\mathbb{E}_{\mathcal{T}_{k}\backsim
    p_{t}(\mathcal{T})}\mathcal{L}_{\mathcal{T}_{k}}(\boldsymbol{\theta}_{k}^{\prime}),$
    |  | (38) |'
- en: where $p_{t}(\mathcal{T})$ is a uniform distribution over tasks $1,\ldots,t$
    (at time $t$).
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p_{t}(\mathcal{T})$ 是任务 $1,\ldots,t$（在时间 $t$ 时）的均匀分布。
- en: '[Algorithm 4](#alg4 "Algorithm 4 ‣ 5.10 Online MAML (FTML) ‣ 5 Optimization-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning") contains the full pseudocode
    for FTML. In this algorithm, $\mathit{MetaUpdate}$ performs a few ($N_{meta}$)
    meta-steps. In each meta-step, a task is sampled from $B$, together with train
    and test mini-batches to compute the gradient $g_{t}$ in [Equation 37](#S5.E37
    "37 ‣ 5.10 Online MAML (FTML) ‣ 5 Optimization-based Meta-Learning ‣ A Survey
    of Deep Meta-Learning"). The initialization $\boldsymbol{\theta}$ is then updated
    ($\boldsymbol{\theta}:=\boldsymbol{\theta}-\beta g_{t}(\boldsymbol{\theta})$),
    where $\beta$ is the meta-learning rate. Note that the memory usage keeps increasing
    over time, as at every time step $t$, we append tasks to the buffer $B$, and keep
    task data sets in memory.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: '[算法 4](#alg4 "算法 4 ‣ 5.10 在线 MAML (FTML) ‣ 5 基于优化的元学习 ‣ 深度元学习概述") 包含了 FTML
    的完整伪代码。在此算法中，$\mathit{MetaUpdate}$ 执行了几个（$N_{meta}$）元步骤。在每个元步骤中，从 $B$ 中抽取一个任务，并提供训练和测试小批量数据以计算梯度
    $g_{t}$，见 [方程 37](#S5.E37 "37 ‣ 5.10 在线 MAML (FTML) ‣ 5 基于优化的元学习 ‣ 深度元学习概述")。初始化的
    $\boldsymbol{\theta}$ 随后会被更新（$\boldsymbol{\theta}:=\boldsymbol{\theta}-\beta g_{t}(\boldsymbol{\theta})$），其中
    $\beta$ 是元学习率。请注意，随着时间的推移，内存使用量不断增加，因为在每个时间步 $t$，我们将任务添加到缓冲区 $B$ 中，并将任务数据集保留在内存中。'
- en: Algorithm 4 FTML by Finn et al. ([2019](#bib.bib16))
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 4 FTML 由 Finn 等人 ([2019](#bib.bib16))
- en: 1:Performance threshold $\gamma$2:Initialize empty task buffer $B$3:for $t=1,\ldots$ do4:     Initialize
    data set $D_{t}=\emptyset$5:     Append $\mathcal{T}_{t}$ to B6:     while $|D_{t}|<N$ do7:         Append
    batch of data $\{(\boldsymbol{x}_{i},y_{i})\}_{i=1}^{n}$ to $D_{t}$8:         $\boldsymbol{\theta}_{t}=\mathit{MetaUpdate}(\boldsymbol{\theta}_{t},B,t)$9:         Compute
    $\boldsymbol{\theta}^{\prime}_{t}$10:         if $\mathcal{L}_{D^{test}_{\mathcal{T}_{t}}}(\boldsymbol{\theta}^{\prime}_{t})<\gamma$ then11:              Save
    $|D_{t}|$ as the efficiency for task $\mathcal{T}_{t}$12:         end if13:     end while14:     Save
    final performance $\mathcal{L}_{D^{test}_{\mathcal{T}_{t}}}$($\boldsymbol{\theta}^{\prime}_{t}$)15:     $\boldsymbol{\theta}_{t+1}=\boldsymbol{\theta}_{t}$16:end for
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 1:性能阈值 $\gamma$ 2:初始化空任务缓冲区 $B$ 3:对于 $t=1,\ldots$ 执行 4:     初始化数据集 $D_{t}=\emptyset$
    5:     将 $\mathcal{T}_{t}$ 添加到 B 中 6:     当 $|D_{t}|<N$ 时 7:         将数据批次 $\{(\boldsymbol{x}_{i},y_{i})\}_{i=1}^{n}$
    添加到 $D_{t}$ 中 8:         $\boldsymbol{\theta}_{t}=\mathit{MetaUpdate}(\boldsymbol{\theta}_{t},B,t)$
    9:         计算 $\boldsymbol{\theta}^{\prime}_{t}$ 10:         如果 $\mathcal{L}_{D^{test}_{\mathcal{T}_{t}}}(\boldsymbol{\theta}^{\prime}_{t})<\gamma$
    11:              将 $|D_{t}|$ 保存为任务 $\mathcal{T}_{t}$ 的效率 12:         结束 if 13:     结束
    while 14:     保存最终性能 $\mathcal{L}_{D^{test}_{\mathcal{T}_{t}}}$($\boldsymbol{\theta}^{\prime}_{t}$)
    15:     $\boldsymbol{\theta}_{t+1}=\boldsymbol{\theta}_{t}$ 16:结束 for
- en: In summary, Online MAML is a robust technique for online-learning (Finn et al.,
    [2019](#bib.bib16)). A downside of this approach is the computational costs that
    keep growing over time, as all encountered data are stored. Reducing these costs
    is a direction for future work. Also, one could experiment with how well the approach
    works when more than one inner gradient update steps per task are used, as mentioned
    by Finn et al. ([2019](#bib.bib16)).
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，在线 MAML 是一种强大的在线学习技术（Finn 等，[2019](#bib.bib16)）。这种方法的一个缺点是计算成本随着时间的推移不断增长，因为所有遇到的数据都会被存储。减少这些成本是未来研究的方向。此外，还可以尝试在每个任务使用多个内梯度更新步骤时，这种方法的效果如何，正如
    Finn 等（[2019](#bib.bib16)）所提到的。
- en: 5.11 LLAMA
  id: totrans-441
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.11 LLAMA
- en: Grant et al. ([2018](#bib.bib23)) mold MAML into a probabilistic framework,
    such that a probability distribution over task-specific parameters $\boldsymbol{\theta}_{j}^{\prime}$
    is learned, instead of a single one. In this way, multiple potential solutions
    can be obtained for a task. The resulting technique is called LLAMA (Laplace Approximation
    for Meta-Adaptation). Importantly, LLAMA is only developed for supervised learning
    settings.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: Grant 等（[2018](#bib.bib23)）将 MAML 模塑为一个概率框架，从而学习任务特定参数 $\boldsymbol{\theta}_{j}^{\prime}$
    的概率分布，而不是单一的值。这样可以为一个任务获得多个潜在解决方案。结果的技术称为 LLAMA（用于元适应的拉普拉斯近似）。重要的是，LLAMA 仅用于监督学习环境。
- en: A key observation is that a neural network $f_{\boldsymbol{\theta}^{\prime}_{j}}$,
    parameterized by updated parameters $\boldsymbol{\theta}^{\prime}_{j}$ (obtained
    from few gradient updates using $D^{tr}_{\mathcal{T}_{j}}$), outputs class probabilities
    $p(y_{i}|\boldsymbol{x}_{i},\boldsymbol{\theta}^{\prime}_{j})$. To minimize the
    error on the query set $D^{test}_{\mathcal{T}_{j}}$, the model must output large
    probability scores for the true classes. This objective is captured in the maximum
    log-likelihood loss function
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键观察是，神经网络 $f_{\boldsymbol{\theta}^{\prime}_{j}}$ 由更新后的参数 $\boldsymbol{\theta}^{\prime}_{j}$
    参数化（通过使用 $D^{tr}_{\mathcal{T}_{j}}$ 的少量梯度更新获得），其输出类别概率 $p(y_{i}|\boldsymbol{x}_{i},\boldsymbol{\theta}^{\prime}_{j})$。为了最小化查询集
    $D^{test}_{\mathcal{T}_{j}}$ 上的错误，模型必须为真实类别输出较大的概率分数。这个目标被最大对数似然损失函数捕捉。
- en: '|  | $\displaystyle\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})=-\sum_{\boldsymbol{x}_{i},y_{i}\in
    D^{test}_{\mathcal{T}_{j}}}log\,p(y_{i}&#124;\boldsymbol{x}_{i},\boldsymbol{\theta}^{\prime}_{j}).$
    |  | (39) |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\theta}^{\prime}_{j})=-\sum_{\boldsymbol{x}_{i},y_{i}\in
    D^{test}_{\mathcal{T}_{j}}}log\,p(y_{i}\mid \boldsymbol{x}_{i},\boldsymbol{\theta}^{\prime}_{j}).$
    |  | (39) |'
- en: Simply put, if we see a task $j$ as a probability distribution over examples
    $p_{\mathcal{T}_{j}}$, we wish to maximize the probability that the model predicts
    the correct class $y_{i}$, given an input $\boldsymbol{x}_{i}$. This can be done
    by plain gradient descent, as shown in [Algorithm 5](#alg5 "Algorithm 5 ‣ 5.11
    LLAMA ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning"),
    where $\beta$ is the meta-learning rate. Line 4 refers to ML-LAPLACE, which is
    a subroutine that computes task-specific updated parameters $\boldsymbol{\theta}^{\prime}_{j}$,
    and estimates the negative log likelihood (loss function) which is used to update
    the initialization $\boldsymbol{\theta}$, as shown in [Algorithm 6](#alg6 "Algorithm
    6 ‣ 5.11 LLAMA ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning").
    Grant et al. ([2018](#bib.bib23)) approximated the quadratic curvature matrix
    $\hat{H}$ using K-FAC (Martens and Grosse, [2015](#bib.bib49)).
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，如果我们将任务 $j$ 看作是对示例的概率分布 $p_{\mathcal{T}_{j}}$，我们希望最大化模型预测正确类别 $y_{i}$ 的概率，给定输入
    $\boldsymbol{x}_{i}$。这可以通过简单的梯度下降来实现，如 [算法 5](#alg5 "Algorithm 5 ‣ 5.11 LLAMA
    ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning") 中所示，其中
    $\beta$ 是元学习率。第 4 行提到的 ML-LAPLACE 是一个子程序，用于计算任务特定的更新参数 $\boldsymbol{\theta}^{\prime}_{j}$，并估计用于更新初始化
    $\boldsymbol{\theta}$ 的负对数似然（损失函数），如 [算法 6](#alg6 "Algorithm 6 ‣ 5.11 LLAMA ‣
    5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning") 中所示。Grant
    等人 ([2018](#bib.bib23)) 使用 K-FAC (Martens and Grosse, [2015](#bib.bib49)) 近似了二次曲率矩阵
    $\hat{H}$。
- en: The trick is that the initialization $\boldsymbol{\theta}$ defines a distribution
    $p(\boldsymbol{\theta}^{\prime}_{j}|\boldsymbol{\theta})$ over task-specific parameters
    $\boldsymbol{\theta}^{\prime}_{j}$. This distribution was taken to be a diagonal
    Gaussian (Grant et al., [2018](#bib.bib23)). Then, to sample solutions for a new
    task $\mathcal{T}_{j}$, one can simply generate possible solutions $\boldsymbol{\theta}^{\prime}_{j}$
    from the learned Gaussian distribution.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 诀窍在于初始化 $\boldsymbol{\theta}$ 定义了一个任务特定参数 $\boldsymbol{\theta}^{\prime}_{j}$
    上的分布 $p(\boldsymbol{\theta}^{\prime}_{j}|\boldsymbol{\theta})$。这个分布被认为是对角高斯分布
    (Grant et al., [2018](#bib.bib23))。然后，为了为新任务 $\mathcal{T}_{j}$ 采样解决方案，可以简单地从学习到的高斯分布中生成可能的解决方案
    $\boldsymbol{\theta}^{\prime}_{j}$。
- en: Algorithm 5 LLAMA by Grant et al. ([2018](#bib.bib23))
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 5 LLAMA 由 Grant 等人 ([2018](#bib.bib23)) 提出
- en: '1:Initialize $\boldsymbol{\theta}$ randomly2:while not converged do3:     Sample
    a batch of $J$ tasks: $B=\mathcal{T}_{1},\ldots,\mathcal{T}_{J}\backsim p(\mathcal{T})$4:     Estimate
    $\mathbb{E}_{(\boldsymbol{x}_{i},y_{i})\backsim p_{\mathcal{T}_{j}}}[-log\,p(y_{i}|\boldsymbol{x}_{i},\boldsymbol{\theta})]\,\forall\mathcal{T}_{j}\in
    B$ using ML-LAPLACE5:     $\boldsymbol{\theta}=\boldsymbol{\theta}-\beta\nabla_{\boldsymbol{\theta}}\sum_{j}\mathbb{E}_{(\boldsymbol{x}_{i},y_{i})\backsim
    p_{\mathcal{T}_{j}}}[-log\,p(y_{i}|\boldsymbol{x}_{i},\boldsymbol{\theta})$6:end while'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '1:随机初始化 $\boldsymbol{\theta}$ 2:当未收敛时 3:     采样一个 $J$ 任务的批次: $B=\mathcal{T}_{1},\ldots,\mathcal{T}_{J}\backsim
    p(\mathcal{T})$ 4:     使用 ML-LAPLACE 估计 $\mathbb{E}_{(\boldsymbol{x}_{i},y_{i})\backsim
    p_{\mathcal{T}_{j}}}[-log\,p(y_{i}|\boldsymbol{x}_{i},\boldsymbol{\theta})]\,\forall\mathcal{T}_{j}\in
    B$ 5:     $\boldsymbol{\theta}=\boldsymbol{\theta}-\beta\nabla_{\boldsymbol{\theta}}\sum_{j}\mathbb{E}_{(\boldsymbol{x}_{i},y_{i})\backsim
    p_{\mathcal{T}_{j}}}[-log\,p(y_{i}|\boldsymbol{x}_{i},\boldsymbol{\theta})$ 6:结束
    当'
- en: Algorithm 6 ML-LAPLACE (Grant et al., [2018](#bib.bib23))
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 6 ML-LAPLACE (Grant et al., [2018](#bib.bib23))
- en: 1:$\boldsymbol{\theta}^{\prime}_{j}=\boldsymbol{\theta}$2:for $k=1,\ldots,K$ do3:     $\boldsymbol{\theta}^{\prime}_{j}=\boldsymbol{\theta}^{\prime}_{j}+\alpha\nabla_{\boldsymbol{\theta}^{\prime}_{j}}log\,p(y_{i}\in
    D^{tr}_{\mathcal{T}_{j}}|\boldsymbol{\theta}^{\prime}_{j},\boldsymbol{x}_{i}\in
    D^{tr}_{\mathcal{T}_{j}})$4:end for5:Compute curvature matrix $\hat{H}=\nabla_{\boldsymbol{\theta}^{\prime}_{j}}^{2}[-log\,p(y_{i}\in
    D^{test}_{\mathcal{T}_{j}}|\boldsymbol{\theta}^{\prime}_{j},\boldsymbol{x}_{i}\in
    D^{test}_{\mathcal{T}_{j}})]+\nabla_{\boldsymbol{\theta}^{\prime}_{j}}^{2}[-log\,p(\boldsymbol{\theta}^{\prime}_{j}|\boldsymbol{\theta})]$6:return
    $-log\,p(y_{i}\in D^{test}_{\mathcal{T}_{j}}|\boldsymbol{\theta}^{\prime}_{j},\boldsymbol{x}_{i}\in
    D^{test}_{\mathcal{T}_{j}})+\eta\,log[det(\hat{H})]$
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 1:$\boldsymbol{\theta}^{\prime}_{j}=\boldsymbol{\theta}$2:对 $k=1,\ldots,K$ 执行3:     $\boldsymbol{\theta}^{\prime}_{j}=\boldsymbol{\theta}^{\prime}_{j}+\alpha\nabla_{\boldsymbol{\theta}^{\prime}_{j}}log\,p(y_{i}\in
    D^{tr}_{\mathcal{T}_{j}}|\boldsymbol{\theta}^{\prime}_{j},\boldsymbol{x}_{i}\in
    D^{tr}_{\mathcal{T}_{j}})$4:结束 5:计算曲率矩阵 $\hat{H}=\nabla_{\boldsymbol{\theta}^{\prime}_{j}}^{2}[-log\,p(y_{i}\in
    D^{test}_{\mathcal{T}_{j}}|\boldsymbol{\theta}^{\prime}_{j},\boldsymbol{x}_{i}\in
    D^{test}_{\mathcal{T}_{j}})]+\nabla_{\boldsymbol{\theta}^{\prime}_{j}}^{2}[-log\,p(\boldsymbol{\theta}^{\prime}_{j}|\boldsymbol{\theta})]$6:返回
    $-log\,p(y_{i}\in D^{test}_{\mathcal{T}_{j}}|\boldsymbol{\theta}^{\prime}_{j},\boldsymbol{x}_{i}\in
    D^{test}_{\mathcal{T}_{j}})+\eta\,log[det(\hat{H})]$
- en: In short, LLAMA extends MAML in a probabilistic fashion, such that one can obtain
    multiple solutions for a single task, instead of one. This does, however, increase
    the computational costs. On top of that, the used Laplace approximation (in ML-LAPLACE)
    can be quite inaccurate (Grant et al., [2018](#bib.bib23)).
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，LLAMA 以概率方式扩展了 MAML，使得可以为单一任务获得多个解决方案，而不是一个。然而，这确实增加了计算成本。此外，使用的拉普拉斯近似（在
    ML-LAPLACE 中）可能非常不准确（Grant 等人，[2018](#bib.bib23)）。
- en: 5.12 PLATIPUS
  id: totrans-452
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.12 PLATIPUS
- en: PLATIPUS (Finn et al., [2018](#bib.bib15)) builds upon the probabilistic interpretation
    of LLAMA (Grant et al., [2018](#bib.bib23)), but learns a probability distribution
    over initializations $\boldsymbol{\theta}$, instead of task-specific parameters
    $\boldsymbol{\theta}_{j}^{\prime}$. Thus, PLATIPUS allows one to sample an initialization
    $\boldsymbol{\theta}\backsim p(\boldsymbol{\theta})$, which can be updated with
    gradient descent to obtain task-specific weights (fast weights) $\boldsymbol{\theta}_{j}^{\prime}$.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: PLATIPUS（Finn 等人，[2018](#bib.bib15)）建立在 LLAMA（Grant 等人，[2018](#bib.bib23)）的概率解释基础上，但学习的是初始化
    $\boldsymbol{\theta}$ 的概率分布，而不是任务特定参数 $\boldsymbol{\theta}_{j}^{\prime}$。因此，PLATIPUS
    允许从初始化 $\boldsymbol{\theta}\backsim p(\boldsymbol{\theta})$ 进行采样，并通过梯度下降更新以获得任务特定权重（快速权重）
    $\boldsymbol{\theta}_{j}^{\prime}$。
- en: Algorithm 7 PLATIPUS training algorithm by Finn et al. ([2018](#bib.bib15))
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 7 PLATIPUS 训练算法，作者 Finn 等人 ([2018](#bib.bib15))
- en: 1:Initialize $\boldsymbol{\Theta}=\{\boldsymbol{\mu}_{\boldsymbol{\theta}},\boldsymbol{\sigma}^{2}_{\boldsymbol{\theta}},\boldsymbol{v}_{q},\boldsymbol{\gamma}_{p},\boldsymbol{\gamma}_{q}\}$2:while Not
    done do3:     Sample batch of tasks $B=\{\mathcal{T}_{j}\backsim p(\mathcal{T})\}_{i=1}^{m}$4:     for $\mathcal{T}_{j}\in
    B$ do5:         $D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}}=\mathcal{T}_{j}$6:         Compute
    $\nabla_{\boldsymbol{\mu}_{\boldsymbol{\theta}}}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\mu}_{\boldsymbol{\theta}})$7:         Sample
    $\boldsymbol{\theta}\backsim q=N(\boldsymbol{\mu}_{\boldsymbol{\theta}}-\boldsymbol{\gamma}_{q}\nabla_{\boldsymbol{\mu}_{\boldsymbol{\theta}}}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\mu}_{\boldsymbol{\theta}}),\boldsymbol{v}_{q})$8:         Compute
    $\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})$9:         Compute
    fast weights $\boldsymbol{\theta}^{\prime}_{i}=\boldsymbol{\theta}-\alpha\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})$10:     end for11:     $p(\boldsymbol{\theta}|D^{tr}_{\mathcal{T}_{j}})=N(\boldsymbol{\mu}_{\boldsymbol{\theta}}-\boldsymbol{\gamma}_{p}\nabla_{\boldsymbol{\mu}_{\boldsymbol{\theta}}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\mu}_{\boldsymbol{\theta}}),\boldsymbol{\sigma}^{2}_{\boldsymbol{\theta}})$12:     Compute
    $\nabla_{\boldsymbol{\Theta}}\left[\sum_{\mathcal{T}_{j}}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\phi}_{i})+D_{\mathit{KL}}(q(\boldsymbol{\theta}|D^{test}_{\mathcal{T}_{j}}),p(\boldsymbol{\theta}|D^{tr}_{\mathcal{T}_{j}}))\right]$13:     Update
    $\boldsymbol{\Theta}$ using the Adam optimizer14:end while
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: '1: 初始化 $\boldsymbol{\Theta}=\{\boldsymbol{\mu}_{\boldsymbol{\theta}},\boldsymbol{\sigma}^{2}_{\boldsymbol{\theta}},\boldsymbol{v}_{q},\boldsymbol{\gamma}_{p},\boldsymbol{\gamma}_{q}\}$
    2: 当 未完成 时 3:     采样任务批次 $B=\{\mathcal{T}_{j}\backsim p(\mathcal{T})\}_{i=1}^{m}$
    4:     对于 $\mathcal{T}_{j}\in B$  5:        $D^{tr}_{\mathcal{T}_{j}},D^{test}_{\mathcal{T}_{j}}=\mathcal{T}_{j}$
    6:        计算 $\nabla_{\boldsymbol{\mu}_{\boldsymbol{\theta}}}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\mu}_{\boldsymbol{\theta}})$
    7:        采样 $\boldsymbol{\theta}\backsim q=N(\boldsymbol{\mu}_{\boldsymbol{\theta}}-\boldsymbol{\gamma}_{q}\nabla_{\boldsymbol{\mu}_{\boldsymbol{\theta}}}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\mu}_{\boldsymbol{\theta}}),\boldsymbol{v}_{q})$
    8:        计算 $\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})$
    9:        计算快速权重 $\boldsymbol{\theta}^{\prime}_{i}=\boldsymbol{\theta}-\alpha\nabla_{\boldsymbol{\theta}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\theta})$
    10:     结束 for 11:     $p(\boldsymbol{\theta}|D^{tr}_{\mathcal{T}_{j}})=N(\boldsymbol{\mu}_{\boldsymbol{\theta}}-\boldsymbol{\gamma}_{p}\nabla_{\boldsymbol{\mu}_{\boldsymbol{\theta}}}\mathcal{L}_{D^{tr}_{\mathcal{T}_{j}}}(\boldsymbol{\mu}_{\boldsymbol{\theta}}),\boldsymbol{\sigma}^{2}_{\boldsymbol{\theta}})$
    12:     计算 $\nabla_{\boldsymbol{\Theta}}\left[\sum_{\mathcal{T}_{j}}\mathcal{L}_{D^{test}_{\mathcal{T}_{j}}}(\boldsymbol{\phi}_{i})+D_{\mathit{KL}}(q(\boldsymbol{\theta}|D^{test}_{\mathcal{T}_{j}}),p(\boldsymbol{\theta}|D^{tr}_{\mathcal{T}_{j}}))\right]$
    13:     使用 Adam 优化器更新 $\boldsymbol{\Theta}$ 14: 结束 while'
- en: The approach is best explained by its pseudocode, as shown in [Algorithm 7](#alg7
    "Algorithm 7 ‣ 5.12 PLATIPUS ‣ 5 Optimization-based Meta-Learning ‣ A Survey of
    Deep Meta-Learning"). In contrast to the original MAML, PLATIPUS introduces five
    more parameter vectors (line 1). All of these parameters are used to facilitate
    the creation of Gaussian distributions over prior initializations (or simply priors)
    $\boldsymbol{\theta}$. That is, $\boldsymbol{\mu}_{\boldsymbol{\theta}}$ represents
    the vector mean of the distributions. $\boldsymbol{\sigma}^{2}_{\boldsymbol{q}}$,
    and $\boldsymbol{v}_{q}$ represent the covariances of train and test distributions
    respectively. $\boldsymbol{\gamma}_{x}$ for $x=q,p$ are learning rate vectors
    for performing gradient steps on distributions $q$ (line 6 and 7) and $P$ (line
    11).
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法通过其伪代码解释得最为清楚，如[算法 7](#alg7 "Algorithm 7 ‣ 5.12 PLATIPUS ‣ 5 Optimization-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning")所示。与原始的MAML相比，PLATIPUS引入了五个额外的参数向量（第1行）。所有这些参数都用于促进在先验初始化（或简单地说，先验）$\boldsymbol{\theta}$上创建高斯分布。也就是说，$\boldsymbol{\mu}_{\boldsymbol{\theta}}$表示分布的向量均值。$\boldsymbol{\sigma}^{2}_{\boldsymbol{q}}$和$\boldsymbol{v}_{q}$分别表示训练和测试分布的协方差。$\boldsymbol{\gamma}_{x}$（对于$x=q,p$）是对分布$q$（第6行和第7行）和$P$（第11行）进行梯度更新的学习率向量。
- en: 'The key difference with the regular MAML is that instead of having a single
    initialization point $\boldsymbol{\theta}$, we now learn distributions over priors:
    $q$ and $P$, which are based on query and support data sets of task $\mathcal{T}_{j}$
    respectively. Since these data sets come from the same task, we want the distributions
    $q(\boldsymbol{\theta}|D^{test}_{\mathcal{T}_{j}})$, and $p(\boldsymbol{\theta}|D^{tr}_{\mathcal{T}_{j}})$
    to be close to each other. This is enforced by the Kullback–Leibler divergence
    ($D_{\mathit{KL}}$) loss term on line 12, which measures the distance between
    the two distributions. Importantly, note that $q$ (line 7) and $P$ (line 11) use
    vector means which are computed with one gradient update steps using the query
    and support data sets respectively. The idea is that the mean of the Gaussian
    distributions should be close to the updated mean $\boldsymbol{\mu}_{\boldsymbol{\theta}}$
    because we want to enable fast learning. As one can see, the training process
    is very similar to that of MAML (Finn et al., [2017](#bib.bib14)) ([Section 5.5](#S5.SS5
    "5.5 MAML ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning")),
    with some small adjustments to allow us to work with the probability distributions
    over $\boldsymbol{\theta}$.'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 与常规MAML的关键区别在于，我们不再有单一的初始化点$\boldsymbol{\theta}$，而是学习基于任务$\mathcal{T}_{j}$的查询和支持数据集的先验分布：$q$和$P$。由于这些数据集来自同一任务，我们希望分布$q(\boldsymbol{\theta}|D^{test}_{\mathcal{T}_{j}})$和$p(\boldsymbol{\theta}|D^{tr}_{\mathcal{T}_{j}})$彼此接近。这通过第12行的Kullback–Leibler散度（$D_{\mathit{KL}}$）损失项来强制执行，该损失项测量两个分布之间的距离。重要的是，注意到$q$（第7行）和$P$（第11行）使用的是通过一个梯度更新步骤计算的向量均值，分别使用查询和支持数据集。这个想法是，高斯分布的均值应该接近更新后的均值$\boldsymbol{\mu}_{\boldsymbol{\theta}}$，因为我们希望实现快速学习。如可以看到，训练过程与MAML（Finn等，[2017](#bib.bib14)）([第5.5节](#S5.SS5
    "5.5 MAML ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning"))非常相似，只是做了一些小的调整，以使我们能够处理关于$\boldsymbol{\theta}$的概率分布。
- en: At test-time, one can simply sample a new initialization $\boldsymbol{\theta}$
    from the prior distribution $p(\boldsymbol{\theta}|D^{tr}_{\mathcal{T}_{j}})$
    (note that $q$ cannot be used at test-time as we do not have access to $D^{test}_{\mathcal{T}_{j}}$),
    and apply a gradient update on the provided support set $D^{tr}_{\mathcal{T}_{j}}$.
    Note that this allows us to sample multiple potential initializations $\boldsymbol{\theta}$
    for the given task.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试时，可以从先验分布$p(\boldsymbol{\theta}|D^{tr}_{\mathcal{T}_{j}})$中简单地采样一个新的初始化$\boldsymbol{\theta}$（注意$q$在测试时不能使用，因为我们无法访问$D^{test}_{\mathcal{T}_{j}}$），然后在提供的支持集$D^{tr}_{\mathcal{T}_{j}}$上应用梯度更新。请注意，这允许我们为给定任务采样多个潜在初始化$\boldsymbol{\theta}$。
- en: The key advantage of PLATIPUS is that it is aware of its uncertainty, which
    greatly increases the applicability of Deep Meta-Learning in critical domains
    such as medical diagnosis (Finn et al., [2018](#bib.bib15)). Based on this uncertainty,
    it can ask for labels of some inputs it is unsure about (active learning). A downside
    to this approach, however, is the increased computational costs, and the fact
    that it is not applicable to reinforcement learning.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: PLATIPUS 的关键优势在于它能够意识到自身的不确定性，这大大增加了深度元学习在医疗诊断等关键领域的适用性（Finn et al., [2018](#bib.bib15)）。基于这种不确定性，它可以要求对一些不确定的输入进行标注（主动学习）。然而，这种方法的一个缺点是计算成本增加，并且不适用于强化学习。
- en: 5.13 Bayesian MAML (BMAML)
  id: totrans-460
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.13 贝叶斯 MAML（BMAML）
- en: Bayesian MAML (Yoon et al., [2018](#bib.bib92)) is another probabilistic variant
    of MAML that can generate multiple solutions. However, instead of learning a distribution
    over potential solutions, BMAML simply keeps $M$ possible solutions, and optimizes
    them in joint fashion. Recall that probabilistic MAMLs (e.g., PLATIPUS) attempt
    to maximize the data likelihood of task $\mathcal{T}_{j}$, i.e., $p(\boldsymbol{y}^{test}_{j}|\boldsymbol{\theta}^{\prime}_{j})$,
    where $\boldsymbol{\theta}^{\prime}_{j}$ are task-specific fast weights obtained
    by one or more gradient updates. Yoon et al. ([2018](#bib.bib92)) model this likelihood
    using Stein Variational Gradient Descent (SVGD) (Liu and Wang, [2016](#bib.bib48)).
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯 MAML（Yoon et al., [2018](#bib.bib92)）是 MAML 的另一种概率变体，可以生成多个解。然而，BMAML 不是学习潜在解的分布，而是简单地保持
    $M$ 个可能的解，并以联合方式对其进行优化。回顾一下，概率 MAML（例如，PLATIPUS）试图最大化任务 $\mathcal{T}_{j}$ 的数据似然，即
    $p(\boldsymbol{y}^{test}_{j}|\boldsymbol{\theta}^{\prime}_{j})$，其中 $\boldsymbol{\theta}^{\prime}_{j}$
    是通过一次或多次梯度更新获得的任务特定快速权重。Yoon et al. ([2018](#bib.bib92)) 使用 Stein 变分梯度下降（SVGD）（Liu
    和 Wang, [2016](#bib.bib48)）来建模这种似然。
- en: To obtain $M$ solutions, or equivalently, parameter settings $\boldsymbol{\theta}^{m}$,
    SVGD keeps a set of $M$ particles $\boldsymbol{\Theta}=\{\boldsymbol{\theta}^{m}\}_{i=1}^{M}$.
    At iteration $t$, every $\boldsymbol{\theta}_{t}\in\boldsymbol{\Theta}$ is updated
    as follows
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得 $M$ 个解，或等效地，参数设置 $\boldsymbol{\theta}^{m}$，SVGD 保持一组 $M$ 个粒子 $\boldsymbol{\Theta}=\{\boldsymbol{\theta}^{m}\}_{i=1}^{M}$。在迭代
    $t$ 时，每个 $\boldsymbol{\theta}_{t}\in\boldsymbol{\Theta}$ 的更新方式如下
- en: '|  | $\displaystyle\boldsymbol{\theta}_{t+1}=\boldsymbol{\theta}_{t}+\epsilon(\phi(\boldsymbol{\theta}_{t}))$
    |  | (40) |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\theta}_{t+1}=\boldsymbol{\theta}_{t}+\epsilon(\phi(\boldsymbol{\theta}_{t}))$
    |  | (40) |'
- en: '|  | $\displaystyle\text{ where }\phi(\boldsymbol{\theta}_{t})=\frac{1}{M}\sum_{m=1}^{M}\left[k(\boldsymbol{\theta}^{m}_{t},\boldsymbol{\theta}_{t})\nabla_{\boldsymbol{\theta}^{m}_{t}}log\,p(\boldsymbol{\theta}_{t}^{m})+\nabla_{\boldsymbol{\theta}_{t}^{m}}k(\boldsymbol{\theta}^{m}_{t},\boldsymbol{\theta}_{t})\right].$
    |  | (41) |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{ 其中 }\phi(\boldsymbol{\theta}_{t})=\frac{1}{M}\sum_{m=1}^{M}\left[k(\boldsymbol{\theta}^{m}_{t},\boldsymbol{\theta}_{t})\nabla_{\boldsymbol{\theta}^{m}_{t}}log\,p(\boldsymbol{\theta}_{t}^{m})+\nabla_{\boldsymbol{\theta}_{t}^{m}}k(\boldsymbol{\theta}^{m}_{t},\boldsymbol{\theta}_{t})\right].$
    |  | (41) |'
- en: Here, $k(\boldsymbol{x},\boldsymbol{x}^{\prime})$ is a similarity kernel between
    $\boldsymbol{x}$ and $\boldsymbol{x}^{\prime}$. The authors used a radial basis
    function (RBF) kernel, but in theory, any other kernel could be used. Note that
    the update of one particle depends on the other gradients of particles. The first
    term in the summation ($k(\boldsymbol{\theta}^{m}_{t},\boldsymbol{\theta}_{t})\nabla_{\boldsymbol{\theta}^{m}_{t}}log\,p(\boldsymbol{\theta}_{t}^{m})$)
    moves the particle in the direction of the gradients of other particles, based
    on particle similarity. The second term ($\nabla_{\boldsymbol{\theta}_{t}^{m}}k(\boldsymbol{\theta}^{m}_{t},\boldsymbol{\theta}_{t})$)
    ensures that particles do not collapse (repulsive force) (Yoon et al., [2018](#bib.bib92)).
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，$k(\boldsymbol{x},\boldsymbol{x}^{\prime})$ 是 $\boldsymbol{x}$ 和 $\boldsymbol{x}^{\prime}$
    之间的相似性核。作者使用了径向基函数（RBF）核，但理论上可以使用任何其他核。请注意，一个粒子的更新依赖于其他粒子的梯度。求和中的第一项（$k(\boldsymbol{\theta}^{m}_{t},\boldsymbol{\theta}_{t})\nabla_{\boldsymbol{\theta}^{m}_{t}}log\,p(\boldsymbol{\theta}_{t}^{m})$）使粒子沿着其他粒子的梯度方向移动，基于粒子的相似性。第二项（$\nabla_{\boldsymbol{\theta}_{t}^{m}}k(\boldsymbol{\theta}^{m}_{t},\boldsymbol{\theta}_{t})$）确保粒子不会坍缩（排斥力）（Yoon
    et al., [2018](#bib.bib92)）。
- en: These particles can then be used to approximate the probability distribution
    of the test labels
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 这些粒子可以用来近似测试标签的概率分布。
- en: '|  | $\displaystyle p(\boldsymbol{y}^{test}_{j}&#124;\boldsymbol{\theta}^{\prime}_{j})\approx\frac{1}{M}\sum_{m=1}^{M}p(\boldsymbol{y}_{j}^{test}&#124;\boldsymbol{\theta}^{m}_{\mathcal{T}_{j}}),$
    |  | (42) |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle p(\boldsymbol{y}^{test}_{j}&#124;\boldsymbol{\theta}^{\prime}_{j})\approx\frac{1}{M}\sum_{m=1}^{M}p(\boldsymbol{y}_{j}^{test}&#124;\boldsymbol{\theta}^{m}_{\mathcal{T}_{j}}),$
    |  | (42) |'
- en: where $\boldsymbol{\theta}_{\mathcal{T}_{j}}^{m}$ is the $m$-th particle obtained
    by training on the support set $D^{tr}_{\mathcal{T}_{j}}$ of task $\mathcal{T}_{j}$.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\boldsymbol{\theta}_{\mathcal{T}_{j}}^{m}$ 是通过在任务 $\mathcal{T}_{j}$ 的支持集
    $D^{tr}_{\mathcal{T}_{j}}$ 上进行训练获得的第 $m$ 个粒子。
- en: Yoon et al. ([2018](#bib.bib92)) proposed a new meta-loss to train BMAML, called
    the Chaser Loss. This loss relies on the insight that we want the approximated
    parameter distribution (obtained from the support set $p^{n}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{\mathcal{T}_{j}}|D^{tr},\boldsymbol{\Theta}_{0})$)
    and true distribution $p^{\infty}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{\mathcal{T}_{j}}|D^{tr}\cup
    D^{test})$ to be close to each other (since the task is the same). Here, $n$ denotes
    the number of SVGD steps, and $\boldsymbol{\Theta}_{0}$ is the set of initial
    particles, in similar fashion to the initial parameters $\boldsymbol{\theta}$
    seen by MAML. Since the true distribution is unknown, Yoon et al. ([2018](#bib.bib92))
    approximate it by running SVGD for $s$ additional steps, granting us the leader
    $\boldsymbol{\Theta}^{n+s}_{\mathcal{T}_{j}}$, where the $s$ additional steps
    are performed on the combined support and query set. The intuition is that as
    the number of updates increases, the obtained distributions become more like the
    true ones. $\boldsymbol{\Theta}^{n}_{\mathcal{T}_{j}}$ in this context is called
    the chaser as it wants to get closer to the leader. The proposed meta-loss is
    then given by
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: Yoon 等人（[2018](#bib.bib92)）提出了一种新的元损失来训练 BMAML，称为追赶损失（Chaser Loss）。这个损失依赖于这样一个洞察：我们希望近似的参数分布（从支持集
    $p^{n}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{\mathcal{T}_{j}}|D^{tr},\boldsymbol{\Theta}_{0})$
    获得）与真实分布 $p^{\infty}_{\mathcal{T}_{j}}(\boldsymbol{\theta}_{\mathcal{T}_{j}}|D^{tr}\cup
    D^{test})$ 彼此接近（因为任务是相同的）。这里，$n$ 表示 SVGD 步数，$\boldsymbol{\Theta}_{0}$ 是初始粒子集合，与
    MAML 看到的初始参数 $\boldsymbol{\theta}$ 类似。由于真实分布未知，Yoon 等人（[2018](#bib.bib92)）通过运行
    SVGD 进行额外的 $s$ 步来逼近它，从而得到领导者 $\boldsymbol{\Theta}^{n+s}_{\mathcal{T}_{j}}$，其中这
    $s$ 步是在组合支持集和查询集上进行的。直觉是，随着更新次数的增加，获得的分布会越来越接近真实分布。在这种情况下，$\boldsymbol{\Theta}^{n}_{\mathcal{T}_{j}}$
    被称为追赶者，因为它想要更接近领导者。提出的元损失为
- en: '|  | $\displaystyle\mathcal{L}_{BMAML}(\boldsymbol{\Theta}_{0})=\sum_{\mathcal{T}_{j}\in
    B}\sum_{m=1}^{M}&#124;&#124;\boldsymbol{\theta}_{\mathcal{T}_{j}}^{n,m}-\boldsymbol{\theta}_{\mathcal{T}_{j}}^{n+s,m}&#124;&#124;^{2}_{2}.$
    |  | (43) |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{BMAML}(\boldsymbol{\Theta}_{0})=\sum_{\mathcal{T}_{j}\in
    B}\sum_{m=1}^{M}&#124;&#124;\boldsymbol{\theta}_{\mathcal{T}_{j}}^{n,m}-\boldsymbol{\theta}_{\mathcal{T}_{j}}^{n+s,m}&#124;&#124;^{2}_{2}.$
    |  | (43) |'
- en: The full pseudocode of BMAML is shown in [Algorithm 8](#alg8 "Algorithm 8 ‣
    5.13 Bayesian MAML (BMAML) ‣ 5 Optimization-based Meta-Learning ‣ A Survey of
    Deep Meta-Learning"). Here, $\boldsymbol{\Theta}^{n}_{\mathcal{T}_{j}}(\boldsymbol{\Theta}_{0})$
    denotes the set of particles after $n$ updates on task $\mathcal{T}_{j}$, and
    $SG$ means “stop gradients" (we do not want the leader to depend on the initialization,
    as the leader must lead).
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: BMAML 的完整伪代码见 [算法 8](#alg8 "Algorithm 8 ‣ 5.13 Bayesian MAML (BMAML) ‣ 5 Optimization-based
    Meta-Learning ‣ A Survey of Deep Meta-Learning")。这里，$\boldsymbol{\Theta}^{n}_{\mathcal{T}_{j}}(\boldsymbol{\Theta}_{0})$
    表示在任务 $\mathcal{T}_{j}$ 上经过 $n$ 次更新后的粒子集合，而 $SG$ 表示“停止梯度”（我们不希望领导者依赖于初始化，因为领导者必须引领）。
- en: Algorithm 8 BMAML by Yoon et al. ([2018](#bib.bib92))
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 8 BMAML，Yoon 等人（[2018](#bib.bib92)）
- en: 1:Initialize $\boldsymbol{\Theta}_{0}$2:for $t=1,\ldots$ until convergence do3:     Sample
    a batch of tasks B from $p(\mathcal{T})$4:     for task $\mathcal{T}_{j}\in B$ do5:         Compute
    chaser $\boldsymbol{\Theta}^{n}_{\mathcal{T}_{j}}(\boldsymbol{\Theta}_{0})=SVGD_{n}(\boldsymbol{\Theta}_{0};D^{tr}_{\mathcal{T}_{j}},\alpha)$6:         Compute
    leader $\boldsymbol{\Theta}^{n+s}_{\mathcal{T}_{j}}(\boldsymbol{\Theta}_{0})=SVGD_{s}(\boldsymbol{\Theta}^{n}_{\mathcal{T}_{j}}(\boldsymbol{\Theta}_{0});D^{tr}_{\mathcal{T}_{j}}\cup
    D^{test}_{\mathcal{T}_{j}},\alpha)$7:     end for8:     $\boldsymbol{\Theta}_{0}=\boldsymbol{\Theta}_{0}-\beta\nabla_{\boldsymbol{\Theta}_{0}}\sum_{\mathcal{T}_{j}\in
    B}d(\boldsymbol{\Theta}^{n}_{\mathcal{T}_{j}}(\boldsymbol{\Theta}_{0}),SG(\boldsymbol{\Theta}^{n+s}_{\mathcal{T}_{j}}(\boldsymbol{\Theta}_{0})))$9:end for
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 1:初始化 $\boldsymbol{\Theta}_{0}$ 2:对于 $t=1,\ldots$ 直到收敛为止 3:     从 $p(\mathcal{T})$
    中采样一个任务批次 B 4:     对于任务 $\mathcal{T}_{j}\in B$ 5:         计算追踪者 $\boldsymbol{\Theta}^{n}_{\mathcal{T}_{j}}(\boldsymbol{\Theta}_{0})=SVGD_{n}(\boldsymbol{\Theta}_{0};D^{tr}_{\mathcal{T}_{j}},\alpha)$
    6:         计算领头者 $\boldsymbol{\Theta}^{n+s}_{\mathcal{T}_{j}}(\boldsymbol{\Theta}_{0})=SVGD_{s}(\boldsymbol{\Theta}^{n}_{\mathcal{T}_{j}}(\boldsymbol{\Theta}_{0});D^{tr}_{\mathcal{T}_{j}}\cup
    D^{test}_{\mathcal{T}_{j}},\alpha)$ 7:     结束 循环 8:     $\boldsymbol{\Theta}_{0}=\boldsymbol{\Theta}_{0}-\beta\nabla_{\boldsymbol{\Theta}_{0}}\sum_{\mathcal{T}_{j}\in
    B}d(\boldsymbol{\Theta}^{n}_{\mathcal{T}_{j}}(\boldsymbol{\Theta}_{0}),SG(\boldsymbol{\Theta}^{n+s}_{\mathcal{T}_{j}}(\boldsymbol{\Theta}_{0})))$
    9:结束 循环
- en: In summary, BMAML is a robust optimization-based meta-learning technique that
    can propose $M$ potential solutions to a task. Additionally, it is applicable
    to reinforcement learning by using Stein Variational Policy Gradient instead of
    SVGD. A downside of this approach is that one has to keep $M$ parameter sets in
    memory, which does not scale well. Reducing the memory costs is a direction for
    future work (Yoon et al., [2018](#bib.bib92)). Furthermore, SVGD is sensitive
    to the selected kernel function, which was pre-defined in BMAML. However, Yoon
    et al. ([2018](#bib.bib92)) point out that it may be beneficial to learn the kernel
    function instead. This is another possibility for future research.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 总结而言，BMAML 是一种基于优化的稳健元学习技术，可以为一个任务提出 $M$ 个潜在解决方案。此外，通过使用 Stein 变分策略梯度代替 SVGD，它还适用于强化学习。这种方法的一个缺点是必须在内存中保持
    $M$ 个参数集，这样的规模扩展性较差。减少内存开销是未来工作的一个方向（Yoon 等人，[2018](#bib.bib92)）。此外，SVGD 对选定的核函数敏感，而
    BMAML 中的核函数是预定义的。然而，Yoon 等人 ([2018](#bib.bib92)) 指出，学习核函数可能更有利。这是未来研究的另一个可能性。
- en: 5.14 Simple Differentiable Solvers
  id: totrans-475
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.14 简单可微分求解器
- en: Bertinetto et al. ([2019](#bib.bib7)) take a quite different approach. That
    is, they pick simple base-learners that have an analytical closed-form solution.
    The intuition is that the existence of a closed-form solution allows for good
    learning efficiency. They propose two techniques using this principle, namely
    R2-D2 (Ridge Regression Differentiable Discriminator), and LR-D2 (Logistic Regression
    Differentiable Discriminator). We cover both in turn.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: Bertinetto 等人 ([2019](#bib.bib7)) 采取了相当不同的方法。也就是说，他们选择具有解析闭式解的简单基本学习器。直观上，闭式解的存在可以实现良好的学习效率。他们提出了两种使用这一原则的技术，即
    R2-D2（岭回归可微分鉴别器）和 LR-D2（逻辑回归可微分鉴别器）。我们将逐一介绍这两种技术。
- en: Let $g_{\boldsymbol{\phi}}:X\rightarrow\mathbb{R}^{e}$ be a pre-trained input
    embedding model (e.g. a CNN), which outputs embeddings with a dimensionality of
    $e$. Furthermore, assume that we use a linear predictor function $f(g_{\boldsymbol{\phi}}(\boldsymbol{x}_{i}))=g_{\boldsymbol{\phi}}(\boldsymbol{x}_{i})W$,
    where $W$ is a $e\times o$ weight matrix, and $o$ is the output dimensionality
    (of the label). When using (regularized) Ridge Regression (done by R2-D2), one
    uses the optimal $W$, i.e.,
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 设 $g_{\boldsymbol{\phi}}:X\rightarrow\mathbb{R}^{e}$ 是一个预训练的输入嵌入模型（例如 CNN），它输出维度为
    $e$ 的嵌入。此外，假设我们使用一个线性预测函数 $f(g_{\boldsymbol{\phi}}(\boldsymbol{x}_{i}))=g_{\boldsymbol{\phi}}(\boldsymbol{x}_{i})W$，其中
    $W$ 是一个 $e\times o$ 权重矩阵，$o$ 是输出维度（标签的维度）。当使用（正则化的）岭回归（由 R2-D2 完成）时，使用的是最佳的 $W$，即：
- en: '|  | $\displaystyle W^{*}$ | $\displaystyle=\operatorname*{arg\,min}_{W}\,&#124;&#124;XW-Y&#124;&#124;^{2}_{2}+\gamma&#124;&#124;W&#124;&#124;^{2}$
    |  |'
  id: totrans-478
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle W^{*}$ | $\displaystyle=\operatorname*{arg\,min}_{W}\,&#124;&#124;XW-Y&#124;&#124;^{2}_{2}+\gamma&#124;&#124;W&#124;&#124;^{2}$
    |  |'
- en: '|  |  | $\displaystyle=(X^{T}X+\gamma I)^{-1}X^{T}Y,$ |  | (44) |'
  id: totrans-479
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=(X^{T}X+\gamma I)^{-1}X^{T}Y,$ |  | (44) |'
- en: where $X\in\mathbb{R}^{n\times e}$ is the input matrix, containing $n$ rows
    (one for each embedded input $g_{\boldsymbol{\phi}}(\boldsymbol{x}_{i})$), $Y\in\mathbb{R}^{n\times
    o}$ is the output matrix with correct outputs corresponding to the inputs, and
    $\gamma$ is a regularization term to prevent overfitting. Note that the analytical
    solution contains the term $(X^{T}X)\in\mathbb{R}^{e\times e}$, which is quadratic
    in the size of the embeddings. Since $e$ can become quite large when using deep
    neural networks, Bertinetto et al. ([2019](#bib.bib7)) use Woodburry’s identity
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$X\in\mathbb{R}^{n\times e}$是输入矩阵，包含$n$行（每行对应一个嵌入输入$g_{\boldsymbol{\phi}}(\boldsymbol{x}_{i})$），$Y\in\mathbb{R}^{n\times
    o}$是输出矩阵，对应于输入的正确输出，$\gamma$是一个正则化项，用于防止过拟合。请注意，解析解中包含了项$(X^{T}X)\in\mathbb{R}^{e\times
    e}$，该项在嵌入的大小上是二次的。由于在使用深度神经网络时$e$可能会变得非常大，Bertinetto等人（[2019](#bib.bib7)）使用Woodburry恒等式
- en: '|  | $\displaystyle W^{*}=X^{T}(XX^{T}+\gamma I)^{-1}Y,$ |  | (45) |'
  id: totrans-481
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle W^{*}=X^{T}(XX^{T}+\gamma I)^{-1}Y,$ |  | (45) |'
- en: where $XX^{T}\in\mathbb{R}^{n\times n}$ is linear in the embedding size, and
    quadratic in the number of examples, which is more manageable in few-shot settings,
    where $n$ is very small. To make predictions with this Ridge Regression based
    model, one can compute
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$XX^{T}\in\mathbb{R}^{n\times n}$在嵌入大小上是线性的，在样本数量上是二次的，这在少量样本设置中更容易处理，因为$n$非常小。为了使用这种基于Ridge回归的模型进行预测，可以计算
- en: '|  | $\displaystyle\hat{Y}=\alpha X_{test}W^{*}+\beta,$ |  | (46) |'
  id: totrans-483
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\hat{Y}=\alpha X_{test}W^{*}+\beta,$ |  | (46) |'
- en: where $\alpha$ and $\beta$ are hyperparameters of the base-learner that can
    be learned by the meta-learner, and $X_{test}\in\mathbb{R}^{m\times e}$ corresponds
    to the $m$ test inputs of a given task. Thus, the meta-learner needs to learn
    $\alpha,\beta,\gamma$, and $\boldsymbol{\phi}$ (embedding weights of the CNN).
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\alpha$和$\beta$是基础学习器的超参数，可以由元学习器学习，$X_{test}\in\mathbb{R}^{m\times e}$对应于给定任务的$m$个测试输入。因此，元学习器需要学习$\alpha,\beta,\gamma$和$\boldsymbol{\phi}$（CNN的嵌入权重）。
- en: The technique can also be applied to iterative solvers when the optimization
    steps are differentiable (Bertinetto et al., [2019](#bib.bib7)). LR-D2 uses the
    Logistic Regression objective and Newton’s method as solver. Outputs $\boldsymbol{y}\in\{-1,+1\}^{n}$
    are now binary. Let $\boldsymbol{w}$ denote a parameter row of our linear model
    (parameterized by $W$). Then, the $i$-th iteration of Newton’s method updates
    $\boldsymbol{w}_{i}$ as follows
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术也可以应用于当优化步骤是可微分时的迭代求解器（Bertinetto等人，[2019](#bib.bib7)）。LR-D2使用Logistic回归目标和Newton方法作为求解器。输出$\boldsymbol{y}\in\{-1,+1\}^{n}$现在是二元的。令$\boldsymbol{w}$表示我们线性模型的参数行（由$W$参数化）。然后，Newton方法的第$i$次迭代更新$\boldsymbol{w}_{i}$如下
- en: '|  | $\displaystyle\boldsymbol{w}_{i}=(X^{T}\mbox{diag}(\boldsymbol{s}_{i})X+\gamma
    I)^{-1}X^{T}\mbox{diag}(\boldsymbol{s}_{i})\boldsymbol{z}_{i},$ |  | (47) |'
  id: totrans-486
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{w}_{i}=(X^{T}\mbox{diag}(\boldsymbol{s}_{i})X+\gamma
    I)^{-1}X^{T}\mbox{diag}(\boldsymbol{s}_{i})\boldsymbol{z}_{i},$ |  | (47) |'
- en: where $\boldsymbol{\mu}_{i}=\sigma(\boldsymbol{w}^{T}_{i-1}X)$, $\boldsymbol{s}_{i}=\boldsymbol{\mu}_{i}(1-\boldsymbol{\mu}_{i})$,
    $\boldsymbol{z}_{i}=\boldsymbol{w}^{T}_{i-1}X+(\boldsymbol{y}-\boldsymbol{\mu}_{i})/\boldsymbol{s}_{i}$,
    and $\sigma$ is the sigmoid function. Since the term $X^{T}\mbox{diag}(\boldsymbol{s}_{i})X$
    is a matrix of size $e\times e$, and thus again quadratic in the embedding size,
    Woodburry’s identity is also applied here to obtain
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\boldsymbol{\mu}_{i}=\sigma(\boldsymbol{w}^{T}_{i-1}X)$，$\boldsymbol{s}_{i}=\boldsymbol{\mu}_{i}(1-\boldsymbol{\mu}_{i})$，$\boldsymbol{z}_{i}=\boldsymbol{w}^{T}_{i-1}X+(\boldsymbol{y}-\boldsymbol{\mu}_{i})/\boldsymbol{s}_{i}$，而$\sigma$是sigmoid函数。由于项$X^{T}\mbox{diag}(\boldsymbol{s}_{i})X$是一个大小为$e\times
    e$的矩阵，因此在嵌入大小上又是二次的，Woodburry恒等式在这里也被应用以得到
- en: '|  | $\displaystyle\boldsymbol{w}_{i}=X^{T}(XX^{T}+\lambda\mbox{diag}(\boldsymbol{s}_{i})^{-1})^{-1}\boldsymbol{z}_{i},$
    |  | (48) |'
  id: totrans-488
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{w}_{i}=X^{T}(XX^{T}+\lambda\mbox{diag}(\boldsymbol{s}_{i})^{-1})^{-1}\boldsymbol{z}_{i},$
    |  | (48) |'
- en: making it quadratic in the input size, which is not a big problem since $n$
    is small in the few-shot setting. The main difference compared to R2-D2 is that
    the base-solver has to be run for multiple iterations to obtain $W$.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 使得它在输入大小上是二次的，这在少量样本设置中并不是一个大问题，因为$n$较小。与R2-D2相比，主要的区别是基础求解器必须运行多次迭代才能获得$W$。
- en: In the few-shot setting, the base-level optimizers compute the weight matrix
    $W$ for a given task $\mathcal{T}_{i}$. The obtained loss on the query set of
    a task $\mathcal{L}_{D_{test}}$ is then used to update the parameters $\boldsymbol{\phi}$
    of the input embedding function (e.g. CNN) and the hyperparameters of the base-learner.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 在少样本设置中，基础优化器计算给定任务$\mathcal{T}_{i}$的权重矩阵$W$。然后，任务的查询集上的损失$\mathcal{L}_{D_{test}}$被用来更新输入嵌入函数（例如CNN）的参数$\boldsymbol{\phi}$和基础学习器的超参数。
- en: Lee et al. ([2019](#bib.bib45)) have done similar work to Bertinetto et al.
    ([2019](#bib.bib7)), but with linear Support Vector Machines (SVMs) as base-learner.
    Their approach is dubbed MetaOptNet and achieved state-of-the-art performance
    on few-shot image classification.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: Lee等人（[2019](#bib.bib45)）做了与Bertinetto等人（[2019](#bib.bib7)）类似的工作，但使用了线性支持向量机（SVMs）作为基本学习器。他们的方法被称为MetaOptNet，并在少样本图像分类上取得了最先进的性能。
- en: In short, simple differentiable solvers are simple, reasonably fast in terms
    of computation time, but limited to few-shot learning settings. Investigating
    the use of other simple base-learners is a direction for future work.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，简单的可微分求解器简单、计算时间上相对较快，但仅限于少样本学习设置。调查使用其他简单基础学习器是未来的研究方向。
- en: 5.15 Optimization-based Techniques, in conclusion
  id: totrans-493
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.15 基于优化的技术，总结
- en: Optimization-based aim to learn new tasks quickly through (learned) optimization
    procedures. Note that this closely resembles base-level learning, which also occurs
    through optimization (e.g., gradient descent). However, in contrast to base-level
    techniques, optimization-based meta-learners can learn the optimizer and/or are
    exposed to multiple tasks, which allows them to learn how to learn new tasks quickly.
    [Figure 28](#S5.F28 "Figure 28 ‣ 5.15 Optimization-based Techniques, in conclusion
    ‣ 5 Optimization-based Meta-Learning ‣ A Survey of Deep Meta-Learning") shows
    the relationships between the covered optimization-based techniques.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 基于优化的技术旨在通过（学习的）优化程序快速学习新任务。请注意，这与基础学习非常相似，基础学习也是通过优化（例如梯度下降）进行的。然而，与基础技术相比，基于优化的元学习器可以学习优化器和/或接触多个任务，从而使它们能够快速学习新任务。[图28](#S5.F28
    "图28 ‣ 5.15 基于优化的技术，总结 ‣ 5 基于优化的元学习 ‣ 深度元学习综述")显示了所覆盖的基于优化的技术之间的关系。
- en: '![Refer to caption](img/da5278a5c5f3709afe144485b7f0251c.png)'
  id: totrans-495
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/da5278a5c5f3709afe144485b7f0251c.png)'
- en: 'Figure 28: The relationships between the covered optimization-based meta-learning
    techniques. As one can see, MAML has a central position in this graph of techniques
    as it has inspired many other works.'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 图28：所覆盖的基于优化的元学习技术之间的关系。可以看出，MAML在这些技术图中占据了核心位置，因为它激发了许多其他工作。
- en: As we can see, the LSTM optimizer (Andrychowicz et al., [2016](#bib.bib2)),
    which replaces hand-crafted optimization procedures such as gradient descent by
    a trainable LSTM, can be seen as the starting point for these optimization-based
    meta-learning techniques. Li and Malik ([2018](#bib.bib46)) also aim to learn
    the optimization procedure with reinforcement learning instead of gradient-based
    methods. The LSTM meta-learner (Ravi and Larochelle, [2017](#bib.bib65)) extends
    the LSTM optimizer to the few-shot setting by not only learning the optimization
    procedure but also a good set of initial weights. This way, it can be used across
    tasks. MAML (Finn et al., [2017](#bib.bib14)) is a simplification of the LSTM
    meta-learner as it replaces the trainable LSTM optimizer by hand-crafted gradient
    descent. MAML has received considerable attention within the field of deep meta-learning,
    and has, as one can see, inspired many other works.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，LSTM优化器（Andrychowicz等人，[2016](#bib.bib2)），它通过可训练的LSTM替代了诸如梯度下降之类的手工优化程序，可以被视为这些基于优化的元学习技术的起点。Li和Malik（[2018](#bib.bib46)）也旨在通过强化学习而不是基于梯度的方法来学习优化过程。LSTM元学习器（Ravi和Larochelle，[2017](#bib.bib65)）将LSTM优化器扩展到少样本设置，不仅学习优化过程，还学习一组良好的初始权重。这样，它可以跨任务使用。MAML（Finn等人，[2017](#bib.bib14)）是LSTM元学习器的简化版，因为它用手工梯度下降替代了可训练的LSTM优化器。MAML在深度元学习领域受到广泛关注，并激发了许多其他工作。
- en: Meta-SGD is an enhancement of MAML that not only learns the initial parameters,
    but also the learning rates (Li et al., [2017](#bib.bib47)). LLAMA (Grant et al.,
    [2018](#bib.bib23)), PLATIPUS (Finn et al., [2018](#bib.bib15)), and online MAML
    (Finn et al., [2019](#bib.bib16)) extend MAML to the active and online learning
    settings. LLAMA and PLATIPUS are probabilistic interpretations of MAML, which
    allow them to sample multiple solutions for a given task and quantify their uncertainty.
    BMAML (Yoon et al., [2018](#bib.bib92)) takes a more discrete approach as it jointly
    optimizes a discrete set of $M$ initializations. iMAML (Rajeswaran et al., [2019](#bib.bib64))
    aims to overcome the computational expenses associated with the computation of
    second-order derivatives, which is needed by MAML. Through implicit differentiation,
    they also allow for the use of non-differentiable inner loop optimization procedures.
    Reptile (Nichol et al., [2018](#bib.bib58)) is an elegant first-order meta-learning
    algorithm for finding a set of initial parameters and removes the need for computing
    higher-order derivatives. LEO (Rusu et al., [2018](#bib.bib67)) tries to improve
    the robustness of MAML by optimizing in lower-dimensional parameter space through
    the use of an encoder-decoder architecture. Lastly, R2-D2, LR-D2 (Bertinetto et al.,
    [2019](#bib.bib7)), and Lee et al. ([2019](#bib.bib45)) use simple classical machine
    learning methods (ridge regression, logistic regression, SVM, respectively) as
    a classifier on top of a learned feature extractor.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: Meta-SGD 是 MAML 的一种增强版本，不仅学习初始参数，还学习学习率（Li et al., [2017](#bib.bib47)）。LLAMA（Grant
    et al., [2018](#bib.bib23)）、PLATIPUS（Finn et al., [2018](#bib.bib15)）和在线 MAML（Finn
    et al., [2019](#bib.bib16)）将 MAML 扩展到主动学习和在线学习环境中。LLAMA 和 PLATIPUS 是 MAML 的概率解释，允许它们为给定任务采样多个解决方案并量化不确定性。BMAML（Yoon
    et al., [2018](#bib.bib92)）采取了更离散的方法，它共同优化一组离散的 $M$ 个初始化。iMAML（Rajeswaran et al.,
    [2019](#bib.bib64)）旨在克服 MAML 所需的二阶导数计算的计算开销。通过隐式微分，它们还允许使用不可微分的内循环优化程序。Reptile（Nichol
    et al., [2018](#bib.bib58)）是一种优雅的一阶元学习算法，用于找到一组初始参数，并消除了计算高阶导数的需要。LEO（Rusu et
    al., [2018](#bib.bib67)）通过使用编码器-解码器架构，在较低维参数空间中优化，试图提高 MAML 的鲁棒性。最后，R2-D2、LR-D2（Bertinetto
    et al., [2019](#bib.bib7)）和 Lee et al.（[2019](#bib.bib45)）在学习特征提取器上方使用简单的经典机器学习方法（岭回归、逻辑回归、SVM）作为分类器。
- en: A key advantage of optimization-based approaches is that they can achieve better
    performance on wider task distributions than, e.g., model-based approaches (Finn
    and Levine, [2018](#bib.bib13)). However, optimization-based techniques optimize
    a base-learner for every task that they are presented with and/or learn the optimization
    procedure, which is computationally expensive (Hospedales et al., [2020](#bib.bib32)).
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 基于优化的方法的一个关键优势是，它们可以在更广泛的任务分布上实现比例如模型基方法（Finn 和 Levine, [2018](#bib.bib13)）更好的性能。然而，基于优化的技术会为每个呈现的任务优化一个基础学习者和/或学习优化过程，这在计算上是昂贵的（Hospedales
    et al., [2020](#bib.bib32)）。
- en: Optimization-based meta-learning is a very active area of research. We expect
    future work to be done in order to reduce the computational demands of these methods
    and improve the solution quality and level of generalization. We think that benchmarking
    and reproducibility research will play an important role in these improvements.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 基于优化的元学习是一个非常活跃的研究领域。我们期望未来的工作将减少这些方法的计算需求，并提高解决方案的质量和泛化水平。我们认为基准测试和可重复性研究将在这些改进中发挥重要作用。
- en: 6 Concluding Remarks
  id: totrans-501
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this section, we give a helicopter view of all that we discussed, and the
    field of Deep Meta-Learning in general. We will also discuss challenges and future
    research.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将对我们讨论的内容以及深度元学习领域做一个宏观的概述。我们还将讨论挑战和未来的研究方向。
- en: 6.1 Overview
  id: totrans-503
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 概述
- en: In recent years, there has been a shift in focus in the broad meta-learning
    community. Traditional algorithm selection and hyperparameter optimization for
    classical machine learning techniques (e.g. Support Vector Machines, Logistic
    Regression, Random Forests, etc.) have been augmented by Deep Meta-Learning, or
    equivalently, the pursuit of self-improving neural networks that can leverage
    prior learning experience to learn new tasks more quickly. Instead of training
    a new model from scratch for different tasks, we can use the same (meta-learning)
    model across tasks. As such, meta-learning can widen the applicability of powerful
    deep learning techniques to domains where fewer data are available and computational
    resources are limited.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，广泛的元学习社区发生了关注点的转变。传统的算法选择和经典机器学习技术（如支持向量机、逻辑回归、随机森林等）的超参数优化已被深度元学习所增强，或者等同于寻求自我提升的神经网络，这些网络能够利用先前的学习经验更快地学习新任务。我们可以在不同任务中使用相同的（元学习）模型，而不是从头开始训练一个新模型。因此，元学习可以扩大强大的深度学习技术在数据较少且计算资源有限的领域的适用性。
- en: Deep Meta-Learning techniques are characterized by their meta-objective, which
    allows them to maximize performance across various tasks, instead of a single
    one, as is the case in base-level learning objectives. This meta-objective is
    reflected in the training procedure of meta-learning methods, as they learn on
    a set of different meta-training tasks. The few-shot setting lends itself nicely
    towards this end, as tasks consist of few data points. This makes it computationally
    feasible to train on many different tasks, and it allows us to evaluate whether
    a neural network can learn new concepts from few examples. Task construction for
    training and evaluation does require some special attention. That is, it has been
    shown beneficial to match training and test conditions (Vinyals et al., [2016](#bib.bib86)),
    and perhaps train in a more difficult setting than the one that will be used for
    evaluation (Snell et al., [2017](#bib.bib74)).
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 深度元学习技术的特点是其元目标，这使得它们能够在多个任务上最大化性能，而不仅仅是单个任务，这与基础级学习目标的情况不同。这个元目标体现在元学习方法的训练过程中，因为它们在一组不同的元训练任务上进行学习。少样本设置非常适合这个目标，因为任务由少量数据点组成。这使得在许多不同任务上训练变得计算上可行，并且可以评估神经网络是否能够从少量示例中学习新概念。任务构建用于训练和评估确实需要特别关注。也就是说，已经证明匹配训练和测试条件是有益的（Vinyals
    等，[2016](#bib.bib86)），并且可能在比评估时更困难的设置中进行训练（Snell 等，[2017](#bib.bib74)）。
- en: On a high level, there are three categories of Deep Meta-Learning techniques,
    namely i) metric-, ii) model-, and iii) optimization-based ones, which rely on
    i) computing input similarity, ii) task embeddings with states, and iii) task-specific
    updates, respectively. Each approach has strengths and weaknesses. Metric-learning
    techniques are simple and effective (Garcia and Bruna, [2017](#bib.bib17)) but
    are not readily applicable outside of the supervised learning setting (Hospedales
    et al., [2020](#bib.bib32)). Model-based techniques, on the other hand, can have
    very flexible internal dynamics, but lack generalization ability to more distant
    tasks than the ones used at meta-train time (Finn and Levine, [2018](#bib.bib13)).
    Optimization-based approaches have shown greater generalizability, but are in
    general computationally expensive, as they optimize a base-learner for every task
    (Finn and Levine, [2018](#bib.bib13); Hospedales et al., [2020](#bib.bib32)).
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，深度元学习技术分为三类，即 i) 度量基础、ii) 模型基础和 iii) 优化基础的方法，分别依赖于 i) 计算输入相似度、ii) 任务嵌入与状态、和
    iii) 任务特定更新。每种方法都有其优缺点。度量学习技术简单有效（Garcia 和 Bruna，[2017](#bib.bib17)），但不容易应用于监督学习环境之外（Hospedales
    等，[2020](#bib.bib32)）。另一方面，基于模型的技术具有非常灵活的内部动态，但在面对与元训练时间不同的任务时缺乏泛化能力（Finn 和 Levine，[2018](#bib.bib13)）。基于优化的方法显示出更好的泛化能力，但通常计算开销较大，因为它们需要为每个任务优化一个基础学习者（Finn
    和 Levine，[2018](#bib.bib13)；Hospedales 等，[2020](#bib.bib32)）。
- en: '[Table 2](#S2.T2 "Table 2 ‣ 2.4 Overview of the rest of this Work ‣ 2 Foundation
    ‣ A Survey of Deep Meta-Learning") provides a concise, tabular overview of these
    approaches. Many techniques have been proposed for each one of the categories,
    and the underlying ideas may vary greatly, even within the same category. [Table 3](#S2.T3
    "Table 3 ‣ 2.4 Overview of the rest of this Work ‣ 2 Foundation ‣ A Survey of
    Deep Meta-Learning"), therefore, provides an overview of all methods and key ideas
    that we have discussed in this work, together with their applicability to supervised
    learning (SL) and reinforcement learning (RL) settings, key ideas, and benchmarks
    that were used for testing them. [Table 5](#S6.T5 "Table 5 ‣ 6.1 Overview ‣ 6
    Concluding Remarks ‣ A Survey of Deep Meta-Learning") displays an overview of
    the 1- and 5-shot classification performances (reported by the original authors)
    of the techniques on the frequently used miniImageNet benchmark. Moreover, it
    displays the used backbone (feature extraction module) as well as the final classification
    mechanism. From this table, it becomes clear that the 5-shot performance is typically
    better than the 1-shot performance, indicating that data scarcity is a large bottleneck
    for achieving good performance. Moreover, there is a strong relationship between
    the expressivity of the backbone and the performance. That is, deeper backbones
    tend to give rise to better classification performance. The best performance is
    achieved by MetaOptNet, yielding a 1-shot accuracy of $64.09$% and a 5-shot accuracy
    of $80.00$%. Note however that MetaOptNet used a deeper backbone than most of
    the other techniques.'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: '[表2](#S2.T2 "Table 2 ‣ 2.4 Overview of the rest of this Work ‣ 2 Foundation
    ‣ A Survey of Deep Meta-Learning") 提供了这些方法的简明表格概述。每个类别都提出了许多技术，而这些技术的基本思想可能在同一类别内差异很大。因此，[表3](#S2.T3
    "Table 3 ‣ 2.4 Overview of the rest of this Work ‣ 2 Foundation ‣ A Survey of
    Deep Meta-Learning") 提供了我们在这项工作中讨论的所有方法和关键思想的概述，包括它们在监督学习（SL）和强化学习（RL）设置中的适用性、关键思想以及用于测试它们的基准。[表5](#S6.T5
    "Table 5 ‣ 6.1 Overview ‣ 6 Concluding Remarks ‣ A Survey of Deep Meta-Learning")
    显示了这些技术在常用的 miniImageNet 基准上的 1-shot 和 5-shot 分类性能（原作者报告的）。此外，它显示了使用的主干网络（特征提取模块）以及最终分类机制。从这个表格中可以明显看出，5-shot
    性能通常优于 1-shot 性能，表明数据稀缺性是实现良好性能的一个重要瓶颈。此外，主干网络的表现力与性能之间存在强烈关系。也就是说，更深的主干网络往往会带来更好的分类性能。最佳性能由
    MetaOptNet 实现，其 1-shot 准确率为 $64.09$% 和 5-shot 准确率为 $80.00$%。但需注意，MetaOptNet 使用的主干网络比大多数其他技术更深。'
- en: '| Name | Backbone | Classifier | 1-shot | 5-shot |'
  id: totrans-508
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 主干网络 | 分类器 | 1-shot | 5-shot |'
- en: '| Metric-based |  |  |  |  |'
  id: totrans-509
  prefs: []
  type: TYPE_TB
  zh: '| Metric-based |  |  |  |  |'
- en: '| Siamese nets | - | - | - |  |'
  id: totrans-510
  prefs: []
  type: TYPE_TB
  zh: '| Siamese nets | - | - | - |  |'
- en: '| Matching nets | 64-64-64-64 | Cosine sim. | $43.56\pm 0.84$ | $55.31\pm 0.73$
    |'
  id: totrans-511
  prefs: []
  type: TYPE_TB
  zh: '| Matching nets | 64-64-64-64 | Cosine sim. | $43.56\pm 0.84$ | $55.31\pm 0.73$
    |'
- en: '| Prototypical nets | 64-64-64-64 | Euclidean dist. | $49.42\pm 0.78$ | $68.20\pm
    0.66$ |'
  id: totrans-512
  prefs: []
  type: TYPE_TB
  zh: '| Prototypical nets | 64-64-64-64 | Euclidean dist. | $49.42\pm 0.78$ | $68.20\pm
    0.66$ |'
- en: '| Relation nets | 64-96-128-256 | Sim. network | $50.44\pm 0.82$ | $65.32\pm
    0.70$ |'
  id: totrans-513
  prefs: []
  type: TYPE_TB
  zh: '| Relation nets | 64-96-128-256 | Sim. network | $50.44\pm 0.82$ | $65.32\pm
    0.70$ |'
- en: '| ARC | - | 64-1 dense | $49.14\pm-$ | - |'
  id: totrans-514
  prefs: []
  type: TYPE_TB
  zh: '| ARC | - | 64-1 dense | $49.14\pm-$ | - |'
- en: '| GNN | 64-96-128-256 | Softmax | $50.33\pm 0.36$ | $66.41\pm 0.63$ |'
  id: totrans-515
  prefs: []
  type: TYPE_TB
  zh: '| GNN | 64-96-128-256 | Softmax | $50.33\pm 0.36$ | $66.41\pm 0.63$ |'
- en: '| Model-based |  |  |  |  |'
  id: totrans-516
  prefs: []
  type: TYPE_TB
  zh: '| Model-based |  |  |  |  |'
- en: '| RMLs | - | - | - |  |'
  id: totrans-517
  prefs: []
  type: TYPE_TB
  zh: '| RMLs | - | - | - |  |'
- en: '| MANNs | - | - | - |  |'
  id: totrans-518
  prefs: []
  type: TYPE_TB
  zh: '| MANNs | - | - | - |  |'
- en: '| Meta nets | 64-64-64-64-64 | 64-Softmax | $49.21\pm 0.96$ | - |'
  id: totrans-519
  prefs: []
  type: TYPE_TB
  zh: '| Meta nets | 64-64-64-64-64 | 64-Softmax | $49.21\pm 0.96$ | - |'
- en: '| SNAIL | Adj. ResNet-12 | Softmax | $55.71\pm 0.99$ | $68.88\pm 0.92$ |'
  id: totrans-520
  prefs: []
  type: TYPE_TB
  zh: '| SNAIL | Adj. ResNet-12 | Softmax | $55.71\pm 0.99$ | $68.88\pm 0.92$ |'
- en: '| CNP | - | - | - |  |'
  id: totrans-521
  prefs: []
  type: TYPE_TB
  zh: '| CNP | - | - | - |  |'
- en: '| Neural stat. | - | - | - |  |'
  id: totrans-522
  prefs: []
  type: TYPE_TB
  zh: '| Neural stat. | - | - | - |  |'
- en: '| Opt.-based |  |  |  |  |'
  id: totrans-523
  prefs: []
  type: TYPE_TB
  zh: '| Opt.-based |  |  |  |  |'
- en: '| LSTM optimizer | - | - | - |  |'
  id: totrans-524
  prefs: []
  type: TYPE_TB
  zh: '| LSTM optimizer | - | - | - |  |'
- en: '| LSTM ml. | 32-32-32-32 | Softmax | $43.44\pm 0.77$ | $60.60\pm 0.71$ |'
  id: totrans-525
  prefs: []
  type: TYPE_TB
  zh: '| LSTM ml. | 32-32-32-32 | Softmax | $43.44\pm 0.77$ | $60.60\pm 0.71$ |'
- en: '| RL optimizer | - | - | - |  |'
  id: totrans-526
  prefs: []
  type: TYPE_TB
  zh: '| RL optimizer | - | - | - |  |'
- en: '| MAML | 32-32-32-32 | Softmax | $48.70\pm 1.84$ | $63.11\pm 0.92$ |'
  id: totrans-527
  prefs: []
  type: TYPE_TB
  zh: '| MAML | 32-32-32-32 | Softmax | $48.70\pm 1.84$ | $63.11\pm 0.92$ |'
- en: '| iMAML | 64-64-64-64 | Softmax | $49.30\pm 1.88$ | - |'
  id: totrans-528
  prefs: []
  type: TYPE_TB
  zh: '| iMAML | 64-64-64-64 | Softmax | $49.30\pm 1.88$ | - |'
- en: '| Meta-SGD | 64-64-64-64 | Softmax | $50.47\pm 1.87$ | $64.03\pm 0.94$ |'
  id: totrans-529
  prefs: []
  type: TYPE_TB
  zh: '| Meta-SGD | 64-64-64-64 | Softmax | $50.47\pm 1.87$ | $64.03\pm 0.94$ |'
- en: '| Reptile | 32-32-32-32 | Softmax | $48.21\pm 0.69$ | $66.00\pm 0.62$ |'
  id: totrans-530
  prefs: []
  type: TYPE_TB
  zh: '| Reptile | 32-32-32-32 | Softmax | $48.21\pm 0.69$ | $66.00\pm 0.62$ |'
- en: '| LEO | WRN-28-10 | Softmax | $61.76\pm 0.08$ | $77.59\pm 0.12$ |'
  id: totrans-531
  prefs: []
  type: TYPE_TB
  zh: '| LEO | WRN-28-10 | Softmax | $61.76\pm 0.08$ | $77.59\pm 0.12$ |'
- en: '| Online MAML | - | - | - |  |'
  id: totrans-532
  prefs: []
  type: TYPE_TB
  zh: '| Online MAML | - | - | - |  |'
- en: '| LLAMA | 64-64-64-64 | Softmax | $49.40\pm 1.83$ | - |'
  id: totrans-533
  prefs: []
  type: TYPE_TB
  zh: '| LLAMA | 64-64-64-64 | Softmax | $49.40\pm 1.83$ | - |'
- en: '| PLATIPUS | - | - | - |  |'
  id: totrans-534
  prefs: []
  type: TYPE_TB
  zh: '| PLATIPUS | - | - | - |  |'
- en: '| BMAML | 64-64-64-64-64 | Softmax | $53.80\pm 1.46$ | - |'
  id: totrans-535
  prefs: []
  type: TYPE_TB
  zh: '| BMAML | 64-64-64-64-64 | Softmax | $53.80\pm 1.46$ | - |'
- en: '| Diff. solvers |  |  |  |  |'
  id: totrans-536
  prefs: []
  type: TYPE_TB
  zh: '| Diff. solvers |  |  |  |  |'
- en: '|           R2-D2 | 96-192-384-512 | Ridge regr. | $51.8\pm 0.2$ | $68.4\pm
    0.2$ |'
  id: totrans-537
  prefs: []
  type: TYPE_TB
  zh: '|           R2-D2 | 96-192-384-512 | Ridge regr. | $51.8\pm 0.2$ | $68.4\pm
    0.2$ |'
- en: '|           LR-D2 | 96-192-384-512 | Log. regr. | $51.90\pm 0.20$ | $68.70\pm
    0.20$ |'
  id: totrans-538
  prefs: []
  type: TYPE_TB
  zh: '|           LR-D2 | 96-192-384-512 | Log. regr. | $51.90\pm 0.20$ | $68.70\pm
    0.20$ |'
- en: '|           MetaOptNet | ResNet-12 | SVM | $\boldsymbol{64.09\pm 0.62}$ | $\boldsymbol{80.00\pm
    0.45}$ |'
  id: totrans-539
  prefs: []
  type: TYPE_TB
  zh: '|           MetaOptNet | ResNet-12 | SVM | $\boldsymbol{64.09\pm 0.62}$ | $\boldsymbol{80.00\pm
    0.45}$ |'
- en: 'Table 5: Comparison of the accuracy scores of the covered meta-learning techniques
    on 1- and 5-shot miniImageNet classification. Scores are taken from the original
    papers. The $\pm$ indicates the 95% confidence interval. The backbone is the used
    feature extraction module. The classifier column shows the final layer(s) that
    were used to transform the features into class predictions. Used abbreviations:
    “sim.": similarity, “Adj.": adjusted, and “dist.": distance, “log.": logistic,
    “regr.": regression, “ml.": meta-learner, “opt.": optimization.'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: '表5：所涵盖的元学习技术在1-shot和5-shot miniImageNet分类中的准确率评分比较。分数取自原始论文。$\pm$表示95%的置信区间。骨干网是所使用的特征提取模块。分类器列显示了用于将特征转化为类别预测的最终层。使用的缩写包括：“sim.”:
    相似性，“Adj.”: 调整，“dist.”: 距离，“log.”: 逻辑回归，“regr.”: 回归，“ml.”: 元学习器，“opt.”: 优化。'
- en: 6.2 Open Challenges and Future Work
  id: totrans-541
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 开放挑战与未来工作
- en: Despite the great potential of Deep Meta-Learning techniques, there are still
    open challenges, which we discuss here.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度元学习技术具有巨大潜力，但仍存在开放的挑战，我们将在此讨论。
- en: '[Figure 1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ A Survey of Deep Meta-Learning")
    in Section [1](#S1 "1 Introduction ‣ A Survey of Deep Meta-Learning") displays
    the accuracy scores of the covered meta-learning techniques on 1-shot miniImageNet
    classification. Techniques that were not tested in this setting by the original
    authors are omitted. As we can see, the performance of the techniques is related
    to the expressivity of the used backbone (ordered in increasing order on the x-axis).
    For example, the best-performing techniques, LEO and MetaOptNet, use the largest
    network architectures. Moreover, the fact that different techniques use different
    backbones poses a problem as it is difficult to fairly compare their classification
    performance. An obvious question arises to which degree the difference in performance
    is due to methodological improvements, or due to the fact that a better backbone
    architecture was chosen. For this reason, we think that it would be useful to
    perform a large-scale benchmark test where techniques are compared when they use
    the same backbones. This would also allow us to get a more clear idea of how the
    expressivity of the feature extraction module affects the performance.'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ A Survey of Deep Meta-Learning") 在第[1节](#S1
    "1 Introduction ‣ A Survey of Deep Meta-Learning")展示了所涵盖的元学习技术在1-shot miniImageNet分类中的准确率评分。未在这种设置中由原作者测试的技术被省略。正如我们所见，这些技术的性能与所使用的骨干网的表现力相关（在x轴上按递增顺序排列）。例如，表现最好的技术LEO和MetaOptNet使用了最大的网络架构。此外，不同技术使用不同骨干网的问题使得公平比较其分类性能变得困难。一个明显的问题是，性能差异在多大程度上是由于方法论改进，还是由于选择了更好的骨干架构。为此，我们认为进行一个大规模的基准测试会很有用，在该测试中对比使用相同骨干网的技术。这也将使我们更清楚地了解特征提取模块的表现力如何影响性能。'
- en: Another challenge of Deep Meta-Learning techniques is that they can be susceptible
    to the memorization problem (meta-overfitting), where the neural network has memorized
    tasks seen at meta-training time and fails to generalize to new tasks. More research
    is required to better understand this problem. Clever task design and meta-regularization
    may prove useful to avoid such problems (Yin et al., [2020](#bib.bib91)).
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 深度元学习技术的另一个挑战是它们可能容易受到记忆问题（元过拟合）的影响，其中神经网络已经记住了在元训练时看到的任务，并且无法对新任务进行泛化。需要更多研究来更好地理解这个问题。巧妙的任务设计和元正则化可能有助于避免这些问题（Yin等，[2020](#bib.bib91)）。
- en: Another problem is that most of the meta-learning techniques discussed in this
    work are evaluated on narrow benchmark sets. This means that the data that the
    meta-learner used for training are not too distant from the data used for evaluating
    its performance. As such, one may wonder how well these techniques are able to
    adapt to more distant tasks. Chen et al. ([2019](#bib.bib9)) showed that the ability
    to adapt to new tasks decreases as they become more distant from the tasks seen
    at training time. Moreover, a simple non-meta-learning baseline (based on pre-training
    and fine-tuning) can outperform state-of-the-art meta-learning techniques when
    meta-test tasks come from a different data set than the one used for meta-training.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作讨论的大多数元学习技术存在另一个问题，即它们在狭窄的基准集上进行评估。这意味着元学习器用于训练的数据与用于评估其性能的数据没有太大差异。因此，人们可能会想知道这些技术能否很好地适应更为不同的任务。陈等人（[2019](#bib.bib9)）表明，随着新任务与训练时看到的任务距离越来越远，适应新任务的能力会下降。此外，一个简单的非元学习基线（基于预训练和微调）在元测试任务来源于与元训练使用的数据集不同的情况下，可以胜过最先进的元学习技术。
- en: In reaction to these findings, Triantafillou et al. ([2020](#bib.bib81)) have
    recently proposed the Meta-Dataset benchmark, which consists of various previously
    used meta-learning benchmarks such as Omniglot (Lake et al., [2011](#bib.bib42))
    and ImageNet (Deng et al., [2009](#bib.bib10)). This way, meta-learning techniques
    can be evaluated in more challenging settings where tasks are diverse. Following
    Hospedales et al. ([2020](#bib.bib32)), we think that this new benchmark can prove
    to be a good means towards the investigation and development of meta-learning
    algorithms for such challenging scenarios.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这些发现，Triantafillou等人（[2020](#bib.bib81)）最近提出了Meta-Dataset基准，其中包括各种先前使用的元学习基准，如Omniglot（Lake等人，[2011](#bib.bib42)）和ImageNet（Deng等人，[2009](#bib.bib10)）。通过这种方式，可以在任务多样的更具挑战性的环境中评估元学习技术。根据Hospedales等人（[2020](#bib.bib32)）的观点，我们认为这一新基准可以成为调查和发展面对这种具有挑战性场景中的元学习算法的良好手段。
- en: As mentioned earlier in this section, Deep Meta-Learning has the appealing prospect
    of widening the applicability of deep learning techniques to more real-world domains.
    For this, increasing the generalization ability of these techniques is very important.
    Additionally, the computational costs associated with the deployment of meta-learning
    techniques should be small. While these techniques can learn new tasks quickly,
    meta-training can be quite computationally expensive. Thus, decreasing the required
    computation time and memory costs of Deep Meta-Learning techniques remains an
    open challenge.
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在本节前面提到的，深度元学习具有将深度学习技术应用于更多真实世界领域的吸引人前景。为此，增强这些技术的泛化能力非常重要。此外，部署元学习技术所涉及的计算成本应该很小。虽然这些技术可以快速学习新任务，但元训练可能是非常计算密集的。因此，减少深度元学习技术所需的计算时间和内存成本仍然是一个未解之谜。
- en: Some real-world problems demand systems that can perform well in online, or
    active learning settings. The investigation of Deep Meta-Learning in these settings
    (Finn et al., [2018](#bib.bib15); Yoon et al., [2018](#bib.bib92); Finn et al.,
    [2019](#bib.bib16); Munkhdalai and Yu, [2017](#bib.bib55); Vuorio et al., [2018](#bib.bib87))
    remains an important direction for future work.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 一些真实世界的问题需要系统能够在在线或主动学习环境中表现良好。在这些环境中研究深度元学习（Finn等人，[2018](#bib.bib15); Yoon等人，[2018](#bib.bib92);
    Finn等人，[2019](#bib.bib16); Munkhdalai和Yu，[2017](#bib.bib55); Vuorio等人，[2018](#bib.bib87)）仍然是未来工作的一个重要方向。
- en: Yet another direction for future research is the creation of compositional Deep
    Meta-Learning systems, which instead of learning flat and associative functions
    $\boldsymbol{x}\rightarrow y$, organize knowledge in a compositional manner. This
    would allow them to decompose an input $\boldsymbol{x}$ into several (already
    learned) components $c_{1}(\boldsymbol{x}),\ldots,c_{n}(\boldsymbol{x})$, which
    in turn could help the performance in low-data regimes (Tokmakov et al., [2019](#bib.bib80)).
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 未来研究的另一个方向是创建组合深度元学习系统，而不是学习扁平和联想的函数$\boldsymbol{x}\rightarrow y$，以组合方式组织知识。这将使它们能够将输入$\boldsymbol{x}$分解成几个（已经学到的）组件$c_{1}(\boldsymbol{x}),\ldots,c_{n}(\boldsymbol{x})$，这反过来可以帮助在低数据情况下的性能（Tokmakov
    et al., [2019](#bib.bib80)）。
- en: The question has been raised whether contemporary Deep Meta-Learning techniques
    actually learn how to perform rapid learning, or simply learn a set of robust
    high-level features, which can be (re)used for many (new) tasks. Raghu et al.
    ([2020](#bib.bib63)) investigated this question for the most popular Deep Meta-Learning
    technique MAML and found that it largely relies on feature reuse. It would be
    interesting to see whether we can develop techniques that rely more upon fast
    learning, and what the effect would be on performance.
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 已提出的问题是，现代深度元学习技术是否真的学会了如何进行快速学习，还是仅仅学会了一组稳健的高层特征，这些特征可以用于许多（新的）任务。Raghu 等人
    ([2020](#bib.bib63)) 针对最流行的深度元学习技术 MAML 调查了这个问题，发现它主要依赖于特征重用。看看我们是否能够开发更多依赖于快速学习的技术，以及这对性能的影响，将是很有趣的。
- en: Lastly, it may be useful to add more meta-abstraction levels, giving rise to,
    e.g., meta-meta-learning, meta-meta-…-learning (Hospedales et al., [2020](#bib.bib32);
    Schmidhuber, [1987](#bib.bib69)).
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，增加更多的元抽象层次可能会有所帮助，从而产生例如元-元学习、元-元-…-学习（Hospedales 等人，[2020](#bib.bib32)；Schmidhuber，[1987](#bib.bib69)）。
- en: Acknowledgements.
  id: totrans-552
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 致谢。
- en: Thanks to Herke van Hoof for an insightful discussion on LLAMA. Thanks to Pavel
    Brazdil for his encouragement and feedback on a preliminary version of this work.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢 Herke van Hoof 对 LLAMA 进行的深入讨论。感谢 Pavel Brazdil 对本工作的初步版本提供的鼓励和反馈。
- en: References
  id: totrans-554
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Anderson (2008) Anderson T (2008) The Theory and Practice of Online Learning.
    AU Press, Athabasca University
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anderson (2008) Anderson T (2008) 在线学习的理论与实践。AU Press，Athabasca 大学。
- en: 'Andrychowicz et al. (2016) Andrychowicz M, Denil M, Colmenarejo SG, Hoffman
    MW, Pfau D, Schaul T, Shillingford B, de Freitas N (2016) Learning to learn by
    gradient descent by gradient descent. In: Advances in Neural Information Processing
    Systems 29, Curran Associates Inc., NIPS’16, pp 3988–3996'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Andrychowicz 等人 (2016) Andrychowicz M, Denil M, Colmenarejo SG, Hoffman MW,
    Pfau D, Schaul T, Shillingford B, de Freitas N (2016) 通过梯度下降学习学习。见于：神经信息处理系统进展
    29，Curran Associates Inc.，NIPS’16，第3988–3996页。
- en: 'Antoniou et al. (2019) Antoniou A, Edwards H, Storkey A (2019) How to train
    your MAML. In: International Conference on Learning Representations, ICLR’19'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Antoniou 等人 (2019) Antoniou A, Edwards H, Storkey A (2019) 如何训练你的 MAML。见于：国际学习表示大会，ICLR’19。
- en: 'Barrett et al. (2018) Barrett DG, Hill F, Santoro A, Morcos AS, Lillicrap T
    (2018) Measuring abstract reasoning in neural networks. In: Proceedings of the
    35th International Conference on Machine Learning, JLMR.org, ICML’18, pp 4477–4486'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barrett 等人 (2018) Barrett DG, Hill F, Santoro A, Morcos AS, Lillicrap T (2018)
    在神经网络中测量抽象推理能力。见于：第35届国际机器学习大会论文集，JLMR.org，ICML’18，第4477–4486页。
- en: 'Bengio et al. (1997) Bengio S, Bengio Y, Cloutier J, Gecsei J (1997) On the
    optimization of a synaptic learning rule. In: Optimality in Artificial and Biological
    Neural Networks, Lawrance Erlbaum Associates, Inc.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengio 等人 (1997) Bengio S, Bengio Y, Cloutier J, Gecsei J (1997) 关于突触学习规则优化的研究。见于：人工和生物神经网络中的最优性，Lawrance
    Erlbaum Associates, Inc.
- en: 'Bengio et al. (1991) Bengio Y, Bengio S, Cloutier J (1991) Learning a synaptic
    learning rule. In: International Joint Conference on Neural Networks, IEEE, IJCNN’91,
    vol 2'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bengio 等人 (1991) Bengio Y, Bengio S, Cloutier J (1991) 学习突触学习规则。见于：国际联合神经网络会议，IEEE，IJCNN’91，第2卷。
- en: 'Bertinetto et al. (2019) Bertinetto L, Henriques JF, Torr PHS, Vedaldi A (2019)
    Meta-learning with differentiable closed-form solvers. In: International Conference
    on Learning Representations, ICLR’19'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bertinetto 等人 (2019) Bertinetto L, Henriques JF, Torr PHS, Vedaldi A (2019)
    使用可微分封闭形式求解器的元学习。见于：国际学习表示大会，ICLR’19。
- en: 'Brazdil et al. (2008) Brazdil P, Carrier CG, Soares C, Vilalta R (2008) Metalearning:
    Applications to Data Mining. Springer-Verlag Berlin Heidelberg'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brazdil 等人 (2008) Brazdil P, Carrier CG, Soares C, Vilalta R (2008) 元学习：数据挖掘应用。Springer-Verlag
    Berlin Heidelberg。
- en: 'Chen et al. (2019) Chen WY, Liu YC, Kira Z, Wang YC, Huang JB (2019) A Closer
    Look at Few-shot Classification. In: International Conference on Learning Representations,
    ICLR’19'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2019) Chen WY, Liu YC, Kira Z, Wang YC, Huang JB (2019) 细看少样本分类。见于：国际学习表示大会，ICLR’19。
- en: 'Deng et al. (2009) Deng J, Dong W, Socher R, Li LJ, Li K, Fei-Fei L (2009)
    ImageNet: A Large-Scale Hierarchical Image Database. In: Proceedings of the IEEE
    Conference on Computer Vision and Pattern Recognition, IEEE, pp 248–255'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng 等人 (2009) Deng J, Dong W, Socher R, Li LJ, Li K, Fei-Fei L (2009) ImageNet：一个大规模层次化图像数据库。见于：IEEE计算机视觉与模式识别大会论文集，IEEE，第248–255页。
- en: 'Duan et al. (2016) Duan Y, Schulman J, Chen X, Bartlett PL, Sutskever I, Abbeel
    P (2016) RL²: Fast Reinforcement Learning via Slow Reinforcement Learning. arXiv
    preprint arXiv:161102779'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Duan 等 (2016) Duan Y, Schulman J, Chen X, Bartlett PL, Sutskever I, Abbeel P
    (2016) RL²：通过慢强化学习实现快速强化学习。arXiv 预印本 arXiv:161102779
- en: 'Edwards and Storkey (2017) Edwards H, Storkey A (2017) Towards a Neural Statistician.
    In: International Conference on Learning Representations, ICLR’17'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Edwards 和 Storkey (2017) Edwards H, Storkey A (2017) 朝向神经统计学家。载于：国际学习表征大会，ICLR’17
- en: 'Finn and Levine (2018) Finn C, Levine S (2018) Meta-Learning and Universality:
    Deep Representations and Gradient Descent can Approximate any Learning Algorithm.
    In: International Conference on Learning Representations, ICLR’18'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Finn 和 Levine (2018) Finn C, Levine S (2018) 元学习与普适性：深度表征和梯度下降可以近似任何学习算法。载于：国际学习表征大会，ICLR’18
- en: 'Finn et al. (2017) Finn C, Abbeel P, Levine S (2017) Model-agnostic Meta-learning
    for Fast Adaptation of Deep Networks. In: Proceedings of the 34th International
    Conference on Machine Learning, JMLR.org, ICML’17, pp 1126–1135'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Finn 等 (2017) Finn C, Abbeel P, Levine S (2017) 模型无关的元学习用于深度网络的快速适应。载于：第34届国际机器学习大会论文集，JMLR.org，ICML’17，第1126–1135页
- en: 'Finn et al. (2018) Finn C, Xu K, Levine S (2018) Probabilistic Model-Agnostic
    Meta-Learning. In: Advances in Neural Information Processing Systems 31, Curran
    Associates Inc., NIPS’18, pp 9516–9527'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Finn 等 (2018) Finn C, Xu K, Levine S (2018) 概率模型无关的元学习。载于：神经信息处理系统进展 31，Curran
    Associates Inc.，NIPS’18，第9516–9527页
- en: 'Finn et al. (2019) Finn C, Rajeswaran A, Kakade S, Levine S (2019) Online Meta-Learning.
    In: Chaudhuri K, Salakhutdinov R (eds) Proceedings of the 36th International Conference
    on Machine Learning, JLMR.org, ICML’19, pp 1920–1930'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Finn 等 (2019) Finn C, Rajeswaran A, Kakade S, Levine S (2019) 在线元学习。载于：Chaudhuri
    K, Salakhutdinov R (编) 第36届国际机器学习大会论文集，JLMR.org，ICML’19，第1920–1930页
- en: 'Garcia and Bruna (2017) Garcia V, Bruna J (2017) Few-Shot Learning with Graph
    Neural Networks. In: International Conference on Learning Representations, ICLR’17'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Garcia 和 Bruna (2017) Garcia V, Bruna J (2017) 基于图神经网络的少样本学习。载于：国际学习表征大会，ICLR’17
- en: 'Garnelo et al. (2018) Garnelo M, Rosenbaum D, Maddison C, Ramalho T, Saxton
    D, Shanahan M, Teh YW, Rezende D, Eslami SMA (2018) Conditional neural processes.
    In: Dy J, Krause A (eds) Proceedings of the 35th International Conference on Machine
    Learning, JMLR.org, ICML’18, vol 80, pp 1704–1713'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Garnelo 等 (2018) Garnelo M, Rosenbaum D, Maddison C, Ramalho T, Saxton D, Shanahan
    M, Teh YW, Rezende D, Eslami SMA (2018) 条件神经过程。载于：Dy J, Krause A (编) 第35届国际机器学习大会论文集，JMLR.org，ICML’18，第80卷，第1704–1713页
- en: Goceri (2019a) Goceri E (2019a) Capsnet topology to classify tumours from brain
    images and comparative evaluation. IET Image Processing 14(5):882–889
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goceri (2019a) Goceri E (2019a) 用于从脑部图像中分类肿瘤的 Capsnet 拓扑及其比较评估。IET 图像处理 14(5)：882–889
- en: 'Goceri (2019b) Goceri E (2019b) Challenges and recent solutions for image segmentation
    in the era of deep learning. In: 2019 ninth international conference on image
    processing theory, tools and applications (IPTA), IEEE, pp 1–6'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goceri (2019b) Goceri E (2019b) 深度学习时代图像分割的挑战与最新解决方案。载于：2019年第九届国际图像处理理论、工具与应用会议
    (IPTA)，IEEE，第1–6页
- en: 'Goceri (2020) Goceri E (2020) Convolutional neural network based desktop applications
    to classify dermatological diseases. In: 2020 IEEE 4th International Conference
    on Image Processing, Applications and Systems (IPAS), IEEE, pp 138–143'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goceri (2020) Goceri E (2020) 基于卷积神经网络的桌面应用程序用于分类皮肤病。载于：2020 IEEE 第4届国际图像处理、应用与系统会议
    (IPAS)，IEEE，第138–143页
- en: 'Goceri and Karakas (2020) Goceri E, Karakas AA (2020) Comparative evaluations
    of cnn based networks for skin lesion classification. In: 14th International Conference
    on Computer Graphics, Visualization, Computer Vision and Image Processing (CGVCVIP),
    Zagreb, Croatia, pp 1–6'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goceri 和 Karakas (2020) Goceri E, Karakas AA (2020) 基于 CNN 网络的皮肤病变分类的比较评估。载于：第14届国际计算机图形学、可视化、计算机视觉与图像处理会议
    (CGVCVIP)，克罗地亚萨格勒布，第1–6页
- en: 'Grant et al. (2018) Grant E, Finn C, Levine S, Darrell T, Griffiths T (2018)
    Recasting Gradient-Based Meta-Learning as Hierarchical Bayes. In: International
    Conference on Learning Representations, ICLR’18'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grant 等 (2018) Grant E, Finn C, Levine S, Darrell T, Griffiths T (2018) 将基于梯度的元学习重构为层次贝叶斯。载于：国际学习表征大会，ICLR’18
- en: Graves et al. (2014) Graves A, Wayne G, Danihelka I (2014) Neural Turing Machines.
    arXiv preprint arXiv:14105401
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Graves 等 (2014) Graves A, Wayne G, Danihelka I (2014) 神经图灵机。arXiv 预印本 arXiv:14105401
- en: 'Gupta et al. (2018) Gupta A, Mendonca R, Liu Y, Abbeel P, Levine S (2018) Meta-Reinforcement
    Learning of Structured Exploration Strategies. In: Advances in Neural Information
    Processing Systems 31, Curran Associates Inc., NIPS’18, pp 5302–5311'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gupta et al. (2018) Gupta A, Mendonca R, Liu Y, Abbeel P, Levine S (2018) 结构化探索策略的元强化学习。发表于：神经信息处理系统进展
    31，Curran Associates Inc.，NIPS’18，第5302–5311页
- en: 'Hamilton et al. (2017) Hamilton WL, Ying R, Leskovec J (2017) Inductive representation
    learning on large graphs. In: Advances in Neural Information Processing Systems,
    Curran Associates Inc., NIPS’17, vol 30, p 1025–1035'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hamilton et al. (2017) Hamilton WL, Ying R, Leskovec J (2017) 在大图上的归纳表示学习。发表于：神经信息处理系统进展，Curran
    Associates Inc.，NIPS’17，第30卷，第1025–1035页
- en: Hannan (1957) Hannan J (1957) Approximation to bayes risk in repeated play.
    Contributions to the Theory of Games 3:97–139
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hannan (1957) Hannan J (1957) 在重复游戏中的贝叶斯风险近似。博弈论贡献 3:97–139
- en: 'Hastie et al. (2009) Hastie T, Tibshirani R, Friedman J (2009) The Elements
    of Statistical Learning: Data Mining, Inference, and Prediction, 2nd edn. Springer,
    New York, NY'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hastie et al. (2009) Hastie T, Tibshirani R, Friedman J (2009) 统计学习的要素：数据挖掘、推断和预测，第2版。Springer，纽约
- en: 'He et al. (2015) He K, Zhang X, Ren S, Sun J (2015) Delving Deep into Rectifiers:
    Surpassing Human-Level Performance on ImageNet Classification. In: Proceedings
    of the IEEE International Conference on Computer Vision, pp 1026–1034'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. (2015) He K, Zhang X, Ren S, Sun J (2015) 深入探讨整流器：超越人类水平的ImageNet分类性能。发表于：IEEE国际计算机视觉会议论文集，第1026–1034页
- en: 'Hinton and Plaut (1987) Hinton GE, Plaut DC (1987) Using Fast Weights to Deblur
    Old Memories. In: Proceedings of the 9th Annual Conference of the Cognitive Science
    Society, pp 177–186'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton and Plaut (1987) Hinton GE, Plaut DC (1987) 使用快速权重来去模糊旧记忆。发表于：第九届认知科学学会年会论文集，第177–186页
- en: 'Hochreiter et al. (2001) Hochreiter S, Younger AS, Conwell PR (2001) Learning
    to Learn Using Gradient Descent. In: International Conference on Artificial Neural
    Networks, Springer, pp 87–94'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hochreiter et al. (2001) Hochreiter S, Younger AS, Conwell PR (2001) 使用梯度下降学习学习。发表于：国际人工神经网络会议，Springer，第87–94页
- en: 'Hospedales et al. (2020) Hospedales T, Antoniou A, Micaelli P, Storkey A (2020)
    Meta-Learning in Neural Networks: A Survey. arXiv preprint arXiv:200405439'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hospedales et al. (2020) Hospedales T, Antoniou A, Micaelli P, Storkey A (2020)
    神经网络中的元学习：综述。arXiv 预印本 arXiv:200405439
- en: Iqbal et al. (2018) Iqbal MS, Luo B, Khan T, Mehmood R, Sadiq M (2018) Heterogeneous
    transfer learning techniques for machine learning. Iran Journal of Computer Science
    1(1):31–46
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iqbal et al. (2018) Iqbal MS, Luo B, Khan T, Mehmood R, Sadiq M (2018) 机器学习的异质迁移学习技术。伊朗计算机科学杂志
    1(1):31–46
- en: Iqbal et al. (2019a) Iqbal MS, El-Ashram S, Hussain S, Khan T, Huang S, Mehmood
    R, Luo B (2019a) Efficient cell classification of mitochondrial images by using
    deep learning. Journal of Optics 48(1):113–122
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iqbal et al. (2019a) Iqbal MS, El-Ashram S, Hussain S, Khan T, Huang S, Mehmood
    R, Luo B (2019a) 利用深度学习进行线粒体图像的高效细胞分类。光学杂志 48(1):113–122
- en: Iqbal et al. (2019b) Iqbal MS, Luo B, Mehmood R, Alrige MA, Alharbey R (2019b)
    Mitochondrial organelle movement classification (fission and fusion) via convolutional
    neural network approach. IEEE Access 7:86570–86577
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iqbal et al. (2019b) Iqbal MS, Luo B, Mehmood R, Alrige MA, Alharbey R (2019b)
    通过卷积神经网络方法进行线粒体细胞器运动分类（分裂与融合）。IEEE Access 7:86570–86577
- en: Iqbal et al. (2020) Iqbal MS, Ahmad I, Bin L, Khan S, Rodrigues JJ (2020) Deep
    learning recognition of diseased and normal cell representation. Transactions
    on Emerging Telecommunications Technologies p e4017
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iqbal et al. (2020) Iqbal MS, Ahmad I, Bin L, Khan S, Rodrigues JJ (2020) 疾病与正常细胞表征的深度学习识别。新兴电信技术交易，第e4017页
- en: Jankowski et al. (2011) Jankowski N, Duch W, Grąbczewski K (2011) Meta-Learning
    in Computational Intelligence, vol 358\. Springer-Verlag Berlin Heidelberg
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jankowski et al. (2011) Jankowski N, Duch W, Grąbczewski K (2011) 计算智能中的元学习，第358卷。Springer-Verlag
    Berlin Heidelberg
- en: Kalai and Vempala (2005) Kalai A, Vempala S (2005) Efficient algorithms for
    online decision problems. Journal of Computer and System Sciences 71(3):291–307
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kalai and Vempala (2005) Kalai A, Vempala S (2005) 在线决策问题的高效算法。计算机与系统科学杂志 71(3):291–307
- en: 'Koch et al. (2015) Koch G, Zemel R, Salakhutdinov R (2015) Siamese Neural Networks
    for One-shot Image Recognition. In: Proceedings of the 32nd International Conference
    on Machine Learning, JMLR.org, ICML’15, vol 37'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koch et al. (2015) Koch G, Zemel R, Salakhutdinov R (2015) 用于一次性图像识别的孪生神经网络。发表于：第32届国际机器学习会议论文集，JMLR.org，ICML’15，第37卷
- en: Krizhevsky (2009) Krizhevsky A (2009) Learning Multiple Layers of Features from
    Tiny Images. Tech. rep., University of Toronto
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky (2009) Krizhevsky A (2009) 从微小图像中学习多层特征。技术报告，多伦多大学
- en: 'Krizhevsky et al. (2012) Krizhevsky A, Sutskever I, Hinton GE (2012) ImageNet
    Classification with Deep Convolutional Neural Networks. In: Advances in Neural
    Information Processing Systems, pp 1097–1105'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky等人（2012）Krizhevsky A, Sutskever I, Hinton GE（2012）《用深度卷积神经网络进行ImageNet分类》。收录于：神经信息处理系统进展，第1097–1105页
- en: 'Lake et al. (2011) Lake B, Salakhutdinov R, Gross J, Tenenbaum J (2011) One
    shot learning of simple visual concepts. In: Proceedings of the annual meeting
    of the cognitive science society, vol 33, pp 2568–2573'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lake等人（2011）Lake B, Salakhutdinov R, Gross J, Tenenbaum J（2011）《单次学习简单视觉概念》。收录于：认知科学学会年会论文集，卷33，第2568–2573页
- en: Lake et al. (2017) Lake BM, Ullman TD, Tenenbaum JB, Gershman SJ (2017) Building
    machines that learn and think like people. Behavioral and brain sciences 40
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lake等人（2017）Lake BM, Ullman TD, Tenenbaum JB, Gershman SJ（2017）《构建像人类一样学习和思考的机器》。《行为与脑科学》40
- en: 'LeCun et al. (2010) LeCun Y, Cortes C, Burges C (2010) MNIST handwritten digit
    database. [http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist),
    accessed: 7-10-2020'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun等人（2010）LeCun Y, Cortes C, Burges C（2010）《MNIST手写数字数据库》。 [http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist)，访问日期：2020年7月10日
- en: 'Lee et al. (2019) Lee K, Maji S, Ravichandran A, Soatto S (2019) Meta-Learning
    with Differentiable Convex Optimization. In: Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition, IEEE, pp 10657–10665'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee等人（2019）Lee K, Maji S, Ravichandran A, Soatto S（2019）《带有可微分凸优化的元学习》。收录于：IEEE计算机视觉与模式识别会议论文集，IEEE，第10657–10665页
- en: Li and Malik (2018) Li K, Malik J (2018) Learning to Optimize Neural Nets. arXiv
    preprint arXiv:170300441
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li和Malik（2018）Li K, Malik J（2018）《学习优化神经网络》。arXiv预印本 arXiv:170300441
- en: 'Li et al. (2017) Li Z, Zhou F, Chen F, Li H (2017) Meta-SGD: Learning to Learn
    Quickly for Few-Shot Learning. arXiv preprint arXiv:170709835'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等人（2017）Li Z, Zhou F, Chen F, Li H（2017）《Meta-SGD：为少样本学习快速学习》。arXiv预印本 arXiv:170709835
- en: 'Liu and Wang (2016) Liu Q, Wang D (2016) Stein Variational Gradient Descent:
    A General Purpose Bayesian Inference Algorithm. In: Advances in neural information
    processing systems 29, Curran Associates Inc., NIPS’16, pp 2378–2386'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu和Wang（2016）Liu Q, Wang D（2016）《Stein变分梯度下降：一种通用的贝叶斯推断算法》。收录于：神经信息处理系统进展29，Curran
    Associates Inc.，NIPS’16，第2378–2386页
- en: 'Martens and Grosse (2015) Martens J, Grosse R (2015) Optimizing Neural Networks
    with Kronecker-factored Approximate Curvature. In: Proceedings of the 32th International
    Conference on Machine Learning, JMLR.org, ICML’15, pp 2408–2417'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Martens和Grosse（2015）Martens J, Grosse R（2015）《用Kronecker分解的近似曲率优化神经网络》。收录于：第32届国际机器学习会议论文集，JMLR.org，ICML’15，第2408–2417页
- en: 'Miconi et al. (2018) Miconi T, Stanley K, Clune J (2018) Differentiable plasticity:
    training plastic neural networks with backpropagation. In: Dy J, Krause A (eds)
    Proceedings of the 35th International Conference on Machine Learning, JLMR.org,
    ICML’18, pp 3559–3568'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miconi等人（2018）Miconi T, Stanley K, Clune J（2018）《可微分塑性：用反向传播训练可塑性神经网络》。收录于：Dy
    J, Krause A（编辑）第35届国际机器学习会议论文集，JLMR.org，ICML’18，第3559–3568页
- en: 'Miconi et al. (2019) Miconi T, Rawal A, Clune J, Stanley KO (2019) Backpropamine:
    training self-modifying neural networks with differentiable neuromodulated plasticity.
    In: International Conference on Learning Representations, ICLR’19'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miconi等人（2019）Miconi T, Rawal A, Clune J, Stanley KO（2019）《Backpropamine：用可微分的神经调节塑性训练自我修改的神经网络》。收录于：国际学习表征会议，ICLR’19
- en: 'Mishra et al. (2018) Mishra N, Rohaninejad M, Chen X, Abbeel P (2018) A Simple
    Neural Attentive Meta-Learner. In: International Conference on Learning Representations,
    ICLR’18'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mishra等人（2018）Mishra N, Rohaninejad M, Chen X, Abbeel P（2018）《一种简单的神经注意力元学习器》。收录于：国际学习表征会议，ICLR’18
- en: Mitchell (1980) Mitchell TM (1980) The need for biases in learning generalizations.
    Tech. Rep. CBM-TR-117, Rutgers University
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mitchell（1980）Mitchell TM（1980）《学习归纳中的偏差需求》。技术报告 CBM-TR-117，拉格斯大学
- en: Mnih et al. (2013) Mnih V, Kavukcuoglu K, Silver D, Graves A, Antonoglou I,
    Wierstra D, Riedmiller M (2013) Playing Atari with Deep Reinforcement Learning.
    arXiv preprint arXiv:13125602
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mnih等人（2013）Mnih V, Kavukcuoglu K, Silver D, Graves A, Antonoglou I, Wierstra
    D, Riedmiller M（2013）《用深度强化学习玩Atari游戏》。arXiv预印本 arXiv:13125602
- en: 'Munkhdalai and Yu (2017) Munkhdalai T, Yu H (2017) Meta networks. In: Proceedings
    of the 34th International Conference on Machine Learning, JLMR.org, ICML’17, pp
    2554–2563'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Munkhdalai和Yu（2017）Munkhdalai T, Yu H（2017）《元网络》。收录于：第34届国际机器学习会议论文集，JLMR.org，ICML’17，第2554–2563页
- en: 'Nagabandi et al. (2019) Nagabandi A, Clavera I, Liu S, Fearing RS, Abbeel P,
    Levine S, Finn C (2019) Learning to Adapt in Dynamic, Real-World Environments
    Through Meta-Reinforcement Learning. In: International Conference on Learning
    Representations, ICLR’19'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nagabandi 等（2019）Nagabandi A, Clavera I, Liu S, Fearing RS, Abbeel P, Levine
    S, Finn C（2019）《通过元强化学习在动态现实环境中学习适应》。在：国际学习表示会议，ICLR’19
- en: 'Naik and Mammone (1992) Naik DK, Mammone RJ (1992) Meta-neural networks that
    learn by learning. In: International Joint Conference on Neural Networks, IEEE,
    IJCNN’92, vol 1, pp 437–442'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Naik 和 Mammone（1992）Naik DK, Mammone RJ（1992）《通过学习进行学习的元神经网络》。在：国际联合神经网络会议，IEEE，IJCNN’92，第1卷，第437–442页
- en: Nichol et al. (2018) Nichol A, Achiam J, Schulman J (2018) On First-Order Meta-Learning
    Algorithms. arXiv preprint arXiv:180302999
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nichol 等（2018）Nichol A, Achiam J, Schulman J（2018）《关于一阶元学习算法》。arXiv 预印本 arXiv:180302999
- en: 'Oord et al. (2016) Oord Avd, Dieleman S, Zen H, Simonyan K, Vinyals O, Graves
    A, Kalchbrenner N, Senior A, Kavukcuoglu K (2016) WaveNet: A Generative Model
    for Raw Audio. arXiv preprint arXiv:160903499'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Oord 等（2016）Oord Avd, Dieleman S, Zen H, Simonyan K, Vinyals O, Graves A, Kalchbrenner
    N, Senior A, Kavukcuoglu K（2016）《WaveNet: 一种用于原始音频的生成模型》。arXiv 预印本 arXiv:160903499'
- en: 'Oreshkin et al. (2018) Oreshkin B, López PR, Lacoste A (2018) Tadam: Task dependent
    adaptive metric for improved few-shot learning. In: Advances in Neural Information
    Processing Systems 31, Curran Associates Inc., NIPS’18, pp 721–731'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Oreshkin 等（2018）Oreshkin B, López PR, Lacoste A（2018）《Tadam: 任务依赖的自适应度量以改善少样本学习》。在：神经信息处理系统进展
    31，Curran Associates Inc.，NIPS’18，第721–731页'
- en: Pan and Yang (2009) Pan SJ, Yang Q (2009) A Survey on Transfer Learning. IEEE
    Transactions on knowledge and data engineering 22(10):1345–1359
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan 和 Yang（2009）Pan SJ, Yang Q（2009）《迁移学习综述》。IEEE 知识与数据工程学报 22(10):1345–1359
- en: 'Peng et al. (2002) Peng Y, Flach PA, Soares C, Brazdil P (2002) Improved Dataset
    Characterisation for Meta-learning. In: International Conference on Discovery
    Science, Springer, Lecture Notes in Computer Science, vol 2534, pp 141–152'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng 等（2002）Peng Y, Flach PA, Soares C, Brazdil P（2002）《改进的元学习数据集特征化》。在：发现科学国际会议，Springer，计算机科学讲义，第2534卷，第141–152页
- en: 'Raghu et al. (2020) Raghu A, Raghu M, Bengio S, Vinyals O (2020) Rapid Learning
    or Feature Reuse? Towards Understanding the Effectiveness of MAML. In: International
    Conference on Learning Representations, ICLR’20'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raghu 等（2020）Raghu A, Raghu M, Bengio S, Vinyals O（2020）《快速学习还是特征重用？理解 MAML
    的有效性》。在：国际学习表示会议，ICLR’20
- en: 'Rajeswaran et al. (2019) Rajeswaran A, Finn C, Kakade SM, Levine S (2019) Meta-Learning
    with Implicit Gradients. In: Advances in Neural Information Processing Systems
    32, Curran Associates Inc., NIPS’19, pp 113–124'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajeswaran 等（2019）Rajeswaran A, Finn C, Kakade SM, Levine S（2019）《隐式梯度的元学习》。在：神经信息处理系统进展
    32，Curran Associates Inc.，NIPS’19，第113–124页
- en: 'Ravi and Larochelle (2017) Ravi S, Larochelle H (2017) Optimization as a Model
    for Few-Shot Learning. In: International Conference on Learning Representations,
    ICLR’17'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ravi 和 Larochelle（2017）Ravi S, Larochelle H（2017）《将优化视为少样本学习的模型》。在：国际学习表示会议，ICLR’17
- en: 'Ren et al. (2018) Ren M, Triantafillou E, Ravi S, Snell J, Swersky K, Tenenbaum
    JB, Larochelle H, Zemel RS (2018) Meta-Learning for Semi-Supervised Few-Shot Classification.
    In: International Conference on Learning Representations, ICLR’18'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ren 等（2018）Ren M, Triantafillou E, Ravi S, Snell J, Swersky K, Tenenbaum JB,
    Larochelle H, Zemel RS（2018）《用于半监督少样本分类的元学习》。在：国际学习表示会议，ICLR’18
- en: 'Rusu et al. (2018) Rusu AA, Rao D, Sygnowski J, Vinyals O, Pascanu R, Osindero
    S, Hadsell R (2018) Meta-Learning with Latent Embedding Optimization. In: International
    Conference on Learning Representations, ICLR’18'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rusu 等（2018）Rusu AA, Rao D, Sygnowski J, Vinyals O, Pascanu R, Osindero S, Hadsell
    R（2018）《带有潜在嵌入优化的元学习》。在：国际学习表示会议，ICLR’18
- en: 'Santoro et al. (2016) Santoro A, Bartunov S, Botvinick M, Wierstra D, Lillicrap
    T (2016) Meta-learning with Memory-augmented Neural Networks. In: Proceedings
    of the 33rd International Conference on International Conference on Machine Learning,
    JMLR.org, ICML’16, pp 1842–1850'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Santoro 等（2016）Santoro A, Bartunov S, Botvinick M, Wierstra D, Lillicrap T（2016）《带有记忆增强神经网络的元学习》。在：第33届国际机器学习会议论文集，JMLR.org，ICML’16，第1842–1850页
- en: Schmidhuber (1987) Schmidhuber J (1987) Evolutionary principles in self-referential
    learning. Diploma Thesis, Technische Universität München
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schmidhuber（1987）Schmidhuber J（1987）《自我参考学习中的进化原则》。毕业论文，慕尼黑工业大学
- en: 'Schmidhuber (1993) Schmidhuber J (1993) A neural network that embeds its own
    meta-levels. In: IEEE International Conference on Neural Networks, IEEE, pp 407–412'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schmidhuber (1993) Schmidhuber J (1993) A neural network that embeds its own
    meta-levels. 收录于: IEEE International Conference on Neural Networks, IEEE, 页 407–412'
- en: Schmidhuber et al. (1997) Schmidhuber J, Zhao J, Wiering M (1997) Shifting Inductive
    Bias with Success-Story Algorithm, Adaptive Levin Search, and Incremental Self-Improvement.
    Machine Learning 28(1):105–130
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schmidhuber 等人 (1997) Schmidhuber J, Zhao J, Wiering M (1997) Shifting Inductive
    Bias with Success-Story Algorithm, Adaptive Levin Search, and Incremental Self-Improvement.
    Machine Learning 28(1):105–130
- en: 'Shyam et al. (2017) Shyam P, Gupta S, Dukkipati A (2017) Attentive Recurrent
    Comparators. In: Proceedings of the 34th International Conference on Machine Learning,
    JLMR.org, ICML’17, pp 3173–3181'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shyam 等人 (2017) Shyam P, Gupta S, Dukkipati A (2017) Attentive Recurrent Comparators.
    收录于: Proceedings of the 34th International Conference on Machine Learning, JLMR.org,
    ICML’17, 页 3173–3181'
- en: Silver et al. (2016) Silver D, Huang A, Maddison CJ, Guez A, Sifre L, van den
    Driessche G, Schrittwieser J, Antonoglou I, Panneershelvam V, Lanctot M, Dieleman
    S, Grewe D, Nham J, Kalchbrenner N, Sutskever I, Lillicrap T, Leach M, Kavukcuoglu
    K, Graepel T, Hassabis D (2016) Mastering the game of Go with deep neural networks
    and tree search. Nature 529(7587):484
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Silver 等人 (2016) Silver D, Huang A, Maddison CJ, Guez A, Sifre L, van den Driessche
    G, Schrittwieser J, Antonoglou I, Panneershelvam V, Lanctot M, Dieleman S, Grewe
    D, Nham J, Kalchbrenner N, Sutskever I, Lillicrap T, Leach M, Kavukcuoglu K, Graepel
    T, Hassabis D (2016) Mastering the game of Go with deep neural networks and tree
    search. Nature 529(7587):484
- en: 'Snell et al. (2017) Snell J, Swersky K, Zemel R (2017) Prototypical Networks
    for Few-shot Learning. In: Advances in Neural Information Processing Systems 30,
    Curran Associates Inc., NIPS’17, pp 4077–4087'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Snell 等人 (2017) Snell J, Swersky K, Zemel R (2017) Prototypical Networks for
    Few-shot Learning. 收录于: Advances in Neural Information Processing Systems 30,
    Curran Associates Inc., NIPS’17, 页 4077–4087'
- en: 'Sun et al. (2017) Sun C, Shrivastava A, Singh S, Gupta A (2017) Revisiting
    Unreasonable Effectiveness of Data in Deep Learning Era. In: Proceedings of the
    IEEE International Conference on Computer Vision, pp 843–852'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sun 等人 (2017) Sun C, Shrivastava A, Singh S, Gupta A (2017) Revisiting Unreasonable
    Effectiveness of Data in Deep Learning Era. 收录于: Proceedings of the IEEE International
    Conference on Computer Vision, 页 843–852'
- en: 'Sung et al. (2018) Sung F, Yang Y, Zhang L, Xiang T, Torr PH, Hospedales TM
    (2018) Learning to Compare: Relation Network for Few-Shot Learning. In: Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition, IEEE, pp 1199–1208'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sung 等人 (2018) Sung F, Yang Y, Zhang L, Xiang T, Torr PH, Hospedales TM (2018)
    Learning to Compare: Relation Network for Few-Shot Learning. 收录于: Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition, IEEE, 页 1199–1208'
- en: 'Sutton and Barto (2018) Sutton RS, Barto AG (2018) Reinforcement Learning:
    An Introduction, 2nd edn. MIT press'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sutton 和 Barto (2018) Sutton RS, Barto AG (2018) Reinforcement Learning: An
    Introduction, 2nd edn. MIT press'
- en: 'Taylor and Stone (2009) Taylor ME, Stone P (2009) Transfer Learning for Reinforcement
    Learning Domains: A Survey. Journal of Machine Learning Research 10(7)'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Taylor 和 Stone (2009) Taylor ME, Stone P (2009) Transfer Learning for Reinforcement
    Learning Domains: A Survey. Journal of Machine Learning Research 10(7)'
- en: 'Thrun (1998) Thrun S (1998) Lifelong Learning Algorithms. In: Learning to learn,
    Springer, pp 181–209'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Thrun (1998) Thrun S (1998) Lifelong Learning Algorithms. 收录于: Learning to
    learn, Springer, 页 181–209'
- en: 'Tokmakov et al. (2019) Tokmakov P, Wang YX, Hebert M (2019) Learning Compositional
    Representations for Few-Shot Recognition. In: Proceedings of the IEEE International
    Conference on Computer Vision, pp 6372–6381'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tokmakov 等人 (2019) Tokmakov P, Wang YX, Hebert M (2019) Learning Compositional
    Representations for Few-Shot Recognition. 收录于: Proceedings of the IEEE International
    Conference on Computer Vision, 页 6372–6381'
- en: 'Triantafillou et al. (2020) Triantafillou E, Zhu T, Dumoulin V, Lamblin P,
    Evci U, Xu K, Goroshin R, Gelada C, Swersky K, Manzagol PA, Larochelle H (2020)
    Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples. In:
    International Conference on Learning Representations, ICLR’20'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Triantafillou 等人 (2020) Triantafillou E, Zhu T, Dumoulin V, Lamblin P, Evci
    U, Xu K, Goroshin R, Gelada C, Swersky K, Manzagol PA, Larochelle H (2020) Meta-Dataset:
    A Dataset of Datasets for Learning to Learn from Few Examples. 收录于: International
    Conference on Learning Representations, ICLR’20'
- en: 'Vanschoren (2018) Vanschoren J (2018) Meta-Learning: A Survey. arXiv preprint
    arXiv:181003548'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Vanschoren (2018) Vanschoren J (2018) Meta-Learning: A Survey. arXiv 预印本 arXiv:181003548'
- en: 'Vanschoren et al. (2014) Vanschoren J, van Rijn JN, Bischl B, Torgo L (2014)
    OpenML: Networked Science in Machine Learning. SIGKDD Explorations 15(2):49–60'
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Vanschoren 等人 (2014) Vanschoren J, van Rijn JN, Bischl B, Torgo L (2014) OpenML:
    Networked Science in Machine Learning. SIGKDD Explorations 15(2):49–60'
- en: 'Vaswani et al. (2017) Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L,
    Gomez AN, Kaiser Ł, Polosukhin I (2017) Attention Is All You Need. In: Advances
    in Neural Information Processing Systems 30, Curran Associates Inc., NIPS’17,
    pp 5998–6008'
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Vaswani 等人 (2017) Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez
    AN, Kaiser Ł, Polosukhin I (2017) Attention Is All You Need. 收录于: Advances in
    Neural Information Processing Systems 30, Curran Associates Inc., NIPS’17, 页 5998–6008'
- en: 'Vinyals (2017) Vinyals O (2017) Talk: Model vs optimization meta learning.
    [http://metalearning-symposium.ml/files/vinyals.pdf](http://metalearning-symposium.ml/files/vinyals.pdf),
    neural Information Processing Systems (NIPS’17); accessed 06-06-2020'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vinyals（2017）Vinyals O（2017）讲座：模型与优化元学习。[http://metalearning-symposium.ml/files/vinyals.pdf](http://metalearning-symposium.ml/files/vinyals.pdf)，神经信息处理系统（NIPS’17）；访问日期：06-06-2020
- en: 'Vinyals et al. (2016) Vinyals O, Blundell C, Lillicrap T, Kavukcuoglu K, Wierstra
    D (2016) Matching Networks for One Shot Learning. In: Advances in Neural Information
    Processing Systems 29, Curran Associates Inc., NIPS’16, pp 3637–3645'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vinyals等（2016）Vinyals O, Blundell C, Lillicrap T, Kavukcuoglu K, Wierstra D（2016）《用于一次性学习的匹配网络》。在：神经信息处理系统进展
    29，Curran Associates Inc.，NIPS’16，第3637–3645页
- en: Vuorio et al. (2018) Vuorio R, Cho DY, Kim D, Kim J (2018) Meta Continual Learning.
    arXiv preprint arXiv:180606928
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vuorio等（2018）Vuorio R, Cho DY, Kim D, Kim J（2018）《元持续学习》。arXiv预印本 arXiv:180606928
- en: Wah et al. (2011) Wah C, Branson S, Welinder P, Perona P, Belongie S (2011)
    The Caltech-UCSD Birds-200-2011 Dataset. Tech. Rep. CNS-TR-2011-001, California
    Institute of Technology
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wah等（2011）Wah C, Branson S, Welinder P, Perona P, Belongie S（2011）《加州理工学院-加州大学圣地亚哥分校鸟类-200-2011数据集》。技术报告
    CNS-TR-2011-001，加州理工学院
- en: Wang et al. (2016) Wang JX, Kurth-Nelson Z, Tirumala D, Soyer H, Leibo JZ, Munos
    R, Blundell C, Kumaran D, Botvinick M (2016) Learning to reinforcement learn.
    arXiv preprint arXiv:161105763
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等（2016）Wang JX, Kurth-Nelson Z, Tirumala D, Soyer H, Leibo JZ, Munos R,
    Blundell C, Kumaran D, Botvinick M（2016）《学习强化学习》。arXiv预印本 arXiv:161105763
- en: 'Wu et al. (2016) Wu Y, Schuster M, Chen Z, Le QV, Norouzi M, Macherey W, Krikun
    M, Cao Y, Gao Q, Macherey K, Klingner J, Shah A, Johnson M, Liu X, Łukasz Kaiser,
    Gouws S, Kato Y, Kudo T, Kazawa H, Stevens K, Kurian G, Patil N, Wang W, Young
    C, Smith J, Riesa J, Rudnick A, Vinyals O, Corrado G, Hughes M, Dean J (2016)
    Google’s Neural Machine Translation System: Bridging the Gap between Human and
    Machine Translation. arXiv preprint arXiv:160908144'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu等（2016）Wu Y, Schuster M, Chen Z, Le QV, Norouzi M, Macherey W, Krikun M, Cao
    Y, Gao Q, Macherey K, Klingner J, Shah A, Johnson M, Liu X, Łukasz Kaiser, Gouws
    S, Kato Y, Kudo T, Kazawa H, Stevens K, Kurian G, Patil N, Wang W, Young C, Smith
    J, Riesa J, Rudnick A, Vinyals O, Corrado G, Hughes M, Dean J（2016）《谷歌神经机器翻译系统：弥合人类与机器翻译之间的差距》。arXiv预印本
    arXiv:160908144
- en: 'Yin et al. (2020) Yin M, Tucker G, Zhou M, Levine S, Finn C (2020) Meta-Learning
    without Memorization. In: International Conference on Learning Representations,
    ICLR’20'
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yin等（2020）Yin M, Tucker G, Zhou M, Levine S, Finn C（2020）《无记忆的元学习》。在：国际学习表示会议，ICLR’20
- en: 'Yoon et al. (2018) Yoon J, Kim T, Dia O, Kim S, Bengio Y, Ahn S (2018) Bayesian
    Model-Agnostic Meta-Learning. In: Advances in Neural Information Processing Systems
    31, Curran Associates Inc., NIPS’18, pp 7332–7342'
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yoon等（2018）Yoon J, Kim T, Dia O, Kim S, Bengio Y, Ahn S（2018）《贝叶斯模型无关元学习》。在：神经信息处理系统进展
    31，Curran Associates Inc.，NIPS’18，第7332–7342页
- en: 'Younger et al. (2001) Younger AS, Hochreiter S, Conwell PR (2001) Meta-learning
    with backpropagation. In: International Joint Conference on Neural Networks, IEEE,
    IJCNN’01, vol 3'
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Younger等（2001）Younger AS, Hochreiter S, Conwell PR（2001）《通过反向传播进行元学习》。在：国际神经网络联合会议，IEEE，IJCNN’01，第3卷
- en: 'Yu et al. (2019) Yu T, Quillen D, He Z, Julian R, Hausman K, Finn C, Levine
    S (2019) Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement
    Learning. arXiv preprint arXiv:191010897'
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu等（2019）Yu T, Quillen D, He Z, Julian R, Hausman K, Finn C, Levine S（2019）《Meta-World：多任务和元强化学习的基准和评估》。arXiv预印本
    arXiv:191010897
