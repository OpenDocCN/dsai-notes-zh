- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: Êú™ÂàÜÁ±ª'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:46:06'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2206.02165] A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Êù•Ê∫êÔºö[https://ar5iv.labs.arxiv.org/html/2206.02165](https://ar5iv.labs.arxiv.org/html/2206.02165)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: DSRC
  prefs: []
  type: TYPE_NORMAL
- en: dedicated short-range communications
  prefs: []
  type: TYPE_NORMAL
- en: C-ITS
  prefs: []
  type: TYPE_NORMAL
- en: cooperative intelligent transport system
  prefs: []
  type: TYPE_NORMAL
- en: RSU
  prefs: []
  type: TYPE_NORMAL
- en: road side unit
  prefs: []
  type: TYPE_NORMAL
- en: TDL
  prefs: []
  type: TYPE_NORMAL
- en: tapped delay line
  prefs: []
  type: TYPE_NORMAL
- en: ITS
  prefs: []
  type: TYPE_NORMAL
- en: Intelligent Transportation Systems
  prefs: []
  type: TYPE_NORMAL
- en: IEEE
  prefs: []
  type: TYPE_NORMAL
- en: Institute of Electrical and Electronics Engineers
  prefs: []
  type: TYPE_NORMAL
- en: WAVE
  prefs: []
  type: TYPE_NORMAL
- en: Wireless Access in Vehicular Environment
  prefs: []
  type: TYPE_NORMAL
- en: V2V
  prefs: []
  type: TYPE_NORMAL
- en: vehicle-to-vehicle
  prefs: []
  type: TYPE_NORMAL
- en: V2I
  prefs: []
  type: TYPE_NORMAL
- en: vehicle-to-infrastructure
  prefs: []
  type: TYPE_NORMAL
- en: CCH
  prefs: []
  type: TYPE_NORMAL
- en: control channel
  prefs: []
  type: TYPE_NORMAL
- en: SCH
  prefs: []
  type: TYPE_NORMAL
- en: service channels
  prefs: []
  type: TYPE_NORMAL
- en: STS
  prefs: []
  type: TYPE_NORMAL
- en: short training symbols
  prefs: []
  type: TYPE_NORMAL
- en: LTS
  prefs: []
  type: TYPE_NORMAL
- en: long training symbols
  prefs: []
  type: TYPE_NORMAL
- en: SS
  prefs: []
  type: TYPE_NORMAL
- en: signal symbol
  prefs: []
  type: TYPE_NORMAL
- en: SoA
  prefs: []
  type: TYPE_NORMAL
- en: state-of-the-art
  prefs: []
  type: TYPE_NORMAL
- en: DPA
  prefs: []
  type: TYPE_NORMAL
- en: data-pilot aided
  prefs: []
  type: TYPE_NORMAL
- en: STA
  prefs: []
  type: TYPE_NORMAL
- en: spectral temporal averaging
  prefs: []
  type: TYPE_NORMAL
- en: CDP
  prefs: []
  type: TYPE_NORMAL
- en: constructed data pilots
  prefs: []
  type: TYPE_NORMAL
- en: TRFI
  prefs: []
  type: TYPE_NORMAL
- en: time domain reliable test frequency domain interpolation
  prefs: []
  type: TYPE_NORMAL
- en: MMSE-VP
  prefs: []
  type: TYPE_NORMAL
- en: minimum mean square error using virtual pilots
  prefs: []
  type: TYPE_NORMAL
- en: iCDP
  prefs: []
  type: TYPE_NORMAL
- en: Improved CDP
  prefs: []
  type: TYPE_NORMAL
- en: SBS
  prefs: []
  type: TYPE_NORMAL
- en: symbol-by-symbol
  prefs: []
  type: TYPE_NORMAL
- en: FBF
  prefs: []
  type: TYPE_NORMAL
- en: frame-by-frame
  prefs: []
  type: TYPE_NORMAL
- en: E-TRFI
  prefs: []
  type: TYPE_NORMAL
- en: Enhanced TRFI
  prefs: []
  type: TYPE_NORMAL
- en: SR-CNN
  prefs: []
  type: TYPE_NORMAL
- en: super resolution CNN
  prefs: []
  type: TYPE_NORMAL
- en: DN-CNN
  prefs: []
  type: TYPE_NORMAL
- en: denoising CNN
  prefs: []
  type: TYPE_NORMAL
- en: RBF
  prefs: []
  type: TYPE_NORMAL
- en: radial basis function
  prefs: []
  type: TYPE_NORMAL
- en: CNN
  prefs: []
  type: TYPE_NORMAL
- en: convolutional neural network
  prefs: []
  type: TYPE_NORMAL
- en: TS-ChannelNet
  prefs: []
  type: TYPE_NORMAL
- en: Temporal spectral ChannelNet
  prefs: []
  type: TYPE_NORMAL
- en: WSSUS
  prefs: []
  type: TYPE_NORMAL
- en: wide-sense stationary uncorrelated scattering
  prefs: []
  type: TYPE_NORMAL
- en: TDR
  prefs: []
  type: TYPE_NORMAL
- en: transmission data rate
  prefs: []
  type: TYPE_NORMAL
- en: LSTM
  prefs: []
  type: TYPE_NORMAL
- en: long short-term memory
  prefs: []
  type: TYPE_NORMAL
- en: ALS
  prefs: []
  type: TYPE_NORMAL
- en: accurate LS
  prefs: []
  type: TYPE_NORMAL
- en: SLS
  prefs: []
  type: TYPE_NORMAL
- en: simple LS
  prefs: []
  type: TYPE_NORMAL
- en: ChannelNet
  prefs: []
  type: TYPE_NORMAL
- en: channel network
  prefs: []
  type: TYPE_NORMAL
- en: ADD-TT
  prefs: []
  type: TYPE_NORMAL
- en: average decision-directed with time truncation
  prefs: []
  type: TYPE_NORMAL
- en: WI
  prefs: []
  type: TYPE_NORMAL
- en: weighted interpolation
  prefs: []
  type: TYPE_NORMAL
- en: DD
  prefs: []
  type: TYPE_NORMAL
- en: decision-directed
  prefs: []
  type: TYPE_NORMAL
- en: SR-ConvLSTM
  prefs: []
  type: TYPE_NORMAL
- en: super resolution convolutional long short-term memory
  prefs: []
  type: TYPE_NORMAL
- en: RS
  prefs: []
  type: TYPE_NORMAL
- en: reliable subcarriers
  prefs: []
  type: TYPE_NORMAL
- en: URS
  prefs: []
  type: TYPE_NORMAL
- en: unreliable subcarriers
  prefs: []
  type: TYPE_NORMAL
- en: AE-DNN
  prefs: []
  type: TYPE_NORMAL
- en: auto-encoder deep neural network
  prefs: []
  type: TYPE_NORMAL
- en: AE
  prefs: []
  type: TYPE_NORMAL
- en: auto-encoder
  prefs: []
  type: TYPE_NORMAL
- en: T-DFT
  prefs: []
  type: TYPE_NORMAL
- en: truncated discrete Fourier transform
  prefs: []
  type: TYPE_NORMAL
- en: TA-TDFT
  prefs: []
  type: TYPE_NORMAL
- en: temporal averaging T-DFT
  prefs: []
  type: TYPE_NORMAL
- en: TA
  prefs: []
  type: TYPE_NORMAL
- en: time averaging
  prefs: []
  type: TYPE_NORMAL
- en: PDP
  prefs: []
  type: TYPE_NORMAL
- en: power delay profile
  prefs: []
  type: TYPE_NORMAL
- en: 1G
  prefs: []
  type: TYPE_NORMAL
- en: first generation
  prefs: []
  type: TYPE_NORMAL
- en: 2G
  prefs: []
  type: TYPE_NORMAL
- en: second generation
  prefs: []
  type: TYPE_NORMAL
- en: 3G
  prefs: []
  type: TYPE_NORMAL
- en: third generation
  prefs: []
  type: TYPE_NORMAL
- en: 3GPP
  prefs: []
  type: TYPE_NORMAL
- en: Third Generation Partnership Project
  prefs: []
  type: TYPE_NORMAL
- en: 4G
  prefs: []
  type: TYPE_NORMAL
- en: fourth generation
  prefs: []
  type: TYPE_NORMAL
- en: 5G
  prefs: []
  type: TYPE_NORMAL
- en: fifth generation
  prefs: []
  type: TYPE_NORMAL
- en: '802.11'
  prefs: []
  type: TYPE_NORMAL
- en: IEEE 802.11 specifications
  prefs: []
  type: TYPE_NORMAL
- en: A/D
  prefs: []
  type: TYPE_NORMAL
- en: analog-to-digital
  prefs: []
  type: TYPE_NORMAL
- en: ADC
  prefs: []
  type: TYPE_NORMAL
- en: analog-to-digital
  prefs: []
  type: TYPE_NORMAL
- en: AM
  prefs: []
  type: TYPE_NORMAL
- en: amplitude modulation
  prefs: []
  type: TYPE_NORMAL
- en: AP
  prefs: []
  type: TYPE_NORMAL
- en: access point
  prefs: []
  type: TYPE_NORMAL
- en: AR
  prefs: []
  type: TYPE_NORMAL
- en: augmented reality
  prefs: []
  type: TYPE_NORMAL
- en: ASIC
  prefs: []
  type: TYPE_NORMAL
- en: application-specific integrated circuit
  prefs: []
  type: TYPE_NORMAL
- en: ASIP
  prefs: []
  type: TYPE_NORMAL
- en: Application Specific Integrated Processors
  prefs: []
  type: TYPE_NORMAL
- en: AWGN
  prefs: []
  type: TYPE_NORMAL
- en: additive white Gaussian noise
  prefs: []
  type: TYPE_NORMAL
- en: BCJR
  prefs: []
  type: TYPE_NORMAL
- en: Bahl, Cocke, Jelinek and Raviv
  prefs: []
  type: TYPE_NORMAL
- en: BER
  prefs: []
  type: TYPE_NORMAL
- en: bit error rate
  prefs: []
  type: TYPE_NORMAL
- en: BFDM
  prefs: []
  type: TYPE_NORMAL
- en: bi-orthogonal frequency division multiplexing
  prefs: []
  type: TYPE_NORMAL
- en: BPSK
  prefs: []
  type: TYPE_NORMAL
- en: binary phase shift keying
  prefs: []
  type: TYPE_NORMAL
- en: BS
  prefs: []
  type: TYPE_NORMAL
- en: base stations
  prefs: []
  type: TYPE_NORMAL
- en: CA
  prefs: []
  type: TYPE_NORMAL
- en: carrier aggregation
  prefs: []
  type: TYPE_NORMAL
- en: CAF
  prefs: []
  type: TYPE_NORMAL
- en: cyclic autocorrelation function
  prefs: []
  type: TYPE_NORMAL
- en: Car-2-x
  prefs: []
  type: TYPE_NORMAL
- en: car-to-car and car-to-infrastructure communication
  prefs: []
  type: TYPE_NORMAL
- en: CAZAC
  prefs: []
  type: TYPE_NORMAL
- en: constant amplitude zero autocorrelation waveform
  prefs: []
  type: TYPE_NORMAL
- en: CB-FMT
  prefs: []
  type: TYPE_NORMAL
- en: cyclic block filtered multitone
  prefs: []
  type: TYPE_NORMAL
- en: CCDF
  prefs: []
  type: TYPE_NORMAL
- en: complementary cumulative density function
  prefs: []
  type: TYPE_NORMAL
- en: CDF
  prefs: []
  type: TYPE_NORMAL
- en: cumulative density function
  prefs: []
  type: TYPE_NORMAL
- en: CDMA
  prefs: []
  type: TYPE_NORMAL
- en: code-division multiple access
  prefs: []
  type: TYPE_NORMAL
- en: CFO
  prefs: []
  type: TYPE_NORMAL
- en: carrier frequency offset
  prefs: []
  type: TYPE_NORMAL
- en: CIR
  prefs: []
  type: TYPE_NORMAL
- en: channel impulse response
  prefs: []
  type: TYPE_NORMAL
- en: CM
  prefs: []
  type: TYPE_NORMAL
- en: complex multiplication
  prefs: []
  type: TYPE_NORMAL
- en: COFDM
  prefs: []
  type: TYPE_NORMAL
- en: coded-[OFDM](#id208.208.id208)
  prefs: []
  type: TYPE_NORMAL
- en: CoMP
  prefs: []
  type: TYPE_NORMAL
- en: coordinated multi point
  prefs: []
  type: TYPE_NORMAL
- en: COQAM
  prefs: []
  type: TYPE_NORMAL
- en: cyclic OQAM
  prefs: []
  type: TYPE_NORMAL
- en: CP
  prefs: []
  type: TYPE_NORMAL
- en: cyclic prefix
  prefs: []
  type: TYPE_NORMAL
- en: CR
  prefs: []
  type: TYPE_NORMAL
- en: cognitive radio
  prefs: []
  type: TYPE_NORMAL
- en: CRC
  prefs: []
  type: TYPE_NORMAL
- en: cyclic redundancy check
  prefs: []
  type: TYPE_NORMAL
- en: CRLB
  prefs: []
  type: TYPE_NORMAL
- en: Cram√©r-Rao lower bound
  prefs: []
  type: TYPE_NORMAL
- en: CS
  prefs: []
  type: TYPE_NORMAL
- en: cyclic suffix
  prefs: []
  type: TYPE_NORMAL
- en: CSI
  prefs: []
  type: TYPE_NORMAL
- en: channel state information
  prefs: []
  type: TYPE_NORMAL
- en: CSMA
  prefs: []
  type: TYPE_NORMAL
- en: carrier-sense multiple access
  prefs: []
  type: TYPE_NORMAL
- en: CWCU
  prefs: []
  type: TYPE_NORMAL
- en: component-wise conditionally unbiased
  prefs: []
  type: TYPE_NORMAL
- en: D/A
  prefs: []
  type: TYPE_NORMAL
- en: digital-to-analog
  prefs: []
  type: TYPE_NORMAL
- en: D2D
  prefs: []
  type: TYPE_NORMAL
- en: device-to-device
  prefs: []
  type: TYPE_NORMAL
- en: DAC
  prefs: []
  type: TYPE_NORMAL
- en: digital-to-analog
  prefs: []
  type: TYPE_NORMAL
- en: DC
  prefs: []
  type: TYPE_NORMAL
- en: direct current
  prefs: []
  type: TYPE_NORMAL
- en: DFE
  prefs: []
  type: TYPE_NORMAL
- en: decision feedback equalizer
  prefs: []
  type: TYPE_NORMAL
- en: DFT
  prefs: []
  type: TYPE_NORMAL
- en: discrete Fourier transform
  prefs: []
  type: TYPE_NORMAL
- en: DL
  prefs: []
  type: TYPE_NORMAL
- en: deep learning
  prefs: []
  type: TYPE_NORMAL
- en: DMT
  prefs: []
  type: TYPE_NORMAL
- en: discrete multitone
  prefs: []
  type: TYPE_NORMAL
- en: DNN
  prefs: []
  type: TYPE_NORMAL
- en: deep neural network
  prefs: []
  type: TYPE_NORMAL
- en: FNN
  prefs: []
  type: TYPE_NORMAL
- en: feed-forward neural network
  prefs: []
  type: TYPE_NORMAL
- en: DSA
  prefs: []
  type: TYPE_NORMAL
- en: dynamic spectrum access
  prefs: []
  type: TYPE_NORMAL
- en: DSL
  prefs: []
  type: TYPE_NORMAL
- en: digital subscriber line
  prefs: []
  type: TYPE_NORMAL
- en: DSP
  prefs: []
  type: TYPE_NORMAL
- en: digital signal processor
  prefs: []
  type: TYPE_NORMAL
- en: DTFT
  prefs: []
  type: TYPE_NORMAL
- en: discrete-time Fourier transform
  prefs: []
  type: TYPE_NORMAL
- en: DVB
  prefs: []
  type: TYPE_NORMAL
- en: digital video broadcasting
  prefs: []
  type: TYPE_NORMAL
- en: DVB-T
  prefs: []
  type: TYPE_NORMAL
- en: terrestrial digital video broadcasting
  prefs: []
  type: TYPE_NORMAL
- en: DWMT
  prefs: []
  type: TYPE_NORMAL
- en: discrete wavelet multi tone
  prefs: []
  type: TYPE_NORMAL
- en: DZT
  prefs: []
  type: TYPE_NORMAL
- en: discrete Zak transform
  prefs: []
  type: TYPE_NORMAL
- en: E2E
  prefs: []
  type: TYPE_NORMAL
- en: end-to-end
  prefs: []
  type: TYPE_NORMAL
- en: eNodeB
  prefs: []
  type: TYPE_NORMAL
- en: evolved node b base station
  prefs: []
  type: TYPE_NORMAL
- en: E-SNR
  prefs: []
  type: TYPE_NORMAL
- en: effective signal-to-noise ratio
  prefs: []
  type: TYPE_NORMAL
- en: EVD
  prefs: []
  type: TYPE_NORMAL
- en: eigenvalue decomposition
  prefs: []
  type: TYPE_NORMAL
- en: FBMC
  prefs: []
  type: TYPE_NORMAL
- en: filter bank multicarrier
  prefs: []
  type: TYPE_NORMAL
- en: FD
  prefs: []
  type: TYPE_NORMAL
- en: frequency-domain
  prefs: []
  type: TYPE_NORMAL
- en: FDD
  prefs: []
  type: TYPE_NORMAL
- en: frequency-division duplexing
  prefs: []
  type: TYPE_NORMAL
- en: FDE
  prefs: []
  type: TYPE_NORMAL
- en: frequency domain equalization
  prefs: []
  type: TYPE_NORMAL
- en: FDM
  prefs: []
  type: TYPE_NORMAL
- en: frequency division multiplex
  prefs: []
  type: TYPE_NORMAL
- en: FDMA
  prefs: []
  type: TYPE_NORMAL
- en: frequency-division multiple access
  prefs: []
  type: TYPE_NORMAL
- en: FEC
  prefs: []
  type: TYPE_NORMAL
- en: forward error correction
  prefs: []
  type: TYPE_NORMAL
- en: FER
  prefs: []
  type: TYPE_NORMAL
- en: frame error rate
  prefs: []
  type: TYPE_NORMAL
- en: FFT
  prefs: []
  type: TYPE_NORMAL
- en: fast Fourier transform
  prefs: []
  type: TYPE_NORMAL
- en: FIR
  prefs: []
  type: TYPE_NORMAL
- en: finite impulse response
  prefs: []
  type: TYPE_NORMAL
- en: FM
  prefs: []
  type: TYPE_NORMAL
- en: frequency modulation
  prefs: []
  type: TYPE_NORMAL
- en: FMT
  prefs: []
  type: TYPE_NORMAL
- en: filtered multi tone
  prefs: []
  type: TYPE_NORMAL
- en: FO
  prefs: []
  type: TYPE_NORMAL
- en: frequency offset
  prefs: []
  type: TYPE_NORMAL
- en: F-OFDM
  prefs: []
  type: TYPE_NORMAL
- en: filtered-[OFDM](#id208.208.id208)
  prefs: []
  type: TYPE_NORMAL
- en: FPGA
  prefs: []
  type: TYPE_NORMAL
- en: field programmable gate array
  prefs: []
  type: TYPE_NORMAL
- en: FSC
  prefs: []
  type: TYPE_NORMAL
- en: frequency selective channel
  prefs: []
  type: TYPE_NORMAL
- en: FS-OQAM-GFDM
  prefs: []
  type: TYPE_NORMAL
- en: frequency-shift OQAM-GFDM
  prefs: []
  type: TYPE_NORMAL
- en: FT
  prefs: []
  type: TYPE_NORMAL
- en: Fourier transform
  prefs: []
  type: TYPE_NORMAL
- en: FTD
  prefs: []
  type: TYPE_NORMAL
- en: fractional time delay
  prefs: []
  type: TYPE_NORMAL
- en: FTN
  prefs: []
  type: TYPE_NORMAL
- en: faster-than-Nyquist signaling
  prefs: []
  type: TYPE_NORMAL
- en: GFDM
  prefs: []
  type: TYPE_NORMAL
- en: generalized frequency division multiplexing
  prefs: []
  type: TYPE_NORMAL
- en: GFDMA
  prefs: []
  type: TYPE_NORMAL
- en: generalized frequency division multiple access
  prefs: []
  type: TYPE_NORMAL
- en: GMC-CDM
  prefs: []
  type: TYPE_NORMAL
- en: generalized multicarrier code-division multiplexing
  prefs: []
  type: TYPE_NORMAL
- en: GNSS
  prefs: []
  type: TYPE_NORMAL
- en: global navigation satellite system
  prefs: []
  type: TYPE_NORMAL
- en: GS
  prefs: []
  type: TYPE_NORMAL
- en: guard symbols
  prefs: []
  type: TYPE_NORMAL
- en: GSM
  prefs: []
  type: TYPE_NORMAL
- en: Groupe Sp√©cial Mobile
  prefs: []
  type: TYPE_NORMAL
- en: GUI
  prefs: []
  type: TYPE_NORMAL
- en: graphical user interface
  prefs: []
  type: TYPE_NORMAL
- en: H2H
  prefs: []
  type: TYPE_NORMAL
- en: human-to-human
  prefs: []
  type: TYPE_NORMAL
- en: H2M
  prefs: []
  type: TYPE_NORMAL
- en: human-to-machine
  prefs: []
  type: TYPE_NORMAL
- en: HTC
  prefs: []
  type: TYPE_NORMAL
- en: human type communication
  prefs: []
  type: TYPE_NORMAL
- en: I
  prefs: []
  type: TYPE_NORMAL
- en: in-phase
  prefs: []
  type: TYPE_NORMAL
- en: i.i.d.
  prefs: []
  type: TYPE_NORMAL
- en: independent and identically distributed
  prefs: []
  type: TYPE_NORMAL
- en: IB
  prefs: []
  type: TYPE_NORMAL
- en: in-band
  prefs: []
  type: TYPE_NORMAL
- en: IBI
  prefs: []
  type: TYPE_NORMAL
- en: inter-block interference
  prefs: []
  type: TYPE_NORMAL
- en: IC
  prefs: []
  type: TYPE_NORMAL
- en: interference cancellation
  prefs: []
  type: TYPE_NORMAL
- en: ICI
  prefs: []
  type: TYPE_NORMAL
- en: inter-carrier interference
  prefs: []
  type: TYPE_NORMAL
- en: ICT
  prefs: []
  type: TYPE_NORMAL
- en: information and communication technologies
  prefs: []
  type: TYPE_NORMAL
- en: ICV
  prefs: []
  type: TYPE_NORMAL
- en: information coefficient vector
  prefs: []
  type: TYPE_NORMAL
- en: IDFT
  prefs: []
  type: TYPE_NORMAL
- en: inverse discrete Fourier transform
  prefs: []
  type: TYPE_NORMAL
- en: IDMA
  prefs: []
  type: TYPE_NORMAL
- en: interleave division multiple access
  prefs: []
  type: TYPE_NORMAL
- en: IEEE
  prefs: []
  type: TYPE_NORMAL
- en: institute of electrical and electronics engineers
  prefs: []
  type: TYPE_NORMAL
- en: IF
  prefs: []
  type: TYPE_NORMAL
- en: intermediate frequency
  prefs: []
  type: TYPE_NORMAL
- en: IFFT
  prefs: []
  type: TYPE_NORMAL
- en: inverse fast Fourier transform
  prefs: []
  type: TYPE_NORMAL
- en: IoT
  prefs: []
  type: TYPE_NORMAL
- en: Internet of Things
  prefs: []
  type: TYPE_NORMAL
- en: IOTA
  prefs: []
  type: TYPE_NORMAL
- en: isotropic orthogonal transform algorithm
  prefs: []
  type: TYPE_NORMAL
- en: IP
  prefs: []
  type: TYPE_NORMAL
- en: internet protocole
  prefs: []
  type: TYPE_NORMAL
- en: IP-core
  prefs: []
  type: TYPE_NORMAL
- en: intellectual property core
  prefs: []
  type: TYPE_NORMAL
- en: ISDB-T
  prefs: []
  type: TYPE_NORMAL
- en: terrestrial integrated services digital broadcasting
  prefs: []
  type: TYPE_NORMAL
- en: ISDN
  prefs: []
  type: TYPE_NORMAL
- en: integrated services digital network
  prefs: []
  type: TYPE_NORMAL
- en: ISI
  prefs: []
  type: TYPE_NORMAL
- en: inter-symbol interference
  prefs: []
  type: TYPE_NORMAL
- en: ITU
  prefs: []
  type: TYPE_NORMAL
- en: International Telecommunication Union
  prefs: []
  type: TYPE_NORMAL
- en: IUI
  prefs: []
  type: TYPE_NORMAL
- en: inter-user interference
  prefs: []
  type: TYPE_NORMAL
- en: LAN
  prefs: []
  type: TYPE_NORMAL
- en: local area netwrok
  prefs: []
  type: TYPE_NORMAL
- en: LLR
  prefs: []
  type: TYPE_NORMAL
- en: log-likelihood ratio
  prefs: []
  type: TYPE_NORMAL
- en: LMMSE
  prefs: []
  type: TYPE_NORMAL
- en: linear minimum mean square error
  prefs: []
  type: TYPE_NORMAL
- en: LNA
  prefs: []
  type: TYPE_NORMAL
- en: low noise amplifier
  prefs: []
  type: TYPE_NORMAL
- en: LO
  prefs: []
  type: TYPE_NORMAL
- en: local oscillator
  prefs: []
  type: TYPE_NORMAL
- en: LOS
  prefs: []
  type: TYPE_NORMAL
- en: line-of-sight
  prefs: []
  type: TYPE_NORMAL
- en: LP
  prefs: []
  type: TYPE_NORMAL
- en: low-pass
  prefs: []
  type: TYPE_NORMAL
- en: LPF
  prefs: []
  type: TYPE_NORMAL
- en: low-pass filter
  prefs: []
  type: TYPE_NORMAL
- en: LS
  prefs: []
  type: TYPE_NORMAL
- en: least squares
  prefs: []
  type: TYPE_NORMAL
- en: LTE
  prefs: []
  type: TYPE_NORMAL
- en: Long Term Evolution
  prefs: []
  type: TYPE_NORMAL
- en: LTE-A
  prefs: []
  type: TYPE_NORMAL
- en: LTE-Advanced
  prefs: []
  type: TYPE_NORMAL
- en: LTIV
  prefs: []
  type: TYPE_NORMAL
- en: linear time invariant
  prefs: []
  type: TYPE_NORMAL
- en: LTV
  prefs: []
  type: TYPE_NORMAL
- en: linear time-variant
  prefs: []
  type: TYPE_NORMAL
- en: LUT
  prefs: []
  type: TYPE_NORMAL
- en: lookup table
  prefs: []
  type: TYPE_NORMAL
- en: M2M
  prefs: []
  type: TYPE_NORMAL
- en: machine-to-machine
  prefs: []
  type: TYPE_NORMAL
- en: MA
  prefs: []
  type: TYPE_NORMAL
- en: multiple access
  prefs: []
  type: TYPE_NORMAL
- en: MAC
  prefs: []
  type: TYPE_NORMAL
- en: multiple access control
  prefs: []
  type: TYPE_NORMAL
- en: MAP
  prefs: []
  type: TYPE_NORMAL
- en: maximum a posteriori
  prefs: []
  type: TYPE_NORMAL
- en: MC
  prefs: []
  type: TYPE_NORMAL
- en: multicarrier
  prefs: []
  type: TYPE_NORMAL
- en: MCA
  prefs: []
  type: TYPE_NORMAL
- en: multicarrier access
  prefs: []
  type: TYPE_NORMAL
- en: MCM
  prefs: []
  type: TYPE_NORMAL
- en: multicarrier modulation
  prefs: []
  type: TYPE_NORMAL
- en: MCS
  prefs: []
  type: TYPE_NORMAL
- en: modulation coding scheme
  prefs: []
  type: TYPE_NORMAL
- en: MF
  prefs: []
  type: TYPE_NORMAL
- en: matched filter
  prefs: []
  type: TYPE_NORMAL
- en: MF-SIC
  prefs: []
  type: TYPE_NORMAL
- en: matched filter with successive interference cancellation
  prefs: []
  type: TYPE_NORMAL
- en: MIMO
  prefs: []
  type: TYPE_NORMAL
- en: multiple-input, multiple-output
  prefs: []
  type: TYPE_NORMAL
- en: MISO
  prefs: []
  type: TYPE_NORMAL
- en: multiple-input single-output
  prefs: []
  type: TYPE_NORMAL
- en: ML
  prefs: []
  type: TYPE_NORMAL
- en: machien learning
  prefs: []
  type: TYPE_NORMAL
- en: MLD
  prefs: []
  type: TYPE_NORMAL
- en: maximum likelihood detection
  prefs: []
  type: TYPE_NORMAL
- en: MLE
  prefs: []
  type: TYPE_NORMAL
- en: maximum likelihood estimator
  prefs: []
  type: TYPE_NORMAL
- en: MMSE
  prefs: []
  type: TYPE_NORMAL
- en: minimum mean squared error
  prefs: []
  type: TYPE_NORMAL
- en: MRC
  prefs: []
  type: TYPE_NORMAL
- en: maximum ratio combining
  prefs: []
  type: TYPE_NORMAL
- en: MS
  prefs: []
  type: TYPE_NORMAL
- en: mobile stations
  prefs: []
  type: TYPE_NORMAL
- en: MSE
  prefs: []
  type: TYPE_NORMAL
- en: mean squared error
  prefs: []
  type: TYPE_NORMAL
- en: MSK
  prefs: []
  type: TYPE_NORMAL
- en: Minimum-shift keying
  prefs: []
  type: TYPE_NORMAL
- en: MSSS
  prefs: []
  type: TYPE_NORMAL
- en: mean-square signal separation
  prefs: []
  type: TYPE_NORMAL
- en: MTC
  prefs: []
  type: TYPE_NORMAL
- en: machine type communication
  prefs: []
  type: TYPE_NORMAL
- en: MU
  prefs: []
  type: TYPE_NORMAL
- en: multi user
  prefs: []
  type: TYPE_NORMAL
- en: MVUE
  prefs: []
  type: TYPE_NORMAL
- en: minimum variance unbiased estimator
  prefs: []
  type: TYPE_NORMAL
- en: NEF
  prefs: []
  type: TYPE_NORMAL
- en: noise enhancement factor
  prefs: []
  type: TYPE_NORMAL
- en: NLOS
  prefs: []
  type: TYPE_NORMAL
- en: non-line-of-sight
  prefs: []
  type: TYPE_NORMAL
- en: NMSE
  prefs: []
  type: TYPE_NORMAL
- en: normalized mean-squared error
  prefs: []
  type: TYPE_NORMAL
- en: NOMA
  prefs: []
  type: TYPE_NORMAL
- en: non-orthogonal multiple access
  prefs: []
  type: TYPE_NORMAL
- en: NPR
  prefs: []
  type: TYPE_NORMAL
- en: near-perfect reconstruction
  prefs: []
  type: TYPE_NORMAL
- en: NRZ
  prefs: []
  type: TYPE_NORMAL
- en: non-return-to-zero
  prefs: []
  type: TYPE_NORMAL
- en: OFDM
  prefs: []
  type: TYPE_NORMAL
- en: orthogonal frequency division multiplexing
  prefs: []
  type: TYPE_NORMAL
- en: OFDMA
  prefs: []
  type: TYPE_NORMAL
- en: orthogonal frequency division multiple access
  prefs: []
  type: TYPE_NORMAL
- en: OOB
  prefs: []
  type: TYPE_NORMAL
- en: out-of-band
  prefs: []
  type: TYPE_NORMAL
- en: OQAM
  prefs: []
  type: TYPE_NORMAL
- en: offset quadrature amplitude modulation
  prefs: []
  type: TYPE_NORMAL
- en: OQPSK
  prefs: []
  type: TYPE_NORMAL
- en: offset quadrature phase shift keying
  prefs: []
  type: TYPE_NORMAL
- en: OTFS
  prefs: []
  type: TYPE_NORMAL
- en: orthogonal time frequency space
  prefs: []
  type: TYPE_NORMAL
- en: PA
  prefs: []
  type: TYPE_NORMAL
- en: power amplifier
  prefs: []
  type: TYPE_NORMAL
- en: PAM
  prefs: []
  type: TYPE_NORMAL
- en: pulse amplitude modulation
  prefs: []
  type: TYPE_NORMAL
- en: PAPR
  prefs: []
  type: TYPE_NORMAL
- en: peak-to-average power ratio
  prefs: []
  type: TYPE_NORMAL
- en: PC-CC
  prefs: []
  type: TYPE_NORMAL
- en: parallel concatenated convolutional code
  prefs: []
  type: TYPE_NORMAL
- en: PCP
  prefs: []
  type: TYPE_NORMAL
- en: pseudo-circular pre/post-amble
  prefs: []
  type: TYPE_NORMAL
- en: PD
  prefs: []
  type: TYPE_NORMAL
- en: probability of detection
  prefs: []
  type: TYPE_NORMAL
- en: pdf
  prefs: []
  type: TYPE_NORMAL
- en: probability density function
  prefs: []
  type: TYPE_NORMAL
- en: PDF
  prefs: []
  type: TYPE_NORMAL
- en: probability distribution function
  prefs: []
  type: TYPE_NORMAL
- en: PFA
  prefs: []
  type: TYPE_NORMAL
- en: probability of false alarm
  prefs: []
  type: TYPE_NORMAL
- en: PHY
  prefs: []
  type: TYPE_NORMAL
- en: physical layer
  prefs: []
  type: TYPE_NORMAL
- en: PIC
  prefs: []
  type: TYPE_NORMAL
- en: parallel interference cancellation
  prefs: []
  type: TYPE_NORMAL
- en: PLC
  prefs: []
  type: TYPE_NORMAL
- en: power line communication
  prefs: []
  type: TYPE_NORMAL
- en: PMF
  prefs: []
  type: TYPE_NORMAL
- en: probability mass function
  prefs: []
  type: TYPE_NORMAL
- en: PN
  prefs: []
  type: TYPE_NORMAL
- en: pseudo noise
  prefs: []
  type: TYPE_NORMAL
- en: ppm
  prefs: []
  type: TYPE_NORMAL
- en: parts per million
  prefs: []
  type: TYPE_NORMAL
- en: PRB
  prefs: []
  type: TYPE_NORMAL
- en: physical resource block
  prefs: []
  type: TYPE_NORMAL
- en: PRB
  prefs: []
  type: TYPE_NORMAL
- en: physical resource block
  prefs: []
  type: TYPE_NORMAL
- en: PSD
  prefs: []
  type: TYPE_NORMAL
- en: power spectral density
  prefs: []
  type: TYPE_NORMAL
- en: Q
  prefs: []
  type: TYPE_NORMAL
- en: quadrature-phase
  prefs: []
  type: TYPE_NORMAL
- en: QAM
  prefs: []
  type: TYPE_NORMAL
- en: quadrature amplitude modulation
  prefs: []
  type: TYPE_NORMAL
- en: QoS
  prefs: []
  type: TYPE_NORMAL
- en: quality of service
  prefs: []
  type: TYPE_NORMAL
- en: QPSK
  prefs: []
  type: TYPE_NORMAL
- en: quadrature phase shift keying
  prefs: []
  type: TYPE_NORMAL
- en: R/W
  prefs: []
  type: TYPE_NORMAL
- en: read-or-write
  prefs: []
  type: TYPE_NORMAL
- en: RAM
  prefs: []
  type: TYPE_NORMAL
- en: random-access memmory
  prefs: []
  type: TYPE_NORMAL
- en: RAN
  prefs: []
  type: TYPE_NORMAL
- en: radio access network
  prefs: []
  type: TYPE_NORMAL
- en: RAT
  prefs: []
  type: TYPE_NORMAL
- en: radio access technologies
  prefs: []
  type: TYPE_NORMAL
- en: RC
  prefs: []
  type: TYPE_NORMAL
- en: raised cosine
  prefs: []
  type: TYPE_NORMAL
- en: RF
  prefs: []
  type: TYPE_NORMAL
- en: radio frequency
  prefs: []
  type: TYPE_NORMAL
- en: rms
  prefs: []
  type: TYPE_NORMAL
- en: root mean square
  prefs: []
  type: TYPE_NORMAL
- en: RRC
  prefs: []
  type: TYPE_NORMAL
- en: root raised cosine
  prefs: []
  type: TYPE_NORMAL
- en: RW
  prefs: []
  type: TYPE_NORMAL
- en: read-and-write
  prefs: []
  type: TYPE_NORMAL
- en: SC
  prefs: []
  type: TYPE_NORMAL
- en: single-carrier
  prefs: []
  type: TYPE_NORMAL
- en: SCA
  prefs: []
  type: TYPE_NORMAL
- en: single-carrier access
  prefs: []
  type: TYPE_NORMAL
- en: SC-FDE
  prefs: []
  type: TYPE_NORMAL
- en: single-carrier with frequency domain equalization
  prefs: []
  type: TYPE_NORMAL
- en: SC-FDM
  prefs: []
  type: TYPE_NORMAL
- en: single-carrier frequency division multiplexing
  prefs: []
  type: TYPE_NORMAL
- en: SC-FDMA
  prefs: []
  type: TYPE_NORMAL
- en: single-carrier frequency division multiple access
  prefs: []
  type: TYPE_NORMAL
- en: SD
  prefs: []
  type: TYPE_NORMAL
- en: sphere decoding
  prefs: []
  type: TYPE_NORMAL
- en: SDD
  prefs: []
  type: TYPE_NORMAL
- en: space-division duplexing
  prefs: []
  type: TYPE_NORMAL
- en: SDMA
  prefs: []
  type: TYPE_NORMAL
- en: space division multiple access
  prefs: []
  type: TYPE_NORMAL
- en: SDR
  prefs: []
  type: TYPE_NORMAL
- en: software-defined radio
  prefs: []
  type: TYPE_NORMAL
- en: SDW
  prefs: []
  type: TYPE_NORMAL
- en: software-defined waveform
  prefs: []
  type: TYPE_NORMAL
- en: SEFDM
  prefs: []
  type: TYPE_NORMAL
- en: spectrally efficient frequency division multiplexing
  prefs: []
  type: TYPE_NORMAL
- en: SE-FDM
  prefs: []
  type: TYPE_NORMAL
- en: spectrally efficient frequency division multiplexing
  prefs: []
  type: TYPE_NORMAL
- en: SER
  prefs: []
  type: TYPE_NORMAL
- en: symbol error rate
  prefs: []
  type: TYPE_NORMAL
- en: SIC
  prefs: []
  type: TYPE_NORMAL
- en: successive interference cancellation
  prefs: []
  type: TYPE_NORMAL
- en: SINR
  prefs: []
  type: TYPE_NORMAL
- en: signal-to-interference-plus-noise ratio
  prefs: []
  type: TYPE_NORMAL
- en: SIR
  prefs: []
  type: TYPE_NORMAL
- en: signal-to-interference ratio
  prefs: []
  type: TYPE_NORMAL
- en: SISO
  prefs: []
  type: TYPE_NORMAL
- en: single-input, single-output
  prefs: []
  type: TYPE_NORMAL
- en: SMS
  prefs: []
  type: TYPE_NORMAL
- en: Short Message Service
  prefs: []
  type: TYPE_NORMAL
- en: SNR
  prefs: []
  type: TYPE_NORMAL
- en: signal-to-noise ratio
  prefs: []
  type: TYPE_NORMAL
- en: STC
  prefs: []
  type: TYPE_NORMAL
- en: space-time coding
  prefs: []
  type: TYPE_NORMAL
- en: STFT
  prefs: []
  type: TYPE_NORMAL
- en: short-time Fourier transform
  prefs: []
  type: TYPE_NORMAL
- en: STO
  prefs: []
  type: TYPE_NORMAL
- en: symbol time offset
  prefs: []
  type: TYPE_NORMAL
- en: SU
  prefs: []
  type: TYPE_NORMAL
- en: single user
  prefs: []
  type: TYPE_NORMAL
- en: SVD
  prefs: []
  type: TYPE_NORMAL
- en: singular value decomposition
  prefs: []
  type: TYPE_NORMAL
- en: TD
  prefs: []
  type: TYPE_NORMAL
- en: time-domain
  prefs: []
  type: TYPE_NORMAL
- en: TDD
  prefs: []
  type: TYPE_NORMAL
- en: time-division duplexing
  prefs: []
  type: TYPE_NORMAL
- en: TDMA
  prefs: []
  type: TYPE_NORMAL
- en: time-division multiple access
  prefs: []
  type: TYPE_NORMAL
- en: TFL
  prefs: []
  type: TYPE_NORMAL
- en: time-frequency localization
  prefs: []
  type: TYPE_NORMAL
- en: TO
  prefs: []
  type: TYPE_NORMAL
- en: time offset
  prefs: []
  type: TYPE_NORMAL
- en: TS-OQAM-GFDM
  prefs: []
  type: TYPE_NORMAL
- en: time-shifted OQAM-GFDM
  prefs: []
  type: TYPE_NORMAL
- en: UE
  prefs: []
  type: TYPE_NORMAL
- en: user equipment
  prefs: []
  type: TYPE_NORMAL
- en: UFMC
  prefs: []
  type: TYPE_NORMAL
- en: universally filtered multicarrier
  prefs: []
  type: TYPE_NORMAL
- en: UL
  prefs: []
  type: TYPE_NORMAL
- en: uplink
  prefs: []
  type: TYPE_NORMAL
- en: US
  prefs: []
  type: TYPE_NORMAL
- en: uncorrelated scattering
  prefs: []
  type: TYPE_NORMAL
- en: USB
  prefs: []
  type: TYPE_NORMAL
- en: universal serial bus
  prefs: []
  type: TYPE_NORMAL
- en: UW
  prefs: []
  type: TYPE_NORMAL
- en: unique word
  prefs: []
  type: TYPE_NORMAL
- en: VLC
  prefs: []
  type: TYPE_NORMAL
- en: visible light communications
  prefs: []
  type: TYPE_NORMAL
- en: VR
  prefs: []
  type: TYPE_NORMAL
- en: virtual reality
  prefs: []
  type: TYPE_NORMAL
- en: WCP
  prefs: []
  type: TYPE_NORMAL
- en: windowing and [CP](#id82.82.id82)
  prefs: []
  type: TYPE_NORMAL
- en: WHT
  prefs: []
  type: TYPE_NORMAL
- en: Walsh-Hadamard transform
  prefs: []
  type: TYPE_NORMAL
- en: WiMAX
  prefs: []
  type: TYPE_NORMAL
- en: worldwide interoperability for microwave access
  prefs: []
  type: TYPE_NORMAL
- en: WLAN
  prefs: []
  type: TYPE_NORMAL
- en: wireless local area network
  prefs: []
  type: TYPE_NORMAL
- en: W-OFDM
  prefs: []
  type: TYPE_NORMAL
- en: windowed-[OFDM](#id208.208.id208)
  prefs: []
  type: TYPE_NORMAL
- en: WOLA
  prefs: []
  type: TYPE_NORMAL
- en: windowing and overlapping
  prefs: []
  type: TYPE_NORMAL
- en: WSS
  prefs: []
  type: TYPE_NORMAL
- en: wide-sense stationary
  prefs: []
  type: TYPE_NORMAL
- en: ZCT
  prefs: []
  type: TYPE_NORMAL
- en: Zadoff-Chu transform
  prefs: []
  type: TYPE_NORMAL
- en: ZF
  prefs: []
  type: TYPE_NORMAL
- en: zero-forcing
  prefs: []
  type: TYPE_NORMAL
- en: ZMCSCG
  prefs: []
  type: TYPE_NORMAL
- en: zero-mean circularly-symmetric complex Gaussian
  prefs: []
  type: TYPE_NORMAL
- en: ZP
  prefs: []
  type: TYPE_NORMAL
- en: zero-padding
  prefs: []
  type: TYPE_NORMAL
- en: ZT
  prefs: []
  type: TYPE_NORMAL
- en: zero-tail
  prefs: []
  type: TYPE_NORMAL
- en: A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Abdul Karim Gizzini, , Marwa Chafii Authors acknowledge the CY INEX for the
    support of the project through the ASIA Chair of Excellence Grant (PIA/ANR-16-IDEX-0008).
    Abdul Karim Gizzini is with ETIS, UMR8051, CY Cergy Paris Universit√©, ENSEA, CNRS,
    France (e-mail: abdulkarim.gizzini@ensea.fr). Marwa Chafii is with the Engineering
    Division, New York University (NYU) Abu Dhabi, 129188, UAE, and NYU WIRELESS,
    NYU Tandon School of Engineering, Brooklyn, 11201, NY (e-mail: marwa.chafii@nyu.edu).'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Wireless communications systems are impacted by multi-path fading and Doppler
    shift in dynamic environments, where the channel becomes doubly-dispersive and
    its estimation becomes an arduous task. Only a few pilots are used for channel
    estimation in conventional approaches to preserve high data rate transmission.
    Consequently, such estimators experience a significant performance degradation
    in high mobility scenarios. Recently, deep learning has been employed for doubly-dispersive
    channel estimation due to its low-complexity, robustness, and good generalization
    ability. Against this backdrop, the current paper presents a comprehensive survey
    on channel estimation techniques based on deep learning by deeply investigating
    different methods. The study also provides extensive experimental simulations
    followed by a computational complexity analysis. After considering different parameters
    such as modulation order, mobility, frame length, and deep learning architecture,
    the performance of the studied estimators is evaluated in several mobility scenarios.
    In addition, the source codes are made available online in order to make the results
    reproducible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Channel estimation, Deep learning, Frequency-selective channels, Time-varying
    channels.
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the commercialization of fifth generation networks globally, research into
    sixth generation (6G) networks has been initiated to address the demands for high
    data rates and low latency mobile applications, including unmanned aerial vehicles¬†[[1](#bib.bib1)],
    high-speed railway¬†[[2](#bib.bib2)], and vehicular communications¬†[[3](#bib.bib3)].
    Mobile wireless communications systems offer the freedom to move around without
    being disconnected from the network. However, the mobility feature is ridden with
    several challenges that have a severely adverse impact on the communication reliability,
    such as fast and frequent handovers¬†[[4](#bib.bib4)], carrier frequency offset¬†[[5](#bib.bib5)],
    inter-carrier interference¬†[[6](#bib.bib6)], high penetration loss¬†[[7](#bib.bib7)],
    and fast time-varying wireless channel¬†[[8](#bib.bib8)].
  prefs: []
  type: TYPE_NORMAL
- en: In wireless environment, transmitted signals are known to propagate via a multitude
    of paths, each entailing a different attenuation and delay in addition to the
    Doppler shift effect stemming from the motion of network nodes along with the
    surrounding environment. As a result, the wireless channel becomes frequency-selective
    and time-varying. Given that a precisely estimated channel response influences
    the follow-up equalization, demodulation, and decoding operations at the receiver,
    the accuracy of the channel estimation influences the system performance. Therefore,
    ensuring communication reliability via accurate channel estimation in such environments
    is highly important.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the extant literature, a vast body of work has been carried out to address
    the problem of doubly-dispersive channels. While some works have focused on investigating
    the waveform design¬†[[9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12)],
    we are interested in this paper in the channel estimation task. In general, channel
    estimators can be classified into two main categories: (i) [symbol-by-symbol](#id22.22.id22)
    ([SBS](#id22.22.id22)) channel estimators: the channel is estimated for each received
    symbol separately using only the previous and current received pilots¬†[[13](#bib.bib13),
    [14](#bib.bib14), [15](#bib.bib15)] (ii) [frame-by-frame](#id23.23.id23) ([FBF](#id23.23.id23))
    channel estimators: the previous, existing, as well as future pilots are employed
    in the channel estimation for each received symbol¬†[[16](#bib.bib16)]. It is possible
    to achieve a higher channel estimation accuracy by utilizing [FBF](#id23.23.id23)
    estimators, since the channel estimation of each symbol benefits from the combined
    knowledge of all allocated pilots within the frame. However, the conventional
    estimators‚Äô performance mainly relies on the allocated reference training pilots
    within the transmitted frames. The majority of standards allocate a few pilots
    to maintain a good transmission data rate. Therefore, these pilots are insufficient
    for accurately tracking the doubly-dispersive channel, because they are not spaced
    closely enough to capture the variation of the channel in the frequency domain.
    Consequently, conventional estimators are primarily based on the demapped data
    subcarriers, besides pilot subcarriers to update the channel estimate for each
    received symbol. This procedure called [data-pilot aided](#id16.16.id16) ([DPA](#id16.16.id16))
    channel estimation is regarded as unreliable because the demapping error gets
    enlarged from one symbol to another, which leads to another additional error in
    the estimation process, especially in highly dynamic time-varying channels. Moreover,
    other conventional estimators like the [linear minimum mean square error](#id166.166.id166)
    ([LMMSE](#id166.166.id166))¬†[[17](#bib.bib17)] estimator rely on many assumptions
    that limit their performance in highly dynamic time-varying channels. Moreover,
    linear conventional estimators are impractical solutions in real case scenarios
    as they rely on statistical models and require high implementation complexity,
    in addition, they lack robustness in highly dynamic environments. Therefore, investigating
    estimators with a good trade-off complexity vs. performance is a crucial need
    for improving the channel estimation accuracy while preserving good data rate
    as well as maintaining affordable computational complexity.'
  prefs: []
  type: TYPE_NORMAL
- en: As a prevailing approach to AI, [deep learning](#id96.96.id96) ([DL](#id96.96.id96))
    is an efficient method to analyze data by identifying patterns and learning underlying
    structures, denoting an effective approach to problems faced in various scientific
    fields. [DL](#id96.96.id96) algorithms have been integrated into the physical
    layer of wireless communications systems ¬†[[18](#bib.bib18), [19](#bib.bib19),
    [20](#bib.bib20)], including channel estimation¬†[[21](#bib.bib21), [22](#bib.bib22),
    [23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25), [26](#bib.bib26)]. In turn,
    this is attributable to the great success in enhancing the overall system performance,
    particularly when used in addition to conventional estimators, where coarse channel
    estimation is derived from conventional estimators, following which DL is employed
    to achieve a fine estimation. Therefore, DL-based channel estimators are capable
    of significantly enhancing the performance while preserving low computational
    complexity. In addition, the GPU-based distributed processing allows the DL employment
    in real-time applications, as a result of which DL can overcome the limitations
    of traditional channel estimation through robust, low-complexity, and generalized
    solutions that improve the performance of wireless systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Motivated by these advantages, [DL](#id96.96.id96) algorithms have been integrated
    in frequency-selective¬†[[24](#bib.bib24), [25](#bib.bib25), [26](#bib.bib26)]
    and doubly-dispersive channel estimation. In this survey, we examine the recently
    proposed DL-based channel estimation schemes in doubly-dispersive environments,
    where DL algorithms are utilized in two different manners: (i) [feed-forward neural
    networks](#id99.99.id99) with different architectures and configurations are employed
    on top of the conventional [SBS](#id22.22.id22) channel estimators¬†[[27](#bib.bib27),
    [28](#bib.bib28), [29](#bib.bib29)]. (ii) [convolutional neural networks](#id28.28.id28)
    processing is employed where the estimated channel for the entire frame is modeled
    as a 2D low-resolution noisy image, whereas [CNN](#id28.28.id28)-based processing
    is implemented as super resolution and denoising techniques¬†[[30](#bib.bib30),
    [31](#bib.bib31), [32](#bib.bib32)].'
  prefs: []
  type: TYPE_NORMAL
- en: The majority of surveys conducted in the literature ¬†[[33](#bib.bib33), [34](#bib.bib34)]
    lack intensive simulations in the performance evaluation and complexity analysis
    of the studied channel estimators. Moreover, they do not cover both SBS and FBF
    based estimators. In addition,¬†[[33](#bib.bib33)] compares the performance of
    different DL architectures used after the [least squares](#id172.172.id172) ([LS](#id172.172.id172))
    and the LMMSE estimators without considering several conventional channel estimation
    schemes, whereas¬†[[34](#bib.bib34)] provides a general overview of several channel
    estimators without any performance evaluation. Given this context, to the best
    of our knowledge, this is the first survey that presents a comprehensive study
    on the recently proposed DL-based SBS and FBF estimators in doubly-dispersive
    environments, while presenting intensive simulations evaluating the system performance
    in different scenarios, providing a detailed complexity analysis, as well as the
    source codes to reproduce all the presented results. We believe that this survey
    is a very relevant reference to initiate researches pertaining to the domain of
    deep learning based channel estimation in doubly dispersive channels. The contributions
    of this paper can be summarized in the following manner
  prefs: []
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comprehensive study on the recently proposed [DL](#id96.96.id96)-based channel
    estimation techniques for doubly-dispersive channels.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview of the [DL](#id96.96.id96) networks, especially those used in the studied
    channel estimators, such as [FNN](#id99.99.id99), [long short-term memory](#id32.32.id32)
    ([LSTM](#id32.32.id32)), [super resolution CNN](#id25.25.id25) ([SR-CNN](#id25.25.id25)),
    and [denoising CNN](#id26.26.id26) ([DN-CNN](#id26.26.id26)).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance analysis of different channel estimation schemes and a fair comparison
    between them in terms of [normalized mean-squared error](#id204.204.id204) ([NMSE](#id204.204.id204))
    and [bit error rate](#id64.64.id64) ([BER](#id64.64.id64)) for different mobility
    scenarios and frame length, and modulation order.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detailed computational complexity analysis for the studied channel estimators
    concerning the overall required real-valued operations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simulation source code for various channel estimation schemes to reproduce all
    the comparison results presented in this paper¬†[[35](#bib.bib35)].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The remainder of this paper is organized as follows: Section¬†[II](#S2 "II System
    Model ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments") elucidates the system model, illustrating signal transmission over
    a doubly-dispersive channel. Section¬†[III](#S3 "III DL Techniques Overview ‚Ä£ A
    Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments")
    provides a brief overview of the main [DL](#id96.96.id96) networks employed in
    this survey. The recently proposed [DL](#id96.96.id96)-based [SBS](#id22.22.id22)
    and [FBF](#id23.23.id23) channel estimation schemes are thoroughly investigated
    and discussed in Sections¬†[IV](#S4 "IV DL-Based SBS Channel Estimation ‚Ä£ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")
    and¬†[V](#S5 "V DL-Based FBF Channel Estimation Schemes ‚Ä£ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments"), respectively. In
    Section¬†[VI](#S6 "VI Simulation Results ‚Ä£ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments"), different modulation orders are
    used to present simulation results, wherein the performance of the studied estimators
    is examined in terms of [BER](#id64.64.id64), and [NMSE](#id204.204.id204). Detailed
    computational complexity analysis is provided in Section¬†[VII](#S7 "VII Complexity
    Analysis ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments"). Finally, Section¬†[VIII](#S8 "VIII Conclusion ‚Ä£ A Survey on Deep
    Learning based Channel Estimation in Doubly Dispersive Environments") concludes
    this study.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Notations: Throughout the paper, vectors are defined with lowercase bold symbols
    $\bm{x}$ whose $k$-th element is $\bm{x}[k]$. Time and frequency domain vectors
    are represented by $\bm{x}$ and $\tilde{\bm{x}}$ respectively. Matrices are written
    as uppercase bold symbols $\bm{X}$. $\mathrm{E}\left[.\right]$ denotes the expectation
    operator. The trace of a square matrix $\bm{X}$ is $\mathrm{trace}\left\{\bm{X}\right\}$.
    The notation $\odot$ and $\oslash$ refer to the element-wise multiplication and
    division operations, respectively. Finally. the pseudo inverse and conjugate matrices
    of $\bm{X}$ are signified by $\bm{X}^{\dagger}$ and $\bm{X}^{\text{H}}$, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: II System Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consider a frame comprising $I$ [orthogonal frequency division multiplexing](#id208.208.id208)
    ([OFDM](#id208.208.id208)) symbols. The $i$-th transmitted frequency-domain [OFDM](#id208.208.id208)
    symbol $\tilde{\bm{x}}_{i}[k]$, is denoted by
  prefs: []
  type: TYPE_NORMAL
- en: '|  | <math  class="ltx_Math" alttext="\tilde{\bm{x}}_{i}[k]=\left\{\begin{array}[]{ll}\tilde{\bm{x}}_{\text{d}_{i}}[k],&amp;\quad
    k\in{\mathcal{K}}_{\text{d}}.\\ \tilde{\bm{x}}_{\text{p}_{i}}[k],&amp;\quad k\in{\mathcal{K}}_{\text{p}}.\\'
  prefs: []
  type: TYPE_NORMAL
- en: \end{array}\right." display="block"><semantics ><mrow 
    ><mrow  ><msub
     ><mover accent="true" 
    ><mi  >ùíô</mi><mo
     >~</mo></mover><mi 
    >i</mi></msub><mo lspace="0em" rspace="0em" 
    >‚Äã</mo><mrow  ><mo
    stretchy="false"  >[</mo><mi
     >k</mi><mo stretchy="false" 
    >]</mo></mrow></mrow><mo  >=</mo><mrow
     ><mo 
    >{</mo><mtable columnspacing="5pt" displaystyle="true"
    rowspacing="0pt"  ><mtr 
    ><mtd class="ltx_align_left" columnalign="left" 
    ><mrow  ><mrow
     ><msub 
    ><mover accent="true" 
    ><mi  >ùíô</mi><mo
     >~</mo></mover><msub
     ><mtext
     >d</mtext><mi
     >i</mi></msub></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
     ><mo stretchy="false"
     >[</mo><mi
     >k</mi><mo stretchy="false"
     >]</mo></mrow></mrow><mo
     >,</mo></mrow></mtd><mtd
    class="ltx_align_left" columnalign="left"  ><mrow
     ><mrow 
    ><mi  >k</mi><mo
     >‚àà</mo><msub
     ><mi class="ltx_font_mathcaligraphic"
     >ùí¶</mi><mtext
     >d</mtext></msub></mrow><mo
    lspace="0em"  >.</mo></mrow></mtd></mtr><mtr
     ><mtd class="ltx_align_left" columnalign="left"
     ><mrow  ><mrow
     ><msub 
    ><mover accent="true" 
    ><mi  >ùíô</mi><mo
     >~</mo></mover><msub
     ><mtext
     >p</mtext><mi
     >i</mi></msub></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
     ><mo stretchy="false"
     >[</mo><mi
     >k</mi><mo stretchy="false"
     >]</mo></mrow></mrow><mo
     >,</mo></mrow></mtd><mtd
    class="ltx_align_left" columnalign="left"  ><mrow
     ><mrow 
    ><mi  >k</mi><mo
     >‚àà</mo><msub
     ><mi class="ltx_font_mathcaligraphic"
     >ùí¶</mi><mtext
     >p</mtext></msub></mrow><mo
    lspace="0em"  >.</mo></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><apply
     ><apply 
    ><csymbol cd="ambiguous"  >subscript</csymbol><apply
     ><ci 
    >~</ci><ci  >ùíô</ci></apply><ci
     >ùëñ</ci></apply><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><ci  >ùëò</ci></apply></apply><apply
     ><csymbol cd="latexml" 
    >cases</csymbol><matrix  ><matrixrow
     ><apply 
    ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><ci 
    >~</ci><ci 
    >ùíô</ci></apply><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    ><mtext mathsize="70%" 
    >d</mtext></ci><ci 
    >ùëñ</ci></apply></apply><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><ci 
    >ùëò</ci></apply></apply><apply 
    ><ci  >ùëò</ci><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><ci
     >ùí¶</ci><ci
     ><mtext
    mathsize="70%"  >d</mtext></ci></apply></apply></matrixrow><matrixrow
     ><apply 
    ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><ci 
    >~</ci><ci 
    >ùíô</ci></apply><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    ><mtext mathsize="70%" 
    >p</mtext></ci><ci 
    >ùëñ</ci></apply></apply><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><ci 
    >ùëò</ci></apply></apply><apply 
    ><ci  >ùëò</ci><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><ci
     >ùí¶</ci><ci
     ><mtext
    mathsize="70%"  >p</mtext></ci></apply></apply></matrixrow></matrix></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\tilde{\bm{x}}_{i}[k]=\left\{\begin{array}[]{ll}\tilde{\bm{x}}_{\text{d}_{i}}[k],&\quad
    k\in{\mathcal{K}}_{\text{d}}.\\ \tilde{\bm{x}}_{\text{p}_{i}}[k],&\quad k\in{\mathcal{K}}_{\text{p}}.\\
    \end{array}\right.</annotation></semantics></math> |  | (1) |
  prefs: []
  type: TYPE_NORMAL
- en: where $0\leq k\leq K-1$. $\tilde{\bm{x}}_{\text{d}_{i}}[k]$ and $\tilde{\bm{x}}_{\text{p}_{i}}[k]$
    represent the modulated data symbols and the predefined pilot symbols allocated
    at a set of subcarriers denoted ${\mathcal{K}}_{\text{d}}$ and ${\mathcal{K}}_{\text{p}}$,
    respectively. $\bm{x}_{i}[k]$ is converted to the time domain by applying the
    [inverse discrete Fourier transform](#id150.150.id150) ([IDFT](#id150.150.id150)),
    such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\bm{x}_{i}[n]=\frac{1}{\sqrt{{{K}}}}\sum_{k=0}^{{K}-1}\tilde{\bm{x}}_{i}[k]e^{j2\pi\frac{nk}{{K}}}.$
    |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: A [cyclic prefix](#id82.82.id82) ([CP](#id82.82.id82)) of length larger than
    the delay spread is added. Therefore, after passing via the doubly-dispersive
    channel and removing the [CP](#id82.82.id82), the received [OFDM](#id208.208.id208)
    symbol $\bm{y}_{i}[n]$ can be expressed as follows
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\bm{y}_{i}[n]&amp;=\sum_{l=0}^{L-1}{\bm{h}_{i}[l,n]}\bm{x}_{i}[n-l]+{\bm{v}}_{i}[n]\\
    &amp;=\frac{1}{\sqrt{{K}}}\sum_{k=0}^{{K}-1}{\tilde{\bm{h}}_{i}[k,n]}\tilde{\bm{x}}_{i}[k]e^{j2\pi\frac{nk}{{K}}}+{\bm{v}}_{i}[n].\end{split}$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: $\bm{h}_{i}[l,n]$ denotes the delay-time response of the discrete [linear time-variant](#id176.176.id176)
    ([LTV](#id176.176.id176)) channel of $L$ taps at the $i$-th [OFDM](#id208.208.id208)
    symbol, whereas $\tilde{\bm{h}}_{i}[k,n]=\sum_{l=0}^{L-1}{{\bm{h}}_{i}[l,n]}e^{-j2\pi\frac{lk}{{K}}}$
    refers to the frequency-time response. Moreover, ${\bm{v}}_{i}$ signifies the
    [additive white Gaussian noise](#id62.62.id62) ([AWGN](#id62.62.id62)) of variance
    $\sigma^{2}$. The $i$-th received frequency-domain [OFDM](#id208.208.id208) symbol
    is derived from ([3](#S2.E3 "In II System Model ‚Ä£ A Survey on Deep Learning based
    Channel Estimation in Doubly Dispersive Environments")) via [discrete Fourier
    transform](#id95.95.id95) ([DFT](#id95.95.id95)), and thus
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\tilde{\bm{y}}_{i}[k]&amp;=\frac{1}{{{K}}}\sum_{q=0}^{{K}-1}\tilde{\bm{x}}_{i}[q]\sum_{n=0}^{{K}-1}\tilde{\bm{h}}_{i}[q,n]e^{-j2\pi\frac{n(k-q)}{{K}}}+\tilde{\bm{v}}_{i}[k].\end{split}$
    |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: It is noteworthy that index $k$ is used in¬†([3](#S2.E3 "In II System Model ‚Ä£
    A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments"))
    to express the channel delay-time response in terms of the channel frequency-time
    response. While the change of index into $q$ in¬†([4](#S2.E4 "In II System Model
    ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments"))
    is used to express the $i$-th received symbol in frequency domain. This, in turn,
    better illustrates the DFT transform. Moreover, $\tilde{\bm{h}}_{i}[q,n]$ refers
    to time-variant at the scale of the [OFDM](#id208.208.id208) symbol duration (the
    index $i$) and within the symbol itself (the index $n$). Accordingly,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\tilde{\bm{h}}_{i}[q,n]&amp;=\sum_{l=0}^{L-1}e^{-j2\pi\frac{lq}{K}}\int_{\nu=-\nu_{d}}^{\nu=\nu_{d}}\bar{h}(l,\nu)e^{j2\pi\nu
    n_{i}}e^{j2\pi\nu n}d\nu,\end{split}$ |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: where $\bar{h}(l,\nu)=\sum\limits_{n}{h}[l,n]e^{-j2\pi n\nu}$ signifies the
    channel delay-Doppler response, $\nu$ refers to the normalized Doppler frequency,
    $n_{i}=i(K+K_{\text{cp}})+K_{\text{cp}}$. And $\nu_{d}=\frac{f_{d}}{F_{s}}$ represents
    the maximum Doppler frequency. Let
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\bar{\bm{h}}_{i}[l,v]&amp;=\frac{1}{K}\sum_{q=0}^{{K}-1}\sum_{n=0}^{{K}-1}\tilde{\bm{h}}_{i}[q,n]e^{-j2\pi\frac{nv}{K}}e^{j2\pi\frac{ql}{K}}\\
    &amp;=\int_{\nu=-\nu_{d}}^{\nu=\nu_{d}}\bar{h}(l,\nu)e^{j2\pi\nu n_{i}}\sum_{n=0}^{{K}-1}e^{-j2\pi(\nu-\frac{v}{K})n}d\nu,\end{split}$
    |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: be the discrete delay-Doppler response at the $i$-th [OFDM](#id208.208.id208)
    symbol. For the sake of simplicity, $\bar{h}(l,\nu)$ is assumed to be uncorrelated
    in both domains¬†[[36](#bib.bib36)], such that $\mathrm{E}\left[\bar{h}(l,\nu)\bar{h}^{*}(l^{\prime},\nu^{\prime})\right]=S_{h}(l,\nu)\delta(l-l^{\prime})\delta(\nu-\nu^{\prime})$,
    where $S_{h}(l,\nu)$ is the delay-Doppler spectrum¬†[[37](#bib.bib37)], and $\delta(x)$
    denotes the Dirac delta function. Using¬†([6](#S2.E6 "In II System Model ‚Ä£ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")),
    we have
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\mathrm{E}\left[\bar{\bm{h}}_{i}[l,v]\bar{\bm{h}}_{i}^{*}[l,v^{\prime}]\right]=&amp;\\
    \int_{\nu=-\nu_{d}}^{\nu=\nu_{d}}S_{h}(l,\nu)\sum_{n=0}^{{K}-1}&amp;\sum_{n^{\prime}=0}^{{K}-1}e^{-j2\pi\nu(n-n^{\prime})}e^{-j2\pi\frac{n^{\prime}v^{\prime}-nv}{K}}d\nu.\end{split}$
    |  | (7) |'
  prefs: []
  type: TYPE_TB
- en: This correlation that is independent of the index $i$ can be approximated as
    follows
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\mathrm{E}\left[\bar{\bm{h}}_{i}[l,v]\bar{\bm{h}}_{i}^{*}[l,v^{\prime}]\right]&amp;\approx
    K^{2}\rho[l,v]\delta[v-v^{\prime}],\\ \mbox{where }&amp;\rho[l,v]=S_{h}(l,\frac{v}{N}).\end{split}$
    |  | (8) |'
  prefs: []
  type: TYPE_TB
- en: The time selectivity of the channel depends on the mobility. In very low mobility,
    where $f_{\text{d}}\approx 0$, $\tilde{\bm{h}}_{i}[q,n]=\tilde{\bm{h}}[q]$ is
    constant during the whole frame. For moderate to high mobility, the channel variation
    within the duration of one [OFDM](#id208.208.id208) symbol is negligible, and
    therefore, $\tilde{\bm{h}}_{i}[q,n]=\tilde{\bm{h}}_{i}[q]$. At very high mobility,
    the channel becomes variant within a single [OFDM](#id208.208.id208) symbol. In
    this instance, $\tilde{\bm{h}}_{i}[q,n]=\tilde{\bm{h}}_{i}[q]+\tilde{\bm{\epsilon}}_{i}[q,n]$,
    where
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\tilde{\bm{h}}_{i}[q]=\frac{1}{K}\sum_{n=0}^{K-1}\tilde{\bm{h}}_{i}[q,n],\leavevmode\nobreak\
    \mbox{and }\tilde{\bm{\epsilon}}_{i}[q,n]=\tilde{\bm{h}}_{i}[q,n]-\tilde{\bm{h}}_{i}[q].$
    |  | (9) |'
  prefs: []
  type: TYPE_TB
- en: Replacing this in ([4](#S2.E4 "In II System Model ‚Ä£ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments")), we get
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\tilde{\bm{y}}_{{i}}[k]&amp;=\tilde{\bm{h}}_{i}[k]\tilde{\bm{x}}_{i}[k]+\tilde{\bm{e}}_{i,\text{d}}[k]+\tilde{\bm{v}}_{i}[k],\leavevmode\nobreak\
    k\in{\mathcal{K}}_{\text{on}}.\end{split}$ |  | (10) |'
  prefs: []
  type: TYPE_TB
- en: The term $\tilde{\bm{e}}_{i,\text{d}}[k]$ denotes the Doppler interference given
    by
  prefs: []
  type: TYPE_NORMAL
- en: '|  | <math  class="ltx_Math" alttext="\begin{split}\tilde{\bm{e}}_{i,\text{d}}[k]&amp;=\frac{1}{{{K}}}\sum_{\begin{subarray}{c}q=0\\
    q\neq k\end{subarray}}^{{K}-1}\sum_{n=0}^{{K}-1}\tilde{\bm{h}}_{i}[q,n]e^{-j2\pi\frac{n(k-q)}{{K}}}\tilde{\bm{x}}_{i}[q]\\'
  prefs: []
  type: TYPE_NORMAL
- en: '&amp;=\frac{1}{K}\sum_{\begin{subarray}{c}q\in{\mathcal{K}}_{\text{on}}\\'
  prefs: []
  type: TYPE_NORMAL
- en: q\neq k\end{subarray}}\sum_{l=0}^{L-1}\bar{\bm{h}}_{i}[l,k-q]e^{-j2\pi\frac{lq}{K}}\tilde{\bm{x}}_{i}[q].\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt" ><mtr ><mtd class="ltx_align_right"
    columnalign="right" ><mrow ><msub
    ><mover accent="true"  ><mi
     >ùíÜ</mi><mo 
    >~</mo></mover><mrow 
    ><mi  >i</mi><mo
     >,</mo><mtext
     >d</mtext></mrow></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
    ><mo stretchy="false"  >[</mo><mi
     >k</mi><mo stretchy="false"
     >]</mo></mrow></mrow></mtd><mtd
    class="ltx_align_left" columnalign="left" ><mrow ><mo
     >=</mo><mrow ><mfrac
     ><mn 
    >1</mn><mi  >K</mi></mfrac><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
    ><munderover ><mo
    movablelimits="false" rspace="0em"  >‚àë</mo><mtable
    rowspacing="0pt"  ><mtr
     ><mtd
     ><mrow
     ><mi
     >q</mi><mo
     >=</mo><mn
     >0</mn></mrow></mtd></mtr><mtr
     ><mtd
     ><mrow
     ><mi
     >q</mi><mo
     >‚â†</mo><mi
     >k</mi></mrow></mtd></mtr></mtable><mrow
     ><mi 
    >K</mi><mo 
    >‚àí</mo><mn 
    >1</mn></mrow></munderover><mrow ><munderover
    ><mo movablelimits="false" 
    >‚àë</mo><mrow 
    ><mi 
    >n</mi><mo 
    >=</mo><mn 
    >0</mn></mrow><mrow 
    ><mi 
    >K</mi><mo 
    >‚àí</mo><mn 
    >1</mn></mrow></munderover><mrow ><msub
    ><mover accent="true" 
    ><mi  >ùíâ</mi><mo
     >~</mo></mover><mi
     >i</mi></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
    ><mo stretchy="false" 
    >[</mo><mi  >q</mi><mo
     >,</mo><mi 
    >n</mi><mo stretchy="false" 
    >]</mo></mrow><mo lspace="0em" rspace="0em" 
    >‚Äã</mo><msup ><mi
     >e</mi><mrow
     ><mo
     >‚àí</mo><mrow
     ><mi
     >j</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mn
     >2</mn><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mi
     >œÄ</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mfrac
     ><mrow
     ><mi
     >n</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
     ><mo
    stretchy="false"  >(</mo><mrow
     ><mi
     >k</mi><mo
     >‚àí</mo><mi
     >q</mi></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow><mi
     >K</mi></mfrac></mrow></mrow></msup><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msub
    ><mover accent="true" 
    ><mi 
    >ùíô</mi><mo 
    >~</mo></mover><mi 
    >i</mi></msub><mo lspace="0em" rspace="0em"
     >‚Äã</mo><mrow
    ><mo stretchy="false" 
    >[</mo><mi  >q</mi><mo
    stretchy="false"  >]</mo></mrow></mrow></mrow></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd class="ltx_align_left" columnalign="left" ><mrow
    ><mrow ><mo
     >=</mo><mrow
    ><mfrac  ><mn
     >1</mn><mi
     >K</mi></mfrac><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
    ><munder ><mo
    movablelimits="false" rspace="0em"  >‚àë</mo><mtable
    rowspacing="0pt"  ><mtr
     ><mtd
     ><mrow
     ><mi
     >q</mi><mo
     >‚àà</mo><msub
     ><mi
    class="ltx_font_mathcaligraphic" 
    >ùí¶</mi><mtext 
    >on</mtext></msub></mrow></mtd></mtr><mtr
     ><mtd
     ><mrow
     ><mi
     >q</mi><mo
     >‚â†</mo><mi
     >k</mi></mrow></mtd></mtr></mtable></munder><mrow
    ><munderover ><mo
    movablelimits="false"  >‚àë</mo><mrow
     ><mi 
    >l</mi><mo 
    >=</mo><mn 
    >0</mn></mrow><mrow 
    ><mi  >L</mi><mo
     >‚àí</mo><mn
     >1</mn></mrow></munderover><mrow
    ><msub ><mover
    accent="true"  ><mi
     >ùíâ</mi><mo
     >¬Ø</mo></mover><mi
     >i</mi></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
    ><mo stretchy="false" 
    >[</mo><mi  >l</mi><mo
     >,</mo><mrow
    ><mi 
    >k</mi><mo 
    >‚àí</mo><mi 
    >q</mi></mrow><mo stretchy="false" 
    >]</mo></mrow><mo lspace="0em" rspace="0em" 
    >‚Äã</mo><msup ><mi
     >e</mi><mrow
     ><mo
     >‚àí</mo><mrow
     ><mi
     >j</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mn
     >2</mn><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mi
     >œÄ</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mfrac
     ><mrow
     ><mi
     >l</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mi
     >q</mi></mrow><mi
     >K</mi></mfrac></mrow></mrow></msup><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msub
    ><mover accent="true" 
    ><mi 
    >ùíô</mi><mo 
    >~</mo></mover><mi 
    >i</mi></msub><mo lspace="0em" rspace="0em"
     >‚Äã</mo><mrow
    ><mo stretchy="false" 
    >[</mo><mi  >q</mi><mo
    stretchy="false"  >]</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo
    lspace="0em"  >.</mo></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply 
    ><apply  ><apply
     ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><ci  >~</ci><ci
     >ùíÜ</ci></apply><list
     ><ci 
    >ùëñ</ci><ci 
    ><mtext mathsize="70%" 
    >d</mtext></ci></list></apply><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><ci 
    >ùëò</ci></apply></apply><apply 
    ><apply  ><cn
    type="integer"  >1</cn><ci
     >ùêæ</ci></apply><apply
     ><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><list 
    ><matrix 
    ><matrixrow 
    ><apply 
    ><ci 
    >ùëû</ci><cn type="integer" 
    >0</cn></apply></matrixrow><matrixrow
     ><apply
     ><ci
     >ùëû</ci><ci
     >ùëò</ci></apply></matrixrow></matrix></list></apply><apply
     ><ci 
    >ùêæ</ci><cn type="integer" 
    >1</cn></apply></apply><apply 
    ><apply  ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><ci 
    >ùëõ</ci><cn type="integer" 
    >0</cn></apply></apply><apply 
    ><ci 
    >ùêæ</ci><cn type="integer" 
    >1</cn></apply></apply><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><ci  >~</ci><ci
     >ùíâ</ci></apply><ci
     >ùëñ</ci></apply><interval
    closure="closed"  ><ci
     >ùëû</ci><ci
     >ùëõ</ci></interval><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >ùëí</ci><apply
     ><apply
     ><ci
     >ùëó</ci><cn
    type="integer"  >2</cn><ci
     >ùúã</ci><apply
     ><apply
     ><ci
     >ùëõ</ci><apply
     ><ci
     >ùëò</ci><ci
     >ùëû</ci></apply></apply><ci
     >ùêæ</ci></apply></apply></apply></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><ci 
    >~</ci><ci 
    >ùíô</ci></apply><ci 
    >ùëñ</ci></apply><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><ci 
    >ùëû</ci></apply></apply></apply></apply></apply></apply><apply
     ><apply 
    ><apply  ><cn
    type="integer"  >1</cn><ci
     >ùêæ</ci></apply><apply
     ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><list 
    ><matrix 
    ><matrixrow 
    ><apply 
    ><ci 
    >ùëû</ci><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >ùí¶</ci><ci 
    ><mtext mathsize="50%" 
    >on</mtext></ci></apply></apply></matrixrow><matrixrow
     ><apply
     ><ci
     >ùëû</ci><ci
     >ùëò</ci></apply></matrixrow></matrix></list></apply><apply
     ><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><ci  >ùëô</ci><cn
    type="integer"  >0</cn></apply></apply><apply
     ><ci 
    >ùêø</ci><cn type="integer" 
    >1</cn></apply></apply><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><ci  >¬Ø</ci><ci
     >ùíâ</ci></apply><ci
     >ùëñ</ci></apply><interval
    closure="closed"  ><ci
     >ùëô</ci><apply
     ><ci
     >ùëò</ci><ci
     >ùëû</ci></apply></interval><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >ùëí</ci><apply
     ><apply
     ><ci
     >ùëó</ci><cn
    type="integer"  >2</cn><ci
     >ùúã</ci><apply
     ><apply
     ><ci
     >ùëô</ci><ci
     >ùëû</ci></apply><ci
     >ùêæ</ci></apply></apply></apply></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><ci 
    >~</ci><ci 
    >ùíô</ci></apply><ci 
    >ùëñ</ci></apply><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><ci 
    >ùëû</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}\tilde{\bm{e}}_{i,\text{d}}[k]&=\frac{1}{{{K}}}\sum_{\begin{subarray}{c}q=0\\
    q\neq k\end{subarray}}^{{K}-1}\sum_{n=0}^{{K}-1}\tilde{\bm{h}}_{i}[q,n]e^{-j2\pi\frac{n(k-q)}{{K}}}\tilde{\bm{x}}_{i}[q]\\
    &=\frac{1}{K}\sum_{\begin{subarray}{c}q\in{\mathcal{K}}_{\text{on}}\\ q\neq k\end{subarray}}\sum_{l=0}^{L-1}\bar{\bm{h}}_{i}[l,k-q]e^{-j2\pi\frac{lq}{K}}\tilde{\bm{x}}_{i}[q].\end{split}</annotation></semantics></math>
    |  | (11) |
  prefs: []
  type: TYPE_NORMAL
- en: The Doppler interference destroys the orthogonality of the subcarriers within
    the received [OFDM](#id208.208.id208) symbol, leading to a significant degradation
    in the overall system performance¬†[[38](#bib.bib38)]. Assuming that the subcarriers
    are uncorrelated with power $E_{q}$, i.e. $\mathrm{E}\left[\tilde{\bm{x}}_{i}[q]\tilde{\bm{x}}^{*}_{i}[q^{\prime}]\right]=E_{q}\delta[q-q^{\prime}]$
    and using ([8](#S2.E8 "In II System Model ‚Ä£ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments")) then
  prefs: []
  type: TYPE_NORMAL
- en: '|  | <math  class="ltx_Math" alttext="\begin{split}\mathrm{E}\left[\tilde{\bm{e}}_{i,\text{d}}[k]\tilde{\bm{e}}^{*}_{i,\text{d}}[k^{\prime}]\right]&amp;=\sum_{l=0}^{L-1}\sum_{\begin{subarray}{c}q\in{\mathcal{K}}_{\text{on}}\\
    q\neq k\end{subarray}}E_{q}\rho[l,k-q]\delta[k-k^{\prime}]\\'
  prefs: []
  type: TYPE_NORMAL
- en: '&amp;=\sigma^{2}_{d}[k]\delta[k-k^{\prime}].\end{split}" display="block"><semantics
    ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"
    ><mtr ><mtd class="ltx_align_right"
    columnalign="right" ><mrow ><mi
    mathvariant="normal"  >E</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
    ><mo  >[</mo><mrow
    ><msub ><mover
    accent="true"  ><mi
     >ùíÜ</mi><mo 
    >~</mo></mover><mrow 
    ><mi  >i</mi><mo
     >,</mo><mtext
     >d</mtext></mrow></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
    ><mo stretchy="false" 
    >[</mo><mi  >k</mi><mo
    stretchy="false"  >]</mo></mrow><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msubsup
    ><mover accent="true" 
    ><mi  >ùíÜ</mi><mo
     >~</mo></mover><mrow
     ><mi
     >i</mi><mo
     >,</mo><mtext
     >d</mtext></mrow><mo
     >‚àó</mo></msubsup><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
    ><mo stretchy="false" 
    >[</mo><msup ><mi
     >k</mi><mo
     >‚Ä≤</mo></msup><mo
    stretchy="false"  >]</mo></mrow></mrow><mo
     >]</mo></mrow></mrow></mtd><mtd
    class="ltx_align_left" columnalign="left" ><mrow ><mo
    rspace="0.111em"  >=</mo><mrow
    ><munderover ><mo
    movablelimits="false" rspace="0em"  >‚àë</mo><mrow
     ><mi 
    >l</mi><mo 
    >=</mo><mn 
    >0</mn></mrow><mrow 
    ><mi 
    >L</mi><mo 
    >‚àí</mo><mn 
    >1</mn></mrow></munderover><mrow ><munder
    ><mo movablelimits="false" 
    >‚àë</mo><mtable rowspacing="0pt" 
    ><mtr 
    ><mtd 
    ><mrow 
    ><mi 
    >q</mi><mo 
    >‚àà</mo><msub 
    ><mi class="ltx_font_mathcaligraphic"
     >ùí¶</mi><mtext
     >on</mtext></msub></mrow></mtd></mtr><mtr
     ><mtd
     ><mrow
     ><mi
     >q</mi><mo
     >‚â†</mo><mi
     >k</mi></mrow></mtd></mtr></mtable></munder><mrow
    ><msub ><mi
     >E</mi><mi
     >q</mi></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mi
     >œÅ</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
    ><mo stretchy="false" 
    >[</mo><mi  >l</mi><mo
     >,</mo><mrow
    ><mi 
    >k</mi><mo 
    >‚àí</mo><mi 
    >q</mi></mrow><mo stretchy="false" 
    >]</mo></mrow><mo lspace="0em" rspace="0em" 
    >‚Äã</mo><mi  >Œ¥</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
    ><mo stretchy="false" 
    >[</mo><mrow ><mi
     >k</mi><mo
     >‚àí</mo><msup
    ><mi 
    >k</mi><mo 
    >‚Ä≤</mo></msup></mrow><mo stretchy="false"
     >]</mo></mrow></mrow></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd class="ltx_align_left" columnalign="left" ><mrow
    ><mrow ><mo
     >=</mo><mrow
    ><msubsup ><mi
     >œÉ</mi><mi 
    >d</mi><mn 
    >2</mn></msubsup><mo lspace="0em" rspace="0em"
     >‚Äã</mo><mrow
    ><mo stretchy="false" 
    >[</mo><mi  >k</mi><mo
    stretchy="false"  >]</mo></mrow><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mi
     >Œ¥</mi><mo lspace="0em"
    rspace="0em"  >‚Äã</mo><mrow
    ><mo stretchy="false" 
    >[</mo><mrow ><mi
     >k</mi><mo
     >‚àí</mo><msup
    ><mi 
    >k</mi><mo 
    >‚Ä≤</mo></msup></mrow><mo stretchy="false"
     >]</mo></mrow></mrow></mrow><mo
    lspace="0em"  >.</mo></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply 
    ><apply  ><apply
     ><ci 
    >E</ci><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><ci  >~</ci><ci
     >ùíÜ</ci></apply><list
     ><ci 
    >ùëñ</ci><ci 
    ><mtext mathsize="70%" 
    >d</mtext></ci></list></apply><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><ci 
    >ùëò</ci></apply><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><apply 
    ><ci  >~</ci><ci
     >ùíÜ</ci></apply></apply><list
     ><ci
     >ùëñ</ci><ci
     ><mtext
    mathsize="70%"  >d</mtext></ci></list></apply><apply
     ><csymbol
    cd="latexml"  >delimited-[]</csymbol><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >ùëò</ci><ci
     >‚Ä≤</ci></apply></apply></apply></apply></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><ci 
    >ùëô</ci><cn type="integer" 
    >0</cn></apply></apply><apply 
    ><ci 
    >ùêø</ci><cn type="integer" 
    >1</cn></apply></apply><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><list 
    ><matrix 
    ><matrixrow 
    ><apply 
    ><ci 
    >ùëû</ci><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >ùí¶</ci><ci 
    ><mtext mathsize="50%" 
    >on</mtext></ci></apply></apply></matrixrow><matrixrow
     ><apply
     ><ci
     >ùëû</ci><ci
     >ùëò</ci></apply></matrixrow></matrix></list></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùê∏</ci><ci
     >ùëû</ci></apply><ci
     >ùúå</ci><interval
    closure="closed"  ><ci
     >ùëô</ci><apply
     ><ci
     >ùëò</ci><ci
     >ùëû</ci></apply></interval><ci
     >ùõø</ci><apply
     ><csymbol
    cd="latexml"  >delimited-[]</csymbol><apply
     ><ci
     >ùëò</ci><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >ùëò</ci><ci
     >‚Ä≤</ci></apply></apply></apply></apply></apply></apply></apply><apply
     ><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >ùúé</ci><cn type="integer" 
    >2</cn></apply><ci 
    >ùëë</ci></apply><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><ci 
    >ùëò</ci></apply><ci 
    >ùõø</ci><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><apply 
    ><ci 
    >ùëò</ci><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >ùëò</ci><ci 
    >‚Ä≤</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}\mathrm{E}\left[\tilde{\bm{e}}_{i,\text{d}}[k]\tilde{\bm{e}}^{*}_{i,\text{d}}[k^{\prime}]\right]&=\sum_{l=0}^{L-1}\sum_{\begin{subarray}{c}q\in{\mathcal{K}}_{\text{on}}\\
    q\neq k\end{subarray}}E_{q}\rho[l,k-q]\delta[k-k^{\prime}]\\ &=\sigma^{2}_{d}[k]\delta[k-k^{\prime}].\end{split}</annotation></semantics></math>
    |  | (12) |'
  prefs: []
  type: TYPE_NORMAL
- en: Thus, it is assumed that the Doppler interference is uncorrelated. However,
    the variance $\sigma^{2}_{d}[k]=\mathrm{E}\left[|\tilde{\bm{e}}_{i,\text{d}}[k]|^{2}\right]$
    depends on the subcarrier index. Noting that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\tilde{\bm{h}}_{i}[k]=\frac{1}{K}\sum_{l=0}^{L-1}\bar{\bm{h}}_{i}[l,0]e^{-j2\pi\frac{kl}{K}},$
    |  | (13) |'
  prefs: []
  type: TYPE_TB
- en: the channel gain and Doppler interference are uncorrelated, i.e. $\mathrm{E}\left[\tilde{\bm{h}}_{i}[k]\tilde{\bm{e}}_{i,\text{d}}^{*}[k]\right]=0$.
    Moreover, it is possible to estimate the $\tilde{\bm{h}}_{i}[k]$ from $L$ uncorrelated
    taps defined by $\bar{\bm{h}}_{i}[l,0]$.
  prefs: []
  type: TYPE_NORMAL
- en: III DL Techniques Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section discusses the [DL](#id96.96.id96) networks employed in the studied
    [DL](#id96.96.id96)-based channel estimation schemes, providing the mathematical
    representation of each network.
  prefs: []
  type: TYPE_NORMAL
- en: III-A FNN
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Neural networks are one of the most popular machine learning algorithms¬†[[39](#bib.bib39)].
    Initially, neural networks are inspired by the neural architecture of a human
    brain, For this reason, the basic building block is called a neuron as is the
    case with a human brain. Its functionality is similar to that of a human neuron,
    i.e. it takes in some inputs and then fires an output. In purely mathematical
    terms, a neuron denotes a placeholder for a mathematical function whose job is
    to yield an output by applying the function on the given inputs. Neurons are stacked
    together to form a layer. The neural network comprises at least one layer; in
    case multiple layers are employed, the neural network is referred to as deep [FNN](#id99.99.id99).
  prefs: []
  type: TYPE_NORMAL
- en: Consider a [FNN](#id99.99.id99) architecture shown in Figure¬†[1](#S3.F1 "Figure
    1 ‚Ä£ III-A FNN ‚Ä£ III DL Techniques Overview ‚Ä£ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments"). Here $\mathcal{L}$ represents
    the number of layers, including one input layer, $\mathcal{L}-2$ hidden layers,
    as well as one output layer . The $l$-th hidden layer of the network consists
    of $J_{l}$ neurons where $2\leq l\leq L-1$. Moreover, each neuron in the $l$-th
    hidden layer is denoted by $j$ where $j$ $1\leq j\leq J_{l}$. The [FNN](#id99.99.id99)
    inputs $\bm{i}$ and outputs $\bm{o}$ are expressed as $\bm{i}=[i_{1},i_{2},...,i_{\mathcal{N}}]^{T}\in\mathbb{R}^{\mathcal{N}\times
    1}$ and $\bm{o}=[o_{1},o_{2},...,o_{\mathcal{M}}]^{T}\in\mathbb{R}^{\mathcal{M}\times
    1}$, where $\mathcal{N}$ and $\mathcal{M}$ refer to the number of [FNN](#id99.99.id99)
    inputs and outputs, respectively. $\bm{W}_{l}\in\mathbb{R}^{J_{l}\times J_{l-1}}$,
    and $\bm{b}_{l}\in\mathbb{R}^{J_{l}\times 1}$ are used to express the weight matrix
    and the bias vector of the $l$-th hidden layer, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Each neuron $n_{(l,j)}$ performs a nonlinear transform of a weighted summation
    of the preceding layer‚Äôs output values. This nonlinear transformation is represented
    by the activation function ${f}_{(l,j)}$ on the neuron input vector $\bm{i}_{(l)}\in\mathbb{R}^{J_{l-1}\times
    1}$ using its weight vector $\bm{\omega}_{(l,j)}\in\mathbb{R}^{J_{l-1}\times 1}$,
    and bias ${b}_{(l,j)}$, respectively. The neuron‚Äôs output ${o}_{(l,j)}$ is
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ${o}_{(l,j)}={f}_{(l,j)}\Big{(}b_{(l,j)}+{\bm{\omega}^{T}_{(l,j)}}\bm{i}_{(l)}\Big{)}.$
    |  | (14) |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/4048d449f7f07aff53d6aa35081402c3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: FNN architecture showing the input, output, and hidden layers.'
  prefs: []
  type: TYPE_NORMAL
- en: The [deep neural network](#id98.98.id98) ([DNN](#id98.98.id98)) overall output
    of the $l$-th hidden layer is signified by the vector form
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\bm{o}_{(l)}=\bm{f}_{(l)}\Big{(}\bm{b}_{(l)}+{\bm{W}_{(l)}}\bm{i}_{(l)}\Big{)},\leavevmode\nobreak\
    \bm{i}_{(l+1)}=\bm{o}_{(l)},$ |  | (15) |'
  prefs: []
  type: TYPE_TB
- en: where $\bm{f}_{(l)}$ is a vector resulting from the stacking of the $n_{l}$
    activation functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the selection of the [FNN](#id99.99.id99) architecture, the parameter
    ${\theta}=(\bm{W},\bm{B})$ representing the total [FNN](#id99.99.id99) weights
    and biases must be estimated via the learning procedure applied during the [FNN](#id99.99.id99)
    training phase. As well known, ${\theta}$ estimation is obtained by minimizing
    a loss function $\text{Loss}({\theta})$. The loss function measures how far apart
    the predicted [FNN](#id99.99.id99) outputs ($\bm{o}_{(\mathcal{L})}^{\text{(P)}}$)
    are from the true outputs ($\bm{o}_{(\mathcal{L})}^{\text{(T)}}$). Therefore,
    the [FNN](#id99.99.id99) training phase carried over $N_{\text{train}}$ training
    samples can be explained in two steps: (i) calculate the loss, and (ii) update
    ${\theta}$. This process is repeated until convergence, so that the loss becomes
    very small. Accordingly, various optimization algorithms can be used for minimizing
    $\text{Loss}({\theta})$ by iteratively updating the parameter ${\theta}$, i.e.,
    stochastic gradient descent¬†[[39](#bib.bib39)], root mean square prop¬†[[40](#bib.bib40)],
    and adaptive moment estimation (ADAM)¬†[[41](#bib.bib41)].'
  prefs: []
  type: TYPE_NORMAL
- en: The final step after [FNN](#id99.99.id99) training is to test the trained [FNN](#id99.99.id99)
    on new data in order to evaluate its performance. An elaborate comprehensive analysis
    of [FNN](#id99.99.id99) different principles is presented in¬†[[42](#bib.bib42)].
  prefs: []
  type: TYPE_NORMAL
- en: III-B LSTM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another well-known [DL](#id96.96.id96) tool is available in the form of [LSTM](#id32.32.id32)
    networks that essentially deal with sequential data where the order of the data
    matters and a correlation exists between the previous and the future data. In
    this context, [LSTM](#id32.32.id32) networks are defined with a special architecture
    capable of learning the data correlation over time, which enables the [LSTM](#id32.32.id32)
    network to predict the future data based on prior observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The [LSTM](#id32.32.id32) unit, as shown in Figure¬†[2](#S3.F2 "Figure 2 ‚Ä£ Forget
    the irrelevant information ‚Ä£ III-B LSTM ‚Ä£ III DL Techniques Overview ‚Ä£ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments"),
    contains computational blocks referred to as gates, which are responsible for
    controlling and tracking the information flow over time. The [LSTM](#id32.32.id32)
    network mechanism can be explicated in four major steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Forget the irrelevant information
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In general, the [LSTM](#id32.32.id32) unit classifies the input data into relevant
    and irrelevant information. The first processing step entails eliminating the
    irrelevant information that is not important for predicting the future. This can
    be undertaken through the forget gate that decides which information the [LSTM](#id32.32.id32)
    unit should retain, and which information can be deleted. The forget gate processing
    is defined as follows
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ${\bm{f}}_{t}=\sigma(\bm{W}_{f,t}\bar{\bm{x}}_{t}+\bm{W}^{\prime}_{f,t}\bar{\bm{z}}_{t-1}+\bar{\bm{b}}_{f,t}),$
    |  | (16) |'
  prefs: []
  type: TYPE_TB
- en: where $\bar{\sigma}$ denotes the sigmoid function, $\bm{W}_{f,t}\in\mathbb{R}^{P\times
    K_{in}}$, $\bm{W}^{\prime}_{f,t}\in\mathbb{R}^{P\times P}$ and $\bar{\bm{b}}_{f,t}\in\mathbb{R}^{P\times
    1}$ are the forget gate weights and biases at time $t$, $\bar{\bm{x}}_{t}\in\mathbb{R}^{K_{in}\times
    1}$ and $\bar{\bm{z}}_{t-1}$ represents the [LSTM](#id32.32.id32) unit input vector
    of size $K_{in}$, and the previous hidden state of size $P$, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/311f67cc6507569e8cd3dcacbeb62d1c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: LSTM unit architecture¬†[[43](#bib.bib43)].'
  prefs: []
  type: TYPE_NORMAL
- en: Store the relevant new information
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: After classifying the relevant information, the [LSTM](#id32.32.id32) unit applies
    some computations on the selected information via the input gate
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ${\bar{\bm{i}}_{t}}=\sigma(\bm{W}_{\bar{\bm{i}},t}\bar{\bm{x}}_{t}+\bm{W}^{\prime}_{\bar{\bm{i}},t}\bar{\bm{z}}_{t-1}+\bar{\bm{b}}_{\bar{\bm{i}},t}),$
    |  | (17) |'
  prefs: []
  type: TYPE_TB
- en: '|  | ${\tilde{{\bm{c}}}}_{t}=\text{tanh}(\bm{W}_{{\tilde{{\bm{c}}}},t}\bar{\bm{x}}_{t}+\bm{W}^{\prime}_{{\tilde{{\bm{c}}}},t}\bar{\bm{z}}_{t-1}+\bar{\bm{b}}_{{\tilde{{\bm{c}}}},t}).$
    |  | (18) |'
  prefs: []
  type: TYPE_TB
- en: Update the new cell state
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Next the [LSTM](#id32.32.id32) unit is supposed to update the current cell state
    ${{{\bm{c}}}}_{t}$ based on the two previously-mentioned steps such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ${{{\bm{c}}}}_{t}={\bm{f}}_{t}\odot{\bm{c}}_{t-1}+\bar{\bm{i}}_{t}\odot{\tilde{{\bm{c}}}}_{t}.$
    |  | (19) |'
  prefs: []
  type: TYPE_TB
- en: where $\odot$ denotes the Hadamard product.
  prefs: []
  type: TYPE_NORMAL
- en: Generate the LSTM unit output
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Updating the hidden state and generating the output by the output gate is the
    final processing step. The output is considered to be a cell state filtered version
    and can be computed such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ${\bm{o}}_{t}=\sigma(\bm{W}_{o,t}\bar{\bm{x}}_{t}+\bm{W}^{\prime}_{o,t}\bar{\bm{z}}_{t-1}+\bar{\bm{b}}_{o,t}),$
    |  | (20) |'
  prefs: []
  type: TYPE_TB
- en: '|  | ${\bar{{\bm{z}}}}_{t}={\bm{o}}_{t}\odot\text{tanh}({\bm{c}}_{t}).$ |  |
    (21) |'
  prefs: []
  type: TYPE_TB
- en: In literature, there exists several [LSTM](#id32.32.id32) architecture variants,
    where the interactions between the [LSTM](#id32.32.id32) unit gates are modified.
    The authors in¬†[[44](#bib.bib44)] provide a detailed comparison of popular [LSTM](#id32.32.id32)
    architecture variants.
  prefs: []
  type: TYPE_NORMAL
- en: III-C CNN
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another type of deep learning is [CNN](#id28.28.id28) model. This is commonly
    used for processing data with grid patterns, such as images¬†[[45](#bib.bib45)].
    Thus, [CNN](#id28.28.id28) has generally become the state of the art for several
    visual applications such as image classification, due to its demonstrated ability
    to extract patterns from the input image. [CNN](#id28.28.id28) can be seen as
    a set of several layers stacked together to accomplish the requisite task. These
    layers include
  prefs: []
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Input layer: It represents the 2D or 3D input image. For the sake of simplicity,
    let us consider a 2D image input to the $l$ -th [CNN](#id28.28.id28) layer denoted
    by $\bm{X}_{l}\in\mathbb{R}^{h_{l}\times w_{l}}$, where $h_{l}$ and $w_{l}$ denote
    the height and the width of the $\bm{X}_{l}$ input image.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Convolutional layer: refers to a specialized type of linear operation used
    for feature extraction, where predefined filters referred to as kernels scan the
    input matrix to fill the output matrix denoted as feature map, which is shown
    in Figure¬†[3](#S3.F3 "Figure 3 ‚Ä£ 2nd item ‚Ä£ III-C CNN ‚Ä£ III DL Techniques Overview
    ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments").
    We note that different kernels can be considered as different feature extractors.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Two key hyper parameters define the [CNN](#id28.28.id28) convolutional layer,
    namely, the size and number of kernels denoted by $f_{l}$ and $n_{l}$, respectively.
    The typical kernel size is $3\times 3$, but sometimes $5\times 5$ or $7\times
    7$. The number of kernels is arbitrary and determines the depth of output feature
    maps. It is possible to tune these parameters according to the application type.
    Furthermore, the process of training a [CNN](#id28.28.id28) model regarding the
    convolution layer involves identifying the kernels values that work optimally
    for a particular task based on a given training dataset. In the convolution layer,
    the kernels are the only automatically learned parameters during the training
    process. Mathematically speaking, for a given input image $\bm{X}_{l}$ and kernel
    $\bm{K_{l}}\in\mathbb{R}^{f_{l}\times f_{l}\times 1}$, we consider one kernel
    for simplicity, the generated feature map $\bm{Y}_{l}\in\mathbb{R}^{(h_{l}-f+1)\times(w_{l}-f+1)}$
    can be expressed as follows
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\bm{Y}_{l}[x,y]=\sum^{h_{l}}_{i=1}\sum^{w_{l}}_{j=1}\bm{K}_{l}[i,j]\bm{X}_{l}[x+i-1,y+j-1].$
    |  | (22) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '![Refer to caption](img/dced3b69d1ec0b710c6a00f04db0bfa6.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3: CNN convolutional layer example¬†[[46](#bib.bib46)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Activation layer: The outputs of a linear operation such as convolution pass
    through a nonlinear activation function. This activation function introduces non-linear
    processing to the [CNN](#id28.28.id28) architecture given that the input-output
    [CNN](#id28.28.id28) pairs relation could be non-linear. While several non-linear
    activation functions exist such as sigmoid or hyperbolic tangent (tanh) function,
    the most common presently used function is the rectified linear unit (ReLU).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pooling layer: This layer is employed to decrease the number of parameters
    when the images are too large. Pooling operation is also referred to as sub-sampling
    or down-sampling. This reduces the dimensionality of all feature maps but does
    manage to retain significant information. Notably, none of the pooling layers
    contains any learnable parameter. The most popular form of pooling operation is
    max pooling, which extracts patches from the input feature maps, outputs the maximum
    value in each patch, and then discards all the other values. However, there are
    other pooling operations such as global average pooling¬†[[47](#bib.bib47)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e1c27c07d08dad404fdacb5826a68cda.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 4: CNN classical architecture¬†[[46](#bib.bib46)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fully connected layer: This layer forms the last block of the [CNN](#id28.28.id28)
    architecture and is mainly employed in the classification problems. It is a simple
    feed-forward neural network layer that comprises at least one hidden layer; its
    role is to transform the 2D [CNN](#id28.28.id28) layer output into a 1D vector.
    In classification problems, the final outputs of the [CNN](#id28.28.id28) network
    represent the probabilities for each class, where the final fully-connected layer
    typically has the same number of output nodes as the number of classes.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Batch normalization: It is used to increase the [CNN](#id28.28.id28) stability
    of the output by normalizing each layer‚Äôs output. Moreover, batch normalization
    layer reduces overfitting and accelerates the [CNN](#id28.28.id28) training.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Output layer: This layer is configured in accordance with the studied problem.
    For instance, in classification problems the [CNN](#id28.28.id28) output layer
    is a fully connected layer with softmax activation function. On the other hand,
    in regression problems, the [CNN](#id28.28.id28) output does not use any activation
    function.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure¬†[4](#S3.F4 "Figure 4 ‚Ä£ 4th item ‚Ä£ III-C CNN ‚Ä£ III DL Techniques Overview
    ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments")
    illustrates the classical CNN architecture. As seen in this figure, the only trainable
    parameters within the [CNN](#id28.28.id28) network are the kernels and the fully
    connected layer weights. Similar to all other [DL](#id96.96.id96) techniques,
    [CNN](#id28.28.id28) network updates its trainable parameters by minimizing the
    [CNN](#id28.28.id28) loss function that measures how far the inputs are from the
    outputs. Thereafter, the [CNN](#id28.28.id28) kernels and weights are updated
    in the back propagation operation¬†[[48](#bib.bib48)]. Finally, the performance
    of the trained [CNN](#id28.28.id28) model is examined in the testing phase where
    new unobserved images are fed to the trained [CNN](#id28.28.id28) model.
  prefs: []
  type: TYPE_NORMAL
- en: It is noteworthy that there are special [CNN](#id28.28.id28) architectures such
    as [SR-CNN](#id25.25.id25)¬†[[49](#bib.bib49)], [DN-CNN](#id26.26.id26)¬†[[50](#bib.bib50)],
    and [super resolution convolutional long short-term memory](#id39.39.id39) ([SR-ConvLSTM](#id39.39.id39))¬†[[51](#bib.bib51)]
    that are mainly used for regression problems. [SR-CNN](#id25.25.id25) is used
    for enhancing the quality of the input image, where it takes the low-resolution
    image as the input and outputs the high-resolution one. [DN-CNN](#id26.26.id26)
    uses another methodology to improve the image quality by separating the noise
    from the input noisy image employing residual learning¬†[[52](#bib.bib52)]. The
    input noisy image is then subtracted from the extracted noise, resulting in the
    denoised image. Furthermore, [SR-ConvLSTM](#id39.39.id39) combines both [LSTM](#id32.32.id32)
    and [CNN](#id28.28.id28) networks together where time correlation across the whole
    input image is learned, thus leading to a better estimation accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: IV DL-Based SBS Channel Estimation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In [DL](#id96.96.id96)-based [SBS](#id22.22.id22) channel estimation, [FNN](#id99.99.id99)
    and [LSTM](#id32.32.id32) networks are primarily integrated with conventional
    estimation schemes in the following two manners: (i) [FNN](#id99.99.id99) is implemented
    as a post-processing module after conventional [DPA](#id16.16.id16), [spectral
    temporal averaging](#id17.17.id17) ([STA](#id17.17.id17)), and [time domain reliable
    test frequency domain interpolation](#id19.19.id19) ([TRFI](#id19.19.id19)) estimators.
    (ii) [LSTM](#id32.32.id32) network gets implemented as a pre-processing unit before
    conventional [DPA](#id16.16.id16) estimation to minimize the DPA demapping error
    iteratively. Both implementations are helpful in improving the channel estimation‚Äôs
    accuracy, particularly in high mobility scenarios. However, the LSTM-based estimation
    illustrates a considerable superiority over the [FNN](#id99.99.id99)-based estimation
    as demonstrated in Section¬†[VI](#S6 "VI Simulation Results ‚Ä£ A Survey on Deep
    Learning based Channel Estimation in Doubly Dispersive Environments"). Hereafter,
    the steps applied in each DL-based [SBS](#id22.22.id22) estimator are presented.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-A DPA-FNN
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9a96b855bd5e20a2f1d345bf66d5db4e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The block diagram of the studied DNN-based SBS estimators.'
  prefs: []
  type: TYPE_NORMAL
- en: The [DPA](#id16.16.id16) estimation¬†[[13](#bib.bib13)] utilizes the demapped
    data subcarriers of the previously received [OFDM](#id208.208.id208) symbol for
    estimating the channel for the existing [OFDM](#id208.208.id208) symbol such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\tilde{\bm{d}}_{i}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i}[k]}{\hat{\tilde{\bm{h}}}_{\text{DPA}_{i-1}}[k]}\big{)},\leavevmode\nobreak\
    \hat{\tilde{\bm{h}}}_{\text{DPA}_{0}}[k]=\hat{\tilde{\bm{h}}}_{\text{LS}}[k],$
    |  | (23) |'
  prefs: []
  type: TYPE_TB
- en: where $\mathfrak{D}(.)$ refers to the demapping operation to the nearest constellation
    point in accordance with the employed modulation order. $\hat{\tilde{\bm{h}}}_{\text{LS}}$
    signifies the LS estimated channel at the received preambles, such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{LS}}[k]=\frac{\sum\limits_{u=1}^{P}\tilde{\bm{y}}^{(p)}_{u}[k]}{P\tilde{\bm{\Lambda}}[k]},\leavevmode\nobreak\
    k\in{\mathcal{K}}_{\text{on}},$ |  | (24) |'
  prefs: []
  type: TYPE_TB
- en: where $\tilde{\bm{\Lambda}}$ denotes the frequency domain predefined preamble
    sequence. Thereafter, the final [DPA](#id16.16.id16) channel estimates are updated
    in the following manner
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]=\frac{\tilde{\bm{y}}_{i}[k]}{\tilde{\bm{d}}_{i}[k]}.$
    |  | (25) |'
  prefs: []
  type: TYPE_TB
- en: '[DPA](#id16.16.id16) estimation suffers from two main limitations. First, it
    is based on the basic $\hat{\tilde{\bm{h}}}_{\text{LS}}$ estimation suffering
    from noise enhancement. Second, the demapping step in [DPA](#id16.16.id16) leads
    to a significant demapping error primarily in low [signal-to-noise ratio](#id263.263.id263)
    ([SNR](#id263.263.id263)) region stemming from the noise imperfections and doubly-dispersive
    channel variations. This demapping error is enlarged in high mobility scenarios
    employing high modulation orders. In addition, since the [DPA](#id16.16.id16)
    estimated channels are updated iteratively over the received frame, the demapping
    error propagates via the frame that results in a significant degradation in performance.
    In order to address these limitations, the DPA-[FNN](#id99.99.id99) scheme¬†[[27](#bib.bib27)]
    has been proposed to compensate the [DPA](#id16.16.id16) estimation error, where
    $\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]$ is fed to a three-hidden-layers [FNN](#id99.99.id99)
    with $40-20-40$ neurons, as shown in Figure¬†[5](#S4.F5 "Figure 5 ‚Ä£ IV-A DPA-FNN
    ‚Ä£ IV DL-Based SBS Channel Estimation ‚Ä£ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments"). Using the [FNN](#id99.99.id99)
    in addition to the [DPA](#id16.16.id16) scheme yields good performance but it
    is not sufficient, because it ignores the time and frequency correlation between
    successive received [OFDM](#id208.208.id208) symbols. Also, the employed [FNN](#id99.99.id99)
    architecture can be optimized to reduce the computational complexity of channel
    estimation.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-B STA-FNN
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To improve the conventional [DPA](#id16.16.id16) estimation, the [STA](#id17.17.id17)
    estimator¬†[[13](#bib.bib13)] has been proposed where frequency and time-domain
    averaging are applied on top of the [DPA](#id16.16.id16) estimated channel as
    follows
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{FD}_{i}}[k]=\sum_{\lambda=-\beta}^{\lambda=\beta}\omega_{\lambda}\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k+\lambda],\leavevmode\nobreak\
    \omega_{\lambda}=\frac{1}{2\beta+1}.$ |  | (26) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{STA}_{i}}[k]=(1-\frac{1}{\alpha})\hat{\tilde{\bm{h}}}_{\text{STA}_{i-1}}[k]+\frac{1}{\alpha}\hat{\tilde{\bm{h}}}_{\text{FD}_{i}}[k].$
    |  | (27) |'
  prefs: []
  type: TYPE_TB
- en: '[STA](#id17.17.id17) estimator performs well in the low [SNR](#id263.263.id263)
    region. However, it suffers from a considerable error floor in high [SNR](#id263.263.id263)
    regions due to the large [DPA](#id16.16.id16) demapping error. Importantly, in¬†[[13](#bib.bib13)],
    the values of the frequency and time averaging coefficients are fixed to $\alpha=\beta=2$.
    Thus, the final STA estimated channel is a linear combination between the previously
    estimated channel¬†([27](#S4.E27 "In IV-B STA-FNN ‚Ä£ IV DL-Based SBS Channel Estimation
    ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments"))
    and the frequency averaged channel estimates¬†([26](#S4.E26 "In IV-B STA-FNN ‚Ä£
    IV DL-Based SBS Channel Estimation ‚Ä£ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments")). However, this linear combination leads to
    a significant performance degradation in real case scenarios due to the doubly-dispersive
    channel non-linear imperfections. Here, [FNN](#id99.99.id99) is utilized as a
    post non-linear processing unit after the conventional [STA](#id17.17.id17) scheme¬†[[28](#bib.bib28)].
    STA-FNN captures more the time-frequency correlations of the channel samples,
    apart from correcting the conventional [STA](#id17.17.id17) estimation error.
    Furthermore, the optimized STA-FNN architecture performs better than the DPA-FNN
    with a significant computational complexity decrease, as elucidated in Section¬†[VII](#S7
    "VII Complexity Analysis ‚Ä£ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments").'
  prefs: []
  type: TYPE_NORMAL
- en: IV-C TRFI-FNN
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[TRFI](#id19.19.id19) estimation scheme¬†[[15](#bib.bib15)] is another methodology
    used for improving the [DPA](#id16.16.id16) estimation in¬†([25](#S4.E25 "In IV-A
    DPA-FNN ‚Ä£ IV DL-Based SBS Channel Estimation ‚Ä£ A Survey on Deep Learning based
    Channel Estimation in Doubly Dispersive Environments")). Assuming that the time
    correlation of the channel response between two adjacent [OFDM](#id208.208.id208)
    symbols is high, [TRFI](#id19.19.id19) define two sets of subcarriers such that:
    (i) ${\mathcal{RS}}_{i}$ set: that includes the reliable subcarriers indices,
    and (ii) ${\mathcal{URS}}_{i}$ set: which contains the unreliable subcarriers
    indices. The estimated channels for the ${\mathcal{URS}}_{i}$ are then interpolated
    using the ${\mathcal{RS}}_{i}$ channel estimates by means of the frequency-domain
    cubic interpolation. This procedure can be expressed in the following manner'
  prefs: []
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Equalize the previously received [OFDM](#id208.208.id208) symbol by ${\hat{\tilde{\bm{h}}}_{\text{TRFI}_{i-1}}[k]}$
    and ${\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]}$, such that
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\begin{split}{\tilde{\bm{d}}^{\prime}}_{i-1}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i-1}[k]}{\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]}\big{)},\leavevmode\nobreak\
    {\tilde{\bm{d}}^{\prime\prime}}_{i-1}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i-1}[k]}{\hat{\tilde{\bm{h}}}_{\text{TRFI}_{i-1}}[k]}\big{)}.\end{split}$
    |  | (28) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: According to the demapping results, the subcarriers are grouped as follows
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\left\{\begin{array}[]{ll}{\mathcal{RS}}_{i}\leftarrow{\mathcal{RS}}_{i}+{k},&amp;\quad\tilde{\bm{d^{\prime}}}_{i-1}[k]=\tilde{\bm{d}}^{\prime\prime}_{i-1}[k]\\
    {\mathcal{URS}}_{i}\leftarrow{\mathcal{URS}}_{i}+{k},&amp;\quad\tilde{\bm{d^{\prime}}}_{i-1}[k]\neq\tilde{\bm{d}}^{\prime\prime}_{i-1}[k]\end{array}\right..$
    |  | (29) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, frequency-domain cubic interpolation is employed to estimate the channels
    at the ${\mathcal{URS}}_{i}$ as follows
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{TRFI}_{i}}[k]=\left\{\begin{array}[]{ll}\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k],&amp;\quad
    k\in{\mathcal{RS}}_{i}\\ \text{Cubic Interpolation},&amp;\quad k\in{\mathcal{URS}}_{i}\end{array}\right..$
    |  | (30) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: Performing frequency-domain interpolation in addition to the [DPA](#id16.16.id16)
    estimation enhances the performance. However, [TRFI](#id19.19.id19) still suffers
    from the demapping and interpolation errors as the number of [reliable subcarriers](#id40.40.id40)
    ([RS](#id40.40.id40)) subcarriers is inversely proportional to the channel variations.
    Additionally, the condition where ${\tilde{\bm{d}}^{\prime}}_{i-1}[k]\neq{\tilde{\bm{d}}^{\prime\prime}}_{i-1}[k]$
    is more dominant in high mobility scenarios. It is for this reason that only a
    few [RS](#id40.40.id40) subcarriers will be selected and the employed cubic interpolation
    performance will be degraded.
  prefs: []
  type: TYPE_NORMAL
- en: Inspired by the work undertaken in [STA](#id17.17.id17)-[FNN](#id99.99.id99),
    the authors in¬†[[29](#bib.bib29)] used the same optimized [FNN](#id99.99.id99)
    architecture as in¬†[[28](#bib.bib28)], albeit with $\hat{\tilde{\bm{h}}}_{\text{TRFI}_{i}}[k]$
    as an input instead of $\hat{\tilde{\bm{h}}}_{\text{STA}_{i}}[k]$. [TRFI](#id19.19.id19)-[FNN](#id99.99.id99)
    corrects the cubic interpolation error and also learns the channel frequency domain
    correlation, thus leading to an improved performance in high [SNR](#id263.263.id263)
    regions.
  prefs: []
  type: TYPE_NORMAL
- en: IV-D LSTM-FNN-DPA
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unlike the [FNN](#id99.99.id99)-based estimators, where the [DL](#id96.96.id96)
    processing is employed following the conventional estimators, the work carried
    out in¬†[[53](#bib.bib53)] shows that employing the [DL](#id96.96.id96) processing
    prior to the conventional estimator, specifically the [DPA](#id16.16.id16) estimation,
    could lead to a significant improvement in the overall performance. In this context,
    the authors have proposed to use two cascaded [LSTM](#id32.32.id32) and [FNN](#id99.99.id99)
    networks for both channel estimation as well as noise compensation, as shown in
    Figure¬†[6](#S4.F6 "Figure 6 ‚Ä£ IV-D LSTM-FNN-DPA ‚Ä£ IV DL-Based SBS Channel Estimation
    ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments").
  prefs: []
  type: TYPE_NORMAL
- en: The LSTM-FNN-DPA estimator employs the previous and current pilot subcarriers
    besides the [LSTM](#id32.32.id32)-[FNN](#id99.99.id99) estimated channel employed
    in the [DPA](#id16.16.id16) estimation, such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\tilde{\bm{d}}_{\text{LSTM-FNN}_{i,d}}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i,d}[k]}{\hat{\tilde{\bm{h}}}_{\text{LSTM-FNN}_{i-1,d}}[k]}\big{)},\leavevmode\nobreak\
    \hat{\tilde{\bm{h}}}_{\text{LSTM}_{0}}[k]=\hat{\tilde{\bm{h}}}_{\text{LS}}[k],$
    |  | (31) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{DL}_{i,d}}[k]=\frac{\tilde{\bm{y}}_{i,d}[k]}{\bm{d}_{\text{LSTM}_{i,d}}[k]}.$
    |  | (32) |'
  prefs: []
  type: TYPE_TB
- en: While this estimator can outperform the [FNN](#id99.99.id99)-based estimators,
    it experiences a considerable computational complexity arising from the employment
    of two [DL](#id96.96.id96) networks.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9f576091e0d4e2c4e4b895ff12474f53.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: The block diagram of the studied LSTM-based SBS estimators.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-E LSTM-DPA-TA
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The authors in¬†[[43](#bib.bib43)] propose to use only LSTM network instead of
    two as implemented in the LSTM-FNN-DPA estimator. In addition, noise compensation
    is made possible by applying [time averaging](#id46.46.id46) ([TA](#id46.46.id46))
    processing as shown in Figure¬†[6](#S4.F6 "Figure 6 ‚Ä£ IV-D LSTM-FNN-DPA ‚Ä£ IV DL-Based
    SBS Channel Estimation ‚Ä£ A Survey on Deep Learning based Channel Estimation in
    Doubly Dispersive Environments"). This methodology only requires the previous
    pilots besides the LSTM estimated channel as an input. Then, the LSTM estimated
    channel is employed in the DPA estimation as follows
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\tilde{\bm{d}}_{\text{LSTM}_{i}}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i}[k]}{\hat{\tilde{\bm{h}}}_{\text{LSTM}_{i-1}}[k]}\big{)},\leavevmode\nobreak\
    \hat{\tilde{\bm{h}}}_{\text{LSTM}_{0}}[k]=\hat{\tilde{\bm{h}}}_{\text{LS}}[k],$
    |  | (33) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{LSTM-DPA}_{i}}[k]=\frac{\tilde{\bm{y}}_{i}[k]}{\tilde{\bm{d}}_{\text{LSTM}_{i}}[k]}.$
    |  | (34) |'
  prefs: []
  type: TYPE_TB
- en: Finally, to alleviate the impact of the AWGN noise, [TA](#id46.46.id46) processing
    is applied to the $\hat{\tilde{\bm{h}}}_{\text{LSTM-DPA}_{i}}[k]$ estimated channel,
    such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\bar{\bm{h}}}_{\text{DL-TA}_{i,d}}=(1-\frac{1}{\alpha})\hat{\bar{\bm{h}}}_{\text{DL-TA}_{i-1,d}}+\frac{1}{\alpha}\hat{\bar{\bm{h}}}_{\text{LSTM-DPA}_{i,d}}.$
    |  | (35) |'
  prefs: []
  type: TYPE_TB
- en: Here, $\alpha$ denotes the utilized weighting coefficient. In¬†[[43](#bib.bib43)],
    the authors use a fixed $\alpha=2$ for simplicity. Therefore, the [TA](#id46.46.id46)
    applied in¬†([35](#S4.E35 "In IV-E LSTM-DPA-TA ‚Ä£ IV DL-Based SBS Channel Estimation
    ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments"))
    reduces the AWGN noise power $\sigma^{2}$ iteratively within the received [OFDM](#id208.208.id208)
    frame according to the ratio
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}{R}_{\text{DL-TA}_{q}}&amp;=\left(\frac{1}{4}\right)^{(q-1)}+\sum_{j=2}^{q}\left(\frac{1}{4}\right)^{(q-j+1)}=\frac{4^{q-1}+2}{3\times
    4^{q-1}}.\end{split}$ |  | (36) |'
  prefs: []
  type: TYPE_TB
- en: This corresponds to the AWGN noise power ratio of the estimated channel at the
    $q$-th estimated channel, where ${1<q<I+1}$ and ${{R}_{\text{DL-TA}_{1}}=1}$ denotes
    the AWGN noise power ratio at $\hat{\tilde{\bm{h}}}_{\text{LS}}[k]$. From the
    derivation of ${R}_{\text{DL-TA}_{q}}$, it can be seen that the noise power decreases
    over the received [OFDM](#id208.208.id208) frame, i.e., the SNR increases, resulting
    in an overall improved performance. Moreover, the input dimension reduction, coupled
    with the simple [TA](#id46.46.id46) processing, significantly lowers the overall
    computational complexity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table I: Parameters of the studied DL-based SBS channel estimators.'
  prefs: []
  type: TYPE_NORMAL
- en: '| DPA-[FNN](#id99.99.id99) (Hidden layers; Neurons per layer) | (3;40-20-40)
    |'
  prefs: []
  type: TYPE_TB
- en: '| STA-[FNN](#id99.99.id99) (Hidden layers; Neurons per layer) | (3;15-15-15)
    |'
  prefs: []
  type: TYPE_TB
- en: '| TRFI-[FNN](#id99.99.id99) (Hidden layers; Neurons per layer) | (3;15-15-15)
    |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM (Hidden layers; Neurons per layer) | (1;128) |'
  prefs: []
  type: TYPE_TB
- en: '| Activation function | ReLU |'
  prefs: []
  type: TYPE_TB
- en: '| Number of epochs | 500 |'
  prefs: []
  type: TYPE_TB
- en: '| Training samples | 800000 |'
  prefs: []
  type: TYPE_TB
- en: '| Testing samples | 200000 |'
  prefs: []
  type: TYPE_TB
- en: '| Batch size | 128 |'
  prefs: []
  type: TYPE_TB
- en: '| Optimizer | ADAM |'
  prefs: []
  type: TYPE_TB
- en: '| Loss function | MSE |'
  prefs: []
  type: TYPE_TB
- en: '| Learning rate | 0.001 |'
  prefs: []
  type: TYPE_TB
- en: '| Training SNR | 40 dB |'
  prefs: []
  type: TYPE_TB
- en: Intensive experiments reveal that the performance of DL networks is strongly
    related to the SNR considered in the training¬†[[54](#bib.bib54)]. The training
    undertaken at the highest SNR value provides the best performance. In fact, the
    DL network is able to learn better the channel when the training is performed
    at a high SNR value because the impact of the channel is higher than the impact
    of the noise in this SNR range. Owing to the robust generalization properties
    of DL, trained networks can still estimate the channel even if the noise increases,
    i.e., at low SNR values. Therefore, [FNN](#id99.99.id99) and LSTM based estimators
    training is performed using [SNR](#id263.263.id263) = $40$ dB to attain the best
    performance. Moreover, intensive experiments are performed using the grid search
    algorithm¬†[[55](#bib.bib55)] to select the most suitable [FNN](#id99.99.id99)
    and LSTM hyper parameters in terms of performance as well as complexity. Figures¬†[5](#S4.F5
    "Figure 5 ‚Ä£ IV-A DPA-FNN ‚Ä£ IV DL-Based SBS Channel Estimation ‚Ä£ A Survey on Deep
    Learning based Channel Estimation in Doubly Dispersive Environments") and¬†[6](#S4.F6
    "Figure 6 ‚Ä£ IV-D LSTM-FNN-DPA ‚Ä£ IV DL-Based SBS Channel Estimation ‚Ä£ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")
    illustrate the block diagram of the [FNN](#id99.99.id99) and LSTM based estimators.
    Furthermore, Table¬†[I](#S4.T1 "Table I ‚Ä£ IV-E LSTM-DPA-TA ‚Ä£ IV DL-Based SBS Channel
    Estimation ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments") presents their parameters.
  prefs: []
  type: TYPE_NORMAL
- en: V DL-Based FBF Channel Estimation Schemes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section presents the [DL](#id96.96.id96)-based [FBF](#id23.23.id23) estimators
    introduced to improve the channel estimation accuracy, particularly in very high
    mobility scenarios, where the channel variation is found to be severe. Similar
    to the [DL](#id96.96.id96)-based [SBS](#id22.22.id22) estimators, the [DL](#id96.96.id96)-based
    [FBF](#id23.23.id23) estimators apply first conventional estimation followed by
    means of [CNN](#id28.28.id28) processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table II: Main characteristics and features of the studied DL-based channel
    estimators.'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Estimator &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; type &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Estimator &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; reference &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Conventional &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; estimation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; DL-based &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Method &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Complexity |'
  prefs: []
  type: TYPE_TB
- en: '&#124; BER &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Performance &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Robustness | Pros and Cons |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| SBS | [[27](#bib.bib27)] | DPA | FNN | ++ | ++ | ++ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; + Significant performance &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; superiority over &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; conventional estimators. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; - Ignore the time and &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; frequency correlation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; between successive &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; received OFDM symbols. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; - Complex FNN architecture &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; to compensate the &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; conventional DPA &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; demapping error. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| [[28](#bib.bib28)] | STA | + | +++ | ++ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; + STA averaging ameliorate the &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; impact of the AWGN noise &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; in low SNR regions. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; + Optimized FNN architecture. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; - Fixed averaging coefficients. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; - Performance degradation in &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; high mobility scenarios. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| [[29](#bib.bib29)] | TRFI | + | ++++ | +++ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; + Cubic Interpolation enhances &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; the performance in the entire &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; SNR region. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; + Optimized FNN architecture. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; - Assume high correlation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; between successive OFDM &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; symbols. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; - Lack of robustness in very &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; high mobiliy scenarios. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| [[53](#bib.bib53)] | DPA | LSTM and FNN | +++ | ++++ | ++++ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; + Outperform FNN-based &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; estimators. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; + Improved estimation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; since LSTM is implemented &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; before DPA estimation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; - Employ LSTM and &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; FNN in the same architecture. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| [[43](#bib.bib43)] | DPA and TA | LSTM | +++ | ++++ | ++++ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; + TA processing results in &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; a considerable decline in &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; the AWGN noise. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; + Employ only one &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; optimized LSTM unit. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; + Reduced input dimension. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| FBF | [[30](#bib.bib30)] | 2D RBF |'
  prefs: []
  type: TYPE_TB
- en: '&#124; SR-CNN and &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; DN-CNN &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| +++++ | ++ | ++ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; - 2D RBF interpolation high &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; computational complexity. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; - The 2D RBF function &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; and scale factor should be &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; optimized in accordance with &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; the channel variations. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; - Employ two high-complexity &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; CNN architectures. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| [[31](#bib.bib31)] | ADD-TT | SR-ConvLSTM | +++++ | +++ | +++ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; + Outperform ChannelNet &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; estimator [29]. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; - Fixed ADD-TT Averaging &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; coefficients. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; - High computational complexity &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; owing to the integration of both &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; LSTM and CNN architectures. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| [[32](#bib.bib32)] | WI |'
  prefs: []
  type: TYPE_TB
- en: '&#124; SR-CNN or &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; DN-CNN &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| +++ | ++++ | ++++ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; + Adaptive frame structure &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; according to the mobility &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; condition. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; + Reduced buffering time &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; at the receiver. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; + Transmission data rate gain. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; + Optimized CNN &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; architectures. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: V-A ChannelNet
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In¬†[[30](#bib.bib30)], the authors use forward a [CNN](#id28.28.id28)-based
    channel estimator denoted as [channel network](#id35.35.id35) ([ChannelNet](#id35.35.id35))
    scheme, where 2D [radial basis function](#id27.27.id27) ([RBF](#id27.27.id27))
    interpolation is implemented as an initial channel estimation. The underlying
    motivation of the 2D [RBF](#id27.27.id27) interpolation is to approximate multidimensional
    scattered unknown data from their surrounding neighbors known data by employing
    the radial basis function. In order to achieve the purpose, the distance function
    is calculated between every data point to be interpolated and its neighbours,
    where closer neighbors are assigned higher weights. Thereby, the [RBF](#id27.27.id27)
    interpolated frame is considered a low resolution image, where [SR-CNN](#id25.25.id25)
    is utilized to obtain an improved estimation. Finally, to ameliorate the effect
    of noise within the high resolution estimated frame, [DN-CNN](#id26.26.id26) is
    implemented leading to a high resolution and noise alleviated estimated channels.
    The ChannelNet estimator considers sparsely allocated pilots within the IEEE 802.11p
    frame and initially applies the [LS](#id172.172.id172) estimation to the pilot
    subcarriers within the received [OFDM](#id208.208.id208) frame. Subsequently,
    the 2D [RBF](#id27.27.id27) interpolation is derived by the weighted summation
    of the distance between each data subcarrier to be interpolated as well as all
    the pilot subcarriers in the received [OFDM](#id208.208.id208) frame, such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{H}}}_{\text{RBF}}[k,i]=\sum_{j=1}^{{K_{{p}}}I}\omega_{j}\Phi(&#124;k-{\mathcal{K}}_{f}[j]&#124;,&#124;i-{\mathcal{K}}_{t}[j]&#124;).$
    |  | (37) |'
  prefs: []
  type: TYPE_TB
- en: ${\mathcal{K}}_{f}=[{{\mathcal{K}}}_{\text{p}_{1}},\dots,{{\mathcal{K}}}_{\text{p}_{I}}]\in\mathbb{R}^{1\times
    K_{p}I}$ and ${\mathcal{K}}_{t}=[(1)_{\times K_{p}},\dots,(I)_{\times K_{p}}]\in\mathbb{R}^{1\times
    K_{p}I}$ represent the frequency and time indices vectors of the allocated pilot
    subcarriers within the received [OFDM](#id208.208.id208) frame, respectively.
    $\omega_{j}$ is the [RBF](#id27.27.id27) weight multiplied by the [RBF](#id27.27.id27)
    interpolation function $\Phi(.)$ between the $(k,i)$ data subcarrier and the $({\mathcal{K}}_{f}[j],{\mathcal{K}}_{t}[j])$
    pilot subcarrier. In¬†[[30](#bib.bib30)], the [RBF](#id27.27.id27) gaussian function
    is applied, such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\Phi(x,y)=e^{-\frac{(x+y)^{2}}{r_{0}}}.$ |  | (38) |'
  prefs: []
  type: TYPE_TB
- en: '$r_{0}$ refers to the 2D [RBF](#id27.27.id27) scale factor that varies based
    on the used [RBF](#id27.27.id27) function. Notably, altering the value of $r_{0}$
    alters the shape of the interpolation function. Moreover, the [RBF](#id27.27.id27)
    weights $\bm{w}_{\text{RBF}}=[\omega_{1},\dots,\omega_{K_{p}I}]\in\mathbb{R}^{K_{p}I\times
    1}$ are calculated using the following relation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\bm{A}_{\text{RBF}}\bm{w}_{\text{RBF}}=\bar{{\bm{h}}}_{\text{LS}}.$ |  |
    (39) |'
  prefs: []
  type: TYPE_TB
- en: Here, $\bm{A}_{\text{RBF}}\in\mathbb{R}^{{K_{{p}}}I\times{K_{{p}}}I}$ is the
    [RBF](#id27.27.id27) interpolation matrix of the pilots subcarriers, with entries
    $a_{i,j}=\Phi({\mathcal{K}}_{f}[i],{\mathcal{K}}_{t}[j])$ where $i,j=1,\dots,K_{p}I$.
    It is observed that, $\bar{{\bm{h}}}_{\text{LS}}=\mathrm{vec}\left\{\hat{\tilde{\bm{H}}}_{\text{LS}}\right\}\in\mathbb{C}^{K_{p}I\times
    1}$ is a vector that contains the [LS](#id172.172.id172) estimated channels at
    all the pilot subcarriers within the received [OFDM](#id208.208.id208) frame.
    This is expressed as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{H}}}_{\text{LS}}[k,i]=\frac{\tilde{\bm{Y}}[k,i]}{\tilde{\bm{P}}[k,i]},\leavevmode\nobreak\
    k\in{{\mathcal{K}}}_{\text{p}},\leavevmode\nobreak\ 1\leq i\leq I,$ |  | (40)
    |'
  prefs: []
  type: TYPE_TB
- en: with $\tilde{\bm{P}}[k,i]$ is the frequency-domain pre-defined pilot subcarriers,
    and ${{\mathcal{K}}}_{\text{p}}$ refers to the allocated sparse pilots indices
    within the received [OFDM](#id208.208.id208) symbol. After computing $\bm{W}_{\text{RBF}}$,
    it is possible to calculate the [RBF](#id27.27.id27) estimated channel for every
    data subcarriers within the received [OFDM](#id208.208.id208) frame, as shown
    in¬†([37](#S5.E37 "In V-A ChannelNet ‚Ä£ V DL-Based FBF Channel Estimation Schemes
    ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments")).
    Finally, the [RBF](#id27.27.id27) interpolation estimated frame $\hat{\tilde{\bm{H}}}_{\text{RBF}}$
    is fed as an input to [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26) to improve
    the channel estimation accuracy and reduce the noise impact.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ChannelNet estimator limitations lie in: (i) 2D [RBF](#id27.27.id27) interpolation
    high computational complexity arising from the computation of¬†([39](#S5.E39 "In
    V-A ChannelNet ‚Ä£ V DL-Based FBF Channel Estimation Schemes ‚Ä£ A Survey on Deep
    Learning based Channel Estimation in Doubly Dispersive Environments")) for the
    channel estimation of all data subcarriers. (ii) The 2D [RBF](#id27.27.id27) function
    and scale factor needs to be optimized in accordance with the channel variations.
    (iii) The integrated [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26) architectures
    have significant computational complexity. Notably, the ChannelNet estimator uses
    a fixed [RBF](#id27.27.id27) function and scale factor, thus experiencing a considerable
    degradation in performance, particularly in low [SNR](#id263.263.id263) regions,
    where the noise impact remains dominant, as well as high mobility vehicular scenarios,
    where the channel varies swiftly within the [OFDM](#id208.208.id208) frame.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table III: Parameters of the studied DL-based FBF channel estimators.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Parameter | Values |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Input/Output dimensions | $2K_{\text{on}}\times I\times 1$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| SR-CNN (Hidden layers - $n_{l},f_{l}$) | (3 - 9,64;¬†1,32;¬† 5,1) |'
  prefs: []
  type: TYPE_TB
- en: '| DN-CNN (Hidden layers - $n_{l},f_{l}$) | (18 - 64,¬†3) |'
  prefs: []
  type: TYPE_TB
- en: '| Optimized SR-CNN (Hidden layers - $n_{l},f_{l}$) | (3 - 9,32;¬†1,16;¬† 5,1)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Optimized DN-CNN (Hidden layers - $n_{l},f_{l}$) | (7 - 16,¬†3) |'
  prefs: []
  type: TYPE_TB
- en: '| SR-ConvLSTM (Hidden layers - $n_{l},f_{l}$) | (3 - 9,64;¬†1,32;¬† 5,1) |'
  prefs: []
  type: TYPE_TB
- en: '| Activation function | ReLU |'
  prefs: []
  type: TYPE_TB
- en: '| Number of epochs | 250 |'
  prefs: []
  type: TYPE_TB
- en: '| Training samples | 8000 |'
  prefs: []
  type: TYPE_TB
- en: '| Testing samples | 2000 |'
  prefs: []
  type: TYPE_TB
- en: '| Batch size | 128 |'
  prefs: []
  type: TYPE_TB
- en: '| Optimizer | ADAM |'
  prefs: []
  type: TYPE_TB
- en: '| Loss function | MSE |'
  prefs: []
  type: TYPE_TB
- en: '| Learning rate | 0.001 |'
  prefs: []
  type: TYPE_TB
- en: '| Training SNR | 40 dB |'
  prefs: []
  type: TYPE_TB
- en: V-B TS-ChannelNet
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Temporal spectral ChannelNet](#id29.29.id29) ([TS-ChannelNet](#id29.29.id29))¬†[[31](#bib.bib31)]
    is based on applying [average decision-directed with time truncation](#id36.36.id36)
    ([ADD-TT](#id36.36.id36)) interpolation to the received [OFDM](#id208.208.id208)
    frame. Thereafter, accurate estimation is achieved by implementing [SR-ConvLSTM](#id39.39.id39)
    network to track doubly-dispersive channel variations by learning the vehicular
    channel‚Äôs time and frequency correlations. It is observed that the [ADD-TT](#id36.36.id36)
    interpolation is an [SBS](#id22.22.id22) estimator, where [DPA](#id16.16.id16)
    estimation is initially applied as explained in¬†([23](#S4.E23 "In IV-A DPA-FNN
    ‚Ä£ IV DL-Based SBS Channel Estimation ‚Ä£ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments")) and¬†([25](#S4.E25 "In IV-A DPA-FNN
    ‚Ä£ IV DL-Based SBS Channel Estimation ‚Ä£ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments")). Thereafter, the enlarged [DPA](#id16.16.id16)
    demapping error is reduced by applying time domain truncation in the following
    manner'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{{\bm{h}}}_{\text{DPA}_{i}}={\bm{F}}_{\text{K}}^{\text{H}}\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}},$
    |  | (41) |'
  prefs: []
  type: TYPE_TB
- en: where ${\bm{F}}_{K}\in\mathbb{C}^{K\times K}$ denotes the $K$-DFT matrix, and
    $\hat{{\bm{h}}}_{\text{DPA}_{i}}$ represents the time-domain [DPA](#id16.16.id16)
    estimated channel. Thereafter, $\hat{{\bm{h}}}_{\text{DPA}_{i}}$ truncation is
    applied to the significant $L$ channel taps, such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{{\bm{h}}}_{\text{DPA}_{i,L}}=\hat{{\bm{h}}}_{\text{DPA}_{i}}(1\mathrel{\mathop{\mathchar
    58\relax}}L).$ |  | (42) |'
  prefs: []
  type: TYPE_TB
- en: Next, $\hat{{\bm{h}}}_{\text{DPA}_{i,L}}$ is converted back to the frequency
    domain such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{TT}_{i}}={\bm{F}}_{\text{K}}\hat{{\bm{h}}}_{\text{DPA}_{i,L}},$
    |  | (43) |'
  prefs: []
  type: TYPE_TB
- en: Implementing the average time truncation operation to $\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]$
    lowers the effect of noise and enlarged demapping error. Moreover, $\hat{\tilde{\bm{h}}}_{\text{TT}_{i}}[k]$
    estimated channel is further enhanced by applying frequency and time-domain averaging
    consecutively as follows
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{FTT}_{i}}[k]=\sum_{\lambda=-\beta}^{\lambda=\beta}\omega_{\lambda}\hat{\tilde{\bm{h}}}_{\text{TT}_{i}}[k+\lambda],\leavevmode\nobreak\
    \omega_{\lambda}=\frac{1}{2\beta+1}.$ |  | (44) |'
  prefs: []
  type: TYPE_TB
- en: The final [ADD-TT](#id36.36.id36) channel estimates are updated using time averaging
    between the previously [ADD-TT](#id36.36.id36) estimated channel and the frequency
    averaged channel in¬†([44](#S5.E44 "In V-B TS-ChannelNet ‚Ä£ V DL-Based FBF Channel
    Estimation Schemes ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly
    Dispersive Environments")), such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{ADD-TT}_{i}}[k]=(1-{\alpha})\hat{\tilde{\bm{h}}}_{\text{ADD-TT}_{i-1}}[k]+{\alpha}\hat{\tilde{\bm{h}}}_{\text{FTT}_{i}}[k].$
    |  | (45) |'
  prefs: []
  type: TYPE_TB
- en: The doubly-dispersive channel can be modeled as a time-series forecasting problem.
    Here, historical data can be utilized to forecast future observations¬†[[56](#bib.bib56)].
    Motiviated by this possibility, the authors in¬†[[31](#bib.bib31)] apply [SR-ConvLSTM](#id39.39.id39)
    network in addition to the [ADD-TT](#id36.36.id36) interpolation, where convolutional
    layers get added to the LSTM network to capture more doubly-dispersive channel
    features. Consequently, this improves the estimation performance. Accordingly,
    the [ADD-TT](#id36.36.id36) estimated channel for the entire received frame is
    modeled as a low resolution image. Next, the [SR-ConvLSTM](#id39.39.id39) network
    is used after the [ADD-TT](#id36.36.id36) interpolation. Unlike [ChannelNet](#id35.35.id35)
    estimator where two [CNNs](#id28.28.id28) are employed, [TS-ChannelNet](#id29.29.id29)
    estimator uses only one [SR-ConvLSTM](#id39.39.id39) network, which relatively
    reduces the overall computational complexity. However, [TS-ChannelNet](#id29.29.id29)
    continues to be ridden with high computational complexity due to the integration
    of LSTM and [CNN](#id28.28.id28) in a single network.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/26928ddade9669e49cad2c374bc69d38.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: The block diagram of the studied CNN-based FBF channel estimators.'
  prefs: []
  type: TYPE_NORMAL
- en: V-C WI-CNN
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To overcome the limitations of the [ChannelNet](#id35.35.id35) and [TS-ChannelNet](#id29.29.id29)
    estimators, [weighted interpolation](#id37.37.id37) ([WI](#id37.37.id37))-[CNN](#id28.28.id28)
    estimator has been proposed in¬†[[32](#bib.bib32)]. In this method, the frame structure
    is adapted in accordance with the mobility condition employing varied pilot allocation
    schemes. Particularly, only $P$ pilot [OFDM](#id208.208.id208) symbols are required
    in the transmitted frame, such that $\tilde{\bm{Y}}_{P}=[\tilde{\bm{y}}^{(p)}_{1},\dots,\tilde{\bm{y}}^{(p)}_{q},\dots,\tilde{\bm{y}}^{(p)}_{P}]\in\mathbb{C}^{K_{\text{on}}\times
    P}$. The index $1\leq q\leq P$ refers to the location of the [OFDM](#id208.208.id208)
    pilot symbol in the frame. The other $I_{d}=I-P$ [OFDM](#id208.208.id208) data
    symbols are employed for data transmission purposes. As per the employed pilots
    allocation scheme, the channel is estimated at the inserted pilot symbols, after
    which [WI](#id37.37.id37) is applied to estimate the channel at the [OFDM](#id208.208.id208)
    data symbols. The estimated frame is then modeled as a 2D noisy image where optimized
    [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26) are utilized for noise elimination.
    Against this backdrop, the [WI](#id37.37.id37)-[CNN](#id28.28.id28) proceeds as
    follows
  prefs: []
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Channel estimation at the pilot symbols: Two pilot allocation schemes are defined.
    The full pilot allocation (FP) where $K$ pilots are inserted within all pilot
    symbols and [LS](#id172.172.id172) estimation is applied to estimate the channel
    for each inserted pilot symbol, such that'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{h}}}_{{\text{SLS}}_{q}}[k]=\frac{\tilde{\bm{y}}^{(p)}_{q}[k]}{\tilde{\bm{p}}[k]}.$
    |  | (46) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: $\hat{\tilde{\bm{h}}}_{{\text{SLS}}_{q}}[k]$ represents the [simple LS](#id34.34.id34)
    ([SLS](#id34.34.id34)) estimation at the $q$-th inserted pilot symbol. In addition,
    the [accurate LS](#id33.33.id33) ([ALS](#id33.33.id33)) that can be obtained by
    implementing the [DFT](#id95.95.id95) interpolation of estimated channel impulse
    response at the $q$-th received pilot symbol $\hat{\bm{h}}_{q,L}$, such that
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{h}}}_{{\text{ALS}}_{q}}=\bm{F}_{\text{K}}\hat{\bm{h}}_{q,L},\leavevmode\nobreak\
    \leavevmode\nobreak\ \hat{\bm{h}}_{q,L}=\bm{F}_{\text{K}}^{\dagger}\hat{\tilde{\bm{h}}}_{{\text{LS}}_{q}}.$
    |  | (47) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '[ALS](#id33.33.id33) relies on the fact that $\tilde{\bm{h}}_{{q}}=\bm{F}_{\text{K}}{\bm{h}}_{q,L}$,
    where ${\bm{h}}_{q,L}\in\mathbb{C}^{L\times 1}$ signifies the channel impulse
    response at the $q$-th received pilot symbol that can be estimated by employing
    the pseudo inverse matrix of $\bm{F}_{\text{K}}$, namely, $\bm{F}_{\text{K}}^{\dagger}=[(\bm{F}_{\text{K}}^{\text{H}}\bm{F}_{\text{K}})^{-1}\bm{F}_{\text{K}}^{\text{H}}]$
    . However, if the number of doubly dispersive-channel taps $L$ remains known,
    only $K_{p}=L$ pilot subcarriers are sufficient in each inserted pilot symbol.
    Accordingly,¬†([47](#S5.E47 "In 1st item ‚Ä£ V-C WI-CNN ‚Ä£ V DL-Based FBF Channel
    Estimation Schemes ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly
    Dispersive Environments")) can be rewritten as'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{h}}}_{{\text{DFT}}_{q}}=\bm{F}_{\text{K}}\hat{\bm{h}}_{q,L},\leavevmode\nobreak\
    \leavevmode\nobreak\ \hat{\bm{h}}_{q,L}=\bm{F}_{p}^{\dagger}\hat{\tilde{\bm{h}}}_{{\text{LS}}_{q}}.$
    |  | (48) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: $\bm{F}_{p}^{\dagger}=[(\bm{F}_{p}^{\text{H}}\bm{F}_{p})^{-1}\bm{F}_{p}^{\text{H}}]$
    denotes the pseudo inverse matrix of $\bm{F}_{p}\in\mathbb{C}^{K_{\text{p}}\times
    L}$ referring to the truncated DFT matrix obtained by selecting ${\mathcal{K}}_{\text{p}}$
    rows, and $L$ columns from the $K$-DFT matrix.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Channel estimation at data symbols: The estimated channels of the $P$ pilot
    symbols are first grouped into $P$ matrices to estimate the channel for each received
    OFDM data symbol, such that'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{H}}}_{q}=[\hat{\tilde{\bm{h}}}_{q-1},\hat{\tilde{\bm{h}}}_{q}],\leavevmode\nobreak\
    q=1,\cdots P.$ |  | (49) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: $\hat{\tilde{\bm{h}}}_{0}=\hat{\tilde{\bm{h}}}_{\text{LS}}$ refers to the [LS](#id172.172.id172)
    estimated channel at the beginning of the received frame¬†([24](#S4.E24 "In IV-A
    DPA-FNN ‚Ä£ IV DL-Based SBS Channel Estimation ‚Ä£ A Survey on Deep Learning based
    Channel Estimation in Doubly Dispersive Environments")). Thus, the received frame
    can be divided into $P$ sub-frames, where $f$ refers to the sub-frame index, such
    that $1\leq f\leq P$. Therefore, the estimated channel for the $i$-th received
    [OFDM](#id208.208.id208) symbol within each $f$-th sub-frame can be expressed
    as follows
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\hat{\tilde{\bm{H}}}_{{\text{WI}}_{f}}=\hat{\tilde{\bm{H}}}_{{f}}\bm{C}_{f}.$
    |  | (50) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: $\hat{\tilde{\bm{H}}}_{f}\in\mathbb{C}^{K\times 2}$ denotes the [LS](#id172.172.id172)
    estimated channels at the pilot symbols within the $f$-th sub-frame, and $\bm{C}_{f}\in\mathbb{R}^{2\times
    I_{f}}$ the interpolation weights of the $I_{f}$ [OFDM](#id208.208.id208) data
    symbols within the $f$-th sub-frame. The interpolation weights $\bm{C}_{f}$ are
    calculated by minimizing the [mean squared error](#id196.196.id196) ([MSE](#id196.196.id196))
    between the ideal channel $\tilde{\bm{H}}_{{f}}$, and the [LS](#id172.172.id172)
    estimated channel at the [OFDM](#id208.208.id208) pilot symbols $\hat{\tilde{\bm{H}}}_{{f}}$
    as obtained in¬†[[57](#bib.bib57)] and expressed in¬†([51](#S5.E51 "In 2nd item
    ‚Ä£ V-C WI-CNN ‚Ä£ V DL-Based FBF Channel Estimation Schemes ‚Ä£ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments")). There, $J_{0}(.)$
    is the zeroth order Bessel function of the first kind, $T_{\text{s}}$ signifies
    the received [OFDM](#id208.208.id208) data symbol duration, whereas $E_{{{q}}}$
    denotes the overall noise of the estimated channel at the $q$-th pilot symbol.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | <math  class="ltx_Math" alttext="\begin{split}\bm{C}_{{f}}&amp;=\mathrm{E}\left[\tilde{\bm{H}}_{{f}}\hat{\tilde{\bm{H}}}^{H}_{{f}}\right]\left[\mathrm{E}\left[\hat{\tilde{\bm{H}}}_{{f}}\hat{\tilde{\bm{H}}}^{H}_{{f}}\right]\right]^{-1}=\begin{bmatrix}\mathrm{E}\left[\tilde{\bm{H}}_{{f}}\hat{\tilde{\bm{h}}}^{H}_{{q}}\right]&amp;\mathrm{E}\left[\tilde{\bm{H}}_{{i}}\hat{\tilde{\bm{h}}}^{H}_{{q+1}}\right]\end{bmatrix}\begin{bmatrix}\mathrm{E}\left[\mathinner{\!\left\lVert{\tilde{\bm{h}}}_{{q}}\right\rVert}^{2}\right]+E_{{{q}}}&amp;\mathrm{E}\left[{\tilde{\bm{h}}}_{{q}}{\tilde{\bm{h}}}^{H}_{{q+1}}\right]\\
    \mathrm{E}\left[{\tilde{\bm{h}}}_{{q+1}}{\tilde{\bm{h}}}^{H}_{{q}}\right]&amp;\mathrm{E}\left[\mathinner{\!\left\lVert{\tilde{\bm{h}}}_{{q+1}}\right\rVert}^{2}\right]+E_{{{q+1}}}\end{bmatrix}^{-1}\\'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '&amp;=\begin{bmatrix}J_{0}(2\pi f_{\text{d}}(f-1)T_{\text{s}})&amp;J_{0}(2\pi
    f_{\text{d}}(I_{f}+1-f)T_{\text{s}})\end{bmatrix}\begin{bmatrix}1+E_{{{\Phi}_{q}}}&amp;J_{0}(2\pi
    f_{\text{d}}I_{f}T_{\text{s}})\\'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: J_{0}(2\pi f_{\text{d}}I_{f}T_{\text{s}})&amp;1+E_{{{q+1}}}\end{bmatrix}^{-1}.\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true"
    rowspacing="0pt" ><mtr ><mtd class="ltx_align_right"
    columnalign="right" ><msub ><mi
     >ùë™</mi><mi 
    >f</mi></msub></mtd><mtd class="ltx_align_left"
    columnalign="left" ><mrow ><mo
     >=</mo><mrow ><mi
    mathvariant="normal"  >E</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
    ><mo  >[</mo><mrow
    ><msub ><mover
    accent="true"  ><mi
     >ùëØ</mi><mo
     >~</mo></mover><mi
     >f</mi></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msubsup
    ><mover accent="true" 
    ><mover accent="true" 
    ><mi 
    >ùëØ</mi><mo 
    >~</mo></mover><mo 
    >^</mo></mover><mi 
    >f</mi><mi 
    >H</mi></msubsup></mrow><mo 
    >]</mo></mrow><mo lspace="0em" rspace="0em" 
    >‚Äã</mo><msup ><mrow
    ><mo 
    >[</mo><mrow ><mi
    mathvariant="normal"  >E</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
    ><mo 
    >[</mo><mrow ><msub
    ><mover accent="true" 
    ><mover accent="true" 
    ><mi 
    >ùëØ</mi><mo 
    >~</mo></mover><mo 
    >^</mo></mover><mi 
    >f</mi></msub><mo lspace="0em" rspace="0em"
     >‚Äã</mo><msubsup
    ><mover accent="true" 
    ><mover accent="true" 
    ><mi 
    >ùëØ</mi><mo 
    >~</mo></mover><mo 
    >^</mo></mover><mi 
    >f</mi><mi 
    >H</mi></msubsup></mrow><mo 
    >]</mo></mrow></mrow><mo 
    >]</mo></mrow><mrow 
    ><mo 
    >‚àí</mo><mn 
    >1</mn></mrow></msup></mrow><mo 
    >=</mo><mrow ><mrow
     ><mo 
    >[</mo><mtable columnspacing="5pt" displaystyle="true"
     ><mtr 
    ><mtd  ><mrow
     ><mi
    mathvariant="normal"  >E</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
     ><mo
     >[</mo><mrow
     ><msub
     ><mover
    accent="true"  ><mi
     >ùëØ</mi><mo
     >~</mo></mover><mi
     >f</mi></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msubsup
     ><mover
    accent="true"  ><mover
    accent="true"  ><mi
     >ùíâ</mi><mo
     >~</mo></mover><mo
     >^</mo></mover><mi
     >q</mi><mi
     >H</mi></msubsup></mrow><mo
     >]</mo></mrow></mrow></mtd><mtd
     ><mrow 
    ><mi mathvariant="normal" 
    >E</mi><mo lspace="0em" rspace="0em"
     >‚Äã</mo><mrow
     ><mo
     >[</mo><mrow
     ><msub
     ><mover
    accent="true"  ><mi
     >ùëØ</mi><mo
     >~</mo></mover><mi
     >i</mi></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msubsup
     ><mover
    accent="true"  ><mover
    accent="true"  ><mi
     >ùíâ</mi><mo
     >~</mo></mover><mo
     >^</mo></mover><mrow
     ><mi
     >q</mi><mo
     >+</mo><mn
     >1</mn></mrow><mi
     >H</mi></msubsup></mrow><mo
     >]</mo></mrow></mrow></mtd></mtr></mtable><mo
     >]</mo></mrow><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msup
    ><mrow  ><mo
     >[</mo><mtable
    columnspacing="5pt" displaystyle="true" rowspacing="0pt" 
    ><mtr  ><mtd
     ><mrow 
    ><mrow 
    ><mi mathvariant="normal" 
    >E</mi><mo lspace="0em" rspace="0em"
     >‚Äã</mo><mrow
     ><mpadded
    width="0.247em"><mo  >[</mo></mpadded><msup
     ><mrow
     ><mo
    fence="true" rspace="0em" stretchy="true" 
    >‚à•</mo><msub 
    ><mover accent="true" 
    ><mi 
    >ùíâ</mi><mo 
    >~</mo></mover><mi 
    >q</mi></msub><mo fence="true"
    lspace="0em" rspace="0em" stretchy="true" 
    >‚à•</mo></mrow><mn 
    >2</mn></msup><mo 
    >]</mo></mrow></mrow><mo
     >+</mo><msub
     ><mi
     >E</mi><mi
     >q</mi></msub></mrow></mtd><mtd
     ><mrow 
    ><mi mathvariant="normal" 
    >E</mi><mo lspace="0em" rspace="0em"
     >‚Äã</mo><mrow
     ><mo
     >[</mo><mrow
     ><msub
     ><mover
    accent="true"  ><mi
     >ùíâ</mi><mo
     >~</mo></mover><mi
     >q</mi></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msubsup
     ><mover
    accent="true"  ><mi
     >ùíâ</mi><mo
     >~</mo></mover><mrow
     ><mi
     >q</mi><mo
     >+</mo><mn
     >1</mn></mrow><mi
     >H</mi></msubsup></mrow><mo
     >]</mo></mrow></mrow></mtd></mtr><mtr
     ><mtd 
    ><mrow 
    ><mi mathvariant="normal" 
    >E</mi><mo lspace="0em" rspace="0em"
     >‚Äã</mo><mrow
     ><mo
     >[</mo><mrow
     ><msub
     ><mover
    accent="true"  ><mi
     >ùíâ</mi><mo
     >~</mo></mover><mrow
     ><mi
     >q</mi><mo
     >+</mo><mn
     >1</mn></mrow></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msubsup
     ><mover
    accent="true"  ><mi
     >ùíâ</mi><mo
     >~</mo></mover><mi
     >q</mi><mi
     >H</mi></msubsup></mrow><mo
     >]</mo></mrow></mrow></mtd><mtd
     ><mrow 
    ><mrow 
    ><mi mathvariant="normal" 
    >E</mi><mo lspace="0em" rspace="0em"
     >‚Äã</mo><mrow
     ><mpadded
    width="0.247em"><mo  >[</mo></mpadded><msup
     ><mrow
     ><mo
    fence="true" rspace="0em" stretchy="true" 
    >‚à•</mo><msub 
    ><mover accent="true" 
    ><mi 
    >ùíâ</mi><mo 
    >~</mo></mover><mrow 
    ><mi 
    >q</mi><mo 
    >+</mo><mn 
    >1</mn></mrow></msub><mo
    fence="true" lspace="0em" rspace="0em" stretchy="true" 
    >‚à•</mo></mrow><mn 
    >2</mn></msup><mo 
    >]</mo></mrow></mrow><mo
     >+</mo><msub
     ><mi
     >E</mi><mrow
     ><mi
     >q</mi><mo
     >+</mo><mn
     >1</mn></mrow></msub></mrow></mtd></mtr></mtable><mo
     >]</mo></mrow><mrow
     ><mo
     >‚àí</mo><mn
     >1</mn></mrow></msup></mrow></mrow></mtd></mtr><mtr
    ><mtd class="ltx_align_left" columnalign="left" ><mrow
    ><mrow ><mo 
    >=</mo><mrow ><mrow
     ><mo 
    >[</mo><mtable columnspacing="5pt" displaystyle="true"
     ><mtr 
    ><mtd  ><mrow
     ><msub
     ><mi
     >J</mi><mn
     >0</mn></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
     ><mo
    stretchy="false"  >(</mo><mrow
     ><mn
     >2</mn><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mi
     >œÄ</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msub
     ><mi
     >f</mi><mtext
     >d</mtext></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
     ><mo
    stretchy="false"  >(</mo><mrow
     ><mi
     >f</mi><mo
     >‚àí</mo><mn
     >1</mn></mrow><mo
    stretchy="false"  >)</mo></mrow><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msub
     ><mi
     >T</mi><mtext
     >s</mtext></msub></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow></mtd><mtd
     ><mrow 
    ><msub 
    ><mi 
    >J</mi><mn 
    >0</mn></msub><mo lspace="0em"
    rspace="0em"  >‚Äã</mo><mrow
     ><mo
    stretchy="false"  >(</mo><mrow
     ><mn
     >2</mn><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mi
     >œÄ</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msub
     ><mi
     >f</mi><mtext
     >d</mtext></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mrow
     ><mo
    stretchy="false"  >(</mo><mrow
     ><mrow
     ><msub
     ><mi
     >I</mi><mi
     >f</mi></msub><mo
     >+</mo><mn
     >1</mn></mrow><mo
     >‚àí</mo><mi
     >f</mi></mrow><mo
    stretchy="false"  >)</mo></mrow><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msub
     ><mi
     >T</mi><mtext
     >s</mtext></msub></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow></mtd></mtr></mtable><mo
     >]</mo></mrow><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msup
    ><mrow  ><mo
     >[</mo><mtable
    columnspacing="5pt" displaystyle="true" rowspacing="0pt" 
    ><mtr  ><mtd
     ><mrow 
    ><mn 
    >1</mn><mo 
    >+</mo><msub 
    ><mi 
    >E</mi><msub 
    ><mi mathvariant="normal" 
    >Œ¶</mi><mi 
    >q</mi></msub></msub></mrow></mtd><mtd
     ><mrow 
    ><msub 
    ><mi 
    >J</mi><mn 
    >0</mn></msub><mo lspace="0em"
    rspace="0em"  >‚Äã</mo><mrow
     ><mo
    stretchy="false"  >(</mo><mrow
     ><mn
     >2</mn><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mi
     >œÄ</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msub
     ><mi
     >f</mi><mtext
     >d</mtext></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msub
     ><mi
     >I</mi><mi
     >f</mi></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msub
     ><mi
     >T</mi><mtext
     >s</mtext></msub></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow></mtd></mtr><mtr
     ><mtd 
    ><mrow 
    ><msub 
    ><mi 
    >J</mi><mn 
    >0</mn></msub><mo lspace="0em"
    rspace="0em"  >‚Äã</mo><mrow
     ><mo
    stretchy="false"  >(</mo><mrow
     ><mn
     >2</mn><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><mi
     >œÄ</mi><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msub
     ><mi
     >f</mi><mtext
     >d</mtext></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msub
     ><mi
     >I</mi><mi
     >f</mi></msub><mo
    lspace="0em" rspace="0em"  >‚Äã</mo><msub
     ><mi
     >T</mi><mtext
     >s</mtext></msub></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow></mtd><mtd
     ><mrow 
    ><mn 
    >1</mn><mo 
    >+</mo><msub 
    ><mi 
    >E</mi><mrow 
    ><mi 
    >q</mi><mo 
    >+</mo><mn 
    >1</mn></mrow></msub></mrow></mtd></mtr></mtable><mo
     >]</mo></mrow><mrow
     ><mo 
    >‚àí</mo><mn 
    >1</mn></mrow></msup></mrow></mrow><mo
    lspace="0em"  >.</mo></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply 
    ><apply  ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùë™</ci><ci 
    >ùëì</ci></apply><apply 
    ><ci  >E</ci><apply
     ><csymbol
    cd="latexml"  >delimited-[]</csymbol><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><ci 
    >~</ci><ci 
    >ùëØ</ci></apply><ci 
    >ùëì</ci></apply><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><apply 
    ><ci  >^</ci><apply
     ><ci 
    >~</ci><ci 
    >ùëØ</ci></apply></apply><ci 
    >ùêª</ci></apply><ci 
    >ùëì</ci></apply></apply></apply><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><apply 
    ><ci 
    >E</ci><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><ci 
    >^</ci><apply 
    ><ci 
    >~</ci><ci 
    >ùëØ</ci></apply></apply><ci 
    >ùëì</ci></apply><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><apply 
    ><ci 
    >^</ci><apply 
    ><ci 
    >~</ci><ci 
    >ùëØ</ci></apply></apply><ci 
    >ùêª</ci></apply><ci 
    >ùëì</ci></apply></apply></apply></apply></apply><apply
     ><cn
    type="integer"  >1</cn></apply></apply></apply></apply><apply
     ><apply 
    ><apply 
    ><csymbol cd="latexml" 
    >matrix</csymbol><matrix 
    ><matrixrow 
    ><apply 
    ><ci 
    >E</ci><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><ci 
    >~</ci><ci 
    >ùëØ</ci></apply><ci 
    >ùëì</ci></apply><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><apply 
    ><ci 
    >^</ci><apply 
    ><ci 
    >~</ci><ci 
    >ùíâ</ci></apply></apply><ci
     >ùêª</ci></apply><ci
     >ùëû</ci></apply></apply></apply></apply><apply
     ><ci
     >E</ci><apply
     ><csymbol
    cd="latexml"  >delimited-[]</csymbol><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><ci
     >~</ci><ci
     >ùëØ</ci></apply><ci
     >ùëñ</ci></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><ci
     >^</ci><apply
     ><ci
     >~</ci><ci
     >ùíâ</ci></apply></apply><ci
     >ùêª</ci></apply><apply
     ><ci
     >ùëû</ci><cn
    type="integer"  >1</cn></apply></apply></apply></apply></apply></matrixrow></matrix></apply><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol cd="latexml"
     >matrix</csymbol><matrix
     ><matrixrow
     ><apply 
    ><apply 
    ><ci 
    >E</ci><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol
    cd="latexml"  >delimited-‚à•‚à•</csymbol><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><ci
     >~</ci><ci
     >ùíâ</ci></apply><ci
     >ùëû</ci></apply></apply><cn
    type="integer"  >2</cn></apply></apply></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùê∏</ci><ci
     >ùëû</ci></apply></apply><apply
     ><ci
     >E</ci><apply
     ><csymbol
    cd="latexml"  >delimited-[]</csymbol><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><ci
     >~</ci><ci
     >ùíâ</ci></apply><ci
     >ùëû</ci></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><ci
     >~</ci><ci
     >ùíâ</ci></apply><ci
     >ùêª</ci></apply><apply
     ><ci
     >ùëû</ci><cn
    type="integer"  >1</cn></apply></apply></apply></apply></apply></matrixrow><matrixrow
     ><apply 
    ><ci 
    >E</ci><apply 
    ><csymbol cd="latexml" 
    >delimited-[]</csymbol><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><ci 
    >~</ci><ci 
    >ùíâ</ci></apply><apply 
    ><ci 
    >ùëû</ci><cn type="integer"
     >1</cn></apply></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><ci
     >~</ci><ci
     >ùíâ</ci></apply><ci
     >ùêª</ci></apply><ci
     >ùëû</ci></apply></apply></apply></apply><apply
     ><apply
     ><ci
     >E</ci><apply
     ><csymbol
    cd="latexml"  >delimited-[]</csymbol><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol
    cd="latexml"  >delimited-‚à•‚à•</csymbol><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><apply
     ><ci
     >~</ci><ci
     >ùíâ</ci></apply><apply
     ><ci
     >ùëû</ci><cn
    type="integer"  >1</cn></apply></apply></apply><cn
    type="integer"  >2</cn></apply></apply></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùê∏</ci><apply
     ><ci
     >ùëû</ci><cn
    type="integer"  >1</cn></apply></apply></apply></matrixrow></matrix></apply><apply
     ><cn
    type="integer"  >1</cn></apply></apply></apply></apply><apply
     ><apply 
    ><apply 
    ><csymbol cd="latexml" 
    >matrix</csymbol><matrix 
    ><matrixrow 
    ><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >ùêΩ</ci><cn type="integer" 
    >0</cn></apply><apply 
    ><cn type="integer" 
    >2</cn><ci 
    >ùúã</ci><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >ùëì</ci><ci 
    ><mtext mathsize="70%" 
    >d</mtext></ci></apply><apply
     ><ci
     >ùëì</ci><cn
    type="integer"  >1</cn></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùëá</ci><ci
     ><mtext
    mathsize="70%"  >s</mtext></ci></apply></apply></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùêΩ</ci><cn
    type="integer"  >0</cn></apply><apply
     ><cn
    type="integer"  >2</cn><ci
     >ùúã</ci><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùëì</ci><ci
     ><mtext
    mathsize="70%"  >d</mtext></ci></apply><apply
     ><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùêº</ci><ci
     >ùëì</ci></apply><cn
    type="integer"  >1</cn></apply><ci
     >ùëì</ci></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùëá</ci><ci
     ><mtext
    mathsize="70%"  >s</mtext></ci></apply></apply></apply></matrixrow></matrix></apply><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol cd="latexml"
     >matrix</csymbol><matrix
     ><matrixrow
     ><apply 
    ><cn type="integer" 
    >1</cn><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >ùê∏</ci><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >Œ¶</ci><ci 
    >ùëû</ci></apply></apply></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùêΩ</ci><cn
    type="integer"  >0</cn></apply><apply
     ><cn
    type="integer"  >2</cn><ci
     >ùúã</ci><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùëì</ci><ci
     ><mtext
    mathsize="70%"  >d</mtext></ci></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùêº</ci><ci
     >ùëì</ci></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùëá</ci><ci
     ><mtext
    mathsize="70%"  >s</mtext></ci></apply></apply></apply></matrixrow><matrixrow
     ><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >ùêΩ</ci><cn type="integer" 
    >0</cn></apply><apply 
    ><cn type="integer" 
    >2</cn><ci 
    >ùúã</ci><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >ùëì</ci><ci 
    ><mtext mathsize="70%" 
    >d</mtext></ci></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùêº</ci><ci
     >ùëì</ci></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùëá</ci><ci
     ><mtext
    mathsize="70%"  >s</mtext></ci></apply></apply></apply><apply
     ><cn
    type="integer"  >1</cn><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >ùê∏</ci><apply
     ><ci
     >ùëû</ci><cn
    type="integer"  >1</cn></apply></apply></apply></matrixrow></matrix></apply><apply
     ><cn type="integer"
     >1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}\bm{C}_{{f}}&=\mathrm{E}\left[\tilde{\bm{H}}_{{f}}\hat{\tilde{\bm{H}}}^{H}_{{f}}\right]\left[\mathrm{E}\left[\hat{\tilde{\bm{H}}}_{{f}}\hat{\tilde{\bm{H}}}^{H}_{{f}}\right]\right]^{-1}=\begin{bmatrix}\mathrm{E}\left[\tilde{\bm{H}}_{{f}}\hat{\tilde{\bm{h}}}^{H}_{{q}}\right]&\mathrm{E}\left[\tilde{\bm{H}}_{{i}}\hat{\tilde{\bm{h}}}^{H}_{{q+1}}\right]\end{bmatrix}\begin{bmatrix}\mathrm{E}\left[\mathinner{\!\left\lVert{\tilde{\bm{h}}}_{{q}}\right\rVert}^{2}\right]+E_{{{q}}}&\mathrm{E}\left[{\tilde{\bm{h}}}_{{q}}{\tilde{\bm{h}}}^{H}_{{q+1}}\right]\\
    \mathrm{E}\left[{\tilde{\bm{h}}}_{{q+1}}{\tilde{\bm{h}}}^{H}_{{q}}\right]&\mathrm{E}\left[\mathinner{\!\left\lVert{\tilde{\bm{h}}}_{{q+1}}\right\rVert}^{2}\right]+E_{{{q+1}}}\end{bmatrix}^{-1}\\
    &=\begin{bmatrix}J_{0}(2\pi f_{\text{d}}(f-1)T_{\text{s}})&J_{0}(2\pi f_{\text{d}}(I_{f}+1-f)T_{\text{s}})\end{bmatrix}\begin{bmatrix}1+E_{{{\Phi}_{q}}}&J_{0}(2\pi
    f_{\text{d}}I_{f}T_{\text{s}})\\ J_{0}(2\pi f_{\text{d}}I_{f}T_{\text{s}})&1+E_{{{q+1}}}\end{bmatrix}^{-1}.\end{split}</annotation></semantics></math>
    |  | (51) |
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CNN-based Processing: The final step in the [WI](#id37.37.id37)-[CNN](#id28.28.id28)
    estimators is to apply [CNN](#id28.28.id28) processing to further improve the
    [WI](#id37.37.id37) estimated channels. Optimized [SR-CNN](#id25.25.id25) and
    [DN-CNN](#id26.26.id26) are employed in this context. The investigations conducted
    in¬†[[32](#bib.bib32)] reveal that both [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26)
    networks have similar performance in low mobility scenarios, whereas [DN-CNN](#id26.26.id26)
    outperforms [SR-CNN](#id25.25.id25) in high mobility scenarios. Figure¬†[7](#S5.F7
    "Figure 7 ‚Ä£ V-B TS-ChannelNet ‚Ä£ V DL-Based FBF Channel Estimation Schemes ‚Ä£ A
    Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments")
    and Table¬†[III](#S5.T3 "Table III ‚Ä£ V-A ChannelNet ‚Ä£ V DL-Based FBF Channel Estimation
    Schemes ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments") illustrate the block diagram as well as configured parameters of
    the studied CNN-based channel estimators, respectively. Furthermore, the salient
    features of the studied DL-based channel estimators are summarized in Table¬†[II](#S5.T2
    "Table II ‚Ä£ V DL-Based FBF Channel Estimation Schemes ‚Ä£ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments"). Notably, robustness
    feature alludes to the ability of the studied estimation to maintain good performance
    as the variation of the doubly-dispersive channel increases.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Table IV: The characteristics of the employed vehicular channel models following
    Jake‚Äôs Doppler spectrum.'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Channel &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; model &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Channel &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; taps &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Vehicle velocity &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [kmph] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Doppler &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; shift [Hz] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Average path gains [dB] | Path delays [ns] |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| VTV-UC | 12 | 45 | 250 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [0, 0, -10, -10, -10, -17.8, -17.8, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; -17.8, -21.1, -21.1, -26.3, -26.3] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [0, 1, 100, 101, 102, 200, 201, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 202, 300, 301, 400, 401] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| VTV-SDWW | 12 | 100-200 | 500-1000 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [0, 0, -11.2, -11.2, -19, -21.9, -25.3, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; -25.3, -24.4, -28, -26.1, -26.1] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; [0, 1, 100, 101, 200, 300, 400, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 401, 500, 600, 700, 701] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: VI Simulation Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section illustrates the performance evaluation of the studied [DL](#id96.96.id96)-based
    SBS and FBF estimators in relation to [BER](#id64.64.id64), [NMSE](#id204.204.id204)
    employing varied metrics and mobility scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: VI-A Configuration Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To simulate doubly-dispersive channels, vehicular communications is considered
    a simulation case study, where three [tapped delay line](#id4.4.id4) ([TDL](#id4.4.id4))
    channel models¬†[[58](#bib.bib58)] are defined as follows
  prefs: []
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Low mobility: where VTV Urban Canyon (VTV-UC) vehicular channel model is considered.
    This channel model is measured between two vehicles moving in a dense urban traffic
    environment at ${V}=45$ Kmph equivalent to ${f}_{d}=250$ Hz.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'High and very high mobility: These scenarios measure the communication channel
    between two vehicles moving on a highway having center wall between its lanes
    at ${V}=100$ Kmph and $200$ Kmph equivalent to ${f}_{d}=500$ Hz and ${f}_{d}=1000$
    Hz, respectively. This vehicular channel model is referred to as VTV Expressway
    Same Direction with Wall (VTV-SDWW).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The employed channel models are generated after the wide-sense stationary uncorrelated
    scattering (WSSUS) model¬†[[59](#bib.bib59)]. Thus, we have
  prefs: []
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each path $h_{l}(t)$ is a zero mean Gaussian complex process, $E\{h_{l}(t)\}=0,\forall
    t$, and the mean of each path is independent of the time variations. Moreover,
    the time correlation function $r_{h_{l}}(t_{1},t_{2})=E\{h_{l}(t_{1})h^{*}_{l}(t_{2})\}$
    can only be written with the difference $\Delta(t)=(t_{1}-t_{2})$, such that
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $r_{h_{l}}(t_{1},t_{2})=r_{h_{l}}(\Delta_{t}).$ |  | (52) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: Then, each path $h_{l}(t)$ is the wide sense stationary (WSS).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ‚Ä¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uncorrelated scattering (US) implies that the paths are uncorrelated, so for
    $l_{1}\neq l_{2}$ we have
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\small E[h_{l_{1}}(t)h^{*}_{l_{2}}(t)]=0.$ |  | (53) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: Table¬†[IV](#S5.T4 "Table IV ‚Ä£ V-C WI-CNN ‚Ä£ V DL-Based FBF Channel Estimation
    Schemes ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments") illustrates the main characteristics of the defined [TDL](#id4.4.id4)
    channel models.
  prefs: []
  type: TYPE_NORMAL
- en: 'The [OFDM](#id208.208.id208) simulation parameters are based on the IEEE 802.11p
    standard as illustrated in¬†Table¬†[V](#S6.T5 "Table V ‚Ä£ VI-A Configuration Setup
    ‚Ä£ VI Simulation Results ‚Ä£ A Survey on Deep Learning based Channel Estimation in
    Doubly Dispersive Environments"). These simulations are implemented using QPSK
    and 16QAM modulation orders, the SNR range is $[0,5,\dots,40]$ dB. In addition,
    the performance evaluation is made according to: (i) modulation order, (ii) mobility,
    (iii) frame length, and (iv) DL architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it is observed that the conventional 2D [LMMSE](#id166.166.id166) estimator¬†[[17](#bib.bib17)]
    is included in the performance evaluation of the DL-based FBF estimators as a
    lower bound performance limit. The 2D LMMSE estimator almost achieves a similar
    performance as the ideal channel, but is ridden with high computational complexity.
    This renders it impractical in terms of real-time applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table V: Simulation parameters of the IEEE 802.11p physical layer.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Parameter | IEEE 802.11p |'
  prefs: []
  type: TYPE_TB
- en: '| Bandwidth | 10 MHz |'
  prefs: []
  type: TYPE_TB
- en: '| Guard interval duration | 1.6¬†$\mu\mbox{s}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Symbol duration | 8¬†$\mu\mbox{s}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Short training symbol duration | 1.6¬†$\mu\mbox{s}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Long training symbol duration | 6.4¬†$\mu\mbox{s}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Total subcarriers | 64 |'
  prefs: []
  type: TYPE_TB
- en: '| Pilot subcarriers | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Data subcarriers | 48 |'
  prefs: []
  type: TYPE_TB
- en: '| Subcarrier spacing | 156.25 KHz |'
  prefs: []
  type: TYPE_TB
- en: VI-B DL-Based SBS Estimation Schemes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: VI-B1 Modulation Order
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fcc7714601b8375736909a941f46a3bb.png)'
  prefs: []
  type: TYPE_IMG
- en: (a)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d90c662d4b14b588b27448e2af7b0bde.png)'
  prefs: []
  type: TYPE_IMG
- en: (b)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8: BER for $I=100$, mobility from left to right: low ($v=45\leavevmode\nobreak\
    \text{Kmph},f_{d}=250$ Hz), high ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$
    Hz), very high ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$ Hz).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9bd0d39c4e69b2c1356bda30e5c0e025.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: NMSE for $I=100$, mobility from left to right: low ($v=45\leavevmode\nobreak\
    \text{Kmph},f_{d}=250$ Hz), high ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$
    Hz), very high ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$ Hz).'
  prefs: []
  type: TYPE_NORMAL
- en: For QPSK modulation order, we can notice from Figure¬†[8](#S6.F8 "Figure 8 ‚Ä£
    VI-B1 Modulation Order ‚Ä£ VI-B DL-Based SBS Estimation Schemes ‚Ä£ VI Simulation
    Results ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments"), and Figure¬†[9](#S6.F9 "Figure 9 ‚Ä£ VI-B1 Modulation Order ‚Ä£ VI-B
    DL-Based SBS Estimation Schemes ‚Ä£ VI Simulation Results ‚Ä£ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments") that conventional
    [SBS](#id22.22.id22) estimators witness a considerable performance degradation
    in different mobility scenarios primarily due to the enlarged DPA demapping error,
    particularly under very high mobility. Nevertheless, employing DL techniques in
    the channel estimation process results in a significant improvement in overall
    performance. To begin with, the FNN-based estimators, where FNN is employed as
    a post-processing unit after conventional estimators, are discussed. As observed,
    FNN can implicitly learn the channel correlations apart from preventing a high
    demapping error arising from conventional DPA-based estimation, while STA-FNN
    and TRFI-FNN outperform conventional STA and TRFI estimators by at least $15$
    dB gain in terms of SNR for BER $=10^{-3}$. Meanwhile, STA-FNN estimator outperforms
    DPA-FNN estimator by around $5$ dB gain in terms of SNR for BER $=10^{-3}$. However,
    STA-FNN suffers from error floor beginning from SNR $=20$ dB, particularly in
    very high mobility scenarios. This is attributed to the fact that conventional
    STA estimation outperforms DPA in low SNR region due to the frequency and time
    averaging operations that can alleviate the impact of noise and demapping error
    in low SNR regions. On the other hand, the averaging operations are not useful
    in high SNR regions since the impact of noise is low, and the STA averaging coefficients
    are fixed. Therefore, TRFI-FNN is used to improve the performance at high SNRs
    to compensate for the STA-FNN performance degradation in high SNR region. Importantly,
    STA-FNN and TRFI-FNN can be employed in an adaptive manner where STA-FNN and TRFI-FNN
    are used in low and high SNR regions, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: For the LSTM-based estimators, employing LSTM as a prepossessing unit rather
    than a simple FNN in the channel estimation has shown to bring about a significant
    improvement in the overall performance. This is because LSTM is capable of efficiently
    learning the time correlations of the channel by taking the advantage of the previous
    output apart from the current input in order to estimate the current output. LSTM-FNN-DPA
    estimator¬†[[53](#bib.bib53)] outperforms STA-FNN and TRFI-FNN estimators by approximately
    $4$ dB gain in terms of SNR for BER $=10^{-3}$. However, this estimator is not
    impervious to high computational complexity, as discussed in the next section,
    due to the utilization of two DL networks, i.e, LSTM followed by FNN. On the other
    hand, the LSTM-DPA-TA estimators performance gain in various scenarios can be
    explained by employing the [TA](#id46.46.id46) processing, which significantly
    alleviates the noise impact aside from the strong ability of the LSTM in learning
    the channel time correlations compared with a simple FNN architecture. The LSTM-DPA-TA
    estimator outperforms the LSTM-FNN-DPA estimator by around $4$ dB gain in terms
    of SNR for BER $=10^{-4}$. When adopting high modulation order (16QAM), the LSTM-DPA-TA
    estimator outperforms the other estimators by at least $7$ dB and $3$ dB gains
    in terms of SNR for BER $=10^{-3}$ in high as well as very high mobility scenarios,
    respectively, as illustrated in Figure¬†LABEL:BER_16QAM_DL_SBS.
  prefs: []
  type: TYPE_NORMAL
- en: VI-B2 Mobility
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The degraded performance with the increased mobility of all the studied schemes
    can be observed from Figure¬†[8](#S6.F8 "Figure 8 ‚Ä£ VI-B1 Modulation Order ‚Ä£ VI-B
    DL-Based SBS Estimation Schemes ‚Ä£ VI Simulation Results ‚Ä£ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments"). However, the time
    diversity gain increases when there is an increase in the Doppler spread, as evidenced
    by comparing the case of the DL-based estimators in high mobility $(f_{d}=500)$
    and very high mobility ($f_{d}=1000$). This behavior can be explained by the ability
    of DL networks to reduce the estimation error stemming from the AWGN noise and
    the DPA demapping error. By contrast, the net gain from the time diversity is
    influenced by the AWGN noise and DPA demapping error, as is the case in conventional
    SBS estimators. The performance degradation is attributed as the mobility increases
    since the impact of the AWGN noise and DPA demapping error is much more dominant
    than the time diversity gain. This observation is also valid for high modulation
    orders such as 16QAM, as evidenced in Figure¬†LABEL:BER_16QAM_DL_SBS.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/646dea683ec34378d7fc5f630245e619.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: BER for QPSK, very high mobility ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$
    Hz) from left to right: $I=10$, $I=100$.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a28d04e18208edc54cdbfef2debad558.png)'
  prefs: []
  type: TYPE_IMG
- en: (a)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0efe8976fddfe6a92e1e226e33123e9f.png)'
  prefs: []
  type: TYPE_IMG
- en: (b)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11: BER for $I=100$, mobility from left to right: low ($v=45\leavevmode\nobreak\
    \text{Kmph},f_{d}=250$ Hz), high ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$
    Hz), very high ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$ Hz). The CNN
    refers to SR-CNN and DN-CNN in low and high/very high) mobility scenarios, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: VI-B3 Frame Length
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The impact of frame length is illustrated in Figure¬†[10](#S6.F10 "Figure 10
    ‚Ä£ VI-B2 Mobility ‚Ä£ VI-B DL-Based SBS Estimation Schemes ‚Ä£ VI Simulation Results
    ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments").
    As can be seen, the performance of the conventional estimators strongly depends
    on the frame length, given that employing short frame $I=10$ results in a negligible
    accumulated DPA demapping error. By contrast, the DL-based estimators are found
    to be more robust against the changes in the employed frame length. However, in
    the case of a long frame ($I=100$), the performance gain of the DL-based estimators
    is significantly remarkable. This behavior is mainly attributed to the time diversity
    negligible gain when short frame is employed and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: To conclude, it can be surmised that increasing the frame length increases the
    time diversity gain. Additionally, the codeword becomes longer with a longer frame.
    Therefore, the time diversity is capable of compensating for Doppler error, particularly
    in very high mobility scenario as illustrated in Figure¬†[10](#S6.F10 "Figure 10
    ‚Ä£ VI-B2 Mobility ‚Ä£ VI-B DL-Based SBS Estimation Schemes ‚Ä£ VI Simulation Results
    ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments")
  prefs: []
  type: TYPE_NORMAL
- en: VI-B4 DL Architecture
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The DPA-FNN estimator integrates three hidden layer FNN in additon to the conventional
    DPA estimation with $40-20-40$ neurons. However, as can be observed in Figure¬†[8](#S6.F8
    "Figure 8 ‚Ä£ VI-B1 Modulation Order ‚Ä£ VI-B DL-Based SBS Estimation Schemes ‚Ä£ VI
    Simulation Results ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly
    Dispersive Environments"), correcting the estimation error of the DPA estimation
    is insufficient even after the inclusion of more neurons in the FNN hidden layers,
    because it merely corrects the demapping error, neglecting the received symbols‚Äôrequency
    and time correlation. Meanwhile, the [STA](#id17.17.id17)-[FNN](#id99.99.id99)
    and TRFI-FNN estimators have better optimized three hidden layers [FNN](#id99.99.id99)
    architecture where $15-15-15$ neurons are used. Consequently, the overall computational
    complexity is considerably lowered when compared to the DPA-FNN, while attaining
    performance superiority. This is due to the fact that [STA](#id17.17.id17) considers
    frequency as well a time correlation between the received [OFDM](#id208.208.id208)
    symbols, while the conventional TRFI estimator employs frequency-domain cubic
    interpolation to make further improvements in the DPA estimation.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, it can be concluded that the pre-estimation should be good enough
    in order for the FNN processing to be more useful. Put differently, with an increased
    accuracy of the pre-estimation, low-complexity FNN architecture can be taken advantage
    of while recording a significant performance gain. On the contrary, if the pre-estimation
    is poor, employing FNN processing with high-complexity architecture results in
    a limited performance gain while increasing the overall computational complexity.
    As is the case with LSTM-based estimators, employing the [TA](#id46.46.id46) processing
    in the LSTM-DPA-TA estimator to ameliorate the AWGN noise impact results in a
    less complex architecture in comparison to the LSTM-FNN-DPA estimator, where two
    [DL](#id96.96.id96) networks are employed.
  prefs: []
  type: TYPE_NORMAL
- en: VI-C DL-Based FBF estimation Scheme
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/24f068f737e3e71fe0b9af50b58b7105.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: NMSE for $I=100$, mobility from left to right: low ($v=45\leavevmode\nobreak\
    \text{Kmph},f_{d}=250$ Hz), high ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$
    Hz), very high ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$ Hz).The CNN
    refers to SR-CNN and DN-CNN in low and high/very high) mobility scenarios, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: VI-C1 Modulation Order
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Figure¬†[11](#S6.F11 "Figure 11 ‚Ä£ VI-B2 Mobility ‚Ä£ VI-B DL-Based SBS Estimation
    Schemes ‚Ä£ VI Simulation Results ‚Ä£ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments") illustrates the BER performance of the studied
    DL-Based FBF estimators employing QPSK and 16QAM modulation orders. The 2D [LMMSE](#id166.166.id166)
    uses the channel and noise statistics in the estimation, thus leading to comparable
    performance in terms of the ideal case. However, the 2D-[LMMSE](#id166.166.id166)
    is ridden with high computational complexity. Moreover, the significant [BER](#id64.64.id64)
    performance superiority of the WI-CNN estimators can be observed where FP-ALS-CNN
    outperforms the ChannelNet as well as TS-ChannelNet estimators by at least $6$
    dB and $3$ dB gain in terms of [SNR](#id263.263.id263) for a BER = $10^{-3}$.
    Importantly, [ChannelNet](#id35.35.id35) and [TS-ChannelNet](#id29.29.id29) estimators
    suffer from a considerable performance degradation that is dominant in very high
    mobility scenarios. This is because their performance accounts for the predefined
    fixed parameters in the applied interpolation scheme, where it is important to
    update the RBF interpolation function and the ADD-TT frequency and time averaging
    parameters in real-time. Furthermore, the ADD-TT interpolation employs only the
    previous and the current pilot subcarriers for the channel estimation at each
    received [OFDM](#id208.208.id208) symbol. By contrast, there are no fixed parameters
    in the WI-CNN estimators. The time correlation between the previous and the future
    pilot symbols is considered in the [WI](#id37.37.id37) interpolation matrix¬†([51](#S5.E51
    "In 2nd item ‚Ä£ V-C WI-CNN ‚Ä£ V DL-Based FBF Channel Estimation Schemes ‚Ä£ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")),
    whereas the estimated channel is considered in the overall estimation at all channel
    taps. These aspects lead to the superior performance of WI-CNN estimators performance,
    where a significant robustness is shown against high mobility with varied performance
    gain according to the employed pilot allocation scheme, i.e FP or LP. In addition,
    WI-CNN estimators employ optimized [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26)
    in accordance with the mobility condition, wherein SR-CNN is utilized in low mobility
    scenarios, whereas, DN-CNN is employed in high and very high mobility scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/51764fea3344eca31836b2cfc22bad42.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: BER performance of VTV-SDWW high mobility vehicular channel model
    employing QPSK modulation and different frame lengths.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4ae79dccf8e3b8c701d79d7a47874296.png)'
  prefs: []
  type: TYPE_IMG
- en: (a)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b6817ee62e2a44d0f19ef1ce0c53b789.png)'
  prefs: []
  type: TYPE_IMG
- en: (b)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 14: BER performance employing three scenarios: (i) first column - low
    mobility ($v=45\leavevmode\nobreak\ \text{Kmph},f_{d}=250$ Hz) (ii) second column
    - high mobility ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$ Hz) (iii) third
    column - very high mobility ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$
    Hz). The CNN refers to SR-CNN and DN-CNN in low and high/very high) mobility scenarios,
    respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: VI-C2 Mobility
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A degradation is observed in the overall performance of [ChannelNet](#id35.35.id35)
    and [TS-ChannelNet](#id29.29.id29) estimators as the mobility increases, while
    the WI-CNN estimators reveal a robustness against high mobility, as illustrated
    in Figure¬†[11](#S6.F11 "Figure 11 ‚Ä£ VI-B2 Mobility ‚Ä£ VI-B DL-Based SBS Estimation
    Schemes ‚Ä£ VI Simulation Results ‚Ä£ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments"). This is primarily attributed to the accuracy
    of the [WI](#id37.37.id37) interpolation, coupled with optimized [SR-CNN](#id25.25.id25)
    and [DN-CNN](#id26.26.id26). Although [CNN](#id28.28.id28) processing is implemented
    in the [ChannelNet](#id35.35.id35) and [TS-ChannelNet](#id29.29.id29), this post
    [CNN](#id28.28.id28) processing is unable to perform well due to the high estimation
    error of the 2D RBF and ADD-TT interpolation techniques in the initial estimation.
    Therefore, it can be concluded that employing robust initial estimation as the
    [WI](#id37.37.id37) interpolation schemes allows the [CNN](#id28.28.id28) to better
    learn the channel correlation with lower complexity, thereby enhancing the channel
    estimation.
  prefs: []
  type: TYPE_NORMAL
- en: VI-C3 Frame Length
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Figure¬†[13](#S6.F13 "Figure 13 ‚Ä£ VI-C1 Modulation Order ‚Ä£ VI-C DL-Based FBF
    estimation Scheme ‚Ä£ VI Simulation Results ‚Ä£ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments") illustrates the [BER](#id64.64.id64)
    performance of high mobility vehicular scenario employing QPSK modulation and
    different frame lengths. As can be clearly observed, the WI-FP-ALS estimator outperforms
    ChannelNet and TS-ChannelNet for different frame lengths without any post CNN
    processing. This is because of the long codeword that shows the robustness of
    the WI-FP-ALS estimator, unlike the 2D RBF and ADD-TT interpolation techniques
    that suffer from a significant estimation error even when considering a short
    frame. Moreover, employing the optimized DN-CNN after the WI-FP-ALS estimator
    significantly enhances the BER performance.
  prefs: []
  type: TYPE_NORMAL
- en: However, although [CNN](#id28.28.id28) processing is applied in the [ChannelNet](#id35.35.id35)
    and [TS-ChannelNet](#id29.29.id29), this post [CNN](#id28.28.id28) processing
    is unable to perform well. This is attributed to the high estimation error of
    the 2D RBF and ADD-TT interpolation techniques in the initial estimation. Thus,
    we can conclude that employing robust initial estimation as the [WI](#id37.37.id37)
    interpolation schemes enable the [CNN](#id28.28.id28) to better learn the channel
    correlation with lower complexity, thereby enhancing the channel estimation, as
    shown in Figure¬†[12](#S6.F12 "Figure 12 ‚Ä£ VI-C DL-Based FBF estimation Scheme
    ‚Ä£ VI Simulation Results ‚Ä£ A Survey on Deep Learning based Channel Estimation in
    Doubly Dispersive Environments").
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/897b4f1b13ea559402809c59e5186937.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: NMSE performance employing three scenarios: (i) first column - low
    mobility ($v=45\leavevmode\nobreak\ \text{Kmph},f_{d}=250$ Hz) (ii) second column
    - high mobility ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$ Hz) (iii) third
    column - very high mobility ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$
    Hz). The CNN refers to SR-CNN and DN-CNN in low and high/very high) mobility scenarios,
    respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: VI-D CNN Architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The [ChannelNet](#id35.35.id35) estimator employs [SR-CNN](#id25.25.id25) and
    [DN-CNN](#id26.26.id26) following the 2D RBF interpolation. The employed [SR-CNN](#id25.25.id25)
    comprises three convolutional layers with $(v_{1}=9;f_{1}=64),(v_{2}=1,f_{2}=32)$
    and $(v_{3}=5,f_{3}=1)$, respectively. Moreover, the [DN-CNN](#id26.26.id26) depth
    is $D=18$ with $3\times 3\times 32$ kernels in each layer. Meanwhile, [SR-ConvLSTM](#id39.39.id39)
    network comprises three ConvLSTM layers of $(v_{1}=9;f_{1}=64),(v_{2}=1,f_{2}=32)$
    and $(v_{3}=5,f_{3}=1)$, respectively, and is integrated after the ADD-TT interpolation
    in the [TS-ChannelNet](#id29.29.id29) estimator. The [SR-ConvLSTM](#id39.39.id39)
    network combines both the [CNN](#id28.28.id28) and the LSTM networks[[51](#bib.bib51)],
    thus increasing the overall computational complexity, as shall be discussed later.
    By contrast, the employed optimized SR-CNN and DN-CNN significantly reduces the
    complexity due to the WI estimators‚Äô accuracy. Put succinctly, the complexity
    of the employed CNN decreases as the accuracy of the pre-estimation increases,
    because low-complexity architectures can be utilized and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: VI-E DL-Based SBS vs. DL-Based FBF estimation Scheme
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section further examines the performance assessment of the studied estimators,
    where only the best DL-based SBS and FBF estimators are compared. Figures [14](#S6.F14
    "Figure 14 ‚Ä£ VI-C1 Modulation Order ‚Ä£ VI-C DL-Based FBF estimation Scheme ‚Ä£ VI
    Simulation Results ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly
    Dispersive Environments") and[15](#S6.F15 "Figure 15 ‚Ä£ VI-C3 Frame Length ‚Ä£ VI-C
    DL-Based FBF estimation Scheme ‚Ä£ VI Simulation Results ‚Ä£ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments") illustrate the BER
    and NMSE performance of the investigated [DL](#id96.96.id96)-based estimators
    in low, high, and very high mobility scenarios, employing QPSK and 16QAM modulation
    orders.
  prefs: []
  type: TYPE_NORMAL
- en: In low-mobility scenario, the LSTM-DPA-TA [SBS](#id22.22.id22) estimator outperforms
    the WI-FP-ALS-SR-CNN FBF estimator. This can be explained by the ability of LSTM
    to better learn the channel time correlation than the SR-CNN, since Doppler error
    is somehow negligible in low mobility scenario. However, in high and very high
    mobility scenarios, WI-FP-ALS-DN-CNN shows a significantly improved performance,
    outperforming the LSTM-DPA-TA SBS estimator by $3$ dB gain in terms of SNR for
    a BER = $10^{-4}$. In high mobility scenarios, where the Doppler error impact
    is high, LSTM suffers from some performance degradation as learning the time correlation
    between successive samples is not achievable in the low mobility scenario case.
    Meanwhile, DN-CNN network can significantly alleviate the impact of noise and
    Doppler error, where it records at least $5$ dB gain in terms of SNR for a BER
    = $10^{-4}$. To conclude, it can be inferred that employing LSTM network rather
    than FNN and DN-CNN networks leads to improved performance in low-mobility scenarios.
    In By contrast, DN-CNN is more useful in high as well as very high mobility scenarios
    because DN-CNN uses the entire pilot subcarriers within the received frame. To
    summarize, the time correlation between successive received OFDM symbols decreases
    as the mobility increases. Therefore, the performance of LSTM suffers from performance
    degradation when compared with CNN. On the other hand, the CNN-based estimators
    become more useful than the LSTM-based estimators in high mobility scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it is observes that DL-based FBF estimators suffer from high buffering
    time at the receiver, because it is necessary to receive the full frame before
    the channel estimation begins leading to high latency. However, this buffering
    time is lowered in the WI-CNN estimators after dividing the received frame into
    sub frames so that the channel estimation process commences prior to the full
    frame reception. Moreover, the WI-CNN estimators also help increase the transmission
    data rate as fewer pilots are inserted into the transmitted frame.
  prefs: []
  type: TYPE_NORMAL
- en: VII Complexity Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section provides a detailed computational complexity analysis of the studied
    [DL](#id96.96.id96)-based [SBS](#id22.22.id22) and [FBF](#id23.23.id23) estimators.
    The computational complexity analysis is performed in accordance with the number
    of real-valued arithmetic operations, multiplication/division and summation/subtraction
    necessary to estimate the channel for one received [OFDM](#id208.208.id208) frame.
    Each complex-valued division requires $6$ real-valued multiplications, $2$ divisions,
    $2$ summations, and $1$ subtraction. In addition, each complex-valued multiplication
    is performed by $4$ real-valued multiplications and $3$ summations.
  prefs: []
  type: TYPE_NORMAL
- en: <svg  class="ltx_picture ltx_centering" height="280.85" overflow="visible"
    version="1.1" width="1187.02" color="#000000"><g transform="translate(0,280.85)
    matrix(1 0 0 -1 0 0) translate(49.01,0) translate(0,24.86) matrix(1.0 0.0 0.0
    1.0 -49.01 -24.86)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0) translate(143.83,0) translate(0,-517.67)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -53.62
    522.28)" fill="#000000" stroke="#000000"><foreignobject width="107.24" height="9.46"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">LSTM-FNN-DPA</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 188.69 522.28)" fill="#000000" stroke="#000000"><foreignobject
    width="97.82" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">LSTM-DPA-TA</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 442.24 522.28)" fill="#000000" stroke="#000000"><foreignobject
    width="63.61" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">DPA-FNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 676.77 522.28)" fill="#000000" stroke="#000000"><foreignobject
    width="68.61" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">TRFI-FNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 917.45 522.28)" fill="#000000" stroke="#000000"><foreignobject
    width="61.31" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">STA-FNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -117.42 615.91)" fill="#000000" stroke="#000000"><foreignobject
    width="17.71" height="11.41" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10^{6}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -117.42 719.51)" fill="#000000" stroke="#000000"><foreignobject
    width="17.71" height="11.41" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10^{7}$</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 -129.61 576.97)" fill="#000000" stroke="#000000"><foreignobject
    width="145.21" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Real-Valued
    Operations</foreignobject></g><g fill="#FFFFFF" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 277.35 777.48)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0
    -1 0 8.995)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 8.99)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    13.01 0) translate(79.27,0) matrix(1.0 0.0 0.0 1.0 -76.51 -4.15)" fill="#000000"
    stroke="#000000"><foreignobject width="153.01" height="13.84" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Multiplications/Divisions</foreignobject></g><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    184.56 0) translate(81.66,0) matrix(1.0 0.0 0.0 1.0 -78.89 -4.15)" fill="#000000"
    stroke="#000000"><foreignobject width="157.78" height="13.84" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Summations/Subtractions</foreignobject></g></g></g></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 16: Computational complexity comparison of the studied DL-based SBS
    estimators.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table VI: Detailed computation complexity of the studied DL-based SBS estimators.'
  prefs: []
  type: TYPE_NORMAL
- en: Estimator Mul./Div. Sum./Sub. FNN($J_{2}$-$J_{3}$-$J_{4}$) $2K_{\text{on}}J_{2}$
    + $J_{2}J_{3}$ + $J_{3}J_{4}$ + $2K_{\text{on}}J_{4}$ $2K_{\text{on}}J_{2}$ +
    $J_{2}J_{3}$ + $J_{3}J_{4}$ +$2K_{\text{on}}J_{4}$ LSTM ($P$) $P^{2}+3P+PK_{in}$
    $4P+K_{in}-2$ Overall channel estimation STA-FNN $82K_{\text{on}}+2K_{d}+450$
    $70K_{\text{on}}+10K_{d}+450$ TRFI-FNN $94K_{\text{on}}+26K_{\text{int}}+450$
    $74K_{\text{on}}+30K_{\text{int}}+450$ DPA-FNN $178K_{\text{on}}+1600$ $168K_{\text{on}}+1600$
    LSTM-FNN-DPA $512K_{\text{in}}+98K_{d}+71040$ $4K_{\text{in}}+88K_{d}+6776$ LSTM-DPA-TA($64$)
    $514K_{on}+18K_{d}+16576$ $10K_{on}+8K_{d}+824$ LSTM-DPA-TA($128$) $1026K_{on}+18K_{d}+65920$
    $10K_{on}+8K_{d}+1656$
  prefs: []
  type: TYPE_NORMAL
- en: VII-A DL-Based SBS Estimators
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The [DPA](#id16.16.id16) estimation implemented in the DL-based [SBS](#id22.22.id22)
    estimators as an initial step needs two equalization steps¬†([23](#S4.E23 "In IV-A
    DPA-FNN ‚Ä£ IV DL-Based SBS Channel Estimation ‚Ä£ A Survey on Deep Learning based
    Channel Estimation in Doubly Dispersive Environments")), and¬†([25](#S4.E25 "In
    IV-A DPA-FNN ‚Ä£ IV DL-Based SBS Channel Estimation ‚Ä£ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments")). Each equalization
    step comprises $K_{\text{on}}$ complex-valued divisions. Moreover, it needs the
    LS estimated channel at the preamble computed by $2K_{\text{on}}$ summation and
    $2K_{\text{on}}$ divisions. Hence, the overall computational complexity of the
    [DPA](#id16.16.id16) estimation is $16K_{\text{on}}$ multiplications/divisions
    and $6K_{\text{on}}$ summations/subtractions.
  prefs: []
  type: TYPE_NORMAL
- en: The [STA](#id17.17.id17) estimator applies frequency as well as time-domain
    averaging in addition to [DPA](#id16.16.id16). The frequency-domain averaging¬†([26](#S4.E26
    "In IV-B STA-FNN ‚Ä£ IV DL-Based SBS Channel Estimation ‚Ä£ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments")) coefficient is fixed
    ($\beta=2$). Thus, each subcarrier requires $5$ complex-valued summations multiplied
    by a real-valued weight, which, in turn, are equivalent to $10$ real-valued summations,
    and $2$ real-valued multiplications. Consequently, the [STA](#id17.17.id17) frequency-domain
    averaging step requires $10K_{d}$ real-valued summations, and $2K_{d}$ real-valued
    multiplications. The [STA](#id17.17.id17) time-domain averaging step¬†([27](#S4.E27
    "In IV-B STA-FNN ‚Ä£ IV DL-Based SBS Channel Estimation ‚Ä£ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments")) requires $4K_{\text{on}}$
    real-valued divisions, and $2K_{\text{on}}$ real-valued summations. For this reason,
    the accumulated overall computational complexity of [STA](#id17.17.id17) estimator
    is $22K_{\text{on}}+2K_{\text{d}}$ multiplications/divisions and $10K_{\text{on}}+10K_{\text{d}}$
    summations/subtractions.
  prefs: []
  type: TYPE_NORMAL
- en: The [TRFI](#id19.19.id19) estimator implements another two equalization steps
    after the [DPA](#id16.16.id16) estimation¬†([28](#S4.E28 "In 1st item ‚Ä£ IV-C TRFI-FNN
    ‚Ä£ IV DL-Based SBS Channel Estimation ‚Ä£ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments")). Thereafter, it applies cubic
    interpolation as the last step. Based on the analysis performed in¬†[[28](#bib.bib28)],
    the computational complexity of [TRFI](#id19.19.id19) is $34K_{\text{on}}+26K_{\text{int}}$
    multiplications/divisions and $14K_{\text{on}}+30K_{\text{int}}$ summations/subtractions,
    where $K_{\text{int}}$ represents the number of unreliable subcarriers in each
    received [OFDM](#id208.208.id208) symbol.
  prefs: []
  type: TYPE_NORMAL
- en: VII-A1 FNN-based Estimators
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For the FNN-based estimators, the DPA-FNN architecture¬†[[27](#bib.bib27)] consists
    of three hidden layers with $J_{1}=J_{5}=2K_{\text{on}}$, $J_{2}=J_{4}=40$, and
    $J_{3}=20$ neurons, respectively. Therefore, the DPA-FNN requires $4K_{\text{on}}J_{2}+2J_{2}J_{3}$
    multiplications, and $2K_{\text{on}}+2J_{2}+J_{3}$ summations. The computational
    complexity of [LS](#id172.172.id172) and the DPA estimation are accumulated for
    DPA-FNN computational complexity resulting in total of $178K_{\text{on}}+1600$
    multiplications and $168K_{\text{on}}+1600$ summations/subtractions.
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $CC_{\text{FNN}}=2\sum_{l=0}^{L+1}{N}_{l-1}{N}_{l},\leavevmode\nobreak\
    \mbox{where }{N}_{0}={N}_{L+1}=2K_{\text{on}}.$ |  | (54) |'
  prefs: []
  type: TYPE_TB
- en: The STA-FNN and TRFI-FNN estimators employ a three-hidden layer FNN architecture
    consisting of $15$ neurons each. This FNN architecture requires $4K_{\text{on}}J_{2}+2J_{2}^{2}$,
    and $2K_{\text{on}}+3J_{2}$ summations. This architecture is less complex when
    compared with the DPA-FNN one. Thus, the [STA](#id17.17.id17)-[FNN](#id99.99.id99)
    overall computational complexity is $82K_{\text{on}}+2K_{d}+450$ multiplications,
    and $70K_{\text{on}}+10K_{d}+450$ summations/subtractions. Furthermore, the TRFI-FNN
    needs $94K_{\text{on}}+26K_{\text{int}}+450$ multiplications, and $74K_{\text{on}}+30K_{\text{int}}+450$
    summations/subtractions. The [TRFI](#id19.19.id19)-[FNN](#id99.99.id99) estimator
    reduces the number of multiplications as well as summations by $48\%$ and $56\%$,
    respectively, when compared with DPA-[FNN](#id99.99.id99), while its computational
    complexity is similar to that of [STA](#id17.17.id17)-[FNN](#id99.99.id99).
  prefs: []
  type: TYPE_NORMAL
- en: VII-A2 LSTM-Based Estimators
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The computational complexity of the [LSTM](#id32.32.id32) unit can be calculated
    with respect to the number of operations performed by its four gates. Each gate
    applies $P^{2}+PK_{in}$ real-valued multiplications and $3P+K_{in}-2$ summations
    apart from $3P$ multiplications, and $P$ summations required by¬†([19](#S3.E19
    "In Update the new cell state ‚Ä£ III-B LSTM ‚Ä£ III DL Techniques Overview ‚Ä£ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")),
    and¬†([21](#S3.E21 "In Generate the LSTM unit output ‚Ä£ III-B LSTM ‚Ä£ III DL Techniques
    Overview ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments")). As a result, the overall computational complexity for the [LSTM](#id32.32.id32)
    becomes
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $CC_{\text{LSTM}}=4(P^{2}+PK_{\text{in}}+3P+K_{\text{in}}-2)+4P.$ |  |
    (55) |'
  prefs: []
  type: TYPE_TB
- en: Notably, [FNN](#id99.99.id99)-based estimators need less computation than [LSTM](#id32.32.id32),
    thus achieving lower complexity.
  prefs: []
  type: TYPE_NORMAL
- en: <svg  class="ltx_picture ltx_centering" height="281" overflow="visible"
    version="1.1" width="1187.02" color="#000000"><g transform="translate(0,281) matrix(1
    0 0 -1 0 0) translate(49.01,0) translate(0,25.01) matrix(1.0 0.0 0.0 1.0 -49.01
    -25.01)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0) translate(143.83,0) translate(0,-408.99)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -35.94
    413.6)" fill="#000000" stroke="#000000"><foreignobject width="71.88" height="9.61"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">ChannelNet</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 268.95 413.6)" fill="#000000" stroke="#000000"><foreignobject
    width="94.17" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">TS-ChannelNet</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 576.72 413.76)" fill="#000000" stroke="#000000"><foreignobject
    width="110.7" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">FP-ALS-DN-CNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 894.29 413.76)" fill="#000000" stroke="#000000"><foreignobject
    width="107.62" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">FP-ALS-SR-CNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -117.42 462.4)" fill="#000000" stroke="#000000"><foreignobject
    width="17.71" height="11.41" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10^{7}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -117.42 529.28)" fill="#000000" stroke="#000000"><foreignobject
    width="17.71" height="11.41" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10^{8}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -117.42 596.15)" fill="#000000" stroke="#000000"><foreignobject
    width="17.71" height="11.41" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10^{9}$</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 -129.61 468.45)" fill="#000000" stroke="#000000"><foreignobject
    width="145.21" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Real-Valued
    Operations</foreignobject></g><g fill="#FFFFFF" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 277.35 668.96)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0
    -1 0 8.995)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 8.99)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    13.01 0) translate(79.27,0) matrix(1.0 0.0 0.0 1.0 -76.51 -4.15)" fill="#000000"
    stroke="#000000"><foreignobject width="153.01" height="13.84" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Multiplications/Divisions</foreignobject></g><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    184.56 0) translate(81.66,0) matrix(1.0 0.0 0.0 1.0 -78.89 -4.15)" fill="#000000"
    stroke="#000000"><foreignobject width="157.78" height="13.84" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Summations/Subtractions</foreignobject></g></g></g></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 17: Computational complexity comparison of the studied DL-based FBF
    estimators.'
  prefs: []
  type: TYPE_NORMAL
- en: The [LSTM](#id32.32.id32)-[FNN](#id99.99.id99)-[DPA](#id16.16.id16) estimator
    employs one [LSTM](#id32.32.id32) unit with $P=128$ and $K_{in}=112$, followed
    by one hidden layer [FNN](#id99.99.id99) network with $N_{1}=40$ neurons. In addition,
    the [LSTM](#id32.32.id32)-[FNN](#id99.99.id99)-[DPA](#id16.16.id16) estimator
    implements the [DPA](#id16.16.id16) estimation that requires $18K_{d}$ real-valued
    multiplication/division and $8K_{d}$ summation/subtraction. Thus, the overall
    computational complexity of the [LSTM](#id32.32.id32)-[FNN](#id99.99.id99)-[DPA](#id16.16.id16)
    estimator is $512K_{\text{in}}+98K_{d}+71040$ multiplication/division and $4K_{\text{in}}+88K_{d}+6776$
    summation/subtraction.
  prefs: []
  type: TYPE_NORMAL
- en: The [LSTM](#id32.32.id32)-[DPA](#id16.16.id16)-[TA](#id46.46.id46) utilizes
    one [LSTM](#id32.32.id32) unit with $P=128$ as [LSTM](#id32.32.id32)-[FNN](#id99.99.id99)-[DPA](#id16.16.id16)
    estimator. It also uses $K_{in}=2K_{on}$, and applies [TA](#id46.46.id46) as a
    noise alleviation technique to the $\hat{\bar{\bm{h}}}_{\text{LSTM-DPA}_{i,d}}$
    estimated channel, that requires only $2K_{on}$ real-valued multiplication/division
    and $2K_{on}$ summation/subtraction. Hence, the [LSTM](#id32.32.id32)-[DPA](#id16.16.id16)-[TA](#id46.46.id46)
    estimator requires $4P^{2}+P(8K_{on}+3)+18K_{d}+2K_{on}$ real-valued multiplication/division
    and $13P+10K_{on}+8K_{d}-8$ summation/subtraction. As per this analysis, the [LSTM](#id32.32.id32)-[DPA](#id16.16.id16)-[TA](#id46.46.id46)
    estimator achieves less computational complexity in comparison to the [LSTM](#id32.32.id32)-[FNN](#id99.99.id99)-[DPA](#id16.16.id16)
    estimator. It records $9.73\%$ and $77.63\%$ computational complexity decline
    in the required real-valued multiplication/division and summation/subtraction,
    respectively. Importantly, replacing the [FNN](#id99.99.id99) network by the [TA](#id46.46.id46)
    to achieve noise alleviation is the primary factor in reducing the overall computational
    complexity. Moreover, the [LSTM](#id32.32.id32)-[DPA](#id16.16.id16)-[TA](#id46.46.id46)
    estimator outperforms the [LSTM](#id32.32.id32)-[FNN](#id99.99.id99)-[DPA](#id16.16.id16)
    estimator while recording lower computational complexity. As a matter of fact,
    employing the [LSTM](#id32.32.id32)-[DPA](#id16.16.id16)-[TA](#id46.46.id46) LSTM-based
    estimators as opposed to the FNN-based estimators results in $89.10\%$ and $62.18\%$
    increase in the necessary multiplication/division and summation/subtraction, respectively.
    Nevertheless, it is possible to achieve a significant performance gain. Table[VI](#S7.T6
    "Table VI ‚Ä£ VII Complexity Analysis ‚Ä£ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments") and Figure[16](#S7.F16 "Figure
    16 ‚Ä£ VII Complexity Analysis ‚Ä£ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments") reveal a detailed summary of the computational
    complexities for the various examined DL-based SBS estimators.
  prefs: []
  type: TYPE_NORMAL
- en: VII-B [DL](#id96.96.id96)-Based FBF Estimators
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: VII-B1 [ChannelNet](#id35.35.id35) estimator
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The [ChannelNet](#id35.35.id35) estimator utilizes the [RBF](#id27.27.id27)
    interpolation followed by [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26)
    networks. Therefore, the overall computational complexity of the [ChannelNet](#id35.35.id35)
    estimator can be expressed as follows
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{CC}_{{\text{ChannelNet}}}=\text{CC}_{{\text{RBF}}}+\text{CC}_{\text{SR-CNN}}+\text{CC}_{\text{DN-CNN}}.$
    |  | (56) |'
  prefs: []
  type: TYPE_TB
- en: The calculation of $\hat{\tilde{\bm{H}}}_{\text{LS}}$ requires $2K_{p}I$ divisions.
    The computation of $\bm{w}_{\text{RBF}}$ requires $4K^{2}_{p}I^{2}$ multiplications/divisions
    and $5K^{2}_{p}I^{2}-2K_{p}I$ summations/subtractions. Meanwhile, $\hat{\tilde{\bm{H}}}_{\text{RBF}}$
    requires $K_{d}I(K^{2}_{p}I^{2}+3K_{p}I)$ multiplications/divisions and $5K_{d}K_{p}I^{2}$
    subtractions/summations. Thus, the total computational complexity of the [RBF](#id27.27.id27)
    interpolation can be expressed by $K^{2}_{p}I^{2}(4+K_{d}I)+K_{p}I(2+3K_{d}I)$
    multiplications/divisions and $K_{p}I(5K_{p}I+5K_{d}I-2)$ summations/subtractions.
    Subsequently, the [ChannelNet](#id35.35.id35) estimator applies [SR-CNN](#id25.25.id25)
    followed by [DN-CNN](#id26.26.id26) in addition to the [RBF](#id27.27.id27) interpolation.
    $\text{CC}_{\text{SR-CNN}}$ and $\text{CC}_{\text{DN-CNN}}$ can be computed as
    follows
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\text{CC}_{\text{SR-CNN}}&amp;=\sum_{l=1}^{\mathcal{L}}h_{l}w_{l}d_{l}v_{l}^{2}f_{l}+h_{l}w_{l}d_{l}f_{l}\\
    &amp;=\sum_{l=1}^{\mathcal{L}}h_{l}w_{l}d_{l}f_{l}(v_{l}^{2}+1).\end{split}$ |  |
    (57) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\text{CC}_{\text{DN-CNN}}=\sum_{l=1}^{\mathcal{L}}h_{l}w_{l}d_{l}f_{l}(v_{l}^{2}+1)+\sum_{j=1}^{D}4h_{j}w_{j}d_{j}.$
    |  | (58) |'
  prefs: []
  type: TYPE_TB
- en: $\mathcal{L}$ signifies the number of employed [CNN](#id28.28.id28) layers.
    It can be noted that the second term in $\text{CC}_{\text{DN-CNN}}$ signifies
    the number of operations required by the batch normalization employed in the [DN-CNN](#id26.26.id26)
    network. Thus, the [SR-CNN](#id25.25.id25) employed in the [ChannelNet](#id35.35.id35)
    estimator needs $16064K_{\text{on}}I$ multiplications/divisions as well as $4288K_{\text{on}}I$
    summations/subtractions, while the [ChannelNet](#id35.35.id35)  [DN-CNN](#id26.26.id26)
    computations require $334080K_{\text{on}}I$ multiplications/divisions and $38144K_{\text{on}}I$
    summations/subtractions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table VII: Detailed computation complexity of the studied CNN-based FBF estimators.'
  prefs: []
  type: TYPE_NORMAL
- en: Scheme Interpolation CNN Mul./Div. Sum./Sub. Mul./Div. Sum./Sub. ChannelNet
    $K^{2}_{p}I^{2}(4+K_{d}I)$ + $K_{p}I(2+3K_{d}I)$ $K_{p}I(5K_{p}I$ + $5K_{d}I-2)$
    $350144K_{\text{on}}I$ $42432K_{\text{on}}I$ TS-ChannelNet $24K_{\text{on}}I+4LK_{\text{on}}I$
    $18K_{\text{on}}I$ + $5K_{\text{on}}IL$ $226880K_{\text{on}}I$ $81472K_{\text{on}}I$
    FP-SLS-SR-CNN $2K_{\text{on}}P+2K_{\text{on}}$ + $4K_{\text{on}}I_{d}$ $2K_{\text{on}}$
    + $2K_{\text{on}}I_{d}$ $7008K_{\text{on}}I_{d}$ $1120K_{\text{on}}I_{d}$ FP-ALS-SR-CNN
    $4K^{2}_{\text{on}}P+2K_{\text{on}}P$ + $2K_{\text{on}}+4K_{\text{on}}I_{d}$ $5K^{2}_{\text{on}}P$
    + $2K_{\text{on}}I_{d}$ LP-SR-CNN $2LP+4K_{\text{on}}LP$ + $2K_{\text{on}}+4K_{\text{on}}I_{d}$
    $5K_{\text{on}}LP$ + $2K_{\text{on}}I_{d}$ FP-SLS-DN-CNN $2K_{\text{on}}P+2K_{\text{on}}$
    + $4K_{\text{on}}I_{d}$ $2K_{\text{on}}$ + $2K_{\text{on}}I_{d}$ $84096K_{\text{on}}I_{d}$
    $9856K_{\text{on}}I_{d}$ FP-ALS-DN-CNN $4K^{2}_{\text{on}}P+2K_{\text{on}}P$ +
    $2K_{\text{on}}+4K_{\text{on}}I_{d}$ $5K^{2}_{\text{on}}P$ + $2K_{\text{on}}I_{d}$
    LP-DN-CNN $2LP+4K_{\text{on}}LP+2K_{\text{on}}$ + $4K_{\text{on}}I_{d}$ $5K_{\text{on}}LP$
    + $2K_{\text{on}}I_{d}$
  prefs: []
  type: TYPE_NORMAL
- en: VII-B2 [TS-ChannelNet](#id29.29.id29) estimator
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The [TS-ChannelNet](#id29.29.id29) estimator applies the [ADD-TT](#id36.36.id36)
    interpolation followed by the [SR-ConvLSTM](#id39.39.id39) network. Hence, the
    overall computational complexity of the [TS-ChannelNet](#id29.29.id29) estimator
    can be expressed in the following manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{CC}_{{\text{TS-ChannelNet}}}=\text{CC}_{{\text{ADD-TT}}}+\text{CC}_{\text{SR-ConvLSTM}}.$
    |  | (59) |'
  prefs: []
  type: TYPE_TB
- en: The [ADD-TT](#id36.36.id36) interpolation first applies the [DPA](#id16.16.id16)
    estimation requiring $18K_{\text{on}}$ multiplications/divisions and $8K_{\text{on}}$
    summations/subtractions. The time-domain truncation operation applied in¬†([43](#S5.E43
    "In V-B TS-ChannelNet ‚Ä£ V DL-Based FBF Channel Estimation Schemes ‚Ä£ A Survey on
    Deep Learning based Channel Estimation in Doubly Dispersive Environments")) requires
    $4LK_{\text{on}}$ multiplications as well as $5K_{\text{on}}L-2K_{\text{on}}$
    summations. In the [ADD-TT](#id36.36.id36) interpolation, the frequency-domain
    averaging¬†([44](#S5.E44 "In V-B TS-ChannelNet ‚Ä£ V DL-Based FBF Channel Estimation
    Schemes ‚Ä£ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments")) requires $10K_{\text{on}}$ summations and $2K_{\text{on}}$ multiplications.
    Furthermore, the time-domain averaging step¬†([45](#S5.E45 "In V-B TS-ChannelNet
    ‚Ä£ V DL-Based FBF Channel Estimation Schemes ‚Ä£ A Survey on Deep Learning based
    Channel Estimation in Doubly Dispersive Environments")) requires $4K_{\text{on}}$
    real valued divisions, and $2K_{\text{on}}$ real valued summations. Thus, the
    overall computational complexity of the [ADD-TT](#id36.36.id36) interpolation
    for the whole received [OFDM](#id208.208.id208) frame requires $24K_{\text{on}}I+4LK_{\text{on}}I$
    real-valued multiplications/divisions, and $18K_{\text{on}}I+5K_{\text{on}}IL$
    summations/subtractions. The total computational complexity is expressed with
    respect to the overall operations implemented in the input, forget, and output
    gates of the [SR-ConvLSTM](#id39.39.id39) network, such that
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{CC}_{\text{ConvLSTM}}=\sum_{l=1}^{\mathcal{L}}h_{l}w_{l}d_{l}f_{l}(8v_{l}^{2}+30).$
    |  | (60) |'
  prefs: []
  type: TYPE_TB
- en: Based on¬†([60](#S7.E60 "In VII-B2 estimator ‚Ä£ VII-B -Based FBF Estimators ‚Ä£
    VII Complexity Analysis ‚Ä£ A Survey on Deep Learning based Channel Estimation in
    Doubly Dispersive Environments")), the [SR-ConvLSTM](#id39.39.id39) network employed
    in the [TS-ChannelNet](#id29.29.id29) estimator requires $226880K_{\text{on}}I$
    multiplications/divisions as well as $81472K_{\text{on}}I$ summations/subtractions.
    [TS-ChannelNet](#id29.29.id29) estimator is less complicated than the [ChannelNet](#id35.35.id35)
    estimator, because it employs only one [CNN](#id28.28.id28) in addition to the
    [ADD-TT](#id36.36.id36) interpolation, unlike the [ChannelNet](#id35.35.id35)
    estimator where both [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26) are employed.
  prefs: []
  type: TYPE_NORMAL
- en: VII-B3 [WI](#id37.37.id37)-CNN estimators
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The [WI](#id37.37.id37)-CNN estimators computational complexity primarily depends
    on the selected frame structure, the pilot allocation scheme, as well as the selected
    optimized [CNN](#id28.28.id28). Thus, the overall computational complexity of
    the [WI](#id37.37.id37)-CNN estimators can be expressed as follows
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{CC}_{{\text{WI}}}=\text{CC}_{\hat{\tilde{\bm{H}}}_{\text{WI}}}+\text{CC}_{\text{O-CNN}}.$
    |  | (61) |'
  prefs: []
  type: TYPE_TB
- en: When full pilot symbols are inserted, two options are taken into consideration.
    The first option is the [SLS](#id34.34.id34) estimator, which is performed using
    $2K_{\text{on}}P+2K_{\text{on}}$ divisions, and $2K_{\text{on}}$ summations. The
    second option entails employing the [ALS](#id33.33.id33) estimator with $2K_{\text{on}}P+2K_{\text{on}}$
    divisions. This is followed by $4K^{2}_{\text{on}}P$ multiplications, and $5K^{2}_{\text{on}}P$
    summations. In the instance where $K_{\text{p}}=L$ pilots are inserted with each
    pilot symbol, the [LS](#id172.172.id172) estimation requires $2LP+2K_{\text{on}}$
    divisions, $4K_{\text{on}}LP$ multiplications, and $5K_{\text{on}}LP$ summations.
    In a similar manner, for employing only $K_{p}=4$ pilot subcarriers, the WI-CP
    estimator needs $8P+2K_{\text{on}}$ divisions, $16K_{\text{on}}P$ multiplications,
    as well as $20K_{\text{on}}P$ summations. Following the selection of the required
    frame structure and pilot allocation scheme, the WI-CNN estimators apply the weighted
    interpolation as demonstrated in¬†([50](#S5.E50 "In 2nd item ‚Ä£ V-C WI-CNN ‚Ä£ V DL-Based
    FBF Channel Estimation Schemes ‚Ä£ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments")).The channel estimation for each received
    [OFDM](#id208.208.id208) frame needs $4K_{\text{on}}I_{d}$ divisions and $2K_{\text{on}}I_{d}$
    summations. Finally, the optimized [SR-CNN](#id25.25.id25) is utilized in low-mobility
    scenario and needs $7008K_{\text{on}}I_{d}$ multiplications/divisions and $1120K_{\text{on}}I_{d}$
    summations/subtractions. For high-mobility scenarios, the optimized [DN-CNN](#id26.26.id26)
    is employed, requiring $84096K_{\text{on}}I_{d}$ multiplications/divisions and
    $9856K_{\text{on}}I_{d}$ summations/subtractions. The [WI](#id37.37.id37)-FP-ALS
    records the higher computational complexity among the other WI estimators in all
    mobility scenarios, due to $\bm{W}_{\text{ALS}}$ calculation in¬†([47](#S5.E47
    "In 1st item ‚Ä£ V-C WI-CNN ‚Ä£ V DL-Based FBF Channel Estimation Schemes ‚Ä£ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")),
    whereas, the [WI](#id37.37.id37)-FP-SLS estimator refers to the simplest one.
  prefs: []
  type: TYPE_NORMAL
- en: Table¬†[VII](#S7.T7 "Table VII ‚Ä£ VII-B1 estimator ‚Ä£ VII-B -Based FBF Estimators
    ‚Ä£ VII Complexity Analysis ‚Ä£ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments") shows the studied estimators‚Äô overall computational
    complexity with respect to real valued operations. It is noteworthy that the [WI](#id37.37.id37)
    estimators achieve significant computational complexity decrease in comparison
    to [ChannelNet](#id35.35.id35) and [TS-ChannelNet](#id29.29.id29) estimators.
    Figure[17](#S7.F17 "Figure 17 ‚Ä£ VII-A2 LSTM-Based Estimators ‚Ä£ VII-A DL-Based
    SBS Estimators ‚Ä£ VII Complexity Analysis ‚Ä£ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments") depicts the computational complexity
    of the studied DL-based FBF estimators. The [ChannelNet](#id35.35.id35) and [TS-ChannelNet](#id29.29.id29)
    estimators are $70$ and $39$ times more complex than the FP-ALS-SR-CNN, respectively.
    In addition, the WI-CNN estimators achieve a minimum of $7027.35$ times less complexity
    than the 2D LMMSE estimator, with an acceptable [BER](#id64.64.id64) performance,
    which makes them a feasible alternative to the 2D LMMSE. It is also observed that
    FP-ALS-DN-CNN is $12$ times more complex than FP-ALS-SR-CNN since the optimized
    [DN-CNN](#id26.26.id26) architecture complexity employed in high and very high
    scenarios is higher than the optimized [SR-CNN](#id25.25.id25) architecture, which,
    in turn, is employed in low mobility scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: VIII Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This survey sheds light on the recently proposed DL-based SBS and FBF channel
    estimators in doubly-dispersive environments. First, we have defined the problem
    of signal propagation in doubly-dispersive channels. Subsequently, a review of
    different DL architectures employed in the doubly-dispersive channel estimation
    has been undertaken, followed by a detailed presentation of the studied DL-based
    estimators. Finally, the studied estimators have been evaluated with respect to
    [NMSE](#id204.204.id204), [BER](#id64.64.id64), and computational complexity,
    clearly demonstrating a significant improvement of employing DL in the channel
    estimation across different mobility conditions. We have shown that, while the
    LSTM and CNN based estimators do outperform the FNN based estimator, more computational
    complexity is necessary where the LSTM-based SBS estimator is $23.6$ times more
    complex than the FNN-based SBS estimators. Nevertheless, the complexity of the
    CNN-based FBF estimator exceeds the complexity of LSTM-based SBS estimator by
    approximately $3450$ times because of the significant difference in terms of required
    operations between the CNN and LSTM networks. Finally, we have observed that the
    choice of the channel estimator is primarily related to the applications requirements
    as well as affordable computational complexity. SBS estimators are more useful
    when the application is sensitive to latency, whereas FBF estimators can be employed
    if some latency can be accepted. To summarize, a trade-off between the required
    performance, computational complexity, and the accepted latency must first be
    defined to select what is the most suitable channel estimator to be employed.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] H.¬†Chang, C.-X. Wang, Y.¬†Liu, J.¬†Huang, J.¬†Sun, W.¬†Zhang, and X.¬†Gao, ‚ÄúA
    Novel Nonstationary 6G UAV-to-Ground Wireless Channel Model With 3-D Arbitrary
    Trajectory Changes,‚Äù *IEEE Internet of Things Journal*, vol.¬†8, no.¬†12, pp. 9865‚Äì9877,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] L.¬†Wang, B.¬†Ai, K.¬†Guan, D.¬†He, Z.¬†Zhong, L.¬†Tian, and J.¬†Dou, ‚ÄúStochastic
    Channel Modeling for High-Speed Railway Viaduct Scenario at 93.2 GHz,‚Äù in *12th
    European Conference on Antennas and Propagation (EuCAP 2018)*, 2018, pp. 1‚Äì4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] B.¬†Turan and S.¬†Coleri, ‚ÄúMachine Learning Based Channel Modeling for Vehicular
    Visible Light Communication,‚Äù *IEEE Transactions on Vehicular Technology*, vol.¬†70,
    no.¬†10, pp. 9659‚Äì9672, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] R.¬†Chen, W.¬†Yang, F.¬†Wu, and M.¬†Sun, ‚ÄúFast Handover for High-Speed Railway
    via NDN,‚Äù in *2018 1st IEEE International Conference on Hot Information-Centric
    Networking (HotICN)*, 2018, pp. 167‚Äì172.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] S.¬†Wang and Q.¬†Zhang, ‚ÄúA Joint Time-Frequency Domain Frequency Offset Estimation
    Algorithm for Busrt Communication,‚Äù in *2020 IEEE 3rd International Conference
    on Electronics Technology (ICET)*, 2020, pp. 1‚Äì5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] T.¬†Ma, X.¬†Jiang, Y.¬†Wang, and F.¬†Li, ‚ÄúA Novel Inter-Carrier Interference
    Cancellation Scheme in Highly Mobile Environments,‚Äù *China Communications*, vol.¬†17,
    no.¬†12, pp. 194‚Äì205, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] K.¬†Saito, Q.¬†Fan, N.¬†Keerativoranan, and J.-i. Takada, ‚Äú4.9 GHz Band Outdoor
    to Indoor Propagation Loss Analysis in High Building Environment Using Unmanned
    Aerial Vehicle,‚Äù in *2019 13th European Conference on Antennas and Propagation
    (EuCAP)*, 2019, pp. 1‚Äì4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] R.¬†Bomfin, M.¬†Chafii, A.¬†Nimr, and G.¬†Fettweis, ‚ÄúA Robust Baseband Transceiver
    Design for Doubly-Dispersive Channels,‚Äù *IEEE Transactions on Wireless Communications*,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] ‚Äî‚Äî, ‚ÄúA Robust Baseband Transceiver Design for Doubly-Dispersive Channels,‚Äù
    *IEEE Transactions on Wireless Communications*, vol.¬†20, no.¬†8, pp. 4781‚Äì4796,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] R.¬†Bomfin, A.¬†Nimr, M.¬†Chafii, and G.¬†Fettweis, ‚ÄúA Robust and Low-Complexity
    Walsh-Hadamard Modulation for Doubly-Dispersive Channels,‚Äù *IEEE Communications
    Letters*, vol.¬†25, no.¬†3, pp. 897‚Äì901, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] A.¬†Nimr, M.¬†Chafii, M.¬†Matthe, and G.¬†Fettweis, ‚ÄúExtended GFDM Framework:
    OTFS and GFDM Comparison,‚Äù in *2018 IEEE Global Communications Conference (GLOBECOM)*,
    2018, pp. 1‚Äì6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] M.¬†Chafii, J.¬†Palicot, R.¬†Gribonval, and F.¬†Bader, ‚ÄúAdaptive Wavelet Packet
    Modulation,‚Äù *IEEE Transactions on Communications*, vol.¬†66, no.¬†7, pp. 2947‚Äì2957,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] J.¬†A. Fernandez, K.¬†Borries, L.¬†Cheng, B.¬†V.¬†K. Vijaya Kumar, D.¬†D. Stancil,
    and F.¬†Bai, ‚ÄúPerformance of the 802.11p Physical Layer in Vehicle-to-Vehicle Environments,‚Äù
    *IEEE Transactions on Vehicular Technology*, vol.¬†61, no.¬†1, pp. 3‚Äì14, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Z.¬†Zhao, X.¬†Cheng, M.¬†Wen, B.¬†Jiao, and C.¬†Wang, ‚ÄúChannel Estimation Schemes
    for IEEE 802.11p Standard,‚Äù *IEEE Intelligent Transportation Systems Magazine*,
    vol.¬†5, no.¬†4, pp. 38‚Äì49, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] Yoon-Kyeong Kim, Jang-Mi Oh, Yoo-Ho Shin, and Cheol Mun, ‚ÄúTime and Frequency
    Domain Channel Estimation Scheme for IEEE 802.11p,‚Äù in *17th International IEEE
    Conference on Intelligent Transportation Systems (ITSC)*, 2014, pp. 1085‚Äì1090.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] S.¬†Ehsanfar, M.¬†Chafii, and G.¬†P. Fettweis, ‚ÄúOn UW-based Transmission
    for MIMO Multi-carriers with Spatial Multiplexing,‚Äù *IEEE Transactions on Wireless
    Communications*, vol.¬†19, no.¬†9, pp. 5875‚Äì5890, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Y.¬†Choi, J.¬†H. Bae, and J.¬†Lee, ‚ÄúLow-Complexity 2D LMMSE Channel Estimation
    for OFDM Systems,‚Äù in *2015 IEEE 82nd Vehicular Technology Conference (VTC2015-Fall)*,
    2015, pp. 1‚Äì5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] T.¬†Wang, C.-K. Wen, H.¬†Wang, F.¬†Gao, T.¬†Jiang, and S.¬†Jin, ‚ÄúDeep Learning
    for Wireless Physical Layer: Opportunities and Challenges,‚Äù 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] T.¬†O‚ÄôShea and J.¬†Hoydis, ‚ÄúAn Introduction to Deep Learning for the Physical
    Layer,‚Äù *IEEE Transactions on Cognitive Communications and Networking*, vol.¬†3,
    no.¬†4, pp. 563‚Äì575, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] M.¬†Chafii, F.¬†Bader, and J.¬†Palicot, ‚ÄúEnhancing Coverage in Narrow Band-IoT
    Using Machine Learning,‚Äù in *2018 IEEE Wireless Communications and Networking
    Conference (WCNC)*.¬†¬†¬†IEEE, 2018, pp. 1‚Äì6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Y.¬†Yang, F.¬†Gao, X.¬†Ma, and S.¬†Zhang, ‚ÄúDeep Learning-Based Channel Estimation
    for Doubly Selective Fading Channels,‚Äù *IEEE Access*, vol.¬†7, pp. 36‚Äâ579‚Äì36‚Äâ589,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] X.¬†Ma, H.¬†Ye, and Y.¬†Li, ‚ÄúLearning Assisted Estimation for Time- Varying
    Channels,‚Äù in *2018 15th International Symposium on Wireless Communication Systems
    (ISWCS)*, 2018, pp. 1‚Äì5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] H.¬†Ye, G.¬†Y. Li, and B.¬†Juang, ‚ÄúPower of Deep Learning for Channel Estimation
    and Signal Detection in OFDM Systems,‚Äù *IEEE Wireless Communications Letters*,
    vol.¬†7, no.¬†1, pp. 114‚Äì117, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] J.¬†Yuan, H.¬†Q. Ngo, and M.¬†Matthaiou, ‚ÄúMachine Learning-Based Channel
    Prediction in Massive MIMO With Channel Aging,‚Äù *IEEE Transactions on Wireless
    Communications*, vol.¬†19, no.¬†5, pp. 2960‚Äì2973, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] H.¬†Kim, S.¬†Kim, H.¬†Lee, C.¬†Jang, Y.¬†Choi, and J.¬†Choi, ‚ÄúMassive MIMO Channel
    Prediction: Kalman Filtering Vs. Machine Learning,‚Äù *IEEE Transactions on Communications*,
    vol.¬†69, no.¬†1, pp. 518‚Äì528, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] C.¬†Wu, X.¬†Yi, Y.¬†Zhu, W.¬†Wang, L.¬†You, and X.¬†Gao, ‚ÄúChannel Prediction
    in High-Mobility Massive MIMO: From Spatio-Temporal Autoregression to Deep Learning,‚Äù
    *IEEE Journal on Selected Areas in Communications*, vol.¬†39, no.¬†7, pp. 1915‚Äì1930,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] S.¬†Han, Y.¬†Oh, and C.¬†Song, ‚ÄúA Deep Learning Based Channel Estimation
    Scheme for IEEE 802.11p Systems,‚Äù in *ICC 2019 - 2019 IEEE International Conference
    on Communications (ICC)*, 2019, pp. 1‚Äì6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] A.¬†K. Gizzini, M.¬†Chafii, A.¬†Nimr, and G.¬†Fettweis, ‚ÄúDeep Learning Based
    Channel Estimation Schemes for IEEE 802.11p Standard,‚Äù *IEEE Access*, vol.¬†8,
    pp. 113‚Äâ751‚Äì113‚Äâ765, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] ‚Äî‚Äî, ‚ÄúJoint TRFI and Deep Learning for Vehicular Channel Estimation,‚Äù in
    *2020 IEEE Globecom Workshops (GC Wkshps*, 2020, pp. 1‚Äì6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] M.¬†Soltani, V.¬†Pourahmadi, A.¬†Mirzaei, and H.¬†Sheikhzadeh, ‚ÄúDeep Learning-Based
    Channel Estimation,‚Äù *IEEE Communications Letters*, vol.¬†23, no.¬†4, pp. 652‚Äì655,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] X.¬†Zhu, Z.¬†Sheng, Y.¬†Fang, and D.¬†Guo, ‚ÄúA Deep Learning-Aided Temporal
    Spectral ChannelNet for IEEE 802.11p-Based Channel Estimation in Vehicular Communications,‚Äù
    *EURASIP Journal on Wireless Communications and Networking*, vol.¬†1, no.¬†94, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] A.¬†Karim¬†Gizzini, M.¬†Chafii, A.¬†Nimr, R.¬†M. Shubair, and G.¬†Fettweis,
    ‚ÄúCNN Aided Weighted Interpolation for Channel Estimation in Vehicular Communications,‚Äù
    *IEEE Transactions on Vehicular Technology*, vol.¬†70, no.¬†12, pp. 12‚Äâ796‚Äì12‚Äâ811,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] H.¬†A. Le, T.¬†Van¬†Chien, T.¬†H. Nguyen, H.¬†Choo, and V.¬†D. Nguyen, ‚ÄúMachine
    Learning-Based 5G-and-Beyond Channel Estimation for MIMO-OFDM Communication Systems,‚Äù
    *Sensors*, vol.¬†21, no.¬†14, 2021\. [Online]. Available: https://www.mdpi.com/1424-8220/21/14/4861'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] F.¬†Tang, B.¬†Mao, N.¬†Kato, and G.¬†Gui, ‚ÄúComprehensive survey on machine
    learning in vehicular network: Technology, applications and challenges,‚Äù *IEEE
    Communications Surveys Tutorials*, vol.¬†23, no.¬†3, pp. 2027‚Äì2057, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] A.¬†K. Gizzini, ‚ÄúDl-based channel estimation in doubly dispersive environments,‚Äù
    in *DL-based Channel Estimation in Doubly Dispersive Environments*, 2022\. [Online].
    Available: https://github.com/abdulkarimgizzini/DL-based-Channel-Estimation-in-Doubly-Dispersive-Environments-/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] G.¬†Matz and F.¬†Hlawatsch, ‚ÄúChapter 1 - fundamentals of time-varying communication
    channels,‚Äù in *Wireless Communications Over Rapidly Time-Varying Channels*, F.¬†Hlawatsch
    and G.¬†Matz, Eds.¬†¬†¬†Oxford: Academic Press, 2011, pp. 1‚Äì63\. [Online]. Available:
    https://www.sciencedirect.com/science/article/pii/B9780123744838000017'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] ‚Äî‚Äî, ‚ÄúChapter 1 - Fundamentals of Time-Varying Communication Channels,‚Äù
    in *Wireless Communications Over Rapidly Time-Varying Channels*, 2011, pp. 1‚Äì63.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] N.¬†D. Ricklin, ‚ÄúTime Varying Channels : Characterization, Estimation,
    and Detection,‚Äù Ph.D. dissertation, University of California, San Diego, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] J.¬†Schmidhuber, ‚ÄúDeep Learning in Neural Networks: An Overview,‚Äù *Neural
    Networks*, vol.¬†61, p. 85‚Äì117, Jan 2015\. [Online]. Available: http://dx.doi.org/10.1016/j.neunet.2014.09.003'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] S.¬†ichi Amari, ‚ÄúBackpropagation and Stochastic Gradient Descent Method,‚Äù
    *Neurocomputing*, vol.¬†5, no.¬†4, pp. 185 ‚Äì 196, 1993.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] S.¬†De, A.¬†Mukherjee, and E.¬†Ullah, ‚ÄúConvergence Guarantees for RMSProp
    and ADAM in Non-Convex Optimization and An Empirical Comparison to Nesterov Acceleration,‚Äù
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] S.¬†Ruder, ‚ÄúAn Overview of Multi-Task Learning in Deep Neural Networks,‚Äù
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] A.¬†K. Gizzini, M.¬†Chafii, S.¬†Ehsanfar, and R.¬†M. Shubair, ‚ÄúTemporal Averaging
    LSTM-based Channel Estimation Scheme for IEEE 802.11p Standard,‚Äù in *IEEE Global
    Communications Conference*, Madrid, Spain, Dec. 2021. [Online]. Available: https://hal.archives-ouvertes.fr/hal-03365697'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] K.¬†Greff, R.¬†K. Srivastava, J.¬†Koutn√≠k, B.¬†R. Steunebrink, and J.¬†Schmidhuber,
    ‚ÄúLSTM: A Search Space Odyssey,‚Äù *IEEE Transactions on Neural Networks and Learning
    Systems*, vol.¬†28, no.¬†10, pp. 2222‚Äì2232, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] S.¬†Albawi, T.¬†A. Mohammed, and S.¬†Al-Zawi, ‚ÄúUnderstanding of a Convolutional
    Neural Network,‚Äù in *2017 International Conference on Engineering and Technology
    (ICET)*, 2017, pp. 1‚Äì6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] A.¬†K. Gizzini, ‚ÄúAdvanced Linear and Deep Learning Based Channel Estimation
    Techniques in Doubly Dispersive Environments,‚Äù Theses, Cergy Paris CY Universit√©,
    Dec. 2021\. [Online]. Available: https://hal.archives-ouvertes.fr/tel-03482053'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] M.¬†Sun, Z.¬†Song, X.¬†Jiang, J.¬†Pan, and Y.¬†Pang, ‚ÄúLearning Pooling for
    Convolutional Neural Network,‚Äù *Neurocomputing*, vol. 224, pp. 96‚Äì104, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] H.¬†Qi, ‚ÄúDerivation of Backpropagation in Convolutional Neural Network
    (CNN),‚Äù in *Derivation of Backpropagation in Convolutional Neural Network ( CNN
    )*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] C.¬†Dong, C.¬†C. Loy, K.¬†He, and X.¬†Tang, ‚ÄúImage Super-Resolution Using
    Deep Convolutional Networks,‚Äù *IEEE Transactions on Pattern Analysis and Machine
    Intelligence*, vol.¬†38, no.¬†2, pp. 295‚Äì307, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] K.¬†Zhang, W.¬†Zuo, Y.¬†Chen, D.¬†Meng, and L.¬†Zhang, ‚ÄúBeyond a Gaussian Denoiser:
    Residual Learning of Deep CNN for Image Denoising,‚Äù *IEEE Transactions on Image
    Processing*, vol.¬†26, no.¬†7, pp. 3142‚Äì3155, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] X.¬†Shi, Z.¬†Chen, H.¬†Wang, D.-Y. Yeung, W.¬†kin Wong, and W.¬†chun Woo, ‚ÄúConvolutional
    LSTM Network: A Machine Learning Approach for Precipitation Nowcasting,‚Äù 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] K.¬†He, X.¬†Zhang, S.¬†Ren, and J.¬†Sun, ‚ÄúDeep Residual Learning for Image
    Recognition,‚Äù in *Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition (CVPR)*, June 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] J.¬†Pan, H.¬†Shan, R.¬†Li, Y.¬†Wu, W.¬†Wua, and T.¬†Q.¬†S. Quek, ‚ÄúChannel Estimation
    Based on Deep Learning in Vehicle-to-everything Environments,‚Äù *IEEE Communications
    Letters*, pp. 1‚Äì1, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] A.¬†K. Gizzini, M.¬†Chafii, A.¬†Nimr, and G.¬†Fettweis, ‚ÄúEnhancing Least Square
    Channel Estimation Using Deep Learning,‚Äù in *2020 IEEE 91st Vehicular Technology
    Conference (VTC2020-Spring)*, 2020, pp. 1‚Äì5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] F.¬†Pontes, G.¬†Amorim, P.¬†Balestrassi, A.¬†Paiva, and J.¬†Ferreira, ‚ÄúDesign
    of Experiments and Focused Grid Search for Neural Network Parameter Optimization,‚Äù
    *Neurocomputing*, vol. 186, pp. 22 ‚Äì 34, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] C.¬†Chatfield, *Time-Series Forecasting*.¬†¬†¬†Chapman and Hall/CRC, 2000.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] Y.¬†R. Zheng and C.¬†Xiao, ‚ÄúChannel Estimation for Frequency-Domain Equalization
    of Single-Carrier Broadband Wireless Communications,‚Äù *IEEE Transactions on Vehicular
    Technology*, vol.¬†58, no.¬†2, pp. 815‚Äì823, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] G.¬†Acosta-Marum and M.¬†A. Ingram, ‚ÄúSix Time and Frequency Selective Empirical
    Channel Models for Vehicular Wireless LANs,‚Äù *IEEE Vehicular Technology Magazine*,
    vol.¬†2, no.¬†4, pp. 4‚Äì11, 2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] G.¬†Acosta-Marum, ‚ÄúMeasurement, Modeling, and OFDM Synchronization for
    the Wideband Mobile-to-Mobile Channel,‚Äù *Ph.D. dissertation, Georgia Inst. Technol.,
    Atlanta, GA*, 2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
