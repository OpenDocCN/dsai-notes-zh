- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:46:06'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:46:06
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2206.02165] A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2206.02165] 关于深度学习基于双重扩散环境中的信道估计的调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2206.02165](https://ar5iv.labs.arxiv.org/html/2206.02165)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2206.02165](https://ar5iv.labs.arxiv.org/html/2206.02165)
- en: DSRC
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: DSRC
- en: dedicated short-range communications
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 专用短程通信
- en: C-ITS
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: C-ITS
- en: cooperative intelligent transport system
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 合作智能交通系统
- en: RSU
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: RSU
- en: road side unit
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 路侧单元
- en: TDL
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: TDL
- en: tapped delay line
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波延迟线
- en: ITS
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ITS
- en: Intelligent Transportation Systems
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 智能交通系统
- en: IEEE
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: IEEE
- en: Institute of Electrical and Electronics Engineers
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 电气和电子工程师学会
- en: WAVE
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: WAVE
- en: Wireless Access in Vehicular Environment
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 无线车载环境接入
- en: V2V
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: V2V
- en: vehicle-to-vehicle
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 车与车
- en: V2I
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: V2I
- en: vehicle-to-infrastructure
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 车对基础设施
- en: CCH
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: CCH
- en: control channel
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 控制通道
- en: SCH
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: SCH
- en: service channels
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 服务通道
- en: STS
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: STS
- en: short training symbols
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 短训练符号
- en: LTS
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: LTS
- en: long training symbols
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 长训练符号
- en: SS
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: SS
- en: signal symbol
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 信号符号
- en: SoA
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: SoA
- en: state-of-the-art
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最先进的
- en: DPA
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: DPA
- en: data-pilot aided
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 数据引导
- en: STA
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: STA
- en: spectral temporal averaging
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 频谱时间平均
- en: CDP
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: CDP
- en: constructed data pilots
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 构建数据引导
- en: TRFI
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: TRFI
- en: time domain reliable test frequency domain interpolation
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 时间域可靠测试频域插值
- en: MMSE-VP
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: MMSE-VP
- en: minimum mean square error using virtual pilots
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用虚拟引导的最小均方误差
- en: iCDP
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: iCDP
- en: Improved CDP
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 改进的CDP
- en: SBS
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: SBS
- en: symbol-by-symbol
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 符号逐个
- en: FBF
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: FBF
- en: frame-by-frame
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 帧对帧
- en: E-TRFI
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: E-TRFI
- en: Enhanced TRFI
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 增强TRFI
- en: SR-CNN
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: SR-CNN
- en: super resolution CNN
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 超分辨率CNN
- en: DN-CNN
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: DN-CNN
- en: denoising CNN
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 去噪CNN
- en: RBF
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: RBF
- en: radial basis function
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 径向基函数
- en: CNN
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: CNN
- en: convolutional neural network
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: TS-ChannelNet
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: TS-ChannelNet
- en: Temporal spectral ChannelNet
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 时间光谱ChannelNet
- en: WSSUS
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: WSSUS
- en: wide-sense stationary uncorrelated scattering
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 广义平稳无关散射
- en: TDR
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: TDR
- en: transmission data rate
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 传输数据速率
- en: LSTM
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM
- en: long short-term memory
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 长短期记忆
- en: ALS
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ALS
- en: accurate LS
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 精确LS
- en: SLS
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: SLS
- en: simple LS
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 简单LS
- en: ChannelNet
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ChannelNet
- en: channel network
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 信道网络
- en: ADD-TT
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ADD-TT
- en: average decision-directed with time truncation
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 平均决策导向与时间截断
- en: WI
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: WI
- en: weighted interpolation
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 加权插值
- en: DD
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: DD
- en: decision-directed
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 决策导向
- en: SR-ConvLSTM
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: SR-ConvLSTM
- en: super resolution convolutional long short-term memory
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 超分辨率卷积长短期记忆
- en: RS
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: RS
- en: reliable subcarriers
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 可靠子载波
- en: URS
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: URS
- en: unreliable subcarriers
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 不可靠子载波
- en: AE-DNN
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: AE-DNN
- en: auto-encoder deep neural network
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器深度神经网络
- en: AE
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: AE
- en: auto-encoder
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器
- en: T-DFT
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: T-DFT
- en: truncated discrete Fourier transform
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 截断离散傅里叶变换
- en: TA-TDFT
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: TA-TDFT
- en: temporal averaging T-DFT
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 时间平均T-DFT
- en: TA
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: TA
- en: time averaging
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 时间平均
- en: PDP
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: PDP
- en: power delay profile
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 功率延迟剖面
- en: 1G
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 1G
- en: first generation
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 第一代
- en: 2G
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 2G
- en: second generation
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 第二代
- en: 3G
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 3G
- en: third generation
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 第三代
- en: 3GPP
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 3GPP
- en: Third Generation Partnership Project
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 第三代合作伙伴计划
- en: 4G
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 4G
- en: fourth generation
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 第四代
- en: 5G
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 5G
- en: fifth generation
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 第五代
- en: '802.11'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '802.11'
- en: IEEE 802.11 specifications
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: IEEE 802.11 规格
- en: A/D
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: A/D
- en: analog-to-digital
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟到数字
- en: ADC
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ADC
- en: analog-to-digital
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟到数字
- en: AM
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: AM
- en: amplitude modulation
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 幅度调制
- en: AP
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: AP
- en: access point
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 接入点
- en: AR
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: AR
- en: augmented reality
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 增强现实
- en: ASIC
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ASIC
- en: application-specific integrated circuit
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 应用特定集成电路
- en: ASIP
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ASIP
- en: Application Specific Integrated Processors
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 应用特定集成处理器
- en: AWGN
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: AWGN
- en: additive white Gaussian noise
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 加性白噪声
- en: BCJR
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: BCJR
- en: Bahl, Cocke, Jelinek and Raviv
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Bahl, Cocke, Jelinek和Raviv
- en: BER
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: BER
- en: bit error rate
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 比特误码率
- en: BFDM
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: BFDM
- en: bi-orthogonal frequency division multiplexing
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 双正交频分复用
- en: BPSK
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: BPSK
- en: binary phase shift keying
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制相位键控
- en: BS
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 基站
- en: base stations
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 基站
- en: CA
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: CA
- en: carrier aggregation
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 载波聚合
- en: CAF
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: CAF
- en: cyclic autocorrelation function
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 循环自相关函数
- en: Car-2-x
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Car-2-x
- en: car-to-car and car-to-infrastructure communication
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 车对车和车对基础设施通信
- en: CAZAC
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: CAZAC
- en: constant amplitude zero autocorrelation waveform
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 恒定幅度零自相关波形
- en: CB-FMT
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: CB-FMT
- en: cyclic block filtered multitone
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 循环块滤波多音
- en: CCDF
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: CCDF
- en: complementary cumulative density function
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 互补累积分布函数
- en: CDF
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: CDF
- en: cumulative density function
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 累积分布函数
- en: CDMA
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: CDMA
- en: code-division multiple access
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 码分多址
- en: CFO
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: CFO
- en: carrier frequency offset
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 载波频率偏移
- en: CIR
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: CIR
- en: channel impulse response
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 信道脉冲响应
- en: CM
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: CM
- en: complex multiplication
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 复数乘法
- en: COFDM
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: COFDM
- en: coded-[OFDM](#id208.208.id208)
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 编码-[OFDM](#id208.208.id208)
- en: CoMP
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: CoMP
- en: coordinated multi point
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 协调多点
- en: COQAM
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: COQAM
- en: cyclic OQAM
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 循环OQAM
- en: CP
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: CP
- en: cyclic prefix
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 循环前缀
- en: CR
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: CR
- en: cognitive radio
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 认知无线电
- en: CRC
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: CRC
- en: cyclic redundancy check
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 循环冗余检验
- en: CRLB
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: CRLB
- en: Cramér-Rao lower bound
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Cramér-Rao下界
- en: CS
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: CS
- en: cyclic suffix
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 循环后缀
- en: CSI
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: CSI
- en: channel state information
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 信道状态信息
- en: CSMA
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: CSMA
- en: carrier-sense multiple access
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 载波侦听多址
- en: CWCU
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: CWCU
- en: component-wise conditionally unbiased
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 组件逐项条件无偏
- en: D/A
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: D/A
- en: digital-to-analog
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 数字到模拟
- en: D2D
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: D2D
- en: device-to-device
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 设备对设备
- en: DAC
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: DAC
- en: digital-to-analog
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 数字到模拟
- en: DC
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: DC
- en: direct current
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 直流
- en: DFE
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: DFE
- en: decision feedback equalizer
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 决策反馈均衡器
- en: DFT
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 离散傅里叶变换
- en: discrete Fourier transform
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 离散傅里叶变换
- en: DL
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: DL
- en: deep learning
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习
- en: DMT
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: DMT
- en: discrete multitone
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 离散多音
- en: DNN
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络
- en: deep neural network
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络
- en: FNN
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: FNN
- en: feed-forward neural network
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 前馈神经网络
- en: DSA
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: DSA
- en: dynamic spectrum access
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 动态频谱接入
- en: DSL
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 数字用户线路
- en: digital subscriber line
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 数字用户线路
- en: DSP
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 数字信号处理
- en: digital signal processor
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 数字信号处理器
- en: DTFT
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: DTFT
- en: discrete-time Fourier transform
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 离散时间傅里叶变换
- en: DVB
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: DVB
- en: digital video broadcasting
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 数字视频广播
- en: DVB-T
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: DVB-T
- en: terrestrial digital video broadcasting
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 地面数字视频广播
- en: DWMT
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: DWMT
- en: discrete wavelet multi tone
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 离散小波多音
- en: DZT
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: DZT
- en: discrete Zak transform
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 离散Zak变换
- en: E2E
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: E2E
- en: end-to-end
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端
- en: eNodeB
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: eNodeB
- en: evolved node b base station
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 演进节点B基站
- en: E-SNR
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: E-SNR
- en: effective signal-to-noise ratio
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 有效信噪比
- en: EVD
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: EVD
- en: eigenvalue decomposition
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值分解
- en: FBMC
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: FBMC
- en: filter bank multicarrier
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波器组多载波
- en: FD
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: FD
- en: frequency-domain
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 频域
- en: FDD
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: FDD
- en: frequency-division duplexing
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 频分双工
- en: FDE
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: FDE
- en: frequency domain equalization
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 频域均衡
- en: FDM
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: FDM
- en: frequency division multiplex
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 频分复用
- en: FDMA
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: FDMA
- en: frequency-division multiple access
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 频分多址
- en: FEC
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: FEC
- en: forward error correction
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 前向错误纠正
- en: FER
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: FER
- en: frame error rate
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 帧错误率
- en: FFT
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: FFT
- en: fast Fourier transform
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 快速傅里叶变换
- en: FIR
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: FIR
- en: finite impulse response
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 有限冲击响应
- en: FM
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: FM
- en: frequency modulation
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 频率调制
- en: FMT
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: FMT
- en: filtered multi tone
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤多音
- en: FO
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: FO
- en: frequency offset
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 频率偏移
- en: F-OFDM
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: F-OFDM
- en: filtered-[OFDM](#id208.208.id208)
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤-[OFDM](#id208.208.id208)
- en: FPGA
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: FPGA
- en: field programmable gate array
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 现场可编程门阵列
- en: FSC
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: FSC
- en: frequency selective channel
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 频率选择性信道
- en: FS-OQAM-GFDM
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: FS-OQAM-GFDM
- en: frequency-shift OQAM-GFDM
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 频移OQAM-GFDM
- en: FT
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: FT
- en: Fourier transform
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 傅里叶变换
- en: FTD
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: FTD
- en: fractional time delay
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 分数时间延迟
- en: FTN
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: FTN
- en: faster-than-Nyquist signaling
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 快于奈奎斯特信号
- en: GFDM
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: GFDM
- en: generalized frequency division multiplexing
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 广义频分复用
- en: GFDMA
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: GFDMA
- en: generalized frequency division multiple access
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 广义频分多址
- en: GMC-CDM
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: GMC-CDM
- en: generalized multicarrier code-division multiplexing
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 广义多载波码分复用
- en: GNSS
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: GNSS
- en: global navigation satellite system
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 全球导航卫星系统
- en: GS
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: GS
- en: guard symbols
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 保护符号
- en: GSM
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: GSM
- en: Groupe Spécial Mobile
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 特殊移动组
- en: GUI
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 图形用户界面
- en: graphical user interface
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图形用户界面
- en: H2H
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: H2H
- en: human-to-human
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 人对人
- en: H2M
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: H2M
- en: human-to-machine
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 人对机器
- en: HTC
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: HTC
- en: human type communication
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 人类通信
- en: I
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: I
- en: in-phase
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 同相
- en: i.i.d.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 独立同分布
- en: independent and identically distributed
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 独立同分布
- en: IB
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: IB
- en: in-band
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 带内
- en: IBI
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: IBI
- en: inter-block interference
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 块间干扰
- en: IC
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: IC
- en: interference cancellation
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 干扰消除
- en: ICI
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: ICI
- en: inter-carrier interference
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 载波间干扰
- en: ICT
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: ICT
- en: information and communication technologies
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 信息与通信技术
- en: ICV
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: ICV
- en: information coefficient vector
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 信息系数向量
- en: IDFT
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: IDFT
- en: inverse discrete Fourier transform
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 逆离散傅里叶变换
- en: IDMA
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: IDMA
- en: interleave division multiple access
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 交织分割多址
- en: IEEE
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: IEEE
- en: institute of electrical and electronics engineers
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 电气和电子工程师协会
- en: IF
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: IF
- en: intermediate frequency
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 中频
- en: IFFT
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: IFFT
- en: inverse fast Fourier transform
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 逆快速傅里叶变换
- en: IoT
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 物联网
- en: Internet of Things
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 物联网
- en: IOTA
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: IOTA
- en: isotropic orthogonal transform algorithm
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 各向同性正交变换算法
- en: IP
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: IP
- en: internet protocole
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 网络协议
- en: IP-core
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: IP核
- en: intellectual property core
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 知识产权核心
- en: ISDB-T
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: ISDB-T
- en: terrestrial integrated services digital broadcasting
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 地面综合服务数字广播
- en: ISDN
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: ISDN
- en: integrated services digital network
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 综合服务数字网络
- en: ISI
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 符号间干扰
- en: inter-symbol interference
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 符号间干扰
- en: ITU
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: ITU
- en: International Telecommunication Union
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 国际电信联盟
- en: IUI
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: IUI
- en: inter-user interference
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 用户间干扰
- en: LAN
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 局域网
- en: local area netwrok
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 局域网
- en: LLR
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: LLR
- en: log-likelihood ratio
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 对数似然比
- en: LMMSE
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: LMMSE
- en: linear minimum mean square error
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 线性最小均方误差
- en: LNA
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: LNA
- en: low noise amplifier
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 低噪声放大器
- en: LO
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: LO
- en: local oscillator
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 本地振荡器
- en: LOS
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: LOS
- en: line-of-sight
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 视距
- en: LP
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: LP
- en: low-pass
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 低通
- en: LPF
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: LPF
- en: low-pass filter
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 低通滤波器
- en: LS
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: LS
- en: least squares
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘
- en: LTE
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: LTE
- en: Long Term Evolution
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 长期演进
- en: LTE-A
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: LTE-A
- en: LTE-Advanced
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: LTE-Advanced
- en: LTIV
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: LTIV
- en: linear time invariant
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 线性时不变
- en: LTV
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: LTV
- en: linear time-variant
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 线性时变
- en: LUT
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: LUT
- en: lookup table
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 查找表
- en: M2M
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: M2M
- en: machine-to-machine
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 机器对机器
- en: MA
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: MA
- en: multiple access
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 多重接入
- en: MAC
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: MAC
- en: multiple access control
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 多重接入控制
- en: MAP
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: MAP
- en: maximum a posteriori
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 最大后验
- en: MC
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: MC
- en: multicarrier
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 多载波
- en: MCA
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: MCA
- en: multicarrier access
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 多载波接入
- en: MCM
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: MCM
- en: multicarrier modulation
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 多载波调制
- en: MCS
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: MCS
- en: modulation coding scheme
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 调制编码方案
- en: MF
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: MF
- en: matched filter
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配滤波器
- en: MF-SIC
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: MF-SIC
- en: matched filter with successive interference cancellation
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配滤波器与连续干扰消除
- en: MIMO
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: MIMO
- en: multiple-input, multiple-output
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 多输入多输出
- en: MISO
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: MISO
- en: multiple-input single-output
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 多输入单输出
- en: ML
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: ML
- en: machien learning
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习
- en: MLD
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: MLD
- en: maximum likelihood detection
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 最大似然检测
- en: MLE
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: MLE
- en: maximum likelihood estimator
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 最大似然估计
- en: MMSE
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: MMSE
- en: minimum mean squared error
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 最小均方误差
- en: MRC
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: MRC
- en: maximum ratio combining
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 最大比合并
- en: MS
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: MS
- en: mobile stations
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 移动台
- en: MSE
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: MSE
- en: mean squared error
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 均方误差
- en: MSK
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: MSK
- en: Minimum-shift keying
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 最小移位键控
- en: MSSS
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: MSSS
- en: mean-square signal separation
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 均方信号分离
- en: MTC
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: MTC
- en: machine type communication
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 机器类型通信
- en: MU
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: MU
- en: multi user
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 多用户
- en: MVUE
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: MVUE
- en: minimum variance unbiased estimator
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 最小方差无偏估计
- en: NEF
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: NEF
- en: noise enhancement factor
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声增强因子
- en: NLOS
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: NLOS
- en: non-line-of-sight
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 非视距
- en: NMSE
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: NMSE
- en: normalized mean-squared error
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化均方误差
- en: NOMA
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: NOMA
- en: non-orthogonal multiple access
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 非正交多址
- en: NPR
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: NPR
- en: near-perfect reconstruction
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 近乎完美重建
- en: NRZ
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: NRZ
- en: non-return-to-zero
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 非归零
- en: OFDM
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: OFDM
- en: orthogonal frequency division multiplexing
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 正交频分复用
- en: OFDMA
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: OFDMA
- en: orthogonal frequency division multiple access
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 正交频分多址
- en: OOB
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: OOB
- en: out-of-band
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 带外
- en: OQAM
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: OQAM
- en: offset quadrature amplitude modulation
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 偏移正交振幅调制
- en: OQPSK
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: OQPSK
- en: offset quadrature phase shift keying
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 偏移正交相位移键控
- en: OTFS
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: OTFS
- en: orthogonal time frequency space
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 正交时间频率空间
- en: PA
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: PA
- en: power amplifier
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 功率放大器
- en: PAM
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: PAM
- en: pulse amplitude modulation
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 脉冲幅度调制
- en: PAPR
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: PAPR
- en: peak-to-average power ratio
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 峰值平均功率比
- en: PC-CC
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: PC-CC
- en: parallel concatenated convolutional code
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 并行串联卷积码
- en: PCP
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: PCP
- en: pseudo-circular pre/post-amble
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 伪圆形前/后导
- en: PD
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: PD
- en: probability of detection
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 检测概率
- en: pdf
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: pdf
- en: probability density function
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 概率密度函数
- en: PDF
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: PDF
- en: probability distribution function
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 概率分布函数
- en: PFA
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: PFA
- en: probability of false alarm
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 假警报概率
- en: PHY
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: PHY
- en: physical layer
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 物理层
- en: PIC
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: PIC
- en: parallel interference cancellation
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 并行干扰消除
- en: PLC
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: PLC
- en: power line communication
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 电力线通信
- en: PMF
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: PMF
- en: probability mass function
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 概率质量函数
- en: PN
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: PN
- en: pseudo noise
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 伪噪声
- en: ppm
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: ppm
- en: parts per million
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 百万分之一
- en: PRB
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: PRB
- en: physical resource block
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 物理资源块
- en: PRB
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: PRB
- en: physical resource block
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 物理资源块
- en: PSD
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: PSD
- en: power spectral density
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 功率谱密度
- en: Q
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: Q
- en: quadrature-phase
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 正交相位
- en: QAM
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: QAM
- en: quadrature amplitude modulation
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 正交振幅调制
- en: QoS
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: QoS
- en: quality of service
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 服务质量
- en: QPSK
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: QPSK
- en: quadrature phase shift keying
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 正交相位移键控
- en: R/W
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: R/W
- en: read-or-write
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 读写
- en: RAM
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: RAM
- en: random-access memmory
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 随机访问内存
- en: RAN
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: RAN
- en: radio access network
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 无线接入网
- en: RAT
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: RAT
- en: radio access technologies
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 无线接入技术
- en: RC
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: RC
- en: raised cosine
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 升余弦
- en: RF
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 射频
- en: radio frequency
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 射频
- en: rms
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: rms
- en: root mean square
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 均方根
- en: RRC
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: RRC
- en: root raised cosine
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 根升余弦
- en: RW
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: RW
- en: read-and-write
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 读写
- en: SC
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: SC
- en: single-carrier
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 单载波
- en: SCA
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: SCA
- en: single-carrier access
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 单载波接入
- en: SC-FDE
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: SC-FDE
- en: single-carrier with frequency domain equalization
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 单载波频域均衡
- en: SC-FDM
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: SC-FDM
- en: single-carrier frequency division multiplexing
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 单载波频分复用
- en: SC-FDMA
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: SC-FDMA
- en: single-carrier frequency division multiple access
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 单载波频分多址
- en: SD
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: SD
- en: sphere decoding
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 球面解码
- en: SDD
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: SDD
- en: space-division duplexing
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 空间分割双工
- en: SDMA
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: SDMA
- en: space division multiple access
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 空间分割多址
- en: SDR
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: SDR
- en: software-defined radio
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 软件定义无线电
- en: SDW
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: SDW
- en: software-defined waveform
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 软件定义波形
- en: SEFDM
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: SEFDM
- en: spectrally efficient frequency division multiplexing
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 频谱效率频分复用
- en: SE-FDM
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: SE-FDM
- en: spectrally efficient frequency division multiplexing
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 频谱效率频分复用
- en: SER
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: SER
- en: symbol error rate
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 符号错误率
- en: SIC
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: SIC
- en: successive interference cancellation
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 连续干扰消除
- en: SINR
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: SINR
- en: signal-to-interference-plus-noise ratio
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 信噪比加噪声比
- en: SIR
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 信噪比
- en: signal-to-interference ratio
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 信噪比
- en: SISO
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: SISO
- en: single-input, single-output
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 单输入单输出
- en: SMS
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 短信服务
- en: Short Message Service
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 短消息服务
- en: SNR
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: SNR
- en: signal-to-noise ratio
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 信噪比
- en: STC
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: STC
- en: space-time coding
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 空时编码
- en: STFT
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: STFT
- en: short-time Fourier transform
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 短时傅里叶变换
- en: STO
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: STO
- en: symbol time offset
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 符号时间偏移
- en: SU
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: SU
- en: single user
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 单用户
- en: SVD
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: SVD
- en: singular value decomposition
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 奇异值分解
- en: TD
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: TD
- en: time-domain
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 时域
- en: TDD
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: TDD
- en: time-division duplexing
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 时分双工
- en: TDMA
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 时分多址
- en: time-division multiple access
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 时分多址
- en: TFL
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: TFL
- en: time-frequency localization
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 时间-频率定位
- en: TO
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: TO
- en: time offset
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 时间偏移
- en: TS-OQAM-GFDM
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: TS-OQAM-GFDM
- en: time-shifted OQAM-GFDM
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 时间偏移的OQAM-GFDM
- en: UE
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: UE
- en: user equipment
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 用户设备
- en: UFMC
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: UFMC
- en: universally filtered multicarrier
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 通用滤波多载波
- en: UL
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 上行链路
- en: uplink
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 上行链路
- en: US
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: US
- en: uncorrelated scattering
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 无关散射
- en: USB
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: USB
- en: universal serial bus
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 通用串行总线
- en: UW
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: UW
- en: unique word
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一字
- en: VLC
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: VLC
- en: visible light communications
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 可见光通信
- en: VR
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: VR
- en: virtual reality
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟现实
- en: WCP
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: WCP
- en: windowing and [CP](#id82.82.id82)
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口化与[CP](#id82.82.id82)
- en: WHT
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: WHT
- en: Walsh-Hadamard transform
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: Walsh-Hadamard变换
- en: WiMAX
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: WiMAX
- en: worldwide interoperability for microwave access
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 全球微波接入互通
- en: WLAN
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: WLAN
- en: wireless local area network
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 无线局域网
- en: W-OFDM
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: W-OFDM
- en: windowed-[OFDM](#id208.208.id208)
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口化-[OFDM](#id208.208.id208)
- en: WOLA
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: WOLA
- en: windowing and overlapping
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口化与重叠
- en: WSS
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: WSS
- en: wide-sense stationary
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 广义平稳
- en: ZCT
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: ZCT
- en: Zadoff-Chu transform
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: Zadoff-Chu变换
- en: ZF
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: ZF
- en: zero-forcing
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 零强制
- en: ZMCSCG
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: ZMCSCG
- en: zero-mean circularly-symmetric complex Gaussian
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 零均值圆对称复高斯
- en: ZP
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: ZP
- en: zero-padding
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 零填充
- en: ZT
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: ZT
- en: zero-tail
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 零尾
- en: A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments
  id: totrans-594
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于深度学习的双重色散环境中的通道估计综述
- en: 'Abdul Karim Gizzini, , Marwa Chafii Authors acknowledge the CY INEX for the
    support of the project through the ASIA Chair of Excellence Grant (PIA/ANR-16-IDEX-0008).
    Abdul Karim Gizzini is with ETIS, UMR8051, CY Cergy Paris Université, ENSEA, CNRS,
    France (e-mail: abdulkarim.gizzini@ensea.fr). Marwa Chafii is with the Engineering
    Division, New York University (NYU) Abu Dhabi, 129188, UAE, and NYU WIRELESS,
    NYU Tandon School of Engineering, Brooklyn, 11201, NY (e-mail: marwa.chafii@nyu.edu).'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: Abdul Karim Gizzini、Marwa Chafii 作者感谢CY INEX对该项目的支持，特别是ASIA Chair of Excellence
    Grant（PIA/ANR-16-IDEX-0008）。Abdul Karim Gizzini现任职于法国ETIS，UMR8051，CY Cergy Paris
    Université，ENSEA，CNRS（电子邮件：abdulkarim.gizzini@ensea.fr）。Marwa Chafii现任职于阿布扎比纽约大学（NYU）工程学院，129188，阿联酋，以及纽约大学无线通信研究所，NYU
    Tandon工程学院，布鲁克林，11201，纽约（电子邮件：marwa.chafii@nyu.edu）。
- en: Abstract
  id: totrans-596
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Wireless communications systems are impacted by multi-path fading and Doppler
    shift in dynamic environments, where the channel becomes doubly-dispersive and
    its estimation becomes an arduous task. Only a few pilots are used for channel
    estimation in conventional approaches to preserve high data rate transmission.
    Consequently, such estimators experience a significant performance degradation
    in high mobility scenarios. Recently, deep learning has been employed for doubly-dispersive
    channel estimation due to its low-complexity, robustness, and good generalization
    ability. Against this backdrop, the current paper presents a comprehensive survey
    on channel estimation techniques based on deep learning by deeply investigating
    different methods. The study also provides extensive experimental simulations
    followed by a computational complexity analysis. After considering different parameters
    such as modulation order, mobility, frame length, and deep learning architecture,
    the performance of the studied estimators is evaluated in several mobility scenarios.
    In addition, the source codes are made available online in order to make the results
    reproducible.
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 无线通信系统在动态环境中受到多径衰落和多普勒频移的影响，使得通道变得双重色散，通道估计变得十分困难。传统方法中，只有少量导频用于通道估计以保持高数据传输速率。因此，这些估计器在高移动场景中经历了显著的性能下降。近年来，由于其低复杂度、鲁棒性和良好的泛化能力，深度学习已被用于双重色散通道估计。在此背景下，本文对基于深度学习的通道估计技术进行了全面调查，深入研究了不同的方法。研究还提供了广泛的实验模拟和计算复杂度分析。在考虑了调制阶数、移动性、帧长度和深度学习架构等不同参数后，评估了所研究的估计器在多个移动场景中的性能。此外，源代码也在线提供，以使结果可重复。
- en: 'Index Terms:'
  id: totrans-598
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Channel estimation, Deep learning, Frequency-selective channels, Time-varying
    channels.
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 通道估计、深度学习、频率选择性通道、时变通道。
- en: I Introduction
  id: totrans-600
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: With the commercialization of fifth generation networks globally, research into
    sixth generation (6G) networks has been initiated to address the demands for high
    data rates and low latency mobile applications, including unmanned aerial vehicles [[1](#bib.bib1)],
    high-speed railway [[2](#bib.bib2)], and vehicular communications [[3](#bib.bib3)].
    Mobile wireless communications systems offer the freedom to move around without
    being disconnected from the network. However, the mobility feature is ridden with
    several challenges that have a severely adverse impact on the communication reliability,
    such as fast and frequent handovers [[4](#bib.bib4)], carrier frequency offset [[5](#bib.bib5)],
    inter-carrier interference [[6](#bib.bib6)], high penetration loss [[7](#bib.bib7)],
    and fast time-varying wireless channel [[8](#bib.bib8)].
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: 随着第五代网络在全球范围内的商业化，研究第六代（6G）网络已经启动，以满足对高速数据传输和低延迟移动应用的需求，包括无人机[[1](#bib.bib1)]、高速铁路[[2](#bib.bib2)]和车载通信[[3](#bib.bib3)]。移动无线通信系统提供了在不与网络断连的情况下自由移动的能力。然而，移动特性伴随着若干挑战，这些挑战对通信可靠性产生了严重的负面影响，例如快速且频繁的切换[[4](#bib.bib4)]、载波频率偏移[[5](#bib.bib5)]、载波间干扰[[6](#bib.bib6)]、高穿透损耗[[7](#bib.bib7)]和快速时变无线通道[[8](#bib.bib8)]。
- en: In wireless environment, transmitted signals are known to propagate via a multitude
    of paths, each entailing a different attenuation and delay in addition to the
    Doppler shift effect stemming from the motion of network nodes along with the
    surrounding environment. As a result, the wireless channel becomes frequency-selective
    and time-varying. Given that a precisely estimated channel response influences
    the follow-up equalization, demodulation, and decoding operations at the receiver,
    the accuracy of the channel estimation influences the system performance. Therefore,
    ensuring communication reliability via accurate channel estimation in such environments
    is highly important.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 在无线环境中，已知传输信号通过多条路径传播，每条路径具有不同的衰减和延迟，还包括由于网络节点及其周围环境的运动引起的多普勒频移效应。结果，无线信道变得频率选择性和时变。由于精确估计的信道响应影响接收端的后续均衡、解调和解码操作，信道估计的准确性会影响系统性能。因此，在这种环境中通过准确的信道估计确保通信可靠性是至关重要的。
- en: 'In the extant literature, a vast body of work has been carried out to address
    the problem of doubly-dispersive channels. While some works have focused on investigating
    the waveform design [[9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12)],
    we are interested in this paper in the channel estimation task. In general, channel
    estimators can be classified into two main categories: (i) [symbol-by-symbol](#id22.22.id22)
    ([SBS](#id22.22.id22)) channel estimators: the channel is estimated for each received
    symbol separately using only the previous and current received pilots [[13](#bib.bib13),
    [14](#bib.bib14), [15](#bib.bib15)] (ii) [frame-by-frame](#id23.23.id23) ([FBF](#id23.23.id23))
    channel estimators: the previous, existing, as well as future pilots are employed
    in the channel estimation for each received symbol [[16](#bib.bib16)]. It is possible
    to achieve a higher channel estimation accuracy by utilizing [FBF](#id23.23.id23)
    estimators, since the channel estimation of each symbol benefits from the combined
    knowledge of all allocated pilots within the frame. However, the conventional
    estimators’ performance mainly relies on the allocated reference training pilots
    within the transmitted frames. The majority of standards allocate a few pilots
    to maintain a good transmission data rate. Therefore, these pilots are insufficient
    for accurately tracking the doubly-dispersive channel, because they are not spaced
    closely enough to capture the variation of the channel in the frequency domain.
    Consequently, conventional estimators are primarily based on the demapped data
    subcarriers, besides pilot subcarriers to update the channel estimate for each
    received symbol. This procedure called [data-pilot aided](#id16.16.id16) ([DPA](#id16.16.id16))
    channel estimation is regarded as unreliable because the demapping error gets
    enlarged from one symbol to another, which leads to another additional error in
    the estimation process, especially in highly dynamic time-varying channels. Moreover,
    other conventional estimators like the [linear minimum mean square error](#id166.166.id166)
    ([LMMSE](#id166.166.id166)) [[17](#bib.bib17)] estimator rely on many assumptions
    that limit their performance in highly dynamic time-varying channels. Moreover,
    linear conventional estimators are impractical solutions in real case scenarios
    as they rely on statistical models and require high implementation complexity,
    in addition, they lack robustness in highly dynamic environments. Therefore, investigating
    estimators with a good trade-off complexity vs. performance is a crucial need
    for improving the channel estimation accuracy while preserving good data rate
    as well as maintaining affordable computational complexity.'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 在现有文献中，大量的研究已致力于解决双重扩散通道的问题。虽然一些工作集中在波形设计上[[9](#bib.bib9), [10](#bib.bib10),
    [11](#bib.bib11), [12](#bib.bib12)]，但本文关注的是通道估计任务。通常，通道估计器可以分为两大类：（i）[逐符号](#id22.22.id22)（[SBS](#id22.22.id22)）通道估计器：每个接收到的符号的通道是单独估计的，仅使用前一个和当前接收到的导频[[13](#bib.bib13),
    [14](#bib.bib14), [15](#bib.bib15)]；（ii）[逐帧](#id23.23.id23)（[FBF](#id23.23.id23)）通道估计器：在每个接收到的符号的通道估计中使用了之前、现有以及未来的导频[[16](#bib.bib16)]。通过利用[FBF](#id23.23.id23)估计器，可以实现更高的通道估计准确性，因为每个符号的通道估计受益于帧内所有分配的导频的综合知识。然而，传统估计器的性能主要依赖于传输帧内分配的参考训练导频。大多数标准只分配少量导频以保持良好的传输数据率。因此，这些导频不足以准确跟踪双重扩散通道，因为它们的间隔不足以捕捉频域中通道的变化。因此，传统估计器主要依赖于去映射的数据子载波，此外还有导频子载波来更新每个接收到的符号的通道估计。这一过程称为[数据-导频辅助](#id16.16.id16)（[DPA](#id16.16.id16)）通道估计，被认为是不可靠的，因为去映射误差从一个符号到另一个符号会被放大，这会导致估计过程中的额外误差，尤其是在高度动态的时变通道中。此外，其他传统估计器如[线性最小均方误差](#id166.166.id166)（[LMMSE](#id166.166.id166)）[[17](#bib.bib17)]估计器依赖于许多假设，这限制了它们在高度动态时变通道中的性能。此外，线性传统估计器在实际场景中是不切实际的，因为它们依赖于统计模型，要求高实现复杂度，而且在高度动态的环境中缺乏鲁棒性。因此，研究具有良好复杂度与性能权衡的估计器，对于提高通道估计准确性，同时保持良好的数据传输速率以及控制计算复杂度，是至关重要的。
- en: As a prevailing approach to AI, [deep learning](#id96.96.id96) ([DL](#id96.96.id96))
    is an efficient method to analyze data by identifying patterns and learning underlying
    structures, denoting an effective approach to problems faced in various scientific
    fields. [DL](#id96.96.id96) algorithms have been integrated into the physical
    layer of wireless communications systems  [[18](#bib.bib18), [19](#bib.bib19),
    [20](#bib.bib20)], including channel estimation [[21](#bib.bib21), [22](#bib.bib22),
    [23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25), [26](#bib.bib26)]. In turn,
    this is attributable to the great success in enhancing the overall system performance,
    particularly when used in addition to conventional estimators, where coarse channel
    estimation is derived from conventional estimators, following which DL is employed
    to achieve a fine estimation. Therefore, DL-based channel estimators are capable
    of significantly enhancing the performance while preserving low computational
    complexity. In addition, the GPU-based distributed processing allows the DL employment
    in real-time applications, as a result of which DL can overcome the limitations
    of traditional channel estimation through robust, low-complexity, and generalized
    solutions that improve the performance of wireless systems.
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种主流的 AI 方法，[深度学习](#id96.96.id96) ([DL](#id96.96.id96)) 是一种通过识别模式和学习潜在结构来分析数据的高效方法，代表了应对各种科学领域问题的有效方法。[DL](#id96.96.id96)
    算法已被整合到无线通信系统的物理层 [[18](#bib.bib18), [19](#bib.bib19), [20](#bib.bib20)]，包括信道估计
    [[21](#bib.bib21), [22](#bib.bib22), [23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25),
    [26](#bib.bib26)]。这归功于显著提升整体系统性能的巨大成功，特别是当与传统估计器配合使用时，传统估计器提供的粗略信道估计后，DL 被用来实现精确估计。因此，基于
    DL 的信道估计器能够在保持低计算复杂度的同时显著提升性能。此外，基于 GPU 的分布式处理允许 DL 在实时应用中的使用，从而 DL 可以通过稳健、低复杂度和通用的解决方案克服传统信道估计的局限性，提升无线系统的性能。
- en: 'Motivated by these advantages, [DL](#id96.96.id96) algorithms have been integrated
    in frequency-selective [[24](#bib.bib24), [25](#bib.bib25), [26](#bib.bib26)]
    and doubly-dispersive channel estimation. In this survey, we examine the recently
    proposed DL-based channel estimation schemes in doubly-dispersive environments,
    where DL algorithms are utilized in two different manners: (i) [feed-forward neural
    networks](#id99.99.id99) with different architectures and configurations are employed
    on top of the conventional [SBS](#id22.22.id22) channel estimators [[27](#bib.bib27),
    [28](#bib.bib28), [29](#bib.bib29)]. (ii) [convolutional neural networks](#id28.28.id28)
    processing is employed where the estimated channel for the entire frame is modeled
    as a 2D low-resolution noisy image, whereas [CNN](#id28.28.id28)-based processing
    is implemented as super resolution and denoising techniques [[30](#bib.bib30),
    [31](#bib.bib31), [32](#bib.bib32)].'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 受这些优势的驱动，[DL](#id96.96.id96) 算法已被整合到频率选择性 [[24](#bib.bib24), [25](#bib.bib25),
    [26](#bib.bib26)] 和双散射信道估计中。在本次调查中，我们将探讨最近提出的基于 DL 的双散射环境中的信道估计方案，其中 DL 算法以两种不同的方式应用：（i）在传统的
    [SBS](#id22.22.id22) 信道估计器上采用不同架构和配置的 [前馈神经网络](#id99.99.id99) [[27](#bib.bib27),
    [28](#bib.bib28), [29](#bib.bib29)]。 （ii）采用 [卷积神经网络](#id28.28.id28) 处理，其中整个帧的估计信道被建模为
    2D 低分辨率噪声图像，而 [CNN](#id28.28.id28) 基于处理则实现为超分辨率和去噪技术 [[30](#bib.bib30), [31](#bib.bib31),
    [32](#bib.bib32)]。
- en: The majority of surveys conducted in the literature  [[33](#bib.bib33), [34](#bib.bib34)]
    lack intensive simulations in the performance evaluation and complexity analysis
    of the studied channel estimators. Moreover, they do not cover both SBS and FBF
    based estimators. In addition, [[33](#bib.bib33)] compares the performance of
    different DL architectures used after the [least squares](#id172.172.id172) ([LS](#id172.172.id172))
    and the LMMSE estimators without considering several conventional channel estimation
    schemes, whereas [[34](#bib.bib34)] provides a general overview of several channel
    estimators without any performance evaluation. Given this context, to the best
    of our knowledge, this is the first survey that presents a comprehensive study
    on the recently proposed DL-based SBS and FBF estimators in doubly-dispersive
    environments, while presenting intensive simulations evaluating the system performance
    in different scenarios, providing a detailed complexity analysis, as well as the
    source codes to reproduce all the presented results. We believe that this survey
    is a very relevant reference to initiate researches pertaining to the domain of
    deep learning based channel estimation in doubly dispersive channels. The contributions
    of this paper can be summarized in the following manner
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 文献中进行的大多数调查[[33](#bib.bib33), [34](#bib.bib34)]在对所研究的信道估计器进行性能评估和复杂度分析时缺乏深入的仿真。此外，它们未涵盖基于SBS和FBF的估计器。另外，[[33](#bib.bib33)]比较了不同DL架构在[最小二乘法](#id172.172.id172)（[LS](#id172.172.id172)）和LMMSE估计器之后的性能，但没有考虑几个传统的信道估计方案，而[[34](#bib.bib34)]则提供了多个信道估计器的一般概述，但没有任何性能评估。在这种背景下，据我们所知，这是第一篇在双重散射环境中对最近提出的基于DL的SBS和FBF估计器进行综合研究的调查论文，同时进行不同场景下系统性能的深入仿真，提供详细的复杂度分析，以及用于重现所有呈现结果的源代码。我们认为这篇调查论文是启动深度学习信道估计领域研究的一个非常相关的参考。本文的贡献可以总结如下：
- en: •
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Comprehensive study on the recently proposed [DL](#id96.96.id96)-based channel
    estimation techniques for doubly-dispersive channels.
  id: totrans-608
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对最近提出的基于[DL](#id96.96.id96)的双重散射信道估计技术进行综合研究。
- en: •
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Overview of the [DL](#id96.96.id96) networks, especially those used in the studied
    channel estimators, such as [FNN](#id99.99.id99), [long short-term memory](#id32.32.id32)
    ([LSTM](#id32.32.id32)), [super resolution CNN](#id25.25.id25) ([SR-CNN](#id25.25.id25)),
    and [denoising CNN](#id26.26.id26) ([DN-CNN](#id26.26.id26)).
  id: totrans-610
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对[DL](#id96.96.id96)网络的概述，特别是那些用于研究中的信道估计器的网络，例如[FNN](#id99.99.id99)、[长短期记忆](#id32.32.id32)（[LSTM](#id32.32.id32)）、[超分辨率CNN](#id25.25.id25)（[SR-CNN](#id25.25.id25)）和[去噪CNN](#id26.26.id26)（[DN-CNN](#id26.26.id26)）。
- en: •
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Performance analysis of different channel estimation schemes and a fair comparison
    between them in terms of [normalized mean-squared error](#id204.204.id204) ([NMSE](#id204.204.id204))
    and [bit error rate](#id64.64.id64) ([BER](#id64.64.id64)) for different mobility
    scenarios and frame length, and modulation order.
  id: totrans-612
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对不同信道估计方案的性能分析，并在[归一化均方误差](#id204.204.id204)（[NMSE](#id204.204.id204)）和[比特误差率](#id64.64.id64)（[BER](#id64.64.id64)）方面进行公平比较，涵盖不同的移动场景、帧长和调制阶数。
- en: •
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Detailed computational complexity analysis for the studied channel estimators
    concerning the overall required real-valued operations.
  id: totrans-614
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对所研究的信道估计器进行详细的计算复杂度分析，涉及所需的总体实值操作。
- en: •
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Simulation source code for various channel estimation schemes to reproduce all
    the comparison results presented in this paper [[35](#bib.bib35)].
  id: totrans-616
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 各种信道估计方案的仿真源代码，用于重现本文中呈现的所有比较结果[[35](#bib.bib35)]。
- en: 'The remainder of this paper is organized as follows: Section [II](#S2 "II System
    Model ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments") elucidates the system model, illustrating signal transmission over
    a doubly-dispersive channel. Section [III](#S3 "III DL Techniques Overview ‣ A
    Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments")
    provides a brief overview of the main [DL](#id96.96.id96) networks employed in
    this survey. The recently proposed [DL](#id96.96.id96)-based [SBS](#id22.22.id22)
    and [FBF](#id23.23.id23) channel estimation schemes are thoroughly investigated
    and discussed in Sections [IV](#S4 "IV DL-Based SBS Channel Estimation ‣ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")
    and [V](#S5 "V DL-Based FBF Channel Estimation Schemes ‣ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments"), respectively. In
    Section [VI](#S6 "VI Simulation Results ‣ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments"), different modulation orders are
    used to present simulation results, wherein the performance of the studied estimators
    is examined in terms of [BER](#id64.64.id64), and [NMSE](#id204.204.id204). Detailed
    computational complexity analysis is provided in Section [VII](#S7 "VII Complexity
    Analysis ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments"). Finally, Section [VIII](#S8 "VIII Conclusion ‣ A Survey on Deep
    Learning based Channel Estimation in Doubly Dispersive Environments") concludes
    this study.'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的其余部分组织如下：第 [II](#S2 "II 系统模型 ‣ 基于深度学习的双重色散环境中的信道估计综述") 节阐述了系统模型，说明了在双重色散通道上的信号传输。第
    [III](#S3 "III 深度学习技术概述 ‣ 基于深度学习的双重色散环境中的信道估计综述") 节简要概述了本综述中使用的主要[DL](#id96.96.id96)网络。最近提出的基于[DL](#id96.96.id96)的[SBS](#id22.22.id22)和[FBF](#id23.23.id23)信道估计方案在第
    [IV](#S4 "IV 基于DL的SBS信道估计 ‣ 基于深度学习的双重色散环境中的信道估计综述") 节和第 [V](#S5 "V 基于DL的FBF信道估计方案
    ‣ 基于深度学习的双重色散环境中的信道估计综述") 节中进行了深入研究和讨论。在第 [VI](#S6 "VI 仿真结果 ‣ 基于深度学习的双重色散环境中的信道估计综述")
    节中，使用不同的调制阶数来展示仿真结果，其中考察了研究的估计器在 [BER](#id64.64.id64) 和 [NMSE](#id204.204.id204)
    方面的性能。第 [VII](#S7 "VII 复杂度分析 ‣ 基于深度学习的双重色散环境中的信道估计综述") 节提供了详细的计算复杂度分析。最后，第 [VIII](#S8
    "VIII 结论 ‣ 基于深度学习的双重色散环境中的信道估计综述") 节总结了本研究。
- en: 'Notations: Throughout the paper, vectors are defined with lowercase bold symbols
    $\bm{x}$ whose $k$-th element is $\bm{x}[k]$. Time and frequency domain vectors
    are represented by $\bm{x}$ and $\tilde{\bm{x}}$ respectively. Matrices are written
    as uppercase bold symbols $\bm{X}$. $\mathrm{E}\left[.\right]$ denotes the expectation
    operator. The trace of a square matrix $\bm{X}$ is $\mathrm{trace}\left\{\bm{X}\right\}$.
    The notation $\odot$ and $\oslash$ refer to the element-wise multiplication and
    division operations, respectively. Finally. the pseudo inverse and conjugate matrices
    of $\bm{X}$ are signified by $\bm{X}^{\dagger}$ and $\bm{X}^{\text{H}}$, respectively.'
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 符号说明：在整个论文中，向量用小写粗体符号 $\bm{x}$ 表示，其第 $k$ 个元素为 $\bm{x}[k]$。时间域和频域向量分别用 $\bm{x}$
    和 $\tilde{\bm{x}}$ 表示。矩阵用大写粗体符号 $\bm{X}$ 表示。$\mathrm{E}\left[.\right]$ 表示期望算子。方阵
    $\bm{X}$ 的迹为 $\mathrm{trace}\left\{\bm{X}\right\}$。符号 $\odot$ 和 $\oslash$ 分别指代元素级的乘法和除法运算。最后，$\bm{X}$
    的伪逆和共轭矩阵分别用 $\bm{X}^{\dagger}$ 和 $\bm{X}^{\text{H}}$ 表示。
- en: II System Model
  id: totrans-619
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 系统模型
- en: Consider a frame comprising $I$ [orthogonal frequency division multiplexing](#id208.208.id208)
    ([OFDM](#id208.208.id208)) symbols. The $i$-th transmitted frequency-domain [OFDM](#id208.208.id208)
    symbol $\tilde{\bm{x}}_{i}[k]$, is denoted by
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个包含 $I$ 个[正交频分复用](#id208.208.id208)（[OFDM](#id208.208.id208)）符号的框架。第 $i$
    个发送的频域[OFDM](#id208.208.id208)符号 $\tilde{\bm{x}}_{i}[k]$ 表示为
- en: '|  | <math   alttext="\tilde{\bm{x}}_{i}[k]=\left\{\begin{array}[]{ll}\tilde{\bm{x}}_{\text{d}_{i}}[k],&amp;\quad
    k\in{\mathcal{K}}_{\text{d}}.\\ \tilde{\bm{x}}_{\text{p}_{i}}[k],&amp;\quad k\in{\mathcal{K}}_{\text{p}}.\\'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math alttext="\tilde{\bm{x}}_{i}[k]=\left\{\begin{array}[]{ll}\tilde{\bm{x}}_{\text{d}_{i}}[k],&amp;\quad
    k\in{\mathcal{K}}_{\text{d}}.\\ \tilde{\bm{x}}_{\text{p}_{i}}[k],&amp;\quad k\in{\mathcal{K}}_{\text{p}}.\\'
- en: \end{array}\right." display="block"><semantics ><mrow ><mrow  ><msub ><mover
    accent="true" ><mi  >𝒙</mi><mo >~</mo></mover><mi >i</mi></msub><mo lspace="0em"
    rspace="0em" >​</mo><mrow  ><mo stretchy="false"  >[</mo><mi >k</mi><mo stretchy="false"
    >]</mo></mrow></mrow><mo  >=</mo><mrow ><mo >{</mo><mtable columnspacing="5pt"
    displaystyle="true" rowspacing="0pt"  ><mtr ><mtd  columnalign="left" ><mrow  ><mrow
    ><msub ><mover accent="true" ><mi  >𝒙</mi><mo >~</mo></mover><msub ><mtext >d</mtext><mi
    >i</mi></msub></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"
    >[</mo><mi >k</mi><mo stretchy="false" >]</mo></mrow></mrow><mo >,</mo></mrow></mtd><mtd
    columnalign="left"  ><mrow ><mrow ><mi  >k</mi><mo >∈</mo><msub ><mi >𝒦</mi><mtext
    >d</mtext></msub></mrow><mo lspace="0em"  >.</mo></mrow></mtd></mtr><mtr ><mtd  columnalign="left"
    ><mrow  ><mrow ><msub ><mover accent="true" ><mi  >𝒙</mi><mo >~</mo></mover><msub
    ><mtext >p</mtext><mi >i</mi></msub></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" >[</mo><mi >k</mi><mo stretchy="false" >]</mo></mrow></mrow><mo
    >,</mo></mrow></mtd><mtd columnalign="left"  ><mrow ><mrow ><mi  >k</mi><mo >∈</mo><msub
    ><mi >𝒦</mi><mtext >p</mtext></msub></mrow><mo lspace="0em"  >.</mo></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><apply ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><apply
    ><ci >~</ci><ci  >𝒙</ci></apply><ci >𝑖</ci></apply><apply ><csymbol cd="latexml"
    >delimited-[]</csymbol><ci  >𝑘</ci></apply></apply><apply ><csymbol cd="latexml"
    >cases</csymbol><matrix  ><matrixrow ><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><apply
    ><ci >~</ci><ci >𝒙</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    ><mtext mathsize="70%" >d</mtext></ci><ci >𝑖</ci></apply></apply><apply ><csymbol
    cd="latexml" >delimited-[]</csymbol><ci >𝑘</ci></apply></apply><apply ><ci  >𝑘</ci><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝒦</ci><ci ><mtext mathsize="70%"  >d</mtext></ci></apply></apply></matrixrow><matrixrow
    ><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><ci >~</ci><ci
    >𝒙</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci ><mtext
    mathsize="70%" >p</mtext></ci><ci >𝑖</ci></apply></apply><apply ><csymbol cd="latexml"
    >delimited-[]</csymbol><ci >𝑘</ci></apply></apply><apply ><ci  >𝑘</ci><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝒦</ci><ci ><mtext mathsize="70%"  >p</mtext></ci></apply></apply></matrixrow></matrix></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\tilde{\bm{x}}_{i}[k]=\left\{\begin{array}[]{ll}\tilde{\bm{x}}_{\text{d}_{i}}[k],&\quad
    k\in{\mathcal{K}}_{\text{d}}.\\ \tilde{\bm{x}}_{\text{p}_{i}}[k],&\quad k\in{\mathcal{K}}_{\text{p}}.\\
    \end{array}\right.</annotation></semantics></math> |  | (1) |
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: \end{array}\right." display="block"><semantics ><mrow ><mrow  ><msub ><mover
    accent="true" ><mi  >𝒙</mi><mo >~</mo></mover><mi >i</mi></msub><mo lspace="0em"
    rspace="0em" >​</mo><mrow  ><mo stretchy="false"  >[</mo><mi >k</mi><mo stretchy="false"
    >]</mo></mrow></mrow><mo  >=</mo><mrow ><mo >{</mo><mtable columnspacing="5pt"
    displaystyle="true" rowspacing="0pt"  ><mtr ><mtd  columnalign="left" ><mrow  ><mrow
    ><msub ><mover accent="true" ><mi  >𝒙</mi><mo >~</mo></mover><msub ><mtext >d</mtext><mi
    >i</mi></msub></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"
    >[</mo><mi >k</mi><mo stretchy="false" >]</mo></mrow></mrow><mo >,</mo></mrow></mtd><mtd
    columnalign="left"  ><mrow ><mrow ><mi  >k</mi><mo >∈</mo><msub ><mi >𝒦</mi><mtext
    >d</mtext></msub></mrow><mo lspace="0em"  >.</mo></mrow></mtd></mtr><mtr ><mtd  columnalign="left"
    ><mrow  ><mrow ><msub ><mover accent="true" ><mi  >𝒙</mi><mo >~</mo></mover><msub
    ><mtext >p</mtext><mi >i</mi></msub></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" >[</mo><mi >k</mi><mo stretchy="false" >]</mo></mrow></mrow><mo
    >,</mo></mrow></mtd><mtd columnalign="left"  ><mrow ><mrow ><mi  >k</mi><mo >∈</mo><msub
    ><mi >𝒦</mi><mtext >p</mtext></msub></mrow><mo lspace="0em"  >.</mo></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><apply ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><apply
    ><ci >~</ci><ci  >𝒙</ci></apply><ci >𝑖</ci></apply><apply ><csymbol cd="latexml"
    >delimited-[]</csymbol><ci >𝑘</ci></apply></apply><apply ><csymbol cd="latexml"
    >cases</csymbol><matrix  ><matrixrow ><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><apply
    ><ci >~</ci><ci >𝒙</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    ><mtext mathsize="70%" >d</mtext></ci><ci >𝑖</ci></apply></apply><apply ><csymbol
    cd="latexml" >delimited-[]</csymbol><ci >𝑘</ci></apply></apply><apply ><ci  >𝑘</ci><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝒦</ci><ci ><mtext mathsize="70%"  >d</mtext></ci></apply></apply></matrixrow><matrixrow
    ><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><ci >~</ci><ci
    >𝒙</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci ><mtext
    mathsize="70%" >p</mtext></ci><ci >𝑖</ci></apply></apply><apply ><csymbol cd="latexml"
    >delimited-[]</csymbol><ci >𝑘</ci></apply></apply><apply ><ci  >𝑘</ci><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝒦</ci><ci ><mtext mathsize="70%"  >p</mtext></ci></apply></apply></matrixrow></matrix></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\tilde{\bm{x}}_{i}[k]=\left\{\begin{array}[]{ll}\tilde{\bm{x}}_{\text{d}_{i}}[k],&\quad
    k\in{\mathcal{K}}_{\text{d}}.\\ \tilde{\bm{x}}_{\text{p}_{i}}[k],&\quad k\in{\mathcal{K}}_{\text{p}}.\\
    \end{array}\right.</annotation></semantics></math> |  | (1) |
- en: where $0\leq k\leq K-1$. $\tilde{\bm{x}}_{\text{d}_{i}}[k]$ and $\tilde{\bm{x}}_{\text{p}_{i}}[k]$
    represent the modulated data symbols and the predefined pilot symbols allocated
    at a set of subcarriers denoted ${\mathcal{K}}_{\text{d}}$ and ${\mathcal{K}}_{\text{p}}$,
    respectively. $\bm{x}_{i}[k]$ is converted to the time domain by applying the
    [inverse discrete Fourier transform](#id150.150.id150) ([IDFT](#id150.150.id150)),
    such that
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $0\leq k\leq K-1$。$\tilde{\bm{x}}_{\text{d}_{i}}[k]$ 和 $\tilde{\bm{x}}_{\text{p}_{i}}[k]$
    分别表示在一组子载波 ${\mathcal{K}}_{\text{d}}$ 和 ${\mathcal{K}}_{\text{p}}$ 上分配的调制数据符号和预定义的导频符号。$\bm{x}_{i}[k]$
    通过应用 [逆离散傅里叶变换](#id150.150.id150) ([IDFT](#id150.150.id150)) 转换到时间域，如下所示
- en: '|  | $\bm{x}_{i}[n]=\frac{1}{\sqrt{{{K}}}}\sum_{k=0}^{{K}-1}\tilde{\bm{x}}_{i}[k]e^{j2\pi\frac{nk}{{K}}}.$
    |  | (2) |'
  id: totrans-624
  prefs: []
  type: TYPE_TB
  zh: '|  | $\bm{x}_{i}[n]=\frac{1}{\sqrt{{{K}}}}\sum_{k=0}^{{K}-1}\tilde{\bm{x}}_{i}[k]e^{j2\pi\frac{nk}{{K}}}.$
    |  | (2) |'
- en: A [cyclic prefix](#id82.82.id82) ([CP](#id82.82.id82)) of length larger than
    the delay spread is added. Therefore, after passing via the doubly-dispersive
    channel and removing the [CP](#id82.82.id82), the received [OFDM](#id208.208.id208)
    symbol $\bm{y}_{i}[n]$ can be expressed as follows
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 添加一个长度大于时延扩展的 [循环前缀](#id82.82.id82) ([CP](#id82.82.id82))。因此，在经过双重色散通道并去除 [CP](#id82.82.id82)
    后，接收到的 [OFDM](#id208.208.id208) 符号 $\bm{y}_{i}[n]$ 可以表示如下
- en: '|  | $\begin{split}\bm{y}_{i}[n]&amp;=\sum_{l=0}^{L-1}{\bm{h}_{i}[l,n]}\bm{x}_{i}[n-l]+{\bm{v}}_{i}[n]\\
    &amp;=\frac{1}{\sqrt{{K}}}\sum_{k=0}^{{K}-1}{\tilde{\bm{h}}_{i}[k,n]}\tilde{\bm{x}}_{i}[k]e^{j2\pi\frac{nk}{{K}}}+{\bm{v}}_{i}[n].\end{split}$
    |  | (3) |'
  id: totrans-626
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\bm{y}_{i}[n]&amp;=\sum_{l=0}^{L-1}{\bm{h}_{i}[l,n]}\bm{x}_{i}[n-l]+{\bm{v}}_{i}[n]\\
    &amp;=\frac{1}{\sqrt{{K}}}\sum_{k=0}^{{K}-1}{\tilde{\bm{h}}_{i}[k,n]}\tilde{\bm{x}}_{i}[k]e^{j2\pi\frac{nk}{{K}}}+{\bm{v}}_{i}[n].\end{split}$
    |  | (3) |'
- en: $\bm{h}_{i}[l,n]$ denotes the delay-time response of the discrete [linear time-variant](#id176.176.id176)
    ([LTV](#id176.176.id176)) channel of $L$ taps at the $i$-th [OFDM](#id208.208.id208)
    symbol, whereas $\tilde{\bm{h}}_{i}[k,n]=\sum_{l=0}^{L-1}{{\bm{h}}_{i}[l,n]}e^{-j2\pi\frac{lk}{{K}}}$
    refers to the frequency-time response. Moreover, ${\bm{v}}_{i}$ signifies the
    [additive white Gaussian noise](#id62.62.id62) ([AWGN](#id62.62.id62)) of variance
    $\sigma^{2}$. The $i$-th received frequency-domain [OFDM](#id208.208.id208) symbol
    is derived from ([3](#S2.E3 "In II System Model ‣ A Survey on Deep Learning based
    Channel Estimation in Doubly Dispersive Environments")) via [discrete Fourier
    transform](#id95.95.id95) ([DFT](#id95.95.id95)), and thus
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: $\bm{h}_{i}[l,n]$ 表示在第 $i$ 个 [OFDM](#id208.208.id208) 符号处，具有 $L$ 个抽头的离散 [线性时变](#id176.176.id176)
    ([LTV](#id176.176.id176)) 通道的时延响应，而 $\tilde{\bm{h}}_{i}[k,n]=\sum_{l=0}^{L-1}{{\bm{h}}_{i}[l,n]}e^{-j2\pi\frac{lk}{{K}}}$
    则指的是频率-时间响应。此外，${\bm{v}}_{i}$ 表示方差为 $\sigma^{2}$ 的 [加性白高斯噪声](#id62.62.id62) ([AWGN](#id62.62.id62))。第
    $i$ 个接收的频域 [OFDM](#id208.208.id208) 符号通过 ([3](#S2.E3 "In II System Model ‣ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments"))
    的 [离散傅里叶变换](#id95.95.id95) ([DFT](#id95.95.id95)) 得到，因此
- en: '|  | $\begin{split}\tilde{\bm{y}}_{i}[k]&amp;=\frac{1}{{{K}}}\sum_{q=0}^{{K}-1}\tilde{\bm{x}}_{i}[q]\sum_{n=0}^{{K}-1}\tilde{\bm{h}}_{i}[q,n]e^{-j2\pi\frac{n(k-q)}{{K}}}+\tilde{\bm{v}}_{i}[k].\end{split}$
    |  | (4) |'
  id: totrans-628
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\tilde{\bm{y}}_{i}[k]&amp;=\frac{1}{{{K}}}\sum_{q=0}^{{K}-1}\tilde{\bm{x}}_{i}[q]\sum_{n=0}^{{K}-1}\tilde{\bm{h}}_{i}[q,n]e^{-j2\pi\frac{n(k-q)}{{K}}}+\tilde{\bm{v}}_{i}[k].\end{split}$
    |  | (4) |'
- en: It is noteworthy that index $k$ is used in ([3](#S2.E3 "In II System Model ‣
    A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments"))
    to express the channel delay-time response in terms of the channel frequency-time
    response. While the change of index into $q$ in ([4](#S2.E4 "In II System Model
    ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments"))
    is used to express the $i$-th received symbol in frequency domain. This, in turn,
    better illustrates the DFT transform. Moreover, $\tilde{\bm{h}}_{i}[q,n]$ refers
    to time-variant at the scale of the [OFDM](#id208.208.id208) symbol duration (the
    index $i$) and within the symbol itself (the index $n$). Accordingly,
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，索引 $k$ 在 ([3](#S2.E3 "In II System Model ‣ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments")) 中用于以通道频率-时间响应的形式表达通道时延响应。而在
    ([4](#S2.E4 "In II System Model ‣ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments")) 中将索引更改为 $q$ 是为了表达第 $i$ 个接收的频域符号。这反过来更好地说明了
    DFT 变换。此外，$\tilde{\bm{h}}_{i}[q,n]$ 指的是在 [OFDM](#id208.208.id208) 符号持续时间尺度（索引
    $i$）和符号本身（索引 $n$）下的时变。
- en: '|  | $\begin{split}\tilde{\bm{h}}_{i}[q,n]&amp;=\sum_{l=0}^{L-1}e^{-j2\pi\frac{lq}{K}}\int_{\nu=-\nu_{d}}^{\nu=\nu_{d}}\bar{h}(l,\nu)e^{j2\pi\nu
    n_{i}}e^{j2\pi\nu n}d\nu,\end{split}$ |  | (5) |'
  id: totrans-630
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\tilde{\bm{h}}_{i}[q,n]&amp;=\sum_{l=0}^{L-1}e^{-j2\pi\frac{lq}{K}}\int_{\nu=-\nu_{d}}^{\nu=\nu_{d}}\bar{h}(l,\nu)e^{j2\pi\nu
    n_{i}}e^{j2\pi\nu n}d\nu,\end{split}$ |  | (5) |'
- en: where $\bar{h}(l,\nu)=\sum\limits_{n}{h}[l,n]e^{-j2\pi n\nu}$ signifies the
    channel delay-Doppler response, $\nu$ refers to the normalized Doppler frequency,
    $n_{i}=i(K+K_{\text{cp}})+K_{\text{cp}}$. And $\nu_{d}=\frac{f_{d}}{F_{s}}$ represents
    the maximum Doppler frequency. Let
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\bar{h}(l,\nu)=\sum\limits_{n}{h}[l,n]e^{-j2\pi n\nu}$ 表示通道延迟-多普勒响应，$\nu$
    指的是归一化多普勒频率，$n_{i}=i(K+K_{\text{cp}})+K_{\text{cp}}$。而 $\nu_{d}=\frac{f_{d}}{F_{s}}$
    表示最大多普勒频率。设
- en: '|  | $\begin{split}\bar{\bm{h}}_{i}[l,v]&amp;=\frac{1}{K}\sum_{q=0}^{{K}-1}\sum_{n=0}^{{K}-1}\tilde{\bm{h}}_{i}[q,n]e^{-j2\pi\frac{nv}{K}}e^{j2\pi\frac{ql}{K}}\\
    &amp;=\int_{\nu=-\nu_{d}}^{\nu=\nu_{d}}\bar{h}(l,\nu)e^{j2\pi\nu n_{i}}\sum_{n=0}^{{K}-1}e^{-j2\pi(\nu-\frac{v}{K})n}d\nu,\end{split}$
    |  | (6) |'
  id: totrans-632
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\bar{\bm{h}}_{i}[l,v]&amp;=\frac{1}{K}\sum_{q=0}^{{K}-1}\sum_{n=0}^{{K}-1}\tilde{\bm{h}}_{i}[q,n]e^{-j2\pi\frac{nv}{K}}e^{j2\pi\frac{ql}{K}}\\
    &amp;=\int_{\nu=-\nu_{d}}^{\nu=\nu_{d}}\bar{h}(l,\nu)e^{j2\pi\nu n_{i}}\sum_{n=0}^{{K}-1}e^{-j2\pi(\nu-\frac{v}{K})n}d\nu,\end{split}$
    |  | (6) |'
- en: be the discrete delay-Doppler response at the $i$-th [OFDM](#id208.208.id208)
    symbol. For the sake of simplicity, $\bar{h}(l,\nu)$ is assumed to be uncorrelated
    in both domains [[36](#bib.bib36)], such that $\mathrm{E}\left[\bar{h}(l,\nu)\bar{h}^{*}(l^{\prime},\nu^{\prime})\right]=S_{h}(l,\nu)\delta(l-l^{\prime})\delta(\nu-\nu^{\prime})$,
    where $S_{h}(l,\nu)$ is the delay-Doppler spectrum [[37](#bib.bib37)], and $\delta(x)$
    denotes the Dirac delta function. Using ([6](#S2.E6 "In II System Model ‣ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")),
    we have
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 是第 $i$ 个 [OFDM](#id208.208.id208) 符号的离散延迟-多普勒响应。为了简化起见，假设 $\bar{h}(l,\nu)$ 在两个领域中都是不相关的
    [[36](#bib.bib36)]，即 $\mathrm{E}\left[\bar{h}(l,\nu)\bar{h}^{*}(l^{\prime},\nu^{\prime})\right]=S_{h}(l,\nu)\delta(l-l^{\prime})\delta(\nu-\nu^{\prime})$，其中
    $S_{h}(l,\nu)$ 是延迟-多普勒谱 [[37](#bib.bib37)]，而 $\delta(x)$ 表示狄拉克 delta 函数。使用 ([6](#S2.E6
    "在 II 系统模型 ‣ 关于双重色散环境中基于深度学习的信道估计的综述"))，我们得到
- en: '|  | $\begin{split}\mathrm{E}\left[\bar{\bm{h}}_{i}[l,v]\bar{\bm{h}}_{i}^{*}[l,v^{\prime}]\right]=&amp;\\
    \int_{\nu=-\nu_{d}}^{\nu=\nu_{d}}S_{h}(l,\nu)\sum_{n=0}^{{K}-1}&amp;\sum_{n^{\prime}=0}^{{K}-1}e^{-j2\pi\nu(n-n^{\prime})}e^{-j2\pi\frac{n^{\prime}v^{\prime}-nv}{K}}d\nu.\end{split}$
    |  | (7) |'
  id: totrans-634
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\mathrm{E}\left[\bar{\bm{h}}_{i}[l,v]\bar{\bm{h}}_{i}^{*}[l,v^{\prime}]\right]=&amp;\\
    \int_{\nu=-\nu_{d}}^{\nu=\nu_{d}}S_{h}(l,\nu)\sum_{n=0}^{{K}-1}&amp;\sum_{n^{\prime}=0}^{{K}-1}e^{-j2\pi\nu(n-n^{\prime})}e^{-j2\pi\frac{n^{\prime}v^{\prime}-nv}{K}}d\nu.\end{split}$
    |  | (7) |'
- en: This correlation that is independent of the index $i$ can be approximated as
    follows
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 这个与索引 $i$ 无关的相关性可以近似为如下
- en: '|  | $\begin{split}\mathrm{E}\left[\bar{\bm{h}}_{i}[l,v]\bar{\bm{h}}_{i}^{*}[l,v^{\prime}]\right]&amp;\approx
    K^{2}\rho[l,v]\delta[v-v^{\prime}],\\ \mbox{where }&amp;\rho[l,v]=S_{h}(l,\frac{v}{N}).\end{split}$
    |  | (8) |'
  id: totrans-636
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\mathrm{E}\left[\bar{\bm{h}}_{i}[l,v]\bar{\bm{h}}_{i}^{*}[l,v^{\prime}]\right]&amp;\approx
    K^{2}\rho[l,v]\delta[v-v^{\prime}],\\ \mbox{where }&amp;\rho[l,v]=S_{h}(l,\frac{v}{N}).\end{split}$
    |  | (8) |'
- en: The time selectivity of the channel depends on the mobility. In very low mobility,
    where $f_{\text{d}}\approx 0$, $\tilde{\bm{h}}_{i}[q,n]=\tilde{\bm{h}}[q]$ is
    constant during the whole frame. For moderate to high mobility, the channel variation
    within the duration of one [OFDM](#id208.208.id208) symbol is negligible, and
    therefore, $\tilde{\bm{h}}_{i}[q,n]=\tilde{\bm{h}}_{i}[q]$. At very high mobility,
    the channel becomes variant within a single [OFDM](#id208.208.id208) symbol. In
    this instance, $\tilde{\bm{h}}_{i}[q,n]=\tilde{\bm{h}}_{i}[q]+\tilde{\bm{\epsilon}}_{i}[q,n]$,
    where
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: 通道的时间选择性依赖于移动性。在非常低的移动性下，$f_{\text{d}}\approx 0$，$\tilde{\bm{h}}_{i}[q,n]=\tilde{\bm{h}}[q]$
    在整个帧内是常量。对于中等到高移动性，单个[OFDM](#id208.208.id208)符号内的通道变化可以忽略，因此，$\tilde{\bm{h}}_{i}[q,n]=\tilde{\bm{h}}_{i}[q]$。在非常高的移动性下，通道在单个[OFDM](#id208.208.id208)符号内会发生变化。在这种情况下，$\tilde{\bm{h}}_{i}[q,n]=\tilde{\bm{h}}_{i}[q]+\tilde{\bm{\epsilon}}_{i}[q,n]$，其中
- en: '|  | $\tilde{\bm{h}}_{i}[q]=\frac{1}{K}\sum_{n=0}^{K-1}\tilde{\bm{h}}_{i}[q,n],\leavevmode\nobreak\
    \mbox{and }\tilde{\bm{\epsilon}}_{i}[q,n]=\tilde{\bm{h}}_{i}[q,n]-\tilde{\bm{h}}_{i}[q].$
    |  | (9) |'
  id: totrans-638
  prefs: []
  type: TYPE_TB
  zh: '|  | $\tilde{\bm{h}}_{i}[q]=\frac{1}{K}\sum_{n=0}^{K-1}\tilde{\bm{h}}_{i}[q,n],\leavevmode\nobreak\
    \mbox{and }\tilde{\bm{\epsilon}}_{i}[q,n]=\tilde{\bm{h}}_{i}[q,n]-\tilde{\bm{h}}_{i}[q].$
    |  | (9) |'
- en: Replacing this in ([4](#S2.E4 "In II System Model ‣ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments")), we get
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 将其代入 ([4](#S2.E4 "在 II 系统模型 ‣ 关于双重色散环境中基于深度学习的信道估计的综述"))，我们得到
- en: '|  | $\begin{split}\tilde{\bm{y}}_{{i}}[k]&amp;=\tilde{\bm{h}}_{i}[k]\tilde{\bm{x}}_{i}[k]+\tilde{\bm{e}}_{i,\text{d}}[k]+\tilde{\bm{v}}_{i}[k],\leavevmode\nobreak\
    k\in{\mathcal{K}}_{\text{on}}.\end{split}$ |  | (10) |'
  id: totrans-640
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\tilde{\bm{y}}_{{i}}[k]&amp;=\tilde{\bm{h}}_{i}[k]\tilde{\bm{x}}_{i}[k]+\tilde{\bm{e}}_{i,\text{d}}[k]+\tilde{\bm{v}}_{i}[k],\leavevmode\nobreak\
    k\in{\mathcal{K}}_{\text{on}}.\end{split}$ |  | (10) |'
- en: The term $\tilde{\bm{e}}_{i,\text{d}}[k]$ denotes the Doppler interference given
    by
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: 符号$\tilde{\bm{e}}_{i,\text{d}}[k]$表示多普勒干涉，由以下公式给出
- en: '|  | <math   alttext="\begin{split}\tilde{\bm{e}}_{i,\text{d}}[k]&amp;=\frac{1}{{{K}}}\sum_{\begin{subarray}{c}q=0\\
    q\neq k\end{subarray}}^{{K}-1}\sum_{n=0}^{{K}-1}\tilde{\bm{h}}_{i}[q,n]e^{-j2\pi\frac{n(k-q)}{{K}}}\tilde{\bm{x}}_{i}[q]\\'
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}\tilde{\bm{e}}_{i,\text{d}}[k]&amp;=\frac{1}{{{K}}}\sum_{\begin{subarray}{c}q=0\\
    q\neq k\end{subarray}}^{{K}-1}\sum_{n=0}^{{K}-1}\tilde{\bm{h}}_{i}[q,n]e^{-j2\pi\frac{n(k-q)}{{K}}}\tilde{\bm{x}}_{i}[q]\\'
- en: '&amp;=\frac{1}{K}\sum_{\begin{subarray}{c}q\in{\mathcal{K}}_{\text{on}}\\'
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;=\frac{1}{K}\sum_{\begin{subarray}{c}q\in{\mathcal{K}}_{\text{on}}\\'
- en: q\neq k\end{subarray}}\sum_{l=0}^{L-1}\bar{\bm{h}}_{i}[l,k-q]e^{-j2\pi\frac{lq}{K}}\tilde{\bm{x}}_{i}[q].\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"
    ><mtr ><mtd columnalign="right" ><mrow ><msub ><mover accent="true"  ><mi >𝒆</mi><mo
    >~</mo></mover><mrow ><mi  >i</mi><mo >,</mo><mtext >d</mtext></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"  >[</mo><mi >k</mi><mo
    stretchy="false" >]</mo></mrow></mrow></mtd><mtd columnalign="left" ><mrow ><mo
    >=</mo><mrow ><mfrac ><mn >1</mn><mi  >K</mi></mfrac><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><munderover ><mo movablelimits="false" rspace="0em"  >∑</mo><mtable rowspacing="0pt"  ><mtr
    ><mtd ><mrow ><mi >q</mi><mo >=</mo><mn >0</mn></mrow></mtd></mtr><mtr ><mtd ><mrow
    ><mi >q</mi><mo >≠</mo><mi >k</mi></mrow></mtd></mtr></mtable><mrow ><mi >K</mi><mo
    >−</mo><mn >1</mn></mrow></munderover><mrow ><munderover ><mo movablelimits="false"
    >∑</mo><mrow ><mi >n</mi><mo >=</mo><mn >0</mn></mrow><mrow ><mi >K</mi><mo >−</mo><mn
    >1</mn></mrow></munderover><mrow ><msub ><mover accent="true" ><mi  >𝒉</mi><mo
    >~</mo></mover><mi >i</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo
    stretchy="false" >[</mo><mi  >q</mi><mo >,</mo><mi >n</mi><mo stretchy="false"
    >]</mo></mrow><mo lspace="0em" rspace="0em" >​</mo><msup ><mi >e</mi><mrow ><mo
    >−</mo><mrow ><mi >j</mi><mo lspace="0em" rspace="0em"  >​</mo><mn >2</mn><mo
    lspace="0em" rspace="0em"  >​</mo><mi >π</mi><mo lspace="0em" rspace="0em"  >​</mo><mfrac
    ><mrow ><mi >n</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"  >(</mo><mrow
    ><mi >k</mi><mo >−</mo><mi >q</mi></mrow><mo stretchy="false"  >)</mo></mrow></mrow><mi
    >K</mi></mfrac></mrow></mrow></msup><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mover accent="true" ><mi >𝒙</mi><mo >~</mo></mover><mi >i</mi></msub><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo stretchy="false" >[</mo><mi  >q</mi><mo stretchy="false"  >]</mo></mrow></mrow></mrow></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="left" ><mrow ><mrow ><mo >=</mo><mrow ><mfrac  ><mn >1</mn><mi
    >K</mi></mfrac><mo lspace="0em" rspace="0em"  >​</mo><mrow ><munder ><mo movablelimits="false"
    rspace="0em"  >∑</mo><mtable rowspacing="0pt"  ><mtr ><mtd ><mrow ><mi >q</mi><mo
    >∈</mo><msub ><mi>𝒦</mi><mtext >on</mtext></msub></mrow></mtd></mtr><mtr ><mtd
    ><mrow ><mi >q</mi><mo >≠</mo><mi >k</mi></mrow></mtd></mtr></mtable></munder><mrow
    ><munderover ><mo movablelimits="false"  >∑</mo><mrow ><mi >l</mi><mo >=</mo><mn
    >0</mn></mrow><mrow ><mi  >L</mi><mo >−</mo><mn >1</mn></mrow></munderover><mrow
    ><msub ><mover accent="true"  ><mi >𝒉</mi><mo >¯</mo></mover><mi >i</mi></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >[</mo><mi  >l</mi><mo
    >,</mo><mrow ><mi >k</mi><mo >−</mo><mi >q</mi></mrow><mo stretchy="false" >]</mo></mrow><mo
    lspace="0em" rspace="0em" >​</mo><msup ><mi >e</mi><mrow ><mo >−</mo><mrow ><mi
    >j</mi><mo lspace="0em" rspace="0em"  >​</mo><mn >2</mn><mo lspace="0em" rspace="0em"  >​</mo><mi
    >π</mi><mo lspace="0em" rspace="0em"  >​</mo><mfrac ><mrow ><mi >l</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi >q</mi></mrow><mi >K</mi></mfrac></mrow></mrow></msup><mo
    lspace="0em" rspace="0em"  >​</mo><msub ><mover accent="true" ><mi >𝒙</mi><mo
    >~</mo></mover><mi >i</mi></msub><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo
    stretchy="false" >[</mo><mi  >q</mi><mo stretchy="false"  >]</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo
    lspace="0em"  >.</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content"
    ><apply ><apply  ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><apply
    ><ci  >~</ci><ci >𝒆</ci></apply><list ><ci >𝑖</ci><ci ><mtext mathsize="70%" >d</mtext></ci></list></apply><apply
    ><csymbol cd="latexml" >delimited-[]</csymbol><ci >𝑘</ci></apply></apply><apply
    ><apply  ><cn type="integer"  >1</cn><ci >𝐾</ci></apply><apply ><apply ><csymbol
    cd="ambiguous" >superscript</csymbol><apply ><csymbol cd="ambiguous" >subscript</csymbol><list
    ><matrix ><matrixrow ><apply ><ci >𝑞</ci><cn type="integer" >0</cn></apply></matrixrow><matrixrow
    ><apply ><ci >𝑞</ci><ci >𝑘</ci></apply></matrixrow></matrix></list></apply><apply
    ><ci >𝐾</ci><cn type="integer" >1</cn></apply></apply><apply ><apply  ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply ><csymbol cd="ambiguous"  >subscript</csymbol><apply
    ><ci >𝑛</ci><cn type="integer" >0</cn></apply></apply><apply ><ci >𝐾</ci><cn type="integer"
    >1</cn></apply></apply><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><apply
    ><ci  >~</ci><ci >𝒉</ci></apply><ci >𝑖</ci></apply><interval closure="closed"  ><ci
    >𝑞</ci><ci >𝑛</ci></interval><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >𝑒</ci><apply ><apply ><ci >𝑗</ci><cn type="integer"  >2</cn><ci >𝜋</ci><apply
    ><apply ><ci >𝑛</ci><apply ><ci >𝑘</ci><ci >𝑞</ci></apply></apply><ci >𝐾</ci></apply></apply></apply></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><ci >~</ci><ci >𝒙</ci></apply><ci
    >𝑖</ci></apply><apply ><csymbol cd="latexml" >delimited-[]</csymbol><ci >𝑞</ci></apply></apply></apply></apply></apply></apply><apply
    ><apply ><apply  ><cn type="integer"  >1</cn><ci >𝐾</ci></apply><apply ><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><list ><matrix ><matrixrow ><apply
    ><ci >𝑞</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝒦</ci><ci
    ><mtext mathsize="50%" >on</mtext></ci></apply></apply></matrixrow><matrixrow
    ><apply ><ci >𝑞</ci><ci >𝑘</ci></apply></matrixrow></matrix></list></apply><apply
    ><apply ><csymbol cd="ambiguous" >superscript</csymbol><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><apply ><ci  >𝑙</ci><cn type="integer"  >0</cn></apply></apply><apply
    ><ci >𝐿</ci><cn type="integer" >1</cn></apply></apply><apply ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><apply ><ci  >¯</ci><ci >𝒉</ci></apply><ci
    >𝑖</ci></apply><interval closure="closed"  ><ci >𝑙</ci><apply ><ci >𝑘</ci><ci
    >𝑞</ci></apply></interval><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >𝑒</ci><apply ><apply ><ci >𝑗</ci><cn type="integer"  >2</cn><ci >𝜋</ci><apply
    ><apply ><ci >𝑙</ci><ci >𝑞</ci></apply><ci >𝐾</ci></apply></apply></apply></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><ci >~</ci><ci >𝒙</ci></apply><ci
    >𝑖</ci></apply><apply ><csymbol cd="latexml" >delimited-[]</csymbol><ci >𝑞</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}\tilde{\bm{e}}_{i,\text{d}}[k]&=\frac{1}{{{K}}}\sum_{\begin{subarray}{c}q=0\\
    q\neq k\end{subarray}}^{{K}-1}\sum_{n=0}^{{K}-1}\tilde{\bm{h}}_{i}[q,n]e^{-j2\pi\frac{n(k-q)}{{K}}}\tilde{\bm{x}}_{i}[q]\\
    &=\frac{1}{K}\sum_{\begin{subarray}{c}q\in{\mathcal{K}}_{\text{on}}\\ q\neq k\end{subarray}}\sum_{l=0}^{L-1}\bar{\bm{h}}_{i}[l,k-q]e^{-j2\pi\frac{lq}{K}}\tilde{\bm{x}}_{i}[q].\end{split}</annotation></semantics></math>
    |  | (11) |
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
- en: The Doppler interference destroys the orthogonality of the subcarriers within
    the received [OFDM](#id208.208.id208) symbol, leading to a significant degradation
    in the overall system performance [[38](#bib.bib38)]. Assuming that the subcarriers
    are uncorrelated with power $E_{q}$, i.e. $\mathrm{E}\left[\tilde{\bm{x}}_{i}[q]\tilde{\bm{x}}^{*}_{i}[q^{\prime}]\right]=E_{q}\delta[q-q^{\prime}]$
    and using ([8](#S2.E8 "In II System Model ‣ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments")) then
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: 假设子载波在功率$E_{q}$下是互不相关的，即$\mathrm{E}\left[\tilde{\bm{x}}_{i}[q]\tilde{\bm{x}}^{*}_{i}[q^{\prime}]\right]=E_{q}\delta[q-q^{\prime}]$，并使用（[8](#S2.E8
    "在 II 系统模型 ‣ 基于深度学习的双重色散环境下的信道估计调查")）然后
- en: '|  | <math   alttext="\begin{split}\mathrm{E}\left[\tilde{\bm{e}}_{i,\text{d}}[k]\tilde{\bm{e}}^{*}_{i,\text{d}}[k^{\prime}]\right]&amp;=\sum_{l=0}^{L-1}\sum_{\begin{subarray}{c}q\in{\mathcal{K}}_{\text{on}}\\
    q\neq k\end{subarray}}E_{q}\rho[l,k-q]\delta[k-k^{\prime}]\\'
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 多普勒干扰破坏了接收的[OFDM](#id208.208.id208)符号中子载波的正交性，导致整体系统性能显著下降[[38](#bib.bib38)]。
- en: '&amp;=\sigma^{2}_{d}[k]\delta[k-k^{\prime}].\end{split}" display="block"><semantics
    ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" ><mtr ><mtd
    columnalign="right" ><mrow ><mi mathvariant="normal"  >E</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo  >[</mo><mrow ><msub ><mover accent="true"  ><mi
    >𝒆</mi><mo >~</mo></mover><mrow ><mi  >i</mi><mo >,</mo><mtext >d</mtext></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >[</mo><mi  >k</mi><mo
    stretchy="false"  >]</mo></mrow><mo lspace="0em" rspace="0em"  >​</mo><msubsup
    ><mover accent="true" ><mi  >𝒆</mi><mo >~</mo></mover><mrow ><mi >i</mi><mo >,</mo><mtext
    >d</mtext></mrow><mo >∗</mo></msubsup><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" >[</mo><msup ><mi >k</mi><mo >′</mo></msup><mo stretchy="false"  >]</mo></mrow></mrow><mo
    >]</mo></mrow></mrow></mtd><mtd columnalign="left" ><mrow ><mo rspace="0.111em"  >=</mo><mrow
    ><munderover ><mo movablelimits="false" rspace="0em"  >∑</mo><mrow ><mi >l</mi><mo
    >=</mo><mn >0</mn></mrow><mrow ><mi >L</mi><mo >−</mo><mn >1</mn></mrow></munderover><mrow
    ><munder ><mo movablelimits="false" >∑</mo><mtable rowspacing="0pt" ><mtr ><mtd
    ><mrow ><mi >q</mi><mo >∈</mo><msub ><mi >𝒦</mi><mtext >on</mtext></msub></mrow></mtd></mtr><mtr
    ><mtd ><mrow ><mi >q</mi><mo >≠</mo><mi >k</mi></mrow></mtd></mtr></mtable></munder><mrow
    ><msub ><mi >E</mi><mi >q</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><mi
    >ρ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >[</mo><mi  >l</mi><mo
    >,</mo><mrow ><mi >k</mi><mo >−</mo><mi >q</mi></mrow><mo stretchy="false" >]</mo></mrow><mo
    lspace="0em" rspace="0em" >​</mo><mi  >δ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" >[</mo><mrow ><mi >k</mi><mo >−</mo><msup ><mi >k</mi><mo
    >′</mo></msup></mrow><mo stretchy="false" >]</mo></mrow></mrow></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="left" ><mrow ><mrow ><mo >=</mo><mrow ><msubsup ><mi >σ</mi><mi
    >d</mi><mn >2</mn></msubsup><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo stretchy="false"
    >[</mo><mi  >k</mi><mo stretchy="false"  >]</mo></mrow><mo lspace="0em" rspace="0em"  >​</mo><mi
    >δ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >[</mo><mrow
    ><mi >k</mi><mo >−</mo><msup ><mi >k</mi><mo >′</mo></msup></mrow><mo stretchy="false"
    >]</mo></mrow></mrow></mrow><mo lspace="0em"  >.</mo></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><ci >E</ci><apply ><csymbol
    cd="latexml" >delimited-[]</csymbol><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><apply
    ><ci  >~</ci><ci >𝒆</ci></apply><list ><ci >𝑖</ci><ci ><mtext mathsize="70%" >d</mtext></ci></list></apply><apply
    ><csymbol cd="latexml" >delimited-[]</csymbol><ci >𝑘</ci></apply><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><apply ><csymbol cd="ambiguous" >superscript</csymbol><apply
    ><ci  >~</ci><ci >𝒆</ci></apply></apply><list ><ci >𝑖</ci><ci ><mtext mathsize="70%"  >d</mtext></ci></list></apply><apply
    ><csymbol cd="latexml"  >delimited-[]</csymbol><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >𝑘</ci><ci >′</ci></apply></apply></apply></apply></apply><apply ><apply ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply ><csymbol cd="ambiguous"  >subscript</csymbol><apply
    ><ci >𝑙</ci><cn type="integer" >0</cn></apply></apply><apply ><ci >𝐿</ci><cn type="integer"
    >1</cn></apply></apply><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><list
    ><matrix ><matrixrow ><apply ><ci >𝑞</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝒦</ci><ci ><mtext mathsize="50%" >on</mtext></ci></apply></apply></matrixrow><matrixrow
    ><apply ><ci >𝑞</ci><ci >𝑘</ci></apply></matrixrow></matrix></list></apply><apply
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐸</ci><ci >𝑞</ci></apply><ci
    >𝜌</ci><interval closure="closed"  ><ci >𝑙</ci><apply ><ci >𝑘</ci><ci >𝑞</ci></apply></interval><ci
    >𝛿</ci><apply ><csymbol cd="latexml"  >delimited-[]</csymbol><apply ><ci >𝑘</ci><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><ci >𝑘</ci><ci >′</ci></apply></apply></apply></apply></apply></apply></apply><apply
    ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><apply ><csymbol
    cd="ambiguous" >superscript</csymbol><ci >𝜎</ci><cn type="integer" >2</cn></apply><ci
    >𝑑</ci></apply><apply ><csymbol cd="latexml" >delimited-[]</csymbol><ci >𝑘</ci></apply><ci
    >𝛿</ci><apply ><csymbol cd="latexml" >delimited-[]</csymbol><apply ><ci >𝑘</ci><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝑘</ci><ci >′</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}\mathrm{E}\left[\tilde{\bm{e}}_{i,\text{d}}[k]\tilde{\bm{e}}^{*}_{i,\text{d}}[k^{\prime}]\right]&=\sum_{l=0}^{L-1}\sum_{\begin{subarray}{c}q\in{\mathcal{K}}_{\text{on}}\\
    q\neq k\end{subarray}}E_{q}\rho[l,k-q]\delta[k-k^{\prime}]\\ &=\sigma^{2}_{d}[k]\delta[k-k^{\prime}].\end{split}</annotation></semantics></math>
    |  | (12) |'
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;=\sigma^{2}_{d}[k]\delta[k-k^{\prime}].\end{split}" display="block"><semantics
    ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" ><mtr ><mtd
    columnalign="right" ><mrow ><mi mathvariant="normal"  >E</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo  >[</mo><mrow ><msub ><mover accent="true"  ><mi
    >𝒆</mi><mo >~</mo></mover><mrow ><mi  >i</mi><mo >,</mo><mtext >d</mtext></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >[</mo><mi  >k</mi><mo
    stretchy="false"  >]</mo></mrow><mo lspace="0em" rspace="0em"  >​</mo><msubsup
    ><mover accent="true" ><mi  >𝒆</mi><mo >~</mo></mover><mrow ><mi >i</mi><mo >,</mo><mtext
    >d</mtext></mrow><mo >∗</mo></msubsup><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" >[</mo><msup ><mi >k</mi><mo >′</mo></msup><mo stretchy="false"  >]</mo></mrow></mrow><mo
    >]</mo></mrow></mrow></mtd><mtd columnalign="left" ><mrow ><mo rspace="0.111em"  >=</mo><mrow
    ><munderover ><mo movablelimits="false" rspace="0em"  >∑</mo><mrow ><mi >l</mi><mo
    >=</mo><mn >0</mn></mrow><mrow ><mi >L</mi><mo >−</mo><mn >1</mn></mrow></munderover><mrow
    ><munder ><mo movablelimits="false" >∑</mo><mtable rowspacing="0pt" ><mtr ><mtd
    ><mrow ><mi >q</mi><mo >∈</mo><msub ><mi >𝒦</mi><mtext >on</mtext></msub></mrow></mtd></mtr><mtr
    ><mtd ><mrow ><mi >q</mi><mo >≠</mo><mi >k</mi></mrow></mtd></mtr></mtable></munder><mrow
    ><msub ><mi >E</mi><mi >q</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><mi
    >ρ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >[</mo><mi  >l</mi><mo
    >,</mo><mrow ><mi >k</mi><mo >−</mo><mi >q</mi></mrow><mo stretchy="false" >]</mo></mrow><mo
    lspace="0em" rspace="0em" >​</mo><mi  >δ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" >[</mo><mrow ><mi >k</mi><mo >−</mo><msup ><mi >k</mi><mo
    >′</mo></msup></mrow><mo stretchy="false" >]</mo></mrow></mrow></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd  columnalign="left" ><mrow ><mrow ><mo >=</mo><mrow ><msubsup ><mi >σ</mi><mi
    >d</mi><mn >2</mn></msubsup><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo stretchy="false"
    >[</mo><mi  >k</mi><mo stretchy="false"  >]</mo></mrow><mo lspace="0em" rspace="0em"  >​</mo><mi
    >δ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >[</mo><mrow
    ><mi >k</mi><mo >−</mo><msup ><mi >k</mi><mo >′</mo></msup></mrow><mo stretchy="false"
    >]</mo></mrow></mrow></mrow><mo lspace="0em"  >.</mo></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><ci >E</ci><apply ><csymbol
    cd="latexml" >delimited-[]</csymbol><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><apply
    ><ci  >~</ci><ci >𝒆</ci></apply><list ><ci >𝑖</ci><ci ><mtext mathsize="70%" >d</mtext></ci></list></apply><apply
    ><csymbol cd="latexml" >delimited-[]</csymbol><ci >𝑘</ci></apply><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><apply ><csymbol cd="ambiguous" >superscript</csymbol><apply
    ><ci  >~</ci><ci >𝒆</ci></apply></apply><list ><ci >𝑖</ci><ci ><mtext mathsize="70%"  >d</mtext></ci></list></apply><apply
    ><csymbol cd="latexml"  >delimited-[]</csymbol><apply ><csymbol cd="ambiguous"  >superscript</csymbol><ci
    >𝑘</ci><ci >′</ci></apply></apply></apply></apply></apply></apply></apply><apply
    ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><apply ><csymbol cd="ambiguous"  >subscript</csymbol><apply
    ><ci >𝑙</ci><cn type="integer" >0</cn></apply></apply><apply ><ci >𝐿</ci><cn type="integer"
    >1</cn></apply></apply><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><list
    ><matrix ><matrixrow ><apply ><ci >𝑞</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝒦</ci><ci ><mtext mathsize="50%" >on</mtext></ci></apply></apply></matrixrow><matrixrow
    ><apply ><ci >𝑞</ci><ci >𝑘</ci></apply></matrixrow></matrix></list></apply><apply
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐸</ci><ci >𝑞</ci></apply><ci
    >𝜌</ci><interval closure="closed"  ><ci >𝑙</ci><apply ><ci >𝑘</ci><ci >𝑞</ci></apply></interval><ci
    >𝛿</ci><apply ><csymbol cd="latexml"  >delimited-[]</csymbol><apply ><ci >𝑘</ci><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><ci >𝑘</ci><ci >′</ci></apply></apply></apply></apply></apply></apply></apply><apply
    ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><apply ><csymbol
    cd="ambiguous" >superscript</csymbol><ci >𝜎</ci><cn type="integer" >2</cn></apply><ci
    >𝑑</ci></apply><apply ><csymbol cd="latexml" >delimited-[]</csymbol><ci >𝑘</ci></apply><ci
    >𝛿</ci><apply ><csymbol cd="latexml" >delimited-[]</csymbol><apply ><ci >𝑘</ci><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><ci >𝑘</ci><ci >′</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}\mathrm{E}\left[\tilde{\bm{e}}_{i,\text{d}}[k]\tilde{\bm{e}}^{*}_{i,\text{d}}[k^{\prime}]\right]&=\sum_{l=0}^{L-1}\sum_{\begin{subarray}{c}q\in{\mathcal{K}}_{\text{on}}\\
    q\neq k\end{subarray}}E_{q}\rho[l,k-q]\delta[k-k'
- en: Thus, it is assumed that the Doppler interference is uncorrelated. However,
    the variance $\sigma^{2}_{d}[k]=\mathrm{E}\left[|\tilde{\bm{e}}_{i,\text{d}}[k]|^{2}\right]$
    depends on the subcarrier index. Noting that
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，假设多普勒干扰是不相关的。然而，方差$\sigma^{2}_{d}[k]=\mathrm{E}\left[|\tilde{\bm{e}}_{i,\text{d}}[k]|^{2}\right]$依赖于子载波索引。注意到
- en: '|  | $\tilde{\bm{h}}_{i}[k]=\frac{1}{K}\sum_{l=0}^{L-1}\bar{\bm{h}}_{i}[l,0]e^{-j2\pi\frac{kl}{K}},$
    |  | (13) |'
  id: totrans-649
  prefs: []
  type: TYPE_TB
  zh: '|  | $\tilde{\bm{h}}_{i}[k]=\frac{1}{K}\sum_{l=0}^{L-1}\bar{\bm{h}}_{i}[l,0]e^{-j2\pi\frac{kl}{K}},$
    |  | (13) |'
- en: the channel gain and Doppler interference are uncorrelated, i.e. $\mathrm{E}\left[\tilde{\bm{h}}_{i}[k]\tilde{\bm{e}}_{i,\text{d}}^{*}[k]\right]=0$.
    Moreover, it is possible to estimate the $\tilde{\bm{h}}_{i}[k]$ from $L$ uncorrelated
    taps defined by $\bar{\bm{h}}_{i}[l,0]$.
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: 信道增益和多普勒干扰是不相关的，即$\mathrm{E}\left[\tilde{\bm{h}}_{i}[k]\tilde{\bm{e}}_{i,\text{d}}^{*}[k]\right]=0$。此外，可以从由$\bar{\bm{h}}_{i}[l,0]$定义的$L$个不相关的抽头中估计$\tilde{\bm{h}}_{i}[k]$。
- en: III DL Techniques Overview
  id: totrans-651
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 深度学习技术概述
- en: This section discusses the [DL](#id96.96.id96) networks employed in the studied
    [DL](#id96.96.id96)-based channel estimation schemes, providing the mathematical
    representation of each network.
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 本节讨论了在研究的[DL](#id96.96.id96)基础信道估计方案中使用的[DL](#id96.96.id96)网络，并提供了每个网络的数学表示。
- en: III-A FNN
  id: totrans-653
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A FNN
- en: Neural networks are one of the most popular machine learning algorithms [[39](#bib.bib39)].
    Initially, neural networks are inspired by the neural architecture of a human
    brain, For this reason, the basic building block is called a neuron as is the
    case with a human brain. Its functionality is similar to that of a human neuron,
    i.e. it takes in some inputs and then fires an output. In purely mathematical
    terms, a neuron denotes a placeholder for a mathematical function whose job is
    to yield an output by applying the function on the given inputs. Neurons are stacked
    together to form a layer. The neural network comprises at least one layer; in
    case multiple layers are employed, the neural network is referred to as deep [FNN](#id99.99.id99).
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络是最受欢迎的机器学习算法之一[[39](#bib.bib39)]。最初，神经网络受到人脑神经结构的启发，因此其基本构件称为神经元，就像人脑中的神经元一样。它的功能类似于人类神经元，即接收一些输入并产生输出。在纯数学术语中，神经元表示一个数学函数的占位符，其任务是通过对给定输入应用函数来产生输出。神经元被堆叠在一起形成一层。神经网络至少包含一层；如果使用多层，神经网络称为深度[FNN](#id99.99.id99)。
- en: Consider a [FNN](#id99.99.id99) architecture shown in Figure [1](#S3.F1 "Figure
    1 ‣ III-A FNN ‣ III DL Techniques Overview ‣ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments"). Here $\mathcal{L}$ represents
    the number of layers, including one input layer, $\mathcal{L}-2$ hidden layers,
    as well as one output layer . The $l$-th hidden layer of the network consists
    of $J_{l}$ neurons where $2\leq l\leq L-1$. Moreover, each neuron in the $l$-th
    hidden layer is denoted by $j$ where $j$ $1\leq j\leq J_{l}$. The [FNN](#id99.99.id99)
    inputs $\bm{i}$ and outputs $\bm{o}$ are expressed as $\bm{i}=[i_{1},i_{2},...,i_{\mathcal{N}}]^{T}\in\mathbb{R}^{\mathcal{N}\times
    1}$ and $\bm{o}=[o_{1},o_{2},...,o_{\mathcal{M}}]^{T}\in\mathbb{R}^{\mathcal{M}\times
    1}$, where $\mathcal{N}$ and $\mathcal{M}$ refer to the number of [FNN](#id99.99.id99)
    inputs and outputs, respectively. $\bm{W}_{l}\in\mathbb{R}^{J_{l}\times J_{l-1}}$,
    and $\bm{b}_{l}\in\mathbb{R}^{J_{l}\times 1}$ are used to express the weight matrix
    and the bias vector of the $l$-th hidden layer, respectively.
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑图[1](#S3.F1 "图 1 ‣ III-A FNN ‣ III 深度学习技术概述 ‣ 基于深度学习的信道估计在双重扩散环境中的调查")中所示的[FNN](#id99.99.id99)架构。这里$\mathcal{L}$表示层数，包括一个输入层、$\mathcal{L}-2$个隐藏层以及一个输出层。网络的第$l$层隐藏层包含$J_{l}$个神经元，其中$2\leq
    l\leq L-1$。此外，第$l$层隐藏层中的每个神经元由$j$表示，其中$1\leq j\leq J_{l}$。[FNN](#id99.99.id99)的输入$\bm{i}$和输出$\bm{o}$分别表示为$\bm{i}=[i_{1},i_{2},...,i_{\mathcal{N}}]^{T}\in\mathbb{R}^{\mathcal{N}\times
    1}$和$\bm{o}=[o_{1},o_{2},...,o_{\mathcal{M}}]^{T}\in\mathbb{R}^{\mathcal{M}\times
    1}$，其中$\mathcal{N}$和$\mathcal{M}$分别指[FNN](#id99.99.id99)的输入和输出数量。$\bm{W}_{l}\in\mathbb{R}^{J_{l}\times
    J_{l-1}}$和$\bm{b}_{l}\in\mathbb{R}^{J_{l}\times 1}$分别表示第$l$层隐藏层的权重矩阵和偏置向量。
- en: Each neuron $n_{(l,j)}$ performs a nonlinear transform of a weighted summation
    of the preceding layer’s output values. This nonlinear transformation is represented
    by the activation function ${f}_{(l,j)}$ on the neuron input vector $\bm{i}_{(l)}\in\mathbb{R}^{J_{l-1}\times
    1}$ using its weight vector $\bm{\omega}_{(l,j)}\in\mathbb{R}^{J_{l-1}\times 1}$,
    and bias ${b}_{(l,j)}$, respectively. The neuron’s output ${o}_{(l,j)}$ is
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: 每个神经元$n_{(l,j)}$对前一层输出值的加权求和进行非线性变换。这个非线性变换由神经元输入向量$\bm{i}_{(l)}\in\mathbb{R}^{J_{l-1}\times
    1}$上的激活函数${f}_{(l,j)}$表示，利用其权重向量$\bm{\omega}_{(l,j)}\in\mathbb{R}^{J_{l-1}\times
    1}$和偏置${b}_{(l,j)}$。神经元的输出${o}_{(l,j)}$是
- en: '|  | ${o}_{(l,j)}={f}_{(l,j)}\Big{(}b_{(l,j)}+{\bm{\omega}^{T}_{(l,j)}}\bm{i}_{(l)}\Big{)}.$
    |  | (14) |'
  id: totrans-657
  prefs: []
  type: TYPE_TB
  zh: '|  | ${o}_{(l,j)}={f}_{(l,j)}\Big{(}b_{(l,j)}+{\bm{\omega}^{T}_{(l,j)}}\bm{i}_{(l)}\Big{)}.$
    |  | (14) |'
- en: '![Refer to caption](img/4048d449f7f07aff53d6aa35081402c3.png)'
  id: totrans-658
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4048d449f7f07aff53d6aa35081402c3.png)'
- en: 'Figure 1: FNN architecture showing the input, output, and hidden layers.'
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：显示输入层、输出层和隐藏层的FNN架构。
- en: The [deep neural network](#id98.98.id98) ([DNN](#id98.98.id98)) overall output
    of the $l$-th hidden layer is signified by the vector form
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: '[深度神经网络](#id98.98.id98)（[DNN](#id98.98.id98)）第$l$层隐藏层的整体输出由向量形式表示'
- en: '|  | $\bm{o}_{(l)}=\bm{f}_{(l)}\Big{(}\bm{b}_{(l)}+{\bm{W}_{(l)}}\bm{i}_{(l)}\Big{)},\leavevmode\nobreak\
    \bm{i}_{(l+1)}=\bm{o}_{(l)},$ |  | (15) |'
  id: totrans-661
  prefs: []
  type: TYPE_TB
  zh: '|  | $\bm{o}_{(l)}=\bm{f}_{(l)}\Big{(}\bm{b}_{(l)}+{\bm{W}_{(l)}}\bm{i}_{(l)}\Big{)},\leavevmode\nobreak\
    \bm{i}_{(l+1)}=\bm{o}_{(l)},$ |  | (15) |'
- en: where $\bm{f}_{(l)}$ is a vector resulting from the stacking of the $n_{l}$
    activation functions.
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\bm{f}_{(l)}$是由$n_{l}$个激活函数叠加而成的向量。
- en: 'After the selection of the [FNN](#id99.99.id99) architecture, the parameter
    ${\theta}=(\bm{W},\bm{B})$ representing the total [FNN](#id99.99.id99) weights
    and biases must be estimated via the learning procedure applied during the [FNN](#id99.99.id99)
    training phase. As well known, ${\theta}$ estimation is obtained by minimizing
    a loss function $\text{Loss}({\theta})$. The loss function measures how far apart
    the predicted [FNN](#id99.99.id99) outputs ($\bm{o}_{(\mathcal{L})}^{\text{(P)}}$)
    are from the true outputs ($\bm{o}_{(\mathcal{L})}^{\text{(T)}}$). Therefore,
    the [FNN](#id99.99.id99) training phase carried over $N_{\text{train}}$ training
    samples can be explained in two steps: (i) calculate the loss, and (ii) update
    ${\theta}$. This process is repeated until convergence, so that the loss becomes
    very small. Accordingly, various optimization algorithms can be used for minimizing
    $\text{Loss}({\theta})$ by iteratively updating the parameter ${\theta}$, i.e.,
    stochastic gradient descent [[39](#bib.bib39)], root mean square prop [[40](#bib.bib40)],
    and adaptive moment estimation (ADAM) [[41](#bib.bib41)].'
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择了[FNN](#id99.99.id99)架构之后，表示总的[FNN](#id99.99.id99)权重和偏置的参数${\theta}=(\bm{W},\bm{B})$必须通过在[FNN](#id99.99.id99)训练阶段应用的学习过程进行估计。众所周知，${\theta}$的估计是通过最小化损失函数$\text{Loss}({\theta})$来获得的。损失函数衡量预测的[FNN](#id99.99.id99)输出($\bm{o}_{(\mathcal{L})}^{\text{(P)}}$)与真实输出($\bm{o}_{(\mathcal{L})}^{\text{(T)}}$)之间的差距。因此，经过$N_{\text{train}}$个训练样本的[FNN](#id99.99.id99)训练阶段可以分为两个步骤：（i）计算损失，以及（ii）更新${\theta}$。这个过程会重复进行直到收敛，使得损失变得非常小。因此，可以使用各种优化算法通过迭代更新参数${\theta}$来最小化$\text{Loss}({\theta})$，即随机梯度下降[[39](#bib.bib39)]、均方根传播[[40](#bib.bib40)]和自适应矩估计（ADAM）[[41](#bib.bib41)]。
- en: The final step after [FNN](#id99.99.id99) training is to test the trained [FNN](#id99.99.id99)
    on new data in order to evaluate its performance. An elaborate comprehensive analysis
    of [FNN](#id99.99.id99) different principles is presented in [[42](#bib.bib42)].
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: 在[FNN](#id99.99.id99)训练后的最后一步是对训练好的[FNN](#id99.99.id99)进行新数据测试，以评估其性能。[FNN](#id99.99.id99)不同原理的详细综合分析见[[42](#bib.bib42)]。
- en: III-B LSTM
  id: totrans-665
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B LSTM
- en: Another well-known [DL](#id96.96.id96) tool is available in the form of [LSTM](#id32.32.id32)
    networks that essentially deal with sequential data where the order of the data
    matters and a correlation exists between the previous and the future data. In
    this context, [LSTM](#id32.32.id32) networks are defined with a special architecture
    capable of learning the data correlation over time, which enables the [LSTM](#id32.32.id32)
    network to predict the future data based on prior observations.
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个著名的[DL](#id96.96.id96)工具是[LSTM](#id32.32.id32)网络，这些网络本质上处理序列数据，其中数据的顺序很重要，并且存在先前数据与未来数据之间的相关性。在这种情况下，[LSTM](#id32.32.id32)网络定义了一种特殊的架构，能够学习数据随时间的相关性，使得[LSTM](#id32.32.id32)网络能够根据先前的观察预测未来的数据。
- en: 'The [LSTM](#id32.32.id32) unit, as shown in Figure [2](#S3.F2 "Figure 2 ‣ Forget
    the irrelevant information ‣ III-B LSTM ‣ III DL Techniques Overview ‣ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments"),
    contains computational blocks referred to as gates, which are responsible for
    controlling and tracking the information flow over time. The [LSTM](#id32.32.id32)
    network mechanism can be explicated in four major steps:'
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [2](#S3.F2 "图 2 ‣ 忘记无关信息 ‣ III-B LSTM ‣ III DL 技术概述 ‣ 深度学习基础下的双散射环境通道估计调查")
    所示，[LSTM](#id32.32.id32) 单元包含被称为门的计算块，这些块负责控制和跟踪信息流动。 [LSTM](#id32.32.id32) 网络机制可以通过四个主要步骤来解释：
- en: Forget the irrelevant information
  id: totrans-668
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 忘记无关信息
- en: In general, the [LSTM](#id32.32.id32) unit classifies the input data into relevant
    and irrelevant information. The first processing step entails eliminating the
    irrelevant information that is not important for predicting the future. This can
    be undertaken through the forget gate that decides which information the [LSTM](#id32.32.id32)
    unit should retain, and which information can be deleted. The forget gate processing
    is defined as follows
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，[LSTM](#id32.32.id32) 单元将输入数据分类为相关和无关信息。第一步处理是消除对预测未来不重要的无关信息。这可以通过遗忘门完成，遗忘门决定了
    [LSTM](#id32.32.id32) 单元应该保留哪些信息，以及哪些信息可以被删除。遗忘门处理定义如下
- en: '|  | ${\bm{f}}_{t}=\sigma(\bm{W}_{f,t}\bar{\bm{x}}_{t}+\bm{W}^{\prime}_{f,t}\bar{\bm{z}}_{t-1}+\bar{\bm{b}}_{f,t}),$
    |  | (16) |'
  id: totrans-670
  prefs: []
  type: TYPE_TB
  zh: '|  | ${\bm{f}}_{t}=\sigma(\bm{W}_{f,t}\bar{\bm{x}}_{t}+\bm{W}^{\prime}_{f,t}\bar{\bm{z}}_{t-1}+\bar{\bm{b}}_{f,t}),$
    |  | (16) |'
- en: where $\bar{\sigma}$ denotes the sigmoid function, $\bm{W}_{f,t}\in\mathbb{R}^{P\times
    K_{in}}$, $\bm{W}^{\prime}_{f,t}\in\mathbb{R}^{P\times P}$ and $\bar{\bm{b}}_{f,t}\in\mathbb{R}^{P\times
    1}$ are the forget gate weights and biases at time $t$, $\bar{\bm{x}}_{t}\in\mathbb{R}^{K_{in}\times
    1}$ and $\bar{\bm{z}}_{t-1}$ represents the [LSTM](#id32.32.id32) unit input vector
    of size $K_{in}$, and the previous hidden state of size $P$, respectively.
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\bar{\sigma}$ 表示 sigmoid 函数，$\bm{W}_{f,t}\in\mathbb{R}^{P\times K_{in}}$，$\bm{W}^{\prime}_{f,t}\in\mathbb{R}^{P\times
    P}$ 和 $\bar{\bm{b}}_{f,t}\in\mathbb{R}^{P\times 1}$ 是时间 $t$ 的遗忘门权重和偏置，$\bar{\bm{x}}_{t}\in\mathbb{R}^{K_{in}\times
    1}$ 和 $\bar{\bm{z}}_{t-1}$ 分别表示 [LSTM](#id32.32.id32) 单元的输入向量（大小为 $K_{in}$）和前一个隐藏状态（大小为
    $P$）。
- en: '![Refer to caption](img/311f67cc6507569e8cd3dcacbeb62d1c.png)'
  id: totrans-672
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/311f67cc6507569e8cd3dcacbeb62d1c.png)'
- en: 'Figure 2: LSTM unit architecture [[43](#bib.bib43)].'
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：LSTM 单元结构 [[43](#bib.bib43)]。
- en: Store the relevant new information
  id: totrans-674
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 存储相关的新信息
- en: After classifying the relevant information, the [LSTM](#id32.32.id32) unit applies
    some computations on the selected information via the input gate
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: 在对相关信息进行分类后，[LSTM](#id32.32.id32) 单元通过输入门对选择的信息进行一些计算
- en: '|  | ${\bar{\bm{i}}_{t}}=\sigma(\bm{W}_{\bar{\bm{i}},t}\bar{\bm{x}}_{t}+\bm{W}^{\prime}_{\bar{\bm{i}},t}\bar{\bm{z}}_{t-1}+\bar{\bm{b}}_{\bar{\bm{i}},t}),$
    |  | (17) |'
  id: totrans-676
  prefs: []
  type: TYPE_TB
  zh: '|  | ${\bar{\bm{i}}_{t}}=\sigma(\bm{W}_{\bar{\bm{i}},t}\bar{\bm{x}}_{t}+\bm{W}^{\prime}_{\bar{\bm{i}},t}\bar{\bm{z}}_{t-1}+\bar{\bm{b}}_{\bar{\bm{i}},t}),$
    |  | (17) |'
- en: '|  | ${\tilde{{\bm{c}}}}_{t}=\text{tanh}(\bm{W}_{{\tilde{{\bm{c}}}},t}\bar{\bm{x}}_{t}+\bm{W}^{\prime}_{{\tilde{{\bm{c}}}},t}\bar{\bm{z}}_{t-1}+\bar{\bm{b}}_{{\tilde{{\bm{c}}}},t}).$
    |  | (18) |'
  id: totrans-677
  prefs: []
  type: TYPE_TB
  zh: '|  | ${\tilde{{\bm{c}}}}_{t}=\text{tanh}(\bm{W}_{{\tilde{{\bm{c}}}},t}\bar{\bm{x}}_{t}+\bm{W}^{\prime}_{{\tilde{{\bm{c}}}},t}\bar{\bm{z}}_{t-1}+\bar{\bm{b}}_{{\tilde{{\bm{c}}}},t}).$
    |  | (18) |'
- en: Update the new cell state
  id: totrans-678
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 更新新的单元状态
- en: Next the [LSTM](#id32.32.id32) unit is supposed to update the current cell state
    ${{{\bm{c}}}}_{t}$ based on the two previously-mentioned steps such that
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，[LSTM](#id32.32.id32) 单元应根据上述两个步骤更新当前的单元状态 ${{{\bm{c}}}}_{t}$，使其
- en: '|  | ${{{\bm{c}}}}_{t}={\bm{f}}_{t}\odot{\bm{c}}_{t-1}+\bar{\bm{i}}_{t}\odot{\tilde{{\bm{c}}}}_{t}.$
    |  | (19) |'
  id: totrans-680
  prefs: []
  type: TYPE_TB
  zh: '|  | ${{{\bm{c}}}}_{t}={\bm{f}}_{t}\odot{\bm{c}}_{t-1}+\bar{\bm{i}}_{t}\odot{\tilde{{\bm{c}}}}_{t}.$
    |  | (19) |'
- en: where $\odot$ denotes the Hadamard product.
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\odot$ 表示 Hadamard 积。
- en: Generate the LSTM unit output
  id: totrans-682
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 生成 LSTM 单元输出
- en: Updating the hidden state and generating the output by the output gate is the
    final processing step. The output is considered to be a cell state filtered version
    and can be computed such that
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 更新隐藏状态并通过输出门生成输出是最终的处理步骤。输出被视为单元状态的过滤版本，可以通过以下方式计算
- en: '|  | ${\bm{o}}_{t}=\sigma(\bm{W}_{o,t}\bar{\bm{x}}_{t}+\bm{W}^{\prime}_{o,t}\bar{\bm{z}}_{t-1}+\bar{\bm{b}}_{o,t}),$
    |  | (20) |'
  id: totrans-684
  prefs: []
  type: TYPE_TB
  zh: '|  | ${\bm{o}}_{t}=\sigma(\bm{W}_{o,t}\bar{\bm{x}}_{t}+\bm{W}^{\prime}_{o,t}\bar{\bm{z}}_{t-1}+\bar{\bm{b}}_{o,t}),$
    |  | (20) |'
- en: '|  | ${\bar{{\bm{z}}}}_{t}={\bm{o}}_{t}\odot\text{tanh}({\bm{c}}_{t}).$ |  |
    (21) |'
  id: totrans-685
  prefs: []
  type: TYPE_TB
  zh: '|  | ${\bar{{\bm{z}}}}_{t}={\bm{o}}_{t}\odot\text{tanh}({\bm{c}}_{t}).$ |  |
    (21) |'
- en: In literature, there exists several [LSTM](#id32.32.id32) architecture variants,
    where the interactions between the [LSTM](#id32.32.id32) unit gates are modified.
    The authors in [[44](#bib.bib44)] provide a detailed comparison of popular [LSTM](#id32.32.id32)
    architecture variants.
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: 文献中存在几种[LSTM](#id32.32.id32)架构变体，其中[LSTM](#id32.32.id32)单元门的相互作用被修改。作者在[[44](#bib.bib44)]中提供了对流行[LSTM](#id32.32.id32)架构变体的详细比较。
- en: III-C CNN
  id: totrans-687
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C CNN
- en: Another type of deep learning is [CNN](#id28.28.id28) model. This is commonly
    used for processing data with grid patterns, such as images [[45](#bib.bib45)].
    Thus, [CNN](#id28.28.id28) has generally become the state of the art for several
    visual applications such as image classification, due to its demonstrated ability
    to extract patterns from the input image. [CNN](#id28.28.id28) can be seen as
    a set of several layers stacked together to accomplish the requisite task. These
    layers include
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种深度学习类型是[CNN](#id28.28.id28)模型。这通常用于处理具有网格模式的数据，如图像[[45](#bib.bib45)]。因此，[CNN](#id28.28.id28)已普遍成为多种视觉应用（如图像分类）的最先进技术，因为它具有从输入图像中提取模式的能力。[CNN](#id28.28.id28)可以视为几个层叠在一起以完成所需任务的集合。这些层包括
- en: •
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Input layer: It represents the 2D or 3D input image. For the sake of simplicity,
    let us consider a 2D image input to the $l$ -th [CNN](#id28.28.id28) layer denoted
    by $\bm{X}_{l}\in\mathbb{R}^{h_{l}\times w_{l}}$, where $h_{l}$ and $w_{l}$ denote
    the height and the width of the $\bm{X}_{l}$ input image.'
  id: totrans-690
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入层：它表示二维或三维输入图像。为了简单起见，我们考虑输入到第$l$层的二维图像，记作$\bm{X}_{l}\in\mathbb{R}^{h_{l}\times
    w_{l}}$，其中$h_{l}$和$w_{l}$分别表示$\bm{X}_{l}$输入图像的高度和宽度。
- en: •
  id: totrans-691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Convolutional layer: refers to a specialized type of linear operation used
    for feature extraction, where predefined filters referred to as kernels scan the
    input matrix to fill the output matrix denoted as feature map, which is shown
    in Figure [3](#S3.F3 "Figure 3 ‣ 2nd item ‣ III-C CNN ‣ III DL Techniques Overview
    ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments").
    We note that different kernels can be considered as different feature extractors.'
  id: totrans-692
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 卷积层：指的是一种用于特征提取的特殊线性操作类型，其中预定义的滤波器（称为卷积核）扫描输入矩阵以填充输出矩阵，输出矩阵称为特征图，如图[3](#S3.F3
    "Figure 3 ‣ 2nd item ‣ III-C CNN ‣ III DL Techniques Overview ‣ A Survey on Deep
    Learning based Channel Estimation in Doubly Dispersive Environments")所示。我们注意到，不同的卷积核可以被视为不同的特征提取器。
- en: Two key hyper parameters define the [CNN](#id28.28.id28) convolutional layer,
    namely, the size and number of kernels denoted by $f_{l}$ and $n_{l}$, respectively.
    The typical kernel size is $3\times 3$, but sometimes $5\times 5$ or $7\times
    7$. The number of kernels is arbitrary and determines the depth of output feature
    maps. It is possible to tune these parameters according to the application type.
    Furthermore, the process of training a [CNN](#id28.28.id28) model regarding the
    convolution layer involves identifying the kernels values that work optimally
    for a particular task based on a given training dataset. In the convolution layer,
    the kernels are the only automatically learned parameters during the training
    process. Mathematically speaking, for a given input image $\bm{X}_{l}$ and kernel
    $\bm{K_{l}}\in\mathbb{R}^{f_{l}\times f_{l}\times 1}$, we consider one kernel
    for simplicity, the generated feature map $\bm{Y}_{l}\in\mathbb{R}^{(h_{l}-f+1)\times(w_{l}-f+1)}$
    can be expressed as follows
  id: totrans-693
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 定义[CNN](#id28.28.id28)卷积层的两个关键超参数是卷积核的大小和数量，分别记作$f_{l}$和$n_{l}$。典型的卷积核大小为$3\times
    3$，但有时为$5\times 5$或$7\times 7$。卷积核的数量是任意的，决定了输出特征图的深度。可以根据应用类型调整这些参数。此外，关于卷积层训练[CNN](#id28.28.id28)模型的过程涉及识别对特定任务在给定训练数据集上效果最佳的卷积核值。在卷积层中，卷积核是训练过程中唯一的自动学习参数。从数学角度来看，对于给定的输入图像$\bm{X}_{l}$和卷积核$\bm{K_{l}}\in\mathbb{R}^{f_{l}\times
    f_{l}\times 1}$，为简单起见，我们考虑一个卷积核，生成的特征图$\bm{Y}_{l}\in\mathbb{R}^{(h_{l}-f+1)\times(w_{l}-f+1)}$可以表示为
- en: '|  | $\bm{Y}_{l}[x,y]=\sum^{h_{l}}_{i=1}\sum^{w_{l}}_{j=1}\bm{K}_{l}[i,j]\bm{X}_{l}[x+i-1,y+j-1].$
    |  | (22) |'
  id: totrans-694
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\bm{Y}_{l}[x,y]=\sum^{h_{l}}_{i=1}\sum^{w_{l}}_{j=1}\bm{K}_{l}[i,j]\bm{X}_{l}[x+i-1,y+j-1].$
    |  | (22) |'
- en: '![Refer to caption](img/dced3b69d1ec0b710c6a00f04db0bfa6.png)'
  id: totrans-695
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![参考说明](img/dced3b69d1ec0b710c6a00f04db0bfa6.png)'
- en: 'Figure 3: CNN convolutional layer example [[46](#bib.bib46)].'
  id: totrans-696
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3：CNN卷积层示例[[46](#bib.bib46)]。
- en: •
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Activation layer: The outputs of a linear operation such as convolution pass
    through a nonlinear activation function. This activation function introduces non-linear
    processing to the [CNN](#id28.28.id28) architecture given that the input-output
    [CNN](#id28.28.id28) pairs relation could be non-linear. While several non-linear
    activation functions exist such as sigmoid or hyperbolic tangent (tanh) function,
    the most common presently used function is the rectified linear unit (ReLU).'
  id: totrans-698
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 激活层：线性操作（如卷积）的输出通过一个非线性激活函数。这种激活函数为[卷积神经网络](#id28.28.id28)架构引入了非线性处理，因为输入输出[卷积神经网络](#id28.28.id28)对的关系可能是非线性的。虽然存在多种非线性激活函数，如sigmoid或双曲正切（tanh）函数，但目前最常用的函数是修正线性单元（ReLU）。
- en: •
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Pooling layer: This layer is employed to decrease the number of parameters
    when the images are too large. Pooling operation is also referred to as sub-sampling
    or down-sampling. This reduces the dimensionality of all feature maps but does
    manage to retain significant information. Notably, none of the pooling layers
    contains any learnable parameter. The most popular form of pooling operation is
    max pooling, which extracts patches from the input feature maps, outputs the maximum
    value in each patch, and then discards all the other values. However, there are
    other pooling operations such as global average pooling [[47](#bib.bib47)].'
  id: totrans-700
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 池化层：当图像过大时，这一层用于减少参数的数量。池化操作也被称为子采样或下采样。这会减少所有特征图的维度，但仍能保留重要信息。值得注意的是，没有任何池化层包含可学习参数。最流行的池化操作形式是最大池化，它从输入特征图中提取补丁，输出每个补丁中的最大值，然后丢弃所有其他值。然而，还有其他池化操作，如全局平均池化[[47](#bib.bib47)]。
- en: '![Refer to caption](img/e1c27c07d08dad404fdacb5826a68cda.png)'
  id: totrans-701
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![参见说明](img/e1c27c07d08dad404fdacb5826a68cda.png)'
- en: 'Figure 4: CNN classical architecture [[46](#bib.bib46)].'
  id: totrans-702
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4：经典卷积神经网络架构[[46](#bib.bib46)]。
- en: •
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Fully connected layer: This layer forms the last block of the [CNN](#id28.28.id28)
    architecture and is mainly employed in the classification problems. It is a simple
    feed-forward neural network layer that comprises at least one hidden layer; its
    role is to transform the 2D [CNN](#id28.28.id28) layer output into a 1D vector.
    In classification problems, the final outputs of the [CNN](#id28.28.id28) network
    represent the probabilities for each class, where the final fully-connected layer
    typically has the same number of output nodes as the number of classes.'
  id: totrans-704
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 全连接层：这一层形成[卷积神经网络](#id28.28.id28)架构的最后一块，主要用于分类问题。这是一个简单的前馈神经网络层，至少包含一个隐藏层，其作用是将二维[卷积神经网络](#id28.28.id28)层的输出转换为一维向量。在分类问题中，[卷积神经网络](#id28.28.id28)网络的最终输出表示每个类别的概率，其中最后的全连接层通常具有与类别数量相同的输出节点数。
- en: •
  id: totrans-705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Batch normalization: It is used to increase the [CNN](#id28.28.id28) stability
    of the output by normalizing each layer’s output. Moreover, batch normalization
    layer reduces overfitting and accelerates the [CNN](#id28.28.id28) training.'
  id: totrans-706
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 批量归一化：用于通过归一化每层的输出来增加[卷积神经网络](#id28.28.id28)的稳定性。此外，批量归一化层减少了过拟合，并加速了[卷积神经网络](#id28.28.id28)的训练。
- en: •
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Output layer: This layer is configured in accordance with the studied problem.
    For instance, in classification problems the [CNN](#id28.28.id28) output layer
    is a fully connected layer with softmax activation function. On the other hand,
    in regression problems, the [CNN](#id28.28.id28) output does not use any activation
    function.'
  id: totrans-708
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出层：这一层根据研究的问题进行配置。例如，在分类问题中，[卷积神经网络](#id28.28.id28)的输出层是一个带有softmax激活函数的全连接层。另一方面，在回归问题中，[卷积神经网络](#id28.28.id28)的输出不使用任何激活函数。
- en: Figure [4](#S3.F4 "Figure 4 ‣ 4th item ‣ III-C CNN ‣ III DL Techniques Overview
    ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments")
    illustrates the classical CNN architecture. As seen in this figure, the only trainable
    parameters within the [CNN](#id28.28.id28) network are the kernels and the fully
    connected layer weights. Similar to all other [DL](#id96.96.id96) techniques,
    [CNN](#id28.28.id28) network updates its trainable parameters by minimizing the
    [CNN](#id28.28.id28) loss function that measures how far the inputs are from the
    outputs. Thereafter, the [CNN](#id28.28.id28) kernels and weights are updated
    in the back propagation operation [[48](#bib.bib48)]. Finally, the performance
    of the trained [CNN](#id28.28.id28) model is examined in the testing phase where
    new unobserved images are fed to the trained [CNN](#id28.28.id28) model.
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: 图[4](#S3.F4 "Figure 4 ‣ 4th item ‣ III-C CNN ‣ III DL Techniques Overview ‣
    A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments")展示了经典的
    CNN 架构。从该图可以看出，[CNN](#id28.28.id28)网络中唯一可训练的参数是卷积核和全连接层的权重。与所有其他[深度学习（DL）](#id96.96.id96)技术类似，[CNN](#id28.28.id28)网络通过最小化[CNN](#id28.28.id28)损失函数来更新其可训练参数，该损失函数衡量输入与输出之间的差距。随后，在反向传播操作中，[CNN](#id28.28.id28)的卷积核和权重会被更新[[48](#bib.bib48)]。最后，在测试阶段，通过将新的未观察图像输入到训练好的[CNN](#id28.28.id28)模型中来检查训练好的[CNN](#id28.28.id28)模型的性能。
- en: It is noteworthy that there are special [CNN](#id28.28.id28) architectures such
    as [SR-CNN](#id25.25.id25) [[49](#bib.bib49)], [DN-CNN](#id26.26.id26) [[50](#bib.bib50)],
    and [super resolution convolutional long short-term memory](#id39.39.id39) ([SR-ConvLSTM](#id39.39.id39)) [[51](#bib.bib51)]
    that are mainly used for regression problems. [SR-CNN](#id25.25.id25) is used
    for enhancing the quality of the input image, where it takes the low-resolution
    image as the input and outputs the high-resolution one. [DN-CNN](#id26.26.id26)
    uses another methodology to improve the image quality by separating the noise
    from the input noisy image employing residual learning [[52](#bib.bib52)]. The
    input noisy image is then subtracted from the extracted noise, resulting in the
    denoised image. Furthermore, [SR-ConvLSTM](#id39.39.id39) combines both [LSTM](#id32.32.id32)
    and [CNN](#id28.28.id28) networks together where time correlation across the whole
    input image is learned, thus leading to a better estimation accuracy.
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，存在一些特殊的[卷积神经网络（CNN）](#id28.28.id28)架构，如[SR-CNN](#id25.25.id25) [[49](#bib.bib49)]、[DN-CNN](#id26.26.id26)
    [[50](#bib.bib50)]以及[超分辨率卷积长短期记忆网络](#id39.39.id39)（[SR-ConvLSTM](#id39.39.id39)）[[51](#bib.bib51)]，这些架构主要用于回归问题。[SR-CNN](#id25.25.id25)用于提高输入图像的质量，它以低分辨率图像作为输入，输出高分辨率图像。[DN-CNN](#id26.26.id26)采用另一种方法，通过利用残差学习将噪声从输入的噪声图像中分离出来，以提高图像质量[[52](#bib.bib52)]。然后，从提取的噪声中减去输入的噪声图像，从而得到去噪图像。此外，[SR-ConvLSTM](#id39.39.id39)结合了[LSTM](#id32.32.id32)和[CNN](#id28.28.id28)网络，通过学习整个输入图像的时间相关性，从而实现更好的估计准确度。
- en: IV DL-Based SBS Channel Estimation
  id: totrans-711
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 基于深度学习的 SBS 信道估计
- en: 'In [DL](#id96.96.id96)-based [SBS](#id22.22.id22) channel estimation, [FNN](#id99.99.id99)
    and [LSTM](#id32.32.id32) networks are primarily integrated with conventional
    estimation schemes in the following two manners: (i) [FNN](#id99.99.id99) is implemented
    as a post-processing module after conventional [DPA](#id16.16.id16), [spectral
    temporal averaging](#id17.17.id17) ([STA](#id17.17.id17)), and [time domain reliable
    test frequency domain interpolation](#id19.19.id19) ([TRFI](#id19.19.id19)) estimators.
    (ii) [LSTM](#id32.32.id32) network gets implemented as a pre-processing unit before
    conventional [DPA](#id16.16.id16) estimation to minimize the DPA demapping error
    iteratively. Both implementations are helpful in improving the channel estimation’s
    accuracy, particularly in high mobility scenarios. However, the LSTM-based estimation
    illustrates a considerable superiority over the [FNN](#id99.99.id99)-based estimation
    as demonstrated in Section [VI](#S6 "VI Simulation Results ‣ A Survey on Deep
    Learning based Channel Estimation in Doubly Dispersive Environments"). Hereafter,
    the steps applied in each DL-based [SBS](#id22.22.id22) estimator are presented.'
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于[DL](#id96.96.id96)的[SBS](#id22.22.id22)信道估计中，[FNN](#id99.99.id99)和[LSTM](#id32.32.id32)网络主要以以下两种方式与传统估计方案集成：(i)
    [FNN](#id99.99.id99)被实现为传统[DPA](#id16.16.id16)、[频谱时间平均](#id17.17.id17) ([STA](#id17.17.id17))和[时域可靠测试频域插值](#id19.19.id19)
    ([TRFI](#id19.19.id19))估计器之后的后处理模块。(ii) [LSTM](#id32.32.id32)网络在传统[DPA](#id16.16.id16)估计之前作为预处理单元实现，以迭代地最小化DPA反映误差。这两种实现都对提高信道估计的准确性有帮助，尤其是在高移动场景中。然而，LSTM-based估计在第[VI](#S6
    "VI Simulation Results ‣ A Survey on Deep Learning based Channel Estimation in
    Doubly Dispersive Environments")节中展示了相对于基于[FNN](#id99.99.id99)的估计有显著的优势。以下是每个基于DL的[SBS](#id22.22.id22)估计器所应用的步骤。
- en: IV-A DPA-FNN
  id: totrans-713
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A DPA-FNN
- en: '![Refer to caption](img/9a96b855bd5e20a2f1d345bf66d5db4e.png)'
  id: totrans-714
  prefs: []
  type: TYPE_IMG
  zh: '![Refer to caption](img/9a96b855bd5e20a2f1d345bf66d5db4e.png)'
- en: 'Figure 5: The block diagram of the studied DNN-based SBS estimators.'
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：所研究的基于DNN的SBS估计器的框图。
- en: The [DPA](#id16.16.id16) estimation [[13](#bib.bib13)] utilizes the demapped
    data subcarriers of the previously received [OFDM](#id208.208.id208) symbol for
    estimating the channel for the existing [OFDM](#id208.208.id208) symbol such that
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: '[DPA](#id16.16.id16)估计[[13](#bib.bib13)]利用之前接收到的[OFDM](#id208.208.id208)符号的反映数据子载波来估计现有[OFDM](#id208.208.id208)符号的信道，如下所示'
- en: '|  | $\tilde{\bm{d}}_{i}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i}[k]}{\hat{\tilde{\bm{h}}}_{\text{DPA}_{i-1}}[k]}\big{)},\leavevmode\nobreak\
    \hat{\tilde{\bm{h}}}_{\text{DPA}_{0}}[k]=\hat{\tilde{\bm{h}}}_{\text{LS}}[k],$
    |  | (23) |'
  id: totrans-717
  prefs: []
  type: TYPE_TB
  zh: '|  | $\tilde{\bm{d}}_{i}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i}[k]}{\hat{\tilde{\bm{h}}}_{\text{DPA}_{i-1}}[k]}\big{)},\leavevmode\nobreak\
    \hat{\tilde{\bm{h}}}_{\text{DPA}_{0}}[k]=\hat{\tilde{\bm{h}}}_{\text{LS}}[k],$
    |  | (23) |'
- en: where $\mathfrak{D}(.)$ refers to the demapping operation to the nearest constellation
    point in accordance with the employed modulation order. $\hat{\tilde{\bm{h}}}_{\text{LS}}$
    signifies the LS estimated channel at the received preambles, such that
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathfrak{D}(.)$指的是根据使用的调制阶数对最近星座点的反映操作。$\hat{\tilde{\bm{h}}}_{\text{LS}}$表示在接收到的前导符号处的LS估计信道，如下所示
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{LS}}[k]=\frac{\sum\limits_{u=1}^{P}\tilde{\bm{y}}^{(p)}_{u}[k]}{P\tilde{\bm{\Lambda}}[k]},\leavevmode\nobreak\
    k\in{\mathcal{K}}_{\text{on}},$ |  | (24) |'
  id: totrans-719
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{\text{LS}}[k]=\frac{\sum\limits_{u=1}^{P}\tilde{\bm{y}}^{(p)}_{u}[k]}{P\tilde{\bm{\Lambda}}[k]},\leavevmode\nobreak\
    k\in{\mathcal{K}}_{\text{on}},$ |  | (24) |'
- en: where $\tilde{\bm{\Lambda}}$ denotes the frequency domain predefined preamble
    sequence. Thereafter, the final [DPA](#id16.16.id16) channel estimates are updated
    in the following manner
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\tilde{\bm{\Lambda}}$表示频域预定义前导序列。然后，最终的[DPA](#id16.16.id16)信道估计以以下方式更新
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]=\frac{\tilde{\bm{y}}_{i}[k]}{\tilde{\bm{d}}_{i}[k]}.$
    |  | (25) |'
  id: totrans-721
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]=\frac{\tilde{\bm{y}}_{i}[k]}{\tilde{\bm{d}}_{i}[k]}.$
    |  | (25) |'
- en: '[DPA](#id16.16.id16) estimation suffers from two main limitations. First, it
    is based on the basic $\hat{\tilde{\bm{h}}}_{\text{LS}}$ estimation suffering
    from noise enhancement. Second, the demapping step in [DPA](#id16.16.id16) leads
    to a significant demapping error primarily in low [signal-to-noise ratio](#id263.263.id263)
    ([SNR](#id263.263.id263)) region stemming from the noise imperfections and doubly-dispersive
    channel variations. This demapping error is enlarged in high mobility scenarios
    employing high modulation orders. In addition, since the [DPA](#id16.16.id16)
    estimated channels are updated iteratively over the received frame, the demapping
    error propagates via the frame that results in a significant degradation in performance.
    In order to address these limitations, the DPA-[FNN](#id99.99.id99) scheme [[27](#bib.bib27)]
    has been proposed to compensate the [DPA](#id16.16.id16) estimation error, where
    $\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]$ is fed to a three-hidden-layers [FNN](#id99.99.id99)
    with $40-20-40$ neurons, as shown in Figure [5](#S4.F5 "Figure 5 ‣ IV-A DPA-FNN
    ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments"). Using the [FNN](#id99.99.id99)
    in addition to the [DPA](#id16.16.id16) scheme yields good performance but it
    is not sufficient, because it ignores the time and frequency correlation between
    successive received [OFDM](#id208.208.id208) symbols. Also, the employed [FNN](#id99.99.id99)
    architecture can be optimized to reduce the computational complexity of channel
    estimation.'
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: '[DPA](#id16.16.id16)估计存在两个主要局限性。首先，它基于基本的$\hat{\tilde{\bm{h}}}_{\text{LS}}$估计，易受噪声增强的影响。其次，[DPA](#id16.16.id16)中的解映射步骤在低[信噪比](#id263.263.id263)（[SNR](#id263.263.id263)）区域会导致显著的解映射误差，这主要源于噪声的不完美和双扩散通道变化。在使用高调制阶数的高移动性场景中，这种解映射误差会放大。此外，由于[DPA](#id16.16.id16)估计的通道会在接收帧上迭代更新，解映射误差会在帧中传播，导致性能显著下降。为了解决这些局限性，提出了DPA-[FNN](#id99.99.id99)方案[[27](#bib.bib27)]，该方案旨在补偿[DPA](#id16.16.id16)估计误差，其中$\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]$被输入到一个具有$40-20-40$神经元的三层隐藏[FNN](#id99.99.id99)中，如图[5](#S4.F5
    "Figure 5 ‣ IV-A DPA-FNN ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep
    Learning based Channel Estimation in Doubly Dispersive Environments")所示。虽然在[DPA](#id16.16.id16)方案中加入[FNN](#id99.99.id99)可以获得良好的性能，但仍然不够，因为它忽略了连续接收[OFDM](#id208.208.id208)符号之间的时间和频率相关性。此外，所使用的[FNN](#id99.99.id99)架构可以优化以减少通道估计的计算复杂度。'
- en: IV-B STA-FNN
  id: totrans-723
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B STA-FNN
- en: To improve the conventional [DPA](#id16.16.id16) estimation, the [STA](#id17.17.id17)
    estimator [[13](#bib.bib13)] has been proposed where frequency and time-domain
    averaging are applied on top of the [DPA](#id16.16.id16) estimated channel as
    follows
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
  zh: 为了改进传统的[DPA](#id16.16.id16)估计，提出了[STA](#id17.17.id17)估计器[[13](#bib.bib13)]，在[DPA](#id16.16.id16)估计的通道上应用了频率和时域平均，如下所示。
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{FD}_{i}}[k]=\sum_{\lambda=-\beta}^{\lambda=\beta}\omega_{\lambda}\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k+\lambda],\leavevmode\nobreak\
    \omega_{\lambda}=\frac{1}{2\beta+1}.$ |  | (26) |'
  id: totrans-725
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{\text{FD}_{i}}[k]=\sum_{\lambda=-\beta}^{\lambda=\beta}\omega_{\lambda}\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k+\lambda],\leavevmode\nobreak\
    \omega_{\lambda}=\frac{1}{2\beta+1}.$ |  | (26) |'
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{STA}_{i}}[k]=(1-\frac{1}{\alpha})\hat{\tilde{\bm{h}}}_{\text{STA}_{i-1}}[k]+\frac{1}{\alpha}\hat{\tilde{\bm{h}}}_{\text{FD}_{i}}[k].$
    |  | (27) |'
  id: totrans-726
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{\text{STA}_{i}}[k]=(1-\frac{1}{\alpha})\hat{\tilde{\bm{h}}}_{\text{STA}_{i-1}}[k]+\frac{1}{\alpha}\hat{\tilde{\bm{h}}}_{\text{FD}_{i}}[k].$
    |  | (27) |'
- en: '[STA](#id17.17.id17) estimator performs well in the low [SNR](#id263.263.id263)
    region. However, it suffers from a considerable error floor in high [SNR](#id263.263.id263)
    regions due to the large [DPA](#id16.16.id16) demapping error. Importantly, in [[13](#bib.bib13)],
    the values of the frequency and time averaging coefficients are fixed to $\alpha=\beta=2$.
    Thus, the final STA estimated channel is a linear combination between the previously
    estimated channel ([27](#S4.E27 "In IV-B STA-FNN ‣ IV DL-Based SBS Channel Estimation
    ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments"))
    and the frequency averaged channel estimates ([26](#S4.E26 "In IV-B STA-FNN ‣
    IV DL-Based SBS Channel Estimation ‣ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments")). However, this linear combination leads to
    a significant performance degradation in real case scenarios due to the doubly-dispersive
    channel non-linear imperfections. Here, [FNN](#id99.99.id99) is utilized as a
    post non-linear processing unit after the conventional [STA](#id17.17.id17) scheme [[28](#bib.bib28)].
    STA-FNN captures more the time-frequency correlations of the channel samples,
    apart from correcting the conventional [STA](#id17.17.id17) estimation error.
    Furthermore, the optimized STA-FNN architecture performs better than the DPA-FNN
    with a significant computational complexity decrease, as elucidated in Section [VII](#S7
    "VII Complexity Analysis ‣ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments").'
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: '[STA](#id17.17.id17) 估计器在低 [SNR](#id263.263.id263) 区域表现良好。然而，由于较大的 [DPA](#id16.16.id16)
    解映射误差，它在高 [SNR](#id263.263.id263) 区域存在较大的误差底线。重要的是，在 [[13](#bib.bib13)] 中，频率和时间平均系数的值被固定为
    $\alpha=\beta=2$。因此，最终的 STA 估计信道是之前估计的信道 ([27](#S4.E27 "在 IV-B STA-FNN ‣ IV 基于深度学习的
    SBS 信道估计 ‣ 双重分散环境下基于深度学习的信道估计综述")) 和频率平均信道估计 ([26](#S4.E26 "在 IV-B STA-FNN ‣ IV
    基于深度学习的 SBS 信道估计 ‣ 双重分散环境下基于深度学习的信道估计综述")) 之间的线性组合。然而，由于双重分散信道的非线性缺陷，这种线性组合会在实际场景中导致显著的性能下降。在这里，[FNN](#id99.99.id99)
    被用作传统 [STA](#id17.17.id17) 方案的后处理非线性处理单元 [[28](#bib.bib28)]。STA-FNN 除了纠正传统 [STA](#id17.17.id17)
    估计误差外，还捕获了更多的信道样本的时间-频率相关性。此外，优化后的 STA-FNN 架构在显著降低计算复杂性的同时，比 DPA-FNN 表现更好，如第 [VII](#S7
    "VII 复杂度分析 ‣ 双重分散环境下基于深度学习的信道估计综述") 节中所述。'
- en: IV-C TRFI-FNN
  id: totrans-728
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C TRFI-FNN
- en: '[TRFI](#id19.19.id19) estimation scheme [[15](#bib.bib15)] is another methodology
    used for improving the [DPA](#id16.16.id16) estimation in ([25](#S4.E25 "In IV-A
    DPA-FNN ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep Learning based
    Channel Estimation in Doubly Dispersive Environments")). Assuming that the time
    correlation of the channel response between two adjacent [OFDM](#id208.208.id208)
    symbols is high, [TRFI](#id19.19.id19) define two sets of subcarriers such that:
    (i) ${\mathcal{RS}}_{i}$ set: that includes the reliable subcarriers indices,
    and (ii) ${\mathcal{URS}}_{i}$ set: which contains the unreliable subcarriers
    indices. The estimated channels for the ${\mathcal{URS}}_{i}$ are then interpolated
    using the ${\mathcal{RS}}_{i}$ channel estimates by means of the frequency-domain
    cubic interpolation. This procedure can be expressed in the following manner'
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: '[TRFI](#id19.19.id19) 估计方案 [[15](#bib.bib15)] 是另一种用于改进 [DPA](#id16.16.id16)
    估计的方法。假设两个相邻的 [OFDM](#id208.208.id208) 符号之间的信道响应时间相关性较高，[TRFI](#id19.19.id19)
    定义了两个子载波集合： (i) ${\mathcal{RS}}_{i}$ 集合：包括可靠的子载波索引，和 (ii) ${\mathcal{URS}}_{i}$
    集合：包含不可靠的子载波索引。然后，使用 ${\mathcal{RS}}_{i}$ 的信道估计通过频域三次插值对 ${\mathcal{URS}}_{i}$
    的估计信道进行插值。这一过程可以表达为以下方式'
- en: •
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Equalize the previously received [OFDM](#id208.208.id208) symbol by ${\hat{\tilde{\bm{h}}}_{\text{TRFI}_{i-1}}[k]}$
    and ${\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]}$, such that
  id: totrans-731
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用 ${\hat{\tilde{\bm{h}}}_{\text{TRFI}_{i-1}}[k]}$ 和 ${\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]}$
    对之前接收到的 [OFDM](#id208.208.id208) 符号进行均衡，使得
- en: '|  | $\begin{split}{\tilde{\bm{d}}^{\prime}}_{i-1}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i-1}[k]}{\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]}\big{)},\leavevmode\nobreak\
    {\tilde{\bm{d}}^{\prime\prime}}_{i-1}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i-1}[k]}{\hat{\tilde{\bm{h}}}_{\text{TRFI}_{i-1}}[k]}\big{)}.\end{split}$
    |  | (28) |'
  id: totrans-732
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\begin{split}{\tilde{\bm{d}}^{\prime}}_{i-1}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i-1}[k]}{\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]}\big{)},\leavevmode\nobreak\
    {\tilde{\bm{d}}^{\prime\prime}}_{i-1}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i-1}[k]}{\hat{\tilde{\bm{h}}}_{\text{TRFI}_{i-1}}[k]}\big{)}.\end{split}$
    |  | (28) |'
- en: •
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: According to the demapping results, the subcarriers are grouped as follows
  id: totrans-734
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据解映射结果，子载波被分组如下：
- en: '|  | $\left\{\begin{array}[]{ll}{\mathcal{RS}}_{i}\leftarrow{\mathcal{RS}}_{i}+{k},&amp;\quad\tilde{\bm{d^{\prime}}}_{i-1}[k]=\tilde{\bm{d}}^{\prime\prime}_{i-1}[k]\\
    {\mathcal{URS}}_{i}\leftarrow{\mathcal{URS}}_{i}+{k},&amp;\quad\tilde{\bm{d^{\prime}}}_{i-1}[k]\neq\tilde{\bm{d}}^{\prime\prime}_{i-1}[k]\end{array}\right..$
    |  | (29) |'
  id: totrans-735
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\left\{\begin{array}[]{ll}{\mathcal{RS}}_{i}\leftarrow{\mathcal{RS}}_{i}+{k},&amp;\quad\tilde{\bm{d^{\prime}}}_{i-1}[k]=\tilde{\bm{d}}^{\prime\prime}_{i-1}[k]\\
    {\mathcal{URS}}_{i}\leftarrow{\mathcal{URS}}_{i}+{k},&amp;\quad\tilde{\bm{d^{\prime}}}_{i-1}[k]\neq\tilde{\bm{d}}^{\prime\prime}_{i-1}[k]\end{array}\right..$
    |  | (29) |'
- en: •
  id: totrans-736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Finally, frequency-domain cubic interpolation is employed to estimate the channels
    at the ${\mathcal{URS}}_{i}$ as follows
  id: totrans-737
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，采用频域三次插值来估计${\mathcal{URS}}_{i}$的信道，如下所示：
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{TRFI}_{i}}[k]=\left\{\begin{array}[]{ll}\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k],&amp;\quad
    k\in{\mathcal{RS}}_{i}\\ \text{Cubic Interpolation},&amp;\quad k\in{\mathcal{URS}}_{i}\end{array}\right..$
    |  | (30) |'
  id: totrans-738
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{\text{TRFI}_{i}}[k]=\left\{\begin{array}[]{ll}\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k],&amp;\quad
    k\in{\mathcal{RS}}_{i}\\ \text{三次插值},&amp;\quad k\in{\mathcal{URS}}_{i}\end{array}\right..$
    |  | (30) |'
- en: Performing frequency-domain interpolation in addition to the [DPA](#id16.16.id16)
    estimation enhances the performance. However, [TRFI](#id19.19.id19) still suffers
    from the demapping and interpolation errors as the number of [reliable subcarriers](#id40.40.id40)
    ([RS](#id40.40.id40)) subcarriers is inversely proportional to the channel variations.
    Additionally, the condition where ${\tilde{\bm{d}}^{\prime}}_{i-1}[k]\neq{\tilde{\bm{d}}^{\prime\prime}}_{i-1}[k]$
    is more dominant in high mobility scenarios. It is for this reason that only a
    few [RS](#id40.40.id40) subcarriers will be selected and the employed cubic interpolation
    performance will be degraded.
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: 除了[DPA](#id16.16.id16)估计外，进行频域插值可以提高性能。然而，[TRFI](#id19.19.id19)仍然受到解映射和插值误差的影响，因为[可靠子载波](#id40.40.id40)（[RS](#id40.40.id40)）的数量与信道变化成反比。此外，当${\tilde{\bm{d}}^{\prime}}_{i-1}[k]\neq{\tilde{\bm{d}}^{\prime\prime}}_{i-1}[k]$的条件在高移动性场景中更为主导。因此，仅选择少量[RS](#id40.40.id40)子载波，使用的三次插值性能会降低。
- en: Inspired by the work undertaken in [STA](#id17.17.id17)-[FNN](#id99.99.id99),
    the authors in [[29](#bib.bib29)] used the same optimized [FNN](#id99.99.id99)
    architecture as in [[28](#bib.bib28)], albeit with $\hat{\tilde{\bm{h}}}_{\text{TRFI}_{i}}[k]$
    as an input instead of $\hat{\tilde{\bm{h}}}_{\text{STA}_{i}}[k]$. [TRFI](#id19.19.id19)-[FNN](#id99.99.id99)
    corrects the cubic interpolation error and also learns the channel frequency domain
    correlation, thus leading to an improved performance in high [SNR](#id263.263.id263)
    regions.
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: 受[STA](#id17.17.id17)-[FNN](#id99.99.id99)工作的启发，[[29](#bib.bib29)]中的作者使用了与[[28](#bib.bib28)]中相同的优化[FNN](#id99.99.id99)架构，虽然输入改为$\hat{\tilde{\bm{h}}}_{\text{TRFI}_{i}}[k]$而不是$\hat{\tilde{\bm{h}}}_{\text{STA}_{i}}[k]$。
    [TRFI](#id19.19.id19)-[FNN](#id99.99.id99)纠正了三次插值误差，并学习了信道频域相关性，从而在高[SNR](#id263.263.id263)区域表现出更好的性能。
- en: IV-D LSTM-FNN-DPA
  id: totrans-741
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-D LSTM-FNN-DPA
- en: Unlike the [FNN](#id99.99.id99)-based estimators, where the [DL](#id96.96.id96)
    processing is employed following the conventional estimators, the work carried
    out in [[53](#bib.bib53)] shows that employing the [DL](#id96.96.id96) processing
    prior to the conventional estimator, specifically the [DPA](#id16.16.id16) estimation,
    could lead to a significant improvement in the overall performance. In this context,
    the authors have proposed to use two cascaded [LSTM](#id32.32.id32) and [FNN](#id99.99.id99)
    networks for both channel estimation as well as noise compensation, as shown in
    Figure [6](#S4.F6 "Figure 6 ‣ IV-D LSTM-FNN-DPA ‣ IV DL-Based SBS Channel Estimation
    ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments").
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于[FNN](#id99.99.id99)的估计器不同，在传统估计器后使用[DL](#id96.96.id96)处理的方式，[[53](#bib.bib53)]的工作表明，在传统估计器之前使用[DL](#id96.96.id96)处理，特别是在[DPA](#id16.16.id16)估计中，可以显著提升整体性能。在这种情况下，作者提出使用两个级联的[LSTM](#id32.32.id32)和[FNN](#id99.99.id99)网络来进行信道估计和噪声补偿，如图[6](#S4.F6
    "Figure 6 ‣ IV-D LSTM-FNN-DPA ‣ IV DL-Based SBS Channel Estimation ‣ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")所示。
- en: The LSTM-FNN-DPA estimator employs the previous and current pilot subcarriers
    besides the [LSTM](#id32.32.id32)-[FNN](#id99.99.id99) estimated channel employed
    in the [DPA](#id16.16.id16) estimation, such that
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM-FNN-DPA估计器除了在[DPA](#id16.16.id16)估计中使用[LSTM](#id32.32.id32)-[FNN](#id99.99.id99)估计的信道外，还使用之前和当前的导频子载波，以便于：
- en: '|  | $\tilde{\bm{d}}_{\text{LSTM-FNN}_{i,d}}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i,d}[k]}{\hat{\tilde{\bm{h}}}_{\text{LSTM-FNN}_{i-1,d}}[k]}\big{)},\leavevmode\nobreak\
    \hat{\tilde{\bm{h}}}_{\text{LSTM}_{0}}[k]=\hat{\tilde{\bm{h}}}_{\text{LS}}[k],$
    |  | (31) |'
  id: totrans-744
  prefs: []
  type: TYPE_TB
  zh: '|  | $\tilde{\bm{d}}_{\text{LSTM-FNN}_{i,d}}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i,d}[k]}{\hat{\tilde{\bm{h}}}_{\text{LSTM-FNN}_{i-1,d}}[k]}\big{)},\leavevmode\nobreak\
    \hat{\tilde{\bm{h}}}_{\text{LSTM}_{0}}[k]=\hat{\tilde{\bm{h}}}_{\text{LS}}[k],$
    |  | (31) |'
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{DL}_{i,d}}[k]=\frac{\tilde{\bm{y}}_{i,d}[k]}{\bm{d}_{\text{LSTM}_{i,d}}[k]}.$
    |  | (32) |'
  id: totrans-745
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{\text{DL}_{i,d}}[k]=\frac{\tilde{\bm{y}}_{i,d}[k]}{\bm{d}_{\text{LSTM}_{i,d}}[k]}.$
    |  | (32) |'
- en: While this estimator can outperform the [FNN](#id99.99.id99)-based estimators,
    it experiences a considerable computational complexity arising from the employment
    of two [DL](#id96.96.id96) networks.
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个估计器可以优于基于 [FNN](#id99.99.id99) 的估计器，但由于使用了两个 [DL](#id96.96.id96) 网络，计算复杂度较高。
- en: '![Refer to caption](img/9f576091e0d4e2c4e4b895ff12474f53.png)'
  id: totrans-747
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/9f576091e0d4e2c4e4b895ff12474f53.png)'
- en: 'Figure 6: The block diagram of the studied LSTM-based SBS estimators.'
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：研究的基于 LSTM 的 SBS 估计器的框图。
- en: IV-E LSTM-DPA-TA
  id: totrans-749
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-E LSTM-DPA-TA
- en: The authors in [[43](#bib.bib43)] propose to use only LSTM network instead of
    two as implemented in the LSTM-FNN-DPA estimator. In addition, noise compensation
    is made possible by applying [time averaging](#id46.46.id46) ([TA](#id46.46.id46))
    processing as shown in Figure [6](#S4.F6 "Figure 6 ‣ IV-D LSTM-FNN-DPA ‣ IV DL-Based
    SBS Channel Estimation ‣ A Survey on Deep Learning based Channel Estimation in
    Doubly Dispersive Environments"). This methodology only requires the previous
    pilots besides the LSTM estimated channel as an input. Then, the LSTM estimated
    channel is employed in the DPA estimation as follows
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [[43](#bib.bib43)] 中，作者建议使用仅 LSTM 网络，而不是在 LSTM-FNN-DPA 估计器中实现的两个网络。此外，通过应用[时间平均](#id46.46.id46)（[TA](#id46.46.id46)）处理实现了噪声补偿，如图
    [6](#S4.F6 "图 6 ‣ IV-D LSTM-FNN-DPA ‣ IV DL 基于 SBS 通道估计 ‣ 关于深度学习基于的双重扩散环境中的通道估计的调查")所示。这种方法仅需前面的导频以及
    LSTM 估计的通道作为输入。然后，LSTM 估计的通道用于 DPA 估计，如下所示
- en: '|  | $\tilde{\bm{d}}_{\text{LSTM}_{i}}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i}[k]}{\hat{\tilde{\bm{h}}}_{\text{LSTM}_{i-1}}[k]}\big{)},\leavevmode\nobreak\
    \hat{\tilde{\bm{h}}}_{\text{LSTM}_{0}}[k]=\hat{\tilde{\bm{h}}}_{\text{LS}}[k],$
    |  | (33) |'
  id: totrans-751
  prefs: []
  type: TYPE_TB
  zh: '|  | $\tilde{\bm{d}}_{\text{LSTM}_{i}}[k]=\mathfrak{D}\big{(}\frac{\tilde{\bm{y}}_{i}[k]}{\hat{\tilde{\bm{h}}}_{\text{LSTM}_{i-1}}[k]}\big{)},\leavevmode\nobreak\
    \hat{\tilde{\bm{h}}}_{\text{LSTM}_{0}}[k]=\hat{\tilde{\bm{h}}}_{\text{LS}}[k],$
    |  | (33) |'
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{LSTM-DPA}_{i}}[k]=\frac{\tilde{\bm{y}}_{i}[k]}{\tilde{\bm{d}}_{\text{LSTM}_{i}}[k]}.$
    |  | (34) |'
  id: totrans-752
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{\text{LSTM-DPA}_{i}}[k]=\frac{\tilde{\bm{y}}_{i}[k]}{\tilde{\bm{d}}_{\text{LSTM}_{i}}[k]}.$
    |  | (34) |'
- en: Finally, to alleviate the impact of the AWGN noise, [TA](#id46.46.id46) processing
    is applied to the $\hat{\tilde{\bm{h}}}_{\text{LSTM-DPA}_{i}}[k]$ estimated channel,
    such that
  id: totrans-753
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了减轻 AWGN 噪声的影响，对估计的 $\hat{\tilde{\bm{h}}}_{\text{LSTM-DPA}_{i}}[k]$ 通道应用了[TA](#id46.46.id46)处理，使得
- en: '|  | $\hat{\bar{\bm{h}}}_{\text{DL-TA}_{i,d}}=(1-\frac{1}{\alpha})\hat{\bar{\bm{h}}}_{\text{DL-TA}_{i-1,d}}+\frac{1}{\alpha}\hat{\bar{\bm{h}}}_{\text{LSTM-DPA}_{i,d}}.$
    |  | (35) |'
  id: totrans-754
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\bar{\bm{h}}}_{\text{DL-TA}_{i,d}}=(1-\frac{1}{\alpha})\hat{\bar{\bm{h}}}_{\text{DL-TA}_{i-1,d}}+\frac{1}{\alpha}\hat{\bar{\bm{h}}}_{\text{LSTM-DPA}_{i,d}}.$
    |  | (35) |'
- en: Here, $\alpha$ denotes the utilized weighting coefficient. In [[43](#bib.bib43)],
    the authors use a fixed $\alpha=2$ for simplicity. Therefore, the [TA](#id46.46.id46)
    applied in ([35](#S4.E35 "In IV-E LSTM-DPA-TA ‣ IV DL-Based SBS Channel Estimation
    ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments"))
    reduces the AWGN noise power $\sigma^{2}$ iteratively within the received [OFDM](#id208.208.id208)
    frame according to the ratio
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，$\alpha$ 表示使用的加权系数。在 [[43](#bib.bib43)] 中，作者为了简化问题使用了固定的 $\alpha=2$。因此，应用于（[35](#S4.E35
    "在 IV-E LSTM-DPA-TA ‣ IV DL 基于 SBS 通道估计 ‣ 关于深度学习基于的双重扩散环境中的通道估计的调查")）的 [TA](#id46.46.id46)
    在接收到的 [OFDM](#id208.208.id208) 帧中根据比例迭代地降低了 AWGN 噪声功率 $\sigma^{2}$。
- en: '|  | $\begin{split}{R}_{\text{DL-TA}_{q}}&amp;=\left(\frac{1}{4}\right)^{(q-1)}+\sum_{j=2}^{q}\left(\frac{1}{4}\right)^{(q-j+1)}=\frac{4^{q-1}+2}{3\times
    4^{q-1}}.\end{split}$ |  | (36) |'
  id: totrans-756
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}{R}_{\text{DL-TA}_{q}}&=\left(\frac{1}{4}\right)^{(q-1)}+\sum_{j=2}^{q}\left(\frac{1}{4}\right)^{(q-j+1)}=\frac{4^{q-1}+2}{3\times
    4^{q-1}}.\end{split}$ |  | (36) |'
- en: This corresponds to the AWGN noise power ratio of the estimated channel at the
    $q$-th estimated channel, where ${1<q<I+1}$ and ${{R}_{\text{DL-TA}_{1}}=1}$ denotes
    the AWGN noise power ratio at $\hat{\tilde{\bm{h}}}_{\text{LS}}[k]$. From the
    derivation of ${R}_{\text{DL-TA}_{q}}$, it can be seen that the noise power decreases
    over the received [OFDM](#id208.208.id208) frame, i.e., the SNR increases, resulting
    in an overall improved performance. Moreover, the input dimension reduction, coupled
    with the simple [TA](#id46.46.id46) processing, significantly lowers the overall
    computational complexity.
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
  zh: 这对应于在第$q$个估计通道的AWGN噪声功率比，其中${1<q<I+1}$和${R}_{\text{DL-TA}_{1}}=1$表示在$\hat{\tilde{\bm{h}}}_{\text{LS}}[k]$处的AWGN噪声功率比。从${R}_{\text{DL-TA}_{q}}$的推导可以看出，噪声功率在接收到的[OFDM](#id208.208.id208)帧上会减少，即SNR增加，从而整体性能得到改善。此外，输入维度的减少，加上简单的[TA](#id46.46.id46)处理，显著降低了整体计算复杂度。
- en: 'Table I: Parameters of the studied DL-based SBS channel estimators.'
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: '表 I: 研究的基于DL的SBS信道估计器的参数。'
- en: '| DPA-[FNN](#id99.99.id99) (Hidden layers; Neurons per layer) | (3;40-20-40)
    |'
  id: totrans-759
  prefs: []
  type: TYPE_TB
  zh: '| DPA-[FNN](#id99.99.id99)（隐藏层；每层神经元数量） | (3;40-20-40) |'
- en: '| STA-[FNN](#id99.99.id99) (Hidden layers; Neurons per layer) | (3;15-15-15)
    |'
  id: totrans-760
  prefs: []
  type: TYPE_TB
  zh: '| STA-[FNN](#id99.99.id99)（隐藏层；每层神经元数量） | (3;15-15-15) |'
- en: '| TRFI-[FNN](#id99.99.id99) (Hidden layers; Neurons per layer) | (3;15-15-15)
    |'
  id: totrans-761
  prefs: []
  type: TYPE_TB
  zh: '| TRFI-[FNN](#id99.99.id99)（隐藏层；每层神经元数量） | (3;15-15-15) |'
- en: '| LSTM (Hidden layers; Neurons per layer) | (1;128) |'
  id: totrans-762
  prefs: []
  type: TYPE_TB
  zh: '| LSTM（隐藏层；每层神经元数量） | (1;128) |'
- en: '| Activation function | ReLU |'
  id: totrans-763
  prefs: []
  type: TYPE_TB
  zh: '| 激活函数 | ReLU |'
- en: '| Number of epochs | 500 |'
  id: totrans-764
  prefs: []
  type: TYPE_TB
  zh: '| 训练轮数 | 500 |'
- en: '| Training samples | 800000 |'
  id: totrans-765
  prefs: []
  type: TYPE_TB
  zh: '| 训练样本 | 800000 |'
- en: '| Testing samples | 200000 |'
  id: totrans-766
  prefs: []
  type: TYPE_TB
  zh: '| 测试样本 | 200000 |'
- en: '| Batch size | 128 |'
  id: totrans-767
  prefs: []
  type: TYPE_TB
  zh: '| 批处理大小 | 128 |'
- en: '| Optimizer | ADAM |'
  id: totrans-768
  prefs: []
  type: TYPE_TB
  zh: '| 优化器 | ADAM |'
- en: '| Loss function | MSE |'
  id: totrans-769
  prefs: []
  type: TYPE_TB
  zh: '| 损失函数 | MSE |'
- en: '| Learning rate | 0.001 |'
  id: totrans-770
  prefs: []
  type: TYPE_TB
  zh: '| 学习率 | 0.001 |'
- en: '| Training SNR | 40 dB |'
  id: totrans-771
  prefs: []
  type: TYPE_TB
  zh: '| 训练信噪比 | 40 dB |'
- en: Intensive experiments reveal that the performance of DL networks is strongly
    related to the SNR considered in the training [[54](#bib.bib54)]. The training
    undertaken at the highest SNR value provides the best performance. In fact, the
    DL network is able to learn better the channel when the training is performed
    at a high SNR value because the impact of the channel is higher than the impact
    of the noise in this SNR range. Owing to the robust generalization properties
    of DL, trained networks can still estimate the channel even if the noise increases,
    i.e., at low SNR values. Therefore, [FNN](#id99.99.id99) and LSTM based estimators
    training is performed using [SNR](#id263.263.id263) = $40$ dB to attain the best
    performance. Moreover, intensive experiments are performed using the grid search
    algorithm [[55](#bib.bib55)] to select the most suitable [FNN](#id99.99.id99)
    and LSTM hyper parameters in terms of performance as well as complexity. Figures [5](#S4.F5
    "Figure 5 ‣ IV-A DPA-FNN ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep
    Learning based Channel Estimation in Doubly Dispersive Environments") and [6](#S4.F6
    "Figure 6 ‣ IV-D LSTM-FNN-DPA ‣ IV DL-Based SBS Channel Estimation ‣ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")
    illustrate the block diagram of the [FNN](#id99.99.id99) and LSTM based estimators.
    Furthermore, Table [I](#S4.T1 "Table I ‣ IV-E LSTM-DPA-TA ‣ IV DL-Based SBS Channel
    Estimation ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments") presents their parameters.
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
  zh: 密集实验表明，DL网络的性能与训练中考虑的SNR密切相关[[54](#bib.bib54)]。在最高SNR值下进行的训练提供了最佳性能。实际上，当在高SNR值下进行训练时，DL网络能够更好地学习信道，因为在该SNR范围内信道的影响大于噪声的影响。由于DL的强大泛化能力，训练过的网络即使在噪声增加时，即在低SNR值下，也能仍然估计信道。因此，[FNN](#id99.99.id99)和基于LSTM的估计器训练使用[SNR](#id263.263.id263)=
    $40$ dB以达到最佳性能。此外，利用网格搜索算法[[55](#bib.bib55)]进行了密集实验，以选择最适合的[FNN](#id99.99.id99)和LSTM超参数，以平衡性能和复杂度。图[5](#S4.F5
    "Figure 5 ‣ IV-A DPA-FNN ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep
    Learning based Channel Estimation in Doubly Dispersive Environments")和[6](#S4.F6
    "Figure 6 ‣ IV-D LSTM-FNN-DPA ‣ IV DL-Based SBS Channel Estimation ‣ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")展示了[FNN](#id99.99.id99)和LSTM基于的估计器的框图。此外，表[I](#S4.T1
    "Table I ‣ IV-E LSTM-DPA-TA ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on
    Deep Learning based Channel Estimation in Doubly Dispersive Environments")展示了它们的参数。
- en: V DL-Based FBF Channel Estimation Schemes
  id: totrans-773
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 基于DL的FBF信道估计方案
- en: This section presents the [DL](#id96.96.id96)-based [FBF](#id23.23.id23) estimators
    introduced to improve the channel estimation accuracy, particularly in very high
    mobility scenarios, where the channel variation is found to be severe. Similar
    to the [DL](#id96.96.id96)-based [SBS](#id22.22.id22) estimators, the [DL](#id96.96.id96)-based
    [FBF](#id23.23.id23) estimators apply first conventional estimation followed by
    means of [CNN](#id28.28.id28) processing.
  id: totrans-774
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了用于提高信道估计精度的[DL](#id96.96.id96)-基于[FBF](#id23.23.id23)的估计器，特别是在信道变化严重的高移动性场景中。与[DL](#id96.96.id96)-基于[SBS](#id22.22.id22)的估计器类似，[DL](#id96.96.id96)-基于[FBF](#id23.23.id23)的估计器首先应用传统估计，然后通过[CNN](#id28.28.id28)处理。
- en: 'Table II: Main characteristics and features of the studied DL-based channel
    estimators.'
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：研究的基于DL的信道估计器的主要特征和功能。
- en: '|'
  id: totrans-776
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Estimator &#124;'
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 估计器 &#124;'
- en: '&#124; type &#124;'
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 类型 &#124;'
- en: '|'
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Estimator &#124;'
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 估计器 &#124;'
- en: '&#124; reference &#124;'
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 参考 &#124;'
- en: '|'
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Conventional &#124;'
  id: totrans-783
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 传统的 &#124;'
- en: '&#124; estimation &#124;'
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 估计 &#124;'
- en: '|'
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DL-based &#124;'
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 基于DL的 &#124;'
- en: '&#124; Method &#124;'
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 方法 &#124;'
- en: '| Complexity |'
  id: totrans-788
  prefs: []
  type: TYPE_TB
  zh: '| 复杂性 |'
- en: '&#124; BER &#124;'
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BER &#124;'
- en: '&#124; Performance &#124;'
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 性能 &#124;'
- en: '| Robustness | Pros and Cons |'
  id: totrans-791
  prefs: []
  type: TYPE_TB
  zh: '| 鲁棒性 | 优缺点 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-792
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| SBS | [[27](#bib.bib27)] | DPA | FNN | ++ | ++ | ++ |'
  id: totrans-793
  prefs: []
  type: TYPE_TB
  zh: '| SBS | [[27](#bib.bib27)] | DPA | FNN | ++ | ++ | ++ |'
- en: '&#124; + Significant performance &#124;'
  id: totrans-794
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 显著的性能 &#124;'
- en: '&#124; superiority over &#124;'
  id: totrans-795
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 优越性 &#124;'
- en: '&#124; conventional estimators. &#124;'
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 传统估计器。 &#124;'
- en: '&#124; - Ignore the time and &#124;'
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; - 忽略时间和 &#124;'
- en: '&#124; frequency correlation &#124;'
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 频率相关性 &#124;'
- en: '&#124; between successive &#124;'
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 连续的 &#124;'
- en: '&#124; received OFDM symbols. &#124;'
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 接收的OFDM符号。 &#124;'
- en: '&#124; - Complex FNN architecture &#124;'
  id: totrans-801
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; - 复杂的FNN架构 &#124;'
- en: '&#124; to compensate the &#124;'
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 以补偿 &#124;'
- en: '&#124; conventional DPA &#124;'
  id: totrans-803
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 传统DPA &#124;'
- en: '&#124; demapping error. &#124;'
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 解映射误差。 &#124;'
- en: '|'
  id: totrans-805
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| [[28](#bib.bib28)] | STA | + | +++ | ++ |'
  id: totrans-806
  prefs: []
  type: TYPE_TB
  zh: '| [[28](#bib.bib28)] | STA | + | +++ | ++ |'
- en: '&#124; + STA averaging ameliorate the &#124;'
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + STA平均化改善了 &#124;'
- en: '&#124; impact of the AWGN noise &#124;'
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; AWGN噪声的影响 &#124;'
- en: '&#124; in low SNR regions. &#124;'
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在低SNR区域。 &#124;'
- en: '&#124; + Optimized FNN architecture. &#124;'
  id: totrans-810
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 优化的FNN架构。 &#124;'
- en: '&#124; - Fixed averaging coefficients. &#124;'
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; - 固定平均系数。 &#124;'
- en: '&#124; - Performance degradation in &#124;'
  id: totrans-812
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; - 在 &#124; 中性能下降'
- en: '&#124; high mobility scenarios. &#124;'
  id: totrans-813
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 高移动性场景。 &#124;'
- en: '|'
  id: totrans-814
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| [[29](#bib.bib29)] | TRFI | + | ++++ | +++ |'
  id: totrans-815
  prefs: []
  type: TYPE_TB
  zh: '| [[29](#bib.bib29)] | TRFI | + | ++++ | +++ |'
- en: '&#124; + Cubic Interpolation enhances &#124;'
  id: totrans-816
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 三次插值增强了 &#124;'
- en: '&#124; the performance in the entire &#124;'
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 整体性能的 &#124;'
- en: '&#124; SNR region. &#124;'
  id: totrans-818
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SNR区域。 &#124;'
- en: '&#124; + Optimized FNN architecture. &#124;'
  id: totrans-819
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 优化的FNN架构。 &#124;'
- en: '&#124; - Assume high correlation &#124;'
  id: totrans-820
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; - 假设高相关性 &#124;'
- en: '&#124; between successive OFDM &#124;'
  id: totrans-821
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 连续OFDM &#124;'
- en: '&#124; symbols. &#124;'
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 符号。 &#124;'
- en: '&#124; - Lack of robustness in very &#124;'
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; - 在非常 &#124;'
- en: '&#124; high mobiliy scenarios. &#124;'
  id: totrans-824
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 高移动性场景。 &#124;'
- en: '|'
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| [[53](#bib.bib53)] | DPA | LSTM and FNN | +++ | ++++ | ++++ |'
  id: totrans-826
  prefs: []
  type: TYPE_TB
  zh: '| [[53](#bib.bib53)] | DPA | LSTM和FNN | +++ | ++++ | ++++ |'
- en: '&#124; + Outperform FNN-based &#124;'
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 超越基于FNN的 &#124;'
- en: '&#124; estimators. &#124;'
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 估计器。 &#124;'
- en: '&#124; + Improved estimation &#124;'
  id: totrans-829
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 改进的估计 &#124;'
- en: '&#124; since LSTM is implemented &#124;'
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 因为LSTM实现了 &#124;'
- en: '&#124; before DPA estimation &#124;'
  id: totrans-831
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在DPA估计之前 &#124;'
- en: '&#124; - Employ LSTM and &#124;'
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; - 使用LSTM和 &#124;'
- en: '&#124; FNN in the same architecture. &#124;'
  id: totrans-833
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FNN在相同架构中。 &#124;'
- en: '|'
  id: totrans-834
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| [[43](#bib.bib43)] | DPA and TA | LSTM | +++ | ++++ | ++++ |'
  id: totrans-835
  prefs: []
  type: TYPE_TB
  zh: '| [[43](#bib.bib43)] | DPA 和 TA | LSTM | +++ | ++++ | ++++ |'
- en: '&#124; + TA processing results in &#124;'
  id: totrans-836
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + TA处理结果 &#124;'
- en: '&#124; a considerable decline in &#124;'
  id: totrans-837
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 产生显著下降 &#124;'
- en: '&#124; the AWGN noise. &#124;'
  id: totrans-838
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; AWGN噪声。 &#124;'
- en: '&#124; + Employ only one &#124;'
  id: totrans-839
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 仅使用一个 &#124;'
- en: '&#124; optimized LSTM unit. &#124;'
  id: totrans-840
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 优化的LSTM单元。 &#124;'
- en: '&#124; + Reduced input dimension. &#124;'
  id: totrans-841
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 降低了输入维度。 &#124;'
- en: '|'
  id: totrans-842
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| FBF | [[30](#bib.bib30)] | 2D RBF |'
  id: totrans-843
  prefs: []
  type: TYPE_TB
  zh: '| FBF | [[30](#bib.bib30)] | 2D RBF |'
- en: '&#124; SR-CNN and &#124;'
  id: totrans-844
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SR-CNN 和 &#124;'
- en: '&#124; DN-CNN &#124;'
  id: totrans-845
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DN-CNN &#124;'
- en: '| +++++ | ++ | ++ |'
  id: totrans-846
  prefs: []
  type: TYPE_TB
  zh: '| +++++ | ++ | ++ |'
- en: '&#124; - 2D RBF interpolation high &#124;'
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; - 2D RBF插值高 &#124;'
- en: '&#124; computational complexity. &#124;'
  id: totrans-848
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 计算复杂度。 &#124;'
- en: '&#124; - The 2D RBF function &#124;'
  id: totrans-849
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; - 2D RBF函数 &#124;'
- en: '&#124; and scale factor should be &#124;'
  id: totrans-850
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 和缩放因子应为 &#124;'
- en: '&#124; optimized in accordance with &#124;'
  id: totrans-851
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 根据 &#124; 进行优化'
- en: '&#124; the channel variations. &#124;'
  id: totrans-852
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 信道变化。 &#124;'
- en: '&#124; - Employ two high-complexity &#124;'
  id: totrans-853
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; - 使用两个高复杂度的 &#124;'
- en: '&#124; CNN architectures. &#124;'
  id: totrans-854
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CNN架构。 &#124;'
- en: '|'
  id: totrans-855
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| [[31](#bib.bib31)] | ADD-TT | SR-ConvLSTM | +++++ | +++ | +++ |'
  id: totrans-856
  prefs: []
  type: TYPE_TB
  zh: '| [[31](#bib.bib31)] | ADD-TT | SR-ConvLSTM | +++++ | +++ | +++ |'
- en: '&#124; + Outperform ChannelNet &#124;'
  id: totrans-857
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 超越ChannelNet &#124;'
- en: '&#124; estimator [29]. &#124;'
  id: totrans-858
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 估计器 [29]。 &#124;'
- en: '&#124; - Fixed ADD-TT Averaging &#124;'
  id: totrans-859
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; - 固定ADD-TT平均 &#124;'
- en: '&#124; coefficients. &#124;'
  id: totrans-860
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 系数。 &#124;'
- en: '&#124; - High computational complexity &#124;'
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; - 高计算复杂度 &#124;'
- en: '&#124; owing to the integration of both &#124;'
  id: totrans-862
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 由于两者的集成 &#124;'
- en: '&#124; LSTM and CNN architectures. &#124;'
  id: totrans-863
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LSTM和CNN架构。 &#124;'
- en: '|'
  id: totrans-864
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| [[32](#bib.bib32)] | WI |'
  id: totrans-865
  prefs: []
  type: TYPE_TB
  zh: '| [[32](#bib.bib32)] | WI |'
- en: '&#124; SR-CNN or &#124;'
  id: totrans-866
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SR-CNN或 &#124;'
- en: '&#124; DN-CNN &#124;'
  id: totrans-867
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DN-CNN &#124;'
- en: '| +++ | ++++ | ++++ |'
  id: totrans-868
  prefs: []
  type: TYPE_TB
  zh: '| +++ | ++++ | ++++ |'
- en: '&#124; + Adaptive frame structure &#124;'
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 自适应帧结构 &#124;'
- en: '&#124; according to the mobility &#124;'
  id: totrans-870
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 根据移动性 &#124;'
- en: '&#124; condition. &#124;'
  id: totrans-871
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 条件。 &#124;'
- en: '&#124; + Reduced buffering time &#124;'
  id: totrans-872
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 减少缓冲时间 &#124;'
- en: '&#124; at the receiver. &#124;'
  id: totrans-873
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在接收端。 &#124;'
- en: '&#124; + Transmission data rate gain. &#124;'
  id: totrans-874
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 传输数据速率增益。 &#124;'
- en: '&#124; + Optimized CNN &#124;'
  id: totrans-875
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; + 优化的CNN &#124;'
- en: '&#124; architectures. &#124;'
  id: totrans-876
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 架构。 &#124;'
- en: '|'
  id: totrans-877
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: V-A ChannelNet
  id: totrans-878
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-A ChannelNet
- en: In [[30](#bib.bib30)], the authors use forward a [CNN](#id28.28.id28)-based
    channel estimator denoted as [channel network](#id35.35.id35) ([ChannelNet](#id35.35.id35))
    scheme, where 2D [radial basis function](#id27.27.id27) ([RBF](#id27.27.id27))
    interpolation is implemented as an initial channel estimation. The underlying
    motivation of the 2D [RBF](#id27.27.id27) interpolation is to approximate multidimensional
    scattered unknown data from their surrounding neighbors known data by employing
    the radial basis function. In order to achieve the purpose, the distance function
    is calculated between every data point to be interpolated and its neighbours,
    where closer neighbors are assigned higher weights. Thereby, the [RBF](#id27.27.id27)
    interpolated frame is considered a low resolution image, where [SR-CNN](#id25.25.id25)
    is utilized to obtain an improved estimation. Finally, to ameliorate the effect
    of noise within the high resolution estimated frame, [DN-CNN](#id26.26.id26) is
    implemented leading to a high resolution and noise alleviated estimated channels.
    The ChannelNet estimator considers sparsely allocated pilots within the IEEE 802.11p
    frame and initially applies the [LS](#id172.172.id172) estimation to the pilot
    subcarriers within the received [OFDM](#id208.208.id208) frame. Subsequently,
    the 2D [RBF](#id27.27.id27) interpolation is derived by the weighted summation
    of the distance between each data subcarrier to be interpolated as well as all
    the pilot subcarriers in the received [OFDM](#id208.208.id208) frame, such that
  id: totrans-879
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[30](#bib.bib30)]中，作者使用了一种基于[CNN](#id28.28.id28)的信道估计器，称为[信道网络](#id35.35.id35)（[ChannelNet](#id35.35.id35)）方案，其中实现了2D[径向基函数](#id27.27.id27)（[RBF](#id27.27.id27)）插值作为初步信道估计。2D[RBF](#id27.27.id27)插值的基本动机是通过使用径向基函数，近似从周围已知数据中散布的多维未知数据。为了实现这个目的，计算每个要插值的数据点与其邻居之间的距离函数，其中距离较近的邻居被分配更高的权重。因此，[RBF](#id27.27.id27)插值的帧被认为是低分辨率图像，其中利用[SR-CNN](#id25.25.id25)获得改进的估计。最后，为了改善高分辨率估计帧中的噪声影响，实施了[DN-CNN](#id26.26.id26)，从而得到高分辨率和噪声减轻的估计信道。ChannelNet估计器考虑了IEEE
    802.11p帧中稀疏分配的导频，并最初将[LS](#id172.172.id172)估计应用于接收到的[OFDM](#id208.208.id208)帧中的导频子载波。随后，通过加权求和每个待插值的数据子载波与接收到的[OFDM](#id208.208.id208)帧中所有导频子载波之间的距离来得出2D[RBF](#id27.27.id27)插值，如此
- en: '|  | $\hat{\tilde{\bm{H}}}_{\text{RBF}}[k,i]=\sum_{j=1}^{{K_{{p}}}I}\omega_{j}\Phi(&#124;k-{\mathcal{K}}_{f}[j]&#124;,&#124;i-{\mathcal{K}}_{t}[j]&#124;).$
    |  | (37) |'
  id: totrans-880
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{H}}}_{\text{RBF}}[k,i]=\sum_{j=1}^{{K_{{p}}}I}\omega_{j}\Phi(&#124;k-{\mathcal{K}}_{f}[j]&#124;,&#124;i-{\mathcal{K}}_{t}[j]&#124;).$
    |  | (37) |'
- en: ${\mathcal{K}}_{f}=[{{\mathcal{K}}}_{\text{p}_{1}},\dots,{{\mathcal{K}}}_{\text{p}_{I}}]\in\mathbb{R}^{1\times
    K_{p}I}$ and ${\mathcal{K}}_{t}=[(1)_{\times K_{p}},\dots,(I)_{\times K_{p}}]\in\mathbb{R}^{1\times
    K_{p}I}$ represent the frequency and time indices vectors of the allocated pilot
    subcarriers within the received [OFDM](#id208.208.id208) frame, respectively.
    $\omega_{j}$ is the [RBF](#id27.27.id27) weight multiplied by the [RBF](#id27.27.id27)
    interpolation function $\Phi(.)$ between the $(k,i)$ data subcarrier and the $({\mathcal{K}}_{f}[j],{\mathcal{K}}_{t}[j])$
    pilot subcarrier. In [[30](#bib.bib30)], the [RBF](#id27.27.id27) gaussian function
    is applied, such that
  id: totrans-881
  prefs: []
  type: TYPE_NORMAL
  zh: ${\mathcal{K}}_{f}=[{{\mathcal{K}}}_{\text{p}_{1}},\dots,{{\mathcal{K}}}_{\text{p}_{I}}]\in\mathbb{R}^{1\times
    K_{p}I}$ 和 ${\mathcal{K}}_{t}=[(1)_{\times K_{p}},\dots,(I)_{\times K_{p}}]\in\mathbb{R}^{1\times
    K_{p}I}$ 分别表示接收到的 [OFDM](#id208.208.id208) 帧中分配的导频子载波的频率和时间索引向量。$\omega_{j}$ 是
    [RBF](#id27.27.id27) 权重与 [RBF](#id27.27.id27) 插值函数 $\Phi(.)$ 之间的乘积，连接了 $(k,i)$
    数据子载波和 $({\mathcal{K}}_{f}[j],{\mathcal{K}}_{t}[j])$ 导频子载波。在 [[30](#bib.bib30)]
    中应用了 [RBF](#id27.27.id27) 高斯函数，具体为
- en: '|  | $\Phi(x,y)=e^{-\frac{(x+y)^{2}}{r_{0}}}.$ |  | (38) |'
  id: totrans-882
  prefs: []
  type: TYPE_TB
  zh: '|  | $\Phi(x,y)=e^{-\frac{(x+y)^{2}}{r_{0}}}.$ |  | (38) |'
- en: '$r_{0}$ refers to the 2D [RBF](#id27.27.id27) scale factor that varies based
    on the used [RBF](#id27.27.id27) function. Notably, altering the value of $r_{0}$
    alters the shape of the interpolation function. Moreover, the [RBF](#id27.27.id27)
    weights $\bm{w}_{\text{RBF}}=[\omega_{1},\dots,\omega_{K_{p}I}]\in\mathbb{R}^{K_{p}I\times
    1}$ are calculated using the following relation:'
  id: totrans-883
  prefs: []
  type: TYPE_NORMAL
  zh: $r_{0}$ 是 2D [RBF](#id27.27.id27) 尺度因子，取决于所使用的 [RBF](#id27.27.id27) 函数。值得注意的是，改变
    $r_{0}$ 的值会改变插值函数的形状。此外，[RBF](#id27.27.id27) 权重 $\bm{w}_{\text{RBF}}=[\omega_{1},\dots,\omega_{K_{p}I}]\in\mathbb{R}^{K_{p}I\times
    1}$ 是通过以下关系计算得到的：
- en: '|  | $\bm{A}_{\text{RBF}}\bm{w}_{\text{RBF}}=\bar{{\bm{h}}}_{\text{LS}}.$ |  |
    (39) |'
  id: totrans-884
  prefs: []
  type: TYPE_TB
  zh: '|  | $\bm{A}_{\text{RBF}}\bm{w}_{\text{RBF}}=\bar{{\bm{h}}}_{\text{LS}}.$ |  |
    (39) |'
- en: Here, $\bm{A}_{\text{RBF}}\in\mathbb{R}^{{K_{{p}}}I\times{K_{{p}}}I}$ is the
    [RBF](#id27.27.id27) interpolation matrix of the pilots subcarriers, with entries
    $a_{i,j}=\Phi({\mathcal{K}}_{f}[i],{\mathcal{K}}_{t}[j])$ where $i,j=1,\dots,K_{p}I$.
    It is observed that, $\bar{{\bm{h}}}_{\text{LS}}=\mathrm{vec}\left\{\hat{\tilde{\bm{H}}}_{\text{LS}}\right\}\in\mathbb{C}^{K_{p}I\times
    1}$ is a vector that contains the [LS](#id172.172.id172) estimated channels at
    all the pilot subcarriers within the received [OFDM](#id208.208.id208) frame.
    This is expressed as
  id: totrans-885
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，$\bm{A}_{\text{RBF}}\in\mathbb{R}^{{K_{{p}}}I\times{K_{{p}}}I}$ 是导频子载波的
    [RBF](#id27.27.id27) 插值矩阵，其条目为 $a_{i,j}=\Phi({\mathcal{K}}_{f}[i],{\mathcal{K}}_{t}[j])$，其中
    $i,j=1,\dots,K_{p}I$。可以观察到，$\bar{{\bm{h}}}_{\text{LS}}=\mathrm{vec}\left\{\hat{\tilde{\bm{H}}}_{\text{LS}}\right\}\in\mathbb{C}^{K_{p}I\times
    1}$ 是一个包含接收到的 [OFDM](#id208.208.id208) 帧中所有导频子载波的 [LS](#id172.172.id172) 估计信道的向量。这可以表示为
- en: '|  | $\hat{\tilde{\bm{H}}}_{\text{LS}}[k,i]=\frac{\tilde{\bm{Y}}[k,i]}{\tilde{\bm{P}}[k,i]},\leavevmode\nobreak\
    k\in{{\mathcal{K}}}_{\text{p}},\leavevmode\nobreak\ 1\leq i\leq I,$ |  | (40)
    |'
  id: totrans-886
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{H}}}_{\text{LS}}[k,i]=\frac{\tilde{\bm{Y}}[k,i]}{\tilde{\bm{P}}[k,i]},\leavevmode\nobreak\
    k\in{{\mathcal{K}}}_{\text{p}},\leavevmode\nobreak\ 1\leq i\leq I,$ |  | (40)
    |'
- en: with $\tilde{\bm{P}}[k,i]$ is the frequency-domain pre-defined pilot subcarriers,
    and ${{\mathcal{K}}}_{\text{p}}$ refers to the allocated sparse pilots indices
    within the received [OFDM](#id208.208.id208) symbol. After computing $\bm{W}_{\text{RBF}}$,
    it is possible to calculate the [RBF](#id27.27.id27) estimated channel for every
    data subcarriers within the received [OFDM](#id208.208.id208) frame, as shown
    in ([37](#S5.E37 "In V-A ChannelNet ‣ V DL-Based FBF Channel Estimation Schemes
    ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments")).
    Finally, the [RBF](#id27.27.id27) interpolation estimated frame $\hat{\tilde{\bm{H}}}_{\text{RBF}}$
    is fed as an input to [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26) to improve
    the channel estimation accuracy and reduce the noise impact.
  id: totrans-887
  prefs: []
  type: TYPE_NORMAL
  zh: $\tilde{\bm{P}}[k,i]$ 是频域预定义的导频子载波，${{\mathcal{K}}}_{\text{p}}$ 指的是接收到的[OFDM](#id208.208.id208)符号中的稀疏导频索引。计算出
    $\bm{W}_{\text{RBF}}$ 后，可以计算接收到的[OFDM](#id208.208.id208)帧中每个数据子载波的 [RBF](#id27.27.id27)
    估计信道，如 [37](#S5.E37 "在 V-A ChannelNet ‣ V 基于 DL 的 FBF 信道估计方案 ‣ 深度学习信道估计在双散射环境中的调查")
    所示。最后，将 [RBF](#id27.27.id27) 插值估计帧 $\hat{\tilde{\bm{H}}}_{\text{RBF}}$ 作为输入提供给
    [SR-CNN](#id25.25.id25) 和 [DN-CNN](#id26.26.id26)，以提高信道估计的准确性并减少噪声的影响。
- en: 'The ChannelNet estimator limitations lie in: (i) 2D [RBF](#id27.27.id27) interpolation
    high computational complexity arising from the computation of ([39](#S5.E39 "In
    V-A ChannelNet ‣ V DL-Based FBF Channel Estimation Schemes ‣ A Survey on Deep
    Learning based Channel Estimation in Doubly Dispersive Environments")) for the
    channel estimation of all data subcarriers. (ii) The 2D [RBF](#id27.27.id27) function
    and scale factor needs to be optimized in accordance with the channel variations.
    (iii) The integrated [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26) architectures
    have significant computational complexity. Notably, the ChannelNet estimator uses
    a fixed [RBF](#id27.27.id27) function and scale factor, thus experiencing a considerable
    degradation in performance, particularly in low [SNR](#id263.263.id263) regions,
    where the noise impact remains dominant, as well as high mobility vehicular scenarios,
    where the channel varies swiftly within the [OFDM](#id208.208.id208) frame.'
  id: totrans-888
  prefs: []
  type: TYPE_NORMAL
  zh: ChannelNet 估计器的局限性在于：（i）2D [RBF](#id27.27.id27) 插值由于计算 ([39](#S5.E39 "在 V-A
    ChannelNet ‣ V DL 基于 FBF 信道估计方案 ‣ 关于深度学习在双重扩散环境中信道估计的综述")) 的高计算复杂性，用于所有数据子载波的信道估计。（ii）2D
    [RBF](#id27.27.id27) 函数和缩放因子需要根据信道变化进行优化。（iii）集成的 [SR-CNN](#id25.25.id25) 和 [DN-CNN](#id26.26.id26)
    架构具有显著的计算复杂性。特别是，ChannelNet 估计器使用固定的 [RBF](#id27.27.id27) 函数和缩放因子，因此在低 [SNR](#id263.263.id263)
    区域表现显著下降，其中噪声影响仍然占主导地位，以及高移动性车辆场景中，信道在 [OFDM](#id208.208.id208) 帧内迅速变化。
- en: 'Table III: Parameters of the studied DL-based FBF channel estimators.'
  id: totrans-889
  prefs: []
  type: TYPE_NORMAL
  zh: '表 III: 研究的基于 DL 的 FBF 信道估计器的参数。'
- en: '| Parameter | Values |'
  id: totrans-890
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 值 |'
- en: '| --- | --- |'
  id: totrans-891
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Input/Output dimensions | $2K_{\text{on}}\times I\times 1$ |'
  id: totrans-892
  prefs: []
  type: TYPE_TB
  zh: '| 输入/输出维度 | $2K_{\text{on}}\times I\times 1$ |'
- en: '| --- | --- |'
  id: totrans-893
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| SR-CNN (Hidden layers - $n_{l},f_{l}$) | (3 - 9,64; 1,32;  5,1) |'
  id: totrans-894
  prefs: []
  type: TYPE_TB
  zh: '| SR-CNN（隐藏层 - $n_{l},f_{l}$） | (3 - 9,64; 1,32; 5,1) |'
- en: '| DN-CNN (Hidden layers - $n_{l},f_{l}$) | (18 - 64, 3) |'
  id: totrans-895
  prefs: []
  type: TYPE_TB
  zh: '| DN-CNN（隐藏层 - $n_{l},f_{l}$） | (18 - 64, 3) |'
- en: '| Optimized SR-CNN (Hidden layers - $n_{l},f_{l}$) | (3 - 9,32; 1,16;  5,1)
    |'
  id: totrans-896
  prefs: []
  type: TYPE_TB
  zh: '| 优化的 SR-CNN（隐藏层 - $n_{l},f_{l}$） | (3 - 9,32; 1,16; 5,1) |'
- en: '| Optimized DN-CNN (Hidden layers - $n_{l},f_{l}$) | (7 - 16, 3) |'
  id: totrans-897
  prefs: []
  type: TYPE_TB
  zh: '| 优化的 DN-CNN（隐藏层 - $n_{l},f_{l}$） | (7 - 16, 3) |'
- en: '| SR-ConvLSTM (Hidden layers - $n_{l},f_{l}$) | (3 - 9,64; 1,32;  5,1) |'
  id: totrans-898
  prefs: []
  type: TYPE_TB
  zh: '| SR-ConvLSTM（隐藏层 - $n_{l},f_{l}$） | (3 - 9,64; 1,32; 5,1) |'
- en: '| Activation function | ReLU |'
  id: totrans-899
  prefs: []
  type: TYPE_TB
  zh: '| 激活函数 | ReLU |'
- en: '| Number of epochs | 250 |'
  id: totrans-900
  prefs: []
  type: TYPE_TB
  zh: '| 迭代次数 | 250 |'
- en: '| Training samples | 8000 |'
  id: totrans-901
  prefs: []
  type: TYPE_TB
  zh: '| 训练样本 | 8000 |'
- en: '| Testing samples | 2000 |'
  id: totrans-902
  prefs: []
  type: TYPE_TB
  zh: '| 测试样本 | 2000 |'
- en: '| Batch size | 128 |'
  id: totrans-903
  prefs: []
  type: TYPE_TB
  zh: '| 批量大小 | 128 |'
- en: '| Optimizer | ADAM |'
  id: totrans-904
  prefs: []
  type: TYPE_TB
  zh: '| 优化器 | ADAM |'
- en: '| Loss function | MSE |'
  id: totrans-905
  prefs: []
  type: TYPE_TB
  zh: '| 损失函数 | MSE |'
- en: '| Learning rate | 0.001 |'
  id: totrans-906
  prefs: []
  type: TYPE_TB
  zh: '| 学习率 | 0.001 |'
- en: '| Training SNR | 40 dB |'
  id: totrans-907
  prefs: []
  type: TYPE_TB
  zh: '| 训练 SNR | 40 dB |'
- en: V-B TS-ChannelNet
  id: totrans-908
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-B TS-ChannelNet
- en: '[Temporal spectral ChannelNet](#id29.29.id29) ([TS-ChannelNet](#id29.29.id29)) [[31](#bib.bib31)]
    is based on applying [average decision-directed with time truncation](#id36.36.id36)
    ([ADD-TT](#id36.36.id36)) interpolation to the received [OFDM](#id208.208.id208)
    frame. Thereafter, accurate estimation is achieved by implementing [SR-ConvLSTM](#id39.39.id39)
    network to track doubly-dispersive channel variations by learning the vehicular
    channel’s time and frequency correlations. It is observed that the [ADD-TT](#id36.36.id36)
    interpolation is an [SBS](#id22.22.id22) estimator, where [DPA](#id16.16.id16)
    estimation is initially applied as explained in ([23](#S4.E23 "In IV-A DPA-FNN
    ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments")) and ([25](#S4.E25 "In IV-A DPA-FNN
    ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments")). Thereafter, the enlarged [DPA](#id16.16.id16)
    demapping error is reduced by applying time domain truncation in the following
    manner'
  id: totrans-909
  prefs: []
  type: TYPE_NORMAL
  zh: '[时域光谱 ChannelNet](#id29.29.id29) ([TS-ChannelNet](#id29.29.id29)) [[31](#bib.bib31)]
    基于将 [平均决策导向时间截断](#id36.36.id36) ([ADD-TT](#id36.36.id36)) 插值应用于接收的 [OFDM](#id208.208.id208)
    帧。随后，通过实现 [SR-ConvLSTM](#id39.39.id39) 网络来跟踪双重扩散信道的变化，学习车辆信道的时间和频率相关性，从而实现准确的估计。观察到
    [ADD-TT](#id36.36.id36) 插值是 [SBS](#id22.22.id22) 估计器，其中 [DPA](#id16.16.id16) 估计最初是应用的，如在
    ([23](#S4.E23 "在 IV-A DPA-FNN ‣ IV DL 基于 SBS 信道估计 ‣ 关于深度学习在双重扩散环境中信道估计的综述")) 和
    ([25](#S4.E25 "在 IV-A DPA-FNN ‣ IV DL 基于 SBS 信道估计 ‣ 关于深度学习在双重扩散环境中信道估计的综述")) 中所解释。随后，通过以如下方式应用时间域截断来减少放大
    [DPA](#id16.16.id16) 解映射误差。'
- en: '|  | $\hat{{\bm{h}}}_{\text{DPA}_{i}}={\bm{F}}_{\text{K}}^{\text{H}}\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}},$
    |  | (41) |'
  id: totrans-910
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{{\bm{h}}}_{\text{DPA}_{i}}={\bm{F}}_{\text{K}}^{\text{H}}\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}},$
    |  | (41) |'
- en: where ${\bm{F}}_{K}\in\mathbb{C}^{K\times K}$ denotes the $K$-DFT matrix, and
    $\hat{{\bm{h}}}_{\text{DPA}_{i}}$ represents the time-domain [DPA](#id16.16.id16)
    estimated channel. Thereafter, $\hat{{\bm{h}}}_{\text{DPA}_{i}}$ truncation is
    applied to the significant $L$ channel taps, such that
  id: totrans-911
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ${\bm{F}}_{K}\in\mathbb{C}^{K\times K}$ 表示 $K$-DFT 矩阵，$\hat{{\bm{h}}}_{\text{DPA}_{i}}$
    表示时域 [DPA](#id16.16.id16) 估计的信道。之后，对重要的 $L$ 个信道抽头应用 $\hat{{\bm{h}}}_{\text{DPA}_{i}}$
    截断操作，如下所示
- en: '|  | $\hat{{\bm{h}}}_{\text{DPA}_{i,L}}=\hat{{\bm{h}}}_{\text{DPA}_{i}}(1\mathrel{\mathop{\mathchar
    58\relax}}L).$ |  | (42) |'
  id: totrans-912
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{{\bm{h}}}_{\text{DPA}_{i,L}}=\hat{{\bm{h}}}_{\text{DPA}_{i}}(1\mathrel{\mathop{\mathchar
    58\relax}}L).$ |  | (42) |'
- en: Next, $\hat{{\bm{h}}}_{\text{DPA}_{i,L}}$ is converted back to the frequency
    domain such that
  id: totrans-913
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，$\hat{{\bm{h}}}_{\text{DPA}_{i,L}}$ 被转换回频域，使得
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{TT}_{i}}={\bm{F}}_{\text{K}}\hat{{\bm{h}}}_{\text{DPA}_{i,L}},$
    |  | (43) |'
  id: totrans-914
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{\text{TT}_{i}}={\bm{F}}_{\text{K}}\hat{{\bm{h}}}_{\text{DPA}_{i,L}},$
    |  | (43) |'
- en: Implementing the average time truncation operation to $\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]$
    lowers the effect of noise and enlarged demapping error. Moreover, $\hat{\tilde{\bm{h}}}_{\text{TT}_{i}}[k]$
    estimated channel is further enhanced by applying frequency and time-domain averaging
    consecutively as follows
  id: totrans-915
  prefs: []
  type: TYPE_NORMAL
  zh: 对 $\hat{\tilde{\bm{h}}}_{\text{DPA}_{i}}[k]$ 实施平均时间截断操作可以降低噪声的影响和放大解映射误差。此外，通过依次应用频域和时域平均，可以进一步增强
    $\hat{\tilde{\bm{h}}}_{\text{TT}_{i}}[k]$ 估计的信道，如下所示
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{FTT}_{i}}[k]=\sum_{\lambda=-\beta}^{\lambda=\beta}\omega_{\lambda}\hat{\tilde{\bm{h}}}_{\text{TT}_{i}}[k+\lambda],\leavevmode\nobreak\
    \omega_{\lambda}=\frac{1}{2\beta+1}.$ |  | (44) |'
  id: totrans-916
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{\text{FTT}_{i}}[k]=\sum_{\lambda=-\beta}^{\lambda=\beta}\omega_{\lambda}\hat{\tilde{\bm{h}}}_{\text{TT}_{i}}[k+\lambda],\leavevmode\nobreak\
    \omega_{\lambda}=\frac{1}{2\beta+1}.$ |  | (44) |'
- en: The final [ADD-TT](#id36.36.id36) channel estimates are updated using time averaging
    between the previously [ADD-TT](#id36.36.id36) estimated channel and the frequency
    averaged channel in ([44](#S5.E44 "In V-B TS-ChannelNet ‣ V DL-Based FBF Channel
    Estimation Schemes ‣ A Survey on Deep Learning based Channel Estimation in Doubly
    Dispersive Environments")), such that
  id: totrans-917
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的 [ADD-TT](#id36.36.id36) 信道估计通过对之前 [ADD-TT](#id36.36.id36) 估计的信道和频域平均信道进行时间平均来更新，如([44](#S5.E44
    "在 V-B TS-ChannelNet ‣ V DL-Based FBF 信道估计方案 ‣ 基于深度学习的双重色散环境信道估计综述"))所示
- en: '|  | $\hat{\tilde{\bm{h}}}_{\text{ADD-TT}_{i}}[k]=(1-{\alpha})\hat{\tilde{\bm{h}}}_{\text{ADD-TT}_{i-1}}[k]+{\alpha}\hat{\tilde{\bm{h}}}_{\text{FTT}_{i}}[k].$
    |  | (45) |'
  id: totrans-918
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{\text{ADD-TT}_{i}}[k]=(1-{\alpha})\hat{\tilde{\bm{h}}}_{\text{ADD-TT}_{i-1}}[k]+{\alpha}\hat{\tilde{\bm{h}}}_{\text{FTT}_{i}}[k].$
    |  | (45) |'
- en: The doubly-dispersive channel can be modeled as a time-series forecasting problem.
    Here, historical data can be utilized to forecast future observations [[56](#bib.bib56)].
    Motiviated by this possibility, the authors in [[31](#bib.bib31)] apply [SR-ConvLSTM](#id39.39.id39)
    network in addition to the [ADD-TT](#id36.36.id36) interpolation, where convolutional
    layers get added to the LSTM network to capture more doubly-dispersive channel
    features. Consequently, this improves the estimation performance. Accordingly,
    the [ADD-TT](#id36.36.id36) estimated channel for the entire received frame is
    modeled as a low resolution image. Next, the [SR-ConvLSTM](#id39.39.id39) network
    is used after the [ADD-TT](#id36.36.id36) interpolation. Unlike [ChannelNet](#id35.35.id35)
    estimator where two [CNNs](#id28.28.id28) are employed, [TS-ChannelNet](#id29.29.id29)
    estimator uses only one [SR-ConvLSTM](#id39.39.id39) network, which relatively
    reduces the overall computational complexity. However, [TS-ChannelNet](#id29.29.id29)
    continues to be ridden with high computational complexity due to the integration
    of LSTM and [CNN](#id28.28.id28) in a single network.
  id: totrans-919
  prefs: []
  type: TYPE_NORMAL
  zh: 双重色散信道可以被建模为时间序列预测问题。在这里，可以利用历史数据来预测未来的观测值[[56](#bib.bib56)]。受这一可能性的激励，[[31](#bib.bib31)]
    的作者在 [ADD-TT](#id36.36.id36) 插值的基础上应用了 [SR-ConvLSTM](#id39.39.id39) 网络，其中卷积层被添加到
    LSTM 网络中以捕捉更多的双重色散信道特征。因此，这改善了估计性能。因此，[ADD-TT](#id36.36.id36) 估计的整个接收帧的信道被建模为低分辨率图像。接下来，在
    [ADD-TT](#id36.36.id36) 插值后使用 [SR-ConvLSTM](#id39.39.id39) 网络。与使用两个 [CNNs](#id28.28.id28)
    的 [ChannelNet](#id35.35.id35) 估计器不同，[TS-ChannelNet](#id29.29.id29) 估计器只使用一个 [SR-ConvLSTM](#id39.39.id39)
    网络，从而相对减少了总体计算复杂度。然而，由于将 LSTM 和 [CNN](#id28.28.id28) 集成到一个网络中，[TS-ChannelNet](#id29.29.id29)
    仍然面临着较高的计算复杂度。
- en: '![Refer to caption](img/26928ddade9669e49cad2c374bc69d38.png)'
  id: totrans-920
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/26928ddade9669e49cad2c374bc69d38.png)'
- en: 'Figure 7: The block diagram of the studied CNN-based FBF channel estimators.'
  id: totrans-921
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：研究的基于 CNN 的 FBF 信道估计器的框图。
- en: V-C WI-CNN
  id: totrans-922
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-C WI-CNN
- en: To overcome the limitations of the [ChannelNet](#id35.35.id35) and [TS-ChannelNet](#id29.29.id29)
    estimators, [weighted interpolation](#id37.37.id37) ([WI](#id37.37.id37))-[CNN](#id28.28.id28)
    estimator has been proposed in [[32](#bib.bib32)]. In this method, the frame structure
    is adapted in accordance with the mobility condition employing varied pilot allocation
    schemes. Particularly, only $P$ pilot [OFDM](#id208.208.id208) symbols are required
    in the transmitted frame, such that $\tilde{\bm{Y}}_{P}=[\tilde{\bm{y}}^{(p)}_{1},\dots,\tilde{\bm{y}}^{(p)}_{q},\dots,\tilde{\bm{y}}^{(p)}_{P}]\in\mathbb{C}^{K_{\text{on}}\times
    P}$. The index $1\leq q\leq P$ refers to the location of the [OFDM](#id208.208.id208)
    pilot symbol in the frame. The other $I_{d}=I-P$ [OFDM](#id208.208.id208) data
    symbols are employed for data transmission purposes. As per the employed pilots
    allocation scheme, the channel is estimated at the inserted pilot symbols, after
    which [WI](#id37.37.id37) is applied to estimate the channel at the [OFDM](#id208.208.id208)
    data symbols. The estimated frame is then modeled as a 2D noisy image where optimized
    [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26) are utilized for noise elimination.
    Against this backdrop, the [WI](#id37.37.id37)-[CNN](#id28.28.id28) proceeds as
    follows
  id: totrans-923
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服[ChannelNet](#id35.35.id35)和[TS-ChannelNet](#id29.29.id29)估计器的局限性，提出了[加权插值](#id37.37.id37)
    ([WI](#id37.37.id37))-[CNN](#id28.28.id28)估计器，如[[32](#bib.bib32)]所示。在此方法中，帧结构根据移动条件进行调整，采用不同的导频分配方案。特别是，传输帧中只需要$P$个导频[OFDM](#id208.208.id208)符号，使得$\tilde{\bm{Y}}_{P}=[\tilde{\bm{y}}^{(p)}_{1},\dots,\tilde{\bm{y}}^{(p)}_{q},\dots,\tilde{\bm{y}}^{(p)}_{P}]\in\mathbb{C}^{K_{\text{on}}\times
    P}$。索引$1\leq q\leq P$表示帧中[OFDM](#id208.208.id208)导频符号的位置。其他$I_{d}=I-P$个[OFDM](#id208.208.id208)数据符号用于数据传输。根据所采用的导频分配方案，在插入的导频符号处进行信道估计，然后应用[WI](#id37.37.id37)来估计[OFDM](#id208.208.id208)数据符号处的信道。然后将估计的帧建模为2D噪声图像，利用优化的[SR-CNN](#id25.25.id25)和[DN-CNN](#id26.26.id26)进行噪声消除。在这种背景下，[WI](#id37.37.id37)-[CNN](#id28.28.id28)的过程如下：
- en: •
  id: totrans-924
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Channel estimation at the pilot symbols: Two pilot allocation schemes are defined.
    The full pilot allocation (FP) where $K$ pilots are inserted within all pilot
    symbols and [LS](#id172.172.id172) estimation is applied to estimate the channel
    for each inserted pilot symbol, such that'
  id: totrans-925
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在导频符号处的信道估计：定义了两种导频分配方案。完全导频分配（FP），其中$K$个导频插入到所有导频符号中，并对每个插入的导频符号应用[LS](#id172.172.id172)估计，以估计信道，如下所示：
- en: '|  | $\hat{\tilde{\bm{h}}}_{{\text{SLS}}_{q}}[k]=\frac{\tilde{\bm{y}}^{(p)}_{q}[k]}{\tilde{\bm{p}}[k]}.$
    |  | (46) |'
  id: totrans-926
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{{\text{SLS}}_{q}}[k]=\frac{\tilde{\bm{y}}^{(p)}_{q}[k]}{\tilde{\bm{p}}[k]}.$
    |  | (46) |'
- en: $\hat{\tilde{\bm{h}}}_{{\text{SLS}}_{q}}[k]$ represents the [simple LS](#id34.34.id34)
    ([SLS](#id34.34.id34)) estimation at the $q$-th inserted pilot symbol. In addition,
    the [accurate LS](#id33.33.id33) ([ALS](#id33.33.id33)) that can be obtained by
    implementing the [DFT](#id95.95.id95) interpolation of estimated channel impulse
    response at the $q$-th received pilot symbol $\hat{\bm{h}}_{q,L}$, such that
  id: totrans-927
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\hat{\tilde{\bm{h}}}_{{\text{SLS}}_{q}}[k]$表示在第$q$个插入的导频符号处的[简单LS](#id34.34.id34)
    ([SLS](#id34.34.id34))估计。此外，可以通过对第$q$个接收导频符号$\hat{\bm{h}}_{q,L}$的估计信道脉冲响应实施[DFT](#id95.95.id95)插值，获得[准确LS](#id33.33.id33)
    ([ALS](#id33.33.id33))，如下所示：
- en: '|  | $\hat{\tilde{\bm{h}}}_{{\text{ALS}}_{q}}=\bm{F}_{\text{K}}\hat{\bm{h}}_{q,L},\leavevmode\nobreak\
    \leavevmode\nobreak\ \hat{\bm{h}}_{q,L}=\bm{F}_{\text{K}}^{\dagger}\hat{\tilde{\bm{h}}}_{{\text{LS}}_{q}}.$
    |  | (47) |'
  id: totrans-928
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{{\text{ALS}}_{q}}=\bm{F}_{\text{K}}\hat{\bm{h}}_{q,L},\leavevmode\nobreak\
    \leavevmode\nobreak\ \hat{\bm{h}}_{q,L}=\bm{F}_{\text{K}}^{\dagger}\hat{\tilde{\bm{h}}}_{{\text{LS}}_{q}}.$
    |  | (47) |'
- en: '[ALS](#id33.33.id33) relies on the fact that $\tilde{\bm{h}}_{{q}}=\bm{F}_{\text{K}}{\bm{h}}_{q,L}$,
    where ${\bm{h}}_{q,L}\in\mathbb{C}^{L\times 1}$ signifies the channel impulse
    response at the $q$-th received pilot symbol that can be estimated by employing
    the pseudo inverse matrix of $\bm{F}_{\text{K}}$, namely, $\bm{F}_{\text{K}}^{\dagger}=[(\bm{F}_{\text{K}}^{\text{H}}\bm{F}_{\text{K}})^{-1}\bm{F}_{\text{K}}^{\text{H}}]$
    . However, if the number of doubly dispersive-channel taps $L$ remains known,
    only $K_{p}=L$ pilot subcarriers are sufficient in each inserted pilot symbol.
    Accordingly, ([47](#S5.E47 "In 1st item ‣ V-C WI-CNN ‣ V DL-Based FBF Channel
    Estimation Schemes ‣ A Survey on Deep Learning based Channel Estimation in Doubly
    Dispersive Environments")) can be rewritten as'
  id: totrans-929
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[ALS](#id33.33.id33) 依赖于 $\tilde{\bm{h}}_{{q}}=\bm{F}_{\text{K}}{\bm{h}}_{q,L}$
    这一事实，其中 ${\bm{h}}_{q,L}\in\mathbb{C}^{L\times 1}$ 表示第 $q$ 个接收导频符号的信道脉冲响应，可以通过使用
    $\bm{F}_{\text{K}}$ 的伪逆矩阵来估计，即 $\bm{F}_{\text{K}}^{\dagger}=[(\bm{F}_{\text{K}}^{\text{H}}\bm{F}_{\text{K}})^{-1}\bm{F}_{\text{K}}^{\text{H}}]$。然而，如果双散射信道的拍数
    $L$ 已知，则每个插入的导频符号中仅需 $K_{p}=L$ 个导频子载波。因此，（[47](#S5.E47 "在第 1 项 ‣ V-C WI-CNN ‣
    V 基于深度学习的 FBF 信道估计方案 ‣ 关于深度学习的信道估计在双散射环境中的调查")）可以改写为：'
- en: '|  | $\hat{\tilde{\bm{h}}}_{{\text{DFT}}_{q}}=\bm{F}_{\text{K}}\hat{\bm{h}}_{q,L},\leavevmode\nobreak\
    \leavevmode\nobreak\ \hat{\bm{h}}_{q,L}=\bm{F}_{p}^{\dagger}\hat{\tilde{\bm{h}}}_{{\text{LS}}_{q}}.$
    |  | (48) |'
  id: totrans-930
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{h}}}_{{\text{DFT}}_{q}}=\bm{F}_{\text{K}}\hat{\bm{h}}_{q,L},\leavevmode\nobreak\
    \leavevmode\nobreak\ \hat{\bm{h}}_{q,L}=\bm{F}_{p}^{\dagger}\hat{\tilde{\bm{h}}}_{{\text{LS}}_{q}}.$
    |  | (48) |'
- en: $\bm{F}_{p}^{\dagger}=[(\bm{F}_{p}^{\text{H}}\bm{F}_{p})^{-1}\bm{F}_{p}^{\text{H}}]$
    denotes the pseudo inverse matrix of $\bm{F}_{p}\in\mathbb{C}^{K_{\text{p}}\times
    L}$ referring to the truncated DFT matrix obtained by selecting ${\mathcal{K}}_{\text{p}}$
    rows, and $L$ columns from the $K$-DFT matrix.
  id: totrans-931
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\bm{F}_{p}^{\dagger}=[(\bm{F}_{p}^{\text{H}}\bm{F}_{p})^{-1}\bm{F}_{p}^{\text{H}}]$
    表示 $\bm{F}_{p}\in\mathbb{C}^{K_{\text{p}}\times L}$ 的伪逆矩阵，$\bm{F}_{p}$ 是通过从 $K$-DFT
    矩阵中选择 ${\mathcal{K}}_{\text{p}}$ 行和 $L$ 列得到的截断 DFT 矩阵。
- en: •
  id: totrans-932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Channel estimation at data symbols: The estimated channels of the $P$ pilot
    symbols are first grouped into $P$ matrices to estimate the channel for each received
    OFDM data symbol, such that'
  id: totrans-933
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据符号的信道估计：首先将 $P$ 个导频符号的估计信道分组成 $P$ 个矩阵，以估计每个接收的 OFDM 数据符号的信道，形式为：
- en: '|  | $\hat{\tilde{\bm{H}}}_{q}=[\hat{\tilde{\bm{h}}}_{q-1},\hat{\tilde{\bm{h}}}_{q}],\leavevmode\nobreak\
    q=1,\cdots P.$ |  | (49) |'
  id: totrans-934
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{H}}}_{q}=[\hat{\tilde{\bm{h}}}_{q-1},\hat{\tilde{\bm{h}}}_{q}],\leavevmode\nobreak\
    q=1,\cdots P.$ |  | (49) |'
- en: $\hat{\tilde{\bm{h}}}_{0}=\hat{\tilde{\bm{h}}}_{\text{LS}}$ refers to the [LS](#id172.172.id172)
    estimated channel at the beginning of the received frame ([24](#S4.E24 "In IV-A
    DPA-FNN ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep Learning based
    Channel Estimation in Doubly Dispersive Environments")). Thus, the received frame
    can be divided into $P$ sub-frames, where $f$ refers to the sub-frame index, such
    that $1\leq f\leq P$. Therefore, the estimated channel for the $i$-th received
    [OFDM](#id208.208.id208) symbol within each $f$-th sub-frame can be expressed
    as follows
  id: totrans-935
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\hat{\tilde{\bm{h}}}_{0}=\hat{\tilde{\bm{h}}}_{\text{LS}}$ 指的是接收到的帧开始时的[LS](#id172.172.id172)
    估计信道（[24](#S4.E24 "在 IV-A DPA-FNN ‣ IV 基于深度学习的 SBS 信道估计 ‣ 关于深度学习的信道估计在双散射环境中的调查")）。因此，接收到的帧可以分为
    $P$ 个子帧，其中 $f$ 表示子帧索引，满足 $1\leq f\leq P$。因此，每个 $f$-th 子帧内第 $i$ 个接收的 [OFDM](#id208.208.id208)
    符号的估计信道可以表达如下：
- en: '|  | $\hat{\tilde{\bm{H}}}_{{\text{WI}}_{f}}=\hat{\tilde{\bm{H}}}_{{f}}\bm{C}_{f}.$
    |  | (50) |'
  id: totrans-936
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\hat{\tilde{\bm{H}}}_{{\text{WI}}_{f}}=\hat{\tilde{\bm{H}}}_{{f}}\bm{C}_{f}.$
    |  | (50) |'
- en: $\hat{\tilde{\bm{H}}}_{f}\in\mathbb{C}^{K\times 2}$ denotes the [LS](#id172.172.id172)
    estimated channels at the pilot symbols within the $f$-th sub-frame, and $\bm{C}_{f}\in\mathbb{R}^{2\times
    I_{f}}$ the interpolation weights of the $I_{f}$ [OFDM](#id208.208.id208) data
    symbols within the $f$-th sub-frame. The interpolation weights $\bm{C}_{f}$ are
    calculated by minimizing the [mean squared error](#id196.196.id196) ([MSE](#id196.196.id196))
    between the ideal channel $\tilde{\bm{H}}_{{f}}$, and the [LS](#id172.172.id172)
    estimated channel at the [OFDM](#id208.208.id208) pilot symbols $\hat{\tilde{\bm{H}}}_{{f}}$
    as obtained in [[57](#bib.bib57)] and expressed in ([51](#S5.E51 "In 2nd item
    ‣ V-C WI-CNN ‣ V DL-Based FBF Channel Estimation Schemes ‣ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments")). There, $J_{0}(.)$
    is the zeroth order Bessel function of the first kind, $T_{\text{s}}$ signifies
    the received [OFDM](#id208.208.id208) data symbol duration, whereas $E_{{{q}}}$
    denotes the overall noise of the estimated channel at the $q$-th pilot symbol.
  id: totrans-937
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\hat{\tilde{\bm{H}}}_{f}\in\mathbb{C}^{K\times 2}$ 表示 $f$-th 子帧中导频符号处的[LS](#id172.172.id172)
    估计信道，$\bm{C}_{f}\in\mathbb{R}^{2\times I_{f}}$ 表示 $f$-th 子帧中 $I_{f}$ 个[OFDM](#id208.208.id208)
    数据符号的插值权重。插值权重 $\bm{C}_{f}$ 通过最小化理想信道 $\tilde{\bm{H}}_{{f}}$ 与[OFDM](#id208.208.id208)
    导频符号处的[LS](#id172.172.id172) 估计信道 $\hat{\tilde{\bm{H}}}_{{f}}$ 之间的[均方误差](#id196.196.id196)（[MSE](#id196.196.id196)）来计算，如 [[57](#bib.bib57)]
    所述，并在 ([51](#S5.E51 "In 2nd item ‣ V-C WI-CNN ‣ V DL-Based FBF Channel Estimation
    Schemes ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments")) 中表达。这里，$J_{0}(.)$ 是零阶第一类贝塞尔函数，$T_{\text{s}}$ 表示接收[OFDM](#id208.208.id208)
    数据符号的持续时间，而 $E_{{{q}}}$ 表示 $q$-th 导频符号处估计信道的总体噪声。
- en: '|  | <math   alttext="\begin{split}\bm{C}_{{f}}&amp;=\mathrm{E}\left[\tilde{\bm{H}}_{{f}}\hat{\tilde{\bm{H}}}^{H}_{{f}}\right]\left[\mathrm{E}\left[\hat{\tilde{\bm{H}}}_{{f}}\hat{\tilde{\bm{H}}}^{H}_{{f}}\right]\right]^{-1}=\begin{bmatrix}\mathrm{E}\left[\tilde{\bm{H}}_{{f}}\hat{\tilde{\bm{h}}}^{H}_{{q}}\right]&amp;\mathrm{E}\left[\tilde{\bm{H}}_{{i}}\hat{\tilde{\bm{h}}}^{H}_{{q+1}}\right]\end{bmatrix}\begin{bmatrix}\mathrm{E}\left[\mathinner{\!\left\lVert{\tilde{\bm{h}}}_{{q}}\right\rVert}^{2}\right]+E_{{{q}}}&amp;\mathrm{E}\left[{\tilde{\bm{h}}}_{{q}}{\tilde{\bm{h}}}^{H}_{{q+1}}\right]\\
    \mathrm{E}\left[{\tilde{\bm{h}}}_{{q+1}}{\tilde{\bm{h}}}^{H}_{{q}}\right]&amp;\mathrm{E}\left[\mathinner{\!\left\lVert{\tilde{\bm{h}}}_{{q+1}}\right\rVert}^{2}\right]+E_{{{q+1}}}\end{bmatrix}^{-1}\\'
  id: totrans-938
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}\bm{C}_{{f}}&amp;=\mathrm{E}\left[\tilde{\bm{H}}_{{f}}\hat{\tilde{\bm{H}}}^{H}_{{f}}\right]\left[\mathrm{E}\left[\hat{\tilde{\bm{H}}}_{{f}}\hat{\tilde{\bm{H}}}^{H}_{{f}}\right]\right]^{-1}=\begin{bmatrix}\mathrm{E}\left[\tilde{\bm{H}}_{{f}}\hat{\tilde{\bm{h}}}^{H}_{{q}}\right]&amp;\mathrm{E}\left[\tilde{\bm{H}}_{{i}}\hat{\tilde{\bm{h}}}^{H}_{{q+1}}\right]\end{bmatrix}\begin{bmatrix}\mathrm{E}\left[\mathinner{\!\left\lVert{\tilde{\bm{h}}}_{{q}}\right\rVert}^{2}\right]+E_{{{q}}}&amp;\mathrm{E}\left[{\tilde{\bm{h}}}_{{q}}{\tilde{\bm{h}}}^{H}_{{q+1}}\right]\\
    \mathrm{E}\left[{\tilde{\bm{h}}}_{{q+1}}{\tilde{\bm{h}}}^{H}_{{q}}\right]&amp;\mathrm{E}\left[\mathinner{\!\left\lVert{\tilde{\bm{h}}}_{{q+1}}\right\rVert}^{2}\right]+E_{{{q+1}}}\end{bmatrix}^{-1}\\'
- en: '&amp;=\begin{bmatrix}J_{0}(2\pi f_{\text{d}}(f-1)T_{\text{s}})&amp;J_{0}(2\pi
    f_{\text{d}}(I_{f}+1-f)T_{\text{s}})\end{bmatrix}\begin{bmatrix}1+E_{{{\Phi}_{q}}}&amp;J_{0}(2\pi
    f_{\text{d}}I_{f}T_{\text{s}})\\'
  id: totrans-939
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '&amp;=\begin{bmatrix}J_{0}(2\pi f_{\text{d}}(f-1)T_{\text{s}})&amp;J_{0}(2\pi
    f_{\text{d}}(I_{f}+1-f)T_{\text{s}})\end{bmatrix}\begin{bmatrix}1+E_{{{\Phi}_{q}}}&amp;J_{0}(2\pi
    f_{\text{d}}I_{f}T_{\text{s}})\\'
- en: J_{0}(2\pi f_{\text{d}}I_{f}T_{\text{s}})&amp;1+E_{{{q+1}}}\end{bmatrix}^{-1}.\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"
    ><mtr ><mtd columnalign="right" ><msub ><mi >𝑪</mi><mi >f</mi></msub></mtd><mtd
    columnalign="left" ><mrow ><mo >=</mo><mrow ><mi mathvariant="normal"  >E</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo  >[</mo><mrow ><msub ><mover accent="true"  ><mi
    >𝑯</mi><mo >~</mo></mover><mi >f</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><msubsup
    ><mover accent="true" ><mover accent="true" ><mi >𝑯</mi><mo >~</mo></mover><mo
    >^</mo></mover><mi >f</mi><mi >H</mi></msubsup></mrow><mo >]</mo></mrow><mo lspace="0em"
    rspace="0em" >​</mo><msup ><mrow ><mo >[</mo><mrow ><mi mathvariant="normal"  >E</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo >[</mo><mrow ><msub ><mover accent="true"
    ><mover accent="true" ><mi >𝑯</mi><mo >~</mo></mover><mo >^</mo></mover><mi >f</mi></msub><mo
    lspace="0em" rspace="0em" >​</mo><msubsup ><mover accent="true" ><mover accent="true"
    ><mi >𝑯</mi><mo >~</mo></mover><mo >^</mo></mover><mi >f</mi><mi >H</mi></msubsup></mrow><mo
    >]</mo></mrow></mrow><mo >]</mo></mrow><mrow ><mo >−</mo><mn >1</mn></mrow></msup></mrow><mo
    >=</mo><mrow ><mrow ><mo >[</mo><mtable columnspacing="5pt" displaystyle="true"
    ><mtr ><mtd  ><mrow ><mi mathvariant="normal"  >E</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo >[</mo><mrow ><msub ><mover accent="true"  ><mi >𝑯</mi><mo >~</mo></mover><mi
    >f</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><msubsup ><mover accent="true"  ><mover
    accent="true"  ><mi >𝒉</mi><mo >~</mo></mover><mo >^</mo></mover><mi >q</mi><mi
    >H</mi></msubsup></mrow><mo >]</mo></mrow></mrow></mtd><mtd ><mrow ><mi mathvariant="normal"
    >E</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mo >[</mo><mrow ><msub ><mover
    accent="true"  ><mi >𝑯</mi><mo >~</mo></mover><mi >i</mi></msub><mo lspace="0em"
    rspace="0em"  >​</mo><msubsup ><mover accent="true"  ><mover accent="true"  ><mi
    >𝒉</mi><mo >~</mo></mover><mo >^</mo></mover><mrow ><mi >q</mi><mo >+</mo><mn
    >1</mn></mrow><mi >H</mi></msubsup></mrow><mo >]</mo></mrow></mrow></mtd></mtr></mtable><mo
    >]</mo></mrow><mo lspace="0em" rspace="0em"  >​</mo><msup ><mrow  ><mo >[</mo><mtable
    columnspacing="5pt" displaystyle="true" rowspacing="0pt" ><mtr  ><mtd ><mrow ><mrow
    ><mi mathvariant="normal" >E</mi><mo lspace="0em" rspace="0em" >​</mo><mrow ><mpadded
    width="0.247em"><mo  >[</mo></mpadded><msup ><mrow ><mo fence="true" rspace="0em"
    stretchy="true" >∥</mo><msub ><mover accent="true" ><mi >𝒉</mi><mo >~</mo></mover><mi
    >q</mi></msub><mo fence="true" lspace="0em" rspace="0em" stretchy="true" >∥</mo></mrow><mn
    >2</mn></msup><mo >]</mo></mrow></mrow><mo >+</mo><msub ><mi >E</mi><mi >q</mi></msub></mrow></mtd><mtd
    ><mrow ><mi mathvariant="normal" >E</mi><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mo >[</mo><mrow ><msub ><mover accent="true"  ><mi >𝒉</mi><mo >~</mo></mover><mi
    >q</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><msubsup ><mover accent="true"  ><mi
    >𝒉</mi><mo >~</mo></mover><mrow ><mi >q</mi><mo >+</mo><mn >1</mn></mrow><mi >H</mi></msubsup></mrow><mo
    >]</mo></mrow></mrow></mtd></mtr><mtr ><mtd ><mrow ><mi mathvariant="normal" >E</mi><mo
    lspace="0em" rspace="0em" >​</mo><mrow ><mo >[</mo><mrow ><msub ><mover accent="true"  ><mi
    >𝒉</mi><mo >~</mo></mover><mrow ><mi >q</mi><mo >+</mo><mn >1</mn></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><msubsup ><mover accent="true"  ><mi >𝒉</mi><mo
    >~</mo></mover><mi >q</mi><mi >H</mi></msubsup></mrow><mo >]</mo></mrow></mrow></mtd><mtd
    ><mrow ><mrow ><mi mathvariant="normal" >E</mi><mo lspace="0em" rspace="0em" >​</mo><mrow
    ><mpadded width="0.247em"><mo  >[</mo></mpadded><msup ><mrow ><mo fence="true"
    rspace="0em" stretchy="true" >∥</mo><msub ><mover accent="true" ><mi >𝒉</mi><mo
    >~</mo></mover><mrow ><mi >q</mi><mo >+</mo><mn >1</mn></mrow></msub><mo fence="true"
    lspace="0em" rspace="0em" stretchy="true" >∥</mo></mrow><mn >2</mn></msup><mo
    >]</mo></mrow></mrow><mo >+</mo><msub ><mi >E</mi><mrow ><mi >q</mi><mo >+</mo><mn
    >1</mn></mrow></msub></mrow></mtd></mtr></mtable><mo >]</mo></mrow><mrow ><mo
    >−</mo><mn >1</mn></mrow></msup></mrow></mrow></mtd></mtr><mtr ><mtd  columnalign="left"
    ><mrow ><mrow ><mo >=</mo><mrow ><mrow ><mo >[</mo><mtable columnspacing="5pt"
    displaystyle="true" ><mtr ><mtd  ><mrow ><msub ><mi >J</mi><mn >0</mn></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"  >(</mo><mrow ><mn
    >2</mn><mo lspace="0em" rspace="0em"  >​</mo><mi >π</mi><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi >f</mi><mtext >d</mtext></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false"  >(</mo><mrow ><mi >f</mi><mo >−</mo><mn >1</mn></mrow><mo
    stretchy="false"  >)</mo></mrow><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi
    >T</mi><mtext >s</mtext></msub></mrow><mo stretchy="false"  >)</mo></mrow></mrow></mtd><mtd
    ><mrow ><msub ><mi >J</mi><mn >0</mn></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false"  >(</mo><mrow ><mn >2</mn><mo lspace="0em" rspace="0em"  >​</mo><mi
    >π</mi><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi >f</mi><mtext >d</mtext></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"  >(</mo><mrow ><mrow
    ><msub ><mi >I</mi><mi >f</mi></msub><mo >+</mo><mn >1</mn></mrow><mo >−</mo><mi
    >f</mi></mrow><mo stretchy="false"  >)</mo></mrow><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi >T</mi><mtext >s</mtext></msub></mrow><mo stretchy="false"  >)</mo></mrow></mrow></mtd></mtr></mtable><mo
    >]</mo></mrow><mo lspace="0em" rspace="0em"  >​</mo><msup ><mrow  ><mo >[</mo><mtable
    columnspacing="5pt" displaystyle="true" rowspacing="0pt" ><mtr  ><mtd ><mrow ><mn
    >1</mn><mo >+</mo><msub ><mi >E</mi><msub ><mi mathvariant="normal" >Φ</mi><mi
    >q</mi></msub></msub></mrow></mtd><mtd ><mrow ><msub ><mi >J</mi><mn >0</mn></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"  >(</mo><mrow ><mn
    >2</mn><mo lspace="0em" rspace="0em"  >​</mo><mi >π</mi><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi >f</mi><mtext >d</mtext></msub><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi >I</mi><mi >f</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi
    >T</mi><mtext >s</mtext></msub></mrow><mo stretchy="false"  >)</mo></mrow></mrow></mtd></mtr><mtr
    ><mtd ><mrow ><msub ><mi >J</mi><mn >0</mn></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false"  >(</mo><mrow ><mn >2</mn><mo lspace="0em" rspace="0em"  >​</mo><mi
    >π</mi><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi >f</mi><mtext >d</mtext></msub><mo
    lspace="0em" rspace="0em"  >​</mo><msub ><mi >I</mi><mi >f</mi></msub><mo lspace="0em"
    rspace="0em"  >​</mo><msub ><mi >T</mi><mtext >s</mtext></msub></mrow><mo stretchy="false"  >)</mo></mrow></mrow></mtd><mtd
    ><mrow ><mn >1</mn><mo >+</mo><msub ><mi >E</mi><mrow ><mi >q</mi><mo >+</mo><mn
    >1</mn></mrow></msub></mrow></mtd></mtr></mtable><mo >]</mo></mrow><mrow ><mo
    >−</mo><mn >1</mn></mrow></msup></mrow></mrow><mo lspace="0em"  >.</mo></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑪</ci><ci >𝑓</ci></apply><apply ><ci  >E</ci><apply ><csymbol cd="latexml"  >delimited-[]</csymbol><apply
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><ci >~</ci><ci >𝑯</ci></apply><ci
    >𝑓</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><apply ><csymbol
    cd="ambiguous" >superscript</csymbol><apply ><ci  >^</ci><apply ><ci >~</ci><ci
    >𝑯</ci></apply></apply><ci >𝐻</ci></apply><ci >𝑓</ci></apply></apply></apply><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><apply ><csymbol cd="latexml" >delimited-[]</csymbol><apply
    ><ci >E</ci><apply ><csymbol cd="latexml" >delimited-[]</csymbol><apply ><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><apply ><ci >^</ci><apply ><ci >~</ci><ci
    >𝑯</ci></apply></apply><ci >𝑓</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><apply ><ci >^</ci><apply ><ci
    >~</ci><ci >𝑯</ci></apply></apply><ci >𝐻</ci></apply><ci >𝑓</ci></apply></apply></apply></apply></apply><apply
    ><cn type="integer"  >1</cn></apply></apply></apply></apply><apply ><apply ><apply
    ><csymbol cd="latexml" >matrix</csymbol><matrix ><matrixrow ><apply ><ci >E</ci><apply
    ><csymbol cd="latexml" >delimited-[]</csymbol><apply ><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><apply ><ci >~</ci><ci >𝑯</ci></apply><ci >𝑓</ci></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><apply ><csymbol cd="ambiguous" >superscript</csymbol><apply
    ><ci >^</ci><apply ><ci >~</ci><ci >𝒉</ci></apply></apply><ci >𝐻</ci></apply><ci
    >𝑞</ci></apply></apply></apply></apply><apply ><ci >E</ci><apply ><csymbol cd="latexml"  >delimited-[]</csymbol><apply
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><ci >~</ci><ci >𝑯</ci></apply><ci
    >𝑖</ci></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply ><ci >^</ci><apply ><ci >~</ci><ci
    >𝒉</ci></apply></apply><ci >𝐻</ci></apply><apply ><ci >𝑞</ci><cn type="integer"  >1</cn></apply></apply></apply></apply></apply></matrixrow></matrix></apply><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><apply ><csymbol cd="latexml"
    >matrix</csymbol><matrix ><matrixrow ><apply ><apply ><ci >E</ci><apply ><csymbol
    cd="latexml" >delimited-[]</csymbol><apply ><csymbol cd="ambiguous"  >superscript</csymbol><apply
    ><csymbol cd="latexml"  >delimited-∥∥</csymbol><apply ><csymbol cd="ambiguous"  >subscript</csymbol><apply
    ><ci >~</ci><ci >𝒉</ci></apply><ci >𝑞</ci></apply></apply><cn type="integer"  >2</cn></apply></apply></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐸</ci><ci >𝑞</ci></apply></apply><apply
    ><ci >E</ci><apply ><csymbol cd="latexml"  >delimited-[]</csymbol><apply ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><ci >~</ci><ci >𝒉</ci></apply><ci
    >𝑞</ci></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply ><ci >~</ci><ci >𝒉</ci></apply><ci
    >𝐻</ci></apply><apply ><ci >𝑞</ci><cn type="integer"  >1</cn></apply></apply></apply></apply></apply></matrixrow><matrixrow
    ><apply ><ci >E</ci><apply ><csymbol cd="latexml" >delimited-[]</csymbol><apply
    ><apply ><csymbol cd="ambiguous" >subscript</csymbol><apply ><ci >~</ci><ci >𝒉</ci></apply><apply
    ><ci >𝑞</ci><cn type="integer" >1</cn></apply></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><apply ><ci >~</ci><ci >𝒉</ci></apply><ci
    >𝐻</ci></apply><ci >𝑞</ci></apply></apply></apply></apply><apply ><apply ><ci
    >E</ci><apply ><csymbol cd="latexml"  >delimited-[]</csymbol><apply ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply ><csymbol cd="latexml"  >delimited-∥∥</csymbol><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><ci >~</ci><ci >𝒉</ci></apply><apply
    ><ci >𝑞</ci><cn type="integer"  >1</cn></apply></apply></apply><cn type="integer"  >2</cn></apply></apply></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐸</ci><apply ><ci >𝑞</ci><cn
    type="integer"  >1</cn></apply></apply></apply></matrixrow></matrix></apply><apply
    ><cn type="integer"  >1</cn></apply></apply></apply></apply><apply ><apply ><apply
    ><csymbol cd="latexml" >matrix</csymbol><matrix ><matrixrow ><apply ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝐽</ci><cn type="integer" >0</cn></apply><apply
    ><cn type="integer" >2</cn><ci >𝜋</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑓</ci><ci ><mtext mathsize="70%" >d</mtext></ci></apply><apply ><ci >𝑓</ci><cn
    type="integer"  >1</cn></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑇</ci><ci ><mtext mathsize="70%"  >s</mtext></ci></apply></apply></apply><apply
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐽</ci><cn type="integer"  >0</cn></apply><apply
    ><cn type="integer"  >2</cn><ci >𝜋</ci><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><ci ><mtext mathsize="70%"  >d</mtext></ci></apply><apply ><apply ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐼</ci><ci >𝑓</ci></apply><cn
    type="integer"  >1</cn></apply><ci >𝑓</ci></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑇</ci><ci ><mtext mathsize="70%"  >s</mtext></ci></apply></apply></apply></matrixrow></matrix></apply><apply
    ><csymbol cd="ambiguous"  >superscript</csymbol><apply ><csymbol cd="latexml"
    >matrix</csymbol><matrix ><matrixrow ><apply ><cn type="integer" >1</cn><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐸</ci><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >Φ</ci><ci >𝑞</ci></apply></apply></apply><apply ><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐽</ci><cn type="integer"  >0</cn></apply><apply
    ><cn type="integer"  >2</cn><ci >𝜋</ci><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑓</ci><ci ><mtext mathsize="70%"  >d</mtext></ci></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝐼</ci><ci >𝑓</ci></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑇</ci><ci ><mtext mathsize="70%"  >s</mtext></ci></apply></apply></apply></matrixrow><matrixrow
    ><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝐽</ci><cn type="integer"
    >0</cn></apply><apply ><cn type="integer" >2</cn><ci >𝜋</ci><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝑓</ci><ci ><mtext mathsize="70%" >d</mtext></ci></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐼</ci><ci >𝑓</ci></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑇</ci><ci ><mtext mathsize="70%"  >s</mtext></ci></apply></apply></apply><apply
    ><cn type="integer"  >1</cn><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝐸</ci><apply ><ci >𝑞</ci><cn type="integer"  >1</cn></apply></apply></apply></matrixrow></matrix></apply><apply
    ><cn type="integer" >1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}\bm{C}_{{f}}&=\mathrm{E}\left[\tilde{\bm{H}}_{{f}}\hat{\tilde{\bm{H}}}^{H}_{{f}}\right]\left[\mathrm{E}\left[\hat{\tilde{\bm{H}}}_{{f}}\hat{\tilde{\bm{H}}}^{H}_{{f}}\right]\right]^{-1}=\begin{bmatrix}\mathrm{E}\left[\tilde{\bm{H}}_{{f}}\hat{\tilde{\bm{h}}}^{H}_{{q}}\right]&\mathrm{E}\left[\tilde{\bm{H}}_{{i}}\hat{\tilde{\bm{h}}}^{H}_{{q+1}}\right]\end{bmatrix}\begin{bmatrix}\mathrm{E}\left[\mathinner{\!\left\lVert{\tilde{\bm{h}}}_{{q}}\right\rVert}^{2}\right]+E_{{{q}}}&\mathrm{E}\left[{\tilde{\bm{h}}}_{{q}}{\tilde{\bm{h}}}^{H}_{{q+1}}\right]\\
    \mathrm{E}\left[{\tilde{\bm{h}}}_{{q+1}}{\tilde{\bm{h}}}^{H}_{{q}}\right]&\mathrm{E}\left[\mathinner{\!\left\lVert{\tilde{\bm{h}}}_{{q+1}}\right\rVert}^{2}\right]+E_{{{q+1}}}\end{bmatrix}^{-1}\\
    &=\begin{bmatrix}J_{0}(2\pi f_{\text{d}}(f-1)T_{\text{s}})&J_{0}(2\pi f_{\text{d}}(I_{f}+1-f)T_{\text{s}})\end{bmatrix}\begin{bmatrix}1+E_{{{\Phi}_{q}}}&J_{0}(2\pi
    f_{\text{d}}I_{f}T_{\text{s}})\\ J_{0}(2\pi f_{\text{d}}I_{f}T_{\text{s}})&1+E_{{{q+1}}}\end{bmatrix}^{-1}.\end{split}</annotation></semantics></math>
    |  | (51) |
  id: totrans-940
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-941
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'CNN-based Processing: The final step in the [WI](#id37.37.id37)-[CNN](#id28.28.id28)
    estimators is to apply [CNN](#id28.28.id28) processing to further improve the
    [WI](#id37.37.id37) estimated channels. Optimized [SR-CNN](#id25.25.id25) and
    [DN-CNN](#id26.26.id26) are employed in this context. The investigations conducted
    in [[32](#bib.bib32)] reveal that both [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26)
    networks have similar performance in low mobility scenarios, whereas [DN-CNN](#id26.26.id26)
    outperforms [SR-CNN](#id25.25.id25) in high mobility scenarios. Figure [7](#S5.F7
    "Figure 7 ‣ V-B TS-ChannelNet ‣ V DL-Based FBF Channel Estimation Schemes ‣ A
    Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments")
    and Table [III](#S5.T3 "Table III ‣ V-A ChannelNet ‣ V DL-Based FBF Channel Estimation
    Schemes ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments") illustrate the block diagram as well as configured parameters of
    the studied CNN-based channel estimators, respectively. Furthermore, the salient
    features of the studied DL-based channel estimators are summarized in Table [II](#S5.T2
    "Table II ‣ V DL-Based FBF Channel Estimation Schemes ‣ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments"). Notably, robustness
    feature alludes to the ability of the studied estimation to maintain good performance
    as the variation of the doubly-dispersive channel increases.'
  id: totrans-942
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于CNN的处理：在[WI](#id37.37.id37)-[CNN](#id28.28.id28)估计器中的最终步骤是应用[CNN](#id28.28.id28)处理，以进一步改善[WI](#id37.37.id37)估计的信道。在此背景下，采用了优化的[SR-CNN](#id25.25.id25)和[DN-CNN](#id26.26.id26)。在[[32](#bib.bib32)]中进行的研究表明，在低移动性场景下，[SR-CNN](#id25.25.id25)和[DN-CNN](#id26.26.id26)网络表现相似，而在高移动性场景下，[DN-CNN](#id26.26.id26)优于[SR-CNN](#id25.25.id25)。图[7](#S5.F7
    "Figure 7 ‣ V-B TS-ChannelNet ‣ V DL-Based FBF Channel Estimation Schemes ‣ A
    Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments")和表[III](#S5.T3
    "Table III ‣ V-A ChannelNet ‣ V DL-Based FBF Channel Estimation Schemes ‣ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")分别展示了所研究的基于CNN的信道估计器的框图和配置参数。此外，表[II](#S5.T2
    "Table II ‣ V DL-Based FBF Channel Estimation Schemes ‣ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments")总结了所研究的基于DL的信道估计器的显著特征。值得注意的是，鲁棒性特征指的是所研究的估计方法在双重散射信道变化增大的情况下保持良好性能的能力。
- en: 'Table IV: The characteristics of the employed vehicular channel models following
    Jake’s Doppler spectrum.'
  id: totrans-943
  prefs: []
  type: TYPE_NORMAL
  zh: 表IV：遵循Jake的多普勒谱的车辆信道模型的特性。
- en: '|'
  id: totrans-944
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Channel &#124;'
  id: totrans-945
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 信道 &#124;'
- en: '&#124; model &#124;'
  id: totrans-946
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模型 &#124;'
- en: '|'
  id: totrans-947
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Channel &#124;'
  id: totrans-948
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 信道 &#124;'
- en: '&#124; taps &#124;'
  id: totrans-949
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 路径数 &#124;'
- en: '|'
  id: totrans-950
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Vehicle velocity &#124;'
  id: totrans-951
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 车辆速度 &#124;'
- en: '&#124; [kmph] &#124;'
  id: totrans-952
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [kmph] &#124;'
- en: '|'
  id: totrans-953
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Doppler &#124;'
  id: totrans-954
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 多普勒 &#124;'
- en: '&#124; shift [Hz] &#124;'
  id: totrans-955
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 移位 [Hz] &#124;'
- en: '| Average path gains [dB] | Path delays [ns] |'
  id: totrans-956
  prefs: []
  type: TYPE_TB
  zh: '| 平均路径增益 [dB] | 路径延迟 [ns] |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-957
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| VTV-UC | 12 | 45 | 250 |'
  id: totrans-958
  prefs: []
  type: TYPE_TB
  zh: '| VTV-UC | 12 | 45 | 250 |'
- en: '&#124; [0, 0, -10, -10, -10, -17.8, -17.8, &#124;'
  id: totrans-959
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [0, 0, -10, -10, -10, -17.8, -17.8, &#124;'
- en: '&#124; -17.8, -21.1, -21.1, -26.3, -26.3] &#124;'
  id: totrans-960
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; -17.8, -21.1, -21.1, -26.3, -26.3] &#124;'
- en: '|'
  id: totrans-961
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; [0, 1, 100, 101, 102, 200, 201, &#124;'
  id: totrans-962
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [0, 1, 100, 101, 102, 200, 201, &#124;'
- en: '&#124; 202, 300, 301, 400, 401] &#124;'
  id: totrans-963
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 202, 300, 301, 400, 401] &#124;'
- en: '|'
  id: totrans-964
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| VTV-SDWW | 12 | 100-200 | 500-1000 |'
  id: totrans-965
  prefs: []
  type: TYPE_TB
  zh: '| VTV-SDWW | 12 | 100-200 | 500-1000 |'
- en: '&#124; [0, 0, -11.2, -11.2, -19, -21.9, -25.3, &#124;'
  id: totrans-966
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [0, 0, -11.2, -11.2, -19, -21.9, -25.3, &#124;'
- en: '&#124; -25.3, -24.4, -28, -26.1, -26.1] &#124;'
  id: totrans-967
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; -25.3, -24.4, -28, -26.1, -26.1] &#124;'
- en: '|'
  id: totrans-968
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; [0, 1, 100, 101, 200, 300, 400, &#124;'
  id: totrans-969
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [0, 1, 100, 101, 200, 300, 400, &#124;'
- en: '&#124; 401, 500, 600, 700, 701] &#124;'
  id: totrans-970
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 401, 500, 600, 700, 701] &#124;'
- en: '|'
  id: totrans-971
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: VI Simulation Results
  id: totrans-972
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 模拟结果
- en: This section illustrates the performance evaluation of the studied [DL](#id96.96.id96)-based
    SBS and FBF estimators in relation to [BER](#id64.64.id64), [NMSE](#id204.204.id204)
    employing varied metrics and mobility scenarios.
  id: totrans-973
  prefs: []
  type: TYPE_NORMAL
  zh: 本节说明了所研究的基于[DL](#id96.96.id96)的SBS和FBF估计器在[BER](#id64.64.id64)、[NMSE](#id204.204.id204)方面的性能评估，使用了各种指标和移动性场景。
- en: VI-A Configuration Setup
  id: totrans-974
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-A 配置设置
- en: To simulate doubly-dispersive channels, vehicular communications is considered
    a simulation case study, where three [tapped delay line](#id4.4.id4) ([TDL](#id4.4.id4))
    channel models [[58](#bib.bib58)] are defined as follows
  id: totrans-975
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟双重散射信道，将车辆通信作为一个模拟案例研究，其中定义了三种[tapped delay line](#id4.4.id4)（[TDL](#id4.4.id4)）信道模型[[58](#bib.bib58)]，具体如下
- en: •
  id: totrans-976
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Low mobility: where VTV Urban Canyon (VTV-UC) vehicular channel model is considered.
    This channel model is measured between two vehicles moving in a dense urban traffic
    environment at ${V}=45$ Kmph equivalent to ${f}_{d}=250$ Hz.'
  id: totrans-977
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-978
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'High and very high mobility: These scenarios measure the communication channel
    between two vehicles moving on a highway having center wall between its lanes
    at ${V}=100$ Kmph and $200$ Kmph equivalent to ${f}_{d}=500$ Hz and ${f}_{d}=1000$
    Hz, respectively. This vehicular channel model is referred to as VTV Expressway
    Same Direction with Wall (VTV-SDWW).'
  id: totrans-979
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The employed channel models are generated after the wide-sense stationary uncorrelated
    scattering (WSSUS) model [[59](#bib.bib59)]. Thus, we have
  id: totrans-980
  prefs: []
  type: TYPE_NORMAL
- en: •
  id: totrans-981
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each path $h_{l}(t)$ is a zero mean Gaussian complex process, $E\{h_{l}(t)\}=0,\forall
    t$, and the mean of each path is independent of the time variations. Moreover,
    the time correlation function $r_{h_{l}}(t_{1},t_{2})=E\{h_{l}(t_{1})h^{*}_{l}(t_{2})\}$
    can only be written with the difference $\Delta(t)=(t_{1}-t_{2})$, such that
  id: totrans-982
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $r_{h_{l}}(t_{1},t_{2})=r_{h_{l}}(\Delta_{t}).$ |  | (52) |'
  id: totrans-983
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: Then, each path $h_{l}(t)$ is the wide sense stationary (WSS).
  id: totrans-984
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-985
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uncorrelated scattering (US) implies that the paths are uncorrelated, so for
    $l_{1}\neq l_{2}$ we have
  id: totrans-986
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\small E[h_{l_{1}}(t)h^{*}_{l_{2}}(t)]=0.$ |  | (53) |'
  id: totrans-987
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: Table [IV](#S5.T4 "Table IV ‣ V-C WI-CNN ‣ V DL-Based FBF Channel Estimation
    Schemes ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments") illustrates the main characteristics of the defined [TDL](#id4.4.id4)
    channel models.
  id: totrans-988
  prefs: []
  type: TYPE_NORMAL
- en: 'The [OFDM](#id208.208.id208) simulation parameters are based on the IEEE 802.11p
    standard as illustrated in Table [V](#S6.T5 "Table V ‣ VI-A Configuration Setup
    ‣ VI Simulation Results ‣ A Survey on Deep Learning based Channel Estimation in
    Doubly Dispersive Environments"). These simulations are implemented using QPSK
    and 16QAM modulation orders, the SNR range is $[0,5,\dots,40]$ dB. In addition,
    the performance evaluation is made according to: (i) modulation order, (ii) mobility,
    (iii) frame length, and (iv) DL architecture.'
  id: totrans-989
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it is observed that the conventional 2D [LMMSE](#id166.166.id166) estimator [[17](#bib.bib17)]
    is included in the performance evaluation of the DL-based FBF estimators as a
    lower bound performance limit. The 2D LMMSE estimator almost achieves a similar
    performance as the ideal channel, but is ridden with high computational complexity.
    This renders it impractical in terms of real-time applications.
  id: totrans-990
  prefs: []
  type: TYPE_NORMAL
- en: 'Table V: Simulation parameters of the IEEE 802.11p physical layer.'
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
- en: '| Parameter | IEEE 802.11p |'
  id: totrans-992
  prefs: []
  type: TYPE_TB
- en: '| Bandwidth | 10 MHz |'
  id: totrans-993
  prefs: []
  type: TYPE_TB
- en: '| Guard interval duration | 1.6 $\mu\mbox{s}$ |'
  id: totrans-994
  prefs: []
  type: TYPE_TB
- en: '| Symbol duration | 8 $\mu\mbox{s}$ |'
  id: totrans-995
  prefs: []
  type: TYPE_TB
- en: '| Short training symbol duration | 1.6 $\mu\mbox{s}$ |'
  id: totrans-996
  prefs: []
  type: TYPE_TB
- en: '| Long training symbol duration | 6.4 $\mu\mbox{s}$ |'
  id: totrans-997
  prefs: []
  type: TYPE_TB
- en: '| Total subcarriers | 64 |'
  id: totrans-998
  prefs: []
  type: TYPE_TB
- en: '| Pilot subcarriers | 4 |'
  id: totrans-999
  prefs: []
  type: TYPE_TB
- en: '| Data subcarriers | 48 |'
  id: totrans-1000
  prefs: []
  type: TYPE_TB
- en: '| Subcarrier spacing | 156.25 KHz |'
  id: totrans-1001
  prefs: []
  type: TYPE_TB
- en: VI-B DL-Based SBS Estimation Schemes
  id: totrans-1002
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: VI-B1 Modulation Order
  id: totrans-1003
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fcc7714601b8375736909a941f46a3bb.png)'
  id: totrans-1004
  prefs: []
  type: TYPE_IMG
- en: (a)
  id: totrans-1005
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d90c662d4b14b588b27448e2af7b0bde.png)'
  id: totrans-1006
  prefs: []
  type: TYPE_IMG
- en: (b)
  id: totrans-1007
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8: BER for $I=100$, mobility from left to right: low ($v=45\leavevmode\nobreak\
    \text{Kmph},f_{d}=250$ Hz), high ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$
    Hz), very high ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$ Hz).'
  id: totrans-1008
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9bd0d39c4e69b2c1356bda30e5c0e025.png)'
  id: totrans-1009
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: NMSE for $I=100$, mobility from left to right: low ($v=45\leavevmode\nobreak\
    \text{Kmph},f_{d}=250$ Hz), high ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$
    Hz), very high ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$ Hz).'
  id: totrans-1010
  prefs: []
  type: TYPE_NORMAL
- en: For QPSK modulation order, we can notice from Figure [8](#S6.F8 "Figure 8 ‣
    VI-B1 Modulation Order ‣ VI-B DL-Based SBS Estimation Schemes ‣ VI Simulation
    Results ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments"), and Figure [9](#S6.F9 "Figure 9 ‣ VI-B1 Modulation Order ‣ VI-B
    DL-Based SBS Estimation Schemes ‣ VI Simulation Results ‣ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments") that conventional
    [SBS](#id22.22.id22) estimators witness a considerable performance degradation
    in different mobility scenarios primarily due to the enlarged DPA demapping error,
    particularly under very high mobility. Nevertheless, employing DL techniques in
    the channel estimation process results in a significant improvement in overall
    performance. To begin with, the FNN-based estimators, where FNN is employed as
    a post-processing unit after conventional estimators, are discussed. As observed,
    FNN can implicitly learn the channel correlations apart from preventing a high
    demapping error arising from conventional DPA-based estimation, while STA-FNN
    and TRFI-FNN outperform conventional STA and TRFI estimators by at least $15$
    dB gain in terms of SNR for BER $=10^{-3}$. Meanwhile, STA-FNN estimator outperforms
    DPA-FNN estimator by around $5$ dB gain in terms of SNR for BER $=10^{-3}$. However,
    STA-FNN suffers from error floor beginning from SNR $=20$ dB, particularly in
    very high mobility scenarios. This is attributed to the fact that conventional
    STA estimation outperforms DPA in low SNR region due to the frequency and time
    averaging operations that can alleviate the impact of noise and demapping error
    in low SNR regions. On the other hand, the averaging operations are not useful
    in high SNR regions since the impact of noise is low, and the STA averaging coefficients
    are fixed. Therefore, TRFI-FNN is used to improve the performance at high SNRs
    to compensate for the STA-FNN performance degradation in high SNR region. Importantly,
    STA-FNN and TRFI-FNN can be employed in an adaptive manner where STA-FNN and TRFI-FNN
    are used in low and high SNR regions, respectively.
  id: totrans-1011
  prefs: []
  type: TYPE_NORMAL
- en: For the LSTM-based estimators, employing LSTM as a prepossessing unit rather
    than a simple FNN in the channel estimation has shown to bring about a significant
    improvement in the overall performance. This is because LSTM is capable of efficiently
    learning the time correlations of the channel by taking the advantage of the previous
    output apart from the current input in order to estimate the current output. LSTM-FNN-DPA
    estimator [[53](#bib.bib53)] outperforms STA-FNN and TRFI-FNN estimators by approximately
    $4$ dB gain in terms of SNR for BER $=10^{-3}$. However, this estimator is not
    impervious to high computational complexity, as discussed in the next section,
    due to the utilization of two DL networks, i.e, LSTM followed by FNN. On the other
    hand, the LSTM-DPA-TA estimators performance gain in various scenarios can be
    explained by employing the [TA](#id46.46.id46) processing, which significantly
    alleviates the noise impact aside from the strong ability of the LSTM in learning
    the channel time correlations compared with a simple FNN architecture. The LSTM-DPA-TA
    estimator outperforms the LSTM-FNN-DPA estimator by around $4$ dB gain in terms
    of SNR for BER $=10^{-4}$. When adopting high modulation order (16QAM), the LSTM-DPA-TA
    estimator outperforms the other estimators by at least $7$ dB and $3$ dB gains
    in terms of SNR for BER $=10^{-3}$ in high as well as very high mobility scenarios,
    respectively, as illustrated in Figure LABEL:BER_16QAM_DL_SBS.
  id: totrans-1012
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于LSTM的估计器，使用LSTM作为预处理单元，而不是简单的FNN，在信道估计中显示出显著提高整体性能的效果。这是因为LSTM能够通过利用前一个输出，除了当前输入外，有效地学习信道的时间相关性，从而估计当前输出。LSTM-FNN-DPA
    估计器[[53](#bib.bib53)] 在BER $=10^{-3}$的SNR方面比STA-FNN和TRFI-FNN估计器高出约$4$ dB。然而，由于利用了两个DL网络，即LSTM随后是FNN，该估计器并不完全免受高计算复杂度的影响，这将在下一节中讨论。另一方面，LSTM-DPA-TA估计器在各种场景中的性能提升可以通过采用[TA](#id46.46.id46)处理来解释，这显著减轻了噪声的影响，与简单的FNN架构相比，LSTM在学习信道时间相关性方面的能力更强。LSTM-DPA-TA估计器在BER
    $=10^{-4}$的SNR方面比LSTM-FNN-DPA估计器高出约$4$ dB。当采用高调制阶数（16QAM）时，LSTM-DPA-TA估计器在BER
    $=10^{-3}$的SNR方面在高移动性和非常高移动性场景中分别比其他估计器高出至少$7$ dB和$3$ dB，如图LABEL:BER_16QAM_DL_SBS所示。
- en: VI-B2 Mobility
  id: totrans-1013
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-B2 移动性
- en: The degraded performance with the increased mobility of all the studied schemes
    can be observed from Figure [8](#S6.F8 "Figure 8 ‣ VI-B1 Modulation Order ‣ VI-B
    DL-Based SBS Estimation Schemes ‣ VI Simulation Results ‣ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments"). However, the time
    diversity gain increases when there is an increase in the Doppler spread, as evidenced
    by comparing the case of the DL-based estimators in high mobility $(f_{d}=500)$
    and very high mobility ($f_{d}=1000$). This behavior can be explained by the ability
    of DL networks to reduce the estimation error stemming from the AWGN noise and
    the DPA demapping error. By contrast, the net gain from the time diversity is
    influenced by the AWGN noise and DPA demapping error, as is the case in conventional
    SBS estimators. The performance degradation is attributed as the mobility increases
    since the impact of the AWGN noise and DPA demapping error is much more dominant
    than the time diversity gain. This observation is also valid for high modulation
    orders such as 16QAM, as evidenced in Figure LABEL:BER_16QAM_DL_SBS.
  id: totrans-1014
  prefs: []
  type: TYPE_NORMAL
  zh: 从图[8](#S6.F8 "图 8 ‣ VI-B1 调制阶数 ‣ VI-B DL 基于 SBS 估计方案 ‣ VI 仿真结果 ‣ 深度学习在双重扩散环境中的信道估计综述")可以观察到，所有研究方案的性能随着移动性的增加而下降。然而，当多普勒扩展增加时，时间多样性增益增加，这可以通过比较高移动性
    $(f_{d}=500)$和非常高移动性 ($f_{d}=1000$) 下DL基估计器的情况来证明。这种行为可以通过DL网络减少来自AWGN噪声和DPA解映射错误的估计误差的能力来解释。相比之下，时间多样性的净增益受到AWGN噪声和DPA解映射错误的影响，就像传统SBS估计器的情况一样。性能下降的原因是由于移动性增加时，AWGN噪声和DPA解映射错误的影响比时间多样性增益更为显著。这一观察结果对于高调制阶数（如16QAM）也是有效的，如图LABEL:BER_16QAM_DL_SBS所示。
- en: '![Refer to caption](img/646dea683ec34378d7fc5f630245e619.png)'
  id: totrans-1015
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/646dea683ec34378d7fc5f630245e619.png)'
- en: 'Figure 10: BER for QPSK, very high mobility ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$
    Hz) from left to right: $I=10$, $I=100$.'
  id: totrans-1016
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：QPSK的BER，非常高的移动性（$v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$ Hz），从左到右：$I=10$，$I=100$。
- en: '![Refer to caption](img/a28d04e18208edc54cdbfef2debad558.png)'
  id: totrans-1017
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/a28d04e18208edc54cdbfef2debad558.png)'
- en: (a)
  id: totrans-1018
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/0efe8976fddfe6a92e1e226e33123e9f.png)'
  id: totrans-1019
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/0efe8976fddfe6a92e1e226e33123e9f.png)'
- en: (b)
  id: totrans-1020
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 11: BER for $I=100$, mobility from left to right: low ($v=45\leavevmode\nobreak\
    \text{Kmph},f_{d}=250$ Hz), high ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$
    Hz), very high ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$ Hz). The CNN
    refers to SR-CNN and DN-CNN in low and high/very high) mobility scenarios, respectively.'
  id: totrans-1021
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：$I=100$ 时的 BER，从左到右的移动性：低 ($v=45\leavevmode\nobreak\ \text{Kmph},f_{d}=250$
    Hz)，高 ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$ Hz)，非常高 ($v=200\leavevmode\nobreak\
    \text{Kmph},f_{d}=1000$ Hz)。CNN 指低和高/非常高移动性场景中的 SR-CNN 和 DN-CNN。
- en: VI-B3 Frame Length
  id: totrans-1022
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-B3 帧长度
- en: The impact of frame length is illustrated in Figure [10](#S6.F10 "Figure 10
    ‣ VI-B2 Mobility ‣ VI-B DL-Based SBS Estimation Schemes ‣ VI Simulation Results
    ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments").
    As can be seen, the performance of the conventional estimators strongly depends
    on the frame length, given that employing short frame $I=10$ results in a negligible
    accumulated DPA demapping error. By contrast, the DL-based estimators are found
    to be more robust against the changes in the employed frame length. However, in
    the case of a long frame ($I=100$), the performance gain of the DL-based estimators
    is significantly remarkable. This behavior is mainly attributed to the time diversity
    negligible gain when short frame is employed and vice versa.
  id: totrans-1023
  prefs: []
  type: TYPE_NORMAL
  zh: 帧长度的影响在图[10](#S6.F10 "图 10 ‣ VI-B2 移动性 ‣ VI-B 基于 DL 的 SBS 估计方案 ‣ VI 仿真结果 ‣ 关于深度学习在双分散环境中通道估计的调查")中进行了说明。如图所示，传统估计器的性能严重依赖于帧长度，因为使用短帧
    $I=10$ 会导致可忽略的累积 DPA 解映射误差。相比之下，基于 DL 的估计器在使用不同帧长度时表现出更强的鲁棒性。然而，在长帧 ($I=100$)
    的情况下，基于 DL 的估计器的性能提升显著。这种行为主要归因于使用短帧时时间分集增益微乎其微，反之亦然。
- en: To conclude, it can be surmised that increasing the frame length increases the
    time diversity gain. Additionally, the codeword becomes longer with a longer frame.
    Therefore, the time diversity is capable of compensating for Doppler error, particularly
    in very high mobility scenario as illustrated in Figure [10](#S6.F10 "Figure 10
    ‣ VI-B2 Mobility ‣ VI-B DL-Based SBS Estimation Schemes ‣ VI Simulation Results
    ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive Environments")
  id: totrans-1024
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，可以推测增加帧长度会增加时间分集增益。此外，帧越长，码字也会变长。因此，时间分集能够补偿多普勒误差，特别是在图[10](#S6.F10 "图
    10 ‣ VI-B2 移动性 ‣ VI-B 基于 DL 的 SBS 估计方案 ‣ VI 仿真结果 ‣ 关于深度学习在双分散环境中通道估计的调查")中所示的非常高移动性场景下。
- en: VI-B4 DL Architecture
  id: totrans-1025
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-B4 DL 架构
- en: The DPA-FNN estimator integrates three hidden layer FNN in additon to the conventional
    DPA estimation with $40-20-40$ neurons. However, as can be observed in Figure [8](#S6.F8
    "Figure 8 ‣ VI-B1 Modulation Order ‣ VI-B DL-Based SBS Estimation Schemes ‣ VI
    Simulation Results ‣ A Survey on Deep Learning based Channel Estimation in Doubly
    Dispersive Environments"), correcting the estimation error of the DPA estimation
    is insufficient even after the inclusion of more neurons in the FNN hidden layers,
    because it merely corrects the demapping error, neglecting the received symbols’requency
    and time correlation. Meanwhile, the [STA](#id17.17.id17)-[FNN](#id99.99.id99)
    and TRFI-FNN estimators have better optimized three hidden layers [FNN](#id99.99.id99)
    architecture where $15-15-15$ neurons are used. Consequently, the overall computational
    complexity is considerably lowered when compared to the DPA-FNN, while attaining
    performance superiority. This is due to the fact that [STA](#id17.17.id17) considers
    frequency as well a time correlation between the received [OFDM](#id208.208.id208)
    symbols, while the conventional TRFI estimator employs frequency-domain cubic
    interpolation to make further improvements in the DPA estimation.
  id: totrans-1026
  prefs: []
  type: TYPE_NORMAL
  zh: DPA-FNN 估计器在常规 DPA 估计的基础上集成了三个隐藏层 FNN，使用 $40-20-40$ 个神经元。然而，正如图[8](#S6.F8 "图
    8 ‣ VI-B1 调制阶数 ‣ VI-B 基于 DL 的 SBS 估计方案 ‣ VI 仿真结果 ‣ 关于深度学习在双分散环境中通道估计的调查")所示，即使在
    FNN 隐藏层中加入更多神经元，纠正 DPA 估计误差也不足够，因为它仅纠正了解映射误差，忽略了接收符号的频率和时间相关性。与此同时，[STA](#id17.17.id17)-[FNN](#id99.99.id99)
    和 TRFI-FNN 估计器优化了三个隐藏层的[FNN](#id99.99.id99)架构，使用 $15-15-15$ 个神经元。因此，与 DPA-FNN
    相比，整体计算复杂性显著降低，同时实现了性能优势。这是因为[STA](#id17.17.id17)考虑了接收的[OFDM](#id208.208.id208)符号之间的频率和时间相关性，而传统的
    TRFI 估计器则采用频域三次插值来进一步改进 DPA 估计。
- en: Therefore, it can be concluded that the pre-estimation should be good enough
    in order for the FNN processing to be more useful. Put differently, with an increased
    accuracy of the pre-estimation, low-complexity FNN architecture can be taken advantage
    of while recording a significant performance gain. On the contrary, if the pre-estimation
    is poor, employing FNN processing with high-complexity architecture results in
    a limited performance gain while increasing the overall computational complexity.
    As is the case with LSTM-based estimators, employing the [TA](#id46.46.id46) processing
    in the LSTM-DPA-TA estimator to ameliorate the AWGN noise impact results in a
    less complex architecture in comparison to the LSTM-FNN-DPA estimator, where two
    [DL](#id96.96.id96) networks are employed.
  id: totrans-1027
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，可以得出结论，预估值应足够准确，以便FNN处理更加有用。换句话说，随着预估准确度的提高，可以利用低复杂度的FNN架构实现显著的性能提升。相反，如果预估值较差，使用高复杂度架构的FNN处理会在增加整体计算复杂度的同时，带来有限的性能提升。与LSTM基础的估计器类似，在LSTM-DPA-TA估计器中使用[TA](#id46.46.id46)处理以减轻AWGN噪声的影响，相较于使用两个[DL](#id96.96.id96)网络的LSTM-FNN-DPA估计器，能够实现更简单的架构。
- en: VI-C DL-Based FBF estimation Scheme
  id: totrans-1028
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-C 基于DL的FBF估计方案
- en: '![Refer to caption](img/24f068f737e3e71fe0b9af50b58b7105.png)'
  id: totrans-1029
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/24f068f737e3e71fe0b9af50b58b7105.png)'
- en: 'Figure 12: NMSE for $I=100$, mobility from left to right: low ($v=45\leavevmode\nobreak\
    \text{Kmph},f_{d}=250$ Hz), high ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$
    Hz), very high ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$ Hz).The CNN
    refers to SR-CNN and DN-CNN in low and high/very high) mobility scenarios, respectively.'
  id: totrans-1030
  prefs: []
  type: TYPE_NORMAL
  zh: '图12: 对于$I=100$，从左到右的移动性：低（$v=45\leavevmode\nobreak\ \text{Kmph},f_{d}=250$
    Hz），高（$v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$ Hz），非常高（$v=200\leavevmode\nobreak\
    \text{Kmph},f_{d}=1000$ Hz）。CNN指在低和高/非常高移动性场景下的SR-CNN和DN-CNN。'
- en: VI-C1 Modulation Order
  id: totrans-1031
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-C1 调制顺序
- en: Figure [11](#S6.F11 "Figure 11 ‣ VI-B2 Mobility ‣ VI-B DL-Based SBS Estimation
    Schemes ‣ VI Simulation Results ‣ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments") illustrates the BER performance of the studied
    DL-Based FBF estimators employing QPSK and 16QAM modulation orders. The 2D [LMMSE](#id166.166.id166)
    uses the channel and noise statistics in the estimation, thus leading to comparable
    performance in terms of the ideal case. However, the 2D-[LMMSE](#id166.166.id166)
    is ridden with high computational complexity. Moreover, the significant [BER](#id64.64.id64)
    performance superiority of the WI-CNN estimators can be observed where FP-ALS-CNN
    outperforms the ChannelNet as well as TS-ChannelNet estimators by at least $6$
    dB and $3$ dB gain in terms of [SNR](#id263.263.id263) for a BER = $10^{-3}$.
    Importantly, [ChannelNet](#id35.35.id35) and [TS-ChannelNet](#id29.29.id29) estimators
    suffer from a considerable performance degradation that is dominant in very high
    mobility scenarios. This is because their performance accounts for the predefined
    fixed parameters in the applied interpolation scheme, where it is important to
    update the RBF interpolation function and the ADD-TT frequency and time averaging
    parameters in real-time. Furthermore, the ADD-TT interpolation employs only the
    previous and the current pilot subcarriers for the channel estimation at each
    received [OFDM](#id208.208.id208) symbol. By contrast, there are no fixed parameters
    in the WI-CNN estimators. The time correlation between the previous and the future
    pilot symbols is considered in the [WI](#id37.37.id37) interpolation matrix ([51](#S5.E51
    "In 2nd item ‣ V-C WI-CNN ‣ V DL-Based FBF Channel Estimation Schemes ‣ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")),
    whereas the estimated channel is considered in the overall estimation at all channel
    taps. These aspects lead to the superior performance of WI-CNN estimators performance,
    where a significant robustness is shown against high mobility with varied performance
    gain according to the employed pilot allocation scheme, i.e FP or LP. In addition,
    WI-CNN estimators employ optimized [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26)
    in accordance with the mobility condition, wherein SR-CNN is utilized in low mobility
    scenarios, whereas, DN-CNN is employed in high and very high mobility scenarios.
  id: totrans-1032
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/51764fea3344eca31836b2cfc22bad42.png)'
  id: totrans-1033
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: BER performance of VTV-SDWW high mobility vehicular channel model
    employing QPSK modulation and different frame lengths.'
  id: totrans-1034
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4ae79dccf8e3b8c701d79d7a47874296.png)'
  id: totrans-1035
  prefs: []
  type: TYPE_IMG
- en: (a)
  id: totrans-1036
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b6817ee62e2a44d0f19ef1ce0c53b789.png)'
  id: totrans-1037
  prefs: []
  type: TYPE_IMG
- en: (b)
  id: totrans-1038
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 14: BER performance employing three scenarios: (i) first column - low
    mobility ($v=45\leavevmode\nobreak\ \text{Kmph},f_{d}=250$ Hz) (ii) second column
    - high mobility ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$ Hz) (iii) third
    column - very high mobility ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$
    Hz). The CNN refers to SR-CNN and DN-CNN in low and high/very high) mobility scenarios,
    respectively.'
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：在三种场景下的BER性能：（i）第一列 - 低移动性（`$v=45\leavevmode\nobreak\ \text{Kmph},f_{d}=250$
    Hz`） （ii）第二列 - 高移动性（`$v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$ Hz`） （iii）第三列
    - 极高移动性（`$v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$ Hz`）。CNN指的是低和高/极高移动性场景中的SR-CNN和DN-CNN。
- en: VI-C2 Mobility
  id: totrans-1040
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-C2 移动性
- en: A degradation is observed in the overall performance of [ChannelNet](#id35.35.id35)
    and [TS-ChannelNet](#id29.29.id29) estimators as the mobility increases, while
    the WI-CNN estimators reveal a robustness against high mobility, as illustrated
    in Figure [11](#S6.F11 "Figure 11 ‣ VI-B2 Mobility ‣ VI-B DL-Based SBS Estimation
    Schemes ‣ VI Simulation Results ‣ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments"). This is primarily attributed to the accuracy
    of the [WI](#id37.37.id37) interpolation, coupled with optimized [SR-CNN](#id25.25.id25)
    and [DN-CNN](#id26.26.id26). Although [CNN](#id28.28.id28) processing is implemented
    in the [ChannelNet](#id35.35.id35) and [TS-ChannelNet](#id29.29.id29), this post
    [CNN](#id28.28.id28) processing is unable to perform well due to the high estimation
    error of the 2D RBF and ADD-TT interpolation techniques in the initial estimation.
    Therefore, it can be concluded that employing robust initial estimation as the
    [WI](#id37.37.id37) interpolation schemes allows the [CNN](#id28.28.id28) to better
    learn the channel correlation with lower complexity, thereby enhancing the channel
    estimation.
  id: totrans-1041
  prefs: []
  type: TYPE_NORMAL
  zh: 随着移动性的增加，[ChannelNet](#id35.35.id35)和[TS-ChannelNet](#id29.29.id29)估计器的整体性能出现了下降，而WI-CNN估计器在高移动性下显示了鲁棒性，如图
    [11](#S6.F11 "Figure 11 ‣ VI-B2 Mobility ‣ VI-B DL-Based SBS Estimation Schemes
    ‣ VI Simulation Results ‣ A Survey on Deep Learning based Channel Estimation in
    Doubly Dispersive Environments") 所示。这主要归因于 [WI](#id37.37.id37) 插值的准确性，加上优化的 [SR-CNN](#id25.25.id25)
    和 [DN-CNN](#id26.26.id26)。虽然 [CNN](#id28.28.id28) 处理在 [ChannelNet](#id35.35.id35)
    和 [TS-ChannelNet](#id29.29.id29) 中已实现，但由于2D RBF和ADD-TT插值技术在初始估计中的高估计误差，这种后续 [CNN](#id28.28.id28)
    处理无法表现良好。因此，可以得出结论，采用鲁棒的初始估计作为 [WI](#id37.37.id37) 插值方案，使 [CNN](#id28.28.id28)
    能够以更低的复杂度更好地学习信道相关性，从而提升信道估计。
- en: VI-C3 Frame Length
  id: totrans-1042
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-C3 帧长度
- en: Figure [13](#S6.F13 "Figure 13 ‣ VI-C1 Modulation Order ‣ VI-C DL-Based FBF
    estimation Scheme ‣ VI Simulation Results ‣ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments") illustrates the [BER](#id64.64.id64)
    performance of high mobility vehicular scenario employing QPSK modulation and
    different frame lengths. As can be clearly observed, the WI-FP-ALS estimator outperforms
    ChannelNet and TS-ChannelNet for different frame lengths without any post CNN
    processing. This is because of the long codeword that shows the robustness of
    the WI-FP-ALS estimator, unlike the 2D RBF and ADD-TT interpolation techniques
    that suffer from a significant estimation error even when considering a short
    frame. Moreover, employing the optimized DN-CNN after the WI-FP-ALS estimator
    significantly enhances the BER performance.
  id: totrans-1043
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [13](#S6.F13 "Figure 13 ‣ VI-C1 Modulation Order ‣ VI-C DL-Based FBF estimation
    Scheme ‣ VI Simulation Results ‣ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments") 展示了在高移动性车辆场景中，采用QPSK调制和不同帧长度的 [BER](#id64.64.id64)
    性能。可以清楚地观察到，WI-FP-ALS估计器在不同帧长度下优于ChannelNet和TS-ChannelNet，而无需任何后续CNN处理。这是由于长码字显示了WI-FP-ALS估计器的鲁棒性，而2D
    RBF和ADD-TT插值技术即使在考虑短帧时也会遭遇显著的估计误差。此外，在WI-FP-ALS估计器之后使用优化的DN-CNN显著提高了BER性能。
- en: However, although [CNN](#id28.28.id28) processing is applied in the [ChannelNet](#id35.35.id35)
    and [TS-ChannelNet](#id29.29.id29), this post [CNN](#id28.28.id28) processing
    is unable to perform well. This is attributed to the high estimation error of
    the 2D RBF and ADD-TT interpolation techniques in the initial estimation. Thus,
    we can conclude that employing robust initial estimation as the [WI](#id37.37.id37)
    interpolation schemes enable the [CNN](#id28.28.id28) to better learn the channel
    correlation with lower complexity, thereby enhancing the channel estimation, as
    shown in Figure [12](#S6.F12 "Figure 12 ‣ VI-C DL-Based FBF estimation Scheme
    ‣ VI Simulation Results ‣ A Survey on Deep Learning based Channel Estimation in
    Doubly Dispersive Environments").
  id: totrans-1044
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管在[ChannelNet](#id35.35.id35)和[TS-ChannelNet](#id29.29.id29)中应用了[CNN](#id28.28.id28)处理，但该后处理[CNN](#id28.28.id28)效果不佳。这归因于初始估计中2D
    RBF和ADD-TT插值技术的高估计误差。因此，我们可以得出结论，采用稳健的初始估计作为[WI](#id37.37.id37)插值方案可以使[CNN](#id28.28.id28)更好地学习通道相关性，降低复杂性，从而增强通道估计，如图[12](#S6.F12
    "图 12 ‣ VI-C 基于DL的FBF估计方案 ‣ VI仿真结果 ‣ 基于深度学习的双散射环境下的通道估计调研")所示。
- en: '![Refer to caption](img/897b4f1b13ea559402809c59e5186937.png)'
  id: totrans-1045
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/897b4f1b13ea559402809c59e5186937.png)'
- en: 'Figure 15: NMSE performance employing three scenarios: (i) first column - low
    mobility ($v=45\leavevmode\nobreak\ \text{Kmph},f_{d}=250$ Hz) (ii) second column
    - high mobility ($v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$ Hz) (iii) third
    column - very high mobility ($v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$
    Hz). The CNN refers to SR-CNN and DN-CNN in low and high/very high) mobility scenarios,
    respectively.'
  id: totrans-1046
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15：NMSE性能在三种场景下的表现：(i) 第一列 - 低速移动（$v=45\leavevmode\nobreak\ \text{Kmph},f_{d}=250$
    Hz）(ii) 第二列 - 高速移动（$v=100\leavevmode\nobreak\ \text{Kmph},f_{d}=500$ Hz）(iii)
    第三列 - 非常高速移动（$v=200\leavevmode\nobreak\ \text{Kmph},f_{d}=1000$ Hz）。CNN指在低和高速/非常高速移动场景下的SR-CNN和DN-CNN。
- en: VI-D CNN Architecture
  id: totrans-1047
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-D CNN架构
- en: The [ChannelNet](#id35.35.id35) estimator employs [SR-CNN](#id25.25.id25) and
    [DN-CNN](#id26.26.id26) following the 2D RBF interpolation. The employed [SR-CNN](#id25.25.id25)
    comprises three convolutional layers with $(v_{1}=9;f_{1}=64),(v_{2}=1,f_{2}=32)$
    and $(v_{3}=5,f_{3}=1)$, respectively. Moreover, the [DN-CNN](#id26.26.id26) depth
    is $D=18$ with $3\times 3\times 32$ kernels in each layer. Meanwhile, [SR-ConvLSTM](#id39.39.id39)
    network comprises three ConvLSTM layers of $(v_{1}=9;f_{1}=64),(v_{2}=1,f_{2}=32)$
    and $(v_{3}=5,f_{3}=1)$, respectively, and is integrated after the ADD-TT interpolation
    in the [TS-ChannelNet](#id29.29.id29) estimator. The [SR-ConvLSTM](#id39.39.id39)
    network combines both the [CNN](#id28.28.id28) and the LSTM networks[[51](#bib.bib51)],
    thus increasing the overall computational complexity, as shall be discussed later.
    By contrast, the employed optimized SR-CNN and DN-CNN significantly reduces the
    complexity due to the WI estimators’ accuracy. Put succinctly, the complexity
    of the employed CNN decreases as the accuracy of the pre-estimation increases,
    because low-complexity architectures can be utilized and vice versa.
  id: totrans-1048
  prefs: []
  type: TYPE_NORMAL
  zh: '[ChannelNet](#id35.35.id35)估计器在2D RBF插值后使用了[SR-CNN](#id25.25.id25)和[DN-CNN](#id26.26.id26)。所用的[SR-CNN](#id25.25.id25)包括三个卷积层，分别为$(v_{1}=9;f_{1}=64),(v_{2}=1,f_{2}=32)$和$(v_{3}=5,f_{3}=1)$。此外，[DN-CNN](#id26.26.id26)的深度为$D=18$，每层使用$3\times
    3\times 32$的卷积核。同时，[SR-ConvLSTM](#id39.39.id39)网络包括三个ConvLSTM层，分别为$(v_{1}=9;f_{1}=64),(v_{2}=1,f_{2}=32)$和$(v_{3}=5,f_{3}=1)$，并在[TS-ChannelNet](#id29.29.id29)估计器中的ADD-TT插值之后进行整合。[SR-ConvLSTM](#id39.39.id39)网络结合了[CNN](#id28.28.id28)和LSTM网络[[51](#bib.bib51)]，从而增加了整体计算复杂性，后续将进一步讨论。相比之下，由于WI估计器的准确性，所用的优化SR-CNN和DN-CNN显著降低了复杂性。简而言之，所用CNN的复杂性随着预估准确性的提高而降低，因为可以利用低复杂度架构，反之亦然。'
- en: VI-E DL-Based SBS vs. DL-Based FBF estimation Scheme
  id: totrans-1049
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-E 基于DL的SBS与基于DL的FBF估计方案
- en: This section further examines the performance assessment of the studied estimators,
    where only the best DL-based SBS and FBF estimators are compared. Figures [14](#S6.F14
    "Figure 14 ‣ VI-C1 Modulation Order ‣ VI-C DL-Based FBF estimation Scheme ‣ VI
    Simulation Results ‣ A Survey on Deep Learning based Channel Estimation in Doubly
    Dispersive Environments") and[15](#S6.F15 "Figure 15 ‣ VI-C3 Frame Length ‣ VI-C
    DL-Based FBF estimation Scheme ‣ VI Simulation Results ‣ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments") illustrate the BER
    and NMSE performance of the investigated [DL](#id96.96.id96)-based estimators
    in low, high, and very high mobility scenarios, employing QPSK and 16QAM modulation
    orders.
  id: totrans-1050
  prefs: []
  type: TYPE_NORMAL
- en: In low-mobility scenario, the LSTM-DPA-TA [SBS](#id22.22.id22) estimator outperforms
    the WI-FP-ALS-SR-CNN FBF estimator. This can be explained by the ability of LSTM
    to better learn the channel time correlation than the SR-CNN, since Doppler error
    is somehow negligible in low mobility scenario. However, in high and very high
    mobility scenarios, WI-FP-ALS-DN-CNN shows a significantly improved performance,
    outperforming the LSTM-DPA-TA SBS estimator by $3$ dB gain in terms of SNR for
    a BER = $10^{-4}$. In high mobility scenarios, where the Doppler error impact
    is high, LSTM suffers from some performance degradation as learning the time correlation
    between successive samples is not achievable in the low mobility scenario case.
    Meanwhile, DN-CNN network can significantly alleviate the impact of noise and
    Doppler error, where it records at least $5$ dB gain in terms of SNR for a BER
    = $10^{-4}$. To conclude, it can be inferred that employing LSTM network rather
    than FNN and DN-CNN networks leads to improved performance in low-mobility scenarios.
    In By contrast, DN-CNN is more useful in high as well as very high mobility scenarios
    because DN-CNN uses the entire pilot subcarriers within the received frame. To
    summarize, the time correlation between successive received OFDM symbols decreases
    as the mobility increases. Therefore, the performance of LSTM suffers from performance
    degradation when compared with CNN. On the other hand, the CNN-based estimators
    become more useful than the LSTM-based estimators in high mobility scenarios.
  id: totrans-1051
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it is observes that DL-based FBF estimators suffer from high buffering
    time at the receiver, because it is necessary to receive the full frame before
    the channel estimation begins leading to high latency. However, this buffering
    time is lowered in the WI-CNN estimators after dividing the received frame into
    sub frames so that the channel estimation process commences prior to the full
    frame reception. Moreover, the WI-CNN estimators also help increase the transmission
    data rate as fewer pilots are inserted into the transmitted frame.
  id: totrans-1052
  prefs: []
  type: TYPE_NORMAL
- en: VII Complexity Analysis
  id: totrans-1053
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section provides a detailed computational complexity analysis of the studied
    [DL](#id96.96.id96)-based [SBS](#id22.22.id22) and [FBF](#id23.23.id23) estimators.
    The computational complexity analysis is performed in accordance with the number
    of real-valued arithmetic operations, multiplication/division and summation/subtraction
    necessary to estimate the channel for one received [OFDM](#id208.208.id208) frame.
    Each complex-valued division requires $6$ real-valued multiplications, $2$ divisions,
    $2$ summations, and $1$ subtraction. In addition, each complex-valued multiplication
    is performed by $4$ real-valued multiplications and $3$ summations.
  id: totrans-1054
  prefs: []
  type: TYPE_NORMAL
- en: <svg   height="280.85" overflow="visible" version="1.1" width="1187.02" color="#000000"><g
    transform="translate(0,280.85) matrix(1 0 0 -1 0 0) translate(49.01,0) translate(0,24.86)
    matrix(1.0 0.0 0.0 1.0 -49.01 -24.86)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    transform="matrix(1 0 0 1 0 0) translate(143.83,0) translate(0,-517.67)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -53.62
    522.28)" fill="#000000" stroke="#000000"><foreignobject width="107.24" height="9.46"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">LSTM-FNN-DPA</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 188.69 522.28)" fill="#000000" stroke="#000000"><foreignobject
    width="97.82" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">LSTM-DPA-TA</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 442.24 522.28)" fill="#000000" stroke="#000000"><foreignobject
    width="63.61" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">DPA-FNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 676.77 522.28)" fill="#000000" stroke="#000000"><foreignobject
    width="68.61" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">TRFI-FNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 917.45 522.28)" fill="#000000" stroke="#000000"><foreignobject
    width="61.31" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">STA-FNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -117.42 615.91)" fill="#000000" stroke="#000000"><foreignobject
    width="17.71" height="11.41" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10^{6}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -117.42 719.51)" fill="#000000" stroke="#000000"><foreignobject
    width="17.71" height="11.41" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10^{7}$</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 -129.61 576.97)" fill="#000000" stroke="#000000"><foreignobject
    width="145.21" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Real-Valued
    Operations</foreignobject></g><g fill="#FFFFFF" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 277.35 777.48)"><g  transform="matrix(1 0 0 -1 0 8.995)"><g  transform="matrix(1
    0 0 1 0 8.99)"><g transform="matrix(1 0 0 -1 13.01 0) translate(79.27,0) matrix(1.0
    0.0 0.0 1.0 -76.51 -4.15)" fill="#000000" stroke="#000000"><foreignobject width="153.01"
    height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Multiplications/Divisions</foreignobject></g><g
    transform="matrix(1 0 0 -1 184.56 0) translate(81.66,0) matrix(1.0 0.0 0.0 1.0
    -78.89 -4.15)" fill="#000000" stroke="#000000"><foreignobject width="157.78" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Summations/Subtractions</foreignobject></g></g></g></g></g></g></svg>
  id: totrans-1055
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 16: Computational complexity comparison of the studied DL-based SBS
    estimators.'
  id: totrans-1056
  prefs: []
  type: TYPE_NORMAL
- en: 'Table VI: Detailed computation complexity of the studied DL-based SBS estimators.'
  id: totrans-1057
  prefs: []
  type: TYPE_NORMAL
- en: Estimator Mul./Div. Sum./Sub. FNN($J_{2}$-$J_{3}$-$J_{4}$) $2K_{\text{on}}J_{2}$
    + $J_{2}J_{3}$ + $J_{3}J_{4}$ + $2K_{\text{on}}J_{4}$ $2K_{\text{on}}J_{2}$ +
    $J_{2}J_{3}$ + $J_{3}J_{4}$ +$2K_{\text{on}}J_{4}$ LSTM ($P$) $P^{2}+3P+PK_{in}$
    $4P+K_{in}-2$ Overall channel estimation STA-FNN $82K_{\text{on}}+2K_{d}+450$
    $70K_{\text{on}}+10K_{d}+450$ TRFI-FNN $94K_{\text{on}}+26K_{\text{int}}+450$
    $74K_{\text{on}}+30K_{\text{int}}+450$ DPA-FNN $178K_{\text{on}}+1600$ $168K_{\text{on}}+1600$
    LSTM-FNN-DPA $512K_{\text{in}}+98K_{d}+71040$ $4K_{\text{in}}+88K_{d}+6776$ LSTM-DPA-TA($64$)
    $514K_{on}+18K_{d}+16576$ $10K_{on}+8K_{d}+824$ LSTM-DPA-TA($128$) $1026K_{on}+18K_{d}+65920$
    $10K_{on}+8K_{d}+1656$
  id: totrans-1058
  prefs: []
  type: TYPE_NORMAL
- en: VII-A DL-Based SBS Estimators
  id: totrans-1059
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The [DPA](#id16.16.id16) estimation implemented in the DL-based [SBS](#id22.22.id22)
    estimators as an initial step needs two equalization steps ([23](#S4.E23 "In IV-A
    DPA-FNN ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep Learning based
    Channel Estimation in Doubly Dispersive Environments")), and ([25](#S4.E25 "In
    IV-A DPA-FNN ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments")). Each equalization
    step comprises $K_{\text{on}}$ complex-valued divisions. Moreover, it needs the
    LS estimated channel at the preamble computed by $2K_{\text{on}}$ summation and
    $2K_{\text{on}}$ divisions. Hence, the overall computational complexity of the
    [DPA](#id16.16.id16) estimation is $16K_{\text{on}}$ multiplications/divisions
    and $6K_{\text{on}}$ summations/subtractions.
  id: totrans-1060
  prefs: []
  type: TYPE_NORMAL
- en: The [STA](#id17.17.id17) estimator applies frequency as well as time-domain
    averaging in addition to [DPA](#id16.16.id16). The frequency-domain averaging ([26](#S4.E26
    "In IV-B STA-FNN ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments")) coefficient is fixed
    ($\beta=2$). Thus, each subcarrier requires $5$ complex-valued summations multiplied
    by a real-valued weight, which, in turn, are equivalent to $10$ real-valued summations,
    and $2$ real-valued multiplications. Consequently, the [STA](#id17.17.id17) frequency-domain
    averaging step requires $10K_{d}$ real-valued summations, and $2K_{d}$ real-valued
    multiplications. The [STA](#id17.17.id17) time-domain averaging step ([27](#S4.E27
    "In IV-B STA-FNN ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep Learning
    based Channel Estimation in Doubly Dispersive Environments")) requires $4K_{\text{on}}$
    real-valued divisions, and $2K_{\text{on}}$ real-valued summations. For this reason,
    the accumulated overall computational complexity of [STA](#id17.17.id17) estimator
    is $22K_{\text{on}}+2K_{\text{d}}$ multiplications/divisions and $10K_{\text{on}}+10K_{\text{d}}$
    summations/subtractions.
  id: totrans-1061
  prefs: []
  type: TYPE_NORMAL
- en: The [TRFI](#id19.19.id19) estimator implements another two equalization steps
    after the [DPA](#id16.16.id16) estimation ([28](#S4.E28 "In 1st item ‣ IV-C TRFI-FNN
    ‣ IV DL-Based SBS Channel Estimation ‣ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments")). Thereafter, it applies cubic
    interpolation as the last step. Based on the analysis performed in [[28](#bib.bib28)],
    the computational complexity of [TRFI](#id19.19.id19) is $34K_{\text{on}}+26K_{\text{int}}$
    multiplications/divisions and $14K_{\text{on}}+30K_{\text{int}}$ summations/subtractions,
    where $K_{\text{int}}$ represents the number of unreliable subcarriers in each
    received [OFDM](#id208.208.id208) symbol.
  id: totrans-1062
  prefs: []
  type: TYPE_NORMAL
- en: VII-A1 FNN-based Estimators
  id: totrans-1063
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For the FNN-based estimators, the DPA-FNN architecture [[27](#bib.bib27)] consists
    of three hidden layers with $J_{1}=J_{5}=2K_{\text{on}}$, $J_{2}=J_{4}=40$, and
    $J_{3}=20$ neurons, respectively. Therefore, the DPA-FNN requires $4K_{\text{on}}J_{2}+2J_{2}J_{3}$
    multiplications, and $2K_{\text{on}}+2J_{2}+J_{3}$ summations. The computational
    complexity of [LS](#id172.172.id172) and the DPA estimation are accumulated for
    DPA-FNN computational complexity resulting in total of $178K_{\text{on}}+1600$
    multiplications and $168K_{\text{on}}+1600$ summations/subtractions.
  id: totrans-1064
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $CC_{\text{FNN}}=2\sum_{l=0}^{L+1}{N}_{l-1}{N}_{l},\leavevmode\nobreak\
    \mbox{where }{N}_{0}={N}_{L+1}=2K_{\text{on}}.$ |  | (54) |'
  id: totrans-1065
  prefs: []
  type: TYPE_TB
- en: The STA-FNN and TRFI-FNN estimators employ a three-hidden layer FNN architecture
    consisting of $15$ neurons each. This FNN architecture requires $4K_{\text{on}}J_{2}+2J_{2}^{2}$,
    and $2K_{\text{on}}+3J_{2}$ summations. This architecture is less complex when
    compared with the DPA-FNN one. Thus, the [STA](#id17.17.id17)-[FNN](#id99.99.id99)
    overall computational complexity is $82K_{\text{on}}+2K_{d}+450$ multiplications,
    and $70K_{\text{on}}+10K_{d}+450$ summations/subtractions. Furthermore, the TRFI-FNN
    needs $94K_{\text{on}}+26K_{\text{int}}+450$ multiplications, and $74K_{\text{on}}+30K_{\text{int}}+450$
    summations/subtractions. The [TRFI](#id19.19.id19)-[FNN](#id99.99.id99) estimator
    reduces the number of multiplications as well as summations by $48\%$ and $56\%$,
    respectively, when compared with DPA-[FNN](#id99.99.id99), while its computational
    complexity is similar to that of [STA](#id17.17.id17)-[FNN](#id99.99.id99).
  id: totrans-1066
  prefs: []
  type: TYPE_NORMAL
- en: VII-A2 LSTM-Based Estimators
  id: totrans-1067
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The computational complexity of the [LSTM](#id32.32.id32) unit can be calculated
    with respect to the number of operations performed by its four gates. Each gate
    applies $P^{2}+PK_{in}$ real-valued multiplications and $3P+K_{in}-2$ summations
    apart from $3P$ multiplications, and $P$ summations required by ([19](#S3.E19
    "In Update the new cell state ‣ III-B LSTM ‣ III DL Techniques Overview ‣ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")),
    and ([21](#S3.E21 "In Generate the LSTM unit output ‣ III-B LSTM ‣ III DL Techniques
    Overview ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments")). As a result, the overall computational complexity for the [LSTM](#id32.32.id32)
    becomes
  id: totrans-1068
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $CC_{\text{LSTM}}=4(P^{2}+PK_{\text{in}}+3P+K_{\text{in}}-2)+4P.$ |  |
    (55) |'
  id: totrans-1069
  prefs: []
  type: TYPE_TB
- en: Notably, [FNN](#id99.99.id99)-based estimators need less computation than [LSTM](#id32.32.id32),
    thus achieving lower complexity.
  id: totrans-1070
  prefs: []
  type: TYPE_NORMAL
- en: <svg   height="281" overflow="visible" version="1.1" width="1187.02" color="#000000"><g
    transform="translate(0,281) matrix(1 0 0 -1 0 0) translate(49.01,0) translate(0,25.01)
    matrix(1.0 0.0 0.0 1.0 -49.01 -25.01)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    transform="matrix(1 0 0 1 0 0) translate(143.83,0) translate(0,-408.99)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -35.94
    413.6)" fill="#000000" stroke="#000000"><foreignobject width="71.88" height="9.61"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">ChannelNet</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 268.95 413.6)" fill="#000000" stroke="#000000"><foreignobject
    width="94.17" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">TS-ChannelNet</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 576.72 413.76)" fill="#000000" stroke="#000000"><foreignobject
    width="110.7" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">FP-ALS-DN-CNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 894.29 413.76)" fill="#000000" stroke="#000000"><foreignobject
    width="107.62" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">FP-ALS-SR-CNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -117.42 462.4)" fill="#000000" stroke="#000000"><foreignobject
    width="17.71" height="11.41" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10^{7}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -117.42 529.28)" fill="#000000" stroke="#000000"><foreignobject
    width="17.71" height="11.41" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10^{8}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -117.42 596.15)" fill="#000000" stroke="#000000"><foreignobject
    width="17.71" height="11.41" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$10^{9}$</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 -129.61 468.45)" fill="#000000" stroke="#000000"><foreignobject
    width="145.21" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Real-Valued
    Operations</foreignobject></g><g fill="#FFFFFF" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 277.35 668.96)"><g  transform="matrix(1 0 0 -1 0 8.995)"><g  transform="matrix(1
    0 0 1 0 8.99)"><g transform="matrix(1 0 0 -1 13.01 0) translate(79.27,0) matrix(1.0
    0.0 0.0 1.0 -76.51 -4.15)" fill="#000000" stroke="#000000"><foreignobject width="153.01"
    height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Multiplications/Divisions</foreignobject></g><g
    transform="matrix(1 0 0 -1 184.56 0) translate(81.66,0) matrix(1.0 0.0 0.0 1.0
    -78.89 -4.15)" fill="#000000" stroke="#000000"><foreignobject width="157.78" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Summations/Subtractions</foreignobject></g></g></g></g></g></g></svg>
  id: totrans-1071
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 17: Computational complexity comparison of the studied DL-based FBF
    estimators.'
  id: totrans-1072
  prefs: []
  type: TYPE_NORMAL
- en: The [LSTM](#id32.32.id32)-[FNN](#id99.99.id99)-[DPA](#id16.16.id16) estimator
    employs one [LSTM](#id32.32.id32) unit with $P=128$ and $K_{in}=112$, followed
    by one hidden layer [FNN](#id99.99.id99) network with $N_{1}=40$ neurons. In addition,
    the [LSTM](#id32.32.id32)-[FNN](#id99.99.id99)-[DPA](#id16.16.id16) estimator
    implements the [DPA](#id16.16.id16) estimation that requires $18K_{d}$ real-valued
    multiplication/division and $8K_{d}$ summation/subtraction. Thus, the overall
    computational complexity of the [LSTM](#id32.32.id32)-[FNN](#id99.99.id99)-[DPA](#id16.16.id16)
    estimator is $512K_{\text{in}}+98K_{d}+71040$ multiplication/division and $4K_{\text{in}}+88K_{d}+6776$
    summation/subtraction.
  id: totrans-1073
  prefs: []
  type: TYPE_NORMAL
- en: The [LSTM](#id32.32.id32)-[DPA](#id16.16.id16)-[TA](#id46.46.id46) utilizes
    one [LSTM](#id32.32.id32) unit with $P=128$ as [LSTM](#id32.32.id32)-[FNN](#id99.99.id99)-[DPA](#id16.16.id16)
    estimator. It also uses $K_{in}=2K_{on}$, and applies [TA](#id46.46.id46) as a
    noise alleviation technique to the $\hat{\bar{\bm{h}}}_{\text{LSTM-DPA}_{i,d}}$
    estimated channel, that requires only $2K_{on}$ real-valued multiplication/division
    and $2K_{on}$ summation/subtraction. Hence, the [LSTM](#id32.32.id32)-[DPA](#id16.16.id16)-[TA](#id46.46.id46)
    estimator requires $4P^{2}+P(8K_{on}+3)+18K_{d}+2K_{on}$ real-valued multiplication/division
    and $13P+10K_{on}+8K_{d}-8$ summation/subtraction. As per this analysis, the [LSTM](#id32.32.id32)-[DPA](#id16.16.id16)-[TA](#id46.46.id46)
    estimator achieves less computational complexity in comparison to the [LSTM](#id32.32.id32)-[FNN](#id99.99.id99)-[DPA](#id16.16.id16)
    estimator. It records $9.73\%$ and $77.63\%$ computational complexity decline
    in the required real-valued multiplication/division and summation/subtraction,
    respectively. Importantly, replacing the [FNN](#id99.99.id99) network by the [TA](#id46.46.id46)
    to achieve noise alleviation is the primary factor in reducing the overall computational
    complexity. Moreover, the [LSTM](#id32.32.id32)-[DPA](#id16.16.id16)-[TA](#id46.46.id46)
    estimator outperforms the [LSTM](#id32.32.id32)-[FNN](#id99.99.id99)-[DPA](#id16.16.id16)
    estimator while recording lower computational complexity. As a matter of fact,
    employing the [LSTM](#id32.32.id32)-[DPA](#id16.16.id16)-[TA](#id46.46.id46) LSTM-based
    estimators as opposed to the FNN-based estimators results in $89.10\%$ and $62.18\%$
    increase in the necessary multiplication/division and summation/subtraction, respectively.
    Nevertheless, it is possible to achieve a significant performance gain. Table[VI](#S7.T6
    "Table VI ‣ VII Complexity Analysis ‣ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments") and Figure[16](#S7.F16 "Figure
    16 ‣ VII Complexity Analysis ‣ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments") reveal a detailed summary of the computational
    complexities for the various examined DL-based SBS estimators.
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
- en: VII-B [DL](#id96.96.id96)-Based FBF Estimators
  id: totrans-1075
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: VII-B1 [ChannelNet](#id35.35.id35) estimator
  id: totrans-1076
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The [ChannelNet](#id35.35.id35) estimator utilizes the [RBF](#id27.27.id27)
    interpolation followed by [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26)
    networks. Therefore, the overall computational complexity of the [ChannelNet](#id35.35.id35)
    estimator can be expressed as follows
  id: totrans-1077
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{CC}_{{\text{ChannelNet}}}=\text{CC}_{{\text{RBF}}}+\text{CC}_{\text{SR-CNN}}+\text{CC}_{\text{DN-CNN}}.$
    |  | (56) |'
  id: totrans-1078
  prefs: []
  type: TYPE_TB
- en: The calculation of $\hat{\tilde{\bm{H}}}_{\text{LS}}$ requires $2K_{p}I$ divisions.
    The computation of $\bm{w}_{\text{RBF}}$ requires $4K^{2}_{p}I^{2}$ multiplications/divisions
    and $5K^{2}_{p}I^{2}-2K_{p}I$ summations/subtractions. Meanwhile, $\hat{\tilde{\bm{H}}}_{\text{RBF}}$
    requires $K_{d}I(K^{2}_{p}I^{2}+3K_{p}I)$ multiplications/divisions and $5K_{d}K_{p}I^{2}$
    subtractions/summations. Thus, the total computational complexity of the [RBF](#id27.27.id27)
    interpolation can be expressed by $K^{2}_{p}I^{2}(4+K_{d}I)+K_{p}I(2+3K_{d}I)$
    multiplications/divisions and $K_{p}I(5K_{p}I+5K_{d}I-2)$ summations/subtractions.
    Subsequently, the [ChannelNet](#id35.35.id35) estimator applies [SR-CNN](#id25.25.id25)
    followed by [DN-CNN](#id26.26.id26) in addition to the [RBF](#id27.27.id27) interpolation.
    $\text{CC}_{\text{SR-CNN}}$ and $\text{CC}_{\text{DN-CNN}}$ can be computed as
    follows
  id: totrans-1079
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\text{CC}_{\text{SR-CNN}}&amp;=\sum_{l=1}^{\mathcal{L}}h_{l}w_{l}d_{l}v_{l}^{2}f_{l}+h_{l}w_{l}d_{l}f_{l}\\
    &amp;=\sum_{l=1}^{\mathcal{L}}h_{l}w_{l}d_{l}f_{l}(v_{l}^{2}+1).\end{split}$ |  |
    (57) |'
  id: totrans-1080
  prefs: []
  type: TYPE_TB
- en: '|  | $\text{CC}_{\text{DN-CNN}}=\sum_{l=1}^{\mathcal{L}}h_{l}w_{l}d_{l}f_{l}(v_{l}^{2}+1)+\sum_{j=1}^{D}4h_{j}w_{j}d_{j}.$
    |  | (58) |'
  id: totrans-1081
  prefs: []
  type: TYPE_TB
- en: $\mathcal{L}$ signifies the number of employed [CNN](#id28.28.id28) layers.
    It can be noted that the second term in $\text{CC}_{\text{DN-CNN}}$ signifies
    the number of operations required by the batch normalization employed in the [DN-CNN](#id26.26.id26)
    network. Thus, the [SR-CNN](#id25.25.id25) employed in the [ChannelNet](#id35.35.id35)
    estimator needs $16064K_{\text{on}}I$ multiplications/divisions as well as $4288K_{\text{on}}I$
    summations/subtractions, while the [ChannelNet](#id35.35.id35)  [DN-CNN](#id26.26.id26)
    computations require $334080K_{\text{on}}I$ multiplications/divisions and $38144K_{\text{on}}I$
    summations/subtractions.
  id: totrans-1082
  prefs: []
  type: TYPE_NORMAL
- en: 'Table VII: Detailed computation complexity of the studied CNN-based FBF estimators.'
  id: totrans-1083
  prefs: []
  type: TYPE_NORMAL
- en: Scheme Interpolation CNN Mul./Div. Sum./Sub. Mul./Div. Sum./Sub. ChannelNet
    $K^{2}_{p}I^{2}(4+K_{d}I)$ + $K_{p}I(2+3K_{d}I)$ $K_{p}I(5K_{p}I$ + $5K_{d}I-2)$
    $350144K_{\text{on}}I$ $42432K_{\text{on}}I$ TS-ChannelNet $24K_{\text{on}}I+4LK_{\text{on}}I$
    $18K_{\text{on}}I$ + $5K_{\text{on}}IL$ $226880K_{\text{on}}I$ $81472K_{\text{on}}I$
    FP-SLS-SR-CNN $2K_{\text{on}}P+2K_{\text{on}}$ + $4K_{\text{on}}I_{d}$ $2K_{\text{on}}$
    + $2K_{\text{on}}I_{d}$ $7008K_{\text{on}}I_{d}$ $1120K_{\text{on}}I_{d}$ FP-ALS-SR-CNN
    $4K^{2}_{\text{on}}P+2K_{\text{on}}P$ + $2K_{\text{on}}+4K_{\text{on}}I_{d}$ $5K^{2}_{\text{on}}P$
    + $2K_{\text{on}}I_{d}$ LP-SR-CNN $2LP+4K_{\text{on}}LP$ + $2K_{\text{on}}+4K_{\text{on}}I_{d}$
    $5K_{\text{on}}LP$ + $2K_{\text{on}}I_{d}$ FP-SLS-DN-CNN $2K_{\text{on}}P+2K_{\text{on}}$
    + $4K_{\text{on}}I_{d}$ $2K_{\text{on}}$ + $2K_{\text{on}}I_{d}$ $84096K_{\text{on}}I_{d}$
    $9856K_{\text{on}}I_{d}$ FP-ALS-DN-CNN $4K^{2}_{\text{on}}P+2K_{\text{on}}P$ +
    $2K_{\text{on}}+4K_{\text{on}}I_{d}$ $5K^{2}_{\text{on}}P$ + $2K_{\text{on}}I_{d}$
    LP-DN-CNN $2LP+4K_{\text{on}}LP+2K_{\text{on}}$ + $4K_{\text{on}}I_{d}$ $5K_{\text{on}}LP$
    + $2K_{\text{on}}I_{d}$
  id: totrans-1084
  prefs: []
  type: TYPE_NORMAL
- en: VII-B2 [TS-ChannelNet](#id29.29.id29) estimator
  id: totrans-1085
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The [TS-ChannelNet](#id29.29.id29) estimator applies the [ADD-TT](#id36.36.id36)
    interpolation followed by the [SR-ConvLSTM](#id39.39.id39) network. Hence, the
    overall computational complexity of the [TS-ChannelNet](#id29.29.id29) estimator
    can be expressed in the following manner:'
  id: totrans-1086
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{CC}_{{\text{TS-ChannelNet}}}=\text{CC}_{{\text{ADD-TT}}}+\text{CC}_{\text{SR-ConvLSTM}}.$
    |  | (59) |'
  id: totrans-1087
  prefs: []
  type: TYPE_TB
- en: The [ADD-TT](#id36.36.id36) interpolation first applies the [DPA](#id16.16.id16)
    estimation requiring $18K_{\text{on}}$ multiplications/divisions and $8K_{\text{on}}$
    summations/subtractions. The time-domain truncation operation applied in ([43](#S5.E43
    "In V-B TS-ChannelNet ‣ V DL-Based FBF Channel Estimation Schemes ‣ A Survey on
    Deep Learning based Channel Estimation in Doubly Dispersive Environments")) requires
    $4LK_{\text{on}}$ multiplications as well as $5K_{\text{on}}L-2K_{\text{on}}$
    summations. In the [ADD-TT](#id36.36.id36) interpolation, the frequency-domain
    averaging ([44](#S5.E44 "In V-B TS-ChannelNet ‣ V DL-Based FBF Channel Estimation
    Schemes ‣ A Survey on Deep Learning based Channel Estimation in Doubly Dispersive
    Environments")) requires $10K_{\text{on}}$ summations and $2K_{\text{on}}$ multiplications.
    Furthermore, the time-domain averaging step ([45](#S5.E45 "In V-B TS-ChannelNet
    ‣ V DL-Based FBF Channel Estimation Schemes ‣ A Survey on Deep Learning based
    Channel Estimation in Doubly Dispersive Environments")) requires $4K_{\text{on}}$
    real valued divisions, and $2K_{\text{on}}$ real valued summations. Thus, the
    overall computational complexity of the [ADD-TT](#id36.36.id36) interpolation
    for the whole received [OFDM](#id208.208.id208) frame requires $24K_{\text{on}}I+4LK_{\text{on}}I$
    real-valued multiplications/divisions, and $18K_{\text{on}}I+5K_{\text{on}}IL$
    summations/subtractions. The total computational complexity is expressed with
    respect to the overall operations implemented in the input, forget, and output
    gates of the [SR-ConvLSTM](#id39.39.id39) network, such that
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{CC}_{\text{ConvLSTM}}=\sum_{l=1}^{\mathcal{L}}h_{l}w_{l}d_{l}f_{l}(8v_{l}^{2}+30).$
    |  | (60) |'
  id: totrans-1089
  prefs: []
  type: TYPE_TB
- en: Based on ([60](#S7.E60 "In VII-B2 estimator ‣ VII-B -Based FBF Estimators ‣
    VII Complexity Analysis ‣ A Survey on Deep Learning based Channel Estimation in
    Doubly Dispersive Environments")), the [SR-ConvLSTM](#id39.39.id39) network employed
    in the [TS-ChannelNet](#id29.29.id29) estimator requires $226880K_{\text{on}}I$
    multiplications/divisions as well as $81472K_{\text{on}}I$ summations/subtractions.
    [TS-ChannelNet](#id29.29.id29) estimator is less complicated than the [ChannelNet](#id35.35.id35)
    estimator, because it employs only one [CNN](#id28.28.id28) in addition to the
    [ADD-TT](#id36.36.id36) interpolation, unlike the [ChannelNet](#id35.35.id35)
    estimator where both [SR-CNN](#id25.25.id25) and [DN-CNN](#id26.26.id26) are employed.
  id: totrans-1090
  prefs: []
  type: TYPE_NORMAL
- en: VII-B3 [WI](#id37.37.id37)-CNN estimators
  id: totrans-1091
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The [WI](#id37.37.id37)-CNN estimators computational complexity primarily depends
    on the selected frame structure, the pilot allocation scheme, as well as the selected
    optimized [CNN](#id28.28.id28). Thus, the overall computational complexity of
    the [WI](#id37.37.id37)-CNN estimators can be expressed as follows
  id: totrans-1092
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{CC}_{{\text{WI}}}=\text{CC}_{\hat{\tilde{\bm{H}}}_{\text{WI}}}+\text{CC}_{\text{O-CNN}}.$
    |  | (61) |'
  id: totrans-1093
  prefs: []
  type: TYPE_TB
- en: When full pilot symbols are inserted, two options are taken into consideration.
    The first option is the [SLS](#id34.34.id34) estimator, which is performed using
    $2K_{\text{on}}P+2K_{\text{on}}$ divisions, and $2K_{\text{on}}$ summations. The
    second option entails employing the [ALS](#id33.33.id33) estimator with $2K_{\text{on}}P+2K_{\text{on}}$
    divisions. This is followed by $4K^{2}_{\text{on}}P$ multiplications, and $5K^{2}_{\text{on}}P$
    summations. In the instance where $K_{\text{p}}=L$ pilots are inserted with each
    pilot symbol, the [LS](#id172.172.id172) estimation requires $2LP+2K_{\text{on}}$
    divisions, $4K_{\text{on}}LP$ multiplications, and $5K_{\text{on}}LP$ summations.
    In a similar manner, for employing only $K_{p}=4$ pilot subcarriers, the WI-CP
    estimator needs $8P+2K_{\text{on}}$ divisions, $16K_{\text{on}}P$ multiplications,
    as well as $20K_{\text{on}}P$ summations. Following the selection of the required
    frame structure and pilot allocation scheme, the WI-CNN estimators apply the weighted
    interpolation as demonstrated in ([50](#S5.E50 "In 2nd item ‣ V-C WI-CNN ‣ V DL-Based
    FBF Channel Estimation Schemes ‣ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments")).The channel estimation for each received
    [OFDM](#id208.208.id208) frame needs $4K_{\text{on}}I_{d}$ divisions and $2K_{\text{on}}I_{d}$
    summations. Finally, the optimized [SR-CNN](#id25.25.id25) is utilized in low-mobility
    scenario and needs $7008K_{\text{on}}I_{d}$ multiplications/divisions and $1120K_{\text{on}}I_{d}$
    summations/subtractions. For high-mobility scenarios, the optimized [DN-CNN](#id26.26.id26)
    is employed, requiring $84096K_{\text{on}}I_{d}$ multiplications/divisions and
    $9856K_{\text{on}}I_{d}$ summations/subtractions. The [WI](#id37.37.id37)-FP-ALS
    records the higher computational complexity among the other WI estimators in all
    mobility scenarios, due to $\bm{W}_{\text{ALS}}$ calculation in ([47](#S5.E47
    "In 1st item ‣ V-C WI-CNN ‣ V DL-Based FBF Channel Estimation Schemes ‣ A Survey
    on Deep Learning based Channel Estimation in Doubly Dispersive Environments")),
    whereas, the [WI](#id37.37.id37)-FP-SLS estimator refers to the simplest one.
  id: totrans-1094
  prefs: []
  type: TYPE_NORMAL
- en: Table [VII](#S7.T7 "Table VII ‣ VII-B1 estimator ‣ VII-B -Based FBF Estimators
    ‣ VII Complexity Analysis ‣ A Survey on Deep Learning based Channel Estimation
    in Doubly Dispersive Environments") shows the studied estimators’ overall computational
    complexity with respect to real valued operations. It is noteworthy that the [WI](#id37.37.id37)
    estimators achieve significant computational complexity decrease in comparison
    to [ChannelNet](#id35.35.id35) and [TS-ChannelNet](#id29.29.id29) estimators.
    Figure[17](#S7.F17 "Figure 17 ‣ VII-A2 LSTM-Based Estimators ‣ VII-A DL-Based
    SBS Estimators ‣ VII Complexity Analysis ‣ A Survey on Deep Learning based Channel
    Estimation in Doubly Dispersive Environments") depicts the computational complexity
    of the studied DL-based FBF estimators. The [ChannelNet](#id35.35.id35) and [TS-ChannelNet](#id29.29.id29)
    estimators are $70$ and $39$ times more complex than the FP-ALS-SR-CNN, respectively.
    In addition, the WI-CNN estimators achieve a minimum of $7027.35$ times less complexity
    than the 2D LMMSE estimator, with an acceptable [BER](#id64.64.id64) performance,
    which makes them a feasible alternative to the 2D LMMSE. It is also observed that
    FP-ALS-DN-CNN is $12$ times more complex than FP-ALS-SR-CNN since the optimized
    [DN-CNN](#id26.26.id26) architecture complexity employed in high and very high
    scenarios is higher than the optimized [SR-CNN](#id25.25.id25) architecture, which,
    in turn, is employed in low mobility scenarios.
  id: totrans-1095
  prefs: []
  type: TYPE_NORMAL
- en: VIII Conclusion
  id: totrans-1096
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This survey sheds light on the recently proposed DL-based SBS and FBF channel
    estimators in doubly-dispersive environments. First, we have defined the problem
    of signal propagation in doubly-dispersive channels. Subsequently, a review of
    different DL architectures employed in the doubly-dispersive channel estimation
    has been undertaken, followed by a detailed presentation of the studied DL-based
    estimators. Finally, the studied estimators have been evaluated with respect to
    [NMSE](#id204.204.id204), [BER](#id64.64.id64), and computational complexity,
    clearly demonstrating a significant improvement of employing DL in the channel
    estimation across different mobility conditions. We have shown that, while the
    LSTM and CNN based estimators do outperform the FNN based estimator, more computational
    complexity is necessary where the LSTM-based SBS estimator is $23.6$ times more
    complex than the FNN-based SBS estimators. Nevertheless, the complexity of the
    CNN-based FBF estimator exceeds the complexity of LSTM-based SBS estimator by
    approximately $3450$ times because of the significant difference in terms of required
    operations between the CNN and LSTM networks. Finally, we have observed that the
    choice of the channel estimator is primarily related to the applications requirements
    as well as affordable computational complexity. SBS estimators are more useful
    when the application is sensitive to latency, whereas FBF estimators can be employed
    if some latency can be accepted. To summarize, a trade-off between the required
    performance, computational complexity, and the accepted latency must first be
    defined to select what is the most suitable channel estimator to be employed.
  id: totrans-1097
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-1098
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] H. Chang, C.-X. Wang, Y. Liu, J. Huang, J. Sun, W. Zhang, and X. Gao, “A
    Novel Nonstationary 6G UAV-to-Ground Wireless Channel Model With 3-D Arbitrary
    Trajectory Changes,” *IEEE Internet of Things Journal*, vol. 8, no. 12, pp. 9865–9877,
    2021.'
  id: totrans-1099
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] L. Wang, B. Ai, K. Guan, D. He, Z. Zhong, L. Tian, and J. Dou, “Stochastic
    Channel Modeling for High-Speed Railway Viaduct Scenario at 93.2 GHz,” in *12th
    European Conference on Antennas and Propagation (EuCAP 2018)*, 2018, pp. 1–4.'
  id: totrans-1100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] B. Turan and S. Coleri, “Machine Learning Based Channel Modeling for Vehicular
    Visible Light Communication,” *IEEE Transactions on Vehicular Technology*, vol. 70,
    no. 10, pp. 9659–9672, 2021.'
  id: totrans-1101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] R. Chen, W. Yang, F. Wu, and M. Sun, “Fast Handover for High-Speed Railway
    via NDN,” in *2018 1st IEEE International Conference on Hot Information-Centric
    Networking (HotICN)*, 2018, pp. 167–172.'
  id: totrans-1102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] S. Wang and Q. Zhang, “A Joint Time-Frequency Domain Frequency Offset Estimation
    Algorithm for Busrt Communication,” in *2020 IEEE 3rd International Conference
    on Electronics Technology (ICET)*, 2020, pp. 1–5.'
  id: totrans-1103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] T. Ma, X. Jiang, Y. Wang, and F. Li, “A Novel Inter-Carrier Interference
    Cancellation Scheme in Highly Mobile Environments,” *China Communications*, vol. 17,
    no. 12, pp. 194–205, 2020.'
  id: totrans-1104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] K. Saito, Q. Fan, N. Keerativoranan, and J.-i. Takada, “4.9 GHz Band Outdoor
    to Indoor Propagation Loss Analysis in High Building Environment Using Unmanned
    Aerial Vehicle,” in *2019 13th European Conference on Antennas and Propagation
    (EuCAP)*, 2019, pp. 1–4.'
  id: totrans-1105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] R. Bomfin, M. Chafii, A. Nimr, and G. Fettweis, “A Robust Baseband Transceiver
    Design for Doubly-Dispersive Channels,” *IEEE Transactions on Wireless Communications*,
    2021.'
  id: totrans-1106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] ——, “A Robust Baseband Transceiver Design for Doubly-Dispersive Channels,”
    *IEEE Transactions on Wireless Communications*, vol. 20, no. 8, pp. 4781–4796,
    2021.'
  id: totrans-1107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] R. Bomfin, A. Nimr, M. Chafii, and G. Fettweis, “A Robust and Low-Complexity
    Walsh-Hadamard Modulation for Doubly-Dispersive Channels,” *IEEE Communications
    Letters*, vol. 25, no. 3, pp. 897–901, 2021.'
  id: totrans-1108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] A. Nimr, M. Chafii, M. Matthe, and G. Fettweis, “Extended GFDM Framework:
    OTFS and GFDM Comparison,” in *2018 IEEE Global Communications Conference (GLOBECOM)*,
    2018, pp. 1–6.'
  id: totrans-1109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] M. Chafii, J. Palicot, R. Gribonval, and F. Bader, “Adaptive Wavelet Packet
    Modulation,” *IEEE Transactions on Communications*, vol. 66, no. 7, pp. 2947–2957,
    2018.'
  id: totrans-1110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] J. A. Fernandez, K. Borries, L. Cheng, B. V. K. Vijaya Kumar, D. D. Stancil,
    and F. Bai, “Performance of the 802.11p Physical Layer in Vehicle-to-Vehicle Environments,”
    *IEEE Transactions on Vehicular Technology*, vol. 61, no. 1, pp. 3–14, 2012.'
  id: totrans-1111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Z. Zhao, X. Cheng, M. Wen, B. Jiao, and C. Wang, “Channel Estimation Schemes
    for IEEE 802.11p Standard,” *IEEE Intelligent Transportation Systems Magazine*,
    vol. 5, no. 4, pp. 38–49, 2013.'
  id: totrans-1112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] Yoon-Kyeong Kim, Jang-Mi Oh, Yoo-Ho Shin, and Cheol Mun, “Time and Frequency
    Domain Channel Estimation Scheme for IEEE 802.11p,” in *17th International IEEE
    Conference on Intelligent Transportation Systems (ITSC)*, 2014, pp. 1085–1090.'
  id: totrans-1113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] S. Ehsanfar, M. Chafii, and G. P. Fettweis, “On UW-based Transmission
    for MIMO Multi-carriers with Spatial Multiplexing,” *IEEE Transactions on Wireless
    Communications*, vol. 19, no. 9, pp. 5875–5890, 2020.'
  id: totrans-1114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Y. Choi, J. H. Bae, and J. Lee, “Low-Complexity 2D LMMSE Channel Estimation
    for OFDM Systems,” in *2015 IEEE 82nd Vehicular Technology Conference (VTC2015-Fall)*,
    2015, pp. 1–5.'
  id: totrans-1115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] T. Wang, C.-K. Wen, H. Wang, F. Gao, T. Jiang, and S. Jin, “Deep Learning
    for Wireless Physical Layer: Opportunities and Challenges,” 2017.'
  id: totrans-1116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] T. O’Shea and J. Hoydis, “An Introduction to Deep Learning for the Physical
    Layer,” *IEEE Transactions on Cognitive Communications and Networking*, vol. 3,
    no. 4, pp. 563–575, 2017.'
  id: totrans-1117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] M. Chafii, F. Bader, and J. Palicot, “Enhancing Coverage in Narrow Band-IoT
    Using Machine Learning,” in *2018 IEEE Wireless Communications and Networking
    Conference (WCNC)*.   IEEE, 2018, pp. 1–6.'
  id: totrans-1118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Y. Yang, F. Gao, X. Ma, and S. Zhang, “Deep Learning-Based Channel Estimation
    for Doubly Selective Fading Channels,” *IEEE Access*, vol. 7, pp. 36 579–36 589,
    2019.'
  id: totrans-1119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] X. Ma, H. Ye, and Y. Li, “Learning Assisted Estimation for Time- Varying
    Channels,” in *2018 15th International Symposium on Wireless Communication Systems
    (ISWCS)*, 2018, pp. 1–5.'
  id: totrans-1120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] H. Ye, G. Y. Li, and B. Juang, “Power of Deep Learning for Channel Estimation
    and Signal Detection in OFDM Systems,” *IEEE Wireless Communications Letters*,
    vol. 7, no. 1, pp. 114–117, 2018.'
  id: totrans-1121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] J. Yuan, H. Q. Ngo, and M. Matthaiou, “Machine Learning-Based Channel
    Prediction in Massive MIMO With Channel Aging,” *IEEE Transactions on Wireless
    Communications*, vol. 19, no. 5, pp. 2960–2973, 2020.'
  id: totrans-1122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] H. Kim, S. Kim, H. Lee, C. Jang, Y. Choi, and J. Choi, “Massive MIMO Channel
    Prediction: Kalman Filtering Vs. Machine Learning,” *IEEE Transactions on Communications*,
    vol. 69, no. 1, pp. 518–528, 2021.'
  id: totrans-1123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] C. Wu, X. Yi, Y. Zhu, W. Wang, L. You, and X. Gao, “Channel Prediction
    in High-Mobility Massive MIMO: From Spatio-Temporal Autoregression to Deep Learning,”
    *IEEE Journal on Selected Areas in Communications*, vol. 39, no. 7, pp. 1915–1930,
    2021.'
  id: totrans-1124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] S. Han, Y. Oh, and C. Song, “A Deep Learning Based Channel Estimation
    Scheme for IEEE 802.11p Systems,” in *ICC 2019 - 2019 IEEE International Conference
    on Communications (ICC)*, 2019, pp. 1–6.'
  id: totrans-1125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] A. K. Gizzini, M. Chafii, A. Nimr, and G. Fettweis, “Deep Learning Based
    Channel Estimation Schemes for IEEE 802.11p Standard,” *IEEE Access*, vol. 8,
    pp. 113 751–113 765, 2020.'
  id: totrans-1126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] ——, “Joint TRFI and Deep Learning for Vehicular Channel Estimation,” in
    *2020 IEEE Globecom Workshops (GC Wkshps*, 2020, pp. 1–6.'
  id: totrans-1127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] M. Soltani, V. Pourahmadi, A. Mirzaei, and H. Sheikhzadeh, “Deep Learning-Based
    Channel Estimation,” *IEEE Communications Letters*, vol. 23, no. 4, pp. 652–655,
    2019.'
  id: totrans-1128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] X. Zhu, Z. Sheng, Y. Fang, and D. Guo, “A Deep Learning-Aided Temporal
    Spectral ChannelNet for IEEE 802.11p-Based Channel Estimation in Vehicular Communications,”
    *EURASIP Journal on Wireless Communications and Networking*, vol. 1, no. 94, 2020.'
  id: totrans-1129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] A. Karim Gizzini, M. Chafii, A. Nimr, R. M. Shubair, and G. Fettweis,
    “CNN Aided Weighted Interpolation for Channel Estimation in Vehicular Communications,”
    *IEEE Transactions on Vehicular Technology*, vol. 70, no. 12, pp. 12 796–12 811,
    2021.'
  id: totrans-1130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] H. A. Le, T. Van Chien, T. H. Nguyen, H. Choo, and V. D. Nguyen, “Machine
    Learning-Based 5G-and-Beyond Channel Estimation for MIMO-OFDM Communication Systems,”
    *Sensors*, vol. 21, no. 14, 2021\. [Online]. Available: https://www.mdpi.com/1424-8220/21/14/4861'
  id: totrans-1131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] F. Tang, B. Mao, N. Kato, and G. Gui, “Comprehensive survey on machine
    learning in vehicular network: Technology, applications and challenges,” *IEEE
    Communications Surveys Tutorials*, vol. 23, no. 3, pp. 2027–2057, 2021.'
  id: totrans-1132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] A. K. Gizzini, “Dl-based channel estimation in doubly dispersive environments,”
    in *DL-based Channel Estimation in Doubly Dispersive Environments*, 2022\. [Online].
    Available: https://github.com/abdulkarimgizzini/DL-based-Channel-Estimation-in-Doubly-Dispersive-Environments-/'
  id: totrans-1133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] G. Matz and F. Hlawatsch, “Chapter 1 - fundamentals of time-varying communication
    channels,” in *Wireless Communications Over Rapidly Time-Varying Channels*, F. Hlawatsch
    and G. Matz, Eds.   Oxford: Academic Press, 2011, pp. 1–63\. [Online]. Available:
    https://www.sciencedirect.com/science/article/pii/B9780123744838000017'
  id: totrans-1134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] ——, “Chapter 1 - Fundamentals of Time-Varying Communication Channels,”
    in *Wireless Communications Over Rapidly Time-Varying Channels*, 2011, pp. 1–63.'
  id: totrans-1135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] N. D. Ricklin, “Time Varying Channels : Characterization, Estimation,
    and Detection,” Ph.D. dissertation, University of California, San Diego, 2010.'
  id: totrans-1136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] J. Schmidhuber, “Deep Learning in Neural Networks: An Overview,” *Neural
    Networks*, vol. 61, p. 85–117, Jan 2015\. [Online]. Available: http://dx.doi.org/10.1016/j.neunet.2014.09.003'
  id: totrans-1137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] S. ichi Amari, “Backpropagation and Stochastic Gradient Descent Method,”
    *Neurocomputing*, vol. 5, no. 4, pp. 185 – 196, 1993.'
  id: totrans-1138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] S. De, A. Mukherjee, and E. Ullah, “Convergence Guarantees for RMSProp
    and ADAM in Non-Convex Optimization and An Empirical Comparison to Nesterov Acceleration,”
    2018.'
  id: totrans-1139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] S. Ruder, “An Overview of Multi-Task Learning in Deep Neural Networks,”
    2017.'
  id: totrans-1140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] A. K. Gizzini, M. Chafii, S. Ehsanfar, and R. M. Shubair, “Temporal Averaging
    LSTM-based Channel Estimation Scheme for IEEE 802.11p Standard,” in *IEEE Global
    Communications Conference*, Madrid, Spain, Dec. 2021. [Online]. Available: https://hal.archives-ouvertes.fr/hal-03365697'
  id: totrans-1141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] K. Greff, R. K. Srivastava, J. Koutník, B. R. Steunebrink, and J. Schmidhuber,
    “LSTM: A Search Space Odyssey,” *IEEE Transactions on Neural Networks and Learning
    Systems*, vol. 28, no. 10, pp. 2222–2232, 2017.'
  id: totrans-1142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] S. Albawi, T. A. Mohammed, and S. Al-Zawi, “Understanding of a Convolutional
    Neural Network,” in *2017 International Conference on Engineering and Technology
    (ICET)*, 2017, pp. 1–6.'
  id: totrans-1143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] A. K. Gizzini, “Advanced Linear and Deep Learning Based Channel Estimation
    Techniques in Doubly Dispersive Environments,” Theses, Cergy Paris CY Université,
    Dec. 2021\. [Online]. Available: https://hal.archives-ouvertes.fr/tel-03482053'
  id: totrans-1144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] M. Sun, Z. Song, X. Jiang, J. Pan, and Y. Pang, “Learning Pooling for
    Convolutional Neural Network,” *Neurocomputing*, vol. 224, pp. 96–104, 2017.'
  id: totrans-1145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] H. Qi, “Derivation of Backpropagation in Convolutional Neural Network
    (CNN),” in *Derivation of Backpropagation in Convolutional Neural Network ( CNN
    )*, 2016.'
  id: totrans-1146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] C. Dong, C. C. Loy, K. He, and X. Tang, “Image Super-Resolution Using
    Deep Convolutional Networks,” *IEEE Transactions on Pattern Analysis and Machine
    Intelligence*, vol. 38, no. 2, pp. 295–307, 2016.'
  id: totrans-1147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang, “Beyond a Gaussian Denoiser:
    Residual Learning of Deep CNN for Image Denoising,” *IEEE Transactions on Image
    Processing*, vol. 26, no. 7, pp. 3142–3155, 2017.'
  id: totrans-1148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] X. Shi, Z. Chen, H. Wang, D.-Y. Yeung, W. kin Wong, and W. chun Woo, “Convolutional
    LSTM Network: A Machine Learning Approach for Precipitation Nowcasting,” 2015.'
  id: totrans-1149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for Image
    Recognition,” in *Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition (CVPR)*, June 2016.'
  id: totrans-1150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] J. Pan, H. Shan, R. Li, Y. Wu, W. Wua, and T. Q. S. Quek, “Channel Estimation
    Based on Deep Learning in Vehicle-to-everything Environments,” *IEEE Communications
    Letters*, pp. 1–1, 2021.'
  id: totrans-1151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] A. K. Gizzini, M. Chafii, A. Nimr, and G. Fettweis, “Enhancing Least Square
    Channel Estimation Using Deep Learning,” in *2020 IEEE 91st Vehicular Technology
    Conference (VTC2020-Spring)*, 2020, pp. 1–5.'
  id: totrans-1152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] F. Pontes, G. Amorim, P. Balestrassi, A. Paiva, and J. Ferreira, “Design
    of Experiments and Focused Grid Search for Neural Network Parameter Optimization,”
    *Neurocomputing*, vol. 186, pp. 22 – 34, 2016.'
  id: totrans-1153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] C. Chatfield, *Time-Series Forecasting*.   Chapman and Hall/CRC, 2000.'
  id: totrans-1154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] Y. R. Zheng and C. Xiao, “Channel Estimation for Frequency-Domain Equalization
    of Single-Carrier Broadband Wireless Communications,” *IEEE Transactions on Vehicular
    Technology*, vol. 58, no. 2, pp. 815–823, 2009.'
  id: totrans-1155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] G. Acosta-Marum and M. A. Ingram, “Six Time and Frequency Selective Empirical
    Channel Models for Vehicular Wireless LANs,” *IEEE Vehicular Technology Magazine*,
    vol. 2, no. 4, pp. 4–11, 2007.'
  id: totrans-1156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] G. Acosta-Marum, “Measurement, Modeling, and OFDM Synchronization for
    the Wideband Mobile-to-Mobile Channel,” *Ph.D. dissertation, Georgia Inst. Technol.,
    Atlanta, GA*, 2007.'
  id: totrans-1157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
