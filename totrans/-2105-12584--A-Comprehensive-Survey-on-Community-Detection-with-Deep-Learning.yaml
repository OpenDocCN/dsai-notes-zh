- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:55:06'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2105.12584] A Comprehensive Survey on Community Detection with Deep Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2105.12584](https://ar5iv.labs.arxiv.org/html/2105.12584)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Comprehensive Survey on Community Detection with Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Xing Su, Shan Xue, Fanzhen Liu, Jia Wu,  Jian Yang, Chuan Zhou, Wenbin Hu,
  prefs: []
  type: TYPE_NORMAL
- en: 'Cecile Paris, Surya Nepal, Di Jin, Quan Z. Sheng, and Philip S. Yu X. Su, S.
    Xue, F. Liu, J. Wu, J. Yang, Q. Z. Sheng are with School of Computing, Macquarie
    University, Sydney, Australia. E-mail: {xing.su2, fanzhen.liu}@students.mq.edu.au,
    {emma.xue, jia.wu, jian.yang, michael.sheng}@mq.edu.au C. Zhou is with Academy
    of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, China.
    E-mail: zhouchuan@amss.ac.cn. W. Hu is with School of Computer Science, Wuhan
    University, Wuhan, China. E-mail: hwb@whu.edu.cn. S. Xue, C. Paris, S. Nepal are
    with CSIRO Data61, Sydney, Australia. E-mail: {emma.xue, surya.nepal, cecile.paris}@data61.csiro.au
    D. Jin is with School of Computer Science and Technology, Tianjin University,
    China. E-mail: jindi@tju.edu.cn.P.S. Yu is with Department of Computer Science,
    University of Illinois at Chicago, Chicago, USA. Email: psyu@uic.edu.'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A community reveals the features and connections of its members that are different
    from those in other communities in a network. Detecting communities is of great
    significance in network analysis. Despite the classical spectral clustering and
    statistical inference methods, we notice a significant development of deep learning
    techniques for community detection in recent years with their advantages in handling
    high dimensional network data. Hence, a comprehensive overview of community detection’s
    latest progress through deep learning is timely to academics and practitioners.
    This survey devises and proposes a new taxonomy covering different state-of-the-art
    methods, including deep learning-based models upon deep neural networks, deep
    nonnegative matrix factorization and deep sparse filtering. The main category,
    i.e., deep neural networks, is further divided into convolutional networks, graph
    attention networks, generative adversarial networks and autoencoders. The survey
    also summarizes the popular benchmark data sets, evaluation metrics, and open-source
    implementations to address experimentation settings. We then discuss the practical
    applications of community detection in various domains and point to implementation
    scenarios. Finally, we outline future directions by suggesting challenging topics
    in this fast-growing deep learning field.
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Community Detection, Deep Learning, Social Networks, Network Representation,
    Graph Neural Network
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Communities have been investigated as early as the 1920s in sociology and social
    anthropology [[1](#bib.bib1)]. However, it is only after the 21st century that
    advanced scientific tools were primarily developed upon real-world data [[2](#bib.bib2)].
    Since 2002 [[3](#bib.bib3)], Girvan and Newman opened a new direction with graph
    partition. In the past ten years, researchers from computer science have extensively
    studied community detection [[4](#bib.bib4)] by utilizing network topological
    structures [[5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8)] and
    semantic information [[9](#bib.bib9), [10](#bib.bib10)] for both static and dynamic
    networks [[11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13)] and small and
    large networks [[14](#bib.bib14), [15](#bib.bib15)]. Graph-based approaches are
    developed increasingly to detect communities in environments with complex data
    structures [[16](#bib.bib16), [17](#bib.bib17)]. Network dynamics and community
    impacts can be analyzed in details within community detection, such as rumor spread,
    virus outbreak, and tumour evolution.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/db223154e3dc6b97aa04ae53c2124278.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) graph
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/38b05d93f88bd788df0e46ff2086312e.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) communities
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1: (a) An illustration of a graph where nodes denote users in a social
    network. (b) An illustration of two communities ($C_{1}$ and $C_{2}$) based on
    the prediction of users’ occupations. The detection utilizes users’ closeness
    in online activities (topology) and account profiles (attributes).'
  prefs: []
  type: TYPE_NORMAL
- en: Community detection is a research area with increasing practical significance.
    As the saying goes, Birds of a feather flock together [[18](#bib.bib18)]. Based
    on the theory of Six Degrees of Separation, any person in the world can know anyone
    else through six acquaintances [[19](#bib.bib19)]. Indeed, our world is a vast
    network formed by a series of communities. For example, in social networks (Fig.
    [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ A Comprehensive Survey on Community Detection
    with Deep Learning")), platform sponsors promote products to targeted users in
    detected communities [[20](#bib.bib20), [21](#bib.bib21)]. Community detection
    in citation networks [[22](#bib.bib22)] determines the importance, interconnectedness,
    evolution of research topics and identifies research trends. In metabolic networks
    [[23](#bib.bib23), [24](#bib.bib24)] and Protein-Protein Interaction (PPI) networks
    [[25](#bib.bib25)], community detection reveals the complexities of metabolisms
    and proteins with similar biological functions. Similarly, community detection
    in brain networks [[26](#bib.bib26), [17](#bib.bib17)] reflects the functional
    and anatomical segregation of brain regions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many traditional techniques, such as spectral clustering [[27](#bib.bib27),
    [28](#bib.bib28)] and statistical inference [[29](#bib.bib29), [30](#bib.bib30),
    [31](#bib.bib31)], are applied to small networks and simple cases. However, real-world
    networks in rich nonlinear information make traditional models less applicable
    to practical applications, including complex topology and high dimensional features.
    Their computational costs are expensive. The powerful techniques of deep learning
    offer flexible solutions with good community detection performance to: (1) learn
    nonlinear network properties, such as relations denoting edges between nodes,
    (2) represent lower-dimensional network embeddings preserving the complicated
    network structure, and (3) achieve better community detection from various information.
    Therefore, deep learning for community detection is a new trend that demands a
    timely comprehensive survey¹¹1This paper is an extended vision of our published
    survey [[4](#bib.bib4)] in IJCAI-20, which is the first published work on the
    review of community detection approaches with deep learning..'
  prefs: []
  type: TYPE_NORMAL
- en: To the best of our knowledge, this paper is the first comprehensive survey focusing
    on deep learning contributions in community detection. In discovering inherent
    patterns and functions [[32](#bib.bib32), [33](#bib.bib33)], existing surveys
    mainly focused on community detection on specific techniques [[34](#bib.bib34),
    [35](#bib.bib35), [36](#bib.bib36), [13](#bib.bib13), [12](#bib.bib12), [37](#bib.bib37)],
    different network types [[11](#bib.bib11), [38](#bib.bib38), [5](#bib.bib5)],
    community types [[6](#bib.bib6), [7](#bib.bib7)], and application scenarios [[39](#bib.bib39),
    [9](#bib.bib9)]. The surveys on specific techniques are summarized but not limited
    to partial detection based on probabilistic graphical models [[34](#bib.bib34),
    [37](#bib.bib37)], Label Propagation Algorithm (LPAs) [[35](#bib.bib35), [36](#bib.bib36)],
    and evolutionary computation for single- and multi-objective optimizations [[13](#bib.bib13),
    [12](#bib.bib12)]. In terms of different network types, researchers provide overviews
    on dynamic networks [[11](#bib.bib11)], directed networks [[38](#bib.bib38)] and
    multi-layer networks [[5](#bib.bib5)]. Moreover, detection techniques are reviewed
    over disjoint and overlapping [[6](#bib.bib6), [7](#bib.bib7)] community types.
    Regarding application scenarios, the focus has been on techniques on social networks
    [[39](#bib.bib39), [9](#bib.bib9)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Observing the past, current and future trends, this paper aims to support researchers
    and practitioners to understand the community detection field with respect to:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Systematic Taxonomy and Comprehensive Review. We propose a new systematic taxonomy
    for this survey (see Fig. [2](#S2.F2 "Figure 2 ‣ II Definitions and Preliminaries
    ‣ A Comprehensive Survey on Community Detection with Deep Learning")). For each
    category, we review, summarize and compare the representative works. We also briefly
    introduce community detection applications in the real world. These scenarios
    provide horizons for future community detection research and practices.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abundant Resources and High-impact References. The survey collects open resources,
    including benchmark data sets, evaluation metrics and technique implementations.
    Publications in the latest high-impact international conferences and high-quality
    peer-reviewed journals cover data mining, artificial intelligence, machine learning
    and knowledge discovery.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Future Directions. As deep learning is a new research area, we discuss current
    limitations, critical challenges and open opportunities for future directions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The rest of the article is organized as follows: Section [II](#S2 "II Definitions
    and Preliminaries ‣ A Comprehensive Survey on Community Detection with Deep Learning")
    defines essential notations, concepts, input and output of deep learning approaches.
    Section [III](#S3 "III A Development of Community Detection ‣ A Comprehensive
    Survey on Community Detection with Deep Learning") overviews community detection
    development. Section [IV](#S4 "IV A Taxonomy of Community Detection with Deep
    Learning ‣ A Comprehensive Survey on Community Detection with Deep Learning")
    introduces a deep learning taxonomy. Sections [V](#S5 "V Convolutional Network-based
    Community Detection ‣ A Comprehensive Survey on Community Detection with Deep
    Learning")–[X](#S10 "X Deep Sparse Filtering-based Community Detection ‣ A Comprehensive
    Survey on Community Detection with Deep Learning") summarize comprehensive reviews
    on each category in the taxonomy. Section [XI](#S11 "XI Published Resources ‣
    A Comprehensive Survey on Community Detection with Deep Learning") and Section
    [XII](#S12 "XII Practical Applications ‣ A Comprehensive Survey on Community Detection
    with Deep Learning") organize the popular implementation resources and real-world
    applications. Lastly, Section [XIII](#S13 "XIII Future Directions ‣ A Comprehensive
    Survey on Community Detection with Deep Learning") discusses current challenges,
    suggests future research directions before the conclusion in Section [XIV](#S14
    "XIV Conclusions ‣ A Comprehensive Survey on Community Detection with Deep Learning").
    The supporting materials can be found in APPENDIX [A](#A1 "Appendix A Summarized
    Techniques of Deep Learning-based Community Detection Methods ‣ A Comprehensive
    Survey on Community Detection with Deep Learning") (core techniques of reviewed
    literature summarized in tables), APPENDIX [B](#A2 "Appendix B Detailed description:
    Data Sets ‣ A Comprehensive Survey on Community Detection with Deep Learning")–[D](#A4
    "Appendix D Detailed description: Open-source Implementations ‣ A Comprehensive
    Survey on Community Detection with Deep Learning") (resource descriptions of data
    sets, evaluation metrics and implementation projects) and APPENDIX [E](#A5 "Appendix
    E Abbreviations ‣ A Comprehensive Survey on Community Detection with Deep Learning")
    (abbreviations).'
  prefs: []
  type: TYPE_NORMAL
- en: II Definitions and Preliminaries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, preliminaries include primary definitions, notations in TABLE
    [I](#S2.T1 "TABLE I ‣ II Definitions and Preliminaries ‣ A Comprehensive Survey
    on Community Detection with Deep Learning"), and general inputs and outputs of
    deep learning-based community detection models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Definition 1: Network. Given a basic network $\mathcal{G}=(V,E)$, where $V=\{v_{1},\cdots,v_{n}\}$
    is the node set with $E=\{e_{ij}\}_{i,j=1}^{n}$ representing the edge set among
    nodes. $N(v_{i})=\{u\in V|(v_{i},u)\in E\}$ defines the neighborhood of a node
    $v_{i}$. $\bm{A}=[a_{ij}]$ denotes an $n\times n$ dimensional adjacency matrix,
    where $a_{ij}=1$ if $e_{ij}\in E$, otherwise $a_{ij}=0$. If $a_{ij}\neq a_{ji}$,
    $\mathcal{G}$ is a directed network, or else it is an undirected network. If $a_{ij}$
    is weighted by $w_{ij}\in\bm{W}$, $\mathcal{G}=(V,E,\bm{W})$ is a weighted network,
    otherwise it is an unweighted network. If $a_{ij}$’s value differs in $+1$ (positive)
    and $-1$ (negative), $\mathcal{G}$ is a signed network. If node $v_{i}\in V$ is
    attributed by $\bm{x}_{i}\in\bm{X}\subseteq\mathbb{R}^{n\times d}$, $\mathcal{G}=(V,E,\bm{X})$
    is an attributed network, otherwise it is an unattributed network.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE I: Notations and descriptions used in this paper.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Notations | Descriptions |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbb{R}$ | A data space |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{G}$ | A graph |'
  prefs: []
  type: TYPE_TB
- en: '| $V$, $E$, $\mathcal{C}$ | A set of nodes, edges, communities |'
  prefs: []
  type: TYPE_TB
- en: '| $v_{i}$, $e_{ij}$, $C_{k}$ | The $i$-th node, edge of ($v_{i},v_{j}$), $k$-th
    community |'
  prefs: []
  type: TYPE_TB
- en: '| $N(v_{i})$ | A neighborhood of $v_{i}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\bm{A}$, $a_{ij}$ | An adjacency matrix, value |'
  prefs: []
  type: TYPE_TB
- en: '| $\bm{X}$, $\bm{x}_{i}$ | A node attribute matrix, vector |'
  prefs: []
  type: TYPE_TB
- en: '| $y_{i}$, $c_{k}$ | The node label of $v_{i}$, community label of $C_{k}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| $y^{k}_{i}$ | The binary community label of $v_{i}$ in $C_{k}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n$, $m$, $K$, $d$ | The number of nodes, edges, communities, attributes
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{A}_{ij}$ | The anchor links between graphs $(\mathcal{G}_{i},\mathcal{G}_{j})$
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{V}$, $\mathcal{E}$, $\mathcal{X}$ | A set of heterogeneous nodes,
    edges, attributes |'
  prefs: []
  type: TYPE_TB
- en: '| $E^{(r)}$ | $r$-th type edges in multiplex network |'
  prefs: []
  type: TYPE_TB
- en: '| $\bm{A}(+,-)$ | The adjacency matrix of a signed network |'
  prefs: []
  type: TYPE_TB
- en: '| $\hat{\bm{A}}$ | A reconstructed adjacency matrix |'
  prefs: []
  type: TYPE_TB
- en: '| $\widetilde{\bm{X}}$ | The corrupted node attribute matrix |'
  prefs: []
  type: TYPE_TB
- en: '| $\bm{D}$ | A degree matrix |'
  prefs: []
  type: TYPE_TB
- en: '| $\bm{B}$, $b_{ij}$ | A modularity matrix, value |'
  prefs: []
  type: TYPE_TB
- en: '| $\bm{S}$, $s_{ij}$ | A similarity matrix, value |'
  prefs: []
  type: TYPE_TB
- en: '| $\bm{O}$, $o_{ij}$ | Node pairwise constraint matrix, value |'
  prefs: []
  type: TYPE_TB
- en: '| $\bm{P}$, $p_{ij}$ | Community membership matrix, probability of ($v_{i},C_{j}$)
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\bm{L}$, $\bm{M}$ | A Laplacian, Markov matrix |'
  prefs: []
  type: TYPE_TB
- en: '| $\bm{Z}$, $\bm{z}$ | A latent variable matrix, vector |'
  prefs: []
  type: TYPE_TB
- en: '| $\Theta$ | Trainable parameters |'
  prefs: []
  type: TYPE_TB
- en: '| $\bm{W}^{(l)}$ | The weight matrix of the $l$-th layer in DNN |'
  prefs: []
  type: TYPE_TB
- en: '| $\bm{H}^{(l)}$, $\bm{h}_{i}^{(l)}$ | The $l$-th layer representation matrix,
    vector |'
  prefs: []
  type: TYPE_TB
- en: '| $\sigma(\cdot)$ | An activation function |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{L}$ | A loss function |'
  prefs: []
  type: TYPE_TB
- en: '| $\Omega$ | A sparsity penalty |'
  prefs: []
  type: TYPE_TB
- en: '| $&#124;\cdot&#124;$ | The length of a set |'
  prefs: []
  type: TYPE_TB
- en: '| $\&#124;\cdot\&#124;$ | The norm operator |'
  prefs: []
  type: TYPE_TB
- en: '| $\phi_{g}$, $\phi_{d}$ | A generator, discriminator |'
  prefs: []
  type: TYPE_TB
- en: '| $\phi_{e}$, $\phi_{r}$ | An encoder, decoder |'
  prefs: []
  type: TYPE_TB
- en: 'Definition 2: Community. Given a set of communities $\mathcal{C}=\{C_{1},C_{2},\cdots,C_{K}\}$,
    each community $C_{k}$ is a partition of $\mathcal{G}$ which keeps regional structure
    and cluster properties. A node $v_{i}$ clustered into community $C_{k}$ should
    satisfy the condition that the internal node degree inside the community exceeds
    its external degree. Suppose $C_{k}\cap C_{k^{\prime}}=\emptyset$, ($\forall k,k^{\prime}$),
    $\mathcal{C}$ denotes disjoint communities; otherwise overlapping communities.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/45a1ec9cd050cad69142115b84e19e72.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Traditional community detection methods and the taxonomy of deep
    learning-based methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/59f6f369e09cfca2dbdd10ffe11eb3ce.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: A timeline of community detection development.'
  prefs: []
  type: TYPE_NORMAL
- en: Community Detection Input. Deep learning models take inputs as the network topology
    and network attributes. The topology formed by nodes and edges can be represented
    in matrices such as adjacency matrix $\bm{A}$, signed adjacency matrix $\bm{A}(+,-)$
    and the measurement matrices like the modularity matrix $\bm{B}$. Network attributes
    denote additional information on the network entities such as node attributes
    $\bm{X}$.
  prefs: []
  type: TYPE_NORMAL
- en: Community Detection Output. Community detection methods aim to output a set
    of communities which can be either disjoint or overlapping. TABLEs [V](#A1.T5
    "TABLE V ‣ Appendix A Summarized Techniques of Deep Learning-based Community Detection
    Methods ‣ A Comprehensive Survey on Community Detection with Deep Learning")–[VIII](#A1.T8
    "TABLE VIII ‣ Appendix A Summarized Techniques of Deep Learning-based Community
    Detection Methods ‣ A Comprehensive Survey on Community Detection with Deep Learning")
    in APPENDIX [A](#A1 "Appendix A Summarized Techniques of Deep Learning-based Community
    Detection Methods ‣ A Comprehensive Survey on Community Detection with Deep Learning")
    indicate different output by different community detection methods. Disjoint communities
    represent, for example, student clubs that allow a student to join only one club.
    Overlapping communities describe, for instance, users who participate in several
    circles in the social network. The methods for overlapping communities can detect
    disjoint communities.
  prefs: []
  type: TYPE_NORMAL
- en: III A Development of Community Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Community detection has been significant in network analysis and data mining.
    Fig. [3](#S2.F3 "Figure 3 ‣ II Definitions and Preliminaries ‣ A Comprehensive
    Survey on Community Detection with Deep Learning") illustrates its development
    from traditional to deep learning in a timeline. Their respective categories are
    summarized in Fig. [2](#S2.F2 "Figure 2 ‣ II Definitions and Preliminaries ‣ A
    Comprehensive Survey on Community Detection with Deep Learning") in the left and
    right parts, respectively. Two categories of methods suggest the development changes.
    Traditional methods mainly explore communities from network structures. We briefly
    review these seven categories of methods in this section. Deep learning uncovers
    deep network information and models complex relationships from high-dimensional
    data to lower-dimensional vectors. These will be reviewed in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Graph Partition. These methods, well known as graph clustering [[32](#bib.bib32)],
    are employed in deep learning models. They partition a network into communities
    with a given number $K$. Kernighan-Lin [[40](#bib.bib40)] is a representative
    heuristic algorithm. It initially divides a network into two arbitrary subgraphs
    and optimizes on nodes. Spectral bisection [[41](#bib.bib41)] is another representative
    method applying spectrum Laplacian matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Statistical Inference. Stochastic Block Model (SBM) [[29](#bib.bib29)] is a
    widely applied generative model by assigning nodes into communities and controlling
    their probabilities of likelihood. The variants include Degree-Corrected SBM (DCSBM)
    [[30](#bib.bib30)] and Mixed Membership SBM (MMB) [[31](#bib.bib31)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Hierarchical Clustering. This group of methods discover hierarchical community
    structures (i.e., dendrogram) in three ways: divisive, agglomerative and hybrid.
    The Girvan-Newman (GN) algorithm finds community structure in a divisive way by
    successively removing edges such that a new community occurs [[3](#bib.bib3),
    [42](#bib.bib42)]. Fast Modularity (FastQ) [[2](#bib.bib2), [43](#bib.bib43)],
    an agglomerative algorithm, gradually merges nodes, each of which is initially
    regarded as a community. Community Detection Algorithm based on Structural Similarity
    (CDASS) [[44](#bib.bib44)] jointly applies divisive and agglomerative strategies
    in a hybrid way.'
  prefs: []
  type: TYPE_NORMAL
- en: Dynamical Methods. Random walks are utilized to detect communities dynamically.
    For example, the random walk in WalkTrap [[45](#bib.bib45)] calculates node distances
    and the probability of community membership. Information Mapping (InfoMap) [[46](#bib.bib46)]
    applies the minimal-length encoding. Label Propagation Algorithm (LPA) [[47](#bib.bib47)]
    identifies diffusion communities through an information propagation mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Spectral Clustering. The network spectra reflects the community structure. Spectral
    clustering [[27](#bib.bib27)] partitions the network on the normalized Laplacian
    matrix and the regularized adjacency matrix, and fits SBM in the pseudo-likelihood
    algorithm. On the spectra of normalized Laplacian matrices, Siemon et al.[[28](#bib.bib28)]
    integrated communities in macroscopic and microscopic neural brain networks to
    obtain clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Density-based Algorithms. Significant clustering algorithms include Density-Based
    Spatial Clustering of Applications with Noise (DBSCAN) [[48](#bib.bib48)], Structural
    Clustering Algorithm for Networks (SCAN) [[49](#bib.bib49)] and Locating Structural
    Centers for Community Detection (LCCD) [[50](#bib.bib50)]. They identify communities,
    hubs and outliers by measuring entities’ density.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/025afcec4e942cbd01b7139a203ee7b5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: A general framework for CNN-based community detection with details
    in Section [V-A](#S5.SS1 "V-A CNN-based Community Detection ‣ V Convolutional
    Network-based Community Detection ‣ A Comprehensive Survey on Community Detection
    with Deep Learning"). As Convolutional Neural Network (CNN) input, the graph is
    preprocessed into the image data on nodes or edges. The $d$-dimensional latent
    features are convolutionally mapped within multiple CNN hidden layers and a final
    fully connected layer outputs representations of each node or each edge for classifications.
    Focusing on nodes, the flow ① predicts community labels in $k$ classes that nodes
    with same labels are clustered into a community. Focusing on edges, the flow ②
    predicts edge labels in two classes, i.e., inner and inter. The preliminary communities
    are formed by removing inter-community edges and optimized by merging with a measurement
    such as Modularity $Q$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Optimizations. Community detection generally maximizes the likelihood. Modularity
    (Q) [[42](#bib.bib42)] is the most classic optimization function following its
    variant FastQ [[2](#bib.bib2), [43](#bib.bib43)]. Louvain [[51](#bib.bib51)] is
    another well-known optimization algorithm that employs the node-moving strategy
    on optimized modularity. Moreover, the extensions of greedy optimizations include
    simulated annealing [[52](#bib.bib52)], extremal optimization [[53](#bib.bib53)]
    and spectral optimization [[54](#bib.bib54)]. Effective in local and global searching
    [[55](#bib.bib55)], the evolutionary optimizations consist of single and multiple
    objectives. For example, Multi-Agent Genetic Algorithm (MAGA-Net) [[56](#bib.bib56)]
    applies a single modularity function. Combo [[57](#bib.bib57)] mixes Normalized
    Mutual Information (NMI) [[58](#bib.bib58)] and Conductance (CON) [[59](#bib.bib59)].
    Q, NMI and CON estimate the network partition quality with details in APPENDIX
    [C](#A3 "Appendix C Detailed DESCRIPTION: Evaluation Metrics ‣ A Comprehensive
    Survey on Community Detection with Deep Learning").'
  prefs: []
  type: TYPE_NORMAL
- en: Why community detection needs deep learning? Capturing information from connections
    in a straightforward way may lead to sub-optimal community detection results.
    Deep learning models [[60](#bib.bib60)] bring the following additional advantages
    to community detection. Thus, deep learning-based community detection has been
    a new emerging branch. Its general framework learns lower-dimensional vectors
    from high-dimensional data of complex structural relationships [[10](#bib.bib10),
    [61](#bib.bib61), [62](#bib.bib62), [63](#bib.bib63)]. It, therefore, enables
    knowledge discoveries via the state-of-the-art machine learning and data mining
    techniques. The framework with representations can further embed non-structural
    features, such as node attributes, to increase the knowledge of community memberships
    [[64](#bib.bib64), [65](#bib.bib65), [66](#bib.bib66)]. Besides, groups of information
    from nodes [[61](#bib.bib61)], edges [[67](#bib.bib67)], neighborhoods [[68](#bib.bib68)]
    or multi-graphs [[69](#bib.bib69)] can be jointly recognized with special attentions
    in the deep learning process, leading to effective community detection results.
    With the deep learning ability to big data, more and more large-scale [[15](#bib.bib15)],
    high-sparse [[70](#bib.bib70)], complex structural [[71](#bib.bib71), [72](#bib.bib72)],
    dynamic [[73](#bib.bib73)] networks in real-world scenarios can be explored. Along
    with the achievements in a relatively short time (in Fig. [3](#S2.F3 "Figure 3
    ‣ II Definitions and Preliminaries ‣ A Comprehensive Survey on Community Detection
    with Deep Learning")), the development of community detection within the deep
    learning domain keeps facing a series of challenges. In this paper, we review
    accomplishments in Sections [V](#S5 "V Convolutional Network-based Community Detection
    ‣ A Comprehensive Survey on Community Detection with Deep Learning")–[XII](#S12
    "XII Practical Applications ‣ A Comprehensive Survey on Community Detection with
    Deep Learning"), and point out opportunities and challenges in Section [XIII](#S13
    "XIII Future Directions ‣ A Comprehensive Survey on Community Detection with Deep
    Learning").
  prefs: []
  type: TYPE_NORMAL
- en: IV A Taxonomy of Community Detection with Deep Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This survey proposes a taxonomy for deep community detection methods according
    to the iconic characteristics of the employed deep learning models. The taxonomy
    summarizes six categories: convolutional networks, Graph Attention Network (GAT),
    Generative Adversarial Network (GAN), Autoencoder (AE), Deep Nonnegative Matrix
    Factorization (DNMF) and Deep Sparse Filtering (DSF). In this taxonomy, convolutional
    networks include Convolutional Neural Network (CNN) and Graph Convolutional Network
    (GCN). They both contribute convolutions in representing latent features for community
    detection. GATs are significant at special attentions to community signals. The
    adversarial training process between the input graph and fake samples in the GAN
    model is successfully employed by community detection. On a universal AE framework,
    subcategories consist of stacked AE, sparse AE, denoising AE, graph convolutional
    AE, graph attention AE and Variational AE (VAE). The taxonomy structure is shown
    in Fig. [2](#S2.F2 "Figure 2 ‣ II Definitions and Preliminaries ‣ A Comprehensive
    Survey on Community Detection with Deep Learning"). The following Sections [V](#S5
    "V Convolutional Network-based Community Detection ‣ A Comprehensive Survey on
    Community Detection with Deep Learning")–[X](#S10 "X Deep Sparse Filtering-based
    Community Detection ‣ A Comprehensive Survey on Community Detection with Deep
    Learning") overview each category of methods, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: V Convolutional Network-based Community Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Community detection applying convolutional network models includes Convolutional
    Neural Networks (CNNs) and Graph Convolutional Networks (GCNs). CNNs [[74](#bib.bib74)]
    are a particular class of feed-forward Deep Neural Network (DNN) proposed for
    grid-like topology data such as image data, where convolution layers reduce computational
    costs and pooling operators ensure CNN’s robustness in feature representations.
    GCNs [[75](#bib.bib75)] are proposed for graph-structured data based on CNNs and
    performed on the first-order approximation of spectral filters. The rule of GCNs’
    layer-wise propagation is:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\bm{H}^{(l+1)}=\sigma(\tilde{\bm{D}}^{-\frac{1}{2}}\tilde{\bm{A}}\tilde{\bm{D}}^{-\frac{1}{2}}\bm{H}^{(l)}\bm{W}^{(l)}),$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: where the latent representations of the $l$-th layer are preserved in the matrix
    $\bm{H}^{(l)}$ ($\bm{H}^{(0)}=\bm{X}$), through the activation function $\sigma(\cdot)$
    with the layer-specific trainable weight matrix $\bm{W}^{(l)}$; $\tilde{\bm{A}}=\bm{A}+\bm{I}_{n}$
    with $\bm{I}_{n}$ denoting the identity matrix; and $\tilde{\bm{D}}_{ii}=\sum_{j}\tilde{a}_{ij}$
    where $\tilde{a}_{ij}\in\tilde{\bm{A}}$.
  prefs: []
  type: TYPE_NORMAL
- en: V-A CNN-based Community Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The existing CNN-based community detection methods implement CNN models with
    strict data input limitations so that they need to preprocess for image-formatted
    and labeled data (Fig. [4](#S3.F4 "Figure 4 ‣ III A Development of Community Detection
    ‣ A Comprehensive Survey on Community Detection with Deep Learning")). Techniques
    below solve particular problems in community detection with summaries in TABLE
    [IV](#A1.T4 "TABLE IV ‣ Appendix A Summarized Techniques of Deep Learning-based
    Community Detection Methods ‣ A Comprehensive Survey on Community Detection with
    Deep Learning").
  prefs: []
  type: TYPE_NORMAL
- en: 'The traditional community detection is an unsupervised learning task for deep
    learning models, incomplete topological structure affects its neighborhood analyzes
    and reduces the accuracy of community detection. However, networks in the real
    world have limited structural information. To this end, Xin et al. [[8](#bib.bib8)]
    proposed the first community detection model based on supervised CNN for Topologically
    Incomplete Networks (TINs). The model has two CNN layers with max-pooling operators
    for network representation and a fully connected DNN layer for community detection.
    The CNN architecture gradually recovers intact latent features from the rudimental
    input. The convolutional layers represent each node’s local features from different
    views. The last full connection layer $f$ updates communities for each node $v_{i}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small o_{i}^{k}=\sigma(b_{k}^{f}+\bm{W}_{k}^{f}\bm{h}^{(2)}_{i}),$ |  |
    (2) |'
  prefs: []
  type: TYPE_TB
- en: 'where $\sigma$ indicates the sigmoid function, $\bm{W}_{k}^{f}$ and $b_{k}^{f}$
    are weights and bias of the $k$-th neuron $o_{i}^{k}$, and $\bm{h}^{(2)}_{i}$
    is the node representation vector output by the previous two convolutional layers.
    The model performs back-propagation to minimize:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}=\frac{1}{2}\sum\nolimits_{i}\&#124;\bm{o}_{i}-\bm{y}_{i}\&#124;_{2}^{2}=\frac{1}{2}\sum\nolimits_{i}\sum\nolimits_{k}(o_{i}^{k}-y^{k}_{i})^{2},$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: where $\bm{y}_{i}$ denotes a ground truth label vector of node $v_{i}$, in which
    $y^{k}_{i}\in\{0,1\}$ represents whether $v_{i}$ belongs to the $k$-th community
    or not. The experiments on this model achieve a community detection accuracy around
    80% in TINs with 10% labeled nodes and the rest unlabeled, indicating that a high-order
    neighborhood representation in a range of multiple hops can improve the community
    detection accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: To deal with the high sparsity in large-scale social networks, the following
    two methods work on particular sparse matrices (i.e., non-zero elements of adjacency
    matrix) for efficient community detection. Sperlí [[70](#bib.bib70)] designed
    a sparse matrix convolution (SparseConv) into CNN. Santo et al. [[76](#bib.bib76)]
    further proposed a sparse CNN approach with a SparseConv2D operator so that the
    number of operations in the approach are significantly decreased.
  prefs: []
  type: TYPE_NORMAL
- en: Community Network Local Modularity R (ComNet-R) [[77](#bib.bib77)] is an edge-2-image
    model for community detection, classifying edges within and across communities
    through CNN. ComNet-R removes inter-community edges to prepare the disconnected
    preliminary communities. The optimization process is designed to merge communities
    based on the local modularity.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/09806135c476cd18975460615d7dc0f4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: A general framework for GCN-based community detection with details
    in Section [V-B](#S5.SS2 "V-B GCN-based Community Detection ‣ V Convolutional
    Network-based Community Detection ‣ A Comprehensive Survey on Community Detection
    with Deep Learning"). It inputs a graph structure $\bm{A}$ and optional node attributes
    $\bm{X}$. Within multiple Graph Convolutional Network (GCN) layers, graph latent
    features are smoothed based on community detection requirements. The graph representation
    learning is activated by $\sigma(\cdot)$. Four community detection frameworks
    are illustrated in ①–④ applying either final node representations (① and ②) or
    temporal representations in hidden layers (③ and ④). Given node labels, communities
    are detected based on node classification in ① while ② implements node clustering
    on embeddings $\bm{H}$ and can further optimized in ③ with measurements, e.g.,
    Mutual Information (MI), for best community affiliations. ④ jointly optimizes
    clustering results and GCN representations that gradually detects each node into
    communities with convolutionally represented node embeddings.'
  prefs: []
  type: TYPE_NORMAL
- en: V-B GCN-based Community Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'GCNs aggregate node neighborhood’s information in deep graph convolutional
    layers to globally capture complex features for community detection (Fig. [5](#S5.F5
    "Figure 5 ‣ V-A CNN-based Community Detection ‣ V Convolutional Network-based
    Community Detection ‣ A Comprehensive Survey on Community Detection with Deep
    Learning")). There are two classes of community detection methods based on GCNs:
    (1) supervised/semi-supervised community classification, and (2) community clustering
    with unsupervised network representation. Community classification methods are
    limited by a lack of labels in the real world. In comparison, network representations
    are more flexible to cluster communities through techniques such as matrix reconstructions
    and objective optimizations. TABLE [V](#A1.T5 "TABLE V ‣ Appendix A Summarized
    Techniques of Deep Learning-based Community Detection Methods ‣ A Comprehensive
    Survey on Community Detection with Deep Learning") in APPENDIX [A](#A1 "Appendix
    A Summarized Techniques of Deep Learning-based Community Detection Methods ‣ A
    Comprehensive Survey on Community Detection with Deep Learning") compares the
    techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: 'GCNs employ a few traditional community detection methods as deep graph operators,
    such as SBMs for statistical inference, Laplacian matrix for spectrum analysis
    and probabilistic graphical models for belief propagation. For example, Line Graph
    Neural Network (LGNN) [[78](#bib.bib78)] is a supervised community detection model,
    which improves SBMs with better community detection performance and reduces the
    computational cost. Integrating the non-backtracking operator with belief propagation’s
    message-passing rules, LGNN learns node represented features in directed networks.
    The softmax function identifies conditional probabilities that a node $v_{i}$
    belongs to the community $C_{k}$ ($o_{i,k}=p(y_{i}=c_{k}|\Theta,\mathcal{G}$),
    and minimizes the cross-entropy loss over all possible permutations $S_{\mathcal{C}}$
    of community labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}(\Theta)=\min_{\pi\in S_{\mathcal{C}}}{-\sum\nolimits_{i}\log{o_{i,\pi(y_{i})}}}.$
    |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: Since GCN is not initially designed for the community detection task, community
    structures are not the focus in learning node embeddings. To meet this gap, a
    semi-supervised GCN community detection model, named MRFasGCN, characterizes hidden
    communities through extending the network-specific Markov Random Field as a new
    convolutional layer (eMRF) which makes MRFasGCN community oriented and performs
    a smooth refinement to the coarse results from GCN. To enable unsupervised community
    detection, the GCN-based framework, denoted as SGCN [[79](#bib.bib79)], designs
    a local label sampling model to locate the structural centers for community detection.
    By integrating the label sampling model with GCN, SGCN encodes both network topology
    and node attributes in the training of each node’s community membership without
    any prior label information.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of a probabilistic inference framework, detecting overlapping communities
    can be solved by a generative model inferring the community affiliations of nodes.
    For example, Neural Overlapping Community Detection (NOCD) [[80](#bib.bib80)]
    combines the Bernoulli–Poisson (BP) probabilistic model and a two-layer GCN to
    learn community affiliation vectors by minimizing BP’s negative log-likelihood.
    By setting a threshold to keep recognizing and removing weak affiliations, final
    communities are obtained.
  prefs: []
  type: TYPE_NORMAL
- en: Spectral GCNs represent all latent features from the node’s neighborhood. The
    features of neighboring nodes converge to the same values by repeatedly operating
    Laplacian smoothing in deep GCN layers. However, these models lead to an over-smoothing
    problem in community detection. To reduce the negative impact, Graph Convolutional
    Ladder-shape Networks (GCLN) [[81](#bib.bib81)] is designed as a new GCN architecture
    for unsupervised community detection ($k$-means), which is based on the U-Net
    in the CNN field. A contracting path and an expanding path are built symmetrically
    in GCLN. The contextual features captured from the contracting path fuse with
    the localized information learned in the expanding path. The layer-wise propagation
    follows Eq. ([1](#S5.E1 "In V Convolutional Network-based Community Detection
    ‣ A Comprehensive Survey on Community Detection with Deep Learning")).
  prefs: []
  type: TYPE_NORMAL
- en: Since different types of connections are generally treated as plain edges, GCNs
    represent each type of connection and aggregate them, leading to redundant representations.
    Independence Promoted Graph Disentangled Network (IPGDN) [[82](#bib.bib82)] distinguishes
    the neighborhood into different parts and automatically discovers the nuances
    of a graph’s independent latent features to reduce the difficulty in detecting
    communities. IPGDN is supported by Hilbert-Schmidt Independence Criterion (HSIC)
    regularization [[83](#bib.bib83)] in neighborhood routings.
  prefs: []
  type: TYPE_NORMAL
- en: 'For attributed graphs, community detection by GCNs relies on both structural
    information and attributed features, where neighboring nodes and the nodes with
    similar features are likely to cluster in the same community. Therefore, graph
    convolutions multiply the above two graph signals and need to filter out high-frequency
    noises smoothly. To this end, a low-pass filter is embedded in Adaptive Graph
    Convolution (AGC) [[64](#bib.bib64)] with spectral clustering through:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small p(\lambda_{q})=(1-\frac{1}{2}\lambda_{q})^{k},$ |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: 'where the frequency response function of $\mathcal{G}$ denotes $p(\Lambda)=\text{diag}\left(p\left(\lambda_{1}\right),\cdots,p\left(\lambda_{n}\right)\right)$
    decreasing and nonnegative on all eigenvalues. AGC convolutionally selects suitable
    neighborhood hop sizes in $k$ and represents graph features by the $k$-order graph
    convolution as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\bar{\bm{X}}=(I-\frac{1}{2}\bm{L}_{s})^{k}\bm{X},$ |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: where $\bm{L}_{s}$ denotes the symmetrically normalized graph Laplacian on $\lambda_{q}$.
    The filter smooths the node embedding $\bar{\bm{X}}$ adjusting to $k$ that higher
    $k$ leads to better filtering performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adaptive Graph Encoder (AGE) [[84](#bib.bib84)] is another smoothing filter
    model scalable to community detection. AGE adaptively performs node similarity
    measurement ($\bm{S}=\left[s_{ij}\right]$) and $t$-stacked Laplacian smoothing
    filters ($\bar{\bm{X}}=(\bm{I}-\gamma\bm{L})^{t}\bm{X}$):'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}=\sum\nolimits_{(v_{i},v_{j})\in V^{\prime}}-s^{\prime}_{ij}\log(s_{ij})-(1-s^{\prime}_{ij})\log(1-s_{ij}),$
    |  | (7) |'
  prefs: []
  type: TYPE_TB
- en: where $V^{\prime}$ denotes balanced training set over positive (similar) and
    negative (dissimilar) samples, $s^{\prime}_{ij}$ is the ranked binary similarity
    label on node pairs $(v_{i},v_{j})$.
  prefs: []
  type: TYPE_NORMAL
- en: A few works make significant contributions to GCN’s filters. For example, Graph
    Convolutional Neural Networks with Cayley Polynomials (CayleyNets) [[85](#bib.bib85)],
    in a spectral graph convolution architecture, proposes an effective Cayley filter
    for high-order approximation on community detection. It specializes in narrow-band
    filtering since low frequencies contain extensive community information for community
    detection-aimed representations. Cooperating with the Cayley filter, CayleyNets
    involves a mean pooling in spectral convolutional layers and a semi-supervised
    softmax classifier on nodes for community membership prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'To capture the global cluster structure for community detection, the Spectral
    Embedding Network for attributed graph clustering (SENet) [[86](#bib.bib86)] introduces
    the loss of spectral clustering into a three-layer GCN’s output layer by minimizing:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}=-\operatorname{tr}((\bm{H}^{(3)})^{\top}\bm{D}^{-\frac{1}{2}}\bm{K}\bm{D}^{-\frac{1}{2}}\bm{H}^{(3)}),$
    |  | (8) |'
  prefs: []
  type: TYPE_TB
- en: where $\bm{K}$ is a kernel matrix encoding typologies and attributes.
  prefs: []
  type: TYPE_NORMAL
- en: Community Deep Graph Infomax (CommDGI) [[87](#bib.bib87)] jointly optimizes
    graph representations and clustering through Mutual Information (MI) on nodes
    and communities, and measures graph modularity for maximization. It applies contrastive
    training to obtain better representations, $k$-means for node clustering and targets
    cluster centers. Zhao et al. [[88](#bib.bib88)] proposed a graph debiased contrastive
    learning which simultaneously performs representations and clustering so that
    the clustering results and discriminative representations are both improved.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2672d97ce610f70834d442e94d4f143a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: A general framework for GAT-based community detection with details
    in Section [VI](#S6 "VI Graph Attention Network-based Community Detection ‣ A
    Comprehensive Survey on Community Detection with Deep Learning"). Graph Attention
    Network (GAT) assigns attention coefficients $\bm{\alpha}^{(l)}_{ij}$: {green,
    blue, purple} in each neighborhood $N(v_{i})$ in $l$-th hidden layer. The represented
    vector $\bm{h}^{\prime}_{i}$ aggregates available information: ① differently colored
    edges between the same node pairs in multiplex networks, or ② metapaths or context
    paths in a heterogeneous network. The GAT embeddings $\bm{H}$ are analyzed to
    cluster communities.'
  prefs: []
  type: TYPE_NORMAL
- en: VI Graph Attention Network-based Community Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Graph Attention Networks (GATs) [[89](#bib.bib89)] aggregate nodes’ features
    in neighborhoods by trainable weights with attentions:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\bm{h}_{i}^{(l+1)}=\sigma\left(\sum\nolimits_{j\in N(v_{i})}\alpha_{ij}^{(l+1)}\bm{W}^{(l+1)}\bm{h}_{j}^{(l)}\right),$
    |  | (9) |'
  prefs: []
  type: TYPE_TB
- en: where $\bm{h}_{i}^{(l)}$ represents the node $v_{i}$’s representation in the
    $l$-th layer ($\bm{h}_{i}^{(0)}=\bm{x}_{i}$) and $\alpha_{ij}^{(l)}$ is the attention
    coefficient between $v_{i}$ and $v_{j}\in N(v_{i})$. In community detection (Fig.
    [6](#S5.F6 "Figure 6 ‣ V-B GCN-based Community Detection ‣ V Convolutional Network-based
    Community Detection ‣ A Comprehensive Survey on Community Detection with Deep
    Learning")), the attention mechanism contributes to adaptively learning the importance
    of each node in a neighborhood. Correlations between similar nodes are computed
    close to the ground truth of community membership, which is inherited in GAT’s
    representations. These attentions filter spatial relations or integrate metapaths.
    Therefore, communities in attributed, multiplex, heterogeneous networks can be
    easily detected (TABLE [VI](#A1.T6 "TABLE VI ‣ Appendix A Summarized Techniques
    of Deep Learning-based Community Detection Methods ‣ A Comprehensive Survey on
    Community Detection with Deep Learning")).
  prefs: []
  type: TYPE_NORMAL
- en: The relations need special attention in deep community detection models. For
    example, citations and co-subject relationships are both significant in clustering
    papers into research topics. The multiplex network is constructed by multiple
    relation types reflected on edges (i.e., $E^{(r)}$). Each type of edges is grouped
    in a layer $r$. Thus, GATs can pay attentions to relation types. Deep Graph Infomax
    for attributed Multiplex network embedding (DMGI) [[61](#bib.bib61)] independently
    embeds each relation type and computes network embeddings in maximizing the globally
    shared features to detect communities. Its contrastive learning conducts between
    the original network and a corrupted network on each layer through the discriminator.
    A consensus regularization is subsequently applied with the attention coefficient
    to integrate final embeddings. The benefit of applying the attention mechanism
    is to preprocess the less significant relations by weakening their coefficient,
    especially when various types of relations are presented.
  prefs: []
  type: TYPE_NORMAL
- en: Despite the extrinsic supervision signal sharing globally in multiple relations,
    DMGI cannot capture the intrinsic signal into node embeddings where node attributes
    are considered. To fill the gap, High-order Deep Multiplex Infomax (HDMI) [[65](#bib.bib65)]
    is developed to capture both signals and their interactions. HDMI further designs
    a fusion module for the node embedding combination over multiplex network layers
    based on the semantic attention [[90](#bib.bib90)] on community memberships.
  prefs: []
  type: TYPE_NORMAL
- en: Heterogeneous Information Network (HIN) involves diverse types of nodes $\mathcal{V}$
    and edges $\mathcal{E}$. Deep community detection over heterogeneous networks
    represents heterogeneous typologies and attributes $\mathcal{X}$. Metapath Aggregated
    Graph Neural Network (MAGNN) [[72](#bib.bib72)] offers a superior community detection
    solution by multi-informative semantic metapaths which distinguish heterogeneous
    structures in graph attention layers. MAGNN generates node attributes from semantic
    information. Since heterogeneous nodes and edges exist in intra- and inter-metapaths,
    MAGNN utilizes the attention mechanism in both of their embeddings by aggregating
    semantic variances over nodes and metapaths. Thus, MAGNN reduces the high heterogeneity
    and embeds richer topological and semantic information to enhance community detection
    results. Moreover, HeCo [[91](#bib.bib91)] embeds network schema and metapaths
    from HINs. A modified contrastive learning is employed to guide two parts of embeddings.
    Sequentially, the attention mechanism acts on node importance, network heterogeneity
    and semantic features, where community detection benefits.
  prefs: []
  type: TYPE_NORMAL
- en: The above two works both use metapaths to facilitate community detection, but
    defining meaningful metapaths requires lots of domain knowledge. Thus, Context
    Path-based Graph Neural Network (CP-GNN) [[92](#bib.bib92)] is built to learn
    node embeddings by context paths where attention mechanisms are exploited to discriminate
    the importance of different relationships. The non-predefined context paths are
    significant in capturing the high-order relationship for community detection.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/85e2585ee10d4bfd47152c8fcc027507.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: A general framework for GAN-based community detection with details
    in Section [VII](#S7 "VII Generative Adversarial Network-based Community Detection
    ‣ A Comprehensive Survey on Community Detection with Deep Learning"). Generative
    Adversarial Network (GAN) produces fake samples $\phi_{g}(\bm{z})$ by the generator
    $\phi_{g}$ to fool the discriminator $\phi_{d}$. GAN’s real samples can be node
    embeddings $\bm{H}_{v}$, local topology (e.g., triplet, clique) or communities.
    Thus, real and fake samples competitively finetune community features: The flow
    ① obtains community membership via clique-level GAN. The flow ② detects communities
    based on competitive node-level representations from $\bm{H}_{v}$ or triplets.
    The flow ③ directly discriminates communities through the discriminator.'
  prefs: []
  type: TYPE_NORMAL
- en: VII Generative Adversarial Network-based Community Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Adversarial training is effective in generative models and improves discriminative
    ability. However, it needs to solve the overfitting problem when applied to community
    detection (see Fig. [7](#S6.F7 "Figure 7 ‣ VI Graph Attention Network-based Community
    Detection ‣ A Comprehensive Survey on Community Detection with Deep Learning")
    and TABLE [VII](#A1.T7 "TABLE VII ‣ Appendix A Summarized Techniques of Deep Learning-based
    Community Detection Methods ‣ A Comprehensive Survey on Community Detection with
    Deep Learning")). Generative Adversarial Networks (GANs) [[93](#bib.bib93)] competitively
    trains a generator $\phi_{g}$ and a discriminator $\phi_{d}$ in the adversarial
    framework. $\phi_{d}(\bm{x})$ represents the probability of input data, while
    $\phi_{g}(\bm{z})$ learns the generator’s distribution $p_{g}$ via input noise
    variables $p_{\bm{z}}(\bm{z})$. The generator fools the discriminator by generating
    fake samples. Its objective function is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\min_{\phi_{g}}\max_{\phi_{d}}$ | $\displaystyle\mathbb{E}_{\bm{x}\sim
    p_{data}(\bm{x})}[\log\phi_{d}(\bm{x})]$ |  | (10) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle+\mathbb{E}_{\bm{z}\sim p_{\bm{z}}(\bm{z})}[\log(1-\phi_{d}(\phi_{g}(\bm{z})))].$
    |  |'
  prefs: []
  type: TYPE_TB
- en: Seed Expansion with generative Adversarial Learning (SEAL) [[94](#bib.bib94)]
    generates seed-aware communities from selected seed nodes by Graph Pointer Network
    with incremental updates (iGPN). It consists of four components in the community
    level, i.e., generator, discriminator, seed selector and locator. The discriminator
    adopts Graph Isomorphism Networks (GINs) to modify generated communities with
    the ground truth of community labels. The locator is designed to provide regularization
    signals to the generator, so that irrelevant nodes in community detection can
    be eliminated.
  prefs: []
  type: TYPE_NORMAL
- en: 'To imbalanced communities, Dual-Regularized Graph Convolutional Networks (DR-GCN)
    [[95](#bib.bib95)] utilizes a conditional GAN into the dual-regularized GCN model,
    i.e., a latent distribution alignment regularization and a class-conditioned adversarial
    regularization. The first regularization $\mathcal{L}=(1-\alpha)\mathcal{L}_{gcn}+\alpha\mathcal{L}_{dist}$
    balances the communities by minimizing the Kullback-Leibler (KL) divergence between
    majority and minority community classes $\mathcal{L}_{dist}$ guided with a standard
    GCN training $\mathcal{L}_{gcn}$. The second regularization is designed to distinguish
    communities on labeled node representations:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\min_{\phi_{g},\mathcal{L}}$ | $\displaystyle\max_{\phi_{d}}\mathcal{L}(\phi_{d},\phi_{g})=\mathbb{E}_{v_{i}\sim
    p_{data}(v_{i})}\log\phi_{d}(v_{i}&#124;y_{i})$ |  | (11) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle+\mathbb{E}_{\bm{z}\sim p_{\bm{z}}(\bm{z})}[\log(1-\phi_{d}(\phi_{g}(\bm{z}&#124;y_{i})))+\mathcal{L}_{reg}],$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\mathcal{L}_{reg}=\sum_{u\in N(v_{i})}\|\bm{h}_{v^{\prime}_{i}}-\bm{h}_{u}\|_{2}$
    forces the generated fake node $v^{\prime}_{i}$ to reconstruct the respective
    neighborhood relations (as $u\sim v_{i}$), $y_{i}$ is the ground truth label of
    node $v_{i}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of generating only one kind of fake samples, Jointly Adversarial Network
    Embedding (JANE) [[62](#bib.bib62)] employs two network information of topology
    and node attributes to capture semantic variations from adversarial groups of
    real and fake samples. Specifically, JANE represents embeddings $\bm{H}$ through
    a multi-head self-attention encoder $\phi_{e}$, where Gaussian noises are added
    for fake features for competition over the generator $\phi_{g}$ and the discriminator
    $\phi_{d}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\min_{\phi_{g},\phi_{e}}\max_{\phi_{d}}$ | $\displaystyle{\mathcal{L}(\phi_{d},\phi_{e},\phi_{g})}=$
    |  | (12) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle\mathbb{E}_{(\bm{a},\bm{x})\sim p_{\bm{AX}}}[\underbrace{\mathbb{E}_{\bm{h}\sim
    p_{\phi_{e}}(\cdot&#124;\bm{a},\bm{x})}[\log\phi_{d}(\bm{h},\bm{a},\bm{x})]}_{\log\phi_{d}(\phi_{e}(\bm{a},\bm{x}),\bm{a},\bm{x})}]$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle+$ | $\displaystyle\mathbb{E}_{\bm{h}\sim p_{\bm{H}}}[\underbrace{\mathbb{E}_{(\bm{a},\bm{x})\sim
    p_{\phi_{g}}(\cdot&#124;\bm{h})}[\log(1-\phi_{d}(\bm{h},\bm{a},\bm{x}))]}_{\log(1-\phi_{d}(\bm{h},\phi_{g}(\bm{h})))}],$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $p_{\bm{AX}}$ denotes the joint distribution of the topology $\bm{A}$
    ($\bm{a}\subseteq\bm{A}$) and sampled node attributes $\bm{X}$ ($\bm{x}\subseteq\bm{X}$).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/792e6b171ad7b41df915e4cf1a995ca0.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) A general framework of AE-based community detection
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e5400cd40a0d5990abc7d92d307b3332.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) static unattributed graph
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/51cb3ace71b44f461561b4fefaed8888.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) static attributed graph
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9dd838a6187435b1cd3ee6daec2f0b62.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) dynamic graph
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d6229576130165808119e73528672b37.png)'
  prefs: []
  type: TYPE_IMG
- en: (e) cross-domain graph
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e107d2f2c0980e058555ecb8e2b22e48.png)'
  prefs: []
  type: TYPE_IMG
- en: (f) heterogeneous graph
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5e1c9ea5161f88f0484df4c6e1ccf878.png)'
  prefs: []
  type: TYPE_IMG
- en: (g) attributed multi-view graph
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8: A general framework for AE-based community detection consists of
    (a) the framework of the input layer, AE and clustering layers and the output
    layer and (b)-(g) AE-based community detection processes for each type of graph:
    (a) The input can be one of the graphs. They have topology and attributes information
    which are represented by the adjacency matrix $\bm{A}$ (①-③, ⑥), node attribute
    vectors $\bm{X}$ (②, ⑥), node similarity matrix $\bm{S}$ (④) and metapaths $\Phi$
    (⑤). More than one AE can be included that each AE embeds a part of input. Two
    optional work flows representively output node embeddings $\bm{H}_{v}$ and community
    membership matrix $\bm{H}_{c}$ for community detection results (i.e., the AE output
    layer). (b) Inputting typologies $\bm{A}$, the AE outputs node embeddings $\bm{H}_{v}$
    by minimizing the reconstruction loss $\mathcal{L}_{re}$ (solid arrows) or outputs
    the community membership matrix $\bm{H}_{c}$ by further minimizing the clustering
    loss over $\bm{P}$ and $\bm{Q}$ distributions which measures node’s probability
    in a community (dashed arrows). The community prior information for $\mathcal{L}(\bm{O},\bm{H})$
    (dashed arrows) or the sparse penalty for $\Omega(\rho\|\sum{\bm{h}_{i}/n})$ (dashed
    arrows) optionally guides AE learning upon hidden layer embeddings $\bm{h}_{i}\in\bm{H}$.
    (c) Aiming at $\bm{H}_{v}$ or $\bm{H}_{c}$, typologies $\bm{A}$ and node attributes
    $\bm{X}$ are respectively represented by AE1 and AE2 (solid arrows). Their embeddings
    $\bm{H}_{\bm{A}}$ and $\bm{H}_{\bm{X}}$ are aggregated by minimizing the consistency
    loss. Otherwise (dashed arrows), an AE embeds all input over $(\bm{A},\bm{X})$.
    (d) The $t$-th snapshot $\bm{A}_{(t)}$ in the dynamic graph is represented for
    the node embeddings $\bm{H}_{(t)}$. The temporal smoothness regularization optimizes
    $\bm{H}_{(t)}$ over the previous snapshot’s embeddings. $\bm{O}$ is optionally
    employed. (e) Two AEs respectively represent similarity matrices from the source
    and target domains into $\bm{H}_{s}$ and $\bm{H}_{t}$ where $\bm{H}_{s}$ guides
    AE2’s training and node embeddings of the target graph $\bm{H}_{t}$ is outputted.
    (f) Each metapath is represented in an AE with the input feature vectors $\{\bm{x}_{i\Phi}\}$
    denoting the meta proximity $\bm{p}_{i}\in\bm{P}$ between node $v_{i}$ in the
    metapath $\Phi$. All metapaths’ embeddings are aggregated for $\bm{H}_{v}$ in
    the fully connected layer in these stacked AEs. (g) Attributes in each view are
    input with $A$ into an AE where node embeddings in different views are optimized
    by the clustering loss.'
  prefs: []
  type: TYPE_NORMAL
- en: The proximity can capture underlying relationships within communities. However,
    sparsely connected networks in the real world do not provide enough edges. Attributes
    in networks cannot be measured by proximity. To address these limitations, Proximity
    Generative Adversarial Network (ProGAN) [[66](#bib.bib66)] encodes each node’s
    proximity from a set of instantiated triplets, so that community relationships
    are discovered and preserved in a low-dimensional space.
  prefs: []
  type: TYPE_NORMAL
- en: 'Community Detection with Generative Adversarial Nets (CommunityGAN) [[96](#bib.bib96)]
    is proposed for overlapping communities, which obtains node representation by
    assigning each node-community pair a nonnegative factor. Its objective function
    optimizes through a motif-level generator $\phi_{g}(\cdot|v_{i};\Theta_{g})$ and
    discriminator $\phi_{d}(\cdot,\Theta_{d})$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\min_{\Theta_{g}}\max_{\Theta_{d}}$ | $\displaystyle{\mathcal{L}(\phi_{g},\phi_{d})}=\sum_{i}(\mathbb{E}_{C^{\prime}\sim
    p_{true}(\cdot&#124;v_{i})}\left[\log\phi_{d}(C^{\prime};\Theta_{d})\right]$ |  |
    (13) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle+\mathbb{E}_{V^{\prime}\sim\phi_{g}(V^{\prime}&#124;v_{i};\Theta_{g})}\left[\log(1-\phi_{d}(V^{\prime};\Theta_{d})\right]),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\Theta_{g}$ and $\Theta_{d}$ unifies all nonnegative representation vector
    of node $v_{i}$ in the generator and the discriminator, $V^{\prime}\subseteq V$
    denotes a node subset, $C^{\prime}$ represents motifs (i.e., cliques), and conditional
    probability $p_{true}(C^{\prime}|v_{i})$ describes the preference distribution
    of $C^{\prime}$ covering $v_{i}$ over all other motifs $C^{\prime}\in\mathcal{C^{\prime}}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'To capture the global structural information, Community-Aware Network Embedding
    (CANE) [[97](#bib.bib97)] integrates a community detection model, i.e. Latent
    Dirichlet Allocation (LDA), into the adversarial node representation process:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\min_{\Theta_{g}}$ | $\displaystyle\max_{\Theta_{d}}{\mathcal{L}(\phi_{g},\phi_{d})}=$
    |  | (14) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\sum_{i}$ | $\displaystyle(\mathbb{E}_{v\sim p_{true}(v&#124;v_{i})}\left[\log\phi_{d}(v,v_{i};\Theta_{d})+P_{\phi}(v&#124;v_{i})\right]$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle+\mathbb{E}_{v\sim\phi_{g}(v&#124;v_{i};\Theta_{g})}\left[\log(1-\phi_{d}(v,v_{i};\Theta_{d})-P_{\phi}(v&#124;v_{i})\right]),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $P_{\phi}(v|v_{i})$ indicates the community similarity between a node
    $v_{i}$ and the node sample $v$, $\phi_{g}(v|v_{i};\Theta_{g})$ outputs the node
    connectivity distribution. In turn, the representations characterize the community
    property.
  prefs: []
  type: TYPE_NORMAL
- en: Network Embedding and overlapping Community detection with Adversarial learning
    (ACNE) [[98](#bib.bib98)] further generates negative communities as fake samples
    to learn distinguished community representation. ACNE utilizes walking strategy
    with perception to assist sampling of overlapping communities for nodes and exploits
    the discriminator to jointly map the node and community membership embeddings,
    so as to preserve the correlation of node-community in representations.
  prefs: []
  type: TYPE_NORMAL
- en: VIII Autoencoder-based Community Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Autoencoders (AEs) are most commonly used in community detection as its unsupervised
    setting, including stacked AE, sparse AE, denoising AE, convolutional AE and Variational
    AE (VAE). AEs can depict nonlinear, noisy real-world networks and represent communities
    from rich information through reconstruction. A general framework for AE [[99](#bib.bib99)]
    is formed by an encoder $\bm{H}=\phi_{e}(\bm{A},\bm{X})$ and decoder $\hat{\bm{A}}=\phi_{r}(\bm{H})$
    or $\bm{\hat{X}}=\phi_{r}(\bm{H})$. The encoder $\phi_{e}$ maps a high-dimensional
    network structure $\bm{A}$ and possible attributes $\bm{X}$ into a low-dimensional
    latent feature space $\bm{H}$. The decoder $\phi_{r}$ reconstructs a decoded network
    from encoder’s representations $\bm{H}$ that $\hat{\bm{A}}$ and $\bm{\hat{X}}$
    inherits preferred information in $\bm{A}$ and $\bm{X}$. A loss function $\mathcal{L}(\bm{x},\phi_{r}(\phi_{e}(\bm{x})))$
    is designed to maximize the likelihood between source data $\bm{x}$ and decoded
    data $\phi_{r}(\phi_{e}(\bm{x}))$. Fig. [8](#S7.F8 "Figure 8 ‣ VII Generative
    Adversarial Network-based Community Detection ‣ A Comprehensive Survey on Community
    Detection with Deep Learning") shows how AEs are generally applied in community
    detection, and TABLE [VIII](#A1.T8 "TABLE VIII ‣ Appendix A Summarized Techniques
    of Deep Learning-based Community Detection Methods ‣ A Comprehensive Survey on
    Community Detection with Deep Learning") compares the techniques.
  prefs: []
  type: TYPE_NORMAL
- en: VIII-A Stacked AE-based Community Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Compared to a single AE, a group of stacked AEs developed in deep hidden layers
    can better embed high-dimensional community features with representing each encoder
    in the stack individually representing one type of input data. In this architecture,
    stacked AEs represent multi-level and dynamic information to flexibly support
    wide community detection implementations [[100](#bib.bib100)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Semi-supervised Nonlinear Reconstruction Algorithm with DNN (semi-DRN) [[63](#bib.bib63)]
    designs a stacked AE into a community detection model, where a modularity matrix
    learns the nonlinear node representations in AEs and $k$-means obtains final community
    structure. Given an edge between nodes $v_{i}$ and $v_{j}$ in the adjacency matrix
    $\bm{A}=[a_{ij}]$, the modularity [[101](#bib.bib101)] $b_{ij}=a_{ij}-\frac{k_{i}k_{j}}{2m}$
    in the modularity matrix $\bm{B}$ is optimized for maximization. Encoding the
    node pairwise similarities (community membership) based on node representations,
    a pairwise constraint matrix $\bm{O}=[o_{i,j}\in\{0,1\}]$ is, meanwhile, defined
    to provide a prior knowledge that nodes $v_{i}$ and $v_{j}$ belong to the same
    community ($o_{i,j}=1$) or not ($o_{i,j}=0$). Thus, semi-DRN is optimized by minimizing
    the loss function:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}=\mathcal{L}(\bm{B},\bm{\hat{B}})+\lambda\mathcal{L}(\bm{O},\bm{H}),$
    |  | (15) |'
  prefs: []
  type: TYPE_TB
- en: where $\bm{\hat{B}}$ represents the reconstructed $\bm{B}$ over stacked representations
    by a series of AEs, $\lambda$ denotes an adjusting weight between the AE reconstruction
    loss $\mathcal{L}(\bm{B},\bm{\hat{B}})$ and the pairwise constraints $\mathcal{L}(\bm{O},\bm{H})$,
    and $\mathcal{L}(\bm{O},\bm{H})$ measures each pair of community membership $o_{ij}$
    and latent representations $(\bm{h}_{i},\bm{h}_{j})$ within stacked AEs.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, Deep Network Embedding with Structural Balance Preservation (DNE-SBP)
    [[67](#bib.bib67)] incorporates the adjusting weight on pairwise constraints for
    signed networks so that the stacked AE clusters the closest nodes distinguished
    by positive and negative connections. Unified Weight-free Multi-component Network
    Embedding (UWMNE) and its variant with Local Enhancement (WMCNE-LE) [[102](#bib.bib102)]
    preserve community properties from network topology and semantic information and
    integrate the diverse information in deep AE from a local network structure perspective.
  prefs: []
  type: TYPE_NORMAL
- en: 'To discover $t$ time-varying community structure, Semi-supervised Evolutionary
    Autoencoder (sE-Autoencoder) [[73](#bib.bib73)] is developed within an evolutionary
    clustering framework, assuming community structures at previous time steps successively
    guide the detection at the current time step. To this end, sE-Autoencoder adds
    a temporal smoothness regularization $\mathcal{L}(\bm{H}_{(t)},\bm{H}_{(t-1)})$
    for minimization [[63](#bib.bib63)] in:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}=\mathcal{L}(\bm{S}_{(t)},\bm{\hat{S}}_{(t)})+\lambda\mathcal{L}(\bm{O},\bm{H}_{(t)})+(1-\lambda)\mathcal{L}(\bm{H}_{(t)},\bm{H}_{(t-1)}),$
    |  | (16) |'
  prefs: []
  type: TYPE_TB
- en: where reconstruction error $\mathcal{L}(\bm{S}_{(t)},\bm{\hat{S}}_{(t)})$ minimizes
    the loss between the similarity matrix $\bm{S}_{(t)}$ and reconstructed matrix
    $\bm{\hat{S}}_{(t)}$ at the time step $t$, and the parameter $\lambda$ controls
    the node pairwise constraint $\mathcal{L}(\bm{O},\bm{H}_{(t)})$ and the temporal
    smoothness regularization over time $t$-th graph representation $\bm{H}_{(t)}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'To attributed networks, Deep Attributed Network Embedding (DANE) [[103](#bib.bib103)]
    develops a two-branch AE framework: one branch maps the highly nonlinear network
    structure to the low-dimensional feature space, and the other collaboratively
    learns node attributes. As similar nodes are more likely to be clustered in the
    same community, DANE measures these similarities by a series of proximity regarding
    network topological and attribute information in the representation learning,
    where optimizations are applied on reconstruction losses at first-order proximity
    $\mathcal{L}_{f}$, higher-order proximity $\mathcal{L}_{h}$ and semantic proximity
    $\mathcal{L}_{s}$, and a negative log likelihood control $\mathcal{L}_{c}$ for
    a consistent and complementary representation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve the problem of shifted distributions, imbalanced features or a lack
    of data, Transfer Learning-inspired Community Detection with Deep Transitive Autoencoder
    (Transfer-CDDTA) [[104](#bib.bib104)] uses the transfer learning framework and
    modifies it to the unsupervised community detection task. On the source and target
    domains, Transfer-CDDTA balances stacked AEs via KL divergence while learning
    node embeddings. Aiming to map community information into one smooth feature space,
    CDDTA separates the input adjacency matrix $\bm{A}$ into a source domain $s$ and
    a target domain $t$ by similarity matrices $\bm{S}_{s}$ and $\bm{S}_{t}$ to keep
    node pairwise similarity values for each stacked AE. Transfer-CDDTA then incorporates
    domain-independent features into the following minimization:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}=\mathcal{L}_{s}(\bm{S}_{s},\bm{\hat{S}}_{s})+\mathcal{L}_{t}(\bm{S}_{t},\bm{\hat{S}}_{t})+\alpha
    KL(\bm{H}_{s},\bm{H}_{t})+\beta\mathcal{L}(\Theta;\gamma),$ |  | (17) |'
  prefs: []
  type: TYPE_TB
- en: where $\alpha$, $\beta$, $\gamma$ are trade-off parameters, $\mathcal{L}_{s}$
    and $\mathcal{L}_{t}$ denote reconstruction losses of source and target domains,
    $KL$ smooths the KL divergence on encoded features ($\bm{H}_{s}$, $\bm{H}_{t}$)
    across two domains, and $\mathcal{L}(\Theta)$ is a regularization term on trainable
    variables to reduce overfitting in the optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Deep alIgned autoencoder-based eMbEdding (DIME) [[105](#bib.bib105)] stacks
    AEs for the multiple aligned structures in heterogeneous social networks. It employs
    metapaths to represent different relations (heterogeneous links denoting $\mathcal{A}_{ij}$
    which represents anchor links between multiple aligned network $\mathcal{G}_{i}$
    and $\mathcal{G}_{j}$) and various attribute information $\mathcal{X}=\{\bm{X}_{i}\}$.
    Correspondingly, a set of meta proximity measurements are developed for each meta
    path and embed the close nodes to a close area in the low-dimensional latent feature
    space. The relatively close region reflects communities going to be detected.
  prefs: []
  type: TYPE_NORMAL
- en: VIII-B Sparse AE-based Community Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The sparsity commonly exists in real-world networks and causes computational
    difficulties in community detection algorithms. To solve these issues, sparse
    AEs [[106](#bib.bib106)] introduce a sparsity penalty $\Omega(\bm{h})$ in hidden
    layers $\bm{h}$. The reconstruction loss function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}(\bm{x},\phi_{r}(\phi_{e}(\bm{x})))+\Omega(\bm{h}).$
    |  | (18) |'
  prefs: []
  type: TYPE_TB
- en: 'Autoencoder-based Graph Clustering Model (GraphEncoder) [[107](#bib.bib107)]
    is the first work that uses AE for graph clustering. It processes the sparsity
    by a sparsity term as a part of the following loss function:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}(\Theta)=\sum\nolimits_{i}\&#124;\bm{\hat{x}_{i}}-\bm{x}_{i}\&#124;_{2}+\beta\Omega(\rho\&#124;\frac{1}{n}\sum\nolimits_{i}\bm{h}_{i}),$
    |  | (19) |'
  prefs: []
  type: TYPE_TB
- en: where the weight parameter $\beta$ controls the sparsity penalty $\Omega(\cdot\|\cdot)$
    over a configuration value $\rho$ (a small constraint such as $0.01$) and the
    average of hidden layers’ activation values. GraphEncoder improves the clustering
    efficiency of large-scale networks and proves that sparse networks can provide
    enough structural information for representations. A Weighted Community Detection
    model (WCD) [[108](#bib.bib108)] is further developed for weighted networks by
    sparse AE in second-order neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning-based Fuzzy Clustering Model (DFuzzy) [[109](#bib.bib109)] is
    proposed for detecting overlapping communities in sparse large-scale networks
    within a parallel processing framework. DFuzzy introduces a stacked sparse AE
    targeting head nodes to evolve overlapping and disjoint communities based on modularity
    measurements. DFuzzy performs 63% (Q) and 34% (CON) higher than non-deep learning
    baselines.
  prefs: []
  type: TYPE_NORMAL
- en: Community Detection Method via Ensemble Clustering (CDMEC) [[110](#bib.bib110)]
    combines sparse AEs with a transfer learning model to discover more valuable information
    from local network structures. To this end, CDMEC constructs four similarity matrices
    and employs transfer learning to share local information via AEs’ parameters.
    A consensus matrix is applied to aggregate community detection results, individually
    produced by four similarity matrices and supported by $k$-means. The final communities
    are globally determined based on the factorization of the consensus matrix.
  prefs: []
  type: TYPE_NORMAL
- en: VIII-C Denoising AE-based Community Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The denoising process, subtracting noises within DNN layers, can effectively
    enhance models’ robustness. Denoising AEs [[111](#bib.bib111)] minimize the reconstruction
    loss between the input $\bm{x}$ and AE features upon corrupt $\widetilde{\bm{x}}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}(\bm{x},\phi_{r}(\phi_{e}(\widetilde{\bm{x}}))).$ |  |
    (20) |'
  prefs: []
  type: TYPE_TB
- en: Deep Neural Networks for Graph Representation (DNGR) [[112](#bib.bib112)] applies
    stacked denoising encoder to increase the robustness of capturing the local structural
    information when detecting communities. Specifically, it generates a probabilistic
    co-occurrence matrix and a shifted positive pointwise MI matrix by randomly walking
    over communities. A Deep Neural network-based Clustering-oriented network network
    embedding (DNC) [[113](#bib.bib113)] is the extension of DNGR which joint learns
    node embeddings and cluster assignments.
  prefs: []
  type: TYPE_NORMAL
- en: To corrupted node attributes, Graph Clustering with dynamic Embedding (GRACE)
    [[68](#bib.bib68)] focuses on the dynamically changing inter-community activities
    via a self-training clustering guided by the influence propagation within neighborhoods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Marginalized Graph AutoEncoder (MGAE) [[111](#bib.bib111)] denoises both graph
    attributes and structures to improve community detection through the marginalization
    process. It obtains the corrupted attributes $\widetilde{\bm{X}}$ in $\eta$ times
    by randomly removing some attributes. The objective function in MGAE training
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}=\frac{1}{\eta}\sum\nolimits_{i=1}^{\eta}\&#124;\bm{X}-\widetilde{\bm{D}}^{-\frac{1}{2}}\widetilde{\bm{A}}\widetilde{\bm{D}}^{-\frac{1}{2}}\widetilde{\bm{X}}\bm{W}\&#124;_{2}+\lambda\mathcal{L}(\bm{W}),$
    |  | (21) |'
  prefs: []
  type: TYPE_TB
- en: where $\mathcal{L}(\bm{W})$ denotes a regularization term on AE’s parameters
    $\bm{W}$ with a coeffcient $\lambda$.
  prefs: []
  type: TYPE_NORMAL
- en: VIII-D Graph Convolutional AE-based Community Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It is a great success to introduce GCNs into AEs: GCNs provide by neighborhood
    aggregation over community representations, and AEs alleviate the over-smoothing
    issue in GCNs to clarify community boundaries. For example, Structural Deep Clustering
    Network (SDCN) [[114](#bib.bib114)] designs a delivery operator to connect AE
    and GCN in DNN layers for the structure-aware representations. When SDCN integrates
    the structural information into deep clustering, it updates communities by applying
    a dual self-supervised optimization in backpropagation.'
  prefs: []
  type: TYPE_NORMAL
- en: GCN-based approach for Unsupervised Community Detection (GUCD) [[115](#bib.bib115)]
    employs the semi-supervised MRF [[10](#bib.bib10)] as the encoder in the convolutional
    layer and proposes a community-centric dual decoder to identify communities in
    attributed networks. The dual decoder reconstructs the network topology and node
    attributes.
  prefs: []
  type: TYPE_NORMAL
- en: One2Multi Graph Autoencoder for Multi-view Graph Clustering (O2MAC) [[69](#bib.bib69)]
    deals with the multi-view graph by dividing it into multiple one-view graphs and
    assigning each with an AE, named One2Multi. In the encoder, a GCN is applied to
    embed a set of view-separated graphs. Decoders respectively for one-view graphs
    select the most informative graph to represent the multi-view graph. O2MAC significantly
    captures shared features among multi-view graphs and improves clustering results
    through a self-training optimization.
  prefs: []
  type: TYPE_NORMAL
- en: VIII-E Graph Attention AE-based Community Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Instead of integrating GCNs, this community detection category applies GATs
    into AEs, in which a GAT is employed as the encoder to rank the importance of
    nodes within a neighborhood. For example, Deep Attentional Embedded Graph Clustering
    (DAEGC) [[116](#bib.bib116)] exploits high-order neighbors to cluster communities
    under self-training. Graph Embedding Clustering with Cluster-Specificity Distribution
    (GEC-CSD) [[117](#bib.bib117)] utilizes graph attention AE as a generator to learn
    the distinguished community representations in the framework of adversarial learning
    integrating self-training, where discriminator can make sure the diversity of
    cluster distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering multi-view attributes in networks, Multi-View Attribute Graph Convolution
    Networks (MAGCN) [[118](#bib.bib118)] designs a two-pathway encoder: the first
    pathway encodes with a multi-view attribute GAT capable of denoising, and the
    second pathway develops a encoder to obtain consistent embeddings over multi-view
    attributes. Thus, noises and distribution variances are removed for community
    detection. Self-supervised Graph Convolutional network for Multi-view Clustering
    (SGCMC) [[119](#bib.bib119)] is developed from MAGCN through sharing a coefficient
    matrix in different views.'
  prefs: []
  type: TYPE_NORMAL
- en: Deep Multi-Graph Clustering (DMGC) [[120](#bib.bib120)] introduces AEs to represent
    each graph with an attention coefficient that node embeddings of multiple graphs
    cluster cross-graph centroids to obtain communities on Cauthy distribution.
  prefs: []
  type: TYPE_NORMAL
- en: VIII-F VAE-based Community Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Variational AutoEncoder (VAE) is an extension of AEs based on variational inference
    (e.g., mean and covariance of features) [[121](#bib.bib121)]. It is first introduced
    into the graph learning field by Variational Graph AutoEncoder (VGAE) [[122](#bib.bib122)]
    assuming prior distribution and applying GCN as the encoder, through which the
    learned representation $\bm{Z}$ is a latent distribution. Community detection
    based on VAEs is activated by algorithms such as SBM, to fast inference community
    memberships in node representations [[123](#bib.bib123)]. The inference process
    considers the uncertainty of the network [[124](#bib.bib124), [125](#bib.bib125)],
    e.g., community contradiction between neighbors of boundary nodes connecting multiple
    communities. VAEs are also required to handle sparsity in detecting communities.
    Meanwhile, VAEs easily incorporate deeper nonlinear relationship information.
    For example, Triad (Variational) Graph Autoencoder (TGA/TVGA) [[126](#bib.bib126)]
    replaces VAE/VGAE’s decoder with a new triad decoder, which describes a real-world
    existing triadic closure property in communities.
  prefs: []
  type: TYPE_NORMAL
- en: Variational Graph Embedding and Clustering with Laplacian Eigenmaps (VGECLE)
    [[124](#bib.bib124)] divides the graph representation into mean and covariance
    while generatively detecting communities, indicating each node’s uncertainty of
    implicit relationships to its actual geographic position. With a Mixture-of-Gaussian
    prior and a Teacher-Student (T-S) as regularization, VGECLE aims to let the node
    $v_{i}$ (student) learn a distribution close to its neighbors’ (teacher).
  prefs: []
  type: TYPE_NORMAL
- en: Deep Generative Latent Feature Relational Model (DGLFRM) [[123](#bib.bib123)]
    and Ladder Gamma Variational Autoencoder for Graphs (LGVG) [[127](#bib.bib127)]
    further capture the community membership strength on each node. DGLFRM models
    the sparse node embeddings by a Beta-Bernoulli process which can detect overlapping
    communities and infer the number of communities. LGVG is devised to learn the
    multi-layered and gamma-distributed embeddings so that it detects communities
    from fine-grained and coarse-grained granularities.
  prefs: []
  type: TYPE_NORMAL
- en: 'To capture the higher-order structural features of communities, Variational
    Graph Autoencoder for Community Detection (VGAECD) [[125](#bib.bib125)] employs
    a Gaussian Mixture Model (GMM) to generalize the network generation process via
    bringing in a parameter of community assignments. VGAECD defines the joint probability
    of generative process, it can be detailed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small p(\bm{a},\bm{z},c)=p(\bm{a}&#124;\bm{z})p(\bm{z}&#124;c)p(c),$
    |  | (22) |'
  prefs: []
  type: TYPE_TB
- en: 'where $p(c)=\pi_{c}$ denotes the prior probability of community $C_{c}$, $p(\bm{z}|c)$
    is calculated from the Gaussain distribution corresponding to community $C_{c}$
    with the mean $\mu_{c}$ and the standard deviation ${\sigma}_{c}$ from a GCN layer
    (i.e., $\bm{z}\sim\mathcal{N}(\mu_{c},{\sigma}_{c}^{2}\bm{I})$), and $\bm{a}$
    with the posterior (reconstruction) probability $p(\bm{a}|\bm{z})$ is sampled
    from the multivariate Bernoulli distribution parametrized by $\mu_{x}$ that is
    learned from the decoder on $\bm{z}$. The variational distribution can be obtained
    by the overall loss function as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}_{\mathrm{ELBO}}(\bm{x})=\mathbb{E}_{q(\bm{z}&#124;\bm{x},\bm{a})}[\log
    p(\bm{x},\bm{a}&#124;\bm{z})]-KL[q(c&#124;\bm{x})\&#124;p(c&#124;\bm{z})],$ |  |
    (23) |'
  prefs: []
  type: TYPE_TB
- en: where the first term calculates reconstruction loss, and $KL$ divergence minimizes
    the clustering loss. The evidence lower bound (ELBO) is maximized to optimize
    the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The training progress of VGAECD reveals a favoured treatment for minimizing
    the reconstruction loss over the community loss, which leads to a sub-optimal
    community detection result. To resolve it, Optimizing Variational Graph Autoencoder
    for Community Detection (VGAECD-OPT) [[124](#bib.bib124)] proposes a dual optimization
    to learn the community-aware latent representation, the ELBO maximization becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}_{\mathrm{ELBO}}(\bm{a})=\mathbb{E}_{q(\bm{z},c&#124;\bm{a})}[\log
    p(\bm{a}&#124;\bm{z})]-KL[q(\bm{z},c&#124;\bm{a})\&#124;p(\bm{z},c)].$ |  | (24)
    |'
  prefs: []
  type: TYPE_TB
- en: 'To the sparsity and noises in the real world, Adversarially Regularized Variational
    Graph AutoEncoder (ARVGA) [[128](#bib.bib128)] embeds the latent representations
    $\bm{Z}$ based on the prior distribution $p_{z}$ under the adversarial AE framework.
    $\bm{Z}$ is represented by a variational graph encoder aiming at a robust community
    detection. Meanwhile, a special discriminator $\phi_{d}$ is designed to decide
    adversarially on $p_{z}$ guided embeddings $\bm{Z}$ and encodings on real samples
    $\phi_{g}(\bm{X},\bm{A})$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\min_{\Theta_{g}}\max_{\Theta_{d}}$ | $\displaystyle\mathbb{E}_{\bm{z}\sim
    p_{z}}[\log\phi_{d}(\bm{Z})]$ |  | (25) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle+\mathbb{E}_{\bm{x}\sim p(\bm{x})}[\log(1-\phi_{d}(\phi_{g}(\bm{X},\bm{A})))].$
    |  |'
  prefs: []
  type: TYPE_TB
- en: IX Deep Nonnegative Matrix Factorization-based Community Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the network embedding domain, Nonnegative Matrix Factorization (NMF)[[129](#bib.bib129)]
    is a particular technique factorizing an adjacency matrix $\bm{A}$ into two nonnegative
    matrices ($\bm{U}\in\mathbb{R}^{n\times k}$ and $\bm{P}\in\mathbb{R}^{k\times
    n}$) with the nonnegative constraints that $\bm{U}\geq 0$ and $\bm{P}\geq 0$.
    The matrix $\bm{U}$ corresponds to the mapping between the given network and the
    community membership space. Each column in the matrix $\bm{P}=[p_{ij}]$ indicates
    the a community membership for each node $(v_{i},C_{j})$ in the probability of
    $p_{ij}$. NMF is applicable for disjoint and overlapping community detection.
    While real-world networks contain complicated topology information, the traditional
    NMF cannot fully uncover them to detect communities. Deep NMF (DNMF) [[130](#bib.bib130)]
    stacks multiple layers of NMF $\{\bm{U}_{1},\cdots,\bm{U}_{p}\}$ to capture pairwise
    node similarities in various levels/aspects, like deep layers in GCN and AE.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the community detection field, Deep Autoencoder-like Nonnegative Matrix
    Fatorization (DANMF) [[131](#bib.bib131)] is the influential model in an unsupervised
    learning setting. In contrast with the conventional NMF-based community detection
    mapping simple community membership, DANMF employs the AE framework to make network
    reconstruction on hierarchical mappings. The learning objective of community membership
    $\bm{P}_{p}$ and the hierarchical mappings $\{\bm{U}_{i}\}^{p}_{1}$ are trained
    by combining reconstruction losses and a $\lambda$ weighted graph regularization:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | <math  class="ltx_Math" alttext="\small\begin{aligned}
    \min_{\bm{P}_{p},\bm{U}_{i}}&amp;\mathcal{L}(\bm{P}_{p},\bm{U}_{i})=\&#124;\bm{A}-\bm{U}_{1}\cdots\bm{U}_{p}\bm{P}_{p}\&#124;_{F}^{2}\\
    &amp;+\&#124;\bm{P}_{p}-\bm{U}_{p}^{T}\cdots\bm{U}_{1}^{T}\bm{A}\&#124;_{F}^{2}+\lambda
    tr(\bm{P}_{p}\bm{L}\bm{P}_{p}^{T})\\'
  prefs: []
  type: TYPE_NORMAL
- en: \text{s.t.}~{}~{}&amp;\bm{P}_{p}\geq 0,\bm{U}_{i}\geq 0,\forall i=1,\cdots,p\end{aligned},"
    display="block"><semantics ><mrow  ><mtable
    columnspacing="0pt" displaystyle="true" rowspacing="0pt" 
    ><mtr  ><mtd
    class="ltx_align_right" columnalign="right"  ><munder
     ><mi mathsize="90%" 
    >min</mi><mrow 
    ><msub  ><mi
    mathsize="90%"  >𝑷</mi><mi
    mathsize="90%"  >p</mi></msub><mo
    mathsize="90%"  >,</mo><msub
     ><mi mathsize="90%"
     >𝑼</mi><mi
    mathsize="90%"  >i</mi></msub></mrow></munder></mtd><mtd
    class="ltx_align_left" columnalign="left"  ><mrow
     ><mrow 
    ><mi class="ltx_font_mathcaligraphic" mathsize="90%"
     >ℒ</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow
     ><mo maxsize="90%"
    minsize="90%"  >(</mo><msub
     ><mi mathsize="90%"
     >𝑷</mi><mi
    mathsize="90%"  >p</mi></msub><mo
    mathsize="90%"  >,</mo><msub
     ><mi mathsize="90%"
     >𝑼</mi><mi
    mathsize="90%"  >i</mi></msub><mo
    maxsize="90%" minsize="90%"  >)</mo></mrow></mrow><mo
    mathsize="90%"  >=</mo><msubsup
     ><mrow 
    ><mo maxsize="90%" minsize="90%" 
    >‖</mo><mrow 
    ><mi mathsize="90%" 
    >𝑨</mi><mo mathsize="90%" 
    >−</mo><mrow 
    ><msub 
    ><mi mathsize="90%" 
    >𝑼</mi><mn mathsize="90%" 
    >1</mn></msub><mo lspace="0em"
    rspace="0em"  >​</mo><mi
    mathsize="90%" mathvariant="normal"  >⋯</mi><mo
    lspace="0em" rspace="0em"  >​</mo><msub
     ><mi
    mathsize="90%"  >𝑼</mi><mi
    mathsize="90%"  >p</mi></msub><mo
    lspace="0em" rspace="0em"  >​</mo><msub
     ><mi
    mathsize="90%"  >𝑷</mi><mi
    mathsize="90%"  >p</mi></msub></mrow></mrow><mo
    maxsize="90%" minsize="90%"  >‖</mo></mrow><mi
    mathsize="90%"  >F</mi><mn
    mathsize="90%"  >2</mn></msubsup></mrow></mtd></mtr><mtr
     ><mtd class="ltx_align_left"
    columnalign="left"  ><mrow 
    ><mrow  ><mo
    mathsize="90%"  >+</mo><msubsup
     ><mrow 
    ><mo maxsize="90%" minsize="90%" 
    >‖</mo><mrow 
    ><msub 
    ><mi mathsize="90%" 
    >𝑷</mi><mi mathsize="90%" 
    >p</mi></msub><mo mathsize="90%"
     >−</mo><mrow
     ><msubsup
     ><mi
    mathsize="90%"  >𝑼</mi><mi
    mathsize="90%"  >p</mi><mi
    mathsize="90%"  >T</mi></msubsup><mo
    lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="90%" mathvariant="normal"  >⋯</mi><mo
    lspace="0em" rspace="0em"  >​</mo><msubsup
     ><mi
    mathsize="90%"  >𝑼</mi><mn
    mathsize="90%"  >1</mn><mi
    mathsize="90%"  >T</mi></msubsup><mo
    lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="90%"  >𝑨</mi></mrow></mrow><mo
    maxsize="90%" minsize="90%"  >‖</mo></mrow><mi
    mathsize="90%"  >F</mi><mn
    mathsize="90%"  >2</mn></msubsup></mrow><mo
    mathsize="90%"  >+</mo><mrow
     ><mi mathsize="90%"
     >λ</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi
    mathsize="90%"  >t</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="90%"  >r</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
     ><mo maxsize="90%"
    minsize="90%"  >(</mo><mrow
     ><msub
     ><mi
    mathsize="90%"  >𝑷</mi><mi
    mathsize="90%"  >p</mi></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="90%"  >𝑳</mi><mo
    lspace="0em" rspace="0em"  >​</mo><msubsup
     ><mi
    mathsize="90%"  >𝑷</mi><mi
    mathsize="90%"  >p</mi><mi
    mathsize="90%"  >T</mi></msubsup></mrow><mo
    maxsize="90%" minsize="90%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
     ><mtd class="ltx_align_right"
    columnalign="right"  ><mtext mathsize="90%"
     >s.t.</mtext></mtd><mtd
    class="ltx_align_left" columnalign="left"  ><mrow
     ><mrow 
    ><msub 
    ><mi mathsize="90%" 
    >𝑷</mi><mi mathsize="90%" 
    >p</mi></msub><mo mathsize="90%" 
    >≥</mo><mn mathsize="90%" 
    >0</mn></mrow><mo mathsize="90%" 
    >,</mo><mrow 
    ><mrow 
    ><msub 
    ><mi mathsize="90%" 
    >𝑼</mi><mi mathsize="90%" 
    >i</mi></msub><mo mathsize="90%"
     >≥</mo><mn
    mathsize="90%"  >0</mn></mrow><mo
    mathsize="90%"  >,</mo><mrow
     ><mrow
     ><mo
    mathsize="90%" rspace="0.167em"  >∀</mo><mi
    mathsize="90%"  >i</mi></mrow><mo
    mathsize="90%"  >=</mo><mrow
     ><mn
    mathsize="90%"  >1</mn><mo
    mathsize="90%"  >,</mo><mi
    mathsize="90%" mathvariant="normal"  >⋯</mi><mo
    mathsize="90%"  >,</mo><mi
    mathsize="90%"  >p</mi></mrow></mrow></mrow></mrow></mtd></mtr></mtable><mo
    mathsize="90%"  >,</mo></mrow><annotation-xml
    encoding="MathML-Content" ><matrix 
    ><matrixrow  ><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><list
     ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑷</ci><ci 
    >𝑝</ci></apply><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑼</ci><ci 
    >𝑖</ci></apply></list></apply><apply 
    ><apply  ><ci
     >ℒ</ci><interval
    closure="open"  ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑷</ci><ci
     >𝑝</ci></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑼</ci><ci
     >𝑖</ci></apply></interval></apply><apply
     ><csymbol cd="ambiguous"
     >superscript</csymbol><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><apply
     ><csymbol
    cd="latexml"  >norm</csymbol><apply
     ><ci
     >𝑨</ci><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑼</ci><cn
    type="integer"  >1</cn></apply><ci
     >⋯</ci><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑼</ci><ci
     >𝑝</ci></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑷</ci><ci
     >𝑝</ci></apply></apply></apply></apply><ci
     >𝐹</ci></apply><cn
    type="integer"  >2</cn></apply></apply></matrixrow><matrixrow
     ><cerror 
    ><csymbol cd="ambiguous"  >missing-subexpression</csymbol></cerror><apply
     ><apply 
    ><apply  ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><apply
     ><csymbol
    cd="latexml"  >norm</csymbol><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑷</ci><ci
     >𝑝</ci></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑼</ci><ci
     >𝑝</ci></apply><ci
     >𝑇</ci></apply><ci
     >⋯</ci><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑼</ci><cn
    type="integer"  >1</cn></apply><ci
     >𝑇</ci></apply><ci
     >𝑨</ci></apply></apply></apply><ci
     >𝐹</ci></apply><cn
    type="integer"  >2</cn></apply></apply><apply
     ><ci 
    >𝜆</ci><ci  >𝑡</ci><ci
     >𝑟</ci><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑷</ci><ci
     >𝑝</ci></apply><ci
     >𝑳</ci><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑷</ci><ci
     >𝑝</ci></apply><ci
     >𝑇</ci></apply></apply></apply></apply></matrixrow><matrixrow
     ><ci 
    ><mtext mathsize="90%" 
    >s.t.</mtext></ci><apply 
    ><csymbol cd="ambiguous" 
    >formulae-sequence</csymbol><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑷</ci><ci 
    >𝑝</ci></apply><cn type="integer" 
    >0</cn></apply><apply 
    ><csymbol cd="ambiguous" 
    >formulae-sequence</csymbol><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑼</ci><ci 
    >𝑖</ci></apply><cn type="integer" 
    >0</cn></apply><apply 
    ><apply 
    ><csymbol cd="latexml" 
    >for-all</csymbol><ci 
    >𝑖</ci></apply><list 
    ><cn type="integer" 
    >1</cn><ci  >⋯</ci><ci
     >𝑝</ci></list></apply></apply></apply></matrixrow></matrix></annotation-xml><annotation
    encoding="application/x-tex" >\small\begin{aligned} \min_{\bm{P}_{p},\bm{U}_{i}}&\mathcal{L}(\bm{P}_{p},\bm{U}_{i})=\&#124;\bm{A}-\bm{U}_{1}\cdots\bm{U}_{p}\bm{P}_{p}\&#124;_{F}^{2}\\
    &+\&#124;\bm{P}_{p}-\bm{U}_{p}^{T}\cdots\bm{U}_{1}^{T}\bm{A}\&#124;_{F}^{2}+\lambda
    tr(\bm{P}_{p}\bm{L}\bm{P}_{p}^{T})\\ \text{s.t.}~{}~{}&\bm{P}_{p}\geq 0,\bm{U}_{i}\geq
    0,\forall i=1,\cdots,p\end{aligned},</annotation></semantics></math> |  | (26)
    |
  prefs: []
  type: TYPE_NORMAL
- en: where $\|\cdot\|_{F}$ denotes the Frobenius norm, $\bm{L}$ represents the graph
    Laplacian matrix, and graph regularization focuses on the network topological
    similarity to cluster neighboring nodes. A further work [[132](#bib.bib132)] adds
    a sparsity constraint into the above DNMF-based community detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although DNMF provides a solution to map multiple factors in forming communities,
    the computational cost is relatively high on matrix factorizations. To address
    this issue, Modularized Deep Nonnegative Matrix Factorization (MDNMF) [[133](#bib.bib133)]
    applies modularity (details in Eq. ([36](#A3.E36 "In Appendix C Detailed DESCRIPTION:
    Evaluation Metrics ‣ A Comprehensive Survey on Community Detection with Deep Learning")))
    directly into a basic multi-layer deep learning structure targeting community
    detection. The node membership in communities $\bm{P}_{p}$ can be reached by minimizing
    the objective function below:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | <math  class="ltx_Math" alttext="\small\begin{aligned}
    \mathcal{L}=&amp;\&#124;\bm{A}-\bm{U}_{1}\cdots\bm{U}_{p}\bm{P}_{p}\&#124;_{F}^{2}+\alpha\&#124;\bm{M^{\prime}}-\bm{P}_{p}^{T}\bm{K}^{T}\&#124;_{F}^{2}\\
    &amp;-\beta tr(\bm{M^{\prime}}^{T}\bm{BM^{\prime}})+\lambda tr(\bm{P}_{p}\bm{L}\bm{P}_{p}^{T})\\'
  prefs: []
  type: TYPE_NORMAL
- en: \textrm{s.t.}~{}~{}&amp;\quad\bm{P}_{p}\geq 0,\bm{U}_{i}\geq 0,\forall i=1,...,p\end{aligned},"
    display="block"><semantics ><mrow  ><mtable
    columnspacing="0pt" displaystyle="true" rowspacing="0pt"  ><mtr
     ><mtd class="ltx_align_right" columnalign="right"
     ><mrow  ><mi
    class="ltx_font_mathcaligraphic" mathsize="90%"  >ℒ</mi><mo
    mathsize="90%"  >=</mo></mrow></mtd><mtd
    class="ltx_align_left" columnalign="left"  ><mrow
     ><msubsup 
    ><mrow  ><mo
    maxsize="90%" minsize="90%"  >‖</mo><mrow
     ><mi
    mathsize="90%"  >𝑨</mi><mo
    mathsize="90%"  >−</mo><mrow
     ><msub
     ><mi
    mathsize="90%"  >𝑼</mi><mn
    mathsize="90%"  >1</mn></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="90%" mathvariant="normal"  >⋯</mi><mo
    lspace="0em" rspace="0em"  >​</mo><msub
     ><mi
    mathsize="90%"  >𝑼</mi><mi
    mathsize="90%"  >p</mi></msub><mo
    lspace="0em" rspace="0em"  >​</mo><msub
     ><mi
    mathsize="90%"  >𝑷</mi><mi
    mathsize="90%"  >p</mi></msub></mrow></mrow><mo
    maxsize="90%" minsize="90%"  >‖</mo></mrow><mi
    mathsize="90%"  >F</mi><mn
    mathsize="90%"  >2</mn></msubsup><mo
    mathsize="90%"  >+</mo><mrow
     ><mi mathsize="90%"
     >α</mi><mo lspace="0em"
    rspace="0em"  >​</mo><msubsup
     ><mrow 
    ><mo maxsize="90%" minsize="90%" 
    >‖</mo><mrow 
    ><msup 
    ><mi mathsize="90%" 
    >𝑴</mi><mo class="ltx_mathvariant_bold"
    mathsize="90%" mathvariant="bold"  >′</mo></msup><mo
    mathsize="90%"  >−</mo><mrow
     ><msubsup
     ><mi
    mathsize="90%"  >𝑷</mi><mi
    mathsize="90%"  >p</mi><mi
    mathsize="90%"  >T</mi></msubsup><mo
    lspace="0em" rspace="0em"  >​</mo><msup
     ><mi
    mathsize="90%"  >𝑲</mi><mi
    mathsize="90%"  >T</mi></msup></mrow></mrow><mo
    maxsize="90%" minsize="90%"  >‖</mo></mrow><mi
    mathsize="90%"  >F</mi><mn
    mathsize="90%"  >2</mn></msubsup></mrow></mrow></mtd></mtr><mtr
     ><mtd class="ltx_align_left" columnalign="left"
     ><mrow  ><mrow
     ><mo mathsize="90%"
     >−</mo><mrow 
    ><mi mathsize="90%" 
    >β</mi><mo lspace="0em" rspace="0em" 
    >​</mo><mi mathsize="90%" 
    >t</mi><mo lspace="0em" rspace="0em" 
    >​</mo><mi mathsize="90%" 
    >r</mi><mo lspace="0em" rspace="0em" 
    >​</mo><mrow 
    ><mo maxsize="90%" minsize="90%" 
    >(</mo><mrow 
    ><mmultiscripts 
    ><mi mathsize="90%" 
    >𝑴</mi><mo class="ltx_mathvariant_bold"
    mathsize="90%" mathvariant="bold"  >′</mo><mi
    mathsize="90%"  >T</mi></mmultiscripts><mo
    lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="90%"  >𝑩</mi><mo
    lspace="0em" rspace="0em"  >​</mo><msup
     ><mi
    mathsize="90%"  >𝑴</mi><mo
    class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" 
    >′</mo></msup></mrow><mo maxsize="90%"
    minsize="90%"  >)</mo></mrow></mrow></mrow><mo
    mathsize="90%"  >+</mo><mrow
     ><mi mathsize="90%"
     >λ</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi
    mathsize="90%"  >t</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="90%"  >r</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
     ><mo maxsize="90%"
    minsize="90%"  >(</mo><mrow
     ><msub
     ><mi
    mathsize="90%"  >𝑷</mi><mi
    mathsize="90%"  >p</mi></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mi
    mathsize="90%"  >𝑳</mi><mo
    lspace="0em" rspace="0em"  >​</mo><msubsup
     ><mi
    mathsize="90%"  >𝑷</mi><mi
    mathsize="90%"  >p</mi><mi
    mathsize="90%"  >T</mi></msubsup></mrow><mo
    maxsize="90%" minsize="90%"  >)</mo></mrow></mrow></mrow></mtd></mtr><mtr
     ><mtd class="ltx_align_right" columnalign="right"
     ><mtext mathsize="90%" 
    >s.t.</mtext></mtd><mtd class="ltx_align_left"
    columnalign="left"  ><mrow 
    ><mrow  ><msub
     ><mi mathsize="90%"
     >𝑷</mi><mi
    mathsize="90%"  >p</mi></msub><mo
    mathsize="90%"  >≥</mo><mn
    mathsize="90%"  >0</mn></mrow><mo
    mathsize="90%"  >,</mo><mrow
     ><mrow 
    ><msub 
    ><mi mathsize="90%" 
    >𝑼</mi><mi mathsize="90%" 
    >i</mi></msub><mo mathsize="90%" 
    >≥</mo><mn mathsize="90%" 
    >0</mn></mrow><mo mathsize="90%" 
    >,</mo><mrow 
    ><mrow 
    ><mo mathsize="90%" rspace="0.167em"
     >∀</mo><mi
    mathsize="90%"  >i</mi></mrow><mo
    mathsize="90%"  >=</mo><mrow
     ><mn
    mathsize="90%"  >1</mn><mo
    mathsize="90%"  >,</mo><mi
    mathsize="90%" mathvariant="normal"  >…</mi><mo
    mathsize="90%"  >,</mo><mi
    mathsize="90%"  >p</mi></mrow></mrow></mrow></mrow></mtd></mtr></mtable><mo
    mathsize="90%"  >,</mo></mrow><annotation-xml
    encoding="MathML-Content" ><matrix  ><matrixrow
     ><apply 
    ><ci  >ℒ</ci><csymbol
    cd="latexml"  >absent</csymbol></apply><apply
     ><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><csymbol cd="latexml" 
    >norm</csymbol><apply 
    ><ci 
    >𝑨</ci><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑼</ci><cn type="integer" 
    >1</cn></apply><ci 
    >⋯</ci><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑼</ci><ci 
    >𝑝</ci></apply><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑷</ci><ci 
    >𝑝</ci></apply></apply></apply></apply><ci
     >𝐹</ci></apply><cn
    type="integer"  >2</cn></apply><apply
     ><ci 
    >𝛼</ci><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><apply 
    ><csymbol cd="latexml" 
    >norm</csymbol><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >𝑴</ci><ci 
    >bold-′</ci></apply><apply 
    ><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑷</ci><ci 
    >𝑝</ci></apply><ci 
    >𝑇</ci></apply><apply 
    ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >𝑲</ci><ci 
    >𝑇</ci></apply></apply></apply></apply><ci
     >𝐹</ci></apply><cn
    type="integer"  >2</cn></apply></apply></apply></matrixrow><matrixrow
     ><cerror 
    ><csymbol cd="ambiguous"  >missing-subexpression</csymbol></cerror><apply
     ><apply 
    ><apply  ><ci
     >𝛽</ci><ci
     >𝑡</ci><ci
     >𝑟</ci><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >𝑴</ci><ci
     >bold-′</ci></apply><ci
     >𝑇</ci></apply><ci
     >𝑩</ci><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><ci
     >𝑴</ci><ci
     >bold-′</ci></apply></apply></apply></apply><apply
     ><ci 
    >𝜆</ci><ci  >𝑡</ci><ci
     >𝑟</ci><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑷</ci><ci
     >𝑝</ci></apply><ci
     >𝑳</ci><apply
     ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑷</ci><ci
     >𝑝</ci></apply><ci
     >𝑇</ci></apply></apply></apply></apply></matrixrow><matrixrow
     ><ci 
    ><mtext mathsize="90%" 
    >s.t.</mtext></ci><apply 
    ><csymbol cd="ambiguous" 
    >formulae-sequence</csymbol><apply 
    ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑷</ci><ci
     >𝑝</ci></apply><cn
    type="integer"  >0</cn></apply><apply
     ><csymbol
    cd="ambiguous"  >formulae-sequence</csymbol><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑼</ci><ci
     >𝑖</ci></apply><cn
    type="integer"  >0</cn></apply><apply
     ><apply
     ><csymbol
    cd="latexml"  >for-all</csymbol><ci
     >𝑖</ci></apply><list
     ><cn
    type="integer"  >1</cn><ci
     >…</ci><ci 
    >𝑝</ci></list></apply></apply></apply></matrixrow></matrix></annotation-xml><annotation
    encoding="application/x-tex" >\small\begin{aligned} \mathcal{L}=&\&#124;\bm{A}-\bm{U}_{1}\cdots\bm{U}_{p}\bm{P}_{p}\&#124;_{F}^{2}+\alpha\&#124;\bm{M^{\prime}}-\bm{P}_{p}^{T}\bm{K}^{T}\&#124;_{F}^{2}\\
    &-\beta tr(\bm{M^{\prime}}^{T}\bm{BM^{\prime}})+\lambda tr(\bm{P}_{p}\bm{L}\bm{P}_{p}^{T})\\
    \textrm{s.t.}~{}~{}&\quad\bm{P}_{p}\geq 0,\bm{U}_{i}\geq 0,\forall i=1,...,p\end{aligned},</annotation></semantics></math>
    |  | (27) |
  prefs: []
  type: TYPE_NORMAL
- en: where $\bm{B}$ and $\bm{M^{\prime}}$ are modularity matrix and the corresponding
    community membership matrix, $\bm{K}$ is an extra nonnegative matrix combining
    modularity information so that DNMF can explore the hidden features of network
    topology.
  prefs: []
  type: TYPE_NORMAL
- en: X Deep Sparse Filtering-based Community Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sparse Filtering (SF)[[134](#bib.bib134)] is a two-layer learning model capable
    of handling high-dimensional graph data. The high sparse input $\bm{A}$ with many
    $0$ elements is represented into lower-dimensional feature vectors $\bm{h}_{i}$
    with non-zero values. To explore deeper information such as community membership,
    Deep SF (DSF) stacks multiple hidden layers to finetune hyperparameters $\Theta$
    and extensively smooth data distributions $Pr(\bm{h}_{i})$.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a representative method, Community Discovery based on Deep Sparse Filtering
    (DSFCD) [[135](#bib.bib135)] is developed on three phases: network representation,
    community feature mapping and community discovery. The network representation
    phase performs on the adjacency matrix $\bm{A}$, modularity matrix $\bm{B}$ and
    two similarity matrices $\bm{S}$ and $\bm{S}^{\prime}$, respectively. The best
    representation is selected to input into the DSF for community feature mapping
    represented on each node $\bm{h}_{i}$. Meanwhile, $\bm{h}_{i}$ preserves the node
    similarity in the original network $\bm{A}$ and latent community membership features.
    The node similarity is modeled in the loss function:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\mathcal{L}=\sum\nolimits_{i}\&#124;\bm{h}_{i}\&#124;_{1}+\lambda\sum\nolimits_{i}KL(\bm{h}_{i},\bm{h}^{*}_{j}),$
    |  | (28) |'
  prefs: []
  type: TYPE_TB
- en: where $\|\cdot\|_{1}$ is the $L_{1}$ norm penalty to optimize sparseness, $\bm{h}^{*}_{j}$
    denotes the representation of the most similar node to $v_{i}$ by measuring distances
    through KL divergence. When the learning process is optimized on the minimized
    loss, similar nodes are clustered into communities. The DSF architecture is investigated
    to be significant in experiments on real-world data sets. DSFCD discovers communities
    in higher accuracy than SF.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE II: Summary of commonly used evaluation metrics in community detection.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Metrics | Overlap | Ground Truth | Publications |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | [[70](#bib.bib70), [10](#bib.bib10), [81](#bib.bib81), [87](#bib.bib87),
    [64](#bib.bib64), [84](#bib.bib84), [82](#bib.bib82), [95](#bib.bib95), [66](#bib.bib66),
    [62](#bib.bib62), [103](#bib.bib103), [102](#bib.bib102), [111](#bib.bib111),
    [69](#bib.bib69), [85](#bib.bib85), [115](#bib.bib115), [114](#bib.bib114), [116](#bib.bib116),
    [118](#bib.bib118), [120](#bib.bib120), [79](#bib.bib79), [86](#bib.bib86), [88](#bib.bib88),
    [113](#bib.bib113), [117](#bib.bib117), [119](#bib.bib119)], |'
  prefs: []
  type: TYPE_TB
- en: '| ACC | $\checkmark$ | Yes | [[124](#bib.bib124), [126](#bib.bib126), [125](#bib.bib125),
    [136](#bib.bib136), [128](#bib.bib128), [133](#bib.bib133), [131](#bib.bib131)]
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | [[8](#bib.bib8), [77](#bib.bib77), [10](#bib.bib10), [73](#bib.bib73),
    [79](#bib.bib79), [86](#bib.bib86), [88](#bib.bib88), [80](#bib.bib80), [81](#bib.bib81),
    [87](#bib.bib87), [92](#bib.bib92), [64](#bib.bib64), [84](#bib.bib84), [82](#bib.bib82),
    [61](#bib.bib61), [72](#bib.bib72), [95](#bib.bib95), [66](#bib.bib66), [62](#bib.bib62),
    [96](#bib.bib96), [63](#bib.bib63), [104](#bib.bib104), [102](#bib.bib102), [107](#bib.bib107)],
    |'
  prefs: []
  type: TYPE_TB
- en: '| NMI | $\times$ | Yes | [[110](#bib.bib110), [112](#bib.bib112), [111](#bib.bib111),
    [113](#bib.bib113), [117](#bib.bib117), [119](#bib.bib119)] |'
  prefs: []
  type: TYPE_TB
- en: '| Overlapping-NMI | $\checkmark$ |  | [[115](#bib.bib115), [114](#bib.bib114),
    [69](#bib.bib69), [116](#bib.bib116), [118](#bib.bib118), [120](#bib.bib120),
    [126](#bib.bib126), [125](#bib.bib125), [136](#bib.bib136), [128](#bib.bib128),
    [133](#bib.bib133), [131](#bib.bib131), [65](#bib.bib65), [91](#bib.bib91)] |'
  prefs: []
  type: TYPE_TB
- en: '| Precision | $\checkmark$ | Yes | [[8](#bib.bib8), [81](#bib.bib81), [82](#bib.bib82),
    [95](#bib.bib95), [62](#bib.bib62), [111](#bib.bib111), [126](#bib.bib126), [128](#bib.bib128)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Recall | $\checkmark$ | Yes | [[111](#bib.bib111)] |'
  prefs: []
  type: TYPE_TB
- en: '| F1-Score | $\checkmark$ | Yes | [[77](#bib.bib77), [81](#bib.bib81), [87](#bib.bib87),
    [64](#bib.bib64), [82](#bib.bib82), [61](#bib.bib61), [94](#bib.bib94), [95](#bib.bib95),
    [62](#bib.bib62), [96](#bib.bib96), [68](#bib.bib68), [111](#bib.bib111), [114](#bib.bib114),
    [69](#bib.bib69), [116](#bib.bib116), [126](#bib.bib126), [128](#bib.bib128),
    [76](#bib.bib76), [92](#bib.bib92)] |'
  prefs: []
  type: TYPE_TB
- en: '| ARI | $\checkmark$ | Yes | [[81](#bib.bib81), [87](#bib.bib87), [84](#bib.bib84),
    [82](#bib.bib82), [72](#bib.bib72), [62](#bib.bib62), [111](#bib.bib111), [114](#bib.bib114),
    [69](#bib.bib69), [116](#bib.bib116), [118](#bib.bib118), [126](#bib.bib126),
    [128](#bib.bib128), [131](#bib.bib131), [91](#bib.bib91), [86](#bib.bib86), [88](#bib.bib88),
    [92](#bib.bib92), [113](#bib.bib113), [117](#bib.bib117), [119](#bib.bib119)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Q | $\times$ |  | [[104](#bib.bib104), [73](#bib.bib73), [109](#bib.bib109),
    [110](#bib.bib110), [125](#bib.bib125), [136](#bib.bib136), [108](#bib.bib108)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Extended-Q | $\checkmark$ | No | [[98](#bib.bib98)] |'
  prefs: []
  type: TYPE_TB
- en: '| Jaccard | $\checkmark$ | Yes | [[8](#bib.bib8), [94](#bib.bib94), [68](#bib.bib68)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| CON | $\checkmark$ | No | [[125](#bib.bib125), [136](#bib.bib136), [97](#bib.bib97)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| TPR | $\checkmark$ | No | [[125](#bib.bib125), [136](#bib.bib136)] |'
  prefs: []
  type: TYPE_TB
- en: '| “Overlap” indicates whether the metric can evaluate the overlapping community
    that is defined in Section [II](#S2 "II Definitions and Preliminaries ‣ A Comprehensive
    Survey on Community Detection with Deep Learning"). “Ground Truth” indicates whether
    the actual community structure of the network is required. |'
  prefs: []
  type: TYPE_TB
- en: 'TABLE III: Summary of open-source implementations.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Category | Tool | Method | URL |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | AGE[[84](#bib.bib84)] | [https://github.com/thunlp/AGE](https://github.com/thunlp/AGE)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | LGNN[[78](#bib.bib78)] | [https://github.com/zhengdao-chen/GNN4CD](https://github.com/zhengdao-chen/GNN4CD)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | PyTorch | NOCD[[80](#bib.bib80)] | [https://github.com/shchur/overlapping-community-detection](https://github.com/shchur/overlapping-community-detection)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | AGC[[64](#bib.bib64)] | [https://github.com/karenlatong/AGC-master](https://github.com/karenlatong/AGC-master)
    |'
  prefs: []
  type: TYPE_TB
- en: '| GCN | TensorFlow | CayleyNet[[85](#bib.bib85)] | [https://github.com/amoliu/CayleyNet](https://github.com/amoliu/CayleyNet)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | CP-GNN [[92](#bib.bib92)] | [https://github.com/RManLuo/CP-GNN](https://github.com/RManLuo/CP-GNN)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | DMGI[[61](#bib.bib61)] | [https://github.com/pcy1302/DMGI](https://github.com/pcy1302/DMGI)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | MAGNN[[72](#bib.bib72)] | [https://github.com/cynricfu/MAGNN](https://github.com/cynricfu/MAGNN)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | HDMI [[65](#bib.bib65)] | [https://github.com/baoyujing/HDMI](https://github.com/baoyujing/HDMI)
    |'
  prefs: []
  type: TYPE_TB
- en: '| GAT | PyTorch | HeCo [[91](#bib.bib91)] | [https://github.com/liun-online/HeCo](https://github.com/liun-online/HeCo)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | PyTorch | SEAL[[94](#bib.bib94)] | [https://github.com/yzhang1918/kdd2020seal](https://github.com/yzhang1918/kdd2020seal)
    |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | TensorFlow | CommunityGAN[[96](#bib.bib96)] | [https://github.com/SamJia/CommunityGAN](https://github.com/SamJia/CommunityGAN)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | DANE[[103](#bib.bib103)] | [https://github.com/gaoghc/DANE](https://github.com/gaoghc/DANE)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | TensorFlow | DIME[[105](#bib.bib105)] | [http://www.ifmlab.org/files/code/Aligned-Autoencoder.zip](http://www.ifmlab.org/files/code/Aligned-Autoencoder.zip)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | [https://github.com/shenxiaocam/Deep-network-embedding-for-](https://github.com/shenxiaocam/Deep-network-embedding-for-graph-representation-learning-in-signed-networks)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | DNE-SBP[[67](#bib.bib67)] | [graph-representation-learning-in-signed-networks](https://github.com/shenxiaocam/Deep-network-embedding-for-graph-representation-learning-in-signed-networks)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Stacked AE | Matlab | semi-DRN[[63](#bib.bib63)] | [http://yangliang.github.io/code/DC.zip](http://yangliang.github.io/code/DC.zip)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Sparse AE | PyTorch | GraphEncoder[[107](#bib.bib107)] | [https://github.com/zepx/graphencoder](https://github.com/zepx/graphencoder)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Keras | DNGR[[112](#bib.bib112)] | [https://github.com/MdAsifKhan/DNGR-Keras](https://github.com/MdAsifKhan/DNGR-Keras)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Denoising AE | Matlab | MGAE[[111](#bib.bib111)] | [https://github.com/FakeTibbers/MGAE](https://github.com/FakeTibbers/MGAE)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | PyTorch | SDCN[[114](#bib.bib114)] | [https://github.com/bdy9527/SDCN](https://github.com/bdy9527/SDCN)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Graph Convolutional AE | TensorFlow | O2MAC[[69](#bib.bib69)] | [https://github.com/songzuolong/WWW2020-O2MAC](https://github.com/songzuolong/WWW2020-O2MAC)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Graph Attention |  | DMGC[[120](#bib.bib120)] | [https://github.com/flyingdoog/DMGC](https://github.com/flyingdoog/DMGC)
    |'
  prefs: []
  type: TYPE_TB
- en: '| AE | TensorFlow | SGCMC[[119](#bib.bib119)] | [https://github.com/xdweixia/SGCMC](https://github.com/xdweixia/SGCMC)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Variational |  | ARGA/ARVGA[[128](#bib.bib128)] | [https://github.com/Ruiqi-Hu/ARGA](https://github.com/Ruiqi-Hu/ARGA)
    |'
  prefs: []
  type: TYPE_TB
- en: '| AE | TensorFlow | DGLFRM[[123](#bib.bib123)] | [https://github.com/nikhil-dce/SBM-meet-GNN](https://github.com/nikhil-dce/SBM-meet-GNN)
    |'
  prefs: []
  type: TYPE_TB
- en: XI Published Resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'From surveyed literature in Sections [V](#S5 "V Convolutional Network-based
    Community Detection ‣ A Comprehensive Survey on Community Detection with Deep
    Learning")–[X](#S10 "X Deep Sparse Filtering-based Community Detection ‣ A Comprehensive
    Survey on Community Detection with Deep Learning"), the popular and available
    benchmark data sets, evaluation metrics and open-source implementations are summarized
    in this section with details in APPENDIX [B](#A2 "Appendix B Detailed description:
    Data Sets ‣ A Comprehensive Survey on Community Detection with Deep Learning")–[D](#A4
    "Appendix D Detailed description: Open-source Implementations ‣ A Comprehensive
    Survey on Community Detection with Deep Learning").'
  prefs: []
  type: TYPE_NORMAL
- en: XI-A Data Sets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Both real-world data sets and synthetic data sets are popularly published.
    Real-world data sets in community detection experiments are collected from real-world
    applications, which test performances of proposed methods from the real applicable
    aspect. Synthetic data sets are generated by specific models on manually designed
    rules, and particular functions can be tested by these data sets. The state-of-the-art
    popular real-world data sets can be categorized into citation/co-authorship networks,
    social networks (online and offline), webpage networks and product co-purchasing
    networks. The typical data sets covering various network shapes (i.e., unattributed,
    attributed, multi-view, signed, heterogeneous and dynamic) are summarized in TABLE
    [IX](#A2.T9 "TABLE IX ‣ B-A Real-world Data Sets ‣ Appendix B Detailed description:
    Data Sets ‣ A Comprehensive Survey on Community Detection with Deep Learning").
    The related description is detailed in APPENDIX [B](#A2 "Appendix B Detailed description:
    Data Sets ‣ A Comprehensive Survey on Community Detection with Deep Learning")
    (Real-world Data Sets). Girvan-Newman (GN) networks [[3](#bib.bib3)] and Lancichinetti–Fortunato–Radicchi
    (LFR) networks [[137](#bib.bib137)] are two widely applied synthetic benchmarks,
    described in APPENDIX [B](#A2 "Appendix B Detailed description: Data Sets ‣ A
    Comprehensive Survey on Community Detection with Deep Learning") (Synthetic Benchmark
    Data Sets).'
  prefs: []
  type: TYPE_NORMAL
- en: XI-B Evaluation Metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This section summarizes twelve most popular and commonly applied evaluation
    metrics from the reviewed deep community detection literature (details in APPENDIX
    [C](#A3 "Appendix C Detailed DESCRIPTION: Evaluation Metrics ‣ A Comprehensive
    Survey on Community Detection with Deep Learning")). Evaluations on detection
    performances vary in community types (i.e., disjoint or overlapping) and ground
    truth (i.e., available or lacking). We summarize “Publications” by metrics in
    TABLE [II](#S10.T2 "TABLE II ‣ X Deep Sparse Filtering-based Community Detection
    ‣ A Comprehensive Survey on Community Detection with Deep Learning") over “Overlap”
    and “Ground Truth”.'
  prefs: []
  type: TYPE_NORMAL
- en: XI-C Open-source Implementations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The open-source implementations are summarized by tool, category, repository
    link in TABLE [III](#S10.T3 "TABLE III ‣ X Deep Sparse Filtering-based Community
    Detection ‣ A Comprehensive Survey on Community Detection with Deep Learning").
    The majority of implementations are under Python 3.x, including PyTorch, TensorFlow
    and Keras. There are a few implementations that use Matlab. Each implementation
    project is briefly described and organized by implementation tools and deep learning
    models in APPENDIX [D](#A4 "Appendix D Detailed description: Open-source Implementations
    ‣ A Comprehensive Survey on Community Detection with Deep Learning").'
  prefs: []
  type: TYPE_NORMAL
- en: XII Practical Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Community detection has many applications across different tasks and domains,
    as summarized in Fig. [9](#S12.F9 "Figure 9 ‣ XII Practical Applications ‣ A Comprehensive
    Survey on Community Detection with Deep Learning"). We now detail some typical
    applications in the following areas.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation Systems. Community structure plays a vital role for graph-based
    recommendation systems [[138](#bib.bib138), [139](#bib.bib139)], as the community
    members may have similar interests and preferences. By detecting relations between
    nodes (i.e., users–users, items–tems, users–items), models such as CayleyNets
    [[85](#bib.bib85)] and UWMNE/WMCNE-LE [[102](#bib.bib102)] produce high-quality
    recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: Biochemistry. In this field, nodes represent proteins or atoms in compound and
    molecule graphs, while edges denote their interactions. Community detection can
    identify complexes of new proteins [[8](#bib.bib8), [107](#bib.bib107)] and chemical
    compounds which are functional in regional organs (e.g., in brain [[140](#bib.bib140)])
    or pathogenic factor of a disease (e.g., community-based lung cancer detection
    [[141](#bib.bib141)]). To various tumor types on genomic data sets, the previous
    study [[142](#bib.bib142)] shows relevances between communities’ survival rates
    and distributions of tumor types over communities.
  prefs: []
  type: TYPE_NORMAL
- en: Online Social Networks. Analyzing online social activities can identify online
    communities and correlate them in the real world. The practice on online social
    networks [[3](#bib.bib3)] such as Twitter, LinkedIn and Facebook reveals similar
    interests among online users that individual preferences can be automatically
    provided. Meanwhile, community detection can be used for online privacy [[143](#bib.bib143)]
    and to identify criminals based on online social behaviors [[144](#bib.bib144)],
    who support and diffuse criminal ideas and even who may practice terrorism activities
    [[145](#bib.bib145)].
  prefs: []
  type: TYPE_NORMAL
- en: Community Deception. To hide from the community detection, community deception
    [[146](#bib.bib146)] covers a group of users in social networks such as Facebook.
    Deception is either harmful to virtual communities or harmless that provides justifiable
    benefits. From community-based structural entropy, Residual Entropy Minimization
    (REM) effectively nullify community detection algorithms [[147](#bib.bib147)].
    A systematic evaluation [[148](#bib.bib148)] on community detection robustness
    to deception is carried out in large networks.
  prefs: []
  type: TYPE_NORMAL
- en: Community Search. Community search aims to queue up a series of nodes dependent
    on communities [[15](#bib.bib15)]. For example, a user (node) search on interests
    (communities) after another user (node). To this end, communities are formed temporally
    based on the user’s interest. There are several practices applied in this scenario.
    Local community search [[14](#bib.bib14)] assumes one query node at a time and
    expands the search space around it. The strategy is attempted repeatedly until
    the community finds all its members. Attributed Truss Communities (ATC) [[149](#bib.bib149)]
    interconnects communities on query nodes with similar query node attributes.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/70c257316801fde7971aecc30290a8f9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Practical applications of community detection.'
  prefs: []
  type: TYPE_NORMAL
- en: XIII Future Directions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although deep learning has brought community detection into a prospering era,
    several open issues need further investigation. In this section, we recommend
    twelve future directions.
  prefs: []
  type: TYPE_NORMAL
- en: XIII-A An Unknown Number of Communities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For community detection in real-world scenario, the majority of data are unlabeled
    due to the high-cost acquisition, therefore the number of communities $K$ is often
    unknown. Unsupervised detection methods in deep learning provides an effective
    way to handle such unknown scenario, but they generally need to specify $K$ as
    the prior knowledge. This phenomenon brings us a catch-22: approaches require
    prior knowledge which does not exist. Therefore, there is an urgent demand to
    handle the unknown community number issue.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Opportunities: Analysis of network topological structure offers a potential
    solution to tackle this challenge, and some research efforts have been made [[109](#bib.bib109)].
    Typically, these methods perform random walks to get preliminary communities and
    refine the detection results by modularity. Nevertheless, when they come to disconnected
    networks in practice, random walks cannot involve every node and degrade the detection
    performance. This open issue, therefore, calls for a complete solution and further
    research.'
  prefs: []
  type: TYPE_NORMAL
- en: XIII-B Community Embedding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Node embedding methods traditionally preserve nodes’ neighborhood information,
    in which structural information of communities are ignored [[150](#bib.bib150)].
    To this end, designing community-aware learning processes to characterize community
    information can improve the accuracy of community detection [[151](#bib.bib151)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Opportunities: To date, few works integrate the community embedding into a
    deep learning model, so more efforts are desired for this promising area. In general,
    as community embedding that learns representations on each community increases
    computational cost, future work needs to develop fast computation-aimed algorithms.
    Furthermore, the optimization mechanism to hyperparameters in the community embedding
    needs a new design so that deep community detection can meet the expectation.'
  prefs: []
  type: TYPE_NORMAL
- en: XIII-C Hierarchical Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Networks such as the Web often show a treelike hierarchical organization of
    communities in different scales, in which small communities in lower levels group
    together to form larger ones in higher levels. Hence, community detection is required
    to detect communities from low to high levels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Opportunities: Traditional methods generally follow one of three work lines:
    (1) estimating the hierarchy directly, (2) recursively merging communities in
    a bottom-up fashion, and (3) recursively splitting communities in a top-down fashion.
    Their performance is limited by either a large number of parameters or the requirements
    for network density [[152](#bib.bib152)]. Network embedding shows the efficiency
    to these issues [[71](#bib.bib71), [153](#bib.bib153)]. However, preserving the
    community hierarchy into the embeddings remains unsolved [[153](#bib.bib153)].
    With the advancement of high-order relationship representations, we believe deep
    learning models can facilitate the development of hierarchical community detection.'
  prefs: []
  type: TYPE_NORMAL
- en: XIII-D Multi-layer Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Realistic systems always possess the nature of multiple layers. To exhibit this
    property, the multi-layer network is extracted. It is composed of multiple interdependent
    graphs, called layers, where each layer represents a different type of interactions
    among entities, and the cross-layer links reflect dependencies among entities[[154](#bib.bib154)].
    In the multi-layer social networks, for example, nodes can be individuals, the
    intralayer connections of each layer can represent friendship, kinship, or schoolmates,
    etc., while the interlayer connections align the same individuals [[5](#bib.bib5)].
    Thus, community detection in such networks can leverage more information to benefit
    the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Opportunities: In contrast with the prosperity of community detection works
    in single-layer networks, the development of research on multi-layer networks
    is still in its infancy [[155](#bib.bib155)]. A straightforward process is fusing
    information of multi-layer networks into one layer, followed by monolayer community
    detection methods. In deep learning architecture, a similar solution is to flatten
    the multi-layer information in low dimensional representations with the following
    general open issues: (1) differences among the interaction types, (2) varying
    levels of sparsity in layers, (3) possible connections across layers, and (4)
    the scalability scheme of layers.'
  prefs: []
  type: TYPE_NORMAL
- en: XIII-E Heterogeneous Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For an accurate depiction of reality, networks are required to involve heterogeneous
    information [[156](#bib.bib156)] that characterizes relationships between different
    types of entities, such as the role-play relation between actors and movies. Since
    community detection methods designed for homogeneous networks cannot be directly
    employed, due to lack of capacity to model the complex structural and semantic
    information, community detection research on heterogeneous networks is challenging.
  prefs: []
  type: TYPE_NORMAL
- en: 'Opportunities: Metapath is a promising research effort to deal with diverse
    semantic information, which describes a composite relation between the node types
    involved. It allows deep models to represent nodes by aggregating information
    from the first-order structure with different metapaths and measuring node similarity
    to cluster communities [[105](#bib.bib105), [157](#bib.bib157), [72](#bib.bib72)].
    However, the selection of most meaningful metapaths remains an open problem. The
    future efforts should focus on a flexible schema for metapath selection and novel
    models that can exploit various types of relationships.'
  prefs: []
  type: TYPE_NORMAL
- en: XIII-F Network Heterophily
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Network heterophily [[158](#bib.bib158)] can be interpreted as a phenomenon
    that connected nodes belong to different communities or characterized by dissimilar
    features. For example, fraudsters intentionally make a connection with normal
    users to hide from being discovered. For community detection, boundary nodes connected
    across communities comply with this property. It is significant to capture network
    heterophily providing valuable information on community division.
  prefs: []
  type: TYPE_NORMAL
- en: 'Opportunities: Since most methods heavily rely on homophily, they assume connected
    nodes share more similarities and are more likely from the same community. Deep
    learning methods that exploit network heterophily are expected for better community
    detection performance.'
  prefs: []
  type: TYPE_NORMAL
- en: XIII-G Topologically Incomplete Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Relationships in real-world scenarios are not always available, which leads
    to incomplete network topology and isolated subgraphs [[8](#bib.bib8)]. For example,
    protein-protein interaction (PPI) networks are usually incomplete since monitoring
    all protein-protein interactions are expensive [[159](#bib.bib159)]. Deriving
    meaningful knowledge of communities from limited topology information has been
    crucial to this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Opportunities: The requirement of complete network topology reduces the applicability
    of community detection methods, especially those based on neighborhood aggregations.
    To this end, deep learning methods should be further developed with an information
    recovery mechanism to achieve accurate community detection on TINs.'
  prefs: []
  type: TYPE_NORMAL
- en: XIII-H Cross-domain Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the real world, there are many similar networks such as Facebook and Twitter.
    Each network has its independent domain. Borrowing knowledge from an information-rich
    domain benefits the network learning in the target domain [[160](#bib.bib160)].
    Therefore, community detection is encouraged to develop its own deep learning
    models to improve detection results [[104](#bib.bib104)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Opportunities: Through community adaptations, the latent representation transferring
    from the source to the target domain faces the following challenges: (1) a lack
    of explicit community structure, (2) node label shortages, (3) missing a community’s
    ground truth, (4) poor representation performance caused by the inferior network
    structure, and (5) deep learning with small-scale networks. The future methods
    aim to measure cross-domain coefficiency, distribution shifts, and control computational
    costs.'
  prefs: []
  type: TYPE_NORMAL
- en: XIII-I Attributed Multi-view Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Real-world networks are complex and contain distinctively featured data [[161](#bib.bib161)].
    Attributed multi-view networks provide a new way to describe relational information
    in multiple informative views, each containing a type of attributes [[162](#bib.bib162)].
    Communities are initially detected on each single-view network and deeply encoded
    over multiple views in an expensive way. Hence, cheap community detection methods
    are aimed to exploit the multi-view complementarity [[163](#bib.bib163)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Opportunities: A straightforward workflow is to combine representations learned
    separately from each view, but it may cause noises and redundancy, which worsens
    community detection results. To develop an integrated framework, deep learning
    tries to extract the consistency information among multiple views by learning
    a common clustering embedding for community detection [[118](#bib.bib118)]. Since
    multi-view node attributes still require better integration scheme in the learning
    process, future works on networks with multi-view attributes need to develop a
    suitable integration scheme in the learning process. Meanwhile, more works are
    encouraged to study the under-explored issue of global representation for community
    detection over multi-views to avoid sub-optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: XIII-J Signed Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It has been increasingly noticed that not all occurring connections get entities
    close. Generally, friendship indicates the positive sentiment (e.g., like and
    support), while foes express the negative attitude (e.g., dislike). These distinctions
    are reflected on network edges, called signed edges and signed networks [[164](#bib.bib164)].
    As impacts of positive and negative ties are different, existing community detection
    methods working on unsigned networks are not applicable to signed networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Opportunities: To conduct community detection in signed network, the main challenges
    lie in adapting negative ties. Deep learning techniques should be exploited to
    represent both ties. Negative ties offer distinguishing community knowledge in
    learning signed network embeddings [[67](#bib.bib67)]. Future works are expected
    to cope with signed edges and further identify positive/negative information automatically
    on edges.'
  prefs: []
  type: TYPE_NORMAL
- en: XIII-K Dynamic Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Real networks may evolve over dynamic structures and temporal semantic features.
    The addition/removal of nodes/edges changes the community structure. Accordingly,
    deep learning models should rapidly capture the network evolvement to explore
    community changes. Based on our literature review, only one study touches this
    topic, designing an evolutionary AE to discover smoothly changing community structure
    [[73](#bib.bib73)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Opportunities: Both deep learning and community detection need to handle the
    shifting distributions and evolving data scales. Repeated training over snapshots
    is expensive and slow. Technical challenges in detecting communities from a dynamic
    network mainly come from the dynamics control from both spatial and temporal parts.
    Future directions include: (1) the analysis of spatial changes on communities,
    (2) the recognition of dynamic network patterns, and (3) tracks of network dynamics
    and community detection robustness.'
  prefs: []
  type: TYPE_NORMAL
- en: XIII-L Large-scale Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Large-scale networks may contain massive number of nodes, edges and communities.
    Their inherent scale characteristics, such as scale-free or named as power-law
    degree distribution [[19](#bib.bib19), [165](#bib.bib165)] in social networks,
    can influence the performance of deep community detection. Scalability is another
    crucial issue in large-scale networks [[15](#bib.bib15)]. A suggested direction
    on this topic is to develop a flexible deep learning approach aiming at collaborative
    computing with high robustness.
  prefs: []
  type: TYPE_NORMAL
- en: 'Opportunities: Common dimension reduction strategies in deep learning, such
    as matrix low-rank approximation, cannot cope with the high-dimensional relationships
    in large-scale networks. Current solutions of distributed computing are too expensive.
    Consequently, there is a crying need for novel deep learning frameworks, models
    and algorithms exceeding current benchmarks in terms of precision and speed.'
  prefs: []
  type: TYPE_NORMAL
- en: XIV Conclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This survey provides a comprehensive overview of the state-of-the-art community
    detection methods. During the recent decade, deep learning model-based methods
    are notably developed. This trend completely changes the community detection framework,
    resulting in a large number of publications in multiple fields in high-impact
    international conferences and peer-view journals. According to our survey, these
    methods significantly increase the effectiveness, efficiency, robustness and applicability
    of community detection. New techniques are much more flexible in use than traditional
    methods, and a larger volume of data can be leveraged in a rough preprocess. Selectively
    included into six categories, a taxonomy is newly designed. In each category,
    community detection is aimed by the deep learning model, i.e., encoding representations
    and optimizing clustering results. We discussed the contributions of each deep
    learning model to the community detection task. Furthermore, we summarized and
    provided handy resources, i.e., data sets, evaluation metrics, open-source implementations,
    based on the reviewed literature. We also offered an insight into a range of community
    detection applications. To stimulate further research in this area, we identified
    twelve open directions.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] S. A. Rice, “The identification of blocs in small political bodies,” *The
    American Political Science Review*, vol. 21, no. 3, pp. 619–627, 1927.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] M. E. Newman, “Fast algorithm for detecting community structure in networks,”
    *Physical Review E*, vol. 69, no. 6, p. 066133, 2004.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] M. Girvan and M. E. Newman, “Community structure in social and biological
    networks,” *PNAS*, vol. 99, no. 12, pp. 7821–7826, 2002.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] F. Liu, S. Xue, J. Wu, C. Zhou, W. Hu, C. Paris, S. Nepal, J. Yang, and
    P. S. Yu, “Deep learning for community detection: Progress, challenges and opportunities,”
    in *IJCAI*, 2020, pp. 4981–4987.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] J. Kim and J.-G. Lee, “Community detection in multi-layer graphs: A survey,”
    *ACM SIGMOD Record*, vol. 44, no. 3, pp. 37–48, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] J. Xie, S. Kelley, and B. K. Szymanski, “Overlapping community detection
    in networks: The state-of-the-art and comparative study,” *ACM Computing Surveys*,
    vol. 45, no. 4, pp. 1–35, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] M. A. Javed, M. S. Younis, S. Latif, J. Qadir, and A. Baig, “Community
    detection in networks: A multidisciplinary review,” *Journal of Network and Computer
    Applications*, vol. 108, pp. 87–111, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] X. Xin, C. Wang, X. Ying, and B. Wang, “Deep community detection in topologically
    incomplete networks,” *Physica A: Statistical Mechanics and its Applications*,
    vol. 469, pp. 342–352, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] P. Chunaev, “Community detection in node-attributed social networks: A
    survey,” *Computer Science Review*, vol. 37, p. 100286, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] D. Jin, Z. Liu, W. Li, D. He, and W. Zhang, “Graph convolutional networks
    meet Markov random fields: Semi-supervised community detection in attribute networks,”
    in *AAAI*, 2019, pp. 152–159.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] G. Rossetti and R. Cazabet, “Community discovery in dynamic networks:
    A survey,” *ACM Computing Surveys*, vol. 51, no. 2, p. 37, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] C. Pizzuti, “Evolutionary computation for community detection in networks:
    A review,” *IEEE Transactions on Evolutionary Computation*, vol. 22, no. 3, pp.
    464–483, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Q. Cai, L. Ma, M. Gong, and D. Tian, “A survey on network community detection
    based on evolutionary computation,” *International Journal of Bio-Inspired Computation*,
    vol. 8, no. 2, pp. 84–98, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] W. Cui, Y. Xiao, H. Wang, and W. Wang, “Local search of communities in
    large graphs,” in *SIGMOD*, 2014, pp. 991–1002.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] J. Li, X. Wang, K. Deng, X. Yang, T. Sellis, and J. X. Yu, “Most influential
    community search over large social networks,” in *ICDE*, 2017, pp. 871–882.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] J. Leskovec and J. J. Mcauley, “Learning to discover social circles in
    ego networks,” in *NIPS*, 2012, pp. 539–547.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] C. Nicolini, C. Bordier, and A. Bifone, “Community detection in weighted
    brain connectivity networks beyond the resolution limit,” *Neuroimage*, vol. 146,
    pp. 28–39, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] M. McPherson, L. Smith-Lovin, and J. M. Cook, “Birds of a feather: Homophily
    in social networks,” *Annual Review of Sociology*, vol. 27, no. 1, pp. 415–444,
    2001.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] D. J. Watts and S. H. Strogatz, “Collective dynamics of ‘small-world’
    networks,” *Nature*, vol. 393, no. 6684, pp. 440–442, 1998.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] J. Xie and B. K. Szymanski, “Towards linear time overlapping community
    detection in social networks,” in *PAKDD*, 2012, pp. 25–36.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] J. Yang, J. McAuley, and J. Leskovec, “Community detection in networks
    with node attributes,” in *ICDM*, 2013, pp. 1151–1156.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] P. Chen and S. Redner, “Community structure of the physical review citation
    network,” *Journal of Informetrics*, vol. 4, no. 3, pp. 278–290, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] E. Ravasz, A. L. Somera, D. A. Mongru, Z. N. Oltvai, and A.-L. Barabási,
    “Hierarchical organization of modularity in metabolic networks,” *Science*, vol.
    297, no. 5586, pp. 1551–1555, 2002.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] R. Guimera and L. A. N. Amaral, “Functional cartography of complex metabolic
    networks,” *Nature*, vol. 433, no. 7028, pp. 895–900, 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] J. Chen and B. Yuan, “Detecting functional modules in the yeast protein–protein
    interaction network,” *Bioinformatics*, vol. 22, no. 18, pp. 2283–2290, 2006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] O. Sporns and R. F. Betzel, “Modular brain networks,” *Annual Review of
    Psychology*, vol. 67, pp. 613–640, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] A. A. Amini, A. Chen, P. J. Bickel, E. Levina *et al.*, “Pseudo-likelihood
    methods for community detection in large sparse networks,” *The Annals of Statistics*,
    vol. 41, no. 4, pp. 2097–2122, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] S. de Lange, M. de Reus, and M. Van Den Heuvel, “The Laplacian spectrum
    of neural networks,” *Frontiers in Computational Neuroscience*, vol. 7, p. 189,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] P. W. Holland, K. B. Laskey, and S. Leinhardt, “Stochastic blockmodels:
    First steps,” *Social Networks*, vol. 5, no. 2, pp. 109–137, 1983.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] B. Karrer and M. E. Newman, “Stochastic blockmodels and community structure
    in networks,” *Physical Review E*, vol. 83, no. 1, p. 016107, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] E. M. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing, “Mixed membership
    stochastic blockmodels,” *Journal of Machine Learning Research*, vol. 9, no. Sep,
    pp. 1981–2014, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] S. Fortunato, “Community detection in graphs,” *Physics Reports*, vol.
    486, no. 3-5, pp. 75–174, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] S. Fortunato and D. Hric, “Community detection in networks: A user guide,”
    *Physics Reports*, vol. 659, pp. 1–44, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] E. Abbe, “Community detection and stochastic block models: Recent developments,”
    *Journal of Machine Learning Research*, vol. 18, no. 177, pp. 1–86, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] S. E. Garza and S. E. Schaeffer, “Community detection with the label propagation
    algorithm: A survey,” *Physica A: Statistical Mechanics and its Applications*,
    vol. 534, p. 122058, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] J. H. Chin and K. Ratnavelu, “A semi-synchronous label propagation algorithm
    with constraints for community detection in complex networks,” *Scientific Reports*,
    vol. 7, no. 1, pp. 1–12, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] D. Jin, Z. Yu, P. Jiao, S. Pan, P. S. Yu, and W. Zhang, “A survey of community
    detection approaches: From statistical modeling to deep learning,” *arXiv preprint
    arXiv:2101.01669*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] F. D. Malliaros and M. Vazirgiannis, “Clustering and community detection
    in directed networks: A survey,” *Physics Reports*, vol. 533, no. 4, pp. 95–142,
    2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] P. Bedi and C. Sharma, “Community detection in social networks,” *Wiley
    Interdisciplinary Reviews: Data Mining and Knowledge Discovery*, vol. 6, no. 3,
    pp. 115–135, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] B. W. Kernighan and S. Lin, “An efficient heuristic procedure for partitioning
    graphs,” *The Bell System Technical Journal*, vol. 49, no. 2, pp. 291–307, 1970.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] E. R. Barnes, “An algorithm for partitioning the nodes of a graph,” *SIAM
    Journal on Algebraic Discrete Methods*, vol. 3, no. 4, pp. 541–550, 1982.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] M. E. Newman and M. Girvan, “Finding and evaluating community structure
    in networks,” *Physical Review E*, vol. 69, no. 2, p. 026113, 2004.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] A. Clauset, M. E. Newman, and C. Moore, “Finding community structure in
    very large networks,” *Physical Review E*, vol. 70, no. 6, p. 066111, 2004.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] F. D. Zarandi and M. K. Rafsanjani, “Community detection in complex networks
    using structural similarity,” *Physica A: Statistical Mechanics and its Applications*,
    vol. 503, pp. 882–891, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] P. Pons and M. Latapy, “Computing communities in large networks using
    random walks,” in *Computer and Information Sciences*, 2005, pp. 284–293.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] M. Rosvall and C. T. Bergstrom, “Maps of random walks on complex networks
    reveal community structure,” *PNAS*, vol. 105, no. 4, pp. 1118–1123, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] U. N. Raghavan, R. Albert, and S. Kumara, “Near linear time algorithm
    to detect community structures in large-scale networks,” *Physical Review E*,
    vol. 76, no. 3, p. 036106, 2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] M. Ester, H.-P. Kriegel, J. Sander, and X. Xu, “A density-based algorithm
    for discovering clusters in large spatial databases with noise,” in *KDD*, 1996,
    p. 226–231.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] X. Xu, N. Yuruk, Z. Feng, and T. A. Schweiger, “SCAN: A structural clustering
    algorithm for networks,” in *KDD*, 2007, pp. 824–833.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] X. Wang, G. Liu, J. Li, and J. P. Nees, “Locating structural centers:
    A density-based clustering method for community detection,” *PloS One*, vol. 12,
    no. 1, p. e0169355, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast unfolding
    of communities in large networks,” *Journal of Statistical Mechanics: Theory and
    Experiment*, vol. 2008, no. 10, p. P10008, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi, “Optimization by simulated
    annealing,” *Science*, vol. 220, no. 4598, pp. 671–680, 1983.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] S. Boettcher and A. G. Percus, “Optimization with extremal dynamics,”
    *Complexity*, vol. 8, no. 2, pp. 57–62, 2002.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] M. E. J. Newman, “Spectral methods for community detection and graph partitioning,”
    *Physical Review E*, vol. 88, p. 042822, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] F. Liu, J. Wu, C. Zhou, and J. Yang, “Evolutionary community detection
    in dynamic social networks,” in *IJCNN*, 2019, pp. 1–7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] Z. Li and J. Liu, “A multi-agent genetic algorithm for community detection
    in complex networks,” *Physica A: Statistical Mechanics and its Applications*,
    vol. 449, pp. 336–347, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] S. Sobolevsky, R. Campari, A. Belyi, and C. Ratti, “General optimization
    technique for high-quality community detection in complex networks,” *Physical
    Review E*, vol. 90, no. 1, p. 012811, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] L. Ana and A. K. Jain, “Robust data clustering,” in *CVPR*, vol. 2, 2003.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] R. Kannan, S. Vempala, and A. Vetta, “On clusterings: Good, bad and spectral,”
    *Journal of the ACM*, vol. 51, no. 3, pp. 497–515, 2004.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” *Nature*, vol. 521,
    pp. 436–444, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] C. Park, D. Kim, J. Han, and H. Yu, “Unsupervised attributed multiplex
    network embedding,” in *AAAI*, 2020, pp. 5371–5378.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] L. Yang, Y. Wang, J. Gu, C. Wang, X. Cao, and Y. Guo, “JANE: Jointly adversarial
    network embedding,” in *IJCAI*, 2020, pp. 1381–1387.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] L. Yang, X. Cao, D. He, C. Wang, X. Wang, and W. Zhang, “Modularity based
    community detection with deep learning,” in *IJCAI*, 2016, p. 2252–2258.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] X. Zhang, H. Liu, Q. Li, and X.-M. Wu, “Attributed graph clustering via
    adaptive graph convolution,” in *IJCAI*, 2019, pp. 4327–4333.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] B. Jing, C. Park, and H. Tong, “HDMI: High-order deep multiplex infomax,”
    in *WWW*, 2021, pp. 2414–2424.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] H. Gao, J. Pei, and H. Huang, “ProGAN: Network embedding via proximity
    generative adversarial network,” in *KDD*, 2019, pp. 1308–1316.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] X. Shen and F.-L. Chung, “Deep network embedding for graph representation
    learning in signed networks,” *IEEE Transactions on Cybernetics*, vol. 50, no. 4,
    pp. 1556–1568, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] C. Yang, M. Liu, Z. Wang, L. Liu, and J. Han, “Graph clustering with dynamic
    embedding,” *arXiv preprint arXiv:1712.08249*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] S. Fan, X. Wang, C. Shi, E. Lu, K. Lin, and B. Wang, “One2Multi graph
    autoencoder for multi-view graph clustering,” in *WWW*, 2020, pp. 3070–3076.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] G. Sperlí, “A deep learning based community detection approach,” in *SAC*,
    2019, pp. 1107–1110.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] L. Du, Z. Lu, Y. Wang, G. Song, Y. Wang, and W. Chen, “Galaxy network
    embedding: A hierarchical community structure preserving approach,” in *IJCAI*,
    2018, pp. 2079–2085.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] X. Fu, J. Zhang, Z. Meng, and I. King, “MAGNN: Metapath aggregated graph
    neural network for heterogeneous graph embedding,” in *WWW*, 2020, pp. 2331–2341.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] Z. Wang, C. Wang, C. Gao, X. Li, and X. Li, “An evolutionary autoencoder
    for dynamic community detection,” *Science China Information Sciences*, vol. 63,
    no. 11, pp. 1–16, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] Y. LeCun, Y. Bengio *et al.*, “Convolutional networks for images, speech,
    and time series,” *The Handbook of Brain Theory and Neural Networks*, vol. 3361,
    no. 10, 1995.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] T. N. Kipf and M. Welling, “Semi-supervised classification with graph
    convolutional networks,” in *ICLR*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] A. De Santo, A. Galli, V. Moscato, and G. Sperlì, “A deep learning approach
    for semi-supervised community detection in Online Social Networks,” *Knowledge-Based
    Systems*, vol. 229, p. 107345, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] B. Cai, Y. Wang, L. Zeng, Y. Hu, and H. Li, “Edge classification based
    on convolutional neural networks for community detection in complex network,”
    *Physica A: Statistical Mechanics and its Applications*, vol. 556, p. 124826,
    2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] Z. Chen, L. Li, and J. Bruna, “Supervised community detection with line
    graph neural networks,” in *ICLR*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] X. Wang, J. Li, L. Yang, and H. Mi, “Unsupervised learning for community
    detection in attributed networks based on graph convolutional network,” *Neurocomputing*,
    vol. 456, pp. 147–155, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] O. Shchur and S. Günnemann, “Overlapping community detection with graph
    neural networks,” in *KDD Workshop on Deep Learning for Graphs*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] R. Hu, S. Pan, G. Long, Q. Lu, L. Zhu, and J. Jiang, “Going deep: Graph
    convolutional ladder-shape networks,” in *AAAI*, 2020, pp. 2838–2845.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] Y. Liu, X. Wang, S. Wu, and Z. Xiao, “Independence promoted graph disentangled
    networks,” in *AAAI*, 2020, pp. 4916–4923.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] A. Gretton, O. Bousquet, A. Smola, and B. Schölkopf, “Measuring statistical
    dependence with Hilbert-Schmidt norms,” in *ALT*, 2005, pp. 63–77.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] G. Cui, J. Zhou, C. Yang, and Z. Liu, “Adaptive graph encoder for attributed
    graph embedding,” in *KDD*, 2020, pp. 976–985.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] R. Levie, F. Monti, X. Bresson, and M. M. Bronstein, “CayleyNets: Graph
    convolutional neural networks with complex rational spectral filters,” *IEEE Transactions
    on Signal Processing*, vol. 67, no. 1, pp. 97–109, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] X. Zhang, H. Liu, X.-M. Wu, X. Zhang, and X. Liu, “Spectral embedding
    network for attributed graph clustering,” *Neural Networks*, vol. 142, pp. 388–396,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] T. Zhang, Y. Xiong, J. Zhang, Y. Zhang, Y. Jiao, and Y. Zhu, “CommDGI:
    Community detection oriented deep graph infomax,” in *CIKM*, 2020, pp. 1843–1852.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] H. Zhao, X. Yang, Z. Wang, E. Yang, and C. Deng, “Graph debiased contrastive
    learning with joint representation clustering,” in *IJCAI*, 2021, pp. 3434–3440.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio,
    “Graph attention networks,” in *ICLR*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] Q. You, H. Jin, Z. Wang, C. Fang, and J. Luo, “Image captioning with semantic
    attention,” in *CVPR*, 2016, pp. 4651–4659.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] X. Wang, N. Liu, H. Han, and C. Shi, “Self-supervised heterogeneous graph
    neural network with co-contrastive learning,” in *KDD*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] L. Luo, Y. Fang, X. Cao, X. Zhang, and W. Zhang, “Detecting communities
    from heterogeneous graphs: A context path-based graph neural network model,” in
    *CIKM*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, and Y. Bengio, “Generative adversarial nets,” in *NIPS*, 2014, pp.
    2672–2680.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] Y. Zhang, Y. Xiong, Y. Ye, T. Liu, W. Wang, Y. Zhu, and P. S. Yu, “SEAL:
    Learning heuristics for community detection with generative adversarial networks,”
    in *KDD*, 2020, pp. 1103–1113.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] M. Shi, Y. Tang, X. Zhu, D. Wilson, and J. Liu, “Multi-class imbalanced
    graph convolutional network learning,” in *IJCAI*, 2020, pp. 2879–2885.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] Y. Jia, Q. Zhang, W. Zhang, and X. Wang, “CommunityGAN: Community detection
    with generative adversarial nets,” in *WWW*, 2019, pp. 784–794.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] J. Wang, J. Cao, W. Li, and S. Wang, “CANE: Community-aware network embedding
    via adversarial training,” *Knowledge and Information Systems*, vol. 63, no. 2,
    pp. 411–438, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] J. Chen, Z. Gong, J. Mo, W. Wang, C. Wang, X. Dong, W. Liu, and K. Wu,
    “Self-training enhanced: Network embedding and overlapping community detection
    with adversarial learning,” *IEEE Transactions on Neural Networks and Learning
    Systems*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] G. E. Hinton and R. R. Salakhutdinov, “Reducing the dimensionality of
    data with neural networks,” *Science*, vol. 313, no. 5786, pp. 504–507, 2006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] F. Liu, J. Wu, S. Xue, C. Zhou, J. Yang, and Q. Sheng, “Detecting the
    evolving community structure in dynamic social networks,” *World Wide Web*, vol. 23,
    pp. 715–733, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] M. E. Newman, “Modularity and community structure in networks,” *PNAS*,
    vol. 103, no. 23, pp. 8577–8582, 2006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] D. Jin, M. Ge, L. Yang, D. He, L. Wang, and W. Zhang, “Integrative network
    embedding via deep joint reconstruction,” in *IJCAI*, 2018, pp. 3407–3413.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] H. Gao and H. Huang, “Deep attributed network embedding,” in *IJCAI*,
    2018, pp. 3364–3370.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] Y. Xie, X. Wang, D. Jiang, and R. Xu, “High-performance community detection
    in social networks using a deep transitive autoencoder,” *Information Sciences*,
    vol. 493, pp. 75–90, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] J. Zhang, C. Xia, C. Zhang, L. Cui, Y. Fu, and S. Y. Philip, “BL-MNE:
    Emerging heterogeneous social network embedding through broad learning with aligned
    autoencoder,” in *ICDM*, 2017, pp. 605–614.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] A. Ng *et al.*, “Sparse autoencoder,” *CS294A Lecture notes*, vol. 72,
    no. 2011, pp. 1–19, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] F. Tian, B. Gao, Q. Cui, E. Chen, and T.-Y. Liu, “Learning deep representations
    for graph clustering,” in *AAAI*, 2014, pp. 1293–1299.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] S. Li, L. Jiang, X. Wu, W. Han, D. Zhao, and Z. Wang, “A weighted network
    community detection algorithm based on deep learning,” *Applied Mathematics and
    Computation*, vol. 401, p. 126012, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] V. Bhatia and R. Rani, “DFuzzy: A deep learning-based fuzzy clustering
    model for large graphs,” *Knowledge and Information Systems*, vol. 57, no. 1,
    pp. 159–181, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] R. Xu, Y. Che, X. Wang, J. Hu, and Y. Xie, “Stacked autoencoder-based
    community detection method via an ensemble clustering framework,” *Information
    Sciences*, vol. 526, pp. 151–165, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] C. Wang, S. Pan, G. Long, X. Zhu, and J. Jiang, “MGAE: Marginalized graph
    autoencoder for graph clustering,” in *CIKM*, 2017, pp. 889–898.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] S. Cao, W. Lu, and Q. Xu, “Deep neural networks for learning graph representations,”
    in *AAAI*, 2016, p. 1145–1152.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] B. Li, D. Pi, Y. Lin, and L. Cui, “DNC: A deep neural network-based clustering-oriented
    network embedding algorithm,” *Journal of Network and Computer Applications*,
    vol. 173, p. 102854, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] D. Bo, X. Wang, C. Shi, M. Zhu, E. Lu, and P. Cui, “Structural deep clustering
    network,” in *WWW*, 2020, pp. 1400–1410.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] D. He, Y. Song, D. Jin, Z. Feng, B. Zhang, Z. Yu, and W. Zhang, “Community-centric
    graph convolutional network for unsupervised community detection,” in *IJCAI*,
    2020, pp. 3515–3521.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[116] C. Wang, S. Pan, R. Hu, G. Long, J. Jiang, and C. Zhang, “Attributed
    graph clustering: A deep attentional embedding approach,” in *IJCAI*, 2019, pp.
    3670–3676.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[117] H. Xu, W. Xia, Q. Gao, J. Han, and X. Gao, “Graph embedding clustering:
    Graph attention auto-encoder with cluster-specificity distribution,” *Neural Networks*,
    vol. 142, pp. 221–230, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[118] J. Cheng, Q. Wang, Z. Tao, D. Xie, and Q. Gao, “Multi-view attribute
    graph convolution networks for clustering,” in *IJCAI*, 2020, pp. 2973–2979.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[119] W. Xia, Q. Wang, Q. Gao, X. Zhang, and X. Gao, “Self-supervised graph
    convolutional network for multi-view clustering,” *IEEE Transactions on Multimedia*,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[120] D. Luo, J. Ni, S. Wang, Y. Bian, X. Yu, and X. Zhang, “Deep multi-graph
    clustering via attentive cross-graph association,” in *WSDM*, 2020, pp. 393–401.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[121] D. P. Kingma and M. Welling, “Auto-encoding variational bayes,” in *ICLR*,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[122] T. N. Kipf and M. Welling, “Variational graph auto-encoders,” in *NIPS*,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[123] N. Mehta, L. C. Duke, and P. Rai, “Stochastic blockmodels meet graph
    neural networks,” in *ICML*, 2019, pp. 4466–4474.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[124] Z. Chen, C. Chen, Z. Zhang, Z. Zheng, and Q. Zou, “Variational graph
    embedding and clustering with Laplacian eigenmaps,” in *IJCAI*, 2019, pp. 2144–2150.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[125] J. J. Choong, X. Liu, and T. Murata, “Learning community structure with
    variational autoencoder,” in *ICDM*, 2018, pp. 69–78.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[126] H. Shi, H. Fan, and J. T. Kwok, “Effective decoding in graph auto-encoder
    using triadic closure,” in *AAAI*, 2020, pp. 906–913.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[127] A. Sarkar, N. Mehta, and P. Rai, “Graph representation learning via ladder
    gamma variational autoencoders,” in *AAAI*, 2020, pp. 5604–5611.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[128] S. Pan, R. Hu, G. Long, J. Jiang, L. Yao, and C. Zhang, “Adversarially
    regularized graph autoencoder for graph embedding,” in *IJCAI*, 2018, pp. 2609–2615.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[129] D. D. Lee and H. S. Seung, “Learning the parts of objects by non-negative
    matrix factorization,” *Nature*, vol. 401, no. 6755, pp. 788–791, 1999.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[130] H. A. Song, B.-K. Kim, T. L. Xuan, and S.-Y. Lee, “Hierarchical feature
    extraction by multi-layer non-negative matrix factorization network for classification
    task,” *Neurocomputing*, vol. 165, pp. 63–74, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[131] F. Ye, C. Chen, and Z. Zheng, “Deep autoencoder-like nonnegative matrix
    factorization for community detection,” in *CIKM*, 2018, pp. 1393–1402.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[132] B.-J. Sun, H. Shen, J. Gao, W. Ouyang, and X. Cheng, “A non-negative
    symmetric encoder-decoder approach for community detection,” in *CIKM*, 2017,
    pp. 597–606.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[133] J. Huang, T. Zhang, W. Yu, J. Zhu, and E. Cai, “Community detection based
    on modularized deep nonnegative matrix factorization,” *International Journal
    of Pattern Recognition and Artificial Intelligence*, vol. 35, no. 02, p. 2159006,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[134] J. Ngiam, Z. Chen, S. A. Bhaskar, P. W. Koh, and A. Y. Ng, “Sparse filtering,”
    in *NIPS*, 2011, pp. 1125–1133.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[135] Y. Xie, M. Gong, S. Wang, and B. Yu, “Community discovery in networks
    with deep sparse filtering,” *Pattern Recognition*, vol. 81, pp. 50–59, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[136] J. J. Choong, X. Liu, and T. Murata, “Optimizing variational graph autoencoder
    for community detection,” in *BigData*, 2019, pp. 5353–5358.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[137] A. Lancichinetti, S. Fortunato, and F. Radicchi, “Benchmark graphs for
    testing community detection algorithms,” *Physical Review E*, vol. 78, no. 4,
    p. 046110, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[138] C.-Y. Liu, C. Zhou, J. Wu, Y. Hu, and L. Guo, “Social recommendation
    with an essential preference space,” in *AAAI*, 2018, p. 346–353.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[139] L. Gao, J. Wu, Z. Qiao, C. Zhou, H. Yang, and Y. Hu, “Collaborative social
    group influence for event recommendation,” in *CIKM*, 2016, p. 1941–1944.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[140] J. O. Garcia, A. Ashourvan, S. Muldoon, J. M. Vettel, and D. S. Bassett,
    “Applications of community detection techniques to brain graphs: Algorithmic considerations
    and implications for neural function,” *Proceedings of the IEEE*, vol. 106, no. 5,
    pp. 846–867, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[141] J. J. Bechtel, W. A. Kelley, T. A. Coons, M. G. Klein, D. D. Slagel,
    and T. L. Petty, “Lung cancer detection in patients with airflow obstruction identified
    in a primary care outpatient practice,” *Chest*, vol. 127, no. 4, pp. 1140–1145,
    2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[142] N. Haq and Z. J. Wang, “Community detection from genomic datasets across
    human cancers,” in *GlobalSIP*, 2016, pp. 1147–1150.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[143] C. Remy, B. Rym, and L. Matthieu, “Tracking bitcoin users activity using
    community detection on a network of weak signals,” in *CNA*, 2017, pp. 166–177.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[144] Z. Chen, W. Hendrix, and N. F. Samatova, “Community-based anomaly detection
    in evolutionary networks,” *Journal of Intelligent Information Systems*, vol. 39,
    no. 1, pp. 59–85, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[145] T. Waskiewicz, “Friend of a friend influence in terrorist social networks,”
    in *International Conference on Artificial Intelligence*, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[146] V. Fionda and G. Pirrò, “From community detection to community deception,”
    *arXiv preprint arXiv:1609.00149*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[147] Y. Liu, J. Liu, Z. Zhang, L. Zhu, and A. Li, “REM: From structural entropy
    to community structure deception,” in *NIPS*, 2019, pp. 12 938–12 948.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[148] V. Fionda and G. Pirro, “Community deception or: How to stop fearing
    community detection algorithms,” *IEEE Transactions on Knowledge and Data Engineering*,
    vol. 30, no. 4, pp. 660–673, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[149] X. Huang and L. V. Lakshmanan, “Attribute-driven community search,” *VLDBJ*,
    vol. 10, no. 9, pp. 949–960, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[150] B. Perozzi, R. Al-Rfou, and S. Skiena, “DeepWalk: Online learning of
    social representations,” in *KDD*, 2014, pp. 701–710.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[151] S. Cavallari, V. W. Zheng, H. Cai, K. C.-C. Chang, and E. Cambria, “Learning
    community embedding with community detection and node embedding on graphs,” in
    *CIKM*, 2017, pp. 377–386.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[152] T. Li, L. Lei, S. Bhattacharyya, K. V. den Berge, P. Sarkar, P. J. Bickel,
    and E. Levina, “Hierarchical community detection by recursive partitioning,” *Journal
    of the American Statistical Association*, pp. 1–18, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[153] Q. Long, Y. Wang, L. Du, G. Song, Y. Jin, and W. Lin, “Hierarchical community
    structure preserving network embedding: A subspace approach,” in *CIKM*, 2019,
    pp. 409–418.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[154] J. Wu, S. Pan, X. Zhu, C. Zhang, and P. S. Yu, “Multiple structure-view
    learning for graph classification,” *IEEE Transactions on Neural Networks and
    Learning Systems*, vol. 29, no. 7, pp. 3236–3251, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[155] X. Huang, D. Chen, T. Ren, and D. Wang, “A survey of community detection
    methods in multilayer networks,” *Data Mining and Knowledge Discovery*, vol. 35,
    pp. 1–45, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[156] Y. Cao, H. Peng, J. Wu, Y. Dou, J. Li, and P. S. Yu, “Knowledge-preserving
    incremental social event detection via heterogeneous gnns,” in *WWW*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[157] X. Wang, H. Ji, C. Shi, B. Wang, Y. Ye, P. Cui, and P. S. Yu, “Heterogeneous
    graph attention network,” in *WWW*, 2019, pp. 2022–2032.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[158] J. Zhu, Y. Yan, L. Zhao, M. Heimann, L. Akoglu, and D. Koutra, “Beyond
    homophily in graph neural networks: Current limitations and effective designs,”
    in *NIPS*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[159] H. Jeong, S. P. Mason, A.-L. Barabási, and Z. N. Oltvai, “Lethality and
    centrality in protein networks,” *Nature*, vol. 411, no. 6833, pp. 41–42, 2001.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[160] S. Xue, J. Lu, and G. Zhang, “Cross-domain network representations,”
    *Pattern Recognition*, vol. 94, pp. 135–148, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[161] J. Wu, X. Zhu, C. Zhang, and Z. Cai, “Multi-instance multi-graph dual
    embedding learning,” in *ICDM*, 2013, pp. 827–836.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[162] J. Wu, Z. Hong, S. Pan, X. Zhu, Z. Cai, and C. Zhang, “Multi-graph-view
    learning for graph classification,” in *ICDM*, 2014, pp. 590–599.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[163] R. Li, C. Zhang, Q. Hu, P. Zhu, and Z. Wang, “Flexible multi-view representation
    learning for subspace clustering,” in *IJCAI*, 2019, pp. 2916–2922.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[164] P. Xu, W. Hu, J. Wu, and B. Du, “Link prediction with signed latent factors
    in signed social networks,” in *KDD*, 2019, p. 1046–1054.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[165] A.-L. Barabási and E. Bonabeau, “Scale-free networks,” *Scientific American*,
    vol. 288, no. 5, pp. 60–69, 2003.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[166] D. Bahdanau, K. Cho, and Y. Bengio, “Neural machine translation by jointly
    learning to align and translate,” in *ICLR*, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[167] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” in *NIPS*, 2017, pp.
    5998–6008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[168] W. W. Zachary, “An information flow model for conflict and fission in
    small groups,” *Journal of Anthropological Research*, vol. 33, no. 4, pp. 452–473,
    1977.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[169] D. Lusseau, “The emergent properties of a dolphin social network,” *Proceedings
    of the Royal Society B: Biological Sciences*, vol. 270, no. suppl_2, pp. S186–S188,
    2003.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[170] H. Yin, A. R. Benson, J. Leskovec, and D. F. Gleich, “Local higher-order
    graph clustering,” in *KDD*, 2017, pp. 555–564.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[171] L. A. Adamic and N. Glance, “The political blogosphere and the 2004 us
    election: Divided they blog,” in *KDD Workshop on Link Discovery*, 2005, pp. 36–43.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[172] J. Yang and J. Leskovec, “Defining and evaluating network communities
    based on ground-truth,” *Knowledge and Information Systems*, vol. 42, no. 1, pp.
    181–213, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[173] C. Yang, Z. Liu, D. Zhao, M. Sun, and E. Y. Chang, “Network representation
    learning with rich text information,” in *IJCAI*, 2015, pp. 2111–2117.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[174] P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Galligher, and T. Eliassi-Rad,
    “Collective classification in network data,” *AI magazine*, vol. 29, no. 3, pp.
    93–93, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[175] X. Huang, J. Li, and X. Hu, “Accelerated attributed network embedding,”
    in *SDM*, 2017, pp. 633–641.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[176] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip, “A comprehensive
    survey on graph neural networks,” *IEEE Transactions on Neural Networks and Learning
    Systems*, vol. 32, no. 1, pp. 4–24, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[177] G. Namata, B. London, L. Getoor, B. Huang, and U. EDU, “Query-driven
    active surveying for collective classification,” in *KDD Workshop on Mining and
    Learning with Graphs*, vol. 8, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[178] P. Massa and P. Avesani, “Controversial users demand local trust metrics:
    An experimental study on Epinions. com community,” in *AAAI*, vol. 5, 2005, pp.
    121–126.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[179] J. Kunegis, A. Lommatzsch, and C. Bauckhage, “The slashdot zoo: Mining
    a social network with negative edges,” in *WWW*, 2009, pp. 741–750.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[180] J. Leskovec, D. Huttenlocher, and J. Kleinberg, “Governance in social
    media: A case study of the wikipedia promotion process,” in *ICWSM*, no. 1, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[181] I. Cantador, P. Brusilovsky, and T. Kuflik, “Second workshop on information
    heterogeneity and fusion in recommender systems (HetRec2011),” in *RecSys*, 2011,
    pp. 387–388.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[182] J. Gao, F. Liang, W. Fan, Y. Sun, and J. Han, “Graph-based consensus
    maximization among multiple supervised and unsupervised models,” *Advances in
    Neural Information Processing Systems*, vol. 22, pp. 585–593, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[183] P. Vanhems, A. Barrat, C. Cattuto, J.-F. Pinton, N. Khanafer, C. Régis,
    B.-a. Kim, B. Comte, and N. Voirin, “Estimating potential infection transmission
    routes in hospital wards using wearable proximity sensors,” *PloS One*, vol. 8,
    no. 9, p. e73970, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[184] L. Isella, J. Stehlé, A. Barrat, C. Cattuto, J.-F. Pinton, and W. Van den
    Broeck, “What’s in a crowd? Analysis of face-to-face behavioral networks,” *Journal
    of theoretical biology*, vol. 271, no. 1, pp. 166–180, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[185] B. Klimt and Y. Yang, “Introducing the enron corpus.” in *CEAS*, 2004.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[186] R. Rossi and N. Ahmed, “The network data repository with interactive
    graph analytics and visualization,” in *AAAI*, 2015, p. 4292–4293.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[187] R. Mastrandrea, J. Fournet, and A. Barrat, “Contact patterns in a high
    school: A comparison between data collected using wearable sensors, contact diaries
    and friendship surveys,” *PloS One*, vol. 10, no. 9, p. e0136497, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[188] A. Lancichinetti and S. Fortunato, “Benchmarks for testing community
    detection algorithms on directed and weighted graphs with overlapping communities,”
    *Physical Review E*, vol. 80, no. 1, p. 016118, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[189] A. F. McDaid, D. Greene, and N. Hurley, “Normalized mutual information
    to evaluate overlapping community finding algorithms,” *arXiv preprint arXiv:1110.2515*,
    2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[190] H. Shen, X. Cheng, K. Cai, and M.-B. Hu, “Detect overlapping and hierarchical
    community structure in networks,” *Physica A: Statistical Mechanics and its Applications*,
    vol. 388, no. 8, pp. 1706–1712, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[191] F. Wu, A. Souza, T. Zhang, C. Fifty, T. Yu, and K. Weinberger, “Simplifying
    graph convolutional networks,” in *ICML*, 2019, pp. 6861–6871.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| ![[Uncaptioned image]](img/8d7f73a3608c084d6278ab5164c8c1e8.png) | Xing Su
    received her M.Eng. degree in computer technology from Lanzhou University, China
    in 2020\. She is currently a Ph.D. candidate in School of Computing at Macquarie
    University, Australia. Her current research interests include community detection,
    deep learning and social network analysis. |'
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/1a77708380cfb78e40077593490bd7bb.png) | Shan Xue
    received her Ph.D. in Computer Science from the Center for Artificial Intelligence,
    University of Technology Sydney, Australia in 2019 and a Ph.D. in Information
    Management from the School of Management, Shanghai University, Shanghai, China
    in 2018\. She is a postdoctoral research fellow of School of Computing, Faculty
    of Science and Engineering, Macquarie University, Sydney, Australia as well as
    a researcher of CSIRO Data61, Sydney, Australia. Her current research interests
    include artificial intelligence, machine learning and knowledge mining. |'
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/231f2ec52c32ebce41b564f8217c4fa4.png) | Fanzhen
    Liu received the M.Res. (Master of Research) degree from Macquarie University,
    Sydney, Australia. He is currently pursuing the Ph.D. degree in computer science
    with Macquarie University, Sydney, Australia. His current research interests include
    graph mining and machine learning. |'
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/4218cfd138280e2f7162b99cdf530d19.png) | Jia Wu
    is an ARC DECRA Fellow at the School of Computing, Macquarie University, Sydney,
    Australia. He received the PhD from the University of Technology Sydney, Australia.
    His current research interests include data mining and machine learning. He has
    published 100+ refereed research papers in the above areas such as TPAMI, TKDE,
    TNNLS, TMM, NIPS, KDD, ICDM, IJCAI, AAAI and WWW. Dr Wu was the recipient of SDM’18
    Best Paper Award in Data Science Track and IJCNN’17 Best Student Paper Award.
    He currently serves as an Associate Editor of ACM Transactions on Knowledge Discovery
    from Data (TKDD). He is a Senior Member of IEEE. |'
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/9599e39406d0f471a9dacc31bdc22f43.png) | Jian Yang
    is a full professor at the School of Computing, Macquarie University. She received
    her PhD in Data Integration from the Australian National University in 1995\.
    Her main research interests are: business process management; data science; social
    networks. Prof. Yang has published more than 200 journal and conference papers
    in international journals and conferences such as IEEE Transactions, Information
    Systems, Data and Knowledge Engineering, VLDB, ICDE, ICDM, CIKM, etc. She is currently
    serving as an Executive Committee for the Computing Research and Education Association
    of Australasia. |'
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/140d2cea242398d66993f33287fc630b.png) | Chuan
    Zhou obtained Ph.D. degree from Chinese Academy of Sciences in 2013\. He won the
    outstanding doctoral dissertation of Chinese Academy of Sciences in 2014, the
    best paper award of ICCS-14, and the best student paper award of IJCNN-17\. Currently,
    he is an Associate Professor at the Academy of Mathematics and Systems Science,
    Chinese Academy of Sciences. His research interests include social network analysis
    and graph mining. To date, he has published more than 80 papers, including TKDE,
    ICDM, AAAI, IJCAI, WWW, etc. |'
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/4baf044c1b6c3b93a010c15ca93bf72d.png) | Wenbin
    Hu is currently a professor with the School of Computer Science, Wuhan University.
    His current research interests include intelligent and complex network, data mining
    and social network. He has more than 80 publications appeared in several top conferences
    such as SIGKDD, IJCAI, AAAI and ICDM, and journals such as IEEE TKDE, IEEE TMC,
    IEEE TITS, and ACM TKDD. |'
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/2d9ca993b29a20d43c417a2a2d0a9dc7.png) | Cecile
    Paris is a pioneer in Natural Language Processing and User Modelling, and, more
    generally, in Artificial Intelligence and human-machine communication. With a
    Bachelor Degree from the University of Berkeley (California) and a PhD from Columbia
    University (New York), she has over to 25 years of experience in research and
    research management, and over 300 refereed publications. She is a Chief Research
    Scientist at CSIRO Data61, a Fellow of the Academy for Technology, Science and
    Engineering (ATSE) and of the Royal Society of NSW, and an Honorary Professor
    at Macquarie University. |'
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/97f3aa7a061d645f57dcd426a118a123.png) | Surya
    Nepal is a Senior Principal Research Scientist at CSIRO Data61 and the Deputy
    Research Director of Cybersecurity Cooperative Research Centre (CRC). He has been
    with CSIRO since 2000 and currently leads the distributed systems security group
    comprising 30 staff and 50 PhD students. His main research focus is on distributed
    systems, with a specific focus on security, privacy and trust. He has more than
    250 peer-reviewed publications to his credit. He is a member of the editorial
    boards of IEEE TSC, ACM TOIT, and IEEE DSC. Dr Nepal also holds an honorary professor
    position at Macquarie University and a conjoint faculty position at UNSW. |'
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/7b381f1ea285975328a36eda3f2f4149.png) | Di Jin
    received the Ph.D. degree in computer science from Jilin University, Changchun,
    China, in 2012\. He was a Postdoctoral Research Fellow with the School of Design,
    Engineering, and Computing, Bournemouth University, Poole, U.K., from 2013 to
    2014\. He is currently an Associate Professor with the College of Intelligence
    and Computing, Tianjin University, Tianjin, China. He has published more than
    50 papers in international journals and conferences in the areas of community
    detection, social network analysis, and machine learning. |'
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/de167adb4454906283a8c5fe0f0c9efd.png) | Quan Z.
    Sheng is a full Professor and Head of School of Computing at Macquarie University,
    Sydney, Australia. His research interests include big data analytics, service
    oriented computing, and Internet of Things. Michael holds a PhD degree in computer
    science from the University of New South Wales. He has more than 400 publications.
    Prof Michael Sheng is the recipient of AMiner Most Influential Scholar Award in
    IoT in 2019, ARC Future Fellowship in 2014, Chris Wallace Award for Outstanding
    Research Contribution in 2012, and Microsoft Fellowship in 2003\. He is ranked
    by Microsoft Academic as one of the Most Impactful Authors in Services Computing
    (ranked Top 5 all time). |'
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/94d92c9dda467083657adc352813d9d3.png) | Philip
    S. Yu (F’93) is a distinguished professor of computer science with the University
    of Illinois at Chicago and also holds the Wexler chair in information technology.
    His research interest is on big data, including data mining, data stream, database,
    and privacy. He has published more than 990 papers in refereed journals and conferences.
    He holds or has applied for more than 300 US patents. He was the editor-in-chief
    of the IEEE TKDE (2001-2004). He has received several IBM honors including two
    IBM Outstanding Innovation Awards. Prof. Yu is a fellow of the ACM and the IEEE.
    |'
  prefs: []
  type: TYPE_TB
- en: Appendix A Summarized Techniques of Deep Learning-based Community Detection
    Methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TABLE [IV](#A1.T4 "TABLE IV ‣ Appendix A Summarized Techniques of Deep Learning-based
    Community Detection Methods ‣ A Comprehensive Survey on Community Detection with
    Deep Learning")–[VIII](#A1.T8 "TABLE VIII ‣ Appendix A Summarized Techniques of
    Deep Learning-based Community Detection Methods ‣ A Comprehensive Survey on Community
    Detection with Deep Learning") summarize the reviewed literature in sections [V-A](#S5.SS1
    "V-A CNN-based Community Detection ‣ V Convolutional Network-based Community Detection
    ‣ A Comprehensive Survey on Community Detection with Deep Learning") (CNN-based
    Community Detection), [V-B](#S5.SS2 "V-B GCN-based Community Detection ‣ V Convolutional
    Network-based Community Detection ‣ A Comprehensive Survey on Community Detection
    with Deep Learning") (GCN-based Community Detection), [VI](#S6 "VI Graph Attention
    Network-based Community Detection ‣ A Comprehensive Survey on Community Detection
    with Deep Learning") (GAT-based Community Detecion), [VII](#S7 "VII Generative
    Adversarial Network-based Community Detection ‣ A Comprehensive Survey on Community
    Detection with Deep Learning") (GAN-based Community Detection) and [VIII](#S8
    "VIII Autoencoder-based Community Detection ‣ A Comprehensive Survey on Community
    Detection with Deep Learning") (AE-based Community Detection), respectively. Regarding
    the “Input”, different methods require different inputs, such as network topology
    $\bm{A}$, node attributes $\bm{X}$ and other preprocessed data. Regarding the
    availability of ground truth labels, methods vary in supervised, semi-supervised
    and unsupervised “Learning”. Meanwhile, methods that are able to output overlapping
    communities are marked by “$\checkmark$” in the “Overlap” column. Methods that
    can detect overlapping communities are also suitable to disjoint community detection.
    To other special requirements summarized in the tables, please refer to the corresponding
    sections.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE IV: Summary of CNN-based community detection methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Input | Learning | Preprocess | Co-technique | Overlap | Network
    |'
  prefs: []
  type: TYPE_TB
- en: '| Xin et al. [[8](#bib.bib8)] | $\bm{A}$ | Supervise | Node to image | – |
    $\times$ | TINs |'
  prefs: []
  type: TYPE_TB
- en: '| SparseConv [[70](#bib.bib70)] | $\bm{A}$ | Supervise | Node to image | Sparse
    matrix | $\times$ | Sparse network |'
  prefs: []
  type: TYPE_TB
- en: '| SparseConv2D [[76](#bib.bib76)] | $\bm{A}$ | Semi-supervise | Node to image
    | Sparse matrix | $\times$ | Sparse network |'
  prefs: []
  type: TYPE_TB
- en: '| ComNet-R [[77](#bib.bib77)] | $\bm{A}$ | Supervise | Edge to image | Local
    modularity | $\times$ | Large-scale network |'
  prefs: []
  type: TYPE_TB
- en: 'TABLE V: Summary of GCN-based community detection methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Input | Learning | Convolution | Clustering | Co-technique | Overlap
    |'
  prefs: []
  type: TYPE_TB
- en: '| LGNN[[78](#bib.bib78)] | $\bm{A},\bm{X}$ | Supervise | First-order + Line
    graph | – | Edge features | $\checkmark$ |'
  prefs: []
  type: TYPE_TB
- en: '| MRFasGCN[[10](#bib.bib10)] | $\bm{A},\bm{X}$ | Semi-supervise | First-order
    + Mean Field Approximate | – | eMRF | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| SGCN[[79](#bib.bib79)] | $\bm{A},\bm{X}$ | Unsupervise | First-order | –
    | Label sampling | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| NOCD[[80](#bib.bib80)] | $\bm{A},\bm{X}$ | Unsupervise | First-order | –
    | Bernoulli–Poisson | $\checkmark$ |'
  prefs: []
  type: TYPE_TB
- en: '| GCLN[[81](#bib.bib81)] | $\bm{A},\bm{X}$ | Unsupervise | First-order | $k$-means
    | U-Net architecture | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| IPGDN[[82](#bib.bib82)] | $\bm{A},\bm{X}$ | Unsupervise | First-order + Disentangled
    representation | $k$-means | HSIC as regularizer | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| AGC[[64](#bib.bib64)] | $\bm{A},\bm{X}$ | Unsupervise | $k$-order + Laplacian
    smoothing filter | Spectral Clustering | – | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| AGE[[84](#bib.bib84)] | $\bm{A},\bm{X}$ | Unsupervise | Laplacian smoothing
    filter | Spectral Clustering | Adaptive learning | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| CayleyNet[[85](#bib.bib85)] | $\bm{A},\bm{X}$ | Semi-supervise | Laplacian
    smoothing filter | – | Cayley polynomial | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| SENet[[86](#bib.bib86)] | $\bm{A},\bm{X}$ | Unsupervise | Third-order + Spectral
    clustering loss | $k$-means | Kernel matrix learning | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| CommDGI[[87](#bib.bib87)] | $\bm{A},\bm{X}$ | Unsupervise | First-order +
    Sampling | – | Joint optimization | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| Zhao et al.[[88](#bib.bib88)] | $\bm{A},\bm{X}$ | Unsupervise | First-order
    + Sampling | – | Joint optimization | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: 'TABLE VI: Summary of GAT-based community detection methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Input | Metapath | Learning | Attention Mechanism | Co-technique
    | Clustering | Overlap | Network |'
  prefs: []
  type: TYPE_TB
- en: '| DMGI[[61](#bib.bib61)] | $V,E^{(r)},\bm{X}$ | $\times$ | Unsupervise | [[166](#bib.bib166)]
    | Contrastive learning | $k$-means | $\times$ | Multiplex |'
  prefs: []
  type: TYPE_TB
- en: '| HDMI[[65](#bib.bib65)] | $V,E^{(r)},\bm{X}$ | $\times$ | Unsupervise | [[90](#bib.bib90)]
    | MI | $k$-means | $\times$ | Multiplex |'
  prefs: []
  type: TYPE_TB
- en: '| MAGNN[[72](#bib.bib72)] | $\mathcal{V},\mathcal{E},\mathcal{X}$ | $\checkmark$
    | Unsupervise | [[167](#bib.bib167)] | – | $k$-means | $\times$ | Heterogeneous
    |'
  prefs: []
  type: TYPE_TB
- en: '| HeCo[[91](#bib.bib91)] | $\mathcal{V},\mathcal{E}$ | $\checkmark$ | Unsupervise
    | [[166](#bib.bib166)] | Contrastive learning | $k$-means | $\times$ | Heterogeneous
    |'
  prefs: []
  type: TYPE_TB
- en: '| CP-GNN[[92](#bib.bib92)] | $\mathcal{V},\mathcal{E}$ | $\times$ | Unsupervise
    | [[167](#bib.bib167)] | – | $k$-means | $\times$ | Heterogeneous |'
  prefs: []
  type: TYPE_TB
- en: 'TABLE VII: Summary of GAN-based community detection methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Input | Learning | Generator | Discriminator | Generated Samples
    | Clustering | Overlap |'
  prefs: []
  type: TYPE_TB
- en: '| SEAL[[94](#bib.bib94)] | $\bm{A},\bm{X}$ | Semi-supervise | iGPN | GINs |
    Communities | – | $\checkmark$ |'
  prefs: []
  type: TYPE_TB
- en: '| DR-GCN[[95](#bib.bib95)] | $\bm{A},\bm{X}$ | Semi-supervise | MLP | MLP |
    Embeddings | $k$-means | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  | Topology, attributes, |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| JANE[[62](#bib.bib62)] | $\bm{A},\bm{X}$ | Unsupervise | Various | MLP |
    embeddings | – | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| ProGAN[[66](#bib.bib66)] | $\bm{A},\bm{X}$ | Unsupervise | MLP | MLP | Triplets
    | $k$-means | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| CommunityGAN[[96](#bib.bib96)] | $\bm{A}$ | Unsupervise | AGM | AGM | Motifs
    | – | $\checkmark$ |'
  prefs: []
  type: TYPE_TB
- en: '| CANE[[97](#bib.bib97)] | $\bm{A}$ | Unsupervise | Softmax | MLP | Node pairs
    | $k$-means | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| ACNE[[98](#bib.bib98)] | $\bm{A}$ | Unsupervise | Softmax | MLP | Nodes,
    Communities | – | $\checkmark$ |'
  prefs: []
  type: TYPE_TB
- en: 'TABLE VIII: Summary of AE-based community detection methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Category | Method | Input | Learning | Encoder | Decoder | Loss | Overlap
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | semi-DNR[[63](#bib.bib63)] | $\bm{B}$ | Semi-supervise | MLP | MLP | reconstruction+pairwise
    | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | DNE-SBP[[67](#bib.bib67)] | $\bm{A}(+,-)$ | Semi-supervise | MLP | MLP
    | reconstruction+regularization+pairwise | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | UWMNE/WMCNE-LE[[102](#bib.bib102)] | $\bm{B},\bm{X}$ | Unsupervise | MLP
    | MLP | reconstruction+pairwise | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | sE-Autoencoder[[73](#bib.bib73)] | $\{\bm{A}_{t}\}$ | Semi-supervise |
    MLP | MLP | reconstruction+regularization+pairwise | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | DANE[[103](#bib.bib103)] | $\bm{A},\bm{X}$ | Unsupervise | MLP | MLP |
    reconstruction+proximity | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | Transfer-CDDTA[[104](#bib.bib104)] | $\bm{S}_{s},\bm{S}_{t}$ | Unsupervise
    | MLP | MLP | reconstruction+regularization+proximity | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\mathcal{V}$, $\mathcal{E}$, |  |  |  | reconstruction+regularization
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| Stacked AE | DIME [[105](#bib.bib105)] | $\mathcal{X},\{\mathcal{A}_{ij}\}$
    | Unsupervise | MLP | MLP | +information fusion | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | GraphEncoder[[107](#bib.bib107)] | $\bm{A},\bm{D},\bm{S}$ | Unsupervise
    | MLP | MLP | reconstruction+regularization+sparsity | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | WCD[[108](#bib.bib108)] | $\bm{S}$ | Unsupervise | MLP | MLP | reconstruction+sparsity
    | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | DFuzzy[[109](#bib.bib109)] | $\bm{A}$ | Unsupervise | MLP | MLP | reconstruction+sparsity
    | $\checkmark$ |'
  prefs: []
  type: TYPE_TB
- en: '| Sparse AE | CDMEC[[110](#bib.bib110)] | $\bm{S}_{s},\bm{S}_{t}$ | Unsupervise
    | MLP | MLP | reconstruction+sparsity | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | DNGR[[112](#bib.bib112)] | $\bm{A}$ | Unsupervise | MLP | MLP | reconstruction
    | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | DNC[[113](#bib.bib113)] | $\bm{A}$ | Unsupervise | MLP | MLP | reconstruction+clustering
    | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | GRACE[[68](#bib.bib68)] | $\bm{A},\bm{X}$ | Unsupervise | MLP | MLP |
    reconstruction+clustering | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| Denoising AE | MGAE[[111](#bib.bib111)] | $\bm{A},\bm{X}$ | Unsupervise |
    GCN | GCN | reconstruction+regularization | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | GUCD[[115](#bib.bib115)] | $\bm{A},\bm{X}$ | Unsupervise | MRFasGCN |
    MLP | reconstruction+pairwise | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | SDCN[[114](#bib.bib114)] | $\bm{A},\bm{X}$ | Unsupervise | GCN+DNN | DNN
    | reconstruction+clustering | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| Graph Convolutional AE | O2MAC[[69](#bib.bib69)] | $\{\bm{A}\},\bm{X}$ |
    Unsupervise | GCN | Inner Product | reconstruction+clustering | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | DAEGC[[116](#bib.bib116)] | $\bm{A},\bm{X}$ | Unsupervise | GAT | Inner
    Product | reconstruction+clustering | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  | Inner Product | reconstruction+regularization |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | GEC-CSD[[117](#bib.bib117)] | $\bm{A},\bm{X}$ | Unsupervise | GAT | +GAT
    | +clustering+adversarial | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  | Inner Product | reconstruction+clustering |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | MAGCN[[118](#bib.bib118)] | $\bm{A},\{\bm{X}\}$ | Unsupervise | GAT+MLP
    | +GCN | +consistency | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  | reconstruction+regularization |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | SGCMC[[119](#bib.bib119)] | $\bm{A},\{\bm{X}\}$ | Unsupervise | GAT |
    GAT | +clustering+consistency | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  | reconstruction+regularization |  |'
  prefs: []
  type: TYPE_TB
- en: '| Graph Attention AE | DMGC[[120](#bib.bib120)] | $\{A\}$ | Unsupervise | MLP
    | MLP | +proximity+clustering | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | TGA/TVGA[[126](#bib.bib126)] | $\bm{A}$,$\bm{X}$ | Unsupervise | GCN |
    Triad | reconstruction | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | VGECLE[[124](#bib.bib124)] | $\bm{A}$ | Semi-supervise | DNN | DNN | reconstruction+pairwise
    | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | DGLFRM[[123](#bib.bib123)] | $\bm{A},\bm{X}$ | Semi-supervise | GCN |
    DNN | reconstruction+regularization | $\checkmark$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | LGVG[[127](#bib.bib127)] | $\bm{A},\bm{X}$ | Semi-supervise | GCN | DNN
    | reconstruction+regularization | $\checkmark$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | VGAECD[[125](#bib.bib125)] | $\bm{A},\bm{X}$ | Unsupervise | GCN | Inner
    Product | reconstruction+clustering | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | VGAECD-OPT[[136](#bib.bib136)] | $\bm{A},\bm{X}$ | Unsupervise | GCN |
    Inner Product | reconstruction+clustering | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| Variational AE | ARGA/ARVGA[[128](#bib.bib128)] | $\bm{A},\bm{X}$ | Unsupervise
    | GCN | Inner Product | reconstruction | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: 'Appendix B Detailed description: Data Sets'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: B-A Real-world Data Sets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Citation/Co-authorship Networks. Citeseer, Cora and Pubmed²²2[https://linqs.soe.ucsc.edu/data](https://linqs.soe.ucsc.edu/data)
    are the most popular group of paper citation networks used in community detection
    experiments as attributed networks, where nodes represent publications and links
    mean citations. The nodes are described by binary word vectors. Topics are class
    labels. DBLP³³3[http://snap.stanford.edu/data/com-DBLP.html](http://snap.stanford.edu/data/com-DBLP.html)
    is a co-authorship network from computer science bibliography website. A ground
    truth community labels that the authors who published papers on one journal or
    conference. In complicated scenarios, the heterogeneous DBLP can be extracted
    with considering diverse information such as co-authorship, citation. ACM⁴⁴4[http://dl.acm.org/](http://dl.acm.org/)
    is a paper network with two views, one view describes whether two papers are written
    by the same author, the other view depicts if the subjects of two papers are the
    same. The nodes (i.e. papers) are described by the bag-of-words of the keywords.
    The heterogeneous ACM can be constructed as well.
  prefs: []
  type: TYPE_NORMAL
- en: Online Social Networks. In most of online social network data sets, nodes represent
    users, edges depict relationship between them such as friendships or followings.
    In the YouTube⁵⁵5[http://snap.stanford.edu/data/com-Youtube.html](http://snap.stanford.edu/data/com-Youtube.html)
    dataset, social network is formed by users having friendship, each user-created
    group for video sharing is a community. LiveJournal⁶⁶6[http://snap.stanford.edu/data/soc-LiveJournal1.html](http://snap.stanford.edu/data/soc-LiveJournal1.html)
    is a friendship social network collected from a online blog community where users
    state friendship to each other and define groups that can be ground truth communities.
    PolBlogs⁷⁷7[http://www-personal.umich.edu/~mejn/netdata/](http://www-personal.umich.edu/~mejn/netdata/)
    is a social blog network of weblogs on US politics, where nodes are blogs and
    hyperlinks between them extract to edges. Some data sets also collect node attributes.
    In the Facebook⁸⁸8[http://snap.stanford.edu/data/ego-Facebook.html](http://snap.stanford.edu/data/ego-Facebook.html)
    and Twitter⁹⁹9[http://snap.stanford.edu/data/ego-Twitter.html](http://snap.stanford.edu/data/ego-Twitter.html)
    data sets, for example, attributes are described by user profiles while nodes
    and edges represent users and their connections, respectively. The heterogeneous
    Twitter extracts different types information from users, tweets, and locations.
    Flickr provides an online platform for users to share photos, the network is formed
    by users following each other, attributes are image tags, and community labels
    represent different interest groups. Blogcatalog is another blogger community,
    where attributes are extracted from users’ blogs, community labels denote various
    topics. Gplus^(10)^(10)10[http://snap.stanford.edu/data/ego-Gplus.html](http://snap.stanford.edu/data/ego-Gplus.html)
    is the ego network constructed by users sharing their circles in Google+, in which
    links exist if users follow each other and their profiles are extracted as attributes.
    Furthermore, there are three signed online social networks, Slashdot is extracted
    from the technology news site Slashdot where users form the relationships of friends
    or foes which represented by positive or negative links. Epinions is a who trust
    whom network constructed from the Epinions site^(11)^(11)11[http://www.epinions.com/](http://www.epinions.com/),
    where the positive and negative edges reflects that users trust or distrust each
    other. In the signed Wiki data set, the network describes election of Wikipedia
    admins among users, edges indicate that the users vote for (positive) or against
    (negative) to the other. Considering heterogeneous information, Last.fm as a music
    website^(12)^(12)12[https://www.last.fm/](https://www.last.fm/) constructs the
    network of users, artists and artist tags by tracking user listening information
    from various sources. Foursquare is another heterogeneous social network, which
    is formed by various kinds of location-related services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional Social Networks. The data sets of Karate, Dolphin and Football
    are the most widely-used social networks in community detection. Karate^([7](#footnote7
    "footnote 7 ‣ B-A Real-world Data Sets ‣ Appendix B Detailed description: Data
    Sets ‣ A Comprehensive Survey on Community Detection with Deep Learning")) describes
    friendships between 34 members of Zachary’s karate club. In Dolphin^([7](#footnote7
    "footnote 7 ‣ B-A Real-world Data Sets ‣ Appendix B Detailed description: Data
    Sets ‣ A Comprehensive Survey on Community Detection with Deep Learning")) social
    network, nodes and edges represent dolphins and tighter connection between two
    dolphins, respectively. In Football^([7](#footnote7 "footnote 7 ‣ B-A Real-world
    Data Sets ‣ Appendix B Detailed description: Data Sets ‣ A Comprehensive Survey
    on Community Detection with Deep Learning")) data set, nodes represent different
    football teams while edges indicate the matches between them. Another traditional
    social network data sets include: the Friendship6 and Friendship7 data sets that
    construct high school friendship networks, and Email^(13)^(13)13[https://snap.stanford.edu/data/email-Eu-core.html](https://snap.stanford.edu/data/email-Eu-core.html)
    data set describing email communication of the EU research institution. Considering
    the evolution of networks, Cellphone Calls^(14)^(14)14[http://www.cs.umd.edu/hcil/VASTchallenge08/download/Download.htm](http://www.cs.umd.edu/hcil/VASTchallenge08/download/Download.htm)
    consists of a set of cell phone call records over ten days, where nodes are cell
    phones and edges represent phone calls. Rados^(15)^(15)15[http://networkrepository.com/ia-radoslaw-email.php](http://networkrepository.com/ia-radoslaw-email.php)
    and Enron Email^(16)^(16)16[http://www.cs.cmu.edu/%7Eenron/](http://www.cs.cmu.edu/%7Eenron/)
    are popular email data sets from employees’ communication over a period of time,
    where senders or recipients are represented by nodes and edges exist if two individuals
    emailed. Another three dynamic netowrks are High School, Hospital and Hypertext^(17)^(17)17[http://www.sociopatterns.org/datasets](http://www.sociopatterns.org/datasets).
    High School forms the temporal friendship network of contacts between students
    in different classes of a high school within one week. Hospital constructs the
    time-varing network of contacts between patients, patients and health-care workers
    and among the workers in a hospital during a few days. Hypertext extracts a social
    network of conference attendees during the ACM Hypertext 2009 conference.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE IX: Summary of real-world benchmark data sets.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Network | Data Set | Number of | Number of | Number of | Given Number of
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| Category | Name | Nodes | Edges | Attributes | Communities | Publications
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Karate [[168](#bib.bib168)] | 34 | 78 | 0 | 2 | [[77](#bib.bib77), [63](#bib.bib63),
    [104](#bib.bib104), [110](#bib.bib110), [125](#bib.bib125), [135](#bib.bib135),
    [79](#bib.bib79)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Dolphins [[169](#bib.bib169)] | 62 | 159 | 0 | 2 | [[77](#bib.bib77),
    [63](#bib.bib63), [104](#bib.bib104), [110](#bib.bib110), [135](#bib.bib135),
    [79](#bib.bib79)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Friendship6 [[6](#bib.bib6)] | 69 | 220 | 0 | 6 | [[63](#bib.bib63), [104](#bib.bib104),
    [110](#bib.bib110)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Friendship7 [[6](#bib.bib6)] | 69 | 220 | 0 | 7 | [[63](#bib.bib63), [104](#bib.bib104),
    [110](#bib.bib110)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Polbooks [[101](#bib.bib101)] | 105 | 441 | 0 | 3 | [[63](#bib.bib63),
    [104](#bib.bib104), [110](#bib.bib110), [79](#bib.bib79)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  | [[8](#bib.bib8), [77](#bib.bib77), [63](#bib.bib63), [104](#bib.bib104),
    [110](#bib.bib110), [133](#bib.bib133), [108](#bib.bib108), [79](#bib.bib79)],
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Football [[3](#bib.bib3)] | 115 | 613 | 0 | 12 | [[135](#bib.bib135)]
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Email[[170](#bib.bib170)] | 1,005 | 25,571 | 0 | 42 | [[131](#bib.bib131),
    [133](#bib.bib133)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Polblogs [[171](#bib.bib171)] | 1,490 | 16,718 | 0 | 2 | [[63](#bib.bib63),
    [104](#bib.bib104), [110](#bib.bib110), [125](#bib.bib125), [133](#bib.bib133),
    [135](#bib.bib135)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Amazon [[172](#bib.bib172)] | 334,863 | 925,872 | 0 | 75,149 | [[77](#bib.bib77),
    [78](#bib.bib78), [94](#bib.bib94), [96](#bib.bib96), [104](#bib.bib104), [109](#bib.bib109),
    [110](#bib.bib110), [132](#bib.bib132)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | DBLP [[172](#bib.bib172)] | 317,080 | 1,049,866 | 0 | 13,477 | [[77](#bib.bib77),
    [78](#bib.bib78), [94](#bib.bib94), [96](#bib.bib96), [104](#bib.bib104), [109](#bib.bib109),
    [114](#bib.bib114), [132](#bib.bib132)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | YouTube [[172](#bib.bib172)] | 1,134,890 | 2,987,624 | 0 | 8,385 | [[8](#bib.bib8),
    [77](#bib.bib77), [78](#bib.bib78), [94](#bib.bib94), [96](#bib.bib96), [109](#bib.bib109),
    [76](#bib.bib76)] |'
  prefs: []
  type: TYPE_TB
- en: '| Unattributed Network | LiveJournal [[173](#bib.bib173)] | 3,997,962 | 34,681,189
    | 0 | 287,512 | [[8](#bib.bib8), [109](#bib.bib109)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Texas [[174](#bib.bib174)] | 187 | 328 | 1,703 | 5 | [[10](#bib.bib10),
    [102](#bib.bib102), [115](#bib.bib115), [79](#bib.bib79)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Cornell [[174](#bib.bib174)] | 195 | 304 | 1,703 | 5 | [[10](#bib.bib10),
    [102](#bib.bib102), [115](#bib.bib115), [79](#bib.bib79)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Washington [[174](#bib.bib174)] | 230 | 446 | 1,703 | 5 | [[10](#bib.bib10),
    [102](#bib.bib102), [115](#bib.bib115), [79](#bib.bib79)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Wisconsin [[174](#bib.bib174)] | 265 | 530 | 1,703 | 5 | [[10](#bib.bib10),
    [102](#bib.bib102), [115](#bib.bib115), [79](#bib.bib79)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Wiki [[173](#bib.bib173)] | 2,405 | 17,981 | 4,973 | 19 | [[64](#bib.bib64),
    [84](#bib.bib84), [103](#bib.bib103), [112](#bib.bib112), [111](#bib.bib111),
    [131](#bib.bib131), [98](#bib.bib98), [119](#bib.bib119)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  | [[10](#bib.bib10), [63](#bib.bib63), [81](#bib.bib81),
    [82](#bib.bib82), [68](#bib.bib68), [64](#bib.bib64), [84](#bib.bib84), [62](#bib.bib62),
    [66](#bib.bib66), [79](#bib.bib79)], |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  | [[86](#bib.bib86), [87](#bib.bib87), [88](#bib.bib88),
    [103](#bib.bib103), [95](#bib.bib95), [104](#bib.bib104), [110](#bib.bib110),
    [112](#bib.bib112), [111](#bib.bib111), [98](#bib.bib98)], |'
  prefs: []
  type: TYPE_TB
- en: '|  | Cora [[174](#bib.bib174)] | 2,708 | 5,429 | 1,433 | 7 | [[115](#bib.bib115),
    [116](#bib.bib116), [118](#bib.bib118), [126](#bib.bib126), [123](#bib.bib123),
    [127](#bib.bib127), [125](#bib.bib125), [124](#bib.bib124), [128](#bib.bib128),
    [131](#bib.bib131), [135](#bib.bib135), [117](#bib.bib117), [119](#bib.bib119)]
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  | [[10](#bib.bib10), [68](#bib.bib68), [81](#bib.bib81),
    [82](#bib.bib82), [64](#bib.bib64), [84](#bib.bib84), [62](#bib.bib62), [66](#bib.bib66),
    [79](#bib.bib79)], |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  | [[87](#bib.bib87), [86](#bib.bib86), [88](#bib.bib88),
    [103](#bib.bib103), [95](#bib.bib95), [104](#bib.bib104), [110](#bib.bib110),
    [112](#bib.bib112), [111](#bib.bib111), [115](#bib.bib115), [114](#bib.bib114),
    [113](#bib.bib113), [123](#bib.bib123)], |'
  prefs: []
  type: TYPE_TB
- en: '|  | Citeseer [[174](#bib.bib174)] | 3,312 | 4,715 | 3,703 | 6 | [[117](#bib.bib117),
    [118](#bib.bib118), [126](#bib.bib126), [127](#bib.bib127), [128](#bib.bib128),
    [131](#bib.bib131), [135](#bib.bib135), [119](#bib.bib119)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | UAI2010 [[174](#bib.bib174)] | 3,363 | 45,006 | 4,972 | 19 | [[10](#bib.bib10),
    [102](#bib.bib102), [115](#bib.bib115)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Facebook [[16](#bib.bib16)] | 4,039 | 88,234 | 1,283 | 193 | [[80](#bib.bib80),
    [94](#bib.bib94), [109](#bib.bib109), [68](#bib.bib68)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Blogcatalog [[175](#bib.bib175)] | 5,196 | 171,743 | 8,189 | 6 | [[66](#bib.bib66),
    [124](#bib.bib124), [86](#bib.bib86), [113](#bib.bib113)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Flickr [[175](#bib.bib175)] | 7,564 | 239,365 | 12,047 | 9 | [[66](#bib.bib66),
    [124](#bib.bib124), [113](#bib.bib113)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | DBLP[[176](#bib.bib176)] | 17,725 | 52,890 | 6,974 | 4 | [[95](#bib.bib95),
    [98](#bib.bib98)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  | [[68](#bib.bib68), [79](#bib.bib79), [87](#bib.bib87),
    [81](#bib.bib81), [82](#bib.bib82), [64](#bib.bib64), [84](#bib.bib84), [62](#bib.bib62),
    [86](#bib.bib86), [88](#bib.bib88)], |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |  | [[102](#bib.bib102), [103](#bib.bib103), [112](#bib.bib112),
    [115](#bib.bib115), [116](#bib.bib116), [118](#bib.bib118), [123](#bib.bib123),
    [117](#bib.bib117), [125](#bib.bib125)], |'
  prefs: []
  type: TYPE_TB
- en: '|  | PubMed [[177](#bib.bib177)] | 19,717 | 44,338 | 500 | 3 | [[127](#bib.bib127),
    [128](#bib.bib128), [131](#bib.bib131)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Twitter [[16](#bib.bib16)] | 81,306 | 1,768,149 | 216,839 | 4,065 | [[94](#bib.bib94),
    [109](#bib.bib109), [68](#bib.bib68), [115](#bib.bib115)] |'
  prefs: []
  type: TYPE_TB
- en: '| Attributed Network | GPlus [[16](#bib.bib16)] | 107,614 | 13,673,453 | 15,907
    | 468 | [[109](#bib.bib109), [68](#bib.bib68)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | View1 View2 |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | ACM [[157](#bib.bib157)] | 3,025 | 29,281 2,210,761 | 1,830 | 3 | [[61](#bib.bib61),
    [69](#bib.bib69), [65](#bib.bib65)] |'
  prefs: []
  type: TYPE_TB
- en: '| Multi-view Network | IMDB [[157](#bib.bib157)] | 4,780 | 98,010     21,018
    | 1,232 | 3 | [[61](#bib.bib61), [72](#bib.bib72), [69](#bib.bib69), [65](#bib.bib65)]
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | Edges (+) | Edges (-) |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Epinions [[178](#bib.bib178)] | 7,000 | 404,006 | 47,143 | – | [[67](#bib.bib67)]
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Slashdot [[179](#bib.bib179)] | 7,000 | 181,354 | 56,675 | – | [[67](#bib.bib67)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Signed Network | Wiki [[180](#bib.bib180)] | 7,118 | 81,318 | 22,357 | –
    | [[67](#bib.bib67)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | Metapath |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | ACM[[157](#bib.bib157)] | 8,916 | 12,769 | ✓ | – | [[92](#bib.bib92),
    [91](#bib.bib91)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | IMDB[[157](#bib.bib157)] | 11,616 | 17,106 | ✓ | – | [[72](#bib.bib72),
    [92](#bib.bib92)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Last.fm[[181](#bib.bib181)] | 20,612 | 128,804 | ✓ | – | [[72](#bib.bib72)]
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | DBLP[[182](#bib.bib182)] | 26,128 | 119,783 | ✓ | – | [[72](#bib.bib72),
    [92](#bib.bib92), [91](#bib.bib91)] |'
  prefs: []
  type: TYPE_TB
- en: '|  | Foursquare[[105](#bib.bib105)] | 93,069 | 174,484 | $\times$ | – | [[105](#bib.bib105)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Heterogeneous Network | Twitter[[105](#bib.bib105)] | 9,793,112 | 10,271,142
    | $\times$ | – | [[105](#bib.bib105)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | Time steps |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Hospital [[183](#bib.bib183)] | 75 | 32,424 | 9 | – | [[73](#bib.bib73)]
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Hypertext [[184](#bib.bib184)] | 113 | 20,818 | 5 | – | [[73](#bib.bib73)]
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Enron Mail [[185](#bib.bib185)] | 151 | 33,124 | 12 | – | [[73](#bib.bib73)]
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Rados [[186](#bib.bib186)] | 167 | 82,927 | 10 | – | [[73](#bib.bib73)]
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | High School [[187](#bib.bib187)] | 327 | 188,508 | 9 | – | [[73](#bib.bib73)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Dynamic Network | Cellphone Calls [[73](#bib.bib73)] | 400 | 9,834 | 10 |
    – | [[73](#bib.bib73)] |'
  prefs: []
  type: TYPE_TB
- en: Webpage Networks. The webpage networks connect between one type of world wide
    web resources. IMDB^(18)^(18)18[https://www.imdb.com/](https://www.imdb.com/)
    is a website of movies, containing information like casts, storyline and user
    reviews. Heterogeneous IMDB is constructed by representing nodes through movies,
    actors and directors. Multi-view IMDB exploits co-actor relationship and co-director
    relationship. The bag-of-words of plots are extracted as attributes, community
    can be labeled by movie’s genre. Wiki^(19)^(19)19[https://linqs.soe.ucsc.edu/data](https://linqs.soe.ucsc.edu/data)
    is a webpage network where a node represents the certain webpage, edge means that
    hyperlink connects any two webpages, and attributes from weighted word vectors.
    Another wiki data set is UAI2010 which extracts related article information from
    English-Wikipedia pages. WebKB^(20)^(20)20[https://linqs-data.soe.ucsc.edu/public/lbc/WebKB.tgz](https://linqs-data.soe.ucsc.edu/public/lbc/WebKB.tgz)
    is the webpage data set which contains 4 sub-datasets extracted from four different
    universities, i.e., Cornell, Texas, Washington and Wisconsin.
  prefs: []
  type: TYPE_NORMAL
- en: 'Product Co-purchasing Networks. The Amazon^(21)^(21)21[http://snap.stanford.edu/data/#amazon](http://snap.stanford.edu/data/#amazon)
    data set is provided by Amazon website to analyze the co-purchased products where
    nodes represent products and edges link any two products which are co-purchased
    frequently. The ground truth communities are labeled by product categories. Polbooks^([7](#footnote7
    "footnote 7 ‣ B-A Real-world Data Sets ‣ Appendix B Detailed description: Data
    Sets ‣ A Comprehensive Survey on Community Detection with Deep Learning")) describes
    the purchase of political books during the time of US presidential election in
    2004\. Nodes donate books, edges link any two frequently co-purchased books by
    the same buyers, and the community labels reflect buyers’ political attitude.'
  prefs: []
  type: TYPE_NORMAL
- en: B-B Synthetic Benchmark Data Sets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Girvan-Newman (GN) Networks[[3](#bib.bib3)]: The classic GN benchmark network
    contains 128 nodes that partitioned into 4 communities with 32 nodes in each community.
    Every node has a fixed average degree $k_{in}$ and connects a pre-defined number
    of nodes in another community $k_{out}$. For example, $k_{in}+k_{out}=16$. A parameter
    $\mu$ controls the ratio of neighbors in other communities for each node.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Lancichinetti–Fortunato–Radicchi (LFR) Networks [[137](#bib.bib137)]: The LFR
    benchmark data set simulates the degree of nodes in a real-world network and the
    scale-free nature of the network for more flexible networks. The community validation
    is more challenging, and the results are more convincing. The LFR generation tool
    controls synthetic network topology via a set of parameters, including network
    size $n$, the average $k$ and maximum $Maxk$ degree, the minimum $Minc$ and maximum
    $Maxc$ community size and the mixing parameter $\mu$. The node degree and community
    size are governed by power laws distributions with exponents of $\gamma$ and $\beta$,
    respectively. LFR is the most common simulation benchmark in community detection
    research, the extended LFR benchmark can generate overlapping communities in directed
    and weighted networks [[188](#bib.bib188)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'Appendix C Detailed DESCRIPTION: Evaluation Metrics'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Normalized Mutual Information (NMI): The metric provides a standard evaluation
    on community detection outputs $\mathcal{C}$ and the ground truth $\mathcal{C^{*}}$.
    It reports the mutual parts in a normalized score:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\operatorname{NMI}(\mathcal{C},\mathcal{C^{*}})=\frac{-2\sum_{i=1}^{K}\sum_{j=1}^{K^{*}}n_{ij}\log\frac{n_{ij}n}{n_{i}n_{j}}}{\sum_{i=1}^{K}n_{i}\log\frac{n_{i}}{n}+\sum_{j=1}^{K^{*}}n_{j}\log\frac{n_{j}}{n}},$
    |  | (29) |'
  prefs: []
  type: TYPE_TB
- en: 'where $K$ and $K^{*}$ are the number of detected and ground truth communities,
    respectively, and $n$ is the number of nodes. $n_{ij}$ denotes the number of nodes
    appearing in both the $i$-th detected community $C_{i}$ and the $j$-th ground
    truth community $C_{j}^{*}$. $n_{i}$ and $n_{j}$ sum up the number of nodes in
    $C_{i}$ and $C_{j}^{*}$, respectively. NMI can evaluate overlapping communities
    by its variant: Normalized Mutual Information for Overlapping Community (Overlapping-NMI)[[189](#bib.bib189)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'Accuracy (ACC): ACC evaluates the community membership on each node as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\operatorname{ACC}\left(\mathcal{C},\mathcal{C^{*}}\right)=\frac{1}{n}\sum_{i=1}^{n}\delta(y_{i},y_{i}^{*}),$
    |  | (30) |'
  prefs: []
  type: TYPE_TB
- en: where $y_{i}$ and $y_{i}^{*}$ denote the $i$-th node’s community label in community
    detection results and the ground truth, respectively. The Kronecker delta function
    $\delta=1$ if $y_{i}=y_{i}^{*}$, otherwise $0$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Precision: In the community detection evaluation, precision describes the percentage
    of clustered nodes in each detected community existing in its ground truth:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\operatorname{Precision}(C_{k},C^{*}_{k})=\frac{&#124;C_{k}\cap
    C^{*}_{k}&#124;}{&#124;C_{k}&#124;},$ |  | (31) |'
  prefs: []
  type: TYPE_TB
- en: where $C_{k}$ and $C_{k}^{*}$ denote the $k$-th detected community and groud
    truth community, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall: Accordingly, recall measures the percentage of ground truth nodes of
    each community discovered in the detected community by counting the $k$-th community
    as below:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\operatorname{Recall}(C_{k},C^{*}_{k})=\frac{&#124;C_{k}\cap C^{*}_{k}&#124;}{&#124;C_{k}^{*}&#124;}.$
    |  | (32) |'
  prefs: []
  type: TYPE_TB
- en: 'F1-score: The F1-score balances Precision and Recall:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\begin{aligned} \operatorname{F1-score}&amp;\left(C_{k},C^{*}_{k}\right)=\\
    &amp;2\cdot\frac{\operatorname{Precision}\left(C_{k},C^{*}_{k}\right)\cdot\operatorname{Recall}\left(C_{k},C^{*}_{k}\right)}{\operatorname{Precision}\left(C_{k},C^{*}_{k}\right)+\operatorname{Recall}\left(C_{k},C^{*}_{k}\right)}\end{aligned}.$
    |  | (33) |'
  prefs: []
  type: TYPE_TB
- en: 'Over the whole set of communities, the F1-score evaluates the true/false positive/negative
    node clustering results in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\begin{aligned} \operatorname{F1-score}&amp;\left(\mathcal{C},\mathcal{C}^{*}\right)=\\
    &amp;\sum\nolimits_{C_{k}\in\mathcal{C}}\frac{&#124;C_{k}&#124;}{\sum_{C_{k}\in\mathcal{C}}&#124;C_{k}&#124;}\max\limits_{C_{k}^{*}\in\mathcal{C}^{*}}\operatorname{F1-score}\left(C_{k},C_{k}^{*}\right)\end{aligned}.$
    |  | (34) |'
  prefs: []
  type: TYPE_TB
- en: 'Adjusted Rand Index (ARI): ARI is a variation of Rand Index (RI) that measures
    the percentage of correctly divided nodes based on true/false positive/negative:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\begin{aligned} \operatorname{ARI}&amp;(\mathcal{C},\mathcal{C}^{*})=\\
    &amp;\frac{\sum_{ij}\tbinom{n_{ij}}{2}-\left[\sum_{i}\tbinom{n_{i}}{2}\sum_{j}\tbinom{n_{j}}{2}\right]/\tbinom{n}{2}}{\frac{1}{2}\left[\sum_{i}\tbinom{n_{i}}{2}+\sum_{j}\tbinom{n_{j}}{2}\right]-\left[\sum_{i}\tbinom{n_{i}}{2}\sum_{j}\tbinom{n_{j}}{2}\right]/\tbinom{n}{2}}\end{aligned},$
    |  | (35) |'
  prefs: []
  type: TYPE_TB
- en: where $n$ is the number of nodes, $n_{i}$ is the number of nodes in the $i$-th
    detected community $C_{i}$ while $n_{j}$ denotes the number of nodes in the $j$-th
    ground truth community $C_{j}^{*}$. $n_{ij}$ indicates the number of nodes simultaneously
    appearing in $C_{i}$ and $C_{j}^{*}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Modularity (Q): Q is widely used to evaluate the strength of detected communities
    without ground truth. It compares with a null model which is a random graph with
    an equivalent degree distribution as the original graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small Q=\sum_{k}(e_{kk}-a_{k}^{2}),$ |  | (36) |'
  prefs: []
  type: TYPE_TB
- en: where $e_{kk}$ is the ratio of edges linking nodes within the $k$-th community
    $C_{k}$ to the total edges in network, $a_{k}$ is the proportion of edges that
    associate with nodes in community $C_{k}$ to the number of total edges. The extended
    modularity [[190](#bib.bib190)] evaluates overlapping community detection performances.
  prefs: []
  type: TYPE_NORMAL
- en: 'Jaccard: Jaccard measures whether the $k$-th detected community $C_{k}$ is
    similar to its ground truth $C_{k}^{*}$ as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\operatorname{JC}(C_{k},C_{k}^{*})=\frac{&#124;C_{k}\cap C_{k}^{*}&#124;}{&#124;C_{k}\cup
    C_{k}^{*}&#124;}.$ |  | (37) |'
  prefs: []
  type: TYPE_TB
- en: 'For the whole set of communities, Jaccard is computed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\begin{aligned} \operatorname{JC}\left(\mathcal{C},\mathcal{C}^{*}\right)=&amp;\sum_{C_{k}\in\mathcal{C}}\frac{\max_{C_{k}^{*}\in\mathcal{C}^{*}}\operatorname{JC}(C_{k},C_{k}^{*})}{2&#124;\mathcal{C}&#124;}\\
    &amp;+\sum_{C_{k}^{*}\in\mathcal{C}^{*}}\frac{\max_{C_{k}\in\mathcal{C}}\operatorname{JC}(C_{k},C_{k}^{*})}{2&#124;\mathcal{C^{*}}&#124;}\end{aligned}.$
    |  | (38) |'
  prefs: []
  type: TYPE_TB
- en: 'Conductance (CON): CON measures the separability of the $k$-th detected community
    through the fraction of total edge numbers of $C_{k}$ linking to outside communities:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\operatorname{CON}(C_{k})=\frac{m_{k}^{out}}{2m_{k}^{in}+m_{k}^{out}},$
    |  | (39) |'
  prefs: []
  type: TYPE_TB
- en: where $m_{k}^{in}$ indicates the number of internal edges in community $C_{k}$,
    and $m_{k}^{out}$ is the number of external edges on the cross-community boundary
    of $C_{k}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Triangle Participation Ratio (TPR): TPR indicates the community density through
    measuring the fraction of triads within a detected community $C_{k}$. It is defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\small\begin{array}[]{r}\operatorname{TPR}(C_{k})=\mid\left\{v_{i}:v_{i}\in
    C_{k},\left\{\left(v_{j},v_{w}\right):v_{j},v_{w}\in C_{k},\right.\right.\\ \left.\left.\left(v_{i},v_{j}\right),\left(v_{j},v_{w}\right),\left(v_{i},v_{w}\right)\in
    E\right\}\neq\emptyset\right\}&#124;/&#124;C_{k}&#124;\end{array}.$ |  | (40)
    |'
  prefs: []
  type: TYPE_TB
- en: 'Appendix D Detailed description: Open-source Implementations'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Under PyTorch and GCN: The implementation of LGNN[[78](#bib.bib78)] for community
    detection in graphs runs 5-class distortive SBMs-based GNN and GCN-based LGNN,
    respectively. The main algorithm and other utilities of NOCD[[80](#bib.bib80)]
    implement overlapping community detection. AGE[[84](#bib.bib84)] implements adaptive
    graph encoder for attributed graph embedding and tests node clustering experiment
    results. Under PyTorch and GAT: DMGI[[61](#bib.bib61)] and HDMI[[65](#bib.bib65)]
    examine graph clustering performance on unsupervised attributed multiplex network
    embedding. The implementation of MAGNN[[72](#bib.bib72)] provides instructions
    to detect node clusters in heterogeneous graphs via metapath aggregated GNN. HeCo[[91](#bib.bib91)]
    testifies the model’s performance of node clustering on heterogeneous networks
    with providing four preprocessed data sets. CP-GNN[[92](#bib.bib92)] implements
    experiments of community detection on four real-world heterogeneous graphs. SEAL
    [[94](#bib.bib94)] runs algorithms on Python and Shell validating on 50 communities.
    Under PyTorch and AEs: GraphEncoder[[107](#bib.bib107)] implements for graph clustering
    on deep representations. Under the DNN architecture, SDCN[[114](#bib.bib114)]
    cluster the graph on AE embeddings.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Under TensorFlow and GCN: AGC[[64](#bib.bib64)] clusters attributed graph via
    adaptive graph convolution and intra-cluster distance computation. CayleyNet[[85](#bib.bib85)]
    presents an implementation of community detection for a variety of different networks,
    including a sparse filter and rational spectral filters with Jacobi. There is
    an implementation on the CommunityGAN [[96](#bib.bib96)] method under TensorFlow
    and GAN. DIME[[105](#bib.bib105)] and DANE[[103](#bib.bib103)] are stacked AE-based
    implementations applying TensorFlow. On heterogeneous networks: Foursquare and
    Twitter, DIME[[105](#bib.bib105)] examines community detection results and hyperparameters.
    For graph convolutional AE-based community detection tasks, TensorFlow is employed
    by O2MAC[[69](#bib.bib69)] and SGCMC[[119](#bib.bib119)] over multi-view graphs,
    while DMGC[[120](#bib.bib120)] via attentive cross-graph association for deep
    multi-graph clustering. Moreover, DGLFRM[[123](#bib.bib123)] and ARGA/ARVGA[[128](#bib.bib128)]
    apply TensorFlow to VAE-based community detection. Other Python packages, such
    as Keras, are employed in our summarized implementations, i.e., DNGR[[112](#bib.bib112)].'
  prefs: []
  type: TYPE_NORMAL
- en: Despite the popularity of Python, Matlab is another popular tool to implement
    deep community detection methods. semi-DRN[[63](#bib.bib63)] implements community
    detection via stacked AE. DNE-SBP [[67](#bib.bib67)] inputs signed adjacency matrix
    to detect $k$ network communities upon node representations. MGAE[[111](#bib.bib111)]
    makes use of marginalized graph autoencoder to cluster graph.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix E Abbreviations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'TABLE X: Abbreviations in this survey.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Abbr. | Full Name | Ref. | Paper Title |'
  prefs: []
  type: TYPE_TB
- en: '| ACC | Accuracy |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Network Embedding and overlapping Community |  | Self-Training Enhanced:
    Network embedding and overlapping |'
  prefs: []
  type: TYPE_TB
- en: '| ACNE[[98](#bib.bib98)] | detection with Adversarial learning | [[98](#bib.bib98)]
    | community detection with adversarial learning |'
  prefs: []
  type: TYPE_TB
- en: '| AE | AutoEncoder |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| AGC | Adaptive Graph Convolution | [[64](#bib.bib64)] | Attributed graph
    clustering via adaptive graph convolution |'
  prefs: []
  type: TYPE_TB
- en: '| AGE | Adaptive Graph Encoder | [[84](#bib.bib84)] | Adaptive graph encoder
    for attributed graph embedding |'
  prefs: []
  type: TYPE_TB
- en: '| ARGA | Adversarial Regularized Graph AutoEncoder | [[128](#bib.bib128)] |
    Adversarially regularized graph autoencoder for graph embedding |'
  prefs: []
  type: TYPE_TB
- en: '| ARI | Adjusted Rand Index |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Adversarially Regularized Variational Graph |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| ARVGA | AutoEncoder | [[128](#bib.bib128)] | Adversarially regularized graph
    autoencoder for graph embedding |'
  prefs: []
  type: TYPE_TB
- en: '| ATC | Attributed Truss Communities | [[149](#bib.bib149)] | Attribute-driven
    community search |'
  prefs: []
  type: TYPE_TB
- en: '| BP | Bernoulli–Poisson |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | CANE: community-aware network embedding via adversarial |'
  prefs: []
  type: TYPE_TB
- en: '| CANE | Community-Aware Network Embedding | [[97](#bib.bib97)] | training
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Graph Convolutional Neural Networks with |  | CayleyNets: Graph convolutional
    neural networks with complex |'
  prefs: []
  type: TYPE_TB
- en: '| CayleyNets | Cayley Polynomials | [[85](#bib.bib85)] | rational spectral
    filters |'
  prefs: []
  type: TYPE_TB
- en: '|  | Community Detection Algorithm based on |  | Community detection in complex
    networks using structural |'
  prefs: []
  type: TYPE_TB
- en: '| CDASS | Structural Similarity | [[44](#bib.bib44)] | similarity |'
  prefs: []
  type: TYPE_TB
- en: '|  | (Stacked Autoencoder-Based) Community |  | Stacked autoencoder-based community
    detection method via |'
  prefs: []
  type: TYPE_TB
- en: '| CDMEC | Detection Method via Ensemble Clustering | [[110](#bib.bib110)] |
    an ensemble clustering framework |'
  prefs: []
  type: TYPE_TB
- en: '| CNN | Convolutional Neural Network |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| CommDGI | Community Deep Graph Infomax | [[87](#bib.bib87)] | CommDGI: Community
    detection oriented deep graph infomax |'
  prefs: []
  type: TYPE_TB
- en: '|  | Community Detection with Generative |  | CommunityGAN: Community detection
    with generative |'
  prefs: []
  type: TYPE_TB
- en: '| CommunityGAN | Adversarial Nets | [[96](#bib.bib96)] | adversarial nets |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | Edge classification based on Convolutional Neural Networks |'
  prefs: []
  type: TYPE_TB
- en: '| ComNet-R | Community Network Local Modularity R | [[77](#bib.bib77)] | for
    community detection in complex network |'
  prefs: []
  type: TYPE_TB
- en: '| CON | Conductance |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | Detecting communities from heterogeneous graphs: A Context |'
  prefs: []
  type: TYPE_TB
- en: '| CP-GNN | Context Path-based Graph Neural Network | [[92](#bib.bib92)] | path-based
    graph neural network model |'
  prefs: []
  type: TYPE_TB
- en: '| DAEGC | Deep Attentional Embedded Graph Clustering | [[116](#bib.bib116)]
    | Attributed graph clustering: A deep attentional embedding approach |'
  prefs: []
  type: TYPE_TB
- en: '| DANE | Deep Attributed Network Embedding | [[103](#bib.bib103)] | Deep attributed
    network embedding |'
  prefs: []
  type: TYPE_TB
- en: '|  | Deep Autoencoder-like Nonnegative |  | Deep autoencoder-like nonnegative
    matrix factorization for |'
  prefs: []
  type: TYPE_TB
- en: '| DANMF | Matrix Fatorization | [[131](#bib.bib131)] | community detection
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Density-Based Spatial Clustering of |  | A density-based algorithm for
    discovering clusters in large |'
  prefs: []
  type: TYPE_TB
- en: '| DBSCAN | Applications with Noise | [[48](#bib.bib48)] | spatial databases
    with noise |'
  prefs: []
  type: TYPE_TB
- en: '| DCSBM | Degree-Corrected Stochastic Block Model | [[30](#bib.bib30)] | Stochastic
    blockmodels and community structure in networks |'
  prefs: []
  type: TYPE_TB
- en: '|  | Deep Learning-based Fuzzy |  | DFuzzy: A deep learning-based fuzzy clustering
    model for large |'
  prefs: []
  type: TYPE_TB
- en: '| DFuzzy | Clustering Model | [[109](#bib.bib109)] | graphs |'
  prefs: []
  type: TYPE_TB
- en: '|  | Deep Generative Latent Feature Relational |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| DGLFRM | Model | [[123](#bib.bib123)] | Stochastic blockmodels meet graph
    neural networks |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | BL-MNE: Emerging heterogeneous social network embedding |'
  prefs: []
  type: TYPE_TB
- en: '| DIME | Deep Aligned Autoencoder-based Embedding | [[105](#bib.bib105)] |
    through broad learning with aligned autoencoder |'
  prefs: []
  type: TYPE_TB
- en: '| DMGC | Deep Multi-Graph Clustering | [[120](#bib.bib120)] | Deep multi-graph
    clustering via attentive cross-graph association |'
  prefs: []
  type: TYPE_TB
- en: '|  | Deep Graph Infomax for attributed |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| DMGI | Multiplex network embedding | [[61](#bib.bib61)] | Unsupervised attributed
    multiplex network embedding |'
  prefs: []
  type: TYPE_TB
- en: '|  | Deep Neural network-based Clustering-oriented |  | DNC: A deep neural
    network-based clustering-oriented network |'
  prefs: []
  type: TYPE_TB
- en: '| DNC | network embedding | [[113](#bib.bib113)] | embedding algorithm |'
  prefs: []
  type: TYPE_TB
- en: '|  | Deep Network Embedding with |  | Deep network embedding for graph representation
    learning |'
  prefs: []
  type: TYPE_TB
- en: '| DNE-SBP | Structural Balance Preservation | [[67](#bib.bib67)] | in signed
    networks |'
  prefs: []
  type: TYPE_TB
- en: '| DNGR | Deep Neural Networks for Graph Representation | [[112](#bib.bib112)]
    | Deep neural networks for learning graph representations |'
  prefs: []
  type: TYPE_TB
- en: '| DNMF | Deep Nonnegative Matrix Factorization |  |  |'
  prefs: []
  type: TYPE_TB
- en: 'TABLE XI: Abbreviations in this survey (continue-1).'
  prefs: []
  type: TYPE_NORMAL
- en: '| Abbr. | Full Name | Ref. | Paper Title |'
  prefs: []
  type: TYPE_TB
- en: '| DNN | Deep Neural Network |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Dual-Regularized Graph Convolutional |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| DR-GCN | Networks | [[95](#bib.bib95)] | Multi-class imbalanced graph convolutional
    network learning |'
  prefs: []
  type: TYPE_TB
- en: '| DSF | Deep Sparse Filtering |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Community Discovery based on Deep |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| DSFCD | Sparse Filtering | [[135](#bib.bib135)] | Community discovery in
    networks with deep sparse filtering |'
  prefs: []
  type: TYPE_TB
- en: '| ELBO | Evidence Lower Bound |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| EM | Expectation-Maximization algorithm |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | Graph convolutional networks meet Markov random fields: |'
  prefs: []
  type: TYPE_TB
- en: '| eMRF | extended Network Markov Random Fields | [[10](#bib.bib10)] | Semi-supervised
    community detection in attribute networks |'
  prefs: []
  type: TYPE_TB
- en: '| FastQ | Fast Modularity |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| GAN | Generative Adversarial Network |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| GAT | Graph Attention Network |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| GCLN | Graph Convolutional Ladder-shape Networks | [[81](#bib.bib81)] | Going
    deep: Graph convolutional ladder-shape networks |'
  prefs: []
  type: TYPE_TB
- en: '| GCN | Graph Convolutional Network |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Graph embedding clustering with |  | Graph embedding clustering: Graph
    attention auto-encoder with |'
  prefs: []
  type: TYPE_TB
- en: '| GEC-CSD | cluster-specificity distribution | [[117](#bib.bib117)] | cluster-specificity
    distribution |'
  prefs: []
  type: TYPE_TB
- en: '| GIN | Graph Isomorphism Network |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| GMM | Gaussian Mixture Model |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| GN | Girvan-Newman networks |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| GRACE | Graph Clustering with Dynamic Embedding | [[68](#bib.bib68)] | Graph
    clustering with dynamic embedding |'
  prefs: []
  type: TYPE_TB
- en: '| GraphEncoder | Autoencoder-based Graph Clustering Model | [[107](#bib.bib107)]
    | Learning deep representations for graph clustering |'
  prefs: []
  type: TYPE_TB
- en: '|  | GCN-based approach for Unsupervised |  | Community-centric graph convolutional
    network for unsupervised |'
  prefs: []
  type: TYPE_TB
- en: '| GUCD | Community Detection | [[115](#bib.bib115)] | community detection |'
  prefs: []
  type: TYPE_TB
- en: '| HDMI | High-order Deep Multiplex Infomax | [[65](#bib.bib65)] | HDMI: High-order
    deep multiplex infomax |'
  prefs: []
  type: TYPE_TB
- en: '|  | Co-contrastive learning mechanism for |  | Self-supervised heterogeneous
    graph neural network with co-contrastive |'
  prefs: []
  type: TYPE_TB
- en: '| HeCo | Heterogeneous graph neural networks | [[91](#bib.bib91)] | learning
    |'
  prefs: []
  type: TYPE_TB
- en: '| HIN | Heterogeneous Information Network |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| HSIC | Hilbert-Schmidt Independence Criterion | [[83](#bib.bib83)] | Measuring
    statistical dependence with Hilbert-Schmidt norms |'
  prefs: []
  type: TYPE_TB
- en: '| InfoMap | Information Mapping | [[46](#bib.bib46)] | Maps of random walks
    on complex networks reveal community structure |'
  prefs: []
  type: TYPE_TB
- en: '|  | Graph Pointer Network with incremental |  | SEAL: Learning heuristics
    for community detection with generative |'
  prefs: []
  type: TYPE_TB
- en: '| iGPN | updates | [[94](#bib.bib94)] | adversarial networks |'
  prefs: []
  type: TYPE_TB
- en: '|  | Independence Promoted Graph Disentangled |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| IPGDN | Network | [[82](#bib.bib82)] | Independence promoted graph disentangled
    networks |'
  prefs: []
  type: TYPE_TB
- en: '| JANE | Jointly Adversarial Network Embedding | [[62](#bib.bib62)] | JANE:
    Jointly adversarial network embedding |'
  prefs: []
  type: TYPE_TB
- en: '| KL | Kullback-Leibler divergence |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Locating Structural Centers for Community |  | Locating structural centers:
    A density-based clustering method for |'
  prefs: []
  type: TYPE_TB
- en: '| LCCD | Detection | [[50](#bib.bib50)] | community detection |'
  prefs: []
  type: TYPE_TB
- en: '| LDA | Latent Dirichlet Allocation |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| LFR | Lancichinetti–Fortunato–Radicchi networks |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| LGNN | Line Graph Neural Network | [[78](#bib.bib78)] | Supervised community
    detection with line graph neural networks |'
  prefs: []
  type: TYPE_TB
- en: '|  | Ladder Gamma Variational Autoencoder for |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| LGVG | Graphs | [[127](#bib.bib127)] | Graph representation learning via
    ladder gamma variational autoencoders |'
  prefs: []
  type: TYPE_TB
- en: '| LPA | Label Propagation Algorithm |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | A multi-agent genetic algorithm for community detection in complex
    |'
  prefs: []
  type: TYPE_TB
- en: '| MAGA-Net | Multi-Agent Genetic Algorithm | [[56](#bib.bib56)] | networks
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Multi-View Attribute Graph Convolution |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| MAGCN | Networks | [[118](#bib.bib118)] | Multi-view attribute graph convolution
    networks for clustering |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | MAGNN: Metapath aggregated graph neural network for heterogeneous
    |'
  prefs: []
  type: TYPE_TB
- en: '| MAGNN | Metapath Aggregated Graph Neural Network | [[72](#bib.bib72)] | graph
    embedding |'
  prefs: []
  type: TYPE_TB
- en: '|  | Modularized Deep NonNegative Matrix |  | Community detection based on
    modularized deep nonnegative matrix |'
  prefs: []
  type: TYPE_TB
- en: '| MDNMF | Factorization | [[133](#bib.bib133)] | factorization |'
  prefs: []
  type: TYPE_TB
- en: '| MGAE | Marginalized Graph AutoEncoder | [[111](#bib.bib111)] | MGAE: Marginalized
    graph autoencoder for graph clustering |'
  prefs: []
  type: TYPE_TB
- en: 'TABLE XII: Abbreviations in this survey (continue-2).'
  prefs: []
  type: TYPE_NORMAL
- en: '| Abbr. | Full Name | Ref. | Paper Title |'
  prefs: []
  type: TYPE_TB
- en: '| MI | Mutual Information |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| MMB | Mixed Membership Stochastic Blockmodel | [[31](#bib.bib31)] | Mixed
    membership stochastic blockmodels |'
  prefs: []
  type: TYPE_TB
- en: '|  | Markov Random Fields as a convolutional |  | Graph convolutional networks
    meet Markov random fields: |'
  prefs: []
  type: TYPE_TB
- en: '| MRFasGCN | layer in Graph Convolutional Networks | [[10](#bib.bib10)] | Semi-supervised
    community detection in attribute networks |'
  prefs: []
  type: TYPE_TB
- en: '| NMF | Nonnegative Matrix Factorization |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| NMI | Normalized Mutual Information |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| NOCD | Neural Overlapping Community Detection | [[80](#bib.bib80)] | Overlapping
    community detection with graph neural networks |'
  prefs: []
  type: TYPE_TB
- en: '| One2Multi | One-view to Multi-view | [[69](#bib.bib69)] | One2multi graph
    autoencoder for multi-view graph clustering |'
  prefs: []
  type: TYPE_TB
- en: '|  | One2Multi Graph Autoencoder for Multi-view |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| O2MAC | Graph Clustering | [[69](#bib.bib69)] | One2multi graph autoencoder
    for multi-view graph clustering |'
  prefs: []
  type: TYPE_TB
- en: '| PPI | Protein-Protein Interaction |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | Progan: Network embedding via proximity generative |'
  prefs: []
  type: TYPE_TB
- en: '| ProGAN | Proximity Generative Adversarial Network | [[66](#bib.bib66)] |
    adversarial network |'
  prefs: []
  type: TYPE_TB
- en: '| Q | Modularity |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| SBM | Stochastic Block Model |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| SCAN | Structural Clustering Algorithm for Networks | [[49](#bib.bib49)]
    | SCAN: A structural clustering algorithm for networks |'
  prefs: []
  type: TYPE_TB
- en: '| SDCN | Structural Deep Clustering Network | [[114](#bib.bib114)] | Structural
    deep clustering network |'
  prefs: []
  type: TYPE_TB
- en: '|  | Seed Expansion with generative Adversarial |  | SEAL: Learning heuristics
    for community detection with |'
  prefs: []
  type: TYPE_TB
- en: '| SEAL | Learning | [[94](#bib.bib94)] | generative adversarial networks |'
  prefs: []
  type: TYPE_TB
- en: '|  | Semi-supervised Nonlinear Reconstruction |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| semi-DRN | Algorithm with Deep Nerual Network | [[63](#bib.bib63)] | Modularity
    based community detection with deep learning |'
  prefs: []
  type: TYPE_TB
- en: '| sE-Autoencoder | Semi-supervised Evolutionary Autoencoder | [[73](#bib.bib73)]
    | An evolutionary autoencoder for dynamic community detection |'
  prefs: []
  type: TYPE_TB
- en: '| SENet | Spectral Embedding Network | [[86](#bib.bib86)] | Spectral embedding
    network for attributed graph clustering |'
  prefs: []
  type: TYPE_TB
- en: '| SF | Sparse Filtering |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| SGC | Simplification of GCN | [[191](#bib.bib191)] | Simplifying graph convolutional
    networks |'
  prefs: []
  type: TYPE_TB
- en: '|  | Self-supervised Graph Convolutional network |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| SGCMC | for Multi-view Clustering | [[119](#bib.bib119)] | Self-supervised
    graph convolutional network for multi-view clustering |'
  prefs: []
  type: TYPE_TB
- en: '|  | A framework of local label sampling model |  | Unsupervised learning for
    community detection in attributed |'
  prefs: []
  type: TYPE_TB
- en: '| SGCN | and GCN model | [[79](#bib.bib79)] | networks based on graph convolutional
    network |'
  prefs: []
  type: TYPE_TB
- en: '| SGVB | Stochastic Gradient Variational Bayes |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| SparseConv | Sparse Matrix Convolution | [[70](#bib.bib70)] | A deep learning
    based community detection approach |'
  prefs: []
  type: TYPE_TB
- en: '| REM | Residual Entropy Minimization |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| TGA/TVGA | Triad (Variational) Graph Autoencoder | [[126](#bib.bib126)] |
    Effective decoding in graph auto-encoder using triadic closure |'
  prefs: []
  type: TYPE_TB
- en: '| TIN | Topologically Incomplete Networks |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Transfer Learning-inspired Community |  | High-performance community detection
    in social networks using |'
  prefs: []
  type: TYPE_TB
- en: '| Transfer-CDDTA | Detection with Deep Transitive Autoencoder | [[104](#bib.bib104)]
    | a deep transitive autoencoder |'
  prefs: []
  type: TYPE_TB
- en: '| TPR | Triangle Participation Ratio |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Unified Weight-free Multi-component |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| UWMNE | Network Embedding | [[102](#bib.bib102)] | Integrative network embedding
    via deep joint reconstruction |'
  prefs: []
  type: TYPE_TB
- en: '| VAE | Variational AutoEncoder | [[121](#bib.bib121)] | Auto-encoding variational
    bayes |'
  prefs: []
  type: TYPE_TB
- en: '| VGAE | Variational Graph AutoEncoder | [[122](#bib.bib122)] | Variational
    graph auto-encoders |'
  prefs: []
  type: TYPE_TB
- en: '|  | Variational Graph Autoencoder for |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| VGAECD | Community Detection | [[125](#bib.bib125)] | Learning community
    structure with variational autoencoder |'
  prefs: []
  type: TYPE_TB
- en: '|  | Optimizing Variational Graph Autoencoder |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| VGAECD-OPT | for Community Detection | [[136](#bib.bib136)] | Optimizing
    variational graph autoencoder for community detection |'
  prefs: []
  type: TYPE_TB
- en: '|  | Variational Graph Embedding and Clustering |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| VGECLE | with Laplacian Eigenmaps | [[124](#bib.bib124)] | Variational graph
    embedding and clustering with Laplacian eigenmaps |'
  prefs: []
  type: TYPE_TB
- en: '| WalkTrap | WalkTrap | [[45](#bib.bib45)] | Computing communities in large
    networks using random walks |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | A weighted network community detection algorithm based on deep |'
  prefs: []
  type: TYPE_TB
- en: '| WCD | Weighted Community Detection | [[108](#bib.bib108)] | learning |'
  prefs: []
  type: TYPE_TB
- en: '|  | Weight-free Multi-Component Network |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| WMCNE-LE | Embedding with Local Enhancement | [[102](#bib.bib102)] | Integrative
    network embedding via deep joint reconstruction |'
  prefs: []
  type: TYPE_TB
