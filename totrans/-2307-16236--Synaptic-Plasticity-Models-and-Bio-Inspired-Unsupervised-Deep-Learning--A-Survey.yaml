- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:37:40'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2307.16236] Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep
    Learning: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2307.16236](https://ar5iv.labs.arxiv.org/html/2307.16236)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Gabriele Lagani [gabriele.lagani@isti.cnr.it](mailto:gabriele.lagani@isti.cnr.it)
    ,  Fabrizio Falchi [fabrizio.falchi@isti.cnr.it](mailto:fabrizio.falchi@isti.cnr.it)
    ,  Claudio Gennaro [claudio.gennaro@isti.cnr.it](mailto:claudio.gennaro@isti.cnr.it)
     and  Giuseppe Amato [giuseppe.amato@isti.cnr.it](mailto:giuseppe.amato@isti.cnr.it)
    ISTI-CNRPisaItaly56124(2018)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Recently emerged technologies based on Deep Learning (DL) achieved outstanding
    results on a variety of tasks in the field of Artificial Intelligence (AI). However,
    these encounter several challenges related to robustness to adversarial inputs,
    ecological impact, and the necessity of huge amounts of training data. In response,
    researchers are focusing more and more interest on biologically grounded mechanisms,
    which are appealing due to the impressive capabilities exhibited by biological
    brains. This survey explores a range of these biologically inspired models of
    synaptic plasticity, their application in DL scenarios, and the connections with
    models of plasticity in Spiking Neural Networks (SNNs). Overall, Bio-Inspired
    Deep Learning (BIDL) represents an exciting research direction, aiming at advancing
    not only our current technologies but also our understanding of intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bio-Inspired, Hebbian, Deep Learning, Neural Networks, Spiking^†^†copyright:
    acmcopyright^†^†journalyear: 2018^†^†doi: XXXXXXX.XXXXXXX^†^†ccs: Computing methodologies Bio-inspired
    approaches^†^†ccs: Computing methodologies Bio-inspired approaches'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the past decade, Deep Learning (DL) technologies have attained performance
    levels equivalent to, or even surpassing, human capabilities across a multitude
    of Artificial Intelligence (AI) applications, such as computer vision (He et al.,
    [2016](#bib.bib89)), reinforcement learning (Silver et al., [2016](#bib.bib220)),
    or language processing (Devlin et al., [2019](#bib.bib58)). Although Deep Neural
    Network (DNN) models were originally inspired by biological mechanisms, current
    technologies have observed a significant departure from their biological counterparts.
    For example, the biological plausibility of the error backpropagation algorithm
    (backprop) – the workhorse of DL – is questioned by neuroscientists (O’Reilly
    and Munakata, [2000](#bib.bib186); Marblestone et al., [2016](#bib.bib164); Hassabis
    et al., [2017](#bib.bib87); Lake et al., [2017](#bib.bib142); Richards et al.,
    [2019](#bib.bib200)).
  prefs: []
  type: TYPE_NORMAL
- en: In this survey, we highlight the connections of biological plausibility with
    a number of other challenges that current DL solutions still need to overcome,
    such as the lack of robustness of traditional DNN architectures to adversarially
    perturbed inputs (Goodfellow et al., [2014](#bib.bib83)), the necessity of huge
    amounts of labeled data (Roh et al., [2019](#bib.bib203)), or the ecological impact
    of neural network training (Badar et al., [2021](#bib.bib13)). For example, in
    (Badar et al., [2021](#bib.bib13)) it is shown how more complex and large-scale
    models allow to improve benchmark results but at a higher energy cost, which is
    typically not taken into account when comparing against other models. On the other
    hand, biological intelligence can exhibit proficient and robust behavior in a
    variety of tasks (Mainen and Sejnowski, [1995](#bib.bib159); Gerstner et al.,
    [1996](#bib.bib79)), while generalizing from little experience (Lake and Piantadosi,
    [2020](#bib.bib141)), with an exceptionally low energy expenditure (Javed et al.,
    [2010](#bib.bib109)). Therefore, it appears that drawing inspiration from biology
    could once again provide valuable insights toward addressing the challenges presented
    above. Indeed, in recent years, significant research efforts have been devoted
    to the development of bio-inspired solutions for DL.
  prefs: []
  type: TYPE_NORMAL
- en: In order to achieve a better understanding of the principles and mechanisms
    behind biological intelligence, scientific investigation moves from two different
    perspectives. On one hand, neuroscientists uncover the low-level working principles
    of biological intelligent systems and try to relate them to high-level intelligent
    behavior in a bottom-up fashion. On the other hand, computer scientists start
    from high-level abstractions to model AI problems and then work out the structures
    and architectural details needed to solve such problems. Unfortunately, finding
    the connections between the high-level and the low-level aspects is often difficult.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1245373a81a17301737a5391b4184229.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1. A schematic view of the topics of Bio-Inspired Deep Learning (BIDL)
    addressed in this work. We provide a comprehensive discussion on biologically
    grounded synaptic plasticity models, starting from Hebbian learning models for
    a single neuron to more complex models for populations of multiple neurons, such
    as competitive learning, subspace learning, etc. These approaches are related
    to pattern discovery mechanisms such as clustering, Principal Component Analysis
    (PCA), manifold learning, etc., thus providing interesting connections between
    neuroscientific models and computer science/engineering aspects of AI. One of
    the goals of this survey is to highlight the relationships between these two fields,
    showing how complex intelligent behavior can emerge from biologically-inspired
    principles.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal of this survey is to provide a comprehensive review of Bio-Inspired
    Deep Learning (BIDL), highlighting the connections between neuroscience and computer
    science viewpoints. We aim to provide a complete picture of the variety of perspectives,
    methods, and solutions that come together in this field, ranging from synaptic
    plasticity models to biologically realistic Spiking Neural Network (SNN) models.
    Fig. [1](#S1.F1 "Figure 1 ‣ 1\. Introduction ‣ Synaptic Plasticity Models and
    Bio-Inspired Unsupervised Deep Learning: A Survey") provides a schematic summary
    of the various sub-topics embraced in this document.'
  prefs: []
  type: TYPE_NORMAL
- en: This survey is intended both as a first approach for readers that are new to
    this field as well as a compact reference for a more experienced audience. The
    contents of this document should be easily accessible to computer scientists,
    as no prerequisite neuroscientific knowledge is expected, but they could also
    represent an interesting read for neuroscientists that are curious about the engineering
    aspects behind AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'This document is structured as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Section [2](#S2 "2\. Related Surveys ‣ Synaptic Plasticity Models and Bio-Inspired
    Unsupervised Deep Learning: A Survey") discusses related surveys in the BIDL field.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Section [3](#S3 "3\. Synaptic Plasticity Models and Hebbian Learning in a Single
    Neuron ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning:
    A Survey") describes biological synaptic plasticity models based on the Hebbian
    principle for a single neuron.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Section [4](#S4 "4\. Plasticity Models for Unsupervised Pattern Discovery with
    Multiple Neurons ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep
    Learning: A Survey") illustrates the extensions of plasticity mechanisms to populations
    of multiple neurons. It will be interesting to observe how certain biological
    aspects turn out to be related to unsupervised pattern discovery methods, thus
    showing a surprising connection between computer science and neuroscience.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Section [5](#S5 "5\. Synaptic Plasticity Models in Deep Learning ‣ Synaptic
    Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey") presents
    some experimental results from the literature regarding the application of synaptic
    plasticity models to DL contexts and the integration of traditional backprop-based
    learning and bio-inspired synaptic plasticity.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Section [6](#S6 "6\. Spiking Neural Networks ‣ Synaptic Plasticity Models and
    Bio-Inspired Unsupervised Deep Learning: A Survey") introduces biologically detailed
    models of neural computation based on SNNs, and highlights their technological
    potential for energy-efficient neuromorphic computing.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we present our conclusions in Section [7](#S7 "7\. Concluding Remarks
    ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey"),
    outlining open challenges and possible future research directions.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Moreover, in our companion paper (Amato et al., [2023](#bib.bib10)), we discuss
    biological models of spike coding and computation in greater detail, and we highlight
    the challenges of training such models with traditional backprop-based optimization.
    Therefore, we discuss recently proposed training algorithms, which pose themselves
    as alternatives to backprop, both for spiking and traditional architectures. These
    novel perspectives are promising to enhance the learning capabilities of current
    DL systems through biological insights and inspiration.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Related Surveys
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Several aspects of BIDL have been reviewed in past contributions, each focused
    on a specific area or collection of methods. Some of these contributions are rooted
    in the neuroscientific viewpoint, while others explore more practical perspectives
    on DL system engineering. Our contribution aims at achieving a comprehensive presentation
    of the various domains and their interplay involved in the BIDL field, showing
    the connections between the neuroscientific aspects and the engineering abstractions.
  prefs: []
  type: TYPE_NORMAL
- en: An interesting treatment on the relationships between neuroscience and AI can
    be found in (Marblestone et al., [2016](#bib.bib164)), where the authors outline
    successful contributions in various aspects of DL, and propose directions of investigation
    for the neuroscientific field based on the insights provided by the high-level
    computational abstractions engineered by computer scientists. Similarly, the authors
    also suggest possible directions of inspiration that might come from neuroscience,
    towards the development of novel DL solutions. A similar discussion is presented
    in (Hassabis et al., [2017](#bib.bib87)), where the authors review historical
    interactions between computer science and neuroscience, showing how these interactions
    lead to novel results in these fields, and highlight possible shared themes for
    future development. Conversely, in (Richards et al., [2019](#bib.bib200)) it is
    outlined how architectures, objective functions, and learning rules developed
    for artificial learning systems can inspire further developments in system neuroscience.
    Focusing on biological and psychological inspiration, another work (Lake et al.,
    [2017](#bib.bib142)) suggests specific areas of exploration towards building more
    human-like DL systems, ranging from causal reasoning to compositional learning
    and program induction, as well as learning-to-learn approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Concerning the biologically grounded modeling of neural systems, in their book,
    Gerstner and Kistler (Gerstner and Kistler, [2002](#bib.bib80)) provides a comprehensive
    presentation of SNN models, as well as Hebbian plasticity and Spike Time Dependent
    Plasticity (STDP) models. A variety of Hebbian plasticity models are also reviewed
    in (Gorchetchnikov et al., [2011](#bib.bib84); Vasilkoski et al., [2011](#bib.bib231)),
    while recent SNN developments and applications are surveyed in (Pfeiffer and Pfeil,
    [2018](#bib.bib194); Tavanaei et al., [2019](#bib.bib228); Nunes et al., [2022](#bib.bib177)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Compared to previous surveys, we provide significant contributions in the following
    directions:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compared to works more focused on high-level perspectives about the interplay
    between neuroscience and computer science as a source of biological inspiration
    (Marblestone et al., [2016](#bib.bib164); Hassabis et al., [2017](#bib.bib87);
    Richards et al., [2019](#bib.bib200); Lake et al., [2017](#bib.bib142)), our work
    delves deeper into specific aspects where the connections between neuroscientific
    models and emergent computational properties arise;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We provide a comprehensive description of bio-inspired synaptic plasticity models,
    showing the connections with learning principles that lead to autonomous pattern
    discovery as a resulting behavior, while other contributions only focus on the
    biological models of synaptic plasticity (Gerstner and Kistler, [2002](#bib.bib80);
    Gorchetchnikov et al., [2011](#bib.bib84); Vasilkoski et al., [2011](#bib.bib231));
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We provide parallel perspectives on bio-inspired methods for traditional networks
    and those based on spiking models, compared to works dedicated only to low-level
    spike-based methods (Pfeiffer and Pfeil, [2018](#bib.bib194); Tavanaei et al.,
    [2019](#bib.bib228); Nunes et al., [2022](#bib.bib177)).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3\. Synaptic Plasticity Models and Hebbian Learning in a Single Neuron
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout life, our brain is continually subject to modifications in order
    to incorporate knowledge from the environment and adapt to new tasks. This adaptation
    process is referred to as plasticity. The most prominent form of plasticity occurs
    in synapses, in the form of strengthening of synaptic efficacy, a.k.a. Long Term
    Potentiation (LTP), or weakening, a.k.a. Long Term Depression (LTD) (Bear, [1996](#bib.bib19);
    Gerstner and Kistler, [2002](#bib.bib80)). Given the crucial role that synaptic
    plasticity plays in neural systems, we begin this review by discussing synaptic
    plasticity models, starting from the simplest formulation of Hebbian plasticity,
    and then moving to more complex models that also recently found applications in
    DNN training. One of the challenges of formulating biologically plausible models
    of synaptic plasticity is the necessity to define local learning rules, i.e. using
    only information that is locally available at the neuron site for computing the
    synaptic updates.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/66810b66e54476ceafc0e5ce390e880a.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2. Representation of a neuron model which takes a vector $\mathbf{x}$
    as input. Inputs are modulated by synaptic weights $\mathbf{w}$, and then summed
    together, before a nonlinearity $f(\cdot)$ is applied. The resulting output is
    $y=f(\sum_{i}w_{i}\,x_{i})$ (where subscript $i$ indexes a specific vector entry).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us consider a neuron model whose synaptic weights are described by a vector
    $\mathbf{w}$. The neuron takes as input a vector $\mathbf{x}$, and produces an
    output $y(\mathbf{x},\mathbf{w})=f(\mathbf{x}^{T}\,\mathbf{w})$ (Fig. [2](#S3.F2
    "Figure 2 ‣ 3\. Synaptic Plasticity Models and Hebbian Learning in a Single Neuron
    ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey")),
    where $f$ is the activation function (optionally, a bias term can be implicitly
    modeled as a synapse connected to a constant input). In the following, we use
    boldface fonts to denote vectors, and normal fonts to denote scalars. In neuroscientific
    terms, input values $\mathbf{x}$ are also termed pre-synaptic activations, while
    the output $y$ is termed post-synaptic activation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to model synaptic plasticity, neuroscientists propose the Hebbian
    principle (Haykin, [2009](#bib.bib88); Gerstner and Kistler, [2002](#bib.bib80)):
    ”fire together, wire together”. According to this principle, the synaptic coupling
    between two neurons is reinforced when the two neurons are simultaneously active
    (Haykin, [2009](#bib.bib88); Gerstner and Kistler, [2002](#bib.bib80)). Mathematically,
    this learning rule, in its simplest ”vanilla” formulation, can be expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (1) |  | $\Delta w_{i}=\eta\,y\,x_{i}$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $\eta$ is the learning rate, and the subscript $i$ refers to the i-th
    input/synapse. The effect of this learning rule is essentially to consolidate
    correlated activations between neural inputs and outputs, by reinforcing the synaptic
    couplings, so that, if a similar input will be observed again in the future, a
    similar response will likely be elicited from the neuron. We can already outline
    a first connection between the neuroscientific Hebbian learning theory and data
    science, specifically Principal Component Analysis (PCA): if multiple inputs are
    presented to a neuron, assuming that the activation function is linear and that
    the inputs have zero means, it can be shown (Gerstner and Kistler, [2002](#bib.bib80);
    Oja, [1982](#bib.bib178)) that Eq. [1](#S3.E1 "In 3\. Synaptic Plasticity Models
    and Hebbian Learning in a Single Neuron ‣ Synaptic Plasticity Models and Bio-Inspired
    Unsupervised Deep Learning: A Survey") induces the weight vector to align towards
    the principal component of the data distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9ad777d95a430ca7037e51ccb7c1359e.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Weight vector subject to an update. Points are inputs (organized in a cluster),
    and the green point is the input currently being processed. The blue arrow represents
    the direction of the update that will affect the weight vector $w$, while the
    red arrow is the actual update.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/60088c6b5dec89581342e290ed94ed42.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Final position of the weight vector after training.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3. Effect of Hebbian updates on a weight vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem with Eq. [1](#S3.E1 "In 3\. Synaptic Plasticity Models and Hebbian
    Learning in a Single Neuron ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised
    Deep Learning: A Survey") is that there are no mechanisms to prevent the weights
    from growing unbounded, thus leading to possible instability. This issue can be
    counteracted by adding a weight decay term $\gamma(\mathbf{w},\mathbf{x})$ to
    the learning rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (2) |  | $\Delta w_{i}=\eta\,y\,x_{i}-\gamma(\mathbf{w},\mathbf{x})$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'In particular, with an appropriate choice for this term, i.e. $\gamma(\mathbf{w},\mathbf{x})=\eta\,y(\mathbf{w},\mathbf{x})\,w_{i}$,
    we obtain a learning rule that has been widely applied to the context of competitive
    learning (which will be discussed more in detail later) (Grossberg, [1976](#bib.bib85);
    Rumelhart and Zipser, [1985](#bib.bib208); Kohonen, [1982](#bib.bib121)):'
  prefs: []
  type: TYPE_NORMAL
- en: '| (3) |  | $\Delta w_{i}=\eta\,y\,x_{i}-\eta\,y\,w_{i}=\eta\,y\,(x_{i}-w_{i})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'This rule has a simple intuitive interpretation, depicted in Fig. [3](#S3.F3
    "Figure 3 ‣ 3\. Synaptic Plasticity Models and Hebbian Learning in a Single Neuron
    ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey"):
    when a collection of inputs is presented to the neuron, the weight vector evolves
    towards the centroid of the cluster formed by the inputs. In essence, the neuron
    is storing, in its synapses, a prototypical representation of the patterns observed
    during training. When a similar pattern is presented again, the neuron will produce
    a stronger response, thus becoming a sort of pattern-matching unit.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The learning rule above is a special case of post-synaptic gating (Gerstner
    and Kistler, [2002](#bib.bib80)):'
  prefs: []
  type: TYPE_NORMAL
- en: '| (4) |  | $\Delta w_{i}=\eta\,y\,(x_{i}-\theta)$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where the update step $x_{i}-\theta$ is ”gated” by the post-synaptic activation
    $y$. The parameter $\theta$ is a threshold parameter that determines the behavior
    of the updates: if the pre-synaptic stimulus is stronger than the threshold, LTP
    will be induced, otherwise we have LTD. Conversely, it is possible to define a
    pre-synaptic gating rule (Gerstner and Kistler, [2002](#bib.bib80)), by inverting
    the role of $x_{i}$ and $y$:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (5) |  | $\Delta w_{i}=\eta\,x_{i}\,(y-\theta)$ |  |'
  prefs: []
  type: TYPE_TB
- en: The threshold parameter can be fixed, or it can depend on the weights, on the
    current pre/post-synaptic activations, or even on the history of past activations.
  prefs: []
  type: TYPE_NORMAL
- en: 'A mixed approach is taken in the covariance rule (Sejnowski and Tesauro, [1989](#bib.bib215)),
    where thresholds are imposed both on the pre-synaptic and post-synaptic signals:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (6) |  | $\Delta w_{i}=\eta\,(y-\theta_{y})\,(x_{i}-\theta_{x})$ |  |'
  prefs: []
  type: TYPE_TB
- en: Specifically, $\theta_{x}$ and $\theta_{y}$ are running averages of pre- and
    post-synaptic activities over time, which are biologically supported by the concept
    of synaptic traces (Izhikevich, [2007](#bib.bib108); Yagishita et al., [2014](#bib.bib243);
    Shindou et al., [2019](#bib.bib218); Gerstner et al., [2018](#bib.bib81)). The
    covariance rule adapts vanilla Hebbian learning to the case of data with non-zero
    mean, tracking statistics online in the same spirit as batch normalization (Ioffe
    and Szegedy, [2015](#bib.bib106)).
  prefs: []
  type: TYPE_NORMAL
- en: <svg  class="ltx_picture ltx_centering" height="95.47" overflow="visible"
    version="1.1" width="141.35"><g transform="translate(0,95.47) matrix(1 0 0 -1
    0 0) translate(23.34,0) translate(0,2.21) matrix(1.0 0.0 0.0 1.0 -23.34 -2.21)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0) translate(23.34,0) translate(0,2.21)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g clip-path="url(#pgfcp1)"><g transform="matrix(1.0
    0.0 0.0 1.0 58.56 37.04)" fill="#000000" stroke="#000000"><foreignobject width="6.5"
    height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$\theta$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 15.4 32.47)" fill="#000000" stroke="#000000"><foreignobject
    width="28.06" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">LTD</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 74.85 51.06)" fill="#000000" stroke="#000000"><foreignobject
    width="26.91" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">LTP</foreignobject></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 105.56 54.07)" fill="#000000" stroke="#000000"><foreignobject
    width="7.28" height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$y$</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 -8.35 24.72)" fill="#000000" stroke="#000000"><foreignobject
    width="43.54" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$\phi(y-\theta)$</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4. Non-linearity in BCM rule.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Bienenstock-Cooper-Munro (BCM) rule (Bienenstock et al., [1982](#bib.bib29))
    introduces a nonlinearity $\phi$ in the learning process:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (7) |  | $\Delta w_{i}=\eta\,x_{i}\,\phi(y-\theta)$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'Fig. [4](#S3.F4 "Figure 4 ‣ 3\. Synaptic Plasticity Models and Hebbian Learning
    in a Single Neuron ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised
    Deep Learning: A Survey") shows a typical shape of the nonlinearity. A threshold
    is still applied to the post-synaptic activity, so that LTP occurs when the neuron
    activity is above the threshold, or LTD takes place otherwise. However, when the
    activity becomes too large, too small, or in proximity to the threshold, plasticity
    is inhibited. The idea is that, when neural activity is too large (or too small),
    LTP leads to a further increase in the activity (conversely, LTD leads to a further
    decrease), but the nonlinearity provides a stabilizing effect.'
  prefs: []
  type: TYPE_NORMAL
- en: Another approach for setting bounds on the synaptic weights could be to adopt
    soft thresholds on the weights, i.e. explicit terms in the update equations that
    automatically limit the weight updates when a given threshold is approached (Gerstner
    and Kistler, [2002](#bib.bib80)).
  prefs: []
  type: TYPE_NORMAL
- en: '| (8) |  | $\Delta w_{i}=\eta\,\Delta w_{i}^{(base)}\,(w_{i}-\theta_{LB})\,(\theta_{UB}-w_{i})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $\theta_{LB}$ and $\theta_{UB}$ act as soft lower and upper thresholds
    for the weights, with $\theta_{LB}<\theta_{UB}$, and $\Delta w_{i}^{(base)}$ is
    a given weight update before soft-thresholding. A similar concept also arises
    in bi-stable synapse models (Fusi et al., [2000](#bib.bib71); Gerstner and Kistler,
    [2002](#bib.bib80)). In these models, synaptic weights are allowed to settle down
    only in one of two possible stable states (for example, 0 and 1). The learning
    rule is divided into two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (9) |  | $\Delta w_{i}=H+R$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $H$ is a generic Hebbian term driving plasticity, while $R$ is a refresh
    term for synaptic stabilization:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (10) |  | $R=\gamma\,w_{i}\,(1-w_{i})\,(w_{i}-\theta)$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\gamma$ is a constant. This term drives weight values towards 1, when
    the current weight value is above a threshold $\theta$, or to 0 otherwise. Thanks
    to this rule, transitions of the weight value from 0 to 1 can occur only when
    the driving Hebbian term provides a stimulation strong enough to bring the weight
    value beyond the threshold, and vice-versa for transitions from 1 to 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'A different approach to the weight instability problem has been proposed in
    (Oja, [1982](#bib.bib178)): the idea is to renormalize the weight vector after
    each update, so that its length is always kept constant, although the direction
    changes over time, aligning towards the data principal component (under the same
    assumptions as in the vanilla case). It can be shown that, under small learning
    rates, the learning rule with the renormalization step can be approximated by
    a first-order Taylor expansion around $\eta=0$, leading to the weight update named
    Oja’s rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (11) |  | $\Delta w_{i}=\eta\,y\,(x_{i}-y\,w_{i})$ |  |'
  prefs: []
  type: TYPE_TB
- en: Note that this update also falls in the category of Hebbian updates with weight
    decay, which in this case is $\gamma(\mathbf{w},\mathbf{x})=\eta\,y(\mathbf{w},\mathbf{x})^{2}\,w_{i}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is worth noting that the aforementioned learning rules can be interpreted
    as instances of a more general local synaptic update equation which, for a generic
    synaptic connection $i$, can be expressed as (Gerstner and Kistler, [2002](#bib.bib80)):'
  prefs: []
  type: TYPE_NORMAL
- en: '| (12) |  | $\Delta w_{i}=a_{0}+a_{1}x_{i}+a_{2}y+a_{3}x_{i}y+a_{4}x_{i}^{2}+a_{5}y^{2}+...$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where the coefficients $a_{i}$ may depend on the weights.
  prefs: []
  type: TYPE_NORMAL
- en: 'Differential Hebbian Learning (DHL) (Kosko, [1986](#bib.bib125)) represents
    a departure from traditional Hebbian models. Instead of considering simply the
    pre- and post-synaptic activities at a given instant, this model proposes to consider
    also the rate of change of these activities over time:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (13) |  | $\Delta w_{i}=\eta\,\frac{dy}{dt}\,x_{i}$ |  |'
  prefs: []
  type: TYPE_TB
- en: This learning rule has interesting properties related to data decorrelation
    (Choi, [1998](#bib.bib42)), temporal difference learning (Kolodziejski et al.,
    [2009a](#bib.bib124), [b](#bib.bib123)), and encoding of error signals in STDP
    neurons (Roberts, [1999](#bib.bib202)) providing a biologically grounded mechanism
    for Contrastive Hebbian Learning (CHL) (Movellan, [1991](#bib.bib175)) in networks
    of spiking neurons (Bengio et al., [2015](#bib.bib26)) (we will come back to these
    topics in the following Sections).
  prefs: []
  type: TYPE_NORMAL
- en: The learning rules presented so far involve only a single neuron. In the next
    subsection, we will consider more complex learning scenarios involving multiple
    neurons.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Plasticity Models for Unsupervised Pattern Discovery with Multiple Neurons
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have considered plasticity models for single neurons. When we are
    dealing with a population with multiple neurons, naively applying a synaptic update
    rule such as those from the previous subsection is not guaranteed to be effective
    for a learning task. In fact, if multiple neurons follow the same learning dynamics,
    it is easy for them to converge to similar configurations. It is instead desirable
    to achieve some form of decorrelation of neural activity, i.e. making sure that
    different neurons learn to encode different pieces of information for given inputs
    (Földiak, [1990](#bib.bib70); Olshausen and Field, [1996a](#bib.bib183)), in order
    to maximize the representation power. This subsection explores the strategies
    to achieve such decorrelation in neural populations with local synaptic plasticity.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1\. Background on Neural Cells
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let us introduce some biological background on the various types of neural cells
    and their functions, from which it will be possible to draw relationships between
    the computational learning mechanisms that we are going to discuss in the following,
    and the biological substrate that supports such mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Neural cells can be classified into two main groups: pyramidal cells and non-pyramidal
    cells (White and Keller, [1989](#bib.bib238)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pyramidal cells represent the fundamental computing unit of biological neural
    networks. They typically have a pyramid-like shape, and they are endowed with
    two types of dendrites (i.e. input connections): apical dendrites, which extend
    from the tip of the pyramid, and several basal dendrites, originating from the
    base. Apical dendrites extend through cortical layers, while basal dendrites extend
    mainly toward neighboring cells in the same region. The axon of pyramidal cells
    (i.e. the output connection) originates at the base of the pyramid and it immediately
    branches into a projection axon and several axon collaterals. The projection axon
    extends towards deeper layers. Axon collaterals can be local, i.e. extending for
    a short distance towards neighboring neurons, or they can extend for longer distances
    either in the same layer or towards other layers.'
  prefs: []
  type: TYPE_NORMAL
- en: Concerning the non-pyramidal cells, they can be further divided into a variety
    of categories (Stefanis, [2020](#bib.bib223)), but the common features are a central
    body with a smaller size compared to pyramidal cells, a number of dendrites originating
    from it, and an axon which tends to branch into multiple ramifications. Dendrites
    and connections are mainly local, hence these cells tend to connect to neighboring
    neurons, such as pyramidal cells, thus transmitting information about the activity
    in the neighborhood. By virtue of this role, these cells are often labeled as
    interneurons. Axons of non-pyramidal cells tend to form mainly inhibitory connections
    with other neural elements, which play an important role in inhibitory interaction
    and shunting inhibition (Kubota et al., [2016](#bib.bib129)) between neurons.
  prefs: []
  type: TYPE_NORMAL
- en: In the following, we will highlight the role played by artificial neurons, which
    correspond to pyramidal cells, and the mechanisms of inhibitory lateral interaction,
    mediated by non-pyramidal cells, which is essential to achieve the necessary decorrelation
    in neural activity, thus showing an interesting mapping between biological circuits
    and artificial learning systems.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2\. Competitive Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bfbcbb63f348884dd9fb0d203dad7a48.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Update step
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/91259a7b814cd02797fbab037fa8e1f5.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Final position after convergence
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5. Hebbian updates with Winner-Takes-All competition.
  prefs: []
  type: TYPE_NORMAL
- en: 'When multiple neurons are involved in a complex network, competitive learning
    can be adopted to force different neurons to learn different patterns. A possible
    strategy is Winner-Takes-All (WTA) (Grossberg, [1976](#bib.bib85); Rumelhart and
    Zipser, [1985](#bib.bib208)): when an input is presented to a WTA layer, the neuron
    whose weight vector is closest to the current input (e.g. in terms of angular
    or euclidean distance) is elected as winner. Only the winner is allowed to perform
    a weight update, according to Eq. [3](#S3.E3 "In 3\. Synaptic Plasticity Models
    and Hebbian Learning in a Single Neuron ‣ Synaptic Plasticity Models and Bio-Inspired
    Unsupervised Deep Learning: A Survey"), thus moving its weight vector closer to
    the current input (Fig. [5](#S4.F5 "Figure 5 ‣ 4.2\. Competitive Learning ‣ 4\.
    Plasticity Models for Unsupervised Pattern Discovery with Multiple Neurons ‣ Synaptic
    Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey")). If
    a similar input will be presented again in the future, the same neuron will be
    more likely to win again. Competitive interaction between neurons is biologically
    motivated by the lateral inhibition mechanisms (Gabbott and Somogyi, [1986](#bib.bib73))
    that we have previously highlighted. This strategy allows a group of neurons to
    align their weight vectors towards the centroids of distinct clusters formed by
    the data points (Fig. [5](#S4.F5 "Figure 5 ‣ 4.2\. Competitive Learning ‣ 4\.
    Plasticity Models for Unsupervised Pattern Discovery with Multiple Neurons ‣ Synaptic
    Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey")), which
    shows another connection between a neuroscience-inspired learning theory, and
    a data analytic operation, namely clustering.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following equation gives a mathematical description of Hebbian WTA learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (14) |  | $\Delta w_{i,j}=\eta\,r_{j}\,(x_{i}-w_{i,j})$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'Here, subscripts $i$ and $j$ refer to the i-th input/synapse and j-th neuron
    in the layer, respectively, and $r_{j}$ is the neuron activation after a competitive
    nonlinearity: it is $1$ for the winning neuron and $0$ otherwise. A variant of
    WTA is k-WTA (Majani et al., [1989](#bib.bib162)), where top-k neurons closest
    to the input are the winners, which means that $r_{j}=1$ for these neurons and
    $0$ for all the others.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast with the sharp competition provided by WTA, soft forms of competition
    are also possible. In these cases, instead of having sharp winning neurons, corresponding
    to $r_{j}$ being $0$ or $1$, we can also attribute intermediate values to $r_{j}$
    for each neuron. For example, soft-WTA (Nowlan, [1990](#bib.bib176)) allows all
    the neurons to receive a score based on their activations so that neurons with
    higher activation will receive a higher score. In the original work, the score
    was computed simply as an $L_{1}$ normalization of the activations of the neurons.
    In (Lagani et al., [2021c](#bib.bib136); Moraitis et al., [2021](#bib.bib174)),
    other soft-WTA variants were introduced where the score was computed as the $L_{p}$
    normalization or as the softmax of neural activations, i.e.:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (15) |  | $r_{j}=\frac{y_{j}^{p}}{\sum_{k}y_{k}^{p}}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '| (16) |  | $r_{j}=\frac{e^{y_{j}/T}}{\sum_{k}e^{y_{k}/T}}$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'respectively. In the latter equation, T is the temperature parameter of the
    softmax (Gao and Pavel, [2017](#bib.bib75)), which serves to cope with the variance
    of the activations. Note that $r$ can be viewed as a step modulation coefficient:
    the higher the neuron activity, the larger the update step will be.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/25aea9abb078d01b3aabb686ee32f3ec.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) 1-dimensional lattice.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/52a5942a2c65ca45beecfba1fa5cd7dc.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) 2-dimensional lattice.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6. Self-Organizing Maps with neurons arranged in different topologies.
    Some of the lateral feedback connections are highlighted in green.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/94fe6db829734ae6e8aa7afb922a4827.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) 2-dimensional lattice with radius highlighted in green and distance $d_{j,i}$
    between neuron $j$ and neuron $i$ highlighted in blue.
  prefs: []
  type: TYPE_NORMAL
- en: <svg  class="ltx_picture ltx_centering" height="455.79" overflow="visible"
    version="1.1" width="538.29"><g transform="translate(0,455.79) matrix(1 0 0 -1
    0 0) translate(0.28,0) translate(0,0.28) matrix(1.0 0.0 0.0 1.0 -0.28 -0.28)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0) translate(0.28,0) translate(0,0.28)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 517.62
    122.76)" fill="#000000" stroke="#000000"><foreignobject width="15.23" height="13.67"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$d_{j,i}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 273.76 439.97)" fill="#000000" stroke="#000000"><foreignobject
    width="33.96" height="14.44" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$h(d_{j,i})$</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (b) Gaussian neighborhood function.
  prefs: []
  type: TYPE_NORMAL
- en: <svg  class="ltx_picture ltx_centering" height="455.79" overflow="visible"
    version="1.1" width="538.29"><g transform="translate(0,455.79) matrix(1 0 0 -1
    0 0) translate(0.28,0) translate(0,0.28) matrix(1.0 0.0 0.0 1.0 -0.28 -0.28)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0) translate(0.28,0) translate(0,0.28)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 517.62
    122.76)" fill="#000000" stroke="#000000"><foreignobject width="15.23" height="13.67"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$d_{j,i}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 273.76 439.97)" fill="#000000" stroke="#000000"><foreignobject
    width="33.96" height="14.44" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$h(d_{j,i})$</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (c) Mexican hat neighborhood function.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7. Lateral interaction with some neighborhood function profiles.
  prefs: []
  type: TYPE_NORMAL
- en: 'In (Kohonen, [1982](#bib.bib121)), the work on competitive learning was further
    extended with the introduction of Self-Organizing Maps (SOMs). A SOM is a layer
    of neurons arranged in an n-dimensional lattice (typically 1-dimensional or 2-dimensional,
    the latter being more common). After the competitive phase, but before the weight
    update, training is extended with a new cooperative phase, in which lateral interaction
    takes place in the form of a lateral feedback signal that is provided by the winning
    neuron to its neighbors in the lattice topology (fig. [6](#S4.F6 "Figure 6 ‣ 4.2\.
    Competitive Learning ‣ 4\. Plasticity Models for Unsupervised Pattern Discovery
    with Multiple Neurons ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised
    Deep Learning: A Survey")). The strength of this signal decreases with the distance
    from the winning neuron. Specifically, denoting with $i(x)$ the winning neuron
    on input $x$, the strength of the signal delivered to any neuron $j$, whose distance
    from $i(x)$ in the lattice topology is $d_{j,i(x)}$, is determined by the neighborhood
    function $h(d_{j,i(x)})$. This function should be equal to $1$ when $d_{j,i(x)}$
    is $0$ and should decrease with the distance. For instance, a possible choice
    for the neighborhood function can be a Gaussian function or a mexican hat function
    centered in zero (Fig. [7](#S4.F7 "Figure 7 ‣ 4.2\. Competitive Learning ‣ 4\.
    Plasticity Models for Unsupervised Pattern Discovery with Multiple Neurons ‣ Synaptic
    Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey")) (Haykin,
    [2009](#bib.bib88); Kohonen, [1993](#bib.bib122)). Other possible choices for
    the neighborhood function and further theoretical details about the SOMs are discussed
    in (Lo et al., [1991](#bib.bib152), [1993](#bib.bib153); Erwin et al., [1991](#bib.bib65),
    [1992a](#bib.bib66), [1992b](#bib.bib67); Cottrell et al., [2018](#bib.bib52)).
    The neighborhood function is characterized by a radius (the standard deviation
    in the Gaussian case) which is typically initialized to be equal to the radius
    of the lattice and then shrank over time. Once the cooperative phase is completed,
    the weight update takes place by applying eq. [14](#S4.E14 "In 4.2\. Competitive
    Learning ‣ 4\. Plasticity Models for Unsupervised Pattern Discovery with Multiple
    Neurons ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning:
    A Survey"), in which $r$ is set to $h(d_{j,i(x)})$. Note that the WTA approach
    can be seen as a particular case of SOM in which the neighborhood function has
    a radius of zero.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3\. Subspace Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: According to the definition given above, WTA enforces a kind of quantized information
    encoding in neural network layers. Only one or a few neurons activate to encode
    the presence of a given pattern in the input. On the other hand, neural networks
    trained with backpropagation exhibit a distributed representation (Agrawal et al.,
    [2014](#bib.bib3)), where multiple neurons activate combinatorially to encode
    different properties of the input, resulting in an improved coding power. Similar
    distributed coding schemes have also been observed in biological neuron populations
    (Averbeck et al., [2006](#bib.bib12); Wohrer et al., [2013](#bib.bib239)). The
    importance of distributed representations was also highlighted in (Földiak, [1989](#bib.bib69);
    Olshausen and Field, [1996a](#bib.bib183)).
  prefs: []
  type: TYPE_NORMAL
- en: A more distributed coding scheme could be obtained by representing data as linear
    combinations of some orthonormal basis of feature vectors. Data projection over
    an orthogonal basis of weight vectors can be easily implemented as a neural mapping.
    In order to capture as much information as possible from the data, this basis
    should span the principal subspace, i.e. the subspace capturing most of the data
    variance, for which the data principal components form an orthogonal basis (Haykin,
    [2009](#bib.bib88)).
  prefs: []
  type: TYPE_NORMAL
- en: A PCA-based neural network, PCANet, was proposed in (Chan et al., [2015](#bib.bib39)).
    Network filters were obtained by running PCA offline on the training dataset and
    using the extracted principal components as weights. Multiple processing layers
    were obtained by stacking PCA filters obtained from feature representations of
    the dataset extracted from previous layers, in a bottom-up fashion. The approach
    achieved 78% accuracy on the CIFAR-10 (Krizhevsky and Hinton, [2009](#bib.bib127))
    dataset with a relatively shallow network. Unfortunately, Offline PCA computation
    is quite expensive, and it becomes prohibitive when applied to larger inputs or
    deeper networks. However, there exists an extension to Oja’s rule that allows
    to perform PCA also in an online fashion, which is more appealing both in terms
    of efficiency and biological plausibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have already observed how Oja’s rule provides a stable Hebbian mechanism
    for extracting the first principal component. Further extensions of such mechanism
    for multiple neurons exist, which allow the extraction of successive directions
    spanning the principal subspace (Sanger, [1989](#bib.bib209); Becker and Plumbley,
    [1996](#bib.bib22)). In order to perform Hebbian PCA, a set of weight vectors
    has to be determined, for the various neurons, that minimize the representation
    error, defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (17) |  | $\mathcal{L}_{R}(\mathbf{w_{i}})=E[(\mathbf{x}-\sum_{j=1}^{i}y_{j}\,\mathbf{w_{j}})^{2}]$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where the subscript $i$ refers to the $i^{th}$ neuron in a given layer and $E[\cdot]$
    is the mean value operator. It can be pointed out that, in the case of linear
    neurons and zero-centered data, this reduces to the classical PCA objective of
    maximizing the output variance, with the weight vectors subject to orthonormality
    constraints (Sanger, [1989](#bib.bib209); Becker and Plumbley, [1996](#bib.bib22);
    Karhunen and Joutsensalo, [1995](#bib.bib113)). From now on, let us assume that
    the input data are centered around zero. If this is not true, we just need to
    subtract the average from the inputs beforehand.
  prefs: []
  type: TYPE_NORMAL
- en: 'It can be shown that Sanger’s rule minimizes the objective in Eq. [17](#S4.E17
    "In 4.3\. Subspace Learning ‣ 4\. Plasticity Models for Unsupervised Pattern Discovery
    with Multiple Neurons ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised
    Deep Learning: A Survey") (Sanger, [1989](#bib.bib209)):'
  prefs: []
  type: TYPE_NORMAL
- en: '| (18) |  | $\Delta\mathbf{w_{i}}=\eta y_{i}(\mathbf{x}-\sum_{j=1}^{i}y_{j}\mathbf{w_{j}})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'The intuition behind this learning rule is the following: 1) for the first
    neuron, it simply corresponds to Oja’s rule, thus extracting the first principal
    component; 2) for a generic successive neuron $i$, the learning rule subtracts
    from the input the partial representation $\sum_{j=1}^{i-1}y_{j}\mathbf{w_{j}}$
    reconstructed from the previous neurons, thus canceling the subspace spanned by
    the first $i-1$ principal components; 3) neuron $i$ then applies Oja’s rule on
    the residual part of the input, which leads to the extraction of the $i$-th principal
    component. In the case of nonlinear neurons, a solution to the problem can still
    be found (Karhunen and Joutsensalo, [1995](#bib.bib113)). Calling $f()$ the neuron
    activation function, under mild conditions that include the monotonic increase
    of $f$, the representation error'
  prefs: []
  type: TYPE_NORMAL
- en: '| (19) |  | $\mathcal{L}_{R}(w_{i})=E[(\mathbf{x}-\sum_{j=1}^{i}f(y_{j})\,\mathbf{w_{j}})^{2}]$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'can be minimized with the following nonlinear version of the previous learning
    rule for nonlinear Hebbian PCA:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (20) |  | $\Delta\mathbf{w_{i}}=\eta f(y_{i})(\mathbf{x}-\sum_{j=1}^{i}f(y_{j})\mathbf{w_{j}})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'Other variants of Hebbian PCA learning rules exist. The subspace learning rule,
    also due to Oja (Oja, [1989](#bib.bib179), [1992](#bib.bib180)), differs from
    Sanger’s rule in that each neuron subtracts from the input the same reconstruction
    vector: $\sum_{j=1}^{N}y_{j}w_{j}$ (mind the summation index running from 1 to
    N, where N is the number of neurons in the layer). The resulting learning rule
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (21) |  | $\Delta w_{i}=\eta y_{i}(x-\sum_{j=1}^{N}y_{j}w_{j})$ |  |'
  prefs: []
  type: TYPE_TB
- en: With this variation in the learning scheme, the network is capable of extracting
    the principal subspace, i.e. the same space spanned by the PCA directions, but
    expressed in terms of some other orthonormal basis (which is going to be a rotated
    version of the PCA basis).
  prefs: []
  type: TYPE_NORMAL
- en: Strictly speaking, Sanger’s rule (as well as Oja’s subspace rule) is not biologically
    plausible, because the weight update of a synapse is computed using information
    about weights on other synapses and outputs from other neurons (i.e. the terms
    in the sum). Nonetheless, network models can be designed that are functionally
    equivalent to Sanger’s (or Oja’s), but they are also consistent with biological
    plausibility requirements, using only local information in the updates. One of
    these was proposed in (Földiak, [1989](#bib.bib69)), and similarly also in (Plumbley,
    [1993](#bib.bib196)), which consisted of a linear single-layer network with both
    feedforward and lateral connections. Feedforward connections were trained with
    Oja’s rule, while lateral connections were trained using an anti-Hebbian rule
    (i.e. with a minus sign in front), an update scheme known as Hebbian/anti-Hebbian
    (HaH). Thanks to the lateral interaction, neurons were able to decorrelate their
    activity, projecting the data onto the principal subspace, while also normalizing
    the variance of neural activations. In data analysis, the operation performed
    by this network configuration corresponds to the whitening transformation (Krizhevsky
    and Hinton, [2009](#bib.bib127)).
  prefs: []
  type: TYPE_NORMAL
- en: A similar approach was taken in (Rubner and Tavan, [1989](#bib.bib207)), where
    purely Hebbian update was used for the feedforward connections and anti-Hebbian
    for the lateral ones, with explicit normalization performed after each update.
    Lateral connectivity was hierarchical, i.e. neuron i received lateral connections
    from neurons 1…i-1\. This organization makes the network equivalent to Sanger’s
    model, hence being capable of extracting principal components from data. The model
    presented in (Kung and Diamantaras, [1990](#bib.bib130)) also used hierarchical
    lateral connectivity, with Hebbian/anti-Hebbian updates. Normalization was not
    performed explicitly, but it was achieved by means of Oja-like weight decay terms.
    Again, the resulting model was able to perform PCA. Conversely, such an update
    scheme applied to networks with symmetric lateral connectivity, instead of hierarchical,
    as in (Leen, [1991](#bib.bib146)), provides a network that extracts the principal
    subspace. An interesting perspective on HaH is presented in (Seung and Zung, [2017](#bib.bib216)),
    which views Hebbian and anti-Hebbian learning parts as competing players in a
    game theoretic setting. Introducing nonlinearities in the learning process, with
    local learning rules in HaH networks, further enables the extraction of directions
    that maximize some generalized nonlinear moments of the data distribution (Karhunen
    and Joutsensalo, [1995](#bib.bib113)). Plasticity models such as BCM (Bienenstock
    et al., [1982](#bib.bib29)) or successive variants (Intrator and Cooper, [1992](#bib.bib105);
    Law and Cooper, [1994](#bib.bib143); Brito and Gerstner, [2016](#bib.bib32)),
    have been shown to be effective to model receptive field formation in these scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: A review of the above-mentioned approaches is provided in (Becker and Plumbley,
    [1996](#bib.bib22)). Although these methods provide biologically grounded mechanisms
    for subspace learning, their disadvantage is that, due to the recurrent nature
    of lateral connections, simulating these networks requires unfolding the recurrent
    dynamics in time. This requires a significant overhead compared to purely feedforward
    models such as Sanger’s or Oja’s. Nonetheless, we argue that the relationships
    between feedforward subspace learning models and HaH configurations have an important
    consequence, i.e. that the former are preferable for software simulation, while
    the correspondence with HaH models also provides biological support. It is also
    possible to build neural networks capable of extracting minor components from
    data, i.e. eigenvectors associated with the smallest eigenvalues of the data covariance
    matrix. This is useful, for example, when we need to recover a signal buried in
    white noise. Minor component extraction can be achieved by reversing the sign
    of Oja’s update rule, thus making it anti-Hebbian (Oja, [1992](#bib.bib180); Luo
    and Unbehauen, [1997](#bib.bib155)). HaH networks have also been derived from
    learning objectives related to Classical Multi-Dimensional Scaling (CMDS - a.k.a.
    strain loss, or similarity matching) (Pehlevan et al., [2015](#bib.bib193); Pehlevan
    and Chklovskii, [2015a](#bib.bib191), [b](#bib.bib192)), which are also shown
    to be related to subspace learning and principal component extraction. These approaches
    are also connected to manifold learning; therefore, they will be discussed in
    more detail in the next subsection.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4\. Manifold Learning Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Manifold learning models aim at mapping samples into lower dimensional spaces
    by constraining the output to preserve certain properties about the geometric
    structure of the data, beyond the simple linear relationships captured by methods
    such as PCA. Popular manifold learning methods include Isomap embeddings (Tenenbaum
    et al., [2000](#bib.bib229)), Locally Linear Embeddings (LLE) (Roweis and Saul,
    [2000](#bib.bib204)), or Laplacian eigenmaps (Belkin and Niyogi, [2003](#bib.bib23)).
  prefs: []
  type: TYPE_NORMAL
- en: 'An interesting manifold learning approach is represented by Classical Multi-Dimensional
    Scaling (CMDS) (Cox and Cox, [2008](#bib.bib53)). The reason is that recent work
    has derived HaH neural networks capable to optimize the CDMS objective (Pehlevan
    et al., [2015](#bib.bib193); Pehlevan and Chklovskii, [2015a](#bib.bib191), [b](#bib.bib192)).
    The particular form of the objective, known as similarity matching, or strain
    loss, is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (22) |  | $Y^{*}=\underset{Y}{arg\ min}\ \&#124;X^{T}X-Y^{T}Y\&#124;^{2}_{F}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'Where $X$ is a matrix obtained by concatenating a set of input vectors and
    similarly $Y$ is the matrix of the output vectors, while $\|\cdot\|_{F}$ is the
    Frobenius norm. For linear mapping, this objective is equivalent to standard subspace
    learning (Pehlevan et al., [2015](#bib.bib193)). Let’s give an intuitive interpretation
    of what this loss represents: $X^{T}X$ is a matrix whose elements are the dot
    products of pairs of input vectors, hence they represent the similarity of input
    vectors with other input vectors, and the same holds for $Y^{T}Y$. Therefore,
    that difference represents how much the similarity metric gets distorted when
    moving from the input space to the output space, and this is what should be minimized.
    The authors show that the problem can be solved by applying the following biologically-grounded
    neural dynamics and learning rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (23) |  | <math  class="ltx_Math" alttext="\begin{split}&amp;y=W\,x-M\,y\\
    &amp;\Delta W_{i,j}=\frac{y_{i}\,(x_{j}-W_{i,j}\,y_{i})}{D_{i}}\\'
  prefs: []
  type: TYPE_NORMAL
- en: '&amp;\Delta M_{i,j\neq i}=\frac{y_{i}\,(y_{j}-M_{i,j}\,y_{i})}{D_{i}},\ M_{i,i}=0\\'
  prefs: []
  type: TYPE_NORMAL
- en: '&amp;\Delta D_{i}=y_{i}^{2}\end{split}" display="block"><semantics ><mtable
    columnspacing="0pt" displaystyle="true" rowspacing="0pt" ><mtr
    ><mtd class="ltx_align_left" columnalign="left" ><mrow
    ><mi  >y</mi><mo
     >=</mo><mrow ><mrow
    ><mi  >W</mi><mo
    lspace="0.170em" rspace="0em"  >​</mo><mi
     >x</mi></mrow><mo
     >−</mo><mrow ><mi
     >M</mi><mo lspace="0.170em"
    rspace="0em"  >​</mo><mi
     >y</mi></mrow></mrow></mrow></mtd></mtr><mtr
    ><mtd class="ltx_align_left" columnalign="left" ><mrow
    ><mrow ><mi mathvariant="normal"
     >Δ</mi><mo lspace="0em"
    rspace="0em"  >​</mo><msub
    ><mi  >W</mi><mrow
     ><mi
     >i</mi><mo
     >,</mo><mi
     >j</mi></mrow></msub></mrow><mo
     >=</mo><mfrac
     ><mrow 
    ><msub 
    ><mi 
    >y</mi><mi 
    >i</mi></msub><mo lspace="0.170em" rspace="0em"
     >​</mo><mrow
     ><mo
    stretchy="false"  >(</mo><mrow
     ><msub
     ><mi
     >x</mi><mi
     >j</mi></msub><mo
     >−</mo><mrow
     ><msub
     ><mi
     >W</mi><mrow
     ><mi
     >i</mi><mo
     >,</mo><mi
     >j</mi></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><msub
     ><mi
     >y</mi><mi
     >i</mi></msub></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow><msub
     ><mi 
    >D</mi><mi 
    >i</mi></msub></mfrac></mrow></mtd></mtr><mtr
    ><mtd class="ltx_align_left" columnalign="left" ><mrow
    ><mrow ><mrow
    ><mi mathvariant="normal" 
    >Δ</mi><mo lspace="0em" rspace="0em" 
    >​</mo><msub ><mi
     >M</mi><mrow
     ><mrow 
    ><mi 
    >i</mi><mo 
    >,</mo><mi 
    >j</mi></mrow><mo 
    >≠</mo><mi 
    >i</mi></mrow></msub></mrow><mo 
    >=</mo><mfrac 
    ><mrow  ><msub
     ><mi
     >y</mi><mi
     >i</mi></msub><mo
    lspace="0.170em" rspace="0em"  >​</mo><mrow
     ><mo
    stretchy="false"  >(</mo><mrow
     ><msub
     ><mi
     >y</mi><mi
     >j</mi></msub><mo
     >−</mo><mrow
     ><msub
     ><mi
     >M</mi><mrow
     ><mi
     >i</mi><mo
     >,</mo><mi
     >j</mi></mrow></msub><mo
    lspace="0em" rspace="0em"  >​</mo><msub
     ><mi
     >y</mi><mi
     >i</mi></msub></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow><msub
     ><mi 
    >D</mi><mi 
    >i</mi></msub></mfrac></mrow><mo rspace="0.667em"
     >,</mo><mrow ><msub
    ><mi  >M</mi><mrow
     ><mi
     >i</mi><mo
     >,</mo><mi
     >i</mi></mrow></msub><mo
     >=</mo><mn 
    >0</mn></mrow></mrow></mtd></mtr><mtr ><mtd
    class="ltx_align_left" columnalign="left" ><mrow ><mrow
    ><mi mathvariant="normal" 
    >Δ</mi><mo lspace="0em" rspace="0em" 
    >​</mo><msub ><mi
     >D</mi><mi 
    >i</mi></msub></mrow><mo 
    >=</mo><msubsup ><mi
     >y</mi><mi 
    >i</mi><mn 
    >2</mn></msubsup></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply 
    ><csymbol cd="ambiguous" 
    >formulae-sequence</csymbol><apply 
    ><apply  ><ci
     >𝑦</ci><apply 
    ><apply  ><ci
     >𝑊</ci><ci 
    >𝑥</ci></apply><apply 
    ><ci  >𝑀</ci><ci
     >𝑦</ci><ci 
    >Δ</ci><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑊</ci><list 
    ><ci 
    >𝑖</ci><ci 
    >𝑗</ci></list></apply></apply></apply></apply><apply
     ><apply 
    ><apply  ><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑦</ci><ci
     >𝑖</ci></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑥</ci><ci
     >𝑗</ci></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑊</ci><list
     ><ci
     >𝑖</ci><ci
     >𝑗</ci></list></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑦</ci><ci
     >𝑖</ci></apply></apply></apply></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝐷</ci><ci
     >𝑖</ci></apply></apply><ci
     >Δ</ci><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><ci
     >𝑀</ci><apply
     ><list 
    ><ci 
    >𝑖</ci><ci 
    >𝑗</ci></list><ci 
    >𝑖</ci></apply></apply></apply></apply><apply
     ><apply 
    ><apply  ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑦</ci><ci
     >𝑖</ci></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑦</ci><ci
     >𝑗</ci></apply><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑀</ci><list
     ><ci
     >𝑖</ci><ci
     >𝑗</ci></list></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑦</ci><ci
     >𝑖</ci></apply></apply></apply></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝐷</ci><ci
     >𝑖</ci></apply></apply></apply></apply><apply
     ><apply 
    ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑀</ci><list
     ><ci
     >𝑖</ci><ci
     >𝑖</ci></list></apply><apply
     ><cn type="integer"
     >0</cn><ci
     >Δ</ci><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><ci
     >𝐷</ci><ci 
    >𝑖</ci></apply></apply></apply><apply 
    ><apply  ><csymbol
    cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><ci
     >𝑦</ci><ci 
    >𝑖</ci></apply><cn type="integer" 
    >2</cn></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}&y=W\,x-M\,y\\ &\Delta
    W_{i,j}=\frac{y_{i}\,(x_{j}-W_{i,j}\,y_{i})}{D_{i}}\\ &\Delta M_{i,j\neq i}=\frac{y_{i}\,(y_{j}-M_{i,j}\,y_{i})}{D_{i}},\
    M_{i,i}=0\\ &\Delta D_{i}=y_{i}^{2}\end{split}</annotation></semantics></math>
    |  |'
  prefs: []
  type: TYPE_NORMAL
- en: where matrices $W$ and $M$ represent respectively the weights associated with
    the feed-forward and lateral interactions, while $D$ is a vector containing the
    cumulative squared activations of the neurons, which act in the equations as a
    dynamic learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: As in the case of CMDS, manifold learning objectives appear to be effective
    principles for deriving data transformations that can be suitably mapped to neural
    layers, with potential applications for neuromorphic computation, thus representing
    an interesting open research area.
  prefs: []
  type: TYPE_NORMAL
- en: 4.5\. Sparse Coding (SC)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another interesting feature observed in biological networks is sparsity in the
    neural activations, i.e. only a small percentage of neurons (around 1%) activate
    simultaneously to encode a given stimulus (Lennie, [2003](#bib.bib147)). This
    property might derive simply from metabolic/energetic constraints, but it is also
    possible that sparsity plays a relevant role to support effective information
    encoding strategies (Földiak, [1990](#bib.bib70); Olshausen and Field, [1996a](#bib.bib183)).
    Indeed, similar coding strategies are also observed in networks trained with backprop
    (Agrawal et al., [2014](#bib.bib3)).
  prefs: []
  type: TYPE_NORMAL
- en: The Sparse Coding (SC) principle explicitly introduces a sparsity constraint
    in the learning framework. Let $\mathcal{X}$ be a dataset of input vectors. SC
    assumes that the elements of $\mathcal{X}$ can be represented as linear combinations
    of few basis vectors $\mathbf{d}_{1},\mathbf{d}_{2},...\mathbf{d}_{N}$, also called
    words. For a compact representation, let $D$ be a matrix whose columns are the
    word vectors, which is called the dictionary matrix. The goal is to find, for
    each input $\mathbf{x}\in\mathcal{X}$, an encoding in terms of linear combinations
    of the dictionary vectors
  prefs: []
  type: TYPE_NORMAL
- en: '| (24) |  | $\mathbf{\hat{x}}=\mathbf{\hat{x}}(\mathbf{y},D)=\sum_{i}y_{i}\mathbf{d}_{i}=D\,\mathbf{y}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'which minimizes the representation error, i.e. a distance measure between the
    original and the reconstructed input. The vector of linear combination coefficients
    $\mathbf{y}=(y_{1},y_{2},...y_{N})^{T}$ is also called the code vector. An additional
    constraint imposed by SC is the sparsity of the representation $\mathbf{y}$. For
    example, using Euclidean distance as an error metric, the SC objective can be
    expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (25) |  | $\mathcal{L}_{SC}(\mathbf{y},D)=\sum_{\frac{1}{2}\mathbf{x}\in\mathcal{X}}(\mathbf{x}-\mathbf{\hat{x}}(\mathbf{y},D))^{2}+\lambda\mathbf{C}(\mathbf{y}(\mathbf{x}))$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{C}(\mathbf{y})=(C(y_{1}),...,C(y_{N}))^{T}$ is a cost function
    that penalizes dense codes, while $\lambda$ is a hyperparameter. In principle,
    we could choose function $C$ to simply count the number of non-zero elements of
    $y$, but this definition is not well suited for gradient-based optimization. Smother
    alternatives can be considered, such as $L_{1}$ or $L_{2}$ penalties on $\mathbf{y}$,
    but other forms are possible (Olshausen and Field, [1996a](#bib.bib183), [b](#bib.bib184)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/080925ca8d94ad71aa87f57f919bc348.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Sparse coding layer with error recirculation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b30c83d768c83afb1a59f07b564463c1.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Sparse coding layer with feedforward and lateral connections, and a shrinkage-thresholding
    nonlinearity implementing the Locally Competitive Algorithm (LCA).
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8. Neural architectures for sparse coding layers.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0b9230c822f85814fb21667d182f4a1a.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9. Shrink-thresholding nonlinearity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the dictionary, there are various algorithms to find sparse codes, such
    as Orthogonal Matching Pursuit (OMP) (Pati et al., [1993](#bib.bib190)), or Fast
    Iterative Shrinkage-Thresholding Algorithm (FISTA) (Beck and Teboulle, [2009](#bib.bib20)).
    If the dictionary is not given a priori, other algorithms can be used to find
    the dictionary vectors, for example, based on clustering (Li et al., [2003](#bib.bib150);
    He and Cichocki, [2006b](#bib.bib91)) or eigenvalue decomposition (He and Cichocki,
    [2006a](#bib.bib90); Aharon et al., [2006](#bib.bib4)). However, a neurally-grounded
    approach (Olshausen and Field, [1996a](#bib.bib183)) can be derived by considering
    SC as two nested optimization problems: first find optimal coding coefficients
    for a fixed dictionary, and then optimize the dictionary code vectors given the
    coding coefficients found before. In this scenario, the first optimization stage
    corresponds to unfolding the neural dynamics, while the second stage yields the
    synaptic dynamics. Specifically, starting from a code $\mathbf{y}$, we can minimize
    the objective in Eq. [25](#S4.E25 "In 4.5\. Sparse Coding (SC) ‣ 4\. Plasticity
    Models for Unsupervised Pattern Discovery with Multiple Neurons ‣ Synaptic Plasticity
    Models and Bio-Inspired Unsupervised Deep Learning: A Survey") by iterating gradient
    descent steps w.r.t. $\mathbf{y}$.This leads to the following update for $\mathbf{y}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (26) |  | $\Delta\mathbf{y}\propto D^{T}\,(\mathbf{x}-\mathbf{\hat{x}})-\mathbf{C}^{\prime}(\mathbf{y})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $\mathbf{C}^{\prime}(\mathbf{y})=(C^{\prime}(y_{1}),...,C^{\prime}(y_{N}))^{T}$
    denotes the derivative of the sparsity-inducing cost function. This formulation
    corresponds to a neural layer (Fig. [8(a)](#S4.F8.sf1 "In Figure 8 ‣ 4.5\. Sparse
    Coding (SC) ‣ 4\. Plasticity Models for Unsupervised Pattern Discovery with Multiple
    Neurons ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning:
    A Survey")) where the activations $\mathbf{y}$ represent the sparse code. The
    dictionary $D$ corresponds to feedback connections that map the code back to the
    reconstruction $\mathbf{\hat{x}}=D\,\mathbf{y}$, and the residual error $(\mathbf{x}-\mathbf{\hat{x}})$
    is computed. The transpose dictionary $D^{T}$ represents forward connections that
    modify the activations $\mathbf{y}$ based on the previous error, such that the
    updates follow a gradient descent direction. The residual error recirculates for
    a number of iterations until convergence is reached, while $-C^{\prime}(\mathbf{y})$
    contributes to a sparsity-inducing decay in the activations. Once convergence
    is reached, the second phase of optimization involves the dictionary vectors.
    Calling $\mathbf{y}^{*}$ the sparse code after convergence, the dictionary can
    be optimized by another gradient descent step, w.r.t. $D$:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (27) |  | $\Delta D=\eta\,(\mathbf{x}-D\,\mathbf{y}^{*})\,(\mathbf{y}^{*})^{T}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: Note that Hebbian PCA algorithms can be considered as a special case of SC with
    a single iteration of the recirculation process (which is sufficient for convergence,
    under the assumption that the dictionary is orthogonal) and no sparsity constraint.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although there is no explicit neural circuitry to support the error recirculation
    process, it is possible to show that sparse coding can also be implemented using
    once again feedforward and lateral connections, supporting biologically plausible
    local processing and plasticity (Fig. [8(b)](#S4.F8.sf2 "In Figure 8 ‣ 4.5\. Sparse
    Coding (SC) ‣ 4\. Plasticity Models for Unsupervised Pattern Discovery with Multiple
    Neurons ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning:
    A Survey")). By rewriting Eq. [26](#S4.E26 "In 4.5\. Sparse Coding (SC) ‣ 4\.
    Plasticity Models for Unsupervised Pattern Discovery with Multiple Neurons ‣ Synaptic
    Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey") as'
  prefs: []
  type: TYPE_NORMAL
- en: '| (28) |  | $\Delta\mathbf{y}\propto D^{T}\,\mathbf{x}-D^{T}D\,\mathbf{y}-C^{\prime}(\mathbf{y})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'we can observe two contributions in particular: $D^{T}\,\mathbf{x}$, which
    corresponds to a feedforward term, and $-D^{T}D\,\mathbf{y}$ which corresponds
    to a lateral interaction term, where $D^{T}$ and $-D^{T}D$ are respectively the
    feedforward and lateral connection weights, which replace the error recirculation
    process. An SC neural layer can also be formulated in terms of an Energy-Based
    Model (EBM) (Hopfield, [1982](#bib.bib95); Haykin, [2009](#bib.bib88)), as done
    in the Locally Competitive Algorithm (LCA) (Rozell et al., [2008](#bib.bib206)).
    An EMB is a dynamical system characterized by a state which evolves according
    to certain equations, in such a way that a certain energy function is progressively
    reduced. In the SC case, neurons maintain an internal state $\mathbf{u}$, represented
    by their membrane potential, in which stimuli are integrated over time. Outputs
    $\mathbf{y}$ are connected to $\mathbf{u}$ by a sparsifying monotonic nonlinearity:
    $\mathbf{y}=T(\mathbf{u})$. The evolution of the system is described by the following
    equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (29) |  | $\begin{split}\Delta\mathbf{u}&amp;\propto D^{T}\,\mathbf{x}-u-(D^{T}D-I)\,\mathbf{y}\\
    \mathbf{y}&amp;=T(\mathbf{u})\end{split}$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'which can be shown to minimize Eq. [25](#S4.E25 "In 4.5\. Sparse Coding (SC)
    ‣ 4\. Plasticity Models for Unsupervised Pattern Discovery with Multiple Neurons
    ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey"),
    which is therefore the energy function of this EBM. Also in this case, the system
    is characterized by a feedforward interaction $D^{T}\,\mathbf{x}$, and a lateral
    interaction $-(D^{T}D-I)\,\mathbf{y}$, where $D^{T}$ and $-(D^{T}D-I)$ are respectively
    the feedforward and lateral connection weights. The specific form of the nonlinearity
    $T(\cdot)$ is related to the choice of the sparsity-inducing cost term $C(\mathbf{y})$
    in Eq. [25](#S4.E25 "In 4.5\. Sparse Coding (SC) ‣ 4\. Plasticity Models for Unsupervised
    Pattern Discovery with Multiple Neurons ‣ Synaptic Plasticity Models and Bio-Inspired
    Unsupervised Deep Learning: A Survey") as follows (Rozell et al., [2008](#bib.bib206)):'
  prefs: []
  type: TYPE_NORMAL
- en: '| (30) |  | $\lambda T^{-1}(y_{i})=C^{\prime}(y_{i})+y_{i}\qquad i=1,...,N$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'A common choice is the shrinkage-threshold function (Fig. [9](#S4.F9 "Figure
    9 ‣ 4.5\. Sparse Coding (SC) ‣ 4\. Plasticity Models for Unsupervised Pattern
    Discovery with Multiple Neurons ‣ Synaptic Plasticity Models and Bio-Inspired
    Unsupervised Deep Learning: A Survey")), which corresponds to the $L_{1}$ sparsity
    penalty. This constitutes the LCA formulation of SC (Rozell et al., [2008](#bib.bib206)).
    As the name of the algorithm suggests, a form of local competition take place
    among neurons. Indeed, it can be noticed that the nonlinearity, together with
    the lateral connections, induces a competitive interaction, where activations
    below a threshold are suppressed, while activations above a threshold inhibit
    the others.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.6\. Independent Component Analysis (ICA)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7dbd711deab3cd3245860f994dc7bded.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10. Blind Source Separation (BSS) problem. A mixing process $M$ generates
    samples $\mathbf{x}$ from source variables $s_{1},...,s_{N}$. A demixer $W$ mapping
    samples $\mathbf{x}$ to outputs $y_{1},...,y_{N}$. The goal is to find a demixer
    capable of reconstructing the original sources, without using information about
    the sources themselves.
  prefs: []
  type: TYPE_NORMAL
- en: 'PCA looks for directions in the data space along have maximum variance while
    being maximally decorrelated. This idea can be generalized also to higher-order
    statistical moments. In particular, a stronger condition than decorrelation is
    represented by independence. Independent Component Analysis (ICA) (Hyvarinen et al.,
    [2002](#bib.bib99)) addresses the problem of finding data representations into
    a set of maximally independent variables. ICA has strong relationships with the
    Blind Source Separation (BSS) problem (Jutten and Herault, [1991](#bib.bib111)).
    In BSS, data are assumed to be generated by a mixing process as in Fig. [10](#S4.F10
    "Figure 10 ‣ 4.6\. Independent Component Analysis (ICA) ‣ 4\. Plasticity Models
    for Unsupervised Pattern Discovery with Multiple Neurons ‣ Synaptic Plasticity
    Models and Bio-Inspired Unsupervised Deep Learning: A Survey"). A mixer generates
    data samples $\mathbf{x}$ from source variables $\mathbf{s}=(s_{1},...,s_{N})^{T}$
    (sampled from a problem-dependent distribution) through a mixing matrix $M$: $\mathbf{x}=M\,\mathbf{s}$.
    A demixer maps samples $\mathbf{x}$ to outputs $\mathbf{y}=(y_{1},...,y_{N})^{T}$,
    through a demixing matrix $W$: $\mathbf{y}=W\,\mathbf{x}$. The goal is to find
    a demixer that is capable of reconstructing the original sources using only information
    about the samples. The task is challenging because the information about the sources
    themselves is not available to guide the search for the desired demixer. Nonetheless,
    theoretical results show that the problem can be solved (Jutten and Herault, [1991](#bib.bib111);
    Comon et al., [1991](#bib.bib51); Comon, [1994](#bib.bib50); Cardoso and Laheld,
    [1996](#bib.bib37); Cardoso, [1997](#bib.bib34), [2001](#bib.bib35), [2003](#bib.bib36);
    Hyvarinen et al., [2002](#bib.bib99)), and the original sources can be correctly
    identified (up to a permutation), provided that the source distribution is non-Gaussian.
    Another scenario where the sources cannot be identified, without additional information,
    is represented by a nonlinear mixing process. Furthermore, depending on whether
    the number of sources is larger or smaller than the sample dimension (overcomplete
    or undercomplete mixtures, respectively), identifiability could be affected. Specifically,
    undercomplete mixtures are identifiable, while overcomplete mixtures require an
    additional constraint on the sparsity of the sources. This condition is reminiscent
    of the SC problem, and indeed it has been shown that ICA and SC are actually related
    (Olshausen, [1996](#bib.bib182)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'ICA approaches rely on information-theoretic methods to identify the correct
    demixer. A popular approach is the nautral gradient method (Amari et al., [1996](#bib.bib8)),
    which enforces the independence requirement by minimizing the Mutual Information
    (MI) of demixer outputs. This can be achieved by considering the distribution
    of the demixer outputs, say $\mathbf{q}_{\mathbf{Y}}(\mathbf{y})$, and observing
    that the output variables are independent only if their distribution is a factorial
    distribution, i.e. has the form $\mathbf{p}_{\mathbf{Y}}(\mathbf{y})=\prod_{i=1}^{N}p_{Y_{i}}(y_{i})$
    (we will come back later on the choice of the specific form of $p$). Therefore,
    an objective can be defined as the minimization of the Kullback-Leibler (KL) divergence
    between the joint distribution $\mathbf{q_{Y}}$ and target factorial distribution
    $\mathbf{p_{Y}}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (31) |  | $\mathcal{L}_{ICA}=D_{KL}(\mathbf{q_{Y}}(\mathbf{y})&#124;&#124;\mathbf{p_{Y}}(\mathbf{y}))$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'A gradient descent step on this objective w.r.t. the demixing matrix $W$ can
    be shown to lead to the following weight update equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (32) |  | $\delta W=\eta\,(W^{-T}-\mathbf{f}(\mathbf{y})\,x^{T})$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $W^{-T}$ denotes the inverse transpose of $W$, and $\mathbf{f}(\mathbf{y})=(f(y_{1}),...,f(y_{N}))^{T}$
    is a nonlinearity whose form is related to the choice of the target distribution
    $p$ as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (33) |  | $f(y)=\frac{d}{dy}\log p(y)=\frac{p^{\prime}(y)}{p(y)}$ |  |'
  prefs: []
  type: TYPE_TB
- en: The drawback of this learning rule is that it requires the computation of a
    matrix inversion $W^{-T}$ at each step, which is expensive. However, the method
    proposed in (Amari et al., [1996](#bib.bib8)) suggests resorting instead to a
    natural gradient, which is a modification of the ordinary gradient by taking into
    consideration the underlying geometric structure of the problem. In our case,
    the natural gradient is simply obtained by multiplying the ordinary gradient by
    $W^{T}\,W$. Notice that the resulting direction will still be a descent direction
    on the objective because we are multiplying the gradient by a positive semi-definite
    matrix (so that the resulting vector will have a positive scalar product with/be
    less the 90° away from the gradient). Luckily, this multiplication removes the
    undesired inverse, leading to the following updated equation for ICA.
  prefs: []
  type: TYPE_NORMAL
- en: '| (34) |  | $\delta W=\eta\,(I-\mathbf{f}(\mathbf{y})\,y^{T})\,W$ |  |'
  prefs: []
  type: TYPE_TB
- en: <svg  class="ltx_picture ltx_centering" height="455.79"
    overflow="visible" version="1.1" width="538.29"><g transform="translate(0,455.79)
    matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,0.28) matrix(1.0 0.0 0.0 1.0
    -0.28 -0.28)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0) translate(0.28,0) translate(0,0.28)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 525.57
    121.39)" fill="#000000" stroke="#000000"><foreignobject width="7.28" height="8.65"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$y$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 273.76 439.97)" fill="#000000" stroke="#000000"><foreignobject
    width="31.22" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$p_{Y}(y)$</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (a) Super-Gaussian distribution (thick line) compared to Gaussian (dashed line).
  prefs: []
  type: TYPE_NORMAL
- en: <svg  class="ltx_picture ltx_centering" height="455.79"
    overflow="visible" version="1.1" width="538.29"><g transform="translate(0,455.79)
    matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,0.28) matrix(1.0 0.0 0.0 1.0
    -0.28 -0.28)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0) translate(0.28,0) translate(0,0.28)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 525.57
    121.39)" fill="#000000" stroke="#000000"><foreignobject width="7.28" height="8.65"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$y$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 273.76 439.97)" fill="#000000" stroke="#000000"><foreignobject
    width="31.22" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$p_{Y}(y)$</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (b) Sub-Gaussian distribution (thick line) compared to Gaussian (dashed line).
  prefs: []
  type: TYPE_NORMAL
- en: <svg  class="ltx_picture ltx_centering" height="455.79"
    overflow="visible" version="1.1" width="538.29"><g transform="translate(0,455.79)
    matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,0.28) matrix(1.0 0.0 0.0 1.0
    -0.28 -0.28)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0) translate(0.28,0) translate(0,0.28)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 525.57
    235.2)" fill="#000000" stroke="#000000"><foreignobject width="7.28" height="8.65"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$y$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 273.76 439.97)" fill="#000000" stroke="#000000"><foreignobject
    width="26.31" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$f(y)$</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (c) Activation function for super-Gaussian distributions.
  prefs: []
  type: TYPE_NORMAL
- en: <svg  class="ltx_picture ltx_centering" height="455.79"
    overflow="visible" version="1.1" width="538.28"><g transform="translate(0,455.79)
    matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,0.28) matrix(1.0 0.0 0.0 1.0
    -0.28 -0.28)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0) translate(-57.34,0) translate(0,-76.35)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 583.17
    311.82)" fill="#000000" stroke="#000000"><foreignobject width="7.28" height="8.65"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$y$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 331.37 516.59)" fill="#000000" stroke="#000000"><foreignobject
    width="26.31" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$f(y)$</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (d) Activation function for sub-Gaussian distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11. Types of distributions and corresponding nonlinearities in ICA.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go back to the choice of the distribution model for $p$. Ideally, the
    form of the target marginal distribution $p$ should correspond to the distribution
    of the sources, but this is often unknown in practice. However, domain expertise
    can help the expert to make assumptions about the distribution of the sources
    and choose $q$ accordingly. Distributions can be divided into two families: super-gaussian
    and sub-gaussian. Super-gaussian distributions are characterized by a sharp central
    peak and heavier tails compared to a Gaussian. Examples of super-gaussian distributions
    are the Laplacian distribution, whose log-density is $\log p_{Y}(y)=\alpha-|y|$
    (where $\alpha$ is a normalizing constant), or the distribution with log-density
    $\log p_{Y}(y)=\alpha-2\log\cosh(y)$. Sub-gaussian distributions are fat at the
    center and lighter-tailed compared to Gaussian, and some examples are the uniform
    distribution, or the distribution with log-density $\log p_{Y}(y)=\alpha-(\frac{1}{2}y^{2}-\log\cosh(y))$.
    Theoretical results (Hyvärinen, [1997](#bib.bib98); Hyvärinen and Oja, [1998](#bib.bib102);
    Hyvarinen et al., [2002](#bib.bib99); Haykin, [2009](#bib.bib88)) show that optimization
    will succeed as long as the assumed distribution belongs to the correct family
    as the true distribution. A simple condition to test whether a chosen nonlinearity
    is adequate for the source distribution of the given dataset is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (35) |  | $\xi_{i}=\mathbb{E}[y_{i}\,f(y_{i})-f^{\prime}(y_{i})]>0\qquad
    i=1,...,N$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'Note that, if $\xi_{i}$ is negative for a given $f(y_{i})$, then it will be
    positive for $g(y_{i})=y_{i}-f(y_{i})$ (assuming that data are normalized to zero
    mean and unit variance). For instance, the example distributions $\log p_{Y}(y)=\alpha-2\log\cosh(y)$
    and $\log p_{Y}(y)=\alpha-(\frac{1}{2}y^{2}-\log\cosh(y))$ lead to functions $f(y)=\tanh(y)$
    and $f(y)=y-\tanh(y)$, respectively. A plot of super-Gaussian and sub-Gaussian
    distributions, and related nonlinearities, is shown in Fig. [11](#S4.F11 "Figure
    11 ‣ 4.6\. Independent Component Analysis (ICA) ‣ 4\. Plasticity Models for Unsupervised
    Pattern Discovery with Multiple Neurons ‣ Synaptic Plasticity Models and Bio-Inspired
    Unsupervised Deep Learning: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'The ICA approach is easily mapped into a feedforward neural layer (with architecture
    as Fig. [10](#S4.F10 "Figure 10 ‣ 4.6\. Independent Component Analysis (ICA) ‣
    4\. Plasticity Models for Unsupervised Pattern Discovery with Multiple Neurons
    ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey")),
    but alternative formulations also map into layers with feedforward and lateral
    connections (Jutten and Herault, [1991](#bib.bib111); Fyfe and Baddeley, [1995](#bib.bib72);
    Oja et al., [1996](#bib.bib181); Karhunen, [1996](#bib.bib112); Amari and Cichocki,
    [1998](#bib.bib7); Hyvärinen and Oja, [1998](#bib.bib102)). ICA is also related
    to nonlinear PCA methods (Karhunen and Joutsensalo, [1995](#bib.bib113); Becker
    and Plumbley, [1996](#bib.bib22)). The latter aims at canceling out some generalized
    higher-order cross-moments between the outputs (the specific form depends on the
    choice of the nonlinearity). Independence represents a stronger condition, as
    it implies the annulment of moments of all orders. However, nonlinear PCA approaches
    can also be effective in practice, as the minimization of higher-order moments
    often represents a good proxy to the maximization of independence.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Other approaches for ICA have been proposed in the literature, such as InfoMax
    (Bell and Sejnowski, [1995](#bib.bib24)), i.e. maximizing the mutual information
    between the demixer output filtered by a nonlinearity $f$ (Fig. [10](#S4.F10 "Figure
    10 ‣ 4.6\. Independent Component Analysis (ICA) ‣ 4\. Plasticity Models for Unsupervised
    Pattern Discovery with Multiple Neurons ‣ Synaptic Plasticity Models and Bio-Inspired
    Unsupervised Deep Learning: A Survey")), whose shape depends on the source distribution,
    and samples $\mathbf{x}$, or maximum-likelihood approaches (Pham and Garat, [1997](#bib.bib195)).
    Indeed, these various formulations can be shown to be equivalent (Pham and Garat,
    [1997](#bib.bib195); Cardoso, [1997](#bib.bib34)). Another interesting aspect
    is the connection between ICA and SC (Olshausen, [1996](#bib.bib182)). The SC
    problem can be mapped to a maximum-likelihood formulation by considering the SC
    objective function $\mathcal{L}_{SC}$ (Eq. [25](#S4.E25 "In 4.5\. Sparse Coding
    (SC) ‣ 4\. Plasticity Models for Unsupervised Pattern Discovery with Multiple
    Neurons ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning:
    A Survey")) as a log-likelihood of a probability density function:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (36) |  | $\ell_{\mathbf{Y}}(\mathbf{y},D)=\frac{1}{Z}\,e^{-\mathcal{L}_{SC}(\mathbf{y},D)}=\frac{1}{Z}\,e^{-\sum_{\frac{1}{2}\mathbf{x}\in\mathcal{X}}(\mathbf{x}-\mathbf{\hat{x}}(\mathbf{y},D))^{2}-\lambda\mathbf{C}(\mathbf{y}(\mathbf{x}))}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $Z$ is a normalizing constant. Without the sparsity-related term $\mathbf{C}$,
    this would just be a Gaussian density attributing higher probability density to
    lower reconstruction errors $(\mathbf{x}-\mathbf{\hat{x}})^{2}$. The sparsity
    term represents a prior that further penalizes dense codes by reducing the corresponding
    probability. Indeed, the sparsity condition in SC is related to the form of the
    marginal distribution in ICA. In particular, super-gaussian distributions induce
    sparse representations, being characterized by samples that are either close to
    zero (often), or very large (rarely).
  prefs: []
  type: TYPE_NORMAL
- en: If samples come from a temporal process, another class of BSS approaches exists,
    which is able to identify sources based on the temporal structure of the signals
    (Matsuoka et al., [1995](#bib.bib167); Belouchrani et al., [1997](#bib.bib25);
    Meyer-Base et al., [2001](#bib.bib170); Choi et al., [2002a](#bib.bib43), [b](#bib.bib44)).
    Finally, recent developments have provided a principled way to overcome previous
    theoretical limitations to the identifiability of nonlinear mixtures (Hyvarinen
    and Morioka, [2016](#bib.bib100), [2017](#bib.bib101); Hyvarinen et al., [2019](#bib.bib103)).
    These approaches are able to achieve nonlinear ICA by augmenting the data with
    additional information, such as temporal information, or any other auxiliary variable
    available, and then training a model to distinguish between the true augmented
    data and some negative data with a randomized auxiliary variable. The idea of
    extracting information by contrasting positive and negative views of the data
    has also emerged in various other domains (Lai and Fyfe, [2001](#bib.bib140);
    Sun et al., [2008](#bib.bib225); Andrew et al., [2013](#bib.bib11); Elmadany et al.,
    [2016](#bib.bib64); Dorfer et al., [2016](#bib.bib61); Gatto and dos Santos, [2017](#bib.bib76);
    Li et al., [2004](#bib.bib148); Dorfer et al., [2015](#bib.bib60); Koch et al.,
    [2015](#bib.bib120); Hoffer and Ailon, [2015](#bib.bib94); Ramachandran et al.,
    [2017](#bib.bib198); Baltrušaitis et al., [2018](#bib.bib16); Hossain et al.,
    [2019](#bib.bib96); Stefanini et al., [2022](#bib.bib222); Kaur et al., [2021](#bib.bib115);
    Oord et al., [2018](#bib.bib185); Löwe et al., [2019](#bib.bib154); Chen et al.,
    [2020](#bib.bib40)). This is the topic of multi-view or contrastive learning,
    which is discussed in the next subsection.
  prefs: []
  type: TYPE_NORMAL
- en: 4.7\. Multi-View Learning Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d383b34fea025ee1a89a58daa1a3569f.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12. Schematic representation of a multi-view learning module. The module
    generates representations for a pair of inputs, driving positive pair together,
    and negative pairs far apart.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the field of machine learning, a variety of approaches exist which are based
    on the idea of processing data observed from multiple views. The concept of view
    is problem-dependent, but, for example, it can refer to multiple modalities through
    which the data are presented (visual, auditory, text, etc.), multiple copies of
    the same sample obtained by different transformations, multiple frames at different
    time instants, multiple features from a feature vector. Another example can be
    simply a sample and corresponding label information. The general idea is to map
    different related views (positives) to a common representation while making sure
    that unrelated views (negatives), which are typically obtained by a randomized
    pairing of views from different samples, are mapped to distinct representations
    (Fig. [12](#S4.F12 "Figure 12 ‣ 4.7\. Multi-View Learning Models ‣ 4\. Plasticity
    Models for Unsupervised Pattern Discovery with Multiple Neurons ‣ Synaptic Plasticity
    Models and Bio-Inspired Unsupervised Deep Learning: A Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: Canonical Correlation Analysis (CCA) (Lai and Fyfe, [2001](#bib.bib140); Sun
    et al., [2008](#bib.bib225); Andrew et al., [2013](#bib.bib11); Elmadany et al.,
    [2016](#bib.bib64); Dorfer et al., [2016](#bib.bib61); Gatto and dos Santos, [2017](#bib.bib76)),
    max-margin approaches (Mao and Jain, [1993](#bib.bib163); Pang et al., [2005](#bib.bib187);
    Demir and Ozmehmet, [2005](#bib.bib56); Li et al., [2004](#bib.bib148); Dorfer
    et al., [2015](#bib.bib60); Koch et al., [2015](#bib.bib120); Hoffer and Ailon,
    [2015](#bib.bib94)), multi-modal learning (Ramachandran et al., [2017](#bib.bib198);
    Baltrušaitis et al., [2018](#bib.bib16); Hossain et al., [2019](#bib.bib96); Stefanini
    et al., [2022](#bib.bib222); Kaur et al., [2021](#bib.bib115)), contrastive representation
    learning (Oord et al., [2018](#bib.bib185); Saunshi et al., [2019](#bib.bib212);
    Hénaff et al., [2019](#bib.bib92); Löwe et al., [2019](#bib.bib154); Chen et al.,
    [2020](#bib.bib40); Bardes et al., [2021](#bib.bib17)), can all be considered
    as multi-view learning approaches.
  prefs: []
  type: TYPE_NORMAL
- en: CCA (Lai and Fyfe, [2001](#bib.bib140); Sun et al., [2008](#bib.bib225); Gatto
    and dos Santos, [2017](#bib.bib76)) aims at finding linear projections of the
    different data modes so that the representations of related views are maximally
    correlated, while different views are uncorrelated. The IMax approach (Becker,
    [1996](#bib.bib21)) is similar, but it considers the Mutual Information (MI) between
    different views instead of simple correlation. Discriminative CCA is a particular
    instantiation in which the views that are considered are a data view and a target
    to be predicted (Kim et al., [2007](#bib.bib118); Sun et al., [2007](#bib.bib226);
    Elmadany et al., [2016](#bib.bib64); Dorfer et al., [2016](#bib.bib61)), which
    has been shown to be equivalent to linear regression methods (Shin and Park, [2011](#bib.bib217)).
    Nonlinear extensions of CCA through deep mappings were also recently explored
    (Andrew et al., [2013](#bib.bib11); Elmadany et al., [2016](#bib.bib64); Dorfer
    et al., [2016](#bib.bib61)). Moreover, Hebbian neural network implementations
    of CCA methods also exist (Lai and Fyfe, [2001](#bib.bib140); Gatto and dos Santos,
    [2017](#bib.bib76)).
  prefs: []
  type: TYPE_NORMAL
- en: Max-margin approaches (Mao and Jain, [1993](#bib.bib163); Pang et al., [2005](#bib.bib187);
    Demir and Ozmehmet, [2005](#bib.bib56); Li et al., [2004](#bib.bib148); Dorfer
    et al., [2015](#bib.bib60); Koch et al., [2015](#bib.bib120); Hoffer and Ailon,
    [2015](#bib.bib94)) are supervised methods where label information is used to
    derive a mapping of samples into a feature space, in order to optimize class separability.
    Linear Discriminant Analysis (LDA) (Mao and Jain, [1993](#bib.bib163); Pang et al.,
    [2005](#bib.bib187); Demir and Ozmehmet, [2005](#bib.bib56)) is a classical method
    that minimizes the distance in feature space of same-class samples from the class
    centroid (intra-class distance), and maximizes the distance between different
    class centroids (inter-class distance). Equivalence between LDA and least-squares
    classification has been demonstrated (Ye, [2007](#bib.bib245)). While LDA focuses
    on linear mappings, max-margin methods were also extended to the nonlinear case
    (Santa Cruz and Dorronsoro, [1998](#bib.bib210); Mika et al., [1999](#bib.bib172);
    Kim and Kittler, [2005](#bib.bib117); Sugiyama, [2006](#bib.bib224); Dorfer et al.,
    [2015](#bib.bib60)). A similar principle is also pursued in metric learning with
    siamese networks (Koch et al., [2015](#bib.bib120)), and triplet loss learning
    (Hoffer and Ailon, [2015](#bib.bib94)), where the same class samples (positives)
    are mapped to nearby locations in feature space, while negative samples are far
    apart. Moreover, bio-inspired extensions of max-margin approaches for local learning
    have been proposed (Mao and Jain, [1993](#bib.bib163); Demir and Ozmehmet, [2005](#bib.bib56);
    Duan et al., [2021](#bib.bib62)). It is worth mentioning that the idea of augmenting
    unsupervised methods with label information has been explored in discriminative
    clustering (Kaski et al., [2005](#bib.bib114); Krause et al., [2010](#bib.bib126)),
    discriminative subspace learning (Bair et al., [2006](#bib.bib15); Barshan et al.,
    [2011](#bib.bib18); Li and Fu, [2015](#bib.bib149); Ritchie et al., [2019](#bib.bib201)),
    discriminative sparse coding (Mairal et al., [2008](#bib.bib160), [2009](#bib.bib161);
    Yang et al., [2011](#bib.bib244)), discriminative ICA (Akaho, [2002](#bib.bib5);
    Bressan and Vitrià, [2002](#bib.bib31); Dhir and Lee, [2011](#bib.bib59)), and
    discriminative manifold learning (De Ridder et al., [2003](#bib.bib55); Geng et al.,
    [2005](#bib.bib77); Zhang et al., [2008](#bib.bib250); Wang and Chen, [2009](#bib.bib236);
    Raducanu and Dornaika, [2012](#bib.bib197); Chien and Chen, [2016](#bib.bib41);
    Liu et al., [2019](#bib.bib151)).
  prefs: []
  type: TYPE_NORMAL
- en: Multi-modal learning (Ramachandran et al., [2017](#bib.bib198); Baltrušaitis
    et al., [2018](#bib.bib16); Hossain et al., [2019](#bib.bib96); Stefanini et al.,
    [2022](#bib.bib222)) aims at creating representations in DNNs that align different
    modalities of information, for example, images and text. Applications involve
    image captioning (Xu et al., [2015](#bib.bib242); Sarto et al., [2023](#bib.bib211)),
    text-to-image synthesis (Reed et al., [2016](#bib.bib199); Carrara et al., [2018](#bib.bib38);
    Zhang et al., [2017](#bib.bib249), [2018](#bib.bib248)), and cross-modal retrieval
    (Messina et al., [2021](#bib.bib169); Wang et al., [2016](#bib.bib235)). Hebbian
    learning could play a relevant role in reinforcing the observed correlations between
    different sensory pathways in the brain (Kaur et al., [2021](#bib.bib115)). Indeed,
    Hebbian approaches have been applied for cross-modal retrieval applications (Kaur
    et al., [2021](#bib.bib115)).
  prefs: []
  type: TYPE_NORMAL
- en: Contrastive representation learning (Oord et al., [2018](#bib.bib185); Saunshi
    et al., [2019](#bib.bib212); Hénaff et al., [2019](#bib.bib92); Löwe et al., [2019](#bib.bib154);
    Chen et al., [2020](#bib.bib40); Bardes et al., [2021](#bib.bib17)) is a popular
    approach for self-supervised learning in DNNs, which has shown promising results.
    Contrastive learning approaches aim at creating similar representations for elements
    that occur in similar contexts. This principle has been successfully used in the
    development of embedding models for language, such as the popular Word2Vec (Mikolov
    et al., [2013](#bib.bib173)), where words that occur in similar contexts are mapped
    to similar vectors. Contrastive learning approaches took inspiration from this
    principle and popularized it also for images. In this case, any two neighboring
    image patches – two views of the same input – are required to have consistent
    representations, while unrelated patches should have distinct representations.
    The SimCLR (Chen et al., [2020](#bib.bib40)) approach uses instead differently
    augmented versions of the same images, imposing consistency conditions over the
    corresponding representations. When data also have a temporal dimension available,
    consistency between neighboring frames can also be an effective approach, and
    it has been shown to yield feature representations that resemble those of biological
    brains (Watanabe et al., [2018](#bib.bib237); Zhuang et al., [2021](#bib.bib252)).
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Synaptic Plasticity Models in Deep Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1d0896190311adf906369cb209dfa487.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13. A given learning rule can be extended to the case of convolutional
    layers by applying it at different locations of the image, in a patch-wise fashion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Synaptic plasticity learning rules can be extended to the case of convolutional
    layers by applying them at different locations of the images, in a patch-wise
    fashion, as illustrated in Fig. [13](#S5.F13 "Figure 13 ‣ 5\. Synaptic Plasticity
    Models in Deep Learning ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised
    Deep Learning: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: The idea of developing feature extractors for CNNs, based on pattern discovery
    mechanisms such as SC or clustering, was already used in the work from Coates
    et al. (Coates et al., [2011](#bib.bib46); Coates and Ng, [2011b](#bib.bib47),
    [a](#bib.bib45), [2012](#bib.bib48)). An SVM classifier stacked on top of multiple
    convolutional layers (up to 3) was able to achieve 82% accuracy on cifar-10 (Krizhevsky
    and Hinton, [2009](#bib.bib127)), 97% on NORB (LeCun et al., [2004](#bib.bib145)),
    72% con Caltech-101 (Fei-Fei et al., [2004](#bib.bib68)), 60% on STL-10 (Coates
    et al., [2011](#bib.bib46)). However, in order to achieve such results, these
    architectures require a significantly larger number of convolutional kernels (ranging
    from 1600 to 6000 in the proposed experiments) compared to traditional backprop-based
    architectures. For example, accuracy on CIFAR-10 drops to around 65% with k-means-based
    learning and 100 convolutional filters (Coates et al., [2011](#bib.bib46)). In
    these works, it has been shown how 1st layer neurons tend to develop simple filters
    such as edges with various orientations. This also happens in networks trained
    with backprop and in biological brains. Nonetheless, the computational power of
    Hebbian neural networks trained with competitive schemes is reduced by the fact
    that different neurons tend to learn shifted versions of the same filter. This
    creates a correlation in the coding scheme which is not detected over the channel
    dimension but over the height and width dimensions of the feature map. In order
    to overcome this problem, the authors of (Dundar et al., [2015](#bib.bib63)) introduced
    competition among neurons not only along the channel dimension but also with neighboring
    neurons in the height and width dimensions. The resulting 3-layer network achieved
    74.1% accuracy on the STL-10 (Coates et al., [2011](#bib.bib46)) dataset and 0.5%
    error rate on MNIST.
  prefs: []
  type: TYPE_NORMAL
- en: 'In (Wadhwa and Madhow, [2016b](#bib.bib234)), the authors propose a CNN architecture
    consisting of three convolutional layers, followed by an SVM classifier. The convolutional
    layers are trained, without supervision, to extract relevant features from the
    inputs. The proposed training algorithm, named Adaptive Hebbian Learning (AHL),
    combines Hebbian weight update with k-WTA, pre-synaptic competition (given two
    winning neurons $j$ and $k$, a pre-synaptic neuron $i$ and the connecting synaptic
    weights $w_{i,j}$ and $w_{i,k}$, only the highest between $w_{i,j}$ and $w_{i,k}$
    is updated) and dynamic recruiting/pruning of neurons. Additionally, a rule for
    learning bias terms, also used in previous works (Földiak, [1989](#bib.bib69)),
    is adopted: the bias term is important to balance the activations of different
    neurons; hence, the idea is to keep a running average of neuron activations as
    $r$, choose a target activation value $A_{bias}$ and increase or decrease the
    bias in order to make $r$ approach $A_{bias}$. The rule, which is biologically
    motivated by homeostatic mechanisms (Turrigiano, [2012](#bib.bib230)) for the
    stabilization of neural activity, is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (37) |  | $\Delta b=\eta\,(r-A_{bias})$ |  |'
  prefs: []
  type: TYPE_TB
- en: The authors applied these ideas to different image datasets and obtained an
    error rate of 0.65% on MNIST (LeCun et al., [1998](#bib.bib144)), an accuracy
    of 75.87% on CIFAR-10, and an error rate of 3.48% on NORB.
  prefs: []
  type: TYPE_NORMAL
- en: Other works applied similar WTA-based approaches on fully connected networks.
    In (Krotov and Hopfield, [2019](#bib.bib128)), the authors achieved 98% accuracy
    on MNIST and 50% accuracy on CIFAR-10 with two fully-connected layers. In (Illing
    et al., [2019](#bib.bib104)) various Hebbian models for sparse coding, principal,
    and independent component analysis were compared, in similar settings as (Krotov
    and Hopfield, [2019](#bib.bib128)). ICA models achieved the best results, with
    53.9 % accuracy on CIFAR-10, and 98.8% mnist. PCA models achieved 50.8% accuracy
    on cifar-10, and 98.2% on MNIST, while SC achieved 50.2% accuracy on cifar-10,
    and 98.4% on MNIST. The HaH model derived from the similarity matching criterion
    (Pehlevan et al., [2015](#bib.bib193); Pehlevan and Chklovskii, [2015b](#bib.bib192))
    was applied to image classification tasks in (Bahroun and Soltoggio, [2017](#bib.bib14)),
    again on the CIFAR-10 dataset, achieving 80% accuracy with a single convolutional
    layer followed by an SVM classifier. Hebbian learning approaches were further
    investigated in(Miconi, [2021](#bib.bib171)), where it was shown that deeper network
    layers were not able to develop more abstract features without supervision. In
    order to achieve more complex feature representations, this work proposed to introduce
    sparsity in the weight configuration by pruning some selected weights. Experiments
    with a 3-layer CNN show 64% accuracy on CIFAR-10\. This work also introduced a
    loss function formulation of the learning rules investigated, which allows a more
    immediate integration with modern deep learning frameworks. The approaches in
    (Moraitis et al., [2021](#bib.bib174)), and layer (Journé et al., [2022](#bib.bib110)),
    use a soft-WTA training approach. In particular, the latter work shows for the
    first time increasing performance while going deeper with the number of layers,
    by resorting to very wide architectures where the number of neurons quadruples
    at each layer. It is shown that, as long as there are enough neurons, the network
    is able to disentangle the latent factors that describe the input, including those
    which provide the classification information. This work also contains experiments
    on ImageNet, but just for a single training epoch. A very recent work (Gupta et al.,
    [2022](#bib.bib86)) provides an interesting investigation of Hebbian learning
    algorithms compared to backprop, showing superior performance of the former in
    single epoch training and in contexts of data scarcity.
  prefs: []
  type: TYPE_NORMAL
- en: The above-mentioned approaches only applied synaptic plasticity models to relatively
    shallow network architectures (generally with 2-3 layers). A further step was
    taken in (Amato et al., [2019](#bib.bib9); Lagani, [2019](#bib.bib131); Lagani
    et al., [2021c](#bib.bib136), [2022b](#bib.bib137); Lagani, [2023](#bib.bib132)),
    where Hebbian WTA and PCA learning rules were investigated for training a 6-layer
    Convolutional Neural Network (CNN). Also, a supervised variant of Hebbian learning
    was proposed to train the final classification layer. Hybrid network models were
    also considered, in which some layers were trained using backprop and others using
    Hebbian learning. The results suggested that Hebbian learning is suitable for
    training early feature detectors, as well as higher network layers, but not very
    effective for training intermediate network layers. Furthermore, Hebbian learning
    was successfully used to retrain the higher layers of a pre-trained network, achieving
    results comparable to backprop, but requiring fewer training epochs, thus suggesting
    potential applications in the context of transfer learning (see also (Magotra
    and kim, [2019](#bib.bib157); Magotra and Kim, [2020](#bib.bib158); Canto, [2020](#bib.bib33))).
    Some contributions (Lagani et al., [2022a](#bib.bib133), [c](#bib.bib138)) showed
    promising results of unsupervised Hebbian algorithms for semi-supervised network
    training, in learning scenarios with scarce data availability, achieving superior
    results compared to other backprop-based unsupervised methods for semi-supervised
    training such as Variational Auto-Encoders (VAE) (Kingma and Welling, [2013](#bib.bib119)).
    In further developments (Lagani et al., [2022a](#bib.bib133), [c](#bib.bib138)),
    a more efficient formulation of Hebbian learning was also proposed, that enabled
    the scaling up of experiments to complex image recognition datasets, such as ImageNet
    (Deng et al., [2009](#bib.bib57)), large-scale image retrieval, and complex network
    architectures, improving training speed up to a factor of 50\. The solution, named
    FastHebb, leveraged some observations that allowed us to rewrite Hebbian update
    equations in terms of matrix multiplications, to better exploit GPU acceleration.
  prefs: []
  type: TYPE_NORMAL
- en: Table 1. Experimental results of bio-inspired learning methods for deep learning
    applications on the CIFAR-10 dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Description | CIFAR-10 Acc. (%) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| K-means features | 3 conv layers with thousands of filters. | 82% (Coates
    and Ng, [2012](#bib.bib48)) |'
  prefs: []
  type: TYPE_TB
- en: '| DHL | Competitive learning approach with 2 conv layers followed by SVM classifier,
    using label information to guide training. | 75.87% (Wadhwa and Madhow, [2016a](#bib.bib233))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Similarity matching | HaH network based on the similarity matching criterion
    (Pehlevan et al., [2015](#bib.bib193)), with multi-scale filters, followed by
    an SVM classifier | 80% (Bahroun and Soltoggio, [2017](#bib.bib14)) |'
  prefs: []
  type: TYPE_TB
- en: '| Krotov and Hopfield | Competitive learning approach with 2 fc layers. | 50%
    (Krotov and Hopfield, [2019](#bib.bib128)) |'
  prefs: []
  type: TYPE_TB
- en: '| Shallow PCA | Analysis of bio-inspired methods on shallow networks: PCA on
    a single fc layer + final classifier. | 50.80% (Illing et al., [2019](#bib.bib104))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Shallow SC | Analysis of bio-inspired methods on shallow networks: PCA on
    a single fc layer + final classifier. | 50.20% (Illing et al., [2019](#bib.bib104))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Shallow ICA | Analysis of bio-inspired methods on shallow networks: PCA on
    a single fc layer + final classifier. | 53.90% (Illing et al., [2019](#bib.bib104))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Hebbian learning with pruning | Objective function formulation of Hebbian
    approaches for gradient-based update computation. Hierarchical organization of
    Hebbian modules (3-layer CNN) with connection pruning and sparsification to induce
    more abstract features. | 64% (Miconi, [2021](#bib.bib171)) |'
  prefs: []
  type: TYPE_TB
- en: '| SoftHebb | Soft-WTA approach in deep CNNs (3 conv layers + final classifier).
    The number of filters is increased by a factor of 4 from each layer to the next,
    leading to very wide deep layers. | 80.31% (Journé et al., [2022](#bib.bib110))
    |'
  prefs: []
  type: TYPE_TB
- en: '| FastHebb | Semi-supervised Hebbian-backprop training based on Hebbian WTA/PCA.
    | 85% (Lagani et al., [2021b](#bib.bib135), [a](#bib.bib134), [2022c](#bib.bib138))
    |'
  prefs: []
  type: TYPE_TB
- en: 'Tab. [1](#S5.T1 "Table 1 ‣ 5\. Synaptic Plasticity Models in Deep Learning
    ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey")
    summarizes the main experimental results presented above on the CIFAR-10 dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We conclude this Section by mentioning some results related to the robustness
    properties of some bio-inspired models against adversarial perturbations (Szegedy
    et al., [2013](#bib.bib227); Akhtar and Mian, [2018](#bib.bib6); Yuan et al.,
    [2019](#bib.bib246)). Early studies on adversarial attacks and defenses (Goodfellow
    et al., [2014](#bib.bib83)) already noticed that Radial-Basis Function (RBF) networks
    exhibited strong robustness against adversarial settings (Vidnerová and Neruda,
    [2018](#bib.bib232); Zadeh et al., [2018](#bib.bib247); Goodfellow, [2017](#bib.bib82)).
    For example, a Gaussian RBF activation function has the form:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (38) |  | $y(\mathbf{x},\mathbf{w})=e^{-\frac{&#124;\mathbf{x}-\mathbf{w}&#124;^{2}}{2\sigma^{2}}}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where the parameter $\sigma$ determines the width of the Gaussian, and the unit
    responds strongly only when the input $\mathbf{x}$ is within a certain distance
    from the reference weight vector $\mathbf{w}$. RBF-like activations could be biologically
    supported by frequency-dependent synaptic responses (Collingridge et al., [1988](#bib.bib49);
    Markram et al., [1998](#bib.bib165)). Although RBF networks are hard to train,
    due to gradient vanishing problems (Goodfellow et al., [2014](#bib.bib83)), gradient-free
    bio-inspired training methods could provide a useful mechanism to effectively
    leverage these types of models also in complex scenarios (Grossberg, [1976](#bib.bib85);
    Kohonen, [1982](#bib.bib121)). Lateral interaction and WTA-type nonlinearities
    have also proven useful to improve the adversarial robustness of DNN models (Kim
    et al., [2019](#bib.bib116); Xiao et al., [2019](#bib.bib241); Panousis et al.,
    [2021a](#bib.bib188), [b](#bib.bib189)).
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Spiking Neural Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This Section introduces models of neural computation based on Spiking Neural
    Networks (SNNs) (Gerstner and Kistler, [2002](#bib.bib80)), which more faithfully
    resemble real neurons compared to traditional ANN models. We start by introducing
    the various neuron models for SNN simulation. We highlight the applications related
    to biological and neuromorphic computing, which are of strong practical interest
    thanks to the energy efficiency of the underlying computing paradigm, and we discuss
    the challenges related to SNN training. We describe the biological plasticity
    models for spiking neurons and the connections with Hebbian synaptic plasticity.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1\. Spiking Neuron Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Spiking Neural Networks (SNNs) are a realistic model of biological networks
    (Gerstner and Kistler, [2002](#bib.bib80); Maass, [1997](#bib.bib156)). While
    in traditional Artificial Neural Networks (ANNs), neurons communicate via real-valued
    signals, in SNNs they emit short pulses called spikes. All the spikes are equal
    to each other and values are encoded in the timing or in the frequency with which
    spikes are emitted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Various spiking neuron models have been proposed in literature (Gerstner and
    Kistler, [2002](#bib.bib80)): from the classical neuron description due to Hodgkin
    and Huxley (HH) (Hodgkin and Huxley, [1952](#bib.bib93)), to more abstract but
    also computationally efficient models such as Izhikevich’s (Izhikevich, [2003](#bib.bib107)),
    Spike-Response Models (SRM) (Gerstner, [1995](#bib.bib78)), and Leaky Integrate
    and Fire (LIF) (Abbott and van Vreeswijk, [1993](#bib.bib2)). In particular, the
    LIF model is probably the highest-level description of spiking neurons, and also
    the most computationally efficient to simulate, which makes this model widely
    used in practice.'
  prefs: []
  type: TYPE_NORMAL
- en: LIF neurons behave like integrators, summing up all the received spikes (weighted
    by the synaptic coefficients) until a threshold is exceeded. At this point, an
    output spike is emitted. In practice, this integration logic is implemented in
    terms of an electric potential that is accumulated on the neural membrane every
    time an input spike is received; when the threshold is reached and the output
    spike is released, the neural membrane discharges the accumulated potential and
    the process restarts. Immediately after the discharge, the neuron enters its refractory
    period, a time interval where it cannot spike regardless of its input. These units
    are leaky in the sense that, when no spikes are received in input, the membrane
    potential decays exponentially.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2\. Neuromorphic Computing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Thanks to the spike-based communication paradigm, biological neurons are extremely
    efficient in terms of energy requirements (Javed et al., [2010](#bib.bib109)).
    Energy efficiency is an important issue in modern deep learning (Badar et al.,
    [2021](#bib.bib13)); hence, research is oriented toward different computing paradigms
    to support neural computation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spiking neuron models represent a promising computing paradigm due to the possible
    applications in the implementation of computing hardware that reproduces the behavior
    of biological neurons in silico, with devices known as neuromorphic hardware (Roy
    et al., [2019](#bib.bib205); Zhu et al., [2020](#bib.bib251); Schuman et al.,
    [2022](#bib.bib214); Huynh et al., [2022](#bib.bib97); Shrestha et al., [2022](#bib.bib219)).
    By reproducing the spike-based computation in hardware, researchers were able
    to develop extremely energy-efficient neuromorphic chips (Gamrat et al., [2015](#bib.bib74);
    Wu et al., [2015](#bib.bib240)), such as Neurogrid (Benjamin et al., [2014](#bib.bib27)),
    TrueNorth (Merolla et al., [2014](#bib.bib168)), BrainScales (Schemmel et al.,
    [2010](#bib.bib213); Billaudelle et al., [2020](#bib.bib30)), Loihi (Davies et al.,
    [2018](#bib.bib54)). Despite the energy-efficient computing paradigm, SNN models
    have to face novel challenges, compared to traditional DNNs, related to the learning
    and optimization paradigms. In fact, traditional learning based on backprop is
    not adequate for SNN, because the spiking nonlinearity is not well suited for
    gradient-based optimization. Therefore, the following subsection is dedicated
    to the description of the counterpart model of Hebbian plasticity for SNNs: Spike
    Time Dependent Plasticity (STDP).'
  prefs: []
  type: TYPE_NORMAL
- en: 6.3\. Plasticity in SNNs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In biological spiking neurons, learning occurs in the form of Spike Time Dependent
    Plasticity (STDP) (Bi and Poo, [1998](#bib.bib28); Song et al., [2000](#bib.bib221);
    Gerstner and Kistler, [2002](#bib.bib80)): when an input spike is received on
    a synapse and it is immediately followed by an output spike, then the weight on
    that synapse is increased. Specifically, a possible STDP rule can be expressed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (39) |  | $\Delta w=\begin{cases}\eta^{+}\,e^{-&#124;\Delta t&#124;/\tau^{+}}&amp;\text{if
    $\Delta t>0$}\\ \eta^{-}\,e^{-&#124;\Delta t&#124;/\tau^{-}}&amp;\text{otherwise}\end{cases}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $w$ is the weight, $\Delta t$ is the time difference between the post-synaptic
    and the pre-synaptic spike, $\eta^{+}$ and $\eta^{-}$ are learning rate parameters
    ($\eta^{+}>0$ and $\eta^{-}<0$) and $\tau^{+}$ and $\tau^{-}$ are time constants.
    Weight strengthening occurs when a pre-synaptic spike has been a likely cause
    for a post-synaptic spike, hence pre-synaptic and post-synaptic activations are
    correlated. If instead, a pre-synaptic spike occurred right after a post-synaptic
    one, then the two activations are anti-correlated and a weight decrease occurs.
    In this perspective, STDP realizes the Hebbian principle in the context of spiking
    neurons. According to Eq. [39](#S6.E39 "In 6.3\. Plasticity in SNNs ‣ 6\. Spiking
    Neural Networks ‣ Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep
    Learning: A Survey") The dependency between $\Delta w$ and $\Delta t$ according
    to the STDP weight update rule follows a double exponential profile.'
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Concluding Remarks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We wish to provide a conclusion to this survey with some final remarks about
    the limitations and potentials of the bio-inspired methods presented so far.
  prefs: []
  type: TYPE_NORMAL
- en: The main limitation of Hebbian and spiking models lies in the fact that their
    performance is not yet comparable to that of traditional DL approaches in terms
    of task performance. However, there exist several compelling factors that justify
    the study of biologically plausible learning models. Research on backprop-based
    models has witnessed extensive efforts, with the development of highly specialized
    hardware and solutions oriented to this type of optimization approach. Similarly,
    we anticipate a growth in efforts directed towards biologically plausible solutions
    in the near future, with an increasing interest in neuromorphic computing technologies
    (Roy et al., [2019](#bib.bib205); Zhu et al., [2020](#bib.bib251); Schuman et al.,
    [2022](#bib.bib214); Huynh et al., [2022](#bib.bib97); Shrestha et al., [2022](#bib.bib219)).
    At the same time, additional efforts may lead to promising results both in the
    refinement of bio-inspired algorithms and in their application to more complex
    network architectures, and this work hopes to stimulate further interest in this
    sense. Another disadvantage of biologically based models is related to the computational
    cost of simulating certain synaptic dynamics or unfolding the temporal evolution
    of complex neural circuitry. A recent work (Lagani et al., [2022c](#bib.bib138))
    addresses in part this problem by leveraging GPU parallelization more carefully.
  prefs: []
  type: TYPE_NORMAL
- en: A possible advantage of bio-inspired plasticity rules is locality, in the sense
    that each layer of neurons can perform an update without having to wait for the
    whole network to process the input (each layer is independent of the subsequent
    ones). This is well suited for highly parallelizable layerwise training. Additionally,
    local plasticity rules do not require gradient computations, which could make
    it easier to train deeper architectures without worrying about gradient vanishing
    problems; a possible application would be, for instance, efficient training of
    deep Radial Basis Function (RBF) networks, which are of great interest for their
    adversarial robustness properties (Goodfellow et al., [2014](#bib.bib83)), and
    whose computing model is biologically grounded (Collingridge et al., [1988](#bib.bib49);
    Markram et al., [1998](#bib.bib165)). Training RBF networks with backpropagation
    is challenging because the gradient vanishes quickly when going far from the center
    of the RBF kernel. Therefore, an effective gradient-free alternative training
    approach would be helpful in these scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: A key aspect of SNN and STDP models is the possibility of realizing energy-efficient
    neural network implementations in neuromorphic hardware, which could also find
    applications in embedded devices. Towards SNN training, where the backpropagation
    algorithm is not directly applicable, exploration of alternatives to backprop
    training, inspired for instance by biological plasticity mechanisms, represents
    a promising direction.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, neuroscience and engineering fields can mutually influence each other,
    as neuroscience can provide engineers with valuable inspiration for the design
    of AI solutions, and, in turn, technological advances can give insights to neuroscientists
    about what to look for in biological systems. Indeed, research efforts focused
    on the formulation of an algorithmic theory of the brain and further investigation
    of biologically plausible learning models are important to finally achieve a deeper
    understanding of how the human brain works, which could open possibilities of
    further advances both in technological and in medical fields (Lagani et al., [2021d](#bib.bib139);
    Markram et al., [2012](#bib.bib166)).
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This work was partially supported by:'
  prefs: []
  type: TYPE_NORMAL
- en: '- Tuscany Health Ecosystem (THE) Project (CUP I53C22000780001), funded by the
    National Recovery and Resilience Plan (NRRP), within the NextGeneration Europe
    (NGEU) Program;'
  prefs: []
  type: TYPE_NORMAL
- en: '- Horizon Europe Research & Innovation Programme under Grant agreement N. 101092612
    (Social and hUman ceNtered XR - SUN project);'
  prefs: []
  type: TYPE_NORMAL
- en: '- AI4Media project, funded by the European Commission (H2020 - Contract n.
    951911);'
  prefs: []
  type: TYPE_NORMAL
- en: '- INAROS (INtelligenza ARtificiale per il mOnitoraggio e Supporto agli anziani)
    project co-funded by Tuscany Region POR FSE CUP B53D21008060008.'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abbott and van Vreeswijk (1993) LF Abbott and Carl van Vreeswijk. 1993. Asynchronous
    states in networks of pulse-coupled oscillators. *Physical Review E* 48, 2 (1993),
    1483.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Agrawal et al. (2014) Pulkit Agrawal, Ross Girshick, and Jitendra Malik. 2014.
    Analyzing the performance of multilayer neural networks for object recognition.
    In *Computer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland,
    September 6-12, 2014, Proceedings, Part VII 13*. Springer, 329–344.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aharon et al. (2006) Michal Aharon, Michael Elad, and Alfred Bruckstein. 2006.
    K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation.
    *IEEE Transactions on signal processing* 54, 11 (2006), 4311–4322.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akaho (2002) Shotaro Akaho. 2002. Conditionally independent component analysis
    for supervised feature extraction. *Neurocomputing* 49, 1-4 (2002), 139–150.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Akhtar and Mian (2018) Naveed Akhtar and Ajmal Mian. 2018. Threat of adversarial
    attacks on deep learning in computer vision: A survey. *IEEE Access* 6 (2018),
    14410–14430.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amari and Cichocki (1998) Shun-ichi Amari and Andrzej Cichocki. 1998. Adaptive
    blind signal processing-neural network approaches. *Proc. IEEE* 86, 10 (1998),
    2026–2048.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amari et al. (1996) Shun-ichi Amari, Andrzej Cichocki, and Howard Hua Yang.
    1996. A new learning algorithm for blind signal separation. In *Advances in neural
    information processing systems*. 757–763.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amato et al. (2019) Giuseppe Amato, Fabio Carrara, Fabrizio Falchi, Claudio
    Gennaro, and Gabriele Lagani. 2019. Hebbian Learning Meets Deep Convolutional
    Neural Networks. In *International Conference on Image Analysis and Processing*.
    Springer, 324–334.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Amato et al. (2023) Giuseppe Amato, Fabio Carrara, Fabrizio Falchi, Claudio
    Gennaro, and Gabriele Lagani. 2023. Spiking Neural Networks and Bio-Inspired Supervised
    Deep Learning: A Survey. (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Andrew et al. (2013) Galen Andrew, Raman Arora, Jeff Bilmes, and Karen Livescu.
    2013. Deep canonical correlation analysis. In *International conference on machine
    learning*. PMLR, 1247–1255.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Averbeck et al. (2006) Bruno B Averbeck, Peter E Latham, and Alexandre Pouget.
    2006. Neural correlations, population coding and computation. *Nature reviews
    neuroscience* 7, 5 (2006), 358–366.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Badar et al. (2021) Ahmed Badar, Arnav Varma, Adrian Staniec, Mahmoud Gamal,
    Omar Magdy, Haris Iqbal, Elahe Arani, and Bahram Zonooz. 2021. Highlighting the
    importance of reducing research bias and carbon emissions in cnns. In *International
    Conference of the Italian Association for Artificial Intelligence*. Springer,
    515–531.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bahroun and Soltoggio (2017) Yanis Bahroun and Andrea Soltoggio. 2017. Online
    representation learning with single and multi-layer Hebbian networks for image
    classification. In *International Conference on Artificial Neural Networks*. Springer,
    354–363.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bair et al. (2006) Eric Bair, Trevor Hastie, Debashis Paul, and Robert Tibshirani.
    2006. Prediction by supervised principal components. *J. Amer. Statist. Assoc.*
    101, 473 (2006), 119–137.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Baltrušaitis et al. (2018) Tadas Baltrušaitis, Chaitanya Ahuja, and Louis-Philippe
    Morency. 2018. Multimodal machine learning: A survey and taxonomy. *IEEE transactions
    on pattern analysis and machine intelligence* 41, 2 (2018), 423–443.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bardes et al. (2021) Adrien Bardes, Jean Ponce, and Yann LeCun. 2021. VICReg:
    Variance-Invariance-Covariance Regularization for Self-Supervised Learning. In
    *International Conference on Learning Representations*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Barshan et al. (2011) Elnaz Barshan, Ali Ghodsi, Zohreh Azimifar, and Mansoor Zolghadri
    Jahromi. 2011. Supervised principal component analysis: Visualization, classification
    and regression on subspaces and submanifolds. *Pattern Recognition* 44, 7 (2011),
    1357–1371.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bear (1996) Mark F Bear. 1996. A synaptic basis for memory storage in the cerebral
    cortex. *Proceedings of the National Academy of Sciences* 93, 24 (1996), 13453–13459.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beck and Teboulle (2009) Amir Beck and Marc Teboulle. 2009. A fast iterative
    shrinkage-thresholding algorithm for linear inverse problems. *SIAM journal on
    imaging sciences* 2, 1 (2009), 183–202.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Becker (1996) Suzanna Becker. 1996. Mutual information maximization: models
    of cortical self-organization. *Network: Computation in neural systems* 7, 1 (1996),
    7–31.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Becker and Plumbley (1996) Suzanna Becker and Mark Plumbley. 1996. Unsupervised
    neural network learning procedures for feature extraction and classification.
    *Applied Intelligence* 6, 3 (1996), 185–203.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Belkin and Niyogi (2003) Mikhail Belkin and Partha Niyogi. 2003. Laplacian eigenmaps
    for dimensionality reduction and data representation. *Neural computation* 15,
    6 (2003), 1373–1396.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bell and Sejnowski (1995) Anthony J Bell and Terrence J Sejnowski. 1995. An
    information-maximization approach to blind separation and blind deconvolution.
    *Neural computation* 7, 6 (1995), 1129–1159.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Belouchrani et al. (1997) Adel Belouchrani, Karim Abed-Meraim, J-F Cardoso,
    and Eric Moulines. 1997. A blind source separation technique using second-order
    statistics. *IEEE Transactions on signal processing* 45, 2 (1997), 434–444.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bengio et al. (2015) Yoshua Bengio, Dong-Hyun Lee, Jorg Bornschein, Thomas Mesnard,
    and Zhouhan Lin. 2015. Towards biologically plausible deep learning. *arXiv preprint
    arXiv:1502.04156* (2015).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Benjamin et al. (2014) Ben Varkey Benjamin, Peiran Gao, Emmett McQuinn, Swadesh
    Choudhary, Anand R Chandrasekaran, Jean-Marie Bussat, Rodrigo Alvarez-Icaza, John V
    Arthur, Paul A Merolla, and Kwabena Boahen. 2014. Neurogrid: A mixed-analog-digital
    multichip system for large-scale neural simulations. *Proc. IEEE* 102, 5 (2014),
    699–716.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bi and Poo (1998) Guo-qiang Bi and Mu-ming Poo. 1998. Synaptic modifications
    in cultured hippocampal neurons: dependence on spike timing, synaptic strength,
    and postsynaptic cell type. *Journal of neuroscience* 18, 24 (1998), 10464–10472.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bienenstock et al. (1982) Elie L Bienenstock, Leon N Cooper, and Paul W Munro.
    1982. Theory for the development of neuron selectivity: orientation specificity
    and binocular interaction in visual cortex. *Journal of Neuroscience* 2, 1 (1982),
    32–48.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Billaudelle et al. (2020) Sebastian Billaudelle, Yannik Stradmann, Korbinian
    Schreiber, Benjamin Cramer, Andreas Baumbach, Dominik Dold, Julian Göltz, Akos F
    Kungl, Timo C Wunderlich, Andreas Hartel, et al. 2020. Versatile emulation of
    spiking neural networks on an accelerated neuromorphic substrate. In *2020 IEEE
    International Symposium on Circuits and Systems (ISCAS)*. IEEE, 1–5.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bressan and Vitrià (2002) Marco Bressan and Jordi Vitrià. 2002. Improving naive
    Bayes using class-conditional ICA. In *Ibero-American Conference on Artificial
    Intelligence*. Springer, 1–10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brito and Gerstner (2016) Carlos SN Brito and Wulfram Gerstner. 2016. Nonlinear
    Hebbian learning as a unifying principle in receptive field formation. *PLoS computational
    biology* 12, 9 (2016), e1005070.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canto (2020) Fernando Javier Aguilar Canto. 2020. Convolutional Neural Networks
    with Hebbian-Based Rules in Online Transfer Learning. In *Mexican International
    Conference on Artificial Intelligence*. Springer, 35–49.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cardoso (1997) J-F Cardoso. 1997. Infomax and maximum likelihood for blind source
    separation. *IEEE Signal processing letters* 4, 4 (1997), 112–114.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cardoso (2001) Jean-François Cardoso. 2001. The three easy routes to independent
    component analysis; contrasts and geometry. In *Proc. ICA*, Vol. 2001\. 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cardoso (2003) Jean-François Cardoso. 2003. Dependence, correlation and gaussianity
    in independent component analysis. *Journal of Machine Learning Research* 4, Dec
    (2003), 1177–1203.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cardoso and Laheld (1996) J-F Cardoso and Beate H Laheld. 1996. Equivariant
    adaptive source separation. *IEEE Transactions on signal processing* 44, 12 (1996),
    3017–3030.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Carrara et al. (2018) Fabio Carrara, Andrea Esuli, Tiziano Fagni, Fabrizio
    Falchi, and Alejandro Moreo Fernández. 2018. Picture it in your mind: Generating
    high level visual representations from textual descriptions. *Information Retrieval
    Journal* 21 (2018), 208–229.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chan et al. (2015) Tsung-Han Chan, Kui Jia, Shenghua Gao, Jiwen Lu, Zinan Zeng,
    and Yi Ma. 2015. PCANet: A simple deep learning baseline for image classification?
    *IEEE transactions on image processing* 24, 12 (2015), 5017–5032.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2020) Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey
    Hinton. 2020. A simple framework for contrastive learning of visual representations.
    In *International conference on machine learning*. PMLR, 1597–1607.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chien and Chen (2016) Jen-Tzung Chien and Ching-Huai Chen. 2016. Deep discriminative
    manifold learning. In *2016 IEEE International Conference on Acoustics, Speech
    and Signal Processing (ICASSP)*. IEEE, 2672–2676.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choi (1998) Seungjin Choi. 1998. Differential Hebbian-type learning algorithms
    for decorrelation and independent component analysis. *Electronics Letters* 34,
    9 (1998), 900–900.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choi et al. (2002a) Seungjin Choi, Andrzej Cichocki, and Shunichi Amari. 2002a.
    Equivariant nonstationary source separation. *Neural networks* 15, 1 (2002), 121–130.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choi et al. (2002b) Seungjin Choi, Andrzej Cichocki, and Adel Beloucharni. 2002b.
    Second order nonstationary source separation. *Journal of VLSI signal processing
    systems for signal, image and video technology* 32, 1-2 (2002), 93–104.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coates and Ng (2011a) Adam Coates and Andrew Ng. 2011a. Selecting receptive
    fields in deep networks. *Advances in neural information processing systems* 24
    (2011).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coates et al. (2011) Adam Coates, Andrew Ng, and Honglak Lee. 2011. An analysis
    of single-layer networks in unsupervised feature learning. In *Proceedings of
    the fourteenth international conference on artificial intelligence and statistics*.
    215–223.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coates and Ng (2011b) Adam Coates and Andrew Y Ng. 2011b. The importance of
    encoding versus training with sparse coding and vector quantization. In *Proceedings
    of the 28th international conference on machine learning (ICML-11)*. 921–928.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Coates and Ng (2012) Adam Coates and Andrew Y Ng. 2012. Learning feature representations
    with k-means. In *Neural Networks: Tricks of the Trade: Second Edition*. Springer,
    561–580.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collingridge et al. (1988) GL Collingridge, CE Herron, and RA Lester. 1988.
    Frequency-dependent N-methyl-D-aspartate receptor-mediated synaptic transmission
    in rat hippocampus. *The Journal of physiology* 399, 1 (1988), 301–312.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comon (1994) Pierre Comon. 1994. Independent component analysis, a new concept?
    *Signal processing* 36, 3 (1994), 287–314.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Comon et al. (1991) Pierre Comon, Christian Jutten, and Jeanny Herault. 1991.
    Blind separation of sources, Part II: Problems statement. *Signal processing*
    24, 1 (1991), 11–20.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cottrell et al. (2018) Marie Cottrell, Madalina Olteanu, Fabrice Rossi, and
    Nathalie Villa-Vialaneix. 2018. Self-OrganizingMaps, theory and applications.
    *Revista de Investigacion Operacional* 39, 1 (2018), 1–22.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cox and Cox (2008) Michael AA Cox and Trevor F Cox. 2008. Multidimensional scaling.
    In *Handbook of data visualization*. Springer, 315–347.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Davies et al. (2018) Mike Davies, Narayan Srinivasa, Tsung-Han Lin, Gautham
    Chinya, Yongqiang Cao, Sri Harsha Choday, Georgios Dimou, Prasad Joshi, Nabil
    Imam, Shweta Jain, et al. 2018. Loihi: A neuromorphic manycore processor with
    on-chip learning. *Ieee Micro* 38, 1 (2018), 82–99.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: De Ridder et al. (2003) Dick De Ridder, Olga Kouropteva, Oleg Okun, Matti Pietikäinen,
    and Robert PW Duin. 2003. Supervised locally linear embedding. In *Artificial
    Neural Networks and Neural Information Processing—ICANN/ICONIP 2003*. Springer,
    333–341.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demir and Ozmehmet (2005) Güleser Kalayci Demir and Kemal Ozmehmet. 2005. Online
    local learning algorithms for linear discriminant analysis. *Pattern Recognition
    Letters* 26, 4 (2005), 421–431.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deng et al. (2009) Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and
    Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In *2009
    IEEE conference on computer vision and pattern recognition*. Ieee, 248–255.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language
    Understanding. In *Proceedings of the 2019 Conference of the North American Chapter
    of the Association for Computational Linguistics: Human Language Technologies,
    Volume 1 (Long and Short Papers)*. Association for Computational Linguistics,
    4171–4186.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dhir and Lee (2011) Chandra Shekhar Dhir and Soo-Young Lee. 2011. Discriminant
    independent component analysis. *IEEE transactions on neural networks* 22, 6 (2011),
    845–857.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dorfer et al. (2015) Matthias Dorfer, Rainer Kelz, and Gerhard Widmer. 2015.
    Deep linear discriminant analysis. *arXiv preprint arXiv:1511.04707* (2015).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dorfer et al. (2016) Matthias Dorfer, Gerhard Widmer, and Gerhard Widmerajku
    At. 2016. Towards Deep and Discriminative Canonical Correlation Analysis. In *Proc.
    ICML Workshop on Multi-view Representaiton Learning*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Duan et al. (2021) Shiyu Duan, Shujian Yu, and José C Príncipe. 2021. Modularizing
    deep learning via pairwise learning with kernels. *IEEE Transactions on Neural
    Networks and Learning Systems* 33, 4 (2021), 1441–1451.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dundar et al. (2015) Aysegul Dundar, Jonghoon Jin, and Eugenio Culurciello.
    2015. Convolutional clustering for unsupervised learning. *arXiv preprint arXiv:1511.06241*
    (2015).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elmadany et al. (2016) Nour El Din Elmadany, Yifeng He, and Ling Guan. 2016.
    Multiview learning via deep discriminative canonical correlation analysis. In
    *2016 IEEE International Conference on Acoustics, Speech and Signal Processing
    (ICASSP)*. IEEE, 2409–2413.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Erwin et al. (1991) Ed Erwin, Klaus Obermayer, and Klaus Schulten. 1991. Convergence
    properties of self-organizing maps.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Erwin et al. (1992a) Ed Erwin, Klaus Obermayer, and Klaus Schulten. 1992a.
    Self-organizing maps: ordering, convergence properties and energy functions. *Biological
    cybernetics* 67, 1 (1992), 47–55.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Erwin et al. (1992b) Ed Erwin, Klaus Obermayer, and Klaus Schulten. 1992b.
    Self-organizing maps: Stationary states, metastability and convergence rate. *Biological
    Cybernetics* 67, 1 (1992), 35–45.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fei-Fei et al. (2004) Li Fei-Fei, Rob Fergus, and Pietro Perona. 2004. Learning
    generative visual models from few training examples: An incremental bayesian approach
    tested on 101 object categories. In *2004 conference on computer vision and pattern
    recognition workshop*. IEEE, 178–178.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Földiak (1989) Peter Földiak. 1989. Adaptive network for optimal linear feature
    extraction. In *Proceedings of IEEE/INNS Int. Joint. Conf. Neural Networks*, Vol. 1.
    401–405.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Földiak (1990) Peter Földiak. 1990. Forming sparse representations by local
    anti-Hebbian learning. *Biological cybernetics* 64, 2 (1990), 165–170.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fusi et al. (2000) Stefano Fusi, Mario Annunziato, Davide Badoni, Andrea Salamon,
    and Daniel J Amit. 2000. Spike-driven synaptic plasticity: theory, simulation,
    VLSI implementation. *Neural computation* 12, 10 (2000), 2227–2258.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fyfe and Baddeley (1995) Colin Fyfe and Roland Baddeley. 1995. Non-linear data
    structure extraction using simple Hebbian networks. *Biological cybernetics* 72,
    6 (1995), 533–541.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gabbott and Somogyi (1986) PLA Gabbott and P Somogyi. 1986. Quantitative distribution
    of GABA-immunoreactive neurons in the visual cortex (area 17) of the cat. *Experimental
    Brain Research* 61, 2 (1986), 323–331.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gamrat et al. (2015) C Gamrat, O Bichler, and D Roclin. 2015. Memristive based
    device arrays combined with Spike based coding can enable efficient implementations
    of embedded neuromorphic circuits. *2015 IEEE International Electron Devices Meeting
    (IEDM)* 2016 (2015), 4–5.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao and Pavel (2017) Bolin Gao and Lacra Pavel. 2017. On the properties of the
    softmax function with application in game theory and reinforcement learning. *arXiv
    preprint arXiv:1704.00805* (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gatto and dos Santos (2017) Bernardo B Gatto and Eulanda M dos Santos. 2017.
    Discriminative canonical correlation analysis network for image classification.
    In *2017 IEEE International Conference on Image Processing (ICIP)*. IEEE, 4487–4491.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geng et al. (2005) Xin Geng, De-Chuan Zhan, and Zhi-Hua Zhou. 2005. Supervised
    nonlinear dimensionality reduction for visualization and classification. *IEEE
    Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)* 35, 6 (2005),
    1098–1107.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gerstner (1995) Wulfram Gerstner. 1995. Time structure of the activity in neural
    network models. *Physical review E* 51, 1 (1995), 738.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gerstner et al. (1996) Wulfram Gerstner, Richard Kempter, J Leo Van Hemmen,
    and Hermann Wagner. 1996. A neuronal learning rule for sub-millisecond temporal
    coding. *Nature* 383, 6595 (1996), 76–78.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gerstner and Kistler (2002) Wulfram Gerstner and Werner M Kistler. 2002. *Spiking
    neuron models: Single neurons, populations, plasticity*. Cambridge university
    press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gerstner et al. (2018) Wulfram Gerstner, Marco Lehmann, Vasiliki Liakoni, Dane
    Corneil, and Johanni Brea. 2018. Eligibility traces and plasticity on behavioral
    time scales: experimental support of neohebbian three-factor learning rules. *Frontiers
    in neural circuits* 12 (2018), 53.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow (2017) I. Goodfellow. 2017. CS231n Lecture 16 - Adversarial Examples
    and Adversarial Training. [https://youtu.be/CIfsB_EYsVI?list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&t=2765](https://youtu.be/CIfsB_EYsVI?list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&t=2765)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2014) Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.
    2014. Explaining and harnessing adversarial examples. *arXiv preprint arXiv:1412.6572*
    (2014).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gorchetchnikov et al. (2011) Anatoli Gorchetchnikov, Massimiliano Versace, Heather
    Ames, Ben Chandler, Jasmin Léveillé, Gennady Livitz, Ennio Mingolla, Greg Snider,
    Rick Amerson, Dick Carter, et al. 2011. Review and unification of learning framework
    in cog ex machina platform for memristive neuromorphic hardware. In *The 2011
    International Joint Conference on Neural Networks*. IEEE, 2601–2608.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Grossberg (1976) Stephen Grossberg. 1976. Adaptive pattern classification and
    universal recoding: I. Parallel development and coding of neural feature detectors.
    *Biological cybernetics* 23, 3 (1976), 121–134.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gupta et al. (2022) Manas Gupta, Sarthak Ketanbhai Modi, Hang Zhang, Joon Hei
    Lee, and Joo Hwee Lim. 2022. Is Bio-Inspired Learning Better than Backprop? Benchmarking
    Bio Learning vs. Backprop. *arXiv preprint arXiv:2212.04614* (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hassabis et al. (2017) Demis Hassabis, Dharshan Kumaran, Christopher Summerfield,
    and Matthew Botvinick. 2017. Neuroscience-inspired artificial intelligence. *Neuron*
    95, 2 (2017), 245–258.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Haykin (2009) Simon Haykin. 2009. *Neural networks and learning machines* (3
    ed.). Pearson.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2016) Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.
    Deep residual learning for image recognition. In *Proceedings of the IEEE conference
    on computer vision and pattern recognition*. 770–778.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He and Cichocki (2006a) Zhaoshui He and Andrzej Cichocki. 2006a. K-EVD clustering
    and its applications to sparse component analysis. In *International Conference
    on Independent Component Analysis and Signal Separation*. Springer, 90–97.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He and Cichocki (2006b) Zhaoshui He and Andrzej Cichocki. 2006b. K-subspace
    clustering and its application in sparse component analysis. In *Proc. ESANN 2006*.
    Citeseer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hénaff et al. (2019) Olivier J Hénaff, Aravind Srinivas, Jeffrey De Fauw, Ali
    Razavi, Carl Doersch, SM Eslami, and Aaron van den Oord. 2019. Data-efficient
    image recognition with contrastive predictive coding. *arXiv preprint arXiv:1905.09272*
    (2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hodgkin and Huxley (1952) Alan L Hodgkin and Andrew F Huxley. 1952. A quantitative
    description of membrane current and its application to conduction and excitation
    in nerve. *The Journal of physiology* 117, 4 (1952), 500.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hoffer and Ailon (2015) Elad Hoffer and Nir Ailon. 2015. Deep metric learning
    using triplet network. In *International Workshop on Similarity-Based Pattern
    Recognition*. Springer, 84–92.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hopfield (1982) John J Hopfield. 1982. Neural networks and physical systems
    with emergent collective computational abilities. *Proceedings of the national
    academy of sciences* 79, 8 (1982), 2554–2558.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hossain et al. (2019) MD Zakir Hossain, Ferdous Sohel, Mohd Fairuz Shiratuddin,
    and Hamid Laga. 2019. A comprehensive survey of deep learning for image captioning.
    *ACM Computing Surveys (CsUR)* 51, 6 (2019), 1–36.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huynh et al. (2022) Phu Khanh Huynh, M Lakshmi Varshika, Ankita Paul, Murat
    Isik, Adarsha Balaji, and Anup Das. 2022. Implementing spiking neural networks
    on neuromorphic architectures: A review. *arXiv preprint arXiv:2202.08897* (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyvärinen (1997) Aapo Hyvärinen. 1997. Independent component analysis by minimization
    of mutual information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyvarinen et al. (2002) Aapo Hyvarinen, Juha Karhunen, and Erkki Oja. 2002.
    Independent component analysis. *Studies in informatics and control* 11, 2 (2002),
    205–207.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyvarinen and Morioka (2016) Aapo Hyvarinen and Hiroshi Morioka. 2016. Unsupervised
    feature extraction by time-contrastive learning and nonlinear ICA. In *Advances
    in Neural Information Processing Systems*. 3765–3773.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyvarinen and Morioka (2017) AJ Hyvarinen and Hiroshi Morioka. 2017. Nonlinear
    ICA of temporally dependent stationary sources. In *Proceedings of Machine Learning
    Research*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyvärinen and Oja (1998) Aapo Hyvärinen and Erkki Oja. 1998. Independent component
    analysis by general nonlinear Hebbian-like learning rules. *signal processing*
    64, 3 (1998), 301–313.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyvarinen et al. (2019) Aapo Hyvarinen, Hiroaki Sasaki, and Richard Turner.
    2019. Nonlinear ICA using auxiliary variables and generalized contrastive learning.
    In *The 22nd International Conference on Artificial Intelligence and Statistics*.
    859–868.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Illing et al. (2019) Bernd Illing, Wulfram Gerstner, and Johanni Brea. 2019.
    Biologically plausible deep learning—But how far can we go with shallow networks?
    *Neural Networks* 118 (2019), 90–101.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Intrator and Cooper (1992) Nathan Intrator and Leon N Cooper. 1992. Objective
    function formulation of the BCM theory of visual cortical plasticity: Statistical
    connections, stability conditions. *Neural Networks* 5, 1 (1992), 3–17.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ioffe and Szegedy (2015) Sergey Ioffe and Christian Szegedy. 2015. Batch normalization:
    Accelerating deep network training by reducing internal covariate shift. *arXiv
    preprint arXiv:1502.03167* (2015).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Izhikevich (2003) Eugene M Izhikevich. 2003. Simple model of spiking neurons.
    *IEEE Transactions on neural networks* 14, 6 (2003), 1569–1572.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Izhikevich (2007) Eugene M Izhikevich. 2007. Solving the distal reward problem
    through linkage of STDP and dopamine signaling. *Cerebral cortex* 17, 10 (2007),
    2443–2452.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Javed et al. (2010) Fahad Javed, Qing He, Lance E Davidson, John C Thornton,
    Jeanine Albu, Lawrence Boxt, Norman Krasnow, Marinos Elia, Patrick Kang, Stanley
    Heshka, et al. 2010. Brain and high metabolic rate organ mass: contributions to
    resting energy expenditure beyond fat-free mass. *The American journal of clinical
    nutrition* 91, 4 (2010), 907–912.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Journé et al. (2022) Adrien Journé, Hector Garcia Rodriguez, Qinghai Guo, and
    Timoleon Moraitis. 2022. Hebbian deep learning without feedback. *arXiv preprint
    arXiv:2209.11883* (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jutten and Herault (1991) Christian Jutten and Jeanny Herault. 1991. Blind
    separation of sources, part I: An adaptive algorithm based on neuromimetic architecture.
    *Signal processing* 24, 1 (1991), 1–10.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Karhunen (1996) Juha Karhunen. 1996. Neural approaches to independent component
    analysis and source separation.. In *ESANN*, Vol. 96\. 249–266.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Karhunen and Joutsensalo (1995) Juha Karhunen and Jyrki Joutsensalo. 1995. Generalizations
    of principal component analysis, optimization problems, and neural networks. *Neural
    Networks* 8, 4 (1995), 549–562.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kaski et al. (2005) Samuel Kaski, Janne Sinkkonen, and Arto Klami. 2005. Discriminative
    clustering. *Neurocomputing* 69, 1-3 (2005), 18–41.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kaur et al. (2021) Parminder Kaur, Avleen Kaur Malhi, and Husanbir Singh Pannu.
    2021. Hybrid SOM based cross-modal retrieval exploiting Hebbian learning. *Knowledge-Based
    Systems* (2021), 108014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2019) Edward Kim, Jessica Yarnall, Priya Shah, and Garrett T Kenyon.
    2019. A neuromorphic sparse coding defense to adversarial images. In *Proceedings
    of the International Conference on Neuromorphic Systems*. 1–8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim and Kittler (2005) Tae-Kyun Kim and Josef Kittler. 2005. Locally linear
    discriminant analysis for multimodally distributed classes for face recognition
    with a single model image. *IEEE transactions on pattern analysis and machine
    intelligence* 27, 3 (2005), 318–327.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2007) Tae-Kyun Kim, Josef Kittler, and Roberto Cipolla. 2007. Discriminative
    learning and recognition of image set classes using canonical correlations. *IEEE
    Transactions on Pattern Analysis and Machine Intelligence* 29, 6 (2007), 1005–1018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kingma and Welling (2013) Diederik P Kingma and Max Welling. 2013. Auto-encoding
    variational bayes. *arXiv preprint arXiv:1312.6114* (2013).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Koch et al. (2015) Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov. 2015.
    Siamese neural networks for one-shot image recognition. In *ICML deep learning
    workshop*, Vol. 2\. Lille.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kohonen (1982) Teuvo Kohonen. 1982. Self-organized formation of topologically
    correct feature maps. *Biological cybernetics* 43, 1 (1982), 59–69.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kohonen (1993) Teuvo Kohonen. 1993. Things you haven’t heard about the Self-Organizing
    Map. *IEEE International Conference on Neural Networks* (1993), 1147–1156.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kolodziejski et al. (2009b) Christoph Kolodziejski, Bernd Porr, Minija Tamosiunaite,
    and Florentin Wörgötter. 2009b. On the asymptotic equivalence between differential
    Hebbian and temporal difference learning using a local third factor. In *Advances
    in Neural Information Processing Systems*. 857–864.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kolodziejski et al. (2009a) Christoph Kolodziejski, Bernd Porr, and Florentin
    Wörgötter. 2009a. On the asymptotic equivalence between differential Hebbian and
    temporal difference learning. *Neural computation* 21, 4 (2009), 1173–1202.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kosko (1986) Bart Kosko. 1986. Differential hebbian learning. In *AIP Conference
    proceedings*, Vol. 151\. American Institute of Physics, 277–282.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krause et al. (2010) Andreas Krause, Pietro Perona, and Ryan G Gomes. 2010.
    Discriminative clustering by regularized information maximization. In *Advances
    in neural information processing systems*. 775–783.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky and Hinton (2009) Alex Krizhevsky and Geoffrey Hinton. 2009. Learning
    multiple layers of features from tiny images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krotov and Hopfield (2019) Dmitry Krotov and John J Hopfield. 2019. Unsupervised
    learning by competing hidden units. *Proceedings of the National Academy of Sciences*
    116, 16 (2019), 7723–7731.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubota et al. (2016) Yoshiyuki Kubota, Fuyuki Karube, Masaki Nomura, and Yasuo
    Kawaguchi. 2016. The diversity of cortical inhibitory synapses. *Frontiers in
    neural circuits* 10 (2016), 27.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kung and Diamantaras (1990) Sun-Yuan Kung and KI Diamantaras. 1990. A neural
    network learning algorithm for adaptive principal component extraction (APEX).
    In *International Conference on Acoustics, Speech, and Signal Processing*. IEEE,
    861–864.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lagani (2019) Gabriele Lagani. 2019. *Hebbian learning algorithms for training
    convolutional neural networks*. Master’s thesis. School of Engineering, University
    of Pisa, Italy. [https://etd.adm.unipi.it/theses/available/etd-03292019-220853/](https://etd.adm.unipi.it/theses/available/etd-03292019-220853/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lagani (2023) Gabriele Lagani. 2023. *Bio-Inspired Approaches for Deep Learning:
    From Spiking Neural Networks to Hebbian Plasticity*. Ph. D. Dissertation. School
    of Engineering, University of Pisa, Italy. [https://etd.adm.unipi.it/t/etd-05022023-121539](https://etd.adm.unipi.it/t/etd-05022023-121539)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lagani et al. (2022a) Gabriele Lagani, Davide Bacciu, Claudio Gallicchio, Fabrizio
    Falchi, Claudio Gennaro, and Giuseppe Amato. 2022a. Deep Features for CBIR with
    Scarce Data using Hebbian Learning. *arXiv preprint arXiv:2205.08935* (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lagani et al. (2021a) Gabriele Lagani, Fabrizio Falchi, Claudio Gennaro, and
    Giuseppe Amato. 2021a. Evaluating Hebbian Learning in a Semi-supervised Setting.
    In *International Conference on Machine Learning, Optimization, and Data Science*.
    Springer, 365–379.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lagani et al. (2021b) Gabriele Lagani, Fabrizio Falchi, Claudio Gennaro, and
    Giuseppe Amato. 2021b. Hebbian semi-supervised learning in a sample efficiency
    setting. *Neural Networks* 143 (2021), 719–731.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lagani et al. (2021c) Gabriele Lagani, Fabrizio Falchi, Claudio Gennaro, and
    Giuseppe Amato. 2021c. Training Convolutional Neural Networks with Competitive
    Hebbian Learning Approaches. In *International Conference on Machine Learning,
    Optimization, and Data Science*. Springer, 25–40.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lagani et al. (2022b) Gabriele Lagani, Fabrizio Falchi, Claudio Gennaro, and
    Giuseppe Amato. 2022b. Comparing the performance of Hebbian against backpropagation
    learning using convolutional neural networks. *Neural Computing and Applications*
    34, 8 (2022), 6503–6519.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lagani et al. (2022c) Gabriele Lagani, Claudio Gennaro, Hannes Fassold, and
    Giuseppe Amato. 2022c. FastHebb: Scaling Hebbian Training of Deep Neural Networks
    to ImageNet Level. In *Similarity Search and Applications: 15th International
    Conference, SISAP 2022, Bologna, Italy, October 5–7, 2022, Proceedings*. Springer,
    251–264.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lagani et al. (2021d) Gabriele Lagani, Raffaele Mazziotti, Fabrizio Falchi,
    Claudio Gennaro, Guido Marco Cicchini, Tommaso Pizzorusso, Federico Cremisi, and
    Giuseppe Amato. 2021d. Assessing Pattern Recognition Performance of Neuronal Cultures
    through Accurate Simulation. In *2021 10th International IEEE/EMBS Conference
    on Neural Engineering (NER)*. IEEE, 726–729.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lai and Fyfe (2001) Pei Ling Lai and Colin Fyfe. 2001. A family of Canonical
    Correlation networks. *Neural processing letters* 14, 2 (2001), 93–105.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lake and Piantadosi (2020) Brenden M Lake and Steven T Piantadosi. 2020. People
    infer recursive visual concepts from just a few examples. *Computational Brain
    & Behavior* 3 (2020), 54–65.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lake et al. (2017) Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J
    Gershman. 2017. Building machines that learn and think like people. *Behavioral
    and brain sciences* 40 (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Law and Cooper (1994) C Charles Law and Leon N Cooper. 1994. Formation of receptive
    fields in realistic visual environments according to the Bienenstock, Cooper,
    and Munro (BCM) theory. *Proceedings of the National Academy of Sciences* 91,
    16 (1994), 7797–7801.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. (1998) Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner,
    et al. 1998. Gradient-based learning applied to document recognition. *Proc. IEEE*
    86, 11 (1998), 2278–2324.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. (2004) Yann LeCun, Fu Jie Huang, and Leon Bottou. 2004. Learning
    methods for generic object recognition with invariance to pose and lighting. In
    *Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and
    Pattern Recognition, 2004\. CVPR 2004.*, Vol. 2\. IEEE, II–104.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leen (1991) Todd K Leen. 1991. Dynamics of learning in recurrent feature-discovery
    networks. In *Advances in neural information processing systems*. 70–76.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lennie (2003) Peter Lennie. 2003. The cost of cortical computation. *Current
    biology* 13, 6 (2003), 493–497.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2004) Haifeng Li, Tao Jiang, and Keshu Zhang. 2004. Efficient and
    robust feature extraction by maximum margin criterion. In *Advances in neural
    information processing systems*. 97–104.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li and Fu (2015) Sheng Li and Yun Fu. 2015. Learning robust and discriminative
    subspace with low-rank constraints. *IEEE transactions on neural networks and
    learning systems* 27, 11 (2015), 2160–2173.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2003) Yuanqing Li, Andrzej Cichocki, and Shun-Ichi Amari. 2003. Sparse
    component analysis for blind source separation with less sensors than sources.
    In *Ica*, Vol. 2003. 89–94.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2019) Zhonghua Liu, Jingjing Wang, Gang Liu, and Lin Zhang. 2019.
    Discriminative low-rank preserving projection for dimensionality reduction. *Applied
    Soft Computing* 85 (2019), 105768.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lo et al. (1991) Zhen-Ping Lo, Masahiro Fujita, and Behnam Bavarian. 1991. Analysis
    of neighborhood interaction in Kohonen neural networks. *[1991] Proceedings. The
    Fifth International Parallel Processing Symposium* (1991), 246–249.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lo et al. (1993) Z-P Lo, Yaoqi Yu, and Behnam Bavarian. 1993. Analysis of the
    convergence properties of topology preserving neural networks. *IEEE Transactions
    on Neural Networks* 4, 2 (1993), 207–220.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Löwe et al. (2019) Sindy Löwe, Peter O’Connor, and Bastiaan Veeling. 2019.
    Putting an end to end-to-end: Gradient-isolated learning of representations. In
    *Advances in Neural Information Processing Systems*. 3039–3051.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luo and Unbehauen (1997) Fa-Long Luo and Rolf Unbehauen. 1997. A generalized
    learning algorithm of minor component. In *1997 IEEE International Conference
    on Acoustics, Speech, and Signal Processing*, Vol. 4. IEEE, 3229–3232.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Maass (1997) Wolfgang Maass. 1997. Networks of spiking neurons: the third generation
    of neural network models. *Neural networks* 10, 9 (1997), 1659–1671.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Magotra and kim (2019) Arjun Magotra and Juntae kim. 2019. Transfer Learning
    for Image Classification Using Hebbian Plasticity Principles. In *Proceedings
    of the 2019 3rd International Conference on Computer Science and Artificial Intelligence*.
    233–238.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Magotra and Kim (2020) Arjun Magotra and Juntae Kim. 2020. Improvement of Heterogeneous
    Transfer Learning Efficiency by Using Hebbian Learning Principle. *Applied Sciences*
    10, 16 (2020), 5631.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mainen and Sejnowski (1995) Zachary F Mainen and Terrence J Sejnowski. 1995.
    Reliability of spike timing in neocortical neurons. *Science* 268, 5216 (1995),
    1503–1506.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mairal et al. (2008) Julien Mairal, Francis Bach, Jean Ponce, Guillermo Sapiro,
    and Andrew Zisserman. 2008. Discriminative learned dictionaries for local image
    analysis. In *2008 IEEE Conference on Computer Vision and Pattern Recognition*.
    IEEE, 1–8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mairal et al. (2009) Julien Mairal, Jean Ponce, Guillermo Sapiro, Andrew Zisserman,
    and Francis R Bach. 2009. Supervised dictionary learning. In *Advances in neural
    information processing systems*. 1033–1040.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Majani et al. (1989) E Majani, Ruth Erlanson, and Yaser S Abu-Mostafa. 1989.
    On the K-winners-take-all network. In *Advances in neural information processing
    systems*. 634–642.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mao and Jain (1993) Jianchang Mao and Anil K Jain. 1993. Discriminant analysis
    neural networks. In *IEEE International Conference on Neural Networks*. IEEE,
    300–305.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marblestone et al. (2016) Adam H Marblestone, Greg Wayne, and Konrad P Kording.
    2016. Toward an integration of deep learning and neuroscience. *Frontiers in computational
    neuroscience* 10 (2016), 94.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Markram et al. (1998) Henry Markram, Anirudh Gupta, Asher Uziel, Yun Wang, and
    Misha Tsodyks. 1998. Information processing with frequency-dependent synaptic
    connections. *Neurobiology of learning and memory* 70, 1-2 (1998), 101–112.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Markram et al. (2012) Henry Markram, K Meier, A Ailamaki, A Alvandpour, K Amunts,
    W Andreoni, et al. 2012. The human brain project: A report to the European Commission.
    *The HBP-PS Consortium, Lausanne* (2012).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matsuoka et al. (1995) Kiyotoshi Matsuoka, Masahiro Ohoya, and Mitsuru Kawamoto.
    1995. A neural net for blind separation of nonstationary signals. *Neural networks*
    8, 3 (1995), 411–419.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Merolla et al. (2014) Paul A Merolla, John V Arthur, Rodrigo Alvarez-Icaza,
    Andrew S Cassidy, Jun Sawada, Filipp Akopyan, Bryan L Jackson, Nabil Imam, Chen
    Guo, Yutaka Nakamura, et al. 2014. A million spiking-neuron integrated circuit
    with a scalable communication network and interface. *Science* 345, 6197 (2014),
    668–673.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Messina et al. (2021) Nicola Messina, Giuseppe Amato, Andrea Esuli, Fabrizio
    Falchi, Claudio Gennaro, and Stéphane Marchand-Maillet. 2021. Fine-grained visual
    textual alignment for cross-modal retrieval using transformer encoders. *ACM Transactions
    on Multimedia Computing, Communications, and Applications (TOMM)* 17, 4 (2021),
    1–23.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meyer-Base et al. (2001) Anke Meyer-Base, Yunmei Chen, and Scott McCullough.
    2001. Hebbian and anti-Hebbian learning for independent component analysis. In
    *IJCNN’01\. International Joint Conference on Neural Networks. Proceedings (Cat.
    No. 01CH37222)*, Vol. 2\. IEEE, 920–925.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Miconi (2021) Thomas Miconi. 2021. Hebbian learning with gradients: Hebbian
    convolutional neural networks with modern deep learning frameworks. *arXiv preprint
    arXiv:2107.01729* (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mika et al. (1999) Sebastian Mika, Gunnar Ratsch, Jason Weston, Bernhard Scholkopf,
    and Klaus-Robert Mullers. 1999. Fisher discriminant analysis with kernels. In
    *Neural networks for signal processing IX: Proceedings of the 1999 IEEE signal
    processing society workshop (cat. no. 98th8468)*. Ieee, 41–48.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mikolov et al. (2013) Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado,
    and Jeff Dean. 2013. Distributed representations of words and phrases and their
    compositionality. In *Advances in neural information processing systems*. 3111–3119.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Moraitis et al. (2021) Timoleon Moraitis, Dmitry Toichkin, Yansong Chua, and
    Qinghai Guo. 2021. SoftHebb: Bayesian inference in unsupervised Hebbian soft winner-take-all
    networks. *arXiv preprint arXiv:2107.05747* (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Movellan (1991) Javier R Movellan. 1991. Contrastive Hebbian learning in the
    continuous Hopfield model. In *Connectionist models*. Elsevier, 10–17.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nowlan (1990) Steven J Nowlan. 1990. Maximum likelihood competitive learning.
    In *Advances in neural information processing systems*. 574–582.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nunes et al. (2022) Joao D Nunes, Marcelo Carvalho, Diogo Carneiro, and Jaime S
    Cardoso. 2022. Spiking neural networks: A survey. *IEEE Access* 10 (2022), 60738–60764.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oja (1982) Erkki Oja. 1982. Simplified neuron model as a principal component
    analyzer. *Journal of mathematical biology* 15, 3 (1982), 267–273.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oja (1989) Erkki Oja. 1989. Neural networks, principal components, and subspaces.
    *International journal of neural systems* 1, 01 (1989), 61–68.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oja (1992) Erkki Oja. 1992. Principal components, minor components, and linear
    neural networks. *Neural networks* 5, 6 (1992), 927–935.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oja et al. (1996) E Oja, J Karhunen, L Wang, and R Vigario. 1996. Principal
    and independent components in neural networks-recent developments. In *Proc. VII
    Italian Workshop Neural Networks WIRN*, Vol. 95. 16–35.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Olshausen (1996) Bruno A Olshausen. 1996. Learning linear, sparse, factorial
    codes. *Massachusetts Institute of Technology, AIM-1580* (1996).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Olshausen and Field (1996a) Bruno A Olshausen and David J Field. 1996a. Emergence
    of simple-cell receptive field properties by learning a sparse code for natural
    images. *Nature* 381, 6583 (1996), 607.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Olshausen and Field (1996b) Bruno A Olshausen and David J Field. 1996b. Natural
    image statistics and efficient coding. *Network: computation in neural systems*
    7, 2 (1996), 333–339.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oord et al. (2018) Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation
    learning with contrastive predictive coding. *arXiv preprint arXiv:1807.03748*
    (2018).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'O’Reilly and Munakata (2000) Randall C O’Reilly and Yuko Munakata. 2000. *Computational
    explorations in cognitive neuroscience: Understanding the mind by simulating the
    brain*. MIT press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pang et al. (2005) Shaoning Pang, Seiichi Ozawa, and Nikola Kasabov. 2005. Incremental
    linear discriminant analysis for classification of data streams. *IEEE transactions
    on Systems, Man, and Cybernetics, part B (Cybernetics)* 35, 5 (2005), 905–914.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Panousis et al. (2021a) Konstantinos Panousis, Sotirios Chatzis, Antonios Alexos,
    and Sergios Theodoridis. 2021a. Local competition and stochasticity for adversarial
    robustness in deep learning. In *International Conference on Artificial Intelligence
    and Statistics*. PMLR, 3862–3870.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Panousis et al. (2021b) Konstantinos P Panousis, Sotirios Chatzis, and Sergios
    Theodoridis. 2021b. Stochastic local winner-takes-all networks enable profound
    adversarial robustness. *arXiv preprint arXiv:2112.02671* (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pati et al. (1993) Yagyensh Chandra Pati, Ramin Rezaiifar, and Perinkulam Sambamurthy
    Krishnaprasad. 1993. Orthogonal matching pursuit: Recursive function approximation
    with applications to wavelet decomposition. In *Proceedings of 27th Asilomar conference
    on signals, systems and computers*. IEEE, 40–44.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pehlevan and Chklovskii (2015a) Cengiz Pehlevan and Dmitri Chklovskii. 2015a.
    A normative theory of adaptive dimensionality reduction in neural networks. In
    *Advances in neural information processing systems*. 2269–2277.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pehlevan and Chklovskii (2015b) Cengiz Pehlevan and Dmitri B Chklovskii. 2015b.
    Optimization theory of hebbian/anti-hebbian networks for pca and whitening. In
    *2015 53rd Annual Allerton Conference on Communication, Control, and Computing
    (Allerton)*. IEEE, 1458–1465.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pehlevan et al. (2015) Cengiz Pehlevan, Tao Hu, and Dmitri B Chklovskii. 2015.
    A hebbian/anti-hebbian neural network for linear subspace learning: A derivation
    from multidimensional scaling of streaming data. *Neural computation* 27, 7 (2015),
    1461–1495.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pfeiffer and Pfeil (2018) Michael Pfeiffer and Thomas Pfeil. 2018. Deep learning
    with spiking neurons: Opportunities and challenges. *Frontiers in neuroscience*
    12 (2018), 774.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pham and Garat (1997) Dinh Tuan Pham and Philippe Garat. 1997. Blind separation
    of mixture of independent sources through a quasi-maximum likelihood approach.
    *IEEE transactions on Signal Processing* 45, 7 (1997), 1712–1725.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plumbley (1993) Mark D Plumbley. 1993. A Hebbian/anti-Hebbian network which
    optimizes information capacity by orthonormalizing the principal subspace. In
    *1993 Third International Conference on Artificial Neural Networks*. IET, 86–90.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raducanu and Dornaika (2012) Bogdan Raducanu and Fadi Dornaika. 2012. A supervised
    non-linear dimensionality reduction approach for manifold learning. *Pattern Recognition*
    45, 6 (2012), 2432–2444.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ramachandran et al. (2017) Prajit Ramachandran, Barret Zoph, and Quoc V Le.
    2017. Searching for activation functions. *arXiv preprint arXiv:1710.05941* (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reed et al. (2016) Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran,
    Bernt Schiele, and Honglak Lee. 2016. Generative adversarial text to image synthesis.
    In *International conference on machine learning*. PMLR, 1060–1069.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Richards et al. (2019) Blake A Richards, Timothy P Lillicrap, Philippe Beaudoin,
    Yoshua Bengio, Rafal Bogacz, Amelia Christensen, Claudia Clopath, Rui Ponte Costa,
    Archy de Berker, Surya Ganguli, et al. 2019. A deep learning framework for neuroscience.
    *Nature neuroscience* 22, 11 (2019), 1761–1770.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ritchie et al. (2019) Alexander Ritchie, Clayton Scott, Laura Balzano, Daniel
    Kessler, and Chandra S Sripada. 2019. Supervised principal component analysis
    via manifold optimization. In *2019 IEEE Data Science Workshop (DSW)*. IEEE, 6–10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Roberts (1999) Patrick D Roberts. 1999. Computational consequences of temporally
    asymmetric learning rules: I. Differential Hebbian learning. *Journal of computational
    neuroscience* 7, 3 (1999), 235–246.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Roh et al. (2019) Yuji Roh, Geon Heo, and Steven Euijong Whang. 2019. A survey
    on data collection for machine learning: a big data-ai integration perspective.
    *IEEE Transactions on Knowledge and Data Engineering* 33, 4 (2019), 1328–1347.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roweis and Saul (2000) Sam T Roweis and Lawrence K Saul. 2000. Nonlinear dimensionality
    reduction by locally linear embedding. *science* 290, 5500 (2000), 2323–2326.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roy et al. (2019) Kaushik Roy, Akhilesh Jaiswal, and Priyadarshini Panda. 2019.
    Towards spike-based machine intelligence with neuromorphic computing. *Nature*
    575, 7784 (2019), 607–617.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rozell et al. (2008) Christopher J Rozell, Don H Johnson, Richard G Baraniuk,
    and Bruno A Olshausen. 2008. Sparse coding via thresholding and local competition
    in neural circuits. *Neural computation* 20, 10 (2008), 2526–2563.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rubner and Tavan (1989) Jeanne Rubner and Paul Tavan. 1989. A self-organizing
    network for principal-component analysis. *EPL (Europhysics Letters)* 10, 7 (1989),
    693.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rumelhart and Zipser (1985) David E Rumelhart and David Zipser. 1985. Feature
    discovery by competitive learning. *Cognitive science* 9, 1 (1985), 75–112.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sanger (1989) Terence D Sanger. 1989. Optimal unsupervised learning in a single-layer
    linear feedforward neural network. *Neural networks* 2, 6 (1989), 459–473.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Santa Cruz and Dorronsoro (1998) Carlos Santa Cruz and Jose R Dorronsoro. 1998.
    A nonlinear discriminant algorithm for feature extraction and data classification.
    *IEEE transactions on neural networks* 9, 6 (1998), 1370–1376.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sarto et al. (2023) Sara Sarto, Manuele Barraco, Marcella Cornia, Lorenzo Baraldi,
    and Rita Cucchiara. 2023. Positive-Augmented Contrastive Learning for Image and
    Video Captioning Evaluation. In *Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition*. 6914–6924.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saunshi et al. (2019) Nikunj Saunshi, Orestis Plevrakis, Sanjeev Arora, Mikhail
    Khodak, and Hrishikesh Khandeparkar. 2019. A theoretical analysis of contrastive
    unsupervised representation learning. In *International Conference on Machine
    Learning*. PMLR, 5628–5637.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schemmel et al. (2010) Johannes Schemmel, Daniel Briiderle, Andreas Griibl,
    Matthias Hock, Karlheinz Meier, and Sebastian Millner. 2010. A wafer-scale neuromorphic
    hardware system for large-scale neural modeling. In *Proceedings of 2010 IEEE
    International Symposium on Circuits and Systems*. IEEE, 1947–1950.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schuman et al. (2022) Catherine D Schuman, Shruti R Kulkarni, Maryam Parsa,
    J Parker Mitchell, Prasanna Date, and Bill Kay. 2022. Opportunities for neuromorphic
    computing algorithms and applications. *Nature Computational Science* 2, 1 (2022),
    10–19.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sejnowski and Tesauro (1989) Terrence J Sejnowski and Gerald Tesauro. 1989.
    Building network learning algorithms from hebbian synapses. *Brain organization
    and memory: cells, systems, and circuits. Oxford University Press, New York* (1989),
    338–355.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seung and Zung (2017) H Sebastian Seung and Jonathan Zung. 2017. A correlation
    game for unsupervised learning yields computational interpretations of Hebbian
    excitation, anti-Hebbian inhibition, and synapse elimination. *arXiv preprint
    arXiv:1704.00646* (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shin and Park (2011) Yong Shin and Cheong Park. 2011. Analysis of correlation
    based dimension reduction methods. *International Journal of Applied Mathematics
    and Computer Science* 21, 3 (2011), 549–558.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shindou et al. (2019) Tomomi Shindou, Mayumi Shindou, Sakurako Watanabe, and
    Jeffery Wickens. 2019. A silent eligibility trace enables dopamine-dependent synaptic
    plasticity for reinforcement learning in the mouse striatum. *European Journal
    of Neuroscience* 49, 5 (2019), 726–736.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shrestha et al. (2022) Amar Shrestha, Haowen Fang, Zaidao Mei, Daniel Patrick
    Rider, Qing Wu, and Qinru Qiu. 2022. A survey on neuromorphic computing: Models
    and hardware. *IEEE Circuits and Systems Magazine* 22, 2 (2022), 6–35.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Silver et al. (2016) David Silver, Aja Huang, Chris J Maddison, Arthur Guez,
    Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou,
    Veda Panneershelvam, Marc Lanctot, et al. 2016. Mastering the game of Go with
    deep neural networks and tree search. *nature* 529, 7587 (2016), 484.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Song et al. (2000) Sen Song, Kenneth D Miller, and Larry F Abbott. 2000. Competitive
    Hebbian learning through spike-timing-dependent synaptic plasticity. *Nature neuroscience*
    3, 9 (2000), 919.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stefanini et al. (2022) Matteo Stefanini, Marcella Cornia, Lorenzo Baraldi,
    Silvia Cascianelli, Giuseppe Fiameni, and Rita Cucchiara. 2022. From show to tell:
    A survey on deep learning-based image captioning. *IEEE transactions on pattern
    analysis and machine intelligence* 45, 1 (2022), 539–559.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stefanis (2020) Costas Stefanis. 2020. Interneuronal mechanisms in the cortex.
    In *The interneuron*. University of California Press, 497–526.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sugiyama (2006) Masashi Sugiyama. 2006. Local fisher discriminant analysis for
    supervised dimensionality reduction. In *Proceedings of the 23rd international
    conference on Machine learning*. 905–912.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2008) Liang Sun, Shuiwang Ji, and Jieping Ye. 2008. A least squares
    formulation for canonical correlation analysis. In *Proceedings of the 25th international
    conference on Machine learning*. 1024–1031.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2007) Ting-Kai Sun, Song-Can Chen, Zhong Jin, and Jing-Yu Yang.
    2007. Kernelized discriminative canonical correlation analysis. In *2007 International
    Conference on Wavelet Analysis and Pattern Recognition*, Vol. 3\. IEEE, 1283–1287.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy et al. (2013) Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan
    Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties
    of neural networks. *arXiv preprint arXiv:1312.6199* (2013).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tavanaei et al. (2019) Amirhossein Tavanaei, Masoud Ghodrati, Saeed Reza Kheradpisheh,
    Timothée Masquelier, and Anthony Maida. 2019. Deep learning in spiking neural
    networks. *Neural Networks* 111 (2019), 47–63.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tenenbaum et al. (2000) Joshua B Tenenbaum, Vin De Silva, and John C Langford.
    2000. A global geometric framework for nonlinear dimensionality reduction. *science*
    290, 5500 (2000), 2319–2323.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Turrigiano (2012) Gina Turrigiano. 2012. Homeostatic synaptic plasticity: local
    and global mechanisms for stabilizing neuronal function. *Cold Spring Harbor perspectives
    in biology* 4, 1 (2012), a005736.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vasilkoski et al. (2011) Zlatko Vasilkoski, Heather Ames, Ben Chandler, Anatoli
    Gorchetchnikov, Jasmin Léveillé, Gennady Livitz, Ennio Mingolla, and Massimiliano
    Versace. 2011. Review of stability properties of neural plasticity rules for implementation
    on memristive neuromorphic hardware. In *The 2011 International Joint Conference
    on Neural Networks*. IEEE, 2563–2569.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vidnerová and Neruda (2018) Petra Vidnerová and Roman Neruda. 2018. Deep networks
    with rbf layers to prevent adversarial examples. In *Artificial Intelligence and
    Soft Computing: 17th International Conference, ICAISC 2018, Zakopane, Poland,
    June 3-7, 2018, Proceedings, Part I 17*. Springer, 257–266.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wadhwa and Madhow (2016a) Aseem Wadhwa and Upamanyu Madhow. 2016a. Bottom-up
    Deep Learning using the Hebbian Principle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wadhwa and Madhow (2016b) Aseem Wadhwa and Upamanyu Madhow. 2016b. Learning
    Sparse, Distributed Representations using the Hebbian Principle. *arXiv preprint
    arXiv:1611.04228* (2016).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2016) Kaiye Wang, Qiyue Yin, Wei Wang, Shu Wu, and Liang Wang.
    2016. A comprehensive survey on cross-modal retrieval. *arXiv preprint arXiv:1607.06215*
    (2016).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang and Chen (2009) Ruiping Wang and Xilin Chen. 2009. Manifold discriminant
    analysis. In *2009 IEEE Conference on Computer Vision and Pattern Recognition*.
    IEEE, 429–436.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Watanabe et al. (2018) Eiji Watanabe, Akiyoshi Kitaoka, Kiwako Sakamoto, Masaki
    Yasugi, and Kenta Tanaka. 2018. Illusory motion reproduced by deep neural networks
    trained for prediction. *Frontiers in psychology* 9 (2018), 345.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'White and Keller (1989) Edward L White and Asaf Keller. 1989. *Cortical circuits:
    synaptic organization of the cerebral cortex: structure, function, and theory*.
    Springer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wohrer et al. (2013) Adrien Wohrer, Mark D Humphries, and Christian K Machens.
    2013. Population-wide distributions of neural activity during perceptual decision-making.
    *Progress in neurobiology* 103 (2013), 156–193.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2015) Xinyu Wu, Vishal Saxena, Kehan Zhu, and Sakkarapani Balagopal.
    2015. A CMOS Spiking Neuron for Brain-Inspired Neural Networks With Resistive
    Synapses andIn SituLearning. *IEEE Transactions on Circuits and Systems II: Express
    Briefs* 62, 11 (2015), 1088–1092.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xiao et al. (2019) Chang Xiao, Peilin Zhong, and Changxi Zheng. 2019. Enhancing
    adversarial defense by k-winners-take-all. *arXiv preprint arXiv:1905.10510* (2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2015) Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville,
    Ruslan Salakhudinov, Rich Zemel, and Yoshua Bengio. 2015. Show, attend and tell:
    Neural image caption generation with visual attention. In *International conference
    on machine learning*. 2048–2057.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yagishita et al. (2014) Sho Yagishita, Akiko Hayashi-Takagi, Graham CR Ellis-Davies,
    Hidetoshi Urakubo, Shin Ishii, and Haruo Kasai. 2014. A critical time window for
    dopamine actions on the structural plasticity of dendritic spines. *Science* 345,
    6204 (2014), 1616–1620.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2011) Meng Yang, Lei Zhang, Xiangchu Feng, and David Zhang. 2011.
    Fisher discrimination dictionary learning for sparse representation. In *2011
    International Conference on Computer Vision*. IEEE, 543–550.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ye (2007) Jieping Ye. 2007. Least squares linear discriminant analysis. In *Proceedings
    of the 24th international conference on Machine learning*. 1087–1093.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yuan et al. (2019) Xiaoyong Yuan, Pan He, Qile Zhu, and Xiaolin Li. 2019. Adversarial
    examples: Attacks and defenses for deep learning. *IEEE transactions on neural
    networks and learning systems* 30, 9 (2019), 2805–2824.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zadeh et al. (2018) Pourya Habib Zadeh, Reshad Hosseini, and Suvrit Sra. 2018.
    Deep-rbf networks revisited: Robust classification with rejection. *arXiv preprint
    arXiv:1812.03190* (2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2018) Hongyang Zhang, Susu Xu, Jiantao Jiao, Pengtao Xie, Ruslan
    Salakhutdinov, and Eric P Xing. 2018. Stackelberg gan: Towards provable minimax
    equilibrium via multi-generator architectures. *arXiv preprint arXiv:1811.08010*
    (2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2017) Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang
    Wang, Xiaolei Huang, and Dimitris N Metaxas. 2017. Stackgan: Text to photo-realistic
    image synthesis with stacked generative adversarial networks. In *Proceedings
    of the IEEE international conference on computer vision*. 5907–5915.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2008) Wei Zhang, Xiangyang Xue, Zichen Sun, Hong Lu, and Yue-Fei
    Guo. 2008. Metric learning by discriminant neighborhood embedding. *Pattern recognition*
    41, 6 (2008), 2086–2096.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. (2020) Jiadi Zhu, Teng Zhang, Yuchao Yang, and Ru Huang. 2020. A
    comprehensive review on emerging artificial neuromorphic devices. *Applied Physics
    Reviews* 7, 1 (2020), 011312.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhuang et al. (2021) Chengxu Zhuang, Siming Yan, Aran Nayebi, Martin Schrimpf,
    Michael C Frank, James J DiCarlo, and Daniel LK Yamins. 2021. Unsupervised neural
    network models of the ventral visual stream. *Proceedings of the National Academy
    of Sciences* 118, 3 (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
