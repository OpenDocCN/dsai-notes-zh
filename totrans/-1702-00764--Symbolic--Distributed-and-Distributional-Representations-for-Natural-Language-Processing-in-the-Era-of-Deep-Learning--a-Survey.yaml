- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:09:06'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:09:06
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1702.00764] Symbolic, Distributed and Distributional Representations for Natural
    Language Processing in the Era of Deep Learning: a Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1702.00764] 符号、分布式和分布式表示在深度学习时代的自然语言处理中的调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1702.00764](https://ar5iv.labs.arxiv.org/html/1702.00764)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1702.00764](https://ar5iv.labs.arxiv.org/html/1702.00764)
- en: \correspondance\extraAuth
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \correspondance\extraAuth
- en: 'Symbolic, Distributed and Distributional Representations for Natural Language
    Processing in the Era of Deep Learning: a Survey'
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 符号、分布式和分布式表示在深度学习时代的自然语言处理中的调查
- en: Lorenzo Ferrone ¹ and Fabio Massimo Zanzotto ^(1,∗)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 洛伦佐·费罗内¹ 和 法比奥·马西莫·赞佐托^(1,∗)
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: '1'
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '1'
- en: 'Natural language is inherently a discrete symbolic representation of human
    knowledge. Recent advances in machine learning (ML) and in natural language processing
    (NLP) seem to contradict the above intuition: discrete symbols are fading away,
    erased by vectors or tensors called *distributed* and *distributional representations*.
    However, there is a strict link between distributed/distributional representations
    and discrete symbols, being the first an approximation of the second. A clearer
    understanding of the strict link between distributed/distributional representations
    and symbols may certainly lead to radically new deep learning networks. In this
    paper we make a survey that aims to renew the link between symbolic representations
    and distributed/distributional representations. This is the right time to revitalize
    the area of interpreting how discrete symbols are represented inside neural networks.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言本质上是人类知识的离散符号表示。最近在机器学习（ML）和自然语言处理（NLP）方面的进展似乎与上述直觉相矛盾：离散符号正在逐渐消失，被称为*分布式*和*分布式表示*的向量或张量所取代。然而，分布式/分布式表示和离散符号之间存在严格的联系，前者是后者的近似。对分布式/分布式表示和符号之间严格联系的更清晰理解，可能会导致全新深度学习网络的诞生。本文对符号表示和分布式/分布式表示之间的联系进行了综述。现在正是重振解释离散符号如何在神经网络内部表示的领域的最佳时机。
- en: \helveticabold
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: \helveticabold
- en: '2 Keywords:'
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 关键字：
- en: keyword, keyword, keyword, keyword, keyword, keyword, keyword, keyword
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 关键字，关键字，关键字，关键字，关键字，关键字，关键字，关键字
- en: 3 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 引言
- en: Natural language is inherently a discrete symbolic representation of human knowledge.
    Sounds are transformed in letters or ideograms and these discrete symbols are
    composed to obtain words. Words then form sentences and sentences form texts,
    discourses, dialogs, which ultimately convey knowledge, emotions, and so on. This
    composition of symbols in words and of words in sentences follow rules that both
    the hearer and the speaker know (Chomsky, [1957](#bib.bib13)). Hence, thinking
    to natural language understanding systems, which are not based on discrete symbols,
    seems to be extremely odd.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言本质上是人类知识的离散符号表示。声音被转化为字母或表意符号，这些离散符号被组合以形成单词。单词然后组成句子，句子组成文本、演讲、对话，最终传达知识、情感等。这些符号在单词中的组合以及单词在句子中的组合遵循了听者和说话者都知道的规则（乔姆斯基，[1957](#bib.bib13)）。因此，考虑那些不基于离散符号的自然语言理解系统似乎极其奇怪。
- en: 'Recent advances in machine learning (ML) applied to natural language processing
    (NLP) seem to contradict the above intuition: discrete symbols are fading away,
    erased by vectors or tensors called *distributed* and *distributional representations*.
    In ML applied to NLP, *distributed representations* are pushing deep learning
    models (LeCun et al., [2015](#bib.bib44); Schmidhuber, [2015](#bib.bib62)) towards
    amazing results in many high-level tasks such as image generation (Goodfellow
    et al., [2014](#bib.bib29)), image captioning (Vinyals et al., [2015b](#bib.bib73);
    Xu et al., [2015](#bib.bib76)), machine translation (Bahdanau et al., [2014](#bib.bib3);
    Zou et al., [2013](#bib.bib82)), syntactic parsing (Vinyals et al., [2015a](#bib.bib72);
    Weiss et al., [2015](#bib.bib74)) and in a variety of other NLP tasks Devlin et al.
    ([2018](#bib.bib19)). In a more traditional NLP, *distributional representations*
    are pursued as a more flexible way to represent semantics of natural language,
    the so-called *distributional semantics* (see (Turney and Pantel, [2010](#bib.bib68))).
    Words as well as sentences are represented as vectors or tensors of real numbersVectors
    for words are obtained observing how rhese words co-occur with other words in
    document collections. Moreover, as in traditional compositional representations,
    vectors for phrases (Mitchell and Lapata, [2008](#bib.bib50); Baroni and Zamparelli,
    [2010](#bib.bib6); Clark et al., [2008](#bib.bib14); Grefenstette and Sadrzadeh,
    [2011](#bib.bib31); Zanzotto et al., [2010](#bib.bib79)) and sentences (Socher
    et al., [2011](#bib.bib64), [2012](#bib.bib65); Kalchbrenner and Blunsom, [2013](#bib.bib40))
    are obtained by composing vectors for words.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 近期在自然语言处理（NLP）中应用的机器学习（ML）进展似乎与上述直觉相矛盾：离散符号正在消退，被称为*分布式*和*分布表征*的向量或张量所取代。在应用于NLP的ML中，*分布式表征*推动深度学习模型（LeCun等，[2015](#bib.bib44)；Schmidhuber，[2015](#bib.bib62)）在许多高级任务中取得了惊人的结果，如图像生成（Goodfellow等，[2014](#bib.bib29)），图像描述（Vinyals等，[2015b](#bib.bib73)；Xu等，[2015](#bib.bib76)），机器翻译（Bahdanau等，[2014](#bib.bib3)；Zou等，[2013](#bib.bib82)），句法分析（Vinyals等，[2015a](#bib.bib72)；Weiss等，[2015](#bib.bib74)）以及其他各种NLP任务（Devlin等，[2018](#bib.bib19)）。在更传统的NLP中，*分布表征*被视为表示自然语言语义的更灵活方式，即所谓的*分布语义*（见（Turney和Pantel，[2010](#bib.bib68)））。单词和句子都被表示为实数的向量或张量。单词的向量通过观察这些单词在文档集合中与其他单词的共现情况来获得。此外，像传统组合表征一样，短语（Mitchell和Lapata，[2008](#bib.bib50)；Baroni和Zamparelli，[2010](#bib.bib6)；Clark等，[2008](#bib.bib14)；Grefenstette和Sadrzadeh，[2011](#bib.bib31)；Zanzotto等，[2010](#bib.bib79)）和句子的向量（Socher等，[2011](#bib.bib64)，[2012](#bib.bib65)；Kalchbrenner和Blunsom，[2013](#bib.bib40)）是通过组合单词的向量来获得的。
- en: The success of distributed and distributional representations over symbolic
    approaches is mainly due to the advent of new parallel paradigms that pushed neural
    networks (Rosenblatt, [1958](#bib.bib58); Werbos, [1974](#bib.bib75)) towards
    deep learning (LeCun et al., [2015](#bib.bib44); Schmidhuber, [2015](#bib.bib62)).
    Massively parallel algorithms running on Graphic Processing Units (GPUs) (Chetlur
    et al., [2014](#bib.bib12); Cui et al., [2015](#bib.bib16)) crunch vectors, matrices
    and tensors faster than decades ago. The back-propagation algorithm can be now
    computed for complex and large neural networks. Symbols are not needed any more
    during “resoning”, that is, the neural network learning and its application. Hence,
    discrete symbols only survive as inputs and outputs of these wonderful learning
    machines.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式和分布表征在符号方法上的成功主要归因于新并行范式的出现，这推动了神经网络（Rosenblatt，[1958](#bib.bib58)；Werbos，[1974](#bib.bib75)）向深度学习（LeCun等，[2015](#bib.bib44)；Schmidhuber，[2015](#bib.bib62)）的发展。运行在图形处理单元（GPU）（Chetlur等，[2014](#bib.bib12)；Cui等，[2015](#bib.bib16)）上的大规模并行算法比几十年前更快地处理向量、矩阵和张量。现在可以为复杂的大型神经网络计算反向传播算法。在“推理”过程中，即神经网络的学习和应用中，已不再需要符号。因此，离散符号仅作为这些神奇学习机器的输入和输出而存在。
- en: However, there is a strict link between distributed/distributional representations
    and symbols, being the first an approximation of the second (Fodor and Pylyshyn,
    [1988](#bib.bib24); Plate, [1994](#bib.bib56), [1995](#bib.bib57); Ferrone et al.,
    [2015](#bib.bib21)). The representation of the input and the output of these networks
    is not that far from their internal representation. The similarity and the interpretation
    of the internal representation is clearer in image processing (Zeiler and Fergus,
    [2014a](#bib.bib80)). In fact, networks are generally interpreted visualizing
    how subparts represent salient subparts of target images. Both input images and
    subparts are tensors of real number. Hence, these networks can be examined and
    understood. The same does not apply to natural language processing with its discrete
    symbols.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，分布式/分配式表示与符号之间存在严格的联系，第一个是对第二个的近似（Fodor 和 Pylyshyn，[1988](#bib.bib24)；Plate，[1994](#bib.bib56)，[1995](#bib.bib57)；Ferrone
    等，[2015](#bib.bib21)）。这些网络的输入和输出表示与其内部表示并没有太大差别。图像处理中的内部表示的相似性和解释更为清晰（Zeiler 和
    Fergus，[2014a](#bib.bib80)）。事实上，网络通常通过可视化子部分如何代表目标图像的显著子部分来进行解释。输入图像和子部分都是实数张量。因此，这些网络可以被检查和理解。自然语言处理中的离散符号则不适用这种情况。
- en: 'A clearer understanding of the strict link between distributed/distributional
    representations and discrete symbols is needed (Jang et al., [2018](#bib.bib38);
    Jacovi et al., [2018](#bib.bib37)) to understand how neural networks treat information
    and to propose novel deep learning architectures. Model interpretability is becoming
    an important topic in machine learning in general (Lipton, [2016](#bib.bib46)).
    This clearer understanding is then the dawn of a new range of possibilities: understanding
    what part of the current symbolic techniques for natural language processing have
    a sufficient representation in deep neural networks; and, ultimately, understanding
    whether a more brain-like model – the neural networks – is compatible with methods
    for syntactic parsing or semantic processing that have been defined in these decades
    of studies in computational linguistics and natural language processing. There
    is thus a tremendous opportunity to understand whether and how symbolic representations
    are used and emitted in a brain model.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 需要对分布式/分配式表示与离散符号之间的严格联系有更清晰的理解（Jang 等，[2018](#bib.bib38)；Jacovi 等，[2018](#bib.bib37)），以理解神经网络如何处理信息，并提出新的深度学习架构。模型可解释性正成为机器学习中的一个重要话题（Lipton，[2016](#bib.bib46)）。这种更清晰的理解标志着新可能性的曙光：理解当前自然语言处理符号技术的哪些部分在深度神经网络中有足够的表示；以及，*最终*，理解更类似大脑的模型——神经网络——是否与这些几十年来在计算语言学和自然语言处理领域定义的句法解析或语义处理方法兼容。因此，了解符号表示是否以及如何在大脑模型中使用和发射是一个巨大的机会。
- en: In this paper we make a survey that aims to draw the link between symbolic representations
    and distributed/distributional representations. This is the right time to revitalize
    the area of interpreting how symbols are represented inside neural networks. In
    our opinion, this survey will help to devise new deep neural networks that can
    exploit existing and novel symbolic models of classical natural language processing
    tasks.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们进行了一项调查，旨在建立符号表示与分布式/分配式表示之间的联系。现在正是振兴解释符号在神经网络内部如何表示的领域的最佳时机。在我们看来，这项调查将有助于设计能够利用现有和新型符号模型的深度神经网络，用于经典自然语言处理任务。
- en: 'The paper is structured as follow: first we give an introduction to the very
    general concept of representations and the difference between *local* and *distributed*
    representations (Plate, [1995](#bib.bib57)). After that we present each techniques
    in detail. Afterwards, we focus on distributional representations (Turney and
    Pantel, [2010](#bib.bib68)), which we treat as a specific example of a distributed
    representation. Finally we discuss more in depth the general issue of compositionality,
    analyzing three different approaches to the problem: compositional distributional
    semantics (Clark et al., [2008](#bib.bib14); Baroni et al., [2014](#bib.bib4)),
    holographic reduced representations (Plate, [1994](#bib.bib56); Neumann, [2001](#bib.bib53)),
    and recurrent neural networks (Kalchbrenner and Blunsom, [2013](#bib.bib40); Socher
    et al., [2012](#bib.bib65)).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的结构如下：首先，我们介绍表示的非常一般的概念以及 *局部* 和 *分布式* 表示之间的区别（Plate，[1995](#bib.bib57)）。然后我们详细介绍每种技术。接下来，我们重点讨论分布式表示（Turney
    和 Pantel，[2010](#bib.bib68)），我们将其视为分布式表示的一个特例。最后，我们深入讨论组合性的总体问题，分析了三种不同的解决方法：组合分布式语义（Clark
    等，[2008](#bib.bib14)；Baroni 等，[2014](#bib.bib4)），全息减少表示（Plate，[1994](#bib.bib56)；Neumann，[2001](#bib.bib53)），以及递归神经网络（Kalchbrenner
    和 Blunsom，[2013](#bib.bib40)；Socher 等，[2012](#bib.bib65)）。
- en: '4 Symbolic and Distributed Representations: Interpretability and *Concatenative*
    Compositionality'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 符号与分布式表示：可解释性和 *连接* 组合性
- en: '*Distributed representations* put symbolic expressions in metric spaces where
    similarity among examples is used to learn regularities for specific tasks by
    using neural networks or other machine learning models. Given two symbolic expressions,
    their distributed representation should capture their similarity along specific
    features useful for the final task. For example, two sentences such as $s_{1}$=*“a
    mouse eats some cheese”* and $s_{2}$=*“a cat swallows a mouse”* can be considered
    similar in many different ways: (1) number of words in common; (2) realization
    of the pattern “ANIMAL EATS FOOD”. The key point is to decide or to let an algorithm
    decide which is the best representation for a specific task.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*分布式表示* 将符号表达放置在度量空间中，通过使用神经网络或其他机器学习模型，利用示例之间的相似性来学习特定任务的规律。给定两个符号表达，它们的分布式表示应捕捉它们在对最终任务有用的特定特征上的相似性。例如，两个句子如
    $s_{1}$=*“一只老鼠吃了一些奶酪”* 和 $s_{2}$=*“一只猫吞下了一只老鼠”* 可以从许多不同的方面看作是相似的：（1）共有的单词数量；（2）模式
    “动物 吃 食物” 的实现。关键在于决定或让算法决定哪个是特定任务的最佳表示。'
- en: '*Distributed representations* are then replacing long-lasting, successful *discrete
    symbolic representations* in representing knowledge for learning machines but
    these representations are less human *interpretable*. Hence, discussing about
    basic, obvious properties of *discrete symbolic representations* is not useless
    as these properties may guarantee success to distributed representations similar
    to the one of discrete symbolic representations.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*分布式表示* 正在取代长期存在且成功的 *离散符号表示*，用于学习机器的知识表示，但这些表示对人类的 *可解释性* 较差。因此，讨论 *离散符号表示*
    的基本明显属性并非毫无意义，因为这些属性可能会对分布式表示的成功提供保证，类似于离散符号表示。'
- en: Discrete symbolic representations are human *interpretable* as *symbols are
    not altered in expressions*. This is one of the most important, obvious feature
    of these representations. Infinite sets of expressions, which are sequences of
    symbols, can be *interpreted* as these expressions are obtained by concatenating
    a finite set of basic symbols according to some concatenative rules. During concatenation,
    symbols are not altered and, then, can be recognized. By using the principle of
    *semantic compositionality*, the meaning of expressions can be obtained by combining
    the meaning of the parts and, hence, recursively, by combining the meaning of
    the finite set of basic symbols. For example, given the set of basic symbols $\mathcal{D}$
    = {*mouse*,*cat*,*a*,*swallows*,*(*,*)*}, expressions like $s_{1}$=*“a cat swallows
    a mouse”* or $t_{1}$=*((a cat) (swallows (a mouse)))* are totally plausible and
    interpretable given rules for producing natural language utterances or for producing
    tree structured representations in parenthetical form, respectively. This strongly
    depends on the fact that individual symbols can be recognized.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 离散符号表示对人类来说*易于解释*，因为*符号在表达式中未被改变*。这是这些表示的一个最重要、最明显的特征。无限的表达式集合，即符号的序列，可以*被解释*为这些表达式是通过按照某些串联规则将有限的基本符号集合连接而成的。在串联过程中，符号不会被改变，从而可以被识别。利用*语义组合性*原理，可以通过组合部分的意义来获得表达式的意义，从而递归地通过组合有限的基本符号的意义来获得。例如，给定基本符号集$\mathcal{D}$
    = {*mouse*,*cat*,*a*,*swallows*,*(*,*)*}，表达式如$s_{1}$=*“一只猫吞食了一只老鼠”*或$t_{1}$=*((一只猫)
    (吞食 (一只老鼠)))*是完全合理且可解释的，前提是有用于生成自然语言发言或生成括号形式的树结构表示的规则。这强烈依赖于个别符号能够被识别的事实。
- en: 'Distributed representations instead seem to *alter symbols* when applied to
    symbolic inputs and, thus, are less interpretable. In fact, symbols as well as
    expressions are represented as vectors in these metric spaces. Observing distributed
    representations, symbols and expressions do not immediately emerge. Moreover,
    these distributed representations may be transformed by using matrix multiplication
    or by using non-linear functions. Hence, it is generally unclear: (1) what is
    the relation between the initial symbols or expressions and their distributed
    representations and (2) how these expressions are manipulated during matrix multiplication
    or when applying non-linear functions. In other words, it is unclear whether symbols
    can be recognized in distributed representations.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式表示在应用于符号输入时似乎会*改变符号*，因此，这些表示较难解释。事实上，符号以及表达式在这些度量空间中被表示为向量。观察分布式表示时，符号和表达式不会立即显现。此外，这些分布式表示可能通过矩阵乘法或非线性函数被转换。因此，一般来说，以下问题不明确：（1）初始符号或表达式与其分布式表示之间的关系是什么，以及（2）这些表达式在矩阵乘法或应用非线性函数过程中如何被操作。换句话说，尚不清楚符号是否可以在分布式表示中被识别。
- en: Hence, a debated question is whether discrete symbolic representations and distributed
    representations are two very different ways of encoding knowledge because of the
    difference in *alterning symbols*. The debate dates back in the late 80s. For
    Fodor and Pylyshyn ([1988](#bib.bib24)), distributed representations in Neural
    Network architectures are *“only an implementation of the Classical approach”*
    where classical approach is related to discrete symbolic representations. Whereas,
    for Chalmers ([1992](#bib.bib11)), distributed representations give the important
    opportunity to reason *“holistically”* about encoded knowledge. This means that
    decisions over some specific part of the stored knowledge can be taken without
    retrieving the specific part but acting on the whole representation. However,
    this does not solve the debated question as it is still unclear what is in a distributed
    representation.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一个有争议的问题是离散符号表示和分布式表示是否由于*符号的改变*的不同而是两种截然不同的知识编码方式。这场辩论可以追溯到80年代末。对于Fodor和Pylyshyn（[1988](#bib.bib24)），神经网络架构中的分布式表示是*“经典方法的仅仅一种实现”*，而经典方法与离散符号表示相关。相比之下，对于Chalmers（[1992](#bib.bib11)），分布式表示提供了*“整体性”*地推理编码知识的重要机会。这意味着可以在不检索特定部分的情况下对存储知识的某些特定部分做出决定，而是对整个表示进行操作。然而，这并没有解决争议的问题，因为在分布式表示中到底包含了什么仍不清楚。
- en: 'To contribute to the above debated question, Gelder ([1990](#bib.bib27)) has
    formalized the property of *altering symbols in expressions* by defining two different
    notions of compositionality: *concatentative* compositionality and *functional*
    compositionality. *Concatenative compositionality* explains how discrete symbolic
    representations compose symbols to obtain expressions. In fact, the mode of combination
    is an extended concept of juxtaposition that provides a way of linking successive
    symbols without altering them as these form expressions. Concatenative compositionality
    explains discrete symbolic representations no matter the means is used to store
    expressions: a piece of paper or a computer memory. Concatenation is sometime
    expressed with an operator like $\circ$, which can be used in a infix or prefix
    notation, that is a sort of function with arguments $\circ(w_{1},...,w_{n})$.
    By using the operator for concatenation, the two above examples $s_{1}$ and $t_{1}$
    can be represented as the following:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $a\circ cat\circ swallows\circ a\circ mouse$ |  |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
- en: that represents a sequence with the infix notation and
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\circ(\circ(a,cat),\circ(swallows,\circ(a,mouse)))$ |  |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
- en: that represents a tree with the prefix notation. *Functional compositionality*
    explains distributed representations. In functional compositionality, the mode
    of combination is a function $\Phi$ that gives a reliable, general process for
    producing expressions given its constituents. Within this perspective, semantic
    compositionality is a special case of functional compositionality where the target
    of the composition is a way to represent meaning (Blutner et al., [2003](#bib.bib10)).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '*Local distributed representations* (as referred in (Plate, [1995](#bib.bib57)))
    or *one-hot encodings* are the easiest way to visualize how *functional compositionality*
    act on *distributed representations*. Local distributed representations give a
    first, simple encoding of discrete symbolic representations in a metric space.
    Given a set of symbols $\mathcal{D}$, a local distributed epresentation maps the
    $i$-th symbol in $\mathcal{D}$ to the $i$-th base unit vector $\mathbf{e}_{i}$
    in $\mathbb{R}^{n}$, where $n$ is the cardinality of $\mathcal{D}$. Hence, the
    $i$-th unit vector represents the $i$-th symbol. In *functional compositionality*,
    expressions $s=w_{1}\ldots w_{k}$ are represented by vectors $\mathbf{s}$ obtained
    with an eventually recursive function $\Phi$ applied to vectors $\mathbf{e}_{w_{1}}\ldots\mathbf{e}_{w_{k}}$.
    The function $f$ may be very simple as the sum or more complex. In case the function
    $\Phi$ is the sum, that is:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{func}_{\Sigma}(s)=\sum_{j=1}^{k}\mathbf{e}_{w_{j}}$ |  | (1)
    |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
- en: 'the derived vector is the classical bag-of-word vector space model (Salton,
    [1989](#bib.bib61)). Whereas, more complex functions $f$ can range from different
    vector-to-vector operations like circular convolution in Holographic Reduced Representations
    (Plate, [1995](#bib.bib57)) to matrix multiplications plus non linear operations
    in models such as in recurrent neural networks (Schuster and Paliwal, [1997](#bib.bib63);
    Hochreiter and Schmidhuber, [1997](#bib.bib36)) or in neural networks with attention
    (Vaswani et al., [2017](#bib.bib69); Devlin et al., [2018](#bib.bib19)). The above
    example can be useful to describe *concatenative* and *functional* compositionality.
    The set $\mathcal{D}$= {*mouse*,*cat*,*a*,*swallows*,*eats*,*some*,*cheese*,*(*,*)*}
    may be represented with the base vectors $\mathbf{e}_{i}\in\mathbb{R}^{9}$ where
    $\mathbf{e}_{1}$ is the base vector for *mouse*, $\mathbf{e}_{2}$ for *cat*, $\mathbf{e}_{3}$
    for *a*, $\mathbf{e}_{4}$ for *swallaws*, $\mathbf{e}_{5}$ for *eats*, $\mathbf{e}_{6}$
    for *some*, $\mathbf{e}_{7}$ for *cheese*, $\mathbf{e}_{8}$ for *(*, and $\mathbf{e}_{9}$
    for *)*. The additive functional composition of the expression $s_{1}$=*a cat
    swallows a mouse* is then:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 所得到的向量是经典的词袋向量空间模型（Salton, [1989](#bib.bib61)）。而更复杂的函数 $f$ 可以涉及从不同的向量到向量操作，比如全息压缩表示中的循环卷积（Plate,
    [1995](#bib.bib57)），到在如递归神经网络（Schuster 和 Paliwal, [1997](#bib.bib63)；Hochreiter
    和 Schmidhuber, [1997](#bib.bib36)）中的矩阵乘法加非线性操作，或在具有注意力机制的神经网络中（Vaswani 等, [2017](#bib.bib69)；Devlin
    等, [2018](#bib.bib19)）。上述示例可以用于描述 *连接性* 和 *功能性* 组合性。集合 $\mathcal{D}$= {*mouse*,*cat*,*a*,*swallows*,*eats*,*some*,*cheese*,*(*,*)*}
    可以用基向量 $\mathbf{e}_{i}\in\mathbb{R}^{9}$ 表示，其中 $\mathbf{e}_{1}$ 是 *mouse* 的基向量，$\mathbf{e}_{2}$
    是 *cat* 的基向量，$\mathbf{e}_{3}$ 是 *a* 的基向量，$\mathbf{e}_{4}$ 是 *swallows* 的基向量，$\mathbf{e}_{5}$
    是 *eats* 的基向量，$\mathbf{e}_{6}$ 是 *some* 的基向量，$\mathbf{e}_{7}$ 是 *cheese* 的基向量，$\mathbf{e}_{8}$
    是 *(* 的基向量，$\mathbf{e}_{9}$ 是 *)* 的基向量。表达式 $s_{1}$=*a cat swallows a mouse* 的加性功能组合为：
- en: '| *expression in $e_{i}$* | *additive functional composition* |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| *在 $e_{i}$ 中的表达式* | *加性功能组合* |'
- en: '|'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; a &#124; cat &#124; swallows &#124; a &#124; mouse &#124;'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; a &#124; cat &#124; swallows &#124; a &#124; mouse &#124; '
- en: '&#124; <math id="S4.p7.31.2.2.1.1.1.1.m1.1" class="ltx_Math" alttext="\begin{pmatrix}0\\
    0\\'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; <math id="S4.p7.31.2.2.1.1.1.1.m1.1" class="ltx_Math" alttext="\begin{pmatrix}0\\
    0\\'
- en: 1\\
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 1\\
- en: 0\\
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: \end{pmatrix}" display="inline"><semantics id="S4.p7.31.2.2.1.1.1.1.m1.1a"><mrow
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.3" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.2.cmml"><mo
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.3.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.2.1.cmml">(</mo><mtable
    rowspacing="0pt" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1a" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1b" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.1.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.1.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1c" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1d" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.2.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.2.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1e" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1f" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.3.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.3.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1g" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1h" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.4.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.4.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1i" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1j" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.5.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.5.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1k" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1l" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.6.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.6.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1m" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1n" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.7.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.7.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1o" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1p" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.8.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.8.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1q" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1r" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.9.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.9.1.1.cmml">0</mn></mtd></mtr></mtable><mo
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.3.2" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.2.1.cmml">)</mo></mrow><annotation-xml
    encoding="MathML-Content" id="S4.p7.31.2.2.1.1.1.1.m1.1b"><apply id="S4.p7.31.2.2.1.1.1.1.m1.1.1.2.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.3"><csymbol cd="latexml" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.2.1.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.3.1">matrix</csymbol><matrix id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1"><matrixrow id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1a.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.1.1.1.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.1.1.1">0</cn></matrixrow><matrixrow id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1b.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.2.1.1.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.2.1.1">0</cn></matrixrow><matrixrow id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1c.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.3.1.1.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.3.1.1">1</cn></matrixrow><matrixrow id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1d.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.4.1.1.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.4.1.1">0</cn></matrixrow><matrixrow id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1e.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.5.1.1.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.5.1.1">0</cn></matrixrow><matrixrow id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1f.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.6.1.1.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.6.1.1">0</cn></matrixrow><matrixrow id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1g.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.7.1.1.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.7.1.1">0</cn></matrixrow><matrixrow id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1h.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.8.1.1.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.8.1.1">0</cn></matrixrow><matrixrow id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1i.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.9.1.1.cmml"
    xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.9.1.1">0</cn></matrixrow></matrix></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S4.p7.31.2.2.1.1.1.1.m1.1c">\begin{pmatrix}0\\
    0\\ 1\\ 0\\ 0\\ 0\\ 0\\ 0\\ 0\\ \end{pmatrix}</annotation></semantics></math>
    &#124; <math id="S4.p7.32.3.3.2.2.2.2.m1.1" class="ltx_Math" alttext="\begin{pmatrix}0\\
    1\\
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: \end{pmatrix}" display="inline"><semantics id="S4.p7.31.2.2.1.1.1.1.m1.1a"><mrow
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.3" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.2.cmml"><mo
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.3.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.2.1.cmml">(</mo><mtable
    rowspacing="0pt" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1a" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1b" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.1.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.1.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1c" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1d" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.2.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.2.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1e" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1f" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.3.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.3.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1g" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1h" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.4.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.4.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1i" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1j" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.5.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.5.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1k" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1l" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.6.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.6.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1m" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1n" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.7.1.1" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.7.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1o" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1p" xref="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.31.2.2.1.1.1.1.m1.1.1.1.1.8.1.1" xref="S4.p7.31.2.2.1.1.1.
- en: 0\\
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: \end{pmatrix}" display="inline"><semantics id="S4.p7.32.3.3.2.2.2.2.m1.1a"><mrow
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.3" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.2.cmml"><mo
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.3.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.2.1.cmml">(</mo><mtable
    rowspacing="0pt" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1a" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1b" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.1.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.1.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1c" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1d" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.2.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.2.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1e" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1f" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.3.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.3.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1g" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1h" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.4.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.4.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1i" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1j" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.5.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.5.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1k" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1l" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.6.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.6.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1m" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1n" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.7.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.7.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1o" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1p" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.8.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.8.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1q" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1r" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.9.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.9.1.1.cmml">0</mn></mtd></mtr></mtable><mo
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.3.2" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.2.1.cmml">)</mo></mrow><annotation-xml
    encoding="MathML-Content" id="S4.p7.32.3.3.2.2.2.2.m1.1b"><apply id="S4.p7.32.3.3.2.2.2.2.m1.1.1.2.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.3"><csymbol cd="latexml" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.2.1.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.3.1">matrix</csymbol><matrix id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1"><matrixrow id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1a.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1"><cn type="integer" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.1.1.1.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.1.1.1">0</cn></matrixrow><matrixrow id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1b.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1"><cn type="integer" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.2.1.1.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.2.1.1">1</cn></matrixrow><matrixrow id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1c.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1"><cn type="integer" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.3.1.1.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.3.1.1">0</cn></matrixrow><matrixrow id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1d.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1"><cn type="integer" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.4.1.1.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.4.1.1">0</cn></matrixrow><matrixrow id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1e.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1"><cn type="integer" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.5.1.1.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.5.1.1">0</cn></matrixrow><matrixrow id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1f.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1"><cn type="integer" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.6.1.1.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.6.1.1">0</cn></matrixrow><matrixrow id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1g.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1"><cn type="integer" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.7.1.1.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.7.1.1">0</cn></matrixrow><matrixrow id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1h.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1"><cn type="integer" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.8.1.1.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.8.1.1">0</cn></matrixrow><matrixrow id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1i.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1"><cn type="integer" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.9.1.1.cmml"
    xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.9.1.1">0</cn></matrixrow></matrix></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S4.p7.32.3.3.2.2.2.2.m1.1c">\begin{pmatrix}0\\
    1\\ 0\\ 0\\ 0\\ 0\\ 0\\ 0\\ 0\\ \end{pmatrix}</annotation></semantics></math>
    &#124; <math id="S4.p7.33.4.4.3.3.3.3.m1.1" class="ltx_Math" alttext="\begin{pmatrix}0\\
    0\\
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: \end{pmatrix}" display="inline"><semantics id="S4.p7.32.3.3.2.2.2.2.m1.1a"><mrow
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.3" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.2.cmml"><mo
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.3.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.2.1.cmml">(</mo><mtable
    rowspacing="0pt" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1a" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1b" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.1.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.1.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1c" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1d" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.2.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.2.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1e" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1f" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.3.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.3.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1g" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1h" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.4.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.4.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1i" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1j" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.5.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.5.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1k" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1l" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.6.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.6.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1m" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1n" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.7.1.1" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.7.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1o" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1p" xref="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.32.3.3.2.2.2.2.m1.1.1.1.1.8.1.1" xref="S4.p7.32.3.3.2.2.2.
- en: 0\\
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 1\\
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 1\\
- en: 0\\
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: \end{pmatrix}" display="inline"><semantics id="S4.p7.33.4.4.3.3.3.3.m1.1a"><mrow
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.3" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.2.cmml"><mo
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.3.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.2.1.cmml">(</mo><mtable
    rowspacing="0pt" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1a" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1b" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.1.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.1.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1c" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1d" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.2.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.2.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1e" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1f" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.3.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.3.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1g" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1h" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.4.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.4.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1i" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1j" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.5.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.5.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1k" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1l" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.6.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.6.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1m" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1n" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.7.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.7.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1o" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1p" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.8.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.8.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1q" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1r" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.9.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.9.1.1.cmml">0</mn></mtd></mtr></mtable><mo
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.3.2" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.2.1.cmml">)</mo></mrow><annotation-xml
    encoding="MathML-Content" id="S4.p7.33.4.4.3.3.3.3.m1.1b"><apply id="S4.p7.33.4.4.3.3.3.3.m1.1.1.2.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.3"><csymbol cd="latexml" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.2.1.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.3.1">matrix</csymbol><matrix id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1"><matrixrow id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1a.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1"><cn type="integer" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.1.1.1.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.1.1.1">0</cn></matrixrow><matrixrow id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1b.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1"><cn type="integer" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.2.1.1.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.2.1.1">0</cn></matrixrow><matrixrow id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1c.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1"><cn type="integer" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.3.1.1.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.3.1.1">0</cn></matrixrow><matrixrow id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1d.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1"><cn type="integer" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.4.1.1.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.4.1.1">1</cn></matrixrow><matrixrow id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1e.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1"><cn type="integer" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.5.1.1.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.5.1.1">0</cn></matrixrow><matrixrow id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1f.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1"><cn type="integer" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.6.1.1.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.6.1.1">0</cn></matrixrow><matrixrow id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1g.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1"><cn type="integer" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.7.1.1.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.7.1.1">0</cn></matrixrow><matrixrow id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1h.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1"><cn type="integer" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.8.1.1.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.8.1.1">0</cn></matrixrow><matrixrow id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1i.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1"><cn type="integer" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.9.1.1.cmml"
    xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.9.1.1">0</cn></matrixrow></matrix></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S4.p7.33.4.4.3.3.3.3.m1.1c">\begin{pmatrix}0\\
    0\\ 0\\ 1\\ 0\\ 0\\ 0\\ 0\\ 0\\ \end{pmatrix}</annotation></semantics></math>
    &#124; <math id="S4.p7.34.5.5.4.4.4.4.m1.1" class="ltx_Math" alttext="\begin{pmatrix}0\\
    0\\
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: \end{pmatrix}" display="inline"><semantics id="S4.p7.33.4.4.3.3.3.3.m1.1a"><mrow
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.3" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.2.cmml"><mo
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.3.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.2.1.cmml">(</mo><mtable
    rowspacing="0pt" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1a" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1b" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.1.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.1.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1c" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1d" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.2.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.2.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1e" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1f" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.3.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.3.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1g" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1h" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.4.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.4.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1i" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1j" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.5.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.5.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1k" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1l" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.6.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.6.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1m" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1n" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.7.1.1" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.7.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1o" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1p" xref="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.33.4.4.3.3.3.3.m1.1.1.1.1.8.1.1" xref="S4.p7.33.4.4.3.3.3.
- en: 1\\
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 1\\
- en: 0\\
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: \end{pmatrix}" display="inline"><semantics id="S4.p7.34.5.5.4.4.4.4.m1.1a"><mrow
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.3" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.2.cmml"><mo
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.3.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.2.1.cmml">(</mo><mtable
    rowspacing="0pt" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1a" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1b" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.1.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.1.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1c" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1d" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.2.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.2.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1e" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1f" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.3.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.3.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1g" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1h" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.4.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.4.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1i" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1j" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.5.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.5.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1k" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1l" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.6.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.6.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1m" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1n" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.7.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.7.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1o" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1p" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.8.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.8.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1q" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1r" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.9.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.9.1.1.cmml">0</mn></mtd></mtr></mtable><mo
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.3.2" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.2.1.cmml">)</mo></mrow><annotation-xml
    encoding="MathML-Content" id="S4.p7.34.5.5.4.4.4.4.m1.1b"><apply id="S4.p7.34.5.5.4.4.4.4.m1.1.1.2.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.3"><csymbol cd="latexml" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.2.1.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.3.1">matrix</csymbol><matrix id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1"><matrixrow id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1a.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1"><cn type="integer" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.1.1.1.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.1.1.1">0</cn></matrixrow><matrixrow id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1b.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1"><cn type="integer" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.2.1.1.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.2.1.1">0</cn></matrixrow><matrixrow id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1c.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1"><cn type="integer" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.3.1.1.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.3.1.1">1</cn></matrixrow><matrixrow id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1d.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1"><cn type="integer" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.4.1.1.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.4.1.1">0</cn></matrixrow><matrixrow id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1e.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1"><cn type="integer" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.5.1.1.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.5.1.1">0</cn></matrixrow><matrixrow id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1f.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1"><cn type="integer" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.6.1.1.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.6.1.1">0</cn></matrixrow><matrixrow id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1g.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1"><cn type="integer" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.7.1.1.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.7.1.1">0</cn></matrixrow><matrixrow id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1h.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1"><cn type="integer" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.8.1.1.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.8.1.1">0</cn></matrixrow><matrixrow id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1i.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1"><cn type="integer" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.9.1.1.cmml"
    xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.9.1.1">0</cn></matrixrow></matrix></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S4.p7.34.5.5.4.4.4.4.m1.1c">\begin{pmatrix}0\\
    0\\ 1\\ 0\\ 0\\ 0\\ 0\\ 0\\ 0\\ \end{pmatrix}</annotation></semantics></math>
    &#124; <math id="S4.p7.35.6.6.5.5.5.5.m1.1" class="ltx_Math" alttext="\begin{pmatrix}1\\
    0\\
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: \end{pmatrix}" display="inline"><semantics id="S4.p7.34.5.5.4.4.4.4.m1.1a"><mrow
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.3" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.2.cmml"><mo
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.3.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.2.1.cmml">(</mo><mtable
    rowspacing="0pt" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1a" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1b" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.1.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.1.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1c" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1d" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.2.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.2.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1e" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1f" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.3.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.3.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1g" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1h" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.4.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.4.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1i" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1j" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.5.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.5.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1k" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1l" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.6.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.6.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1m" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1n" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.7.1.1" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.7.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1o" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1p" xref="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.34.5.5.4.4.4.4.m1.1.1.1.1.8.1.1" xref="S4.p7.34.5.5.4.4.4.
- en: 0\\
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: \end{pmatrix}" display="inline"><semantics id="S4.p7.35.6.6.5.5.5.5.m1.1a"><mrow
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.3" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.2.cmml"><mo
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.3.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.2.1.cmml">(</mo><mtable
    rowspacing="0pt" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1a" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1b" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.1.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.1.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1c" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1d" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.2.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.2.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1e" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1f" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.3.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.3.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1g" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1h" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.4.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.4.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1i" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1j" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.5.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.5.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1k" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1l" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.6.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.6.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1m" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1n" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.7.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.7.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1o" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1p" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.8.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.8.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1q" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1r" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.9.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.9.1.1.cmml">0</mn></mtd></mtr></mtable><mo
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.3.2" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.2.1.cmml">)</mo></mrow><annotation-xml
    encoding="MathML-Content" id="S4.p7.35.6.6.5.5.5.5.m1.1b"><apply id="S4.p7.35.6.6.5.5.5.5.m1.1.1.2.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.3"><csymbol cd="latexml" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.2.1.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.3.1">matrix</csymbol><matrix id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1"><matrixrow id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1a.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1"><cn type="integer" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.1.1.1.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.1.1.1">1</cn></matrixrow><matrixrow id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1b.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1"><cn type="integer" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.2.1.1.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.2.1.1">0</cn></matrixrow><matrixrow id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1c.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1"><cn type="integer" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.3.1.1.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.3.1.1">0</cn></matrixrow><matrixrow id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1d.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1"><cn type="integer" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.4.1.1.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.4.1.1">0</cn></matrixrow><matrixrow id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1e.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1"><cn type="integer" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.5.1.1.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.5.1.1">0</cn></matrixrow><matrixrow id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1f.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1"><cn type="integer" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.6.1.1.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.6.1.1">0</cn></matrixrow><matrixrow id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1g.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1"><cn type="integer" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.7.1.1.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.7.1.1">0</cn></matrixrow><matrixrow id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1h.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1"><cn type="integer" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.8.1.1.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.8.1.1">0</cn></matrixrow><matrixrow id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1i.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1"><cn type="integer" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.9.1.1.cmml"
    xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.9.1.1">0</cn></matrixrow></matrix></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S4.p7.35.6.6.5.5.5.5.m1.1c">\begin{pmatrix}1\\
    0\\ 0\\ 0\\ 0\\ 0\\ 0\\ 0\\ 0\\ \end{pmatrix}</annotation></semantics></math>
    &#124;
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: \end{pmatrix}" display="inline"><semantics id="S4.p7.35.6.6.5.5.5.5.m1.1a"><mrow
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.3" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.2.cmml"><mo
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.3.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.2.1.cmml">(</mo><mtable
    rowspacing="0pt" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1a" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1b" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.1.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.1.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1c" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1d" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.2.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.2.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1e" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1f" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.3.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.3.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1g" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1h" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.4.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.4.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1i" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1j" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.5.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.5.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1k" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1l" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.6.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.6.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1m" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1n" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.7.1.1" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.7.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1o" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1p" xref="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.35.6.6.5.5.5.5.m1.1.1.1.1.8.1.1" xref="S4.p7.35.6.6.5.5.5.
- en: '|'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; $\mathbf{e_{3}}+\mathbf{e_{2}}+\mathbf{e_{4}}+\mathbf{e_{3}}+\mathbf{e_{1}}$
    &#124;'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; $\mathbf{e_{3}}+\mathbf{e_{2}}+\mathbf{e_{4}}+\mathbf{e_{3}}+\mathbf{e_{1}}$
    &#124;'
- en: '&#124; <math id="S4.p7.37.8.8.7.2.2.1.m1.2" class="ltx_Math" alttext="\mathbf{func_{\Sigma}(s_{1})}=\begin{pmatrix}1\\
    1\\'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; <math id="S4.p7.37.8.8.7.2.2.1.m1.2" class="ltx_Math" alttext="\mathbf{func_{\Sigma}(s_{1})}=\begin{pmatrix}1\\
    1\\'
- en: 2\\
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 2\\
- en: 1\\
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 1\\
- en: 0\\
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\\
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 0\\
- en: 0\end{pmatrix}" display="inline"><semantics id="S4.p7.37.8.8.7.2.2.1.m1.2a"><mrow
    id="S4.p7.37.8.8.7.2.2.1.m1.2.2" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.cmml"><mrow
    id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.cmml"><msub
    id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3.cmml"><mi
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3.2" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3.2.cmml">𝐟𝐮𝐧𝐜</mi><mi
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3.3" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3.3.cmml">𝚺</mi></msub><mo
    lspace="0em" rspace="0em" id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.2" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.2.cmml">​</mo><mrow
    id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.cmml"><mo
    maxsize="50%" minsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.2" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.cmml">(</mo><msub
    id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.cmml"><mi
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.2" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.2.cmml">𝐬</mi><mn
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.3" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.3.cmml">𝟏</mn></msub><mo
    maxsize="50%" minsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.3" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.2.2.2" xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.2.cmml">=</mo><mrow
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.3" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.2.cmml"><mo
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.3.1" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.2.1.cmml">(</mo><mtable
    rowspacing="0pt" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mtr
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1a" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1b" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.1.1.1" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.1.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1c" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1d" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.2.1.1" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.2.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1e" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1f" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.3.1.1" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.3.1.1.cmml">2</mn></mtd></mtr><mtr
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1g" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1h" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.4.1.1" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.4.1.1.cmml">1</mn></mtd></mtr><mtr
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1i" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1j" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.5.1.1" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.5.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1k" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1l" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.6.1.1" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.6.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1m" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1n" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.7.1.1" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.7.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1o" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1p" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.8.1.1" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.8.1.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1q" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mtd
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1r" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"><mn
    mathsize="50%" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.9.1.1" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.9.1.1.cmml">0</mn></mtd></mtr></mtable><mo
    id="S4.p7.37.8.8.7.2.2.1.m1.1.1.3.2" xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.2.1.cmml">)</mo></mrow></mrow><annotation-xml
    encoding="MathML-Content" id="S4.p7.37.8.8.7.2.2.1.m1.2b"><apply id="S4.p7.37.8.8.7.2.2.1.m1.2.2.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.2.2"><apply id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1"><apply id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3"><csymbol cd="ambiguous" id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3">subscript</csymbol><ci id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3.2.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3.2">𝐟𝐮𝐧𝐜</ci><ci id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3.3.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.3.3">𝚺</ci></apply><apply id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.2.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.2">𝐬</ci><cn type="integer" id="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.3.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.2.2.1.1.1.1.3">1</cn></apply></apply><apply id="S4.p7.37.8.8.7.2.2.1.m1.1.1.2.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.3"><csymbol cd="latexml" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.2.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.3.1">matrix</csymbol><matrix id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1"><matrixrow id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1a.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.1.1.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.1.1.1">1</cn></matrixrow><matrixrow id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1b.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.2.1.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.2.1.1">1</cn></matrixrow><matrixrow id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1c.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.3.1.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.3.1.1">2</cn></matrixrow><matrixrow id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1d.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.4.1.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.4.1.1">1</cn></matrixrow><matrixrow id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1e.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.5.1.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.5.1.1">0</cn></matrixrow><matrixrow id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1f.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.6.1.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.6.1.1">0</cn></matrixrow><matrixrow id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1g.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.7.1.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.7.1.1">0</cn></matrixrow><matrixrow id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1h.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.8.1.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.8.1.1">0</cn></matrixrow><matrixrow id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1i.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1"><cn type="integer" id="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.9.1.1.cmml"
    xref="S4.p7.37.8.8.7.2.2.1.m1.1.1.1.1.9.1.1">0</cn></matrixrow></matrix></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S4.p7.37.8.8.7.2.2.1.m1.2c">\mathbf{func_{\Sigma}(s_{1})}=\begin{pmatrix}1\\
    1\\ 2\\ 1\\ 0\\ 0\\ 0\\ 0\\ 0\end{pmatrix}</annotation></semantics></math> &#124;
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: where the concatenative operator $\circ$ has been substituted with the sum $+$.
    Just to observe, in the additive functional composition $\mathbf{func_{\Sigma}(s_{1})}$,
    symbols are still visible but the sequence is lost. Hence, it is difficult to
    reproduce the initial discrete symbolic expression. However, for example, the
    additive composition function gives the possibility to compare two expressions.
    Given the expression $s_{1}$ and $s_{2}$=*a mouse eats some cheese*, the dot product
    between $\mathbf{func_{\Sigma}(s_{1})}$ and $\mathbf{func_{\Sigma}(s_{2})}=\begin{pmatrix}1&amp;0&amp;1&amp;0&amp;1&amp;1&amp;1&amp;0&amp;0\end{pmatrix}^{T}$
    counts the common words between the two expressions. In a functional composition
    with a function $\Phi$, the expression $s_{1}$ may become $\mathbf{func_{\Phi}(s_{1})}=\Phi(\Phi(\Phi(\Phi(\mathbf{e_{3}},\mathbf{e_{2}}),\mathbf{e_{4}}),\mathbf{e_{3}}),\mathbf{e_{1}})$
    by following the concatenative compositionality of the discrete symbolic expression.
    The same functional compositional principle can be applied to discrete symbolic
    trees as $t_{1}$ by producing this distributed representation $\Phi(\Phi(\mathbf{e_{3}},\mathbf{e_{2}}),\Phi(\mathbf{e_{4}},\Phi(\mathbf{e_{3}},\mathbf{e_{1}})))$.
    Finally, in the functional composition with a generic recursive function $\mathbf{func_{\Phi}(s_{1})}$,
    the function $\Phi$ will be crucial to determine whether symbols can be recognized
    and sequence is preserved.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 其中连接操作符 $\circ$ 被加法 $+$ 替代。值得注意的是，在加法功能组合 $\mathbf{func_{\Sigma}(s_{1})}$ 中，符号仍然可见但序列丢失。因此，重现初始的离散符号表达式变得困难。然而，例如，加法组合函数提供了比较两个表达式的可能性。给定表达式
    $s_{1}$ 和 $s_{2}$=*一只老鼠吃了一些奶酪*，$\mathbf{func_{\Sigma}(s_{1})}$ 和 $\mathbf{func_{\Sigma}(s_{2})}=\begin{pmatrix}1&amp;0&amp;1&amp;0&amp;1&amp;1&amp;1&amp;0&amp;0\end{pmatrix}^{T}$
    之间的点积计算了两个表达式之间的共同单词。在带有函数 $\Phi$ 的功能组合中，表达式 $s_{1}$ 可能会变成 $\mathbf{func_{\Phi}(s_{1})}=\Phi(\Phi(\Phi(\Phi(\mathbf{e_{3}},\mathbf{e_{2}}),\mathbf{e_{4}}),\mathbf{e_{3}}),\mathbf{e_{1}})$，这是通过遵循离散符号表达式的连接性组合原理实现的。相同的功能组合原理可以应用于离散符号树，如
    $t_{1}$，通过生成这个分布式表示 $\Phi(\Phi(\mathbf{e_{3}},\mathbf{e_{2}}),\Phi(\mathbf{e_{4}},\Phi(\mathbf{e_{3}},\mathbf{e_{1}})))$。最后，在带有通用递归函数
    $\mathbf{func_{\Phi}(s_{1})}$ 的功能组合中，函数 $\Phi$ 将对确定符号是否可以被识别以及序列是否得以保留至关重要。
- en: '*Distributed representations* in their general form are more ambitious than
    distributed *local* representations and tend to encode basic symbols of $\mathcal{D}$
    in vectors in $\mathbb{R}^{d}$ where $d<<n$. These vectors generally alter symbols
    as there is not a direct link between symbols and dimensions of the space. Given
    a distributed local representation $\mathbf{e}_{w}$ of a symbol $w$, the encoder
    for a distributed representation is a matrix $\mathbf{W_{d\times n}}$ that transforms
    $\mathbf{x}_{w}$ in $\mathbf{y}_{w}=\mathbf{W_{d\times n}}\mathbf{e}_{w}$. As
    an example, the encoding matrix $\mathbf{W_{d\times n}}$ can be build by modeling
    words in $\mathcal{D}$ around three dimensions: number of vowels, number of consonants
    and, finally, number of non-alphabetic symbols. Given these dimensions, the matrix
    $\mathbf{W_{3\times 9}}$ for the example is :'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*分布式表示* 在其一般形式上比分布式*局部*表示更具雄心，往往将 $\mathcal{D}$ 的基本符号编码在 $\mathbb{R}^{d}$ 中的向量中，其中
    $d<<n$。这些向量通常会改变符号，因为符号与空间维度之间没有直接的联系。给定符号 $w$ 的分布式局部表示 $\mathbf{e}_{w}$，分布式表示的编码器是一个矩阵
    $\mathbf{W_{d\times n}}$，它将 $\mathbf{x}_{w}$ 转换为 $\mathbf{y}_{w}=\mathbf{W_{d\times
    n}}\mathbf{e}_{w}$。例如，编码矩阵 $\mathbf{W_{d\times n}}$ 可以通过在三个维度上建模 $\mathcal{D}$
    中的单词来构建：元音数、辅音数，最后是非字母符号数。给定这些维度，示例中的矩阵 $\mathbf{W_{3\times 9}}$ 为：'
- en: '|  | <math id="S4.Ex3.m1.1" class="ltx_Math" alttext="\mathbf{W_{3\times 9}}=\begin{pmatrix}3&amp;1&amp;1&amp;2&amp;2&amp;2&amp;3&amp;0&amp;0\\
    2&amp;2&amp;0&amp;6&amp;2&amp;2&amp;3&amp;0&amp;0\\'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math id="S4.Ex3.m1.1" class="ltx_Math" alttext="\mathbf{W_{3\times 9}}=\begin{pmatrix}3&amp;1&amp;1&amp;2&amp;2&amp;2&amp;3&amp;0&amp;0\\
    2&amp;2&amp;0&amp;6&amp;2&amp;2&amp;3&amp;0&amp;0\\'
- en: 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;1\\
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;1\\
- en: \end{pmatrix}" display="block"><semantics id="S4.Ex3.m1.1a"><mrow id="S4.Ex3.m1.1.2"
    xref="S4.Ex3.m1.1.2.cmml"><msub id="S4.Ex3.m1.1.2.2" xref="S4.Ex3.m1.1.2.2.cmml"><mi
    id="S4.Ex3.m1.1.2.2.2" xref="S4.Ex3.m1.1.2.2.2.cmml">𝐖</mi><mrow id="S4.Ex3.m1.1.2.2.3"
    xref="S4.Ex3.m1.1.2.2.3.cmml"><mn id="S4.Ex3.m1.1.2.2.3.2" xref="S4.Ex3.m1.1.2.2.3.2.cmml">𝟑</mn><mo
    lspace="0.222em" rspace="0.222em" id="S4.Ex3.m1.1.2.2.3.1" xref="S4.Ex3.m1.1.2.2.3.1.cmml">×</mo><mn
    id="S4.Ex3.m1.1.2.2.3.3" xref="S4.Ex3.m1.1.2.2.3.3.cmml">𝟗</mn></mrow></msub><mo
    id="S4.Ex3.m1.1.2.1" xref="S4.Ex3.m1.1.2.1.cmml">=</mo><mrow id="S4.Ex3.m1.1.1.3"
    xref="S4.Ex3.m1.1.1.2.cmml"><mo id="S4.Ex3.m1.1.1.3.1" xref="S4.Ex3.m1.1.1.2.1.cmml">(</mo><mtable
    columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S4.Ex3.m1.1.1.1.1"
    xref="S4.Ex3.m1.1.1.1.1.cmml"><mtr id="S4.Ex3.m1.1.1.1.1a" xref="S4.Ex3.m1.1.1.1.1.cmml"><mtd
    id="S4.Ex3.m1.1.1.1.1b" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.1.1.1"
    xref="S4.Ex3.m1.1.1.1.1.1.1.1.cmml">3</mn></mtd><mtd id="S4.Ex3.m1.1.1.1.1c" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn
    id="S4.Ex3.m1.1.1.1.1.1.2.1" xref="S4.Ex3.m1.1.1.1.1.1.2.1.cmml">1</mn></mtd><mtd
    id="S4.Ex3.m1.1.1.1.1d" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.1.3.1"
    xref="S4.Ex3.m1.1.1.1.1.1.3.1.cmml">1</mn></mtd><mtd id="S4.Ex3.m1.1.1.1.1e" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn
    id="S4.Ex3.m1.1.1.1.1.1.4.1" xref="S4.Ex3.m1.1.1.1.1.1.4.1.cmml">2</mn></mtd><mtd
    id="S4.Ex3.m1.1.1.1.1f" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.1.5.1"
    xref="S4.Ex3.m1.1.1.1.1.1.5.1.cmml">2</mn></mtd><mtd id="S4.Ex3.m1.1.1.1.1g" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn
    id="S4.Ex3.m1.1.1.1.1.1.6.1" xref="S4.Ex3.m1.1.1.1.1.1.6.1.cmml">2</mn></mtd><mtd
    id="S4.Ex3.m1.1.1.1.1h" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.1.7.1"
    xref="S4.Ex3.m1.1.1.1.1.1.7.1.cmml">3</mn></mtd><mtd id="S4.Ex3.m1.1.1.1.1i" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn
    id="S4.Ex3.m1.1.1.1.1.1.8.1" xref="S4.Ex3.m1.1.1.1.1.1.8.1.cmml">0</mn></mtd><mtd
    id="S4.Ex3.m1.1.1.1.1j" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.1.9.1"
    xref="S4.Ex3.m1.1.1.1.1.1.9.1.cmml">0</mn></mtd></mtr><mtr id="S4.Ex3.m1.1.1.1.1k"
    xref="S4.Ex3.m1.1.1.1.1.cmml"><mtd id="S4.Ex3.m1.1.1.1.1l" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn
    id="S4.Ex3.m1.1.1.1.1.2.1.1" xref="S4.Ex3.m1.1.1.1.1.2.1.1.cmml">2</mn></mtd><mtd
    id="S4.Ex3.m1.1.1.1.1m" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.2.2.1"
    xref="S4.Ex3.m1.1.1.1.1.2.2.1.cmml">2</mn></mtd><mtd id="S4.Ex3.m1.1.1.1.1n" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn
    id="S4.Ex3.m1.1.1.1.1.2.3.1" xref="S4.Ex3.m1.1.1.1.1.2.3.1.cmml">0</mn></mtd><mtd
    id="S4.Ex3.m1.1.1.1.1o" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.2.4.1"
    xref="S4.Ex3.m1.1.1.1.1.2.4.1.cmml">6</mn></mtd><mtd id="S4.Ex3.m1.1.1.1.1p" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn
    id="S4.Ex3.m1.1.1.1.1.2.5.1" xref="S4.Ex3.m1.1.1.1.1.2.5.1.cmml">2</mn></mtd><mtd
    id="S4.Ex3.m1.1.1.1.1q" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.2.6.1"
    xref="S4.Ex3.m1.1.1.1.1.2.6.1.cmml">2</mn></mtd><mtd id="S4.Ex3.m1.1.1.1.1r" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn
    id="S4.Ex3.m1.1.1.1.1.2.7.1" xref="S4.Ex3.m1.1.1.1.1.2.7.1.cmml">3</mn></mtd><mtd
    id="S4.Ex3.m1.1.1.1.1s" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.2.8.1"
    xref="S4.Ex3.m1.1.1.1.1.2.8.1.cmml">0</mn></mtd><mtd id="S4.Ex3.m1.1.1.1.1t" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn
    id="S4.Ex3.m1.1.1.1.1.2.9.1" xref="S4.Ex3.m1.1.1.1.1.2.9.1.cmml">0</mn></mtd></mtr><mtr
    id="S4.Ex3.m1.1.1.1.1u" xref="S4.Ex3.m1.1.1.1.1.cmml"><mtd id="S4.Ex3.m1.1.1.1.1v"
    xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.3.1.1" xref="S4.Ex3.m1.1.1.1.1.3.1.1.cmml">0</mn></mtd><mtd
    id="S4.Ex3.m1.1.1.1.1w" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.3.2.1"
    xref="S4.Ex3.m1.1.1.1.1.3.2.1.cmml">0</mn></mtd><mtd id="S4.Ex3.m1.1.1.1.1x" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn
    id="S4.Ex3.m1.1.1.1.1.3.3.1" xref="S4.Ex3.m1.1.1.1.1.3.3.1.cmml">0</mn></mtd><mtd
    id="S4.Ex3.m1.1.1.1.1y" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.3.4.1"
    xref="S4.Ex3.m1.1.1.1.1.3.4.1.cmml">0</mn></mtd><mtd id="S4.Ex3.m1.1.1.1.1z" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn
    id="S4.Ex3.m1.1.1.1.1.3.5.1" xref="S4.Ex3.m1.1.1.1.1.3.5.1.cmml">0</mn></mtd><mtd
    id="S4.Ex3.m1.1.1.1.1aa" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.3.6.1"
    xref="S4.Ex3.m1.1.1.1.1.3.6.1.cmml">0</mn></mtd><mtd id="S4.Ex3.m1.1.1.1.1ab"
    xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.3.7.1" xref="S4.Ex3.m1.1.1.1.1.3.7.1.cmml">0</mn></mtd><mtd
    id="S4.Ex3.m1.1.1.1.1ac" xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.3.8.1"
    xref="S4.Ex3.m1.1.1.1.1.3.8.1.cmml">1</mn></mtd><mtd id="S4.Ex3.m1.1.1.1.1ad"
    xref="S4.Ex3.m1.1.1.1.1.cmml"><mn id="S4.Ex3.m1.1.1.1.1.3.9.1" xref="S4.Ex3.m1.1.1.1.1.3.9.1.cmml">1</mn></mtd></mtr></mtable><mo
    id="S4.Ex3.m1.1.1.3.2" xref="S4.Ex3.m1.1.1.2.1.cmml">)</mo></mrow></mrow><annotation-xml
    encoding="MathML-Content" id="S4.Ex3.m1.1b"><apply id="S4.Ex3.m1.1.2.cmml" xref="S4.Ex3.m1.1.2"><apply
    id="S4.Ex3.m1.1.2.2.cmml" xref="S4.Ex3.m1.1.2.2"><csymbol cd="ambiguous" id="S4.Ex3.m1.1.2.2.1.cmml"
    xref="S4.Ex3.m1.1.2.2">subscript</csymbol><ci id="S4.Ex3.m1.1.2.2.2.cmml" xref="S4.Ex3.m1.1.2.2.2">𝐖</ci><apply
    id="S4.Ex3.m1.1.2.2.3.cmml" xref="S4.Ex3.m1.1.2.2.3"><cn type="integer" id="S4.Ex3.m1.1.2.2.3.2.cmml"
    xref="S4.Ex3.m1.1.2.2.3.2">3</cn><cn type="integer" id="S4.Ex3.m1.1.2.2.3.3.cmml"
    xref="S4.Ex3.m1.1.2.2.3.3">9</cn></apply></apply><apply id="S4.Ex3.m1.1.1.2.cmml"
    xref="S4.Ex3.m1.1.1.3"><csymbol cd="latexml" id="S4.Ex3.m1.1.1.2.1.cmml" xref="S4.Ex3.m1.1.1.3.1">matrix</csymbol><matrix
    id="S4.Ex3.m1.1.1.1.1.cmml" xref="S4.Ex3.m1.1.1.1.1"><matrixrow id="S4.Ex3.m1.1.1.1.1a.cmml"
    xref="S4.Ex3.m1.1.1.1.1"><cn type="integer" id="S4.Ex3.m1.1.1.1.1.1.1.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.1.1.1">3</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.1.2.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.1.2.1">1</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.1.3.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.1.3.1">1</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.1.4.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.1.4.1">2</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.1.5.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.1.5.1">2</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.1.6.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.1.6.1">2</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.1.7.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.1.7.1">3</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.1.8.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.1.8.1">0</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.1.9.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.1.9.1">0</cn></matrixrow><matrixrow id="S4.Ex3.m1.1.1.1.1b.cmml"
    xref="S4.Ex3.m1.1.1.1.1"><cn type="integer" id="S4.Ex3.m1.1.1.1.1.2.1.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.2.1.1">2</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.2.2.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.2.2.1">2</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.2.3.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.2.3.1">0</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.2.4.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.2.4.1">6</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.2.5.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.2.5.1">2</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.2.6.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.2.6.1">2</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.2.7.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.2.7.1">3</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.2.8.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.2.8.1">0</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.2.9.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.2.9.1">0</cn></matrixrow><matrixrow id="S4.Ex3.m1.1.1.1.1c.cmml"
    xref="S4.Ex3.m1.1.1.1.1"><cn type="integer" id="S4.Ex3.m1.1.1.1.1.3.1.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.3.1.1">0</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.3.2.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.3.2.1">0</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.3.3.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.3.3.1">0</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.3.4.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.3.4.1">0</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.3.5.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.3.5.1">0</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.3.6.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.3.6.1">0</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.3.7.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.3.7.1">0</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.3.8.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.3.8.1">1</cn><cn type="integer" id="S4.Ex3.m1.1.1.1.1.3.9.1.cmml"
    xref="S4.Ex3.m1.1.1.1.1.3.9.1">1</cn></matrixrow></matrix></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S4.Ex3.m1.1c">\mathbf{W_{3\times 9}}=\begin{pmatrix}3&1&1&2&2&2&3&0&0\\
    2&2&0&6&2&2&3&0&0\\ 0&0&0&0&0&0&0&1&1\\ \end{pmatrix}</annotation></semantics></math>
    |  |
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a simple example of a *distributed* representation. In a distributed
    representation (Plate, [1995](#bib.bib57); Hinton et al., [1986](#bib.bib35))
    the informational content is distributed (hence the name) among multiple units,
    and at the same time each unit can contribute to the representation of multiple
    elements. Distributed representation has two evident advantages with respect to
    a distributed local representation: it is more efficient (in the example, the
    representation uses only 3 numbers instead of 9) and it does not treat each element
    as being equally different to any other. In fact, *mouse* and *cat* in this representation
    are more similar than *mouse* and *a*. In other words, this representation captures
    by construction something interesting about the set of symbols. The drawback is
    that symbols are altered and, hence, it may be difficult to interpret which symbol
    is given its distributed representation. In the example, the distributed representations
    for *eats* and *some* are exactly the same vector $\mathbf{W_{3\times 9}}\mathbf{e_{5}}=\mathbf{W_{3\times
    9}}\mathbf{e_{6}}$.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个*分布式*表示的简单示例。在分布式表示（Plate, [1995](#bib.bib57); Hinton 等, [1986](#bib.bib35)）中，信息内容在多个单元之间分布（因此得名），同时每个单元可以对多个元素的表示做出贡献。与分布式局部表示相比，分布式表示有两个明显的优势：它更高效（在这个示例中，表示只使用了3个数字而不是9个）且它不会将每个元素视为与其他元素同样不同。实际上，在这种表示中，*鼠标*和*猫*比*鼠标*和*a*更相似。换句话说，这种表示通过构造捕捉了关于符号集合的一些有趣的东西。缺点是符号被改变，因此，可能很难解释哪些符号是给定的分布式表示。在这个例子中，*吃*和*一些*的分布式表示是完全相同的向量
    $\mathbf{W_{3\times 9}}\mathbf{e_{5}}=\mathbf{W_{3\times 9}}\mathbf{e_{6}}$。
- en: 'Even for distributed representations in the general form, it is possible to
    define *concatenative composition* and *functional composition* to represent expressions.
    Vectors $\mathbf{W_{d\times n}}\mathbf{e_{i}}$ should be replaced to vectors $\mathbf{e_{i}}$
    in the definition of the concatenative compositionality and the functional compositionality.
    Equation (LABEL:conc) is translated to:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是一般形式的分布式表示，也可以定义*连接性组合*和*功能组合*来表示表达式。在连接性组合性和功能组合性的定义中，向量 $\mathbf{W_{d\times
    n}}\mathbf{e_{i}}$ 应替换为向量 $\mathbf{e_{i}}$。方程 (LABEL:conc) 翻译为：
- en: '|  | $\mathbf{Y_{s}}=\mathbf{W_{d\times n}}\mathbf{conc(s)}=[\mathbf{W_{d\times
    n}}\mathbf{e}_{w_{1}}\ldots\mathbf{W_{d\times n}}\mathbf{e}_{w_{k}}]$ |  |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{Y_{s}}=\mathbf{W_{d\times n}}\mathbf{conc(s)}=[\mathbf{W_{d\times
    n}}\mathbf{e}_{w_{1}}\ldots\mathbf{W_{d\times n}}\mathbf{e}_{w_{k}}]$ |  |'
- en: 'and Equation ([1](#S4.E1 "In 4 Symbolic and Distributed Representations: Interpretability
    and Concatenative Compositionality ‣ Symbolic, Distributed and Distributional
    Representations for Natural Language Processing in the Era of Deep Learning: a
    Survey")) for additive functional compositionality becomes:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 方程 ([1](#S4.E1 "在4中符号和分布式表示：可解释性和连接性组合 ‣ 符号、分布式和分布式表示在深度学习时代的自然语言处理：一项综述"))
    对于加法功能组合性变为：
- en: '|  | $\mathbf{y_{s}}=\mathbf{W_{d\times n}}\mathbf{func}_{\Sigma}(s)=\sum_{j=1}^{k}\mathbf{W_{d\times
    n}}\mathbf{e}_{j}$ |  |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{y_{s}}=\mathbf{W_{d\times n}}\mathbf{func}_{\Sigma}(s)=\sum_{j=1}^{k}\mathbf{W_{d\times
    n}}\mathbf{e}_{j}$ |  |'
- en: 'In the running example, the additive functional compositionality of sentence
    $s_{1}$ is:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行示例中，句子 $s_{1}$ 的加法功能组合性是：
- en: '|  | <math id="S4.Ex6.m1.2" class="ltx_Math" alttext="\mathbf{y_{s_{1}}}=\mathbf{W_{3\times
    9}}\mathbf{func}_{\Sigma}(s_{1})=\begin{pmatrix}8\\ 12\\'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math id="S4.Ex6.m1.2" class="ltx_Math" alttext="\mathbf{y_{s_{1}}}=\mathbf{W_{3\times
    9}}\mathbf{func}_{\Sigma}(s_{1})=\begin{pmatrix}8\\ 12\\'
- en: 0\end{pmatrix}" display="block"><semantics id="S4.Ex6.m1.2a"><mrow id="S4.Ex6.m1.2.2"
    xref="S4.Ex6.m1.2.2.cmml"><msub id="S4.Ex6.m1.2.2.3" xref="S4.Ex6.m1.2.2.3.cmml"><mi
    id="S4.Ex6.m1.2.2.3.2" xref="S4.Ex6.m1.2.2.3.2.cmml">𝐲</mi><msub id="S4.Ex6.m1.2.2.3.3"
    xref="S4.Ex6.m1.2.2.3.3.cmml"><mi id="S4.Ex6.m1.2.2.3.3.2" xref="S4.Ex6.m1.2.2.3.3.2.cmml">𝐬</mi><mn
    id="S4.Ex6.m1.2.2.3.3.3" xref="S4.Ex6.m1.2.2.3.3.3.cmml">𝟏</mn></msub></msub><mo
    id="S4.Ex6.m1.2.2.4" xref="S4.Ex6.m1.2.2.4.cmml">=</mo><mrow id="S4.Ex6.m1.2.2.1"
    xref="S4.Ex6.m1.2.2.1.cmml"><msub id="S4.Ex6.m1.2.2.1.3" xref="S4.Ex6.m1.2.2.1.3.cmml"><mi
    id="S4.Ex6.m1.2.2.1.3.2" xref="S4.Ex6.m1.2.2.1.3.2.cmml">𝐖</mi><mrow id="S4.Ex6.m1.2.2.1.3.3"
    xref="S4.Ex6.m1.2.2.1.3.3.cmml"><mn id="S4.Ex6.m1.2.2.1.3.3.2" xref="S4.Ex6.m1.2.2.1.3.3.2.cmml">𝟑</mn><mo
    lspace="0.222em" rspace="0.222em" id="S4.Ex6.m1.2.2.1.3.3.1" xref="S4.Ex6.m1.2.2.1.3.3.1.cmml">×</mo><mn
    id="S4.Ex6.m1.2.2.1.3.3.3" xref="S4.Ex6.m1.2.2.1.3.3.3.cmml">𝟗</mn></mrow></msub><mo
    lspace="0em" rspace="0em" id="S4.Ex6.m1.2.2.1.2" xref="S4.Ex6.m1.2.2.1.2.cmml">​</mo><msub
    id="S4.Ex6.m1.2.2.1.4" xref="S4.Ex6.m1.2.2.1.4.cmml"><mi id="S4.Ex6.m1.2.2.1.4.2"
    xref="S4.Ex6.m1.2.2.1.4.2.cmml">𝐟𝐮𝐧𝐜</mi><mi mathvariant="normal" id="S4.Ex6.m1.2.2.1.4.3"
    xref="S4.Ex6.m1.2.2.1.4.3.cmml">Σ</mi></msub><mo lspace="0em" rspace="0em" id="S4.Ex6.m1.2.2.1.2a"
    xref="S4.Ex6.m1.2.2.1.2.cmml">​</mo><mrow id="S4.Ex6.m1.2.2.1.1.1" xref="S4.Ex6.m1.2.2.1.1.1.1.cmml"><mo
    stretchy="false" id="S4.Ex6.m1.2.2.1.1.1.2" xref="S4.Ex6.m1.2.2.1.1.1.1.cmml">(</mo><msub
    id="S4.Ex6.m1.2.2.1.1.1.1" xref="S4.Ex6.m1.2.2.1.1.1.1.cmml"><mi id="S4.Ex6.m1.2.2.1.1.1.1.2"
    xref="S4.Ex6.m1.2.2.1.1.1.1.2.cmml">s</mi><mn id="S4.Ex6.m1.2.2.1.1.1.1.3" xref="S4.Ex6.m1.2.2.1.1.1.1.3.cmml">1</mn></msub><mo
    stretchy="false" id="S4.Ex6.m1.2.2.1.1.1.3" xref="S4.Ex6.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo
    id="S4.Ex6.m1.2.2.5" xref="S4.Ex6.m1.2.2.5.cmml">=</mo><mrow id="S4.Ex6.m1.1.1.3"
    xref="S4.Ex6.m1.1.1.2.cmml"><mo id="S4.Ex6.m1.1.1.3.1" xref="S4.Ex6.m1.1.1.2.1.cmml">(</mo><mtable
    displaystyle="true" rowspacing="0pt" id="S4.Ex6.m1.1.1.1.1" xref="S4.Ex6.m1.1.1.1.1.cmml"><mtr
    id="S4.Ex6.m1.1.1.1.1a" xref="S4.Ex6.m1.1.1.1.1.cmml"><mtd id="S4.Ex6.m1.1.1.1.1b"
    xref="S4.Ex6.m1.1.1.1.1.cmml"><mn id="S4.Ex6.m1.1.1.1.1.1.1.1" xref="S4.Ex6.m1.1.1.1.1.1.1.1.cmml">8</mn></mtd></mtr><mtr
    id="S4.Ex6.m1.1.1.1.1c" xref="S4.Ex6.m1.1.1.1.1.cmml"><mtd id="S4.Ex6.m1.1.1.1.1d"
    xref="S4.Ex6.m1.1.1.1.1.cmml"><mn id="S4.Ex6.m1.1.1.1.1.2.1.1" xref="S4.Ex6.m1.1.1.1.1.2.1.1.cmml">12</mn></mtd></mtr><mtr
    id="S4.Ex6.m1.1.1.1.1e" xref="S4.Ex6.m1.1.1.1.1.cmml"><mtd id="S4.Ex6.m1.1.1.1.1f"
    xref="S4.Ex6.m1.1.1.1.1.cmml"><mn id="S4.Ex6.m1.1.1.1.1.3.1.1" xref="S4.Ex6.m1.1.1.1.1.3.1.1.cmml">0</mn></mtd></mtr></mtable><mo
    id="S4.Ex6.m1.1.1.3.2" xref="S4.Ex6.m1.1.1.2.1.cmml">)</mo></mrow></mrow><annotation-xml
    encoding="MathML-Content" id="S4.Ex6.m1.2b"><apply id="S4.Ex6.m1.2.2.cmml" xref="S4.Ex6.m1.2.2"><apply
    id="S4.Ex6.m1.2.2b.cmml" xref="S4.Ex6.m1.2.2"><apply id="S4.Ex6.m1.2.2.3.cmml"
    xref="S4.Ex6.m1.2.2.3"><csymbol cd="ambiguous" id="S4.Ex6.m1.2.2.3.1.cmml" xref="S4.Ex6.m1.2.2.3">subscript</csymbol><ci
    id="S4.Ex6.m1.2.2.3.2.cmml" xref="S4.Ex6.m1.2.2.3.2">𝐲</ci><apply id="S4.Ex6.m1.2.2.3.3.cmml"
    xref="S4.Ex6.m1.2.2.3.3"><csymbol cd="ambiguous" id="S4.Ex6.m1.2.2.3.3.1.cmml"
    xref="S4.Ex6.m1.2.2.3.3">subscript</csymbol><ci id="S4.Ex6.m1.2.2.3.3.2.cmml"
    xref="S4.Ex6.m1.2.2.3.3.2">𝐬</ci><cn type="integer" id="S4.Ex6.m1.2.2.3.3.3.cmml"
    xref="S4.Ex6.m1.2.2.3.3.3">1</cn></apply></apply><apply id="S4.Ex6.m1.2.2.1.cmml"
    xref="S4.Ex6.m1.2.2.1"><apply id="S4.Ex6.m1.2.2.1.3.cmml" xref="S4.Ex6.m1.2.2.1.3"><csymbol
    cd="ambiguous" id="S4.Ex6.m1.2.2.1.3.1.cmml" xref="S4.Ex6.m1.2.2.1.3">subscript</csymbol><ci
    id="S4.Ex6.m1.2.2.1.3.2.cmml" xref="S4.Ex6.m1.2.2.1.3.2">𝐖</ci><apply id="S4.Ex6.m1.2.2.1.3.3.cmml"
    xref="S4.Ex6.m1.2.2.1.3.3"><cn type="integer" id="S4.Ex6.m1.2.2.1.3.3.2.cmml"
    xref="S4.Ex6.m1.2.2.1.3.3.2">3</cn><cn type="integer" id="S4.Ex6.m1.2.2.1.3.3.3.cmml"
    xref="S4.Ex6.m1.2.2.1.3.3.3">9</cn></apply></apply><apply id="S4.Ex6.m1.2.2.1.4.cmml"
    xref="S4.Ex6.m1.2.2.1.4"><csymbol cd="ambiguous" id="S4.Ex6.m1.2.2.1.4.1.cmml"
    xref="S4.Ex6.m1.2.2.1.4">subscript</csymbol><ci id="S4.Ex6.m1.2.2.1.4.2.cmml"
    xref="S4.Ex6.m1.2.2.1.4.2">𝐟𝐮𝐧𝐜</ci><ci id="S4.Ex6.m1.2.2.1.4.3.cmml" xref="S4.Ex6.m1.2.2.1.4.3">Σ</ci></apply><apply
    id="S4.Ex6.m1.2.2.1.1.1.1.cmml" xref="S4.Ex6.m1.2.2.1.1.1"><csymbol cd="ambiguous"
    id="S4.Ex6.m1.2.2.1.1.1.1.1.cmml" xref="S4.Ex6.m1.2.2.1.1.1">subscript</csymbol><ci
    id="S4.Ex6.m1.2.2.1.1.1.1.2.cmml" xref="S4.Ex6.m1.2.2.1.1.1.1.2">𝑠</ci><cn type="integer"
    id="S4.Ex6.m1.2.2.1.1.1.1.3.cmml" xref="S4.Ex6.m1.2.2.1.1.1.1.3">1</cn></apply></apply></apply><apply
    id="S4.Ex6.m1.2.2c.cmml" xref="S4.Ex6.m1.2.2"><apply id="S4.Ex6.m1.1.1.2.cmml"
    xref="S4.Ex6.m1.1.1.3"><csymbol cd="latexml" id="S4.Ex6.m1.1.1.2.1.cmml" xref="S4.Ex6.m1.1.1.3.1">matrix</csymbol><matrix
    id="S4.Ex6.m1.1.1.1.1.cmml" xref="S4.Ex6.m1.1.1.1.1"><matrixrow id="S4.Ex6.m1.1.1.1.1a.cmml"
    xref="S4.Ex6.m1.1.1.1.1"><cn type="integer" id="S4.Ex6.m1.1.1.1.1.1.1.1.cmml"
    xref="S4.Ex6.m1.1.1.1.1.1.1.1">8</cn></matrixrow><matrixrow id="S4.Ex6.m1.1.1.1.1b.cmml"
    xref="S4.Ex6.m1.1.1.1.1"><cn type="integer" id="S4.Ex6.m1.1.1.1.1.2.1.1.cmml"
    xref="S4.Ex6.m1.1.1.1.1.2.1.1">12</cn></matrixrow><matrixrow id="S4.Ex6.m1.1.1.1.1c.cmml"
    xref="S4.Ex6.m1.1.1.1.1"><cn type="integer" id="S4.Ex6.m1.1.1.1.1.3.1.1.cmml"
    xref="S4.Ex6.m1.1.1.1.1.3.1.1">0</cn></matrixrow></matrix></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S4.Ex6.m1.2c">\mathbf{y_{s_{1}}}=\mathbf{W_{3\times
    9}}\mathbf{func}_{\Sigma}(s_{1})=\begin{pmatrix}8\\ 12\\ 0\end{pmatrix}</annotation></semantics></math>
    |  |
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`\mathbf{y_{s_{1}}}` = `\mathbf{W_{3\times 9}}` `\mathbf{func}_{\Sigma}(s_{1})`
    = `\begin{pmatrix}8\\ 12\\ 0\end{pmatrix}`'
- en: Clearly, in this case, it is extremely difficult to derive back the discrete
    symbolic sequence $s_{1}$ that has generated the final distributed representation.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，在这种情况下，从最终的分布式表示中恢复生成的离散符号序列 $s_{1}$ 是极其困难的。
- en: 'Summing up, a distributed representation $y_{s}$ of an discrete symbolic expression
    $s$ is obtained by using an encoder that acts in two ways:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，离散符号表达 $s$ 的分布式表示 $y_{s}$ 是通过使用一种双重作用的编码器获得的：
- en: •
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: transforms symbols $w_{i}$ in vectors by using an embedding matrix $\mathbf{W_{d\times
    n}}$ and the local distributed representation $\mathbf{e_{i}}$ of $w_{i}$;
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过使用嵌入矩阵 $\mathbf{W_{d\times n}}$ 和 $w_{i}$ 的局部分布表示 $\mathbf{e_{i}}$，将符号 $w_{i}$
    转换为向量；
- en: •
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: transposes the concatenative compositionality of the discrete symbolic expression
    $s$ in a functional compositionality by defining the used composition function
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将离散符号表达 $s$ 的串联组合性通过定义所使用的组合函数转置为功能组合性
- en: 'When defining a distributed representation, we need to define two elements:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义分布式表示时，我们需要定义两个要素：
- en: •
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'an embedding matrix $\mathbf{W}$ that should balance these two different aims:
    (1) *maximize* interpretability, that is, inversion; (2) *maximize* similarity
    among different symbols for specific purposes.'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个嵌入矩阵 $\mathbf{W}$ 应该平衡这两个不同的目标：（1）*最大化* 可解释性，即逆转；（2）*最大化* 在特定目的下不同符号之间的相似性。
- en: •
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'the functional composition model: additive, holographic reduced representations
    (Plate, [1995](#bib.bib57)), recursive neural networks Schuster and Paliwal ([1997](#bib.bib63));
    Hochreiter and Schmidhuber ([1997](#bib.bib36)) or with attention Vaswani et al.
    ([2017](#bib.bib69)); Devlin et al. ([2018](#bib.bib19))'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 功能组合模型：加法的，全息缩减表示（Plate，[1995](#bib.bib57)），递归神经网络 Schuster 和 Paliwal（[1997](#bib.bib63)）；Hochreiter
    和 Schmidhuber（[1997](#bib.bib36)）或带有注意力的 Vaswani 等（[2017](#bib.bib69)）；Devlin
    等（[2018](#bib.bib19)）
- en: 'And, the final questions are: What’s inside the distributed representation?
    What’s exactly encoded? How this information is used to take decisions? Hence,
    the debated question become how concatenative is the functional compositionality
    in distributed representations behind neural networks? Can we retrieve discrete
    symbols and rebuild sequences?'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的问题是：分布式表示中包含什么？究竟编码了什么？这些信息如何用于做出决策？因此，争论的问题变成了神经网络中的分布式表示在功能组合性上的串联程度如何？我们能否检索离散符号并重建序列？
- en: To answer the above questions, we then describe the two properties *Interpretability*
    and *concatenative compositionality* for distributed representations. These two
    properties want to measure how far are distributed representations from symbolic
    representations.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答上述问题，我们接着描述分布式表示的两个属性 *可解释性* 和 *串联组合性*。这两个属性旨在衡量分布式表示与符号表示之间的距离。
- en: 'Interpretability is the possibility of decoding distributed representations,
    that is, extracting the embedded symbolic representations. This is an important
    characteristic but it must be noted that it’s not a simple yes-or-no classification.
    It is more a degree associated to specific representations. In fact, even if each
    component of a vector representation does not have a specific meaning, this does
    not mean that the representation is not interpretable as a whole, or that symbolic
    information cannot be recovered from it. For this reason, we can categorize the
    degree of interpretability of a representation as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性是解码分布式表示的可能性，即提取嵌入的符号表示。这是一个重要特性，但需要注意的是，这不是一个简单的“是”或“否”的分类问题。它更像是与特定表示相关的一个程度。实际上，即使一个向量表示的每个组件没有特定的意义，这并不意味着该表示整体上不可解释，或者无法从中恢复符号信息。因此，我们可以按如下方式对表示的可解释性程度进行分类：
- en: '*human-interpretable* – each dimension of a representation has a specific meaning;'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*人类可解释的* — 表示的每个维度具有特定的意义；'
- en: '*decodable* – the representation may be obscure, but it can be decoded into
    an interpretable, symbolic representation.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可解码* — 表示可能很模糊，但可以解码为可解释的符号表示。'
- en: Concatenative Compositionality for distributed representations is the possibility
    of composing basic distributed representations with strong rules and of decomposing
    back composed representations with inverse rules. Generally, in NLP, basic distributed
    representations refer to basic symbols.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式表示的串联组合性是将基本分布式表示按照强规则组合，并根据逆规则分解回组合表示的可能性。通常，在自然语言处理中，基本分布式表示指的是基本符号。
- en: The two axes of *Interpretability* and *Concatenative Compositionality for distributed
    representations* will be used to describe the presented distributed representations
    as we are interested in understanding whether or not a representation can be used
    to represent structures or sequences and whether it is possible to extract back
    the underlying structure or sequence given a distributed representation. It is
    clear that a local distributed representation is more interpretable than a distributed
    representation. Yet, both representations lack in concatenative compositionality
    when sequences or structures are collapsed in vectors or tensors that do not depend
    on the length of represented sequences or structures. For example, the bag-of-word
    local representation does not take into consideration the order of the symbols
    in the sequence.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 将使用*可解释性*和*分布式表示的连接组合性*这两个轴来描述所呈现的分布式表示，因为我们希望深入了解一个表示是否可以用于表示结构或序列，以及是否可以在给定分布式表示的情况下提取出潜在的结构或序列。显然，本地分布式表示比分布式表示更具可解释性。然而，当序列或结构被压缩成不依赖于表示序列或结构长度的向量或张量时，两种表示都缺乏连接组合性。例如，词袋局部表示没有考虑符号在序列中的顺序。
- en: 5 Strategies to obtain distributed representations from symbols
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从符号中获取分布式表示的5种策略
- en: 'There is a wide range of techniques to transform symbolic representations in
    distributed representations. When combining natural language processing and machine
    learning, this is a major issue: transforming symbols, sequences of symbols or
    symbolic structures in vectors or tensors that can be used in learning machines.
    These techniques generally propose a function $\eta$ to transform a *local representation*
    with a large number of dimensions in a *distributed representation* with a lower
    number of dimensions:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 转换符号表示为分布式表示的技术种类繁多。当结合自然语言处理和机器学习时，这是一个主要问题：将符号、符号序列或符号结构转换为可以在学习机器中使用的向量或张量。这些技术通常提出一个函数$\eta$，以将具有大量维度的*局部表示*转换为具有较少维度的*分布式表示*：
- en: '|  | $\eta\colon\mathbb{R}^{n}\to\mathbb{R}^{d}$ |  |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|  | $\eta\colon\mathbb{R}^{n}\to\mathbb{R}^{d}$ |  |'
- en: This function is often called *encoder*.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数通常被称为*编码器*。
- en: 'We propose to categorize techniques to obtain distributed representations in
    two broad categories, showing some degree of overlapping:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议将获取分布式表示的技术分为两个广泛的类别，并显示出一定程度的重叠：
- en: •
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: representations derived from dimensionality reduction techniques;
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从降维技术中获得的表示；
- en: •
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: learned representations
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学到的表示
- en: 'In the rest of the section, we will introduce the different strategies according
    to the proposed categorization. Moreover, we will emphasize its degree of interpretability
    for each representation and its related function $\eta$ by answering to two questions:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的其余部分，我们将根据提出的分类介绍不同的策略。此外，我们将通过回答两个问题来强调每个表示及其相关函数$\eta$的解释程度：
- en: •
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Has a specific dimension in $\mathbb{R}^{d}$ a clear meaning?
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在$\mathbb{R}^{d}$中具有特定维度是否有明确含义？
- en: •
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Can we decode an encoded symbolic representation? In other words, assuming a
    decoding function $\delta\colon\mathbb{R}^{d}\to\mathbb{R}^{n}$, how far is $v\in\mathbb{R}^{n}$,
    which represents a symbolic representation, from $v^{\prime}=\delta(\eta(v))$?
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以解码一个编码的符号表示吗？换句话说，假设有一个解码函数$\delta\colon\mathbb{R}^{d}\to\mathbb{R}^{n}$，那么表示符号表示的$v\in\mathbb{R}^{n}$距离$v^{\prime}=\delta(\eta(v))$有多远？
- en: 'Instead, composability of the resulting representations will be analyzed in
    Sec. [7](#S7 "7 Composing distributed representations ‣ Symbolic, Distributed
    and Distributional Representations for Natural Language Processing in the Era
    of Deep Learning: a Survey").'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，结果表示的可组合性将在第[7](#S7 "7 组成分布式表示 ‣ 符号、分布式和分布化表示在深度学习时代的自然语言处理中的调查")节中进行分析。
- en: 5.1 Dimensionality reductio with Random Projections
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 随机投影的降维
- en: '*Random projection* (RP) (Bingham and Mannila, [2001](#bib.bib9); Fodor, [2002](#bib.bib23))
    is a technique based on random matrices $W_{d}\in\mathbb{R}^{d\times n}$. Generally,
    the rows of the matrix $W_{d}$ are sampled from a Gaussian distribution with zero
    mean, and normalized as to have unit length (Johnson and Lindenstrauss, [1984](#bib.bib39))
    or even less complex random vectors (Achlioptas, [2003](#bib.bib1)). Random projections
    from Gaussian distributions approximately preserves pairwise distance between
    points (see the *Johnsonn-Lindenstrauss Lemma* (Johnson and Lindenstrauss, [1984](#bib.bib39))),
    that is, for any vector $x,y\in X$:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '*随机投影* (RP) (Bingham and Mannila, [2001](#bib.bib9); Fodor, [2002](#bib.bib23))
    是一种基于随机矩阵 $W_{d}\in\mathbb{R}^{d\times n}$ 的技术。通常，矩阵 $W_{d}$ 的行从均值为零的高斯分布中采样，并归一化为单位长度（Johnson
    and Lindenstrauss, [1984](#bib.bib39)），或者甚至从更简单的随机向量中采样（Achlioptas, [2003](#bib.bib1)）。高斯分布中的随机投影大致保留点之间的成对距离（参见
    *Johnson-Lindenstrauss 引理*（Johnson and Lindenstrauss, [1984](#bib.bib39)），即，对于任何向量
    $x,y\in X$：'
- en: '|  | $(1-\varepsilon)\ \&#124;\mathbf{x}-\mathbf{y}\&#124;^{2}\leq\&#124;W\mathbf{x}-W\mathbf{y}\&#124;^{2}\leq(1+\varepsilon)\
    \&#124;\mathbf{x}-\mathbf{y}\&#124;^{2}$ |  |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '|  | $(1-\varepsilon)\ \&#124;\mathbf{x}-\mathbf{y}\&#124;^{2}\leq\&#124;W\mathbf{x}-W\mathbf{y}\&#124;^{2}\leq(1+\varepsilon)\
    \&#124;\mathbf{x}-\mathbf{y}\&#124;^{2}$ |  |'
- en: 'where the approximation factor $\varepsilon$ depends on the dimension of the
    projection, namely, to assure that the approximation factor is $\varepsilon$,
    the dimension $k$ must be chosen such that:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 其中近似因子 $\varepsilon$ 取决于投影的维度，即，为了确保近似因子为 $\varepsilon$，维度 $k$ 必须选择如下：
- en: '|  | $k\geq\frac{8\log(m)}{\varepsilon^{2}}$ |  |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|  | $k\geq\frac{8\log(m)}{\varepsilon^{2}}$ |  |'
- en: 'Constraints for building the matrix $W$ can be significantly relaxed to less
    complex random vectors (Achlioptas, [2003](#bib.bib1)). Rows of the matrix can
    be sampled from very simple zero-mean distributions such as:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 构建矩阵 $W$ 的约束可以显著放宽到更简单的随机向量（Achlioptas，[2003](#bib.bib1)）。矩阵的行可以从非常简单的零均值分布中采样，例如：
- en: '|  | <math id="S5.Ex10.m1.3" class="ltx_Math" alttext="W_{ij}=\sqrt{3}\begin{cases}+1\
    \text{ with probability }\frac{1}{6}\\ -1\ \text{ with probability }\frac{1}{6}\\'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math id="S5.Ex10.m1.3" class="ltx_Math" alttext="W_{ij}=\sqrt{3}\begin{cases}+1\
    \text{ with probability }\frac{1}{6}\\ -1\ \text{ with probability }\frac{1}{6}\\'
- en: 0\ \ \ \text{ with probability }\frac{2}{3}\\
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 0\ \ \ \text{ with probability }\frac{2}{3}\\
- en: \end{cases}" display="block"><semantics id="S5.Ex10.m1.3a"><mrow id="S5.Ex10.m1.3.4"
    xref="S5.Ex10.m1.3.4.cmml"><msub id="S5.Ex10.m1.3.4.2" xref="S5.Ex10.m1.3.4.2.cmml"><mi
    id="S5.Ex10.m1.3.4.2.2" xref="S5.Ex10.m1.3.4.2.2.cmml">W</mi><mrow id="S5.Ex10.m1.3.4.2.3"
    xref="S5.Ex10.m1.3.4.2.3.cmml"><mi id="S5.Ex10.m1.3.4.2.3.2" xref="S5.Ex10.m1.3.4.2.3.2.cmml">i</mi><mo
    lspace="0em" rspace="0em" id="S5.Ex10.m1.3.4.2.3.1" xref="S5.Ex10.m1.3.4.2.3.1.cmml">​</mo><mi
    id="S5.Ex10.m1.3.4.2.3.3" xref="S5.Ex10.m1.3.4.2.3.3.cmml">j</mi></mrow></msub><mo
    id="S5.Ex10.m1.3.4.1" xref="S5.Ex10.m1.3.4.1.cmml">=</mo><mrow id="S5.Ex10.m1.3.4.3"
    xref="S5.Ex10.m1.3.4.3.cmml"><msqrt id="S5.Ex10.m1.3.4.3.2" xref="S5.Ex10.m1.3.4.3.2.cmml"><mn
    id="S5.Ex10.m1.3.4.3.2.2" xref="S5.Ex10.m1.3.4.3.2.2.cmml">3</mn></msqrt><mo lspace="0em"
    rspace="0em" id="S5.Ex10.m1.3.4.3.1" xref="S5.Ex10.m1.3.4.3.1.cmml">​</mo><mrow
    id="S5.Ex10.m1.3.3" xref="S5.Ex10.m1.3.4.3.3.1.cmml"><mo id="S5.Ex10.m1.3.3.4"
    xref="S5.Ex10.m1.3.4.3.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true"
    rowspacing="0pt" id="S5.Ex10.m1.3.3.3" xref="S5.Ex10.m1.3.4.3.3.1.cmml"><mtr id="S5.Ex10.m1.3.3.3a"
    xref="S5.Ex10.m1.3.4.3.3.1.cmml"><mtd class="ltx_align_left" columnalign="left"
    id="S5.Ex10.m1.3.3.3b" xref="S5.Ex10.m1.3.4.3.3.1.cmml"><mrow id="S5.Ex10.m1.1.1.1.1.1.1"
    xref="S5.Ex10.m1.1.1.1.1.1.1.cmml"><mo id="S5.Ex10.m1.1.1.1.1.1.1a" xref="S5.Ex10.m1.1.1.1.1.1.1.cmml">+</mo><mrow
    id="S5.Ex10.m1.1.1.1.1.1.1.2" xref="S5.Ex10.m1.1.1.1.1.1.1.2.cmml"><mn id="S5.Ex10.m1.1.1.1.1.1.1.2.2"
    xref="S5.Ex10.m1.1.1.1.1.1.1.2.2.cmml">1</mn><mo lspace="0.500em" rspace="0em"
    id="S5.Ex10.m1.1.1.1.1.1.1.2.1" xref="S5.Ex10.m1.1.1.1.1.1.1.2.1.cmml">​</mo><mtext
    id="S5.Ex10.m1.1.1.1.1.1.1.2.3" xref="S5.Ex10.m1.1.1.1.1.1.1.2.3a.cmml"> with
    probability </mtext><mo lspace="0em" rspace="0em" id="S5.Ex10.m1.1.1.1.1.1.1.2.1a"
    xref="S5.Ex10.m1.1.1.1.1.1.1.2.1.cmml">​</mo><mstyle displaystyle="false" id="S5.Ex10.m1.1.1.1.1.1.1.2.4"
    xref="S5.Ex10.m1.1.1.1.1.1.1.2.4.cmml"><mfrac id="S5.Ex10.m1.1.1.1.1.1.1.2.4a"
    xref="S5.Ex10.m1.1.1.1.1.1.1.2.4.cmml"><mn id="S5.Ex10.m1.1.1.1.1.1.1.2.4.2" xref="S5.Ex10.m1.1.1.1.1.1.1.2.4.2.cmml">1</mn><mn
    id="S5.Ex10.m1.1.1.1.1.1.1.2.4.3" xref="S5.Ex10.m1.1.1.1.1.1.1.2.4.3.cmml">6</mn></mfrac></mstyle></mrow></mrow></mtd></mtr><mtr
    id="S5.Ex10.m1.3.3.3d" xref="S5.Ex10.m1.3.4.3.3.1.cmml"><mtd class="ltx_align_left"
    columnalign="left" id="S5.Ex10.m1.3.3.3e" xref="S5.Ex10.m1.3.4.3.3.1.cmml"><mrow
    id="S5.Ex10.m1.2.2.2.2.1.1" xref="S5.Ex10.m1.2.2.2.2.1.1.cmml"><mo id="S5.Ex10.m1.2.2.2.2.1.1a"
    xref="S5.Ex10.m1.2.2.2.2.1.1.cmml">−</mo><mrow id="S5.Ex10.m1.2.2.2.2.1.1.2" xref="S5.Ex10.m1.2.2.2.2.1.1.2.cmml"><mn
    id="S5.Ex10.m1.2.2.2.2.1.1.2.2" xref="S5.Ex10.m1.2.2.2.2.1.1.2.2.cmml">1</mn><mo
    lspace="0.500em" rspace="0em" id="S5.Ex10.m1.2.2.2.2.1.1.2.1" xref="S5.Ex10.m1.2.2.2.2.1.1.2.1.cmml">​</mo><mtext
    id="S5.Ex10.m1.2.2.2.2.1.1.2.3" xref="S5.Ex10.m1.2.2.2.2.1.1.2.3a.cmml"> with
    probability </mtext><mo lspace="0em" rspace="0em" id="S5.Ex10.m1.2.2.2.2.1.1.2.1a"
    xref="S5.Ex10.m1.2.2.2.2.1.1.2.1.cmml">​</mo><mstyle displaystyle="false" id="S5.Ex10.m1.2.2.2.2.1.1.2.4"
    xref="S5.Ex10.m1.2.2.2.2.1.1.2.4.cmml"><mfrac id="S5.Ex10.m1.2.2.2.2.1.1.2.4a"
    xref="S5.Ex10.m1.2.2.2.2.1.1.2.4.cmml"><mn id="S5.Ex10.m1.2.2.2.2.1.1.2.4.2" xref="S5.Ex10.m1.2.2.2.2.1.1.2.4.2.cmml">1</mn><mn
    id="S5.Ex10.m1.2.2.2.2.1.1.2.4.3" xref="S5.Ex10.m1.2.2.2.2.1.1.2.4.3.cmml">6</mn></mfrac></mstyle></mrow></mrow></mtd></mtr><mtr
    id="S5.Ex10.m1.3.3.3g" xref="S5.Ex10.m1.3.4.3.3.1.cmml"><mtd class="ltx_align_left"
    columnalign="left" id="S5.Ex10.m1.3.3.3h" xref="S5.Ex10.m1.3.4.3.3.1.cmml"><mrow
    id="S5.Ex10.m1.3.3.3.3.1.1.2" xref="S5.Ex10.m1.3.3.3.3.1.1.3.cmml"><mn id="S5.Ex10.m1.3.3.3.3.1.1.1"
    xref="S5.Ex10.m1.3.3.3.3.1.1.1.cmml">0</mn><mrow id="S5.Ex10.m1.3.3.3.3.1.1.2.1"
    xref="S5.Ex10.m1.3.3.3.3.1.1.2.1.cmml"><mtext id="S5.Ex10.m1.3.3.3.3.1.1.2.1.2"
    xref="S5.Ex10.m1.3.3.3.3.1.1.2.1.2a.cmml"> with probability </mtext><mo lspace="0em"
    rspace="0em" id="S5.Ex10.m1.3.3.3.3.1.1.2.1.1" xref="S5.Ex10.m1.3.3.3.3.1.1.2.1.1.cmml">​</mo><mstyle
    displaystyle="false" id="S5.Ex10.m1.3.3.3.3.1.1.2.1.3" xref="S5.Ex10.m1.3.3.3.3.1.1.2.1.3.cmml"><mfrac
    id="S5.Ex10.m1.3.3.3.3.1.1.2.1.3a" xref="S5.Ex10.m1.3.3.3.3.1.1.2.1.3.cmml"><mn
    id="S5.Ex10.m1.3.3.3.3.1.1.2.1.3.2" xref="S5.Ex10.m1.3.3.3.3.1.1.2.1.3.2.cmml">2</mn><mn
    id="S5.Ex10.m1.3.3.3.3.1.1.2.1.3.3" xref="S5.Ex10.m1.3.3.3.3.1.1.2.1.3.3.cmml">3</mn></mfrac></mstyle></mrow></mrow></mtd></mtr></mtable></mrow></mrow></mrow><annotation-xml
    encoding="MathML-Content" id="S5.Ex10.m1.3b"><apply id="S5.Ex10.m1.3.4.cmml" xref="S5.Ex10.m1.3.4"><apply
    id="S5.Ex10.m1.3.4.2.cmml" xref="S5.Ex10.m1.3.4.2"><csymbol cd="ambiguous" id="S5.Ex10.m1.3.4.2.1.cmml"
    xref="S5.Ex10.m1.3.4.2">subscript</csymbol><ci id="S5.Ex10.m1.3.4.2.2.cmml" xref="S5.Ex10.m1.3.4.2.2">𝑊</ci><apply
    id="S5.Ex10.m1.3.4.2.3.cmml" xref="S5.Ex10.m1.3.4.2.3"><ci id="S5.Ex10.m1.3.4.2.3.2.cmml"
    xref="S5.Ex10.m1.3.4.2.3.2">𝑖</ci><ci id="S5.Ex10.m1.3.4.2.3.3.cmml" xref="S5.Ex10.m1.3.4.2.3.3">𝑗</ci></apply></apply><apply
    id="S5.Ex10.m1.3.4.3.cmml" xref="S5.Ex10.m1.3.4.3"><apply id="S5.Ex10.m1.3.4.3.2.cmml"
    xref="S5.Ex10.m1.3.4.3.2"><cn type="integer" id="S5.Ex10.m1.3.4.3.2.2.cmml" xref="S5.Ex10.m1.3.4.3.2.2">3</cn></apply><apply
    id="S5.Ex10.m1.3.4.3.3.1.cmml" xref="S5.Ex10.m1.3.3"><csymbol cd="latexml" id="S5.Ex10.m1.3.4.3.3.1.1.cmml"
    xref="S5.Ex10.m1.3.3.4">cases</csymbol><apply id="S5.Ex10.m1.1.1.1.1.1.1.cmml"
    xref="S5.Ex10.m1.1.1.1.1.1.1"><apply id="S5.Ex10.m1.1.1.1.1.1.1.2.cmml" xref="S5.Ex10.m1.1.1.1.1.1.1.2"><cn
    type="integer" id="S5.Ex10.m1.1.1.1.1.1.1.2.2.cmml" xref="S5.Ex10.m1.1.1.1.1.1.1.2.2">1</cn><ci
    id="S5.Ex10.m1.1.1.1.1.1.1.2.3a.cmml" xref="S5.Ex10.m1.1.1.1.1.1.1.2.3"><mtext
    id="S5.Ex10.m1.1.1.1.1.1.1.2.3.cmml" xref="S5.Ex10.m1.1.1.1.1.1.1.2.3"> with probability </mtext></ci><apply
    id="S5.Ex10.m1.1.1.1.1.1.1.2.4.cmml" xref="S5.Ex10.m1.1.1.1.1.1.1.2.4"><cn type="integer"
    id="S5.Ex10.m1.1.1.1.1.1.1.2.4.2.cmml" xref="S5.Ex10.m1.1.1.1.1.1.1.2.4.2">1</cn><cn
    type="integer" id="S5.Ex10.m1.1.1.1.1.1.1.2.4.3.cmml" xref="S5.Ex10.m1.1.1.1.1.1.1.2.4.3">6</cn></apply></apply></apply><ci
    id="S5.Ex10.m1.3.4.3.3.1.3a.cmml" xref="S5.Ex10.m1.3.3"><mtext class="ltx_mathvariant_italic"
    id="S5.Ex10.m1.3.4.3.3.1.3.cmml" xref="S5.Ex10.m1.3.3.4">otherwise</mtext></ci><apply
    id="S5.Ex10.m1.2.2.2.2.1.1.cmml" xref="S5.Ex10.m1.2.2.2.2.1.1"><apply id="S5.Ex10.m1.2.2.2.2.1.1.2.cmml"
    xref="S5.Ex10.m1.2.2.2.2.1.1.2"><cn type="integer" id="S5.Ex10.m1.2.2.2.2.1.1.2.2.cmml"
    xref="S5.Ex10.m1.2.2.2.2.1.1.2.2">1</cn><ci id="S5.Ex10.m1.2.2.2.2.1.1.2.3a.cmml"
    xref="S5.Ex10.m1.2.2.2.2.1.1.2.3"><mtext id="S5.Ex10.m1.2.2.2.2.1.1.2.3.cmml"
    xref="S5.Ex10.m1.2.2.2.2.1.1.2.3"> with probability </mtext></ci><apply id="S5.Ex10.m1.2.2.2.2.1.1.2.4.cmml"
    xref="S5.Ex10.m1.2.2.2.2.1.1.2.4"><cn type="integer" id="S5.Ex10.m1.2.2.2.2.1.1.2.4.2.cmml"
    xref="S5.Ex10.m1.2.2.2.2.1.1.2.4.2">1</cn><cn type="integer" id="S5.Ex10.m1.2.2.2.2.1.1.2.4.3.cmml"
    xref="S5.Ex10.m1.2.2.2.2.1.1.2.4.3">6</cn></apply></apply></apply><ci id="S5.Ex10.m1.3.4.3.3.1.5a.cmml"
    xref="S5.Ex10.m1.3.3"><mtext class="ltx_mathvariant_italic" id="S5.Ex10.m1.3.4.3.3.1.5.cmml"
    xref="S5.Ex10.m1.3.3.4">otherwise</mtext></ci><list id="S5.Ex10.m1.3.3.3.3.1.1.3.cmml"
    xref="S5.Ex10.m1.3.3.3.3.1.1.2"><cn type="integer" id="S5.Ex10.m1.3.3.3.3.1.1.1.cmml"
    xref="S5.Ex10.m1.3.3.3.3.1.1.1">0</cn><apply id="S5.Ex10.m1.3.3.3.3.1.1.2.1.cmml"
    xref="S5.Ex10.m1.3.3.3.3.1.1.2.1"><ci id="S5.Ex10.m1.3.3.3.3.1.1.2.1.2a.cmml"
    xref="S5.Ex10.m1.3.3.3.3.1.1.2.1.2"><mtext id="S5.Ex10.m1.3.3.3.3.1.1.2.1.2.cmml"
    xref="S5.Ex10.m1.3.3.3.3.1.1.2.1.2"> with probability </mtext></ci><apply id="S5.Ex10.m1.3.3.3.3.1.1.2.1.3.cmml"
    xref="S5.Ex10.m1.3.3.3.3.1.1.2.1.3"><cn type="integer" id="S5.Ex10.m1.3.3.3.3.1.1.2.1.3.2.cmml"
    xref="S5.Ex10.m1.3.3.3.3.1.1.2.1.3.2">2</cn><cn type="integer" id="S5.Ex10.m1.3.3.3.3.1.1.2.1.3.3.cmml"
    xref="S5.Ex10.m1.3.3.3.3.1.1.2.1.3.3">3</cn></apply></apply></list><ci id="S5.Ex10.m1.3.4.3.3.1.7a.cmml"
    xref="S5.Ex10.m1.3.3"><mtext class="ltx_mathvariant_italic" id="S5.Ex10.m1.3.4.3.3.1.7.cmml"
    xref="S5.Ex10.m1.3.3.4">otherwise</mtext></ci></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S5.Ex10.m1.3c">W_{ij}=\sqrt{3}\begin{cases}+1\
    \text{ with probability }\frac{1}{6}\\ -1\ \text{ with probability }\frac{1}{6}\\
    0\ \ \ \text{ with probability }\frac{2}{3}\\ \end{cases}</annotation></semantics></math>
    |  |
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`W_{ij}=\sqrt{3}\begin{cases}+1\ \text{ with probability }\frac{1}{6}\\ -1\
    \text{ with probability }\frac{1}{6}\\ 0\ \ \ \text{ with probability }\frac{2}{3}\\
    \end{cases}`'
- en: without the need to manually ensure unit-length of the rows, and at the same
    time providing a significant speed up in computation due to the sparsity of the
    projection.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 无需手动确保行的单位长度，同时由于投影的稀疏性，计算速度显著加快。
- en: Unfortunately, vectors $\eta(\mathbf{v})$ are not *human-interpretable* as,
    even if their dimensions represent linear combinations of dimensions in the original
    local distribution, these dimensions have not an interpretation or particular
    properties.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，向量 $\eta(\mathbf{v})$ 并不是*人类可解释的*，即使它们的维度表示原始局部分布中的线性组合，这些维度也没有明确的解释或特定属性。
- en: 'On the contrary, vectors $\eta(\mathbf{v})$ are *decodable*. The decoding function
    is:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，向量 $\eta(\mathbf{v})$ 是*可解码的*。解码函数是：
- en: '|  | $\delta(\mathbf{v^{\prime}})=W_{d}^{T}\mathbf{v^{\prime}}$ |  |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|  | $\delta(\mathbf{v^{\prime}})=W_{d}^{T}\mathbf{v^{\prime}}$ |  |'
- en: and $W_{d}^{T}W_{d}\approx I$ when $W_{d}$ is derived using Gaussian random
    vectors. Hence, distributed vectors in $\mathbb{R}^{d}$ can be approximately decoded
    back in the original symbolic representation with a degree of approximation that
    depends on the distance between $d$ .
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 当 $W_{d}$ 是使用高斯随机向量得出的时，$W_{d}^{T}W_{d}\approx I$。因此，分布向量在 $\mathbb{R}^{d}$
    中可以大致解码回原始符号表示，近似度取决于 $d$ 之间的距离。
- en: The major advantage of RP with respect to PCA is that the matrix $X$ of all
    the data points is not needed to derive the matrix $W_{d}$. Moreover, the matrix
    $W_{d}$ can be produced *à-la-carte* starting from the symbols encountered so
    far in the encoding procedure. In fact, it is sufficient to generate new Gaussian
    vectors for new symbols when they appear.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 与 PCA 相比，RP 的主要优点在于，不需要所有数据点的矩阵 $X$ 来推导矩阵 $W_{d}$。此外，矩阵 $W_{d}$ 可以*按需*从编码过程中遇到的符号开始生成。实际上，当出现新符号时，只需生成新的高斯向量即可。
- en: 5.2 Learned representation
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 学习表示
- en: 'Learned representations differ from the dimensionality reduction techniques
    by the fact that: (1) encoding/decoding functions may not be linear; (2) learning
    can optimize functions that are different with respect to the target of PCA; and,
    (3) solutions are not derived in a closed form but are obtained using optimization
    techniques such as *stochastic gradient decent*.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 学习的表示与降维技术的不同在于：（1）编码/解码函数可能不是线性的；（2）学习可以优化与 PCA 目标不同的函数；以及，（3）解决方案不是以封闭形式得出的，而是使用优化技术如*随机梯度下降*获得的。
- en: 'Learned representation can be further classified into:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 学习的表示可以进一步分类为：
- en: •
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*task-independent representations* learned with a standalone algorithm (as
    in *autoencoders* (Socher et al., [2011](#bib.bib64); Liou et al., [2014](#bib.bib45)))
    which is independent from any task, and which learns a representation that only
    depends from the dataset used;'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*任务无关的表示*，通过独立算法（如*自编码器*（Socher 等，[2011](#bib.bib64); Liou 等，[2014](#bib.bib45)））学习，这与任何任务无关，只学习依赖于使用的数据集的表示；'
- en: •
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*task-dependent representations* learned as the first step of another algorithm
    (this is called *end-to-end training*), usually the first layer of a deep neural
    network. In this case the new representation is driven by the task.'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*任务相关的表示* 作为另一算法的第一步学习（这称为*端到端训练*），通常是深度神经网络的第一层。在这种情况下，新表示是由任务驱动的。'
- en: 5.2.1 Autoencoder
  id: totrans-160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1 自编码器
- en: Autoencoders are a task independent technique to learn a distributed representation
    encoder $\eta\colon\mathbb{R}^{n}\to\mathbb{R}^{d}$ by using local representations
    of a set of examples (Socher et al., [2011](#bib.bib64); Liou et al., [2014](#bib.bib45)).
    The distributed representation encoder $\eta$ is half of an autoencoder.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是一种任务无关的技术，通过使用一组示例的局部表示来学习分布表示编码器 $\eta\colon\mathbb{R}^{n}\to\mathbb{R}^{d}$（Socher
    等，[2011](#bib.bib64); Liou 等，[2014](#bib.bib45)）。分布表示编码器 $\eta$ 是自编码器的一半。
- en: 'An autoencoder is a neural network that aims to reproduce an input vector in
    $\mathbb{R}^{n}$ as output by passing in a hidden layer(s) that are in $\mathbb{R}^{d}$.
    Given $\eta\colon\mathbb{R}^{n}\to\mathbb{R}^{d}$ and $\delta\colon\mathbb{R}^{d}\to\mathbb{R}^{n}$
    as the encoder and the decoder, respectively, an autoencoder aims to maximize
    the following function:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是一个神经网络，旨在通过将输入向量 $\mathbb{R}^{n}$ 通过隐藏层传递，重建为输出。给定编码器 $\eta\colon\mathbb{R}^{n}\to\mathbb{R}^{d}$
    和解码器 $\delta\colon\mathbb{R}^{d}\to\mathbb{R}^{n}$，自编码器旨在最大化以下函数：
- en: '|  | $\mathcal{L}(\mathbf{x},\mathbf{x}^{\prime})=\&#124;\mathbf{x}-\mathbf{x}^{\prime}\&#124;^{2}$
    |  |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}(\mathbf{x},\mathbf{x}^{\prime})=\&#124;\mathbf{x}-\mathbf{x}^{\prime}\&#124;^{2}$
    |  |'
- en: where
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '|  | $\mathbf{x^{\prime}}=\delta(\eta(\mathbf{x}))$ |  |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{x^{\prime}}=\delta(\eta(\mathbf{x}))$ |  |'
- en: The encoding and decoding module are two neural networks, which means that they
    are functions depending on a set of parameters $\theta$ of the form
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 编码和解码模块是两个神经网络，这意味着它们是依赖于一组参数 $\theta$ 的函数，其形式为
- en: '|  | $\displaystyle\eta_{\theta}(x)=s(Wx+b)$ |  |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\eta_{\theta}(x)=s(Wx+b)$ |  |'
- en: '|  | $\displaystyle\delta_{\theta^{\prime}}(y)=s(W^{\prime}y+b^{\prime})$ |  |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\delta_{\theta^{\prime}}(y)=s(W^{\prime}y+b^{\prime})$ |  |'
- en: where the parameters of the entire model are $\theta,\theta^{\prime}=\left\{W,b,W^{\prime},b^{\prime}\right\}$
    with $W,W^{\prime}$ matrices, $b,b^{\prime}$ vectors and $s$ is a function that
    can be either a non-linearity sigmoid shaped function, or in some cases the identity
    function. In some variants the matrices $W$ and $W^{\prime}$ are constrained to
    $W^{T}=W^{\prime}$. This model is different with respect to PCA due to the target
    loss function and the use of non-linear functions.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 其中整个模型的参数为 $\theta,\theta^{\prime}=\left\{W,b,W^{\prime},b^{\prime}\right\}$，$W$
    和 $W^{\prime}$ 是矩阵，$b$ 和 $b^{\prime}$ 是向量，而 $s$ 是一个函数，可以是非线性 sigmoid 形状的函数，或者在某些情况下是恒等函数。在某些变体中，矩阵
    $W$ 和 $W^{\prime}$ 被限制为 $W^{T}=W^{\prime}$。由于目标损失函数和非线性函数的使用，这个模型与 PCA 有所不同。
- en: 'Autoencoders have been further improved with *denoising autoencoders* (Vincent
    et al., [2010](#bib.bib71), [2008](#bib.bib70); Masci et al., [2011](#bib.bib48))
    that are a variant of autoencoders where the goal is to reconstruct the input
    from a corrupted version. The intuition is that higher level features should be
    robust with regard to small noise in the input. In particular, the input $\mathbf{x}$
    gets corrupted via a stochastic function:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器通过 *去噪自编码器*（Vincent et al., [2010](#bib.bib71), [2008](#bib.bib70); Masci
    et al., [2011](#bib.bib48)）得到了进一步的改进，这是自编码器的一种变体，其目标是从损坏的版本中重构输入。直觉是较高层次的特征应该对输入中的小噪声具有鲁棒性。特别地，输入
    $\mathbf{x}$ 通过随机函数进行损坏：
- en: '|  | $\tilde{\mathbf{x}}=g(\mathbf{x})$ |  |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '|  | $\tilde{\mathbf{x}}=g(\mathbf{x})$ |  |'
- en: 'and then one minimizes again the reconstruction error, but with regard to the
    *original* (uncorrupted) input:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 然后再次最小化重构误差，但相对于 *原始*（未损坏）输入：
- en: '|  | $\mathcal{L}(\mathbf{x},\mathbf{x}^{\prime})=\&#124;\mathbf{x}-\delta(\eta(g(\mathbf{x})))\&#124;^{2}$
    |  |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}(\mathbf{x},\mathbf{x}^{\prime})=\&#124;\mathbf{x}-\delta(\eta(g(\mathbf{x})))\&#124;^{2}$
    |  |'
- en: 'Usually $g$ can be either:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 通常 $g$ 可以是以下之一：
- en: •
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'adding gaussian noise: $g(\mathbf{x})=\mathbf{x}+\varepsilon$, where $\varepsilon\sim\mathcal{N}(0,\sigma\mathbb{I})$;'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 添加高斯噪声：$g(\mathbf{x})=\mathbf{x}+\varepsilon$，其中 $\varepsilon\sim\mathcal{N}(0,\sigma\mathbb{I})$；
- en: •
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'masking noise: where a given a fraction $\nu$ of the components of the input
    gets set to $0$'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 掩蔽噪声：将输入的给定分量 $\nu$ 设为 $0$
- en: For what concerns *intepretability*, as for random projection, distributed representations
    $\eta(\mathbf{v})$ obtained with encoders from autoencoders and denoising autoencoders
    are not *human-interpretable* but are *decodable* as this is the nature of autoencoders.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 *可解释性*，与随机投影一样，通过自编码器和去噪自编码器获得的分布式表示 $\eta(\mathbf{v})$ 并不 *人类可解释*，但可以 *解码*，因为这正是自编码器的特性。
- en: Moreover, *composability* is not covered by this formulation of autoencoders.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，*组合性* 不包含在这个自编码器的表述中。
- en: 5.2.2 Embedding layers
  id: totrans-181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2 嵌入层
- en: Embedding layers are generally the first layers of more complex neural networks
    which are responsible to transform an initial local representation in the first
    internal distributed representation. The main difference with autoencoders is
    that these layers are shaped by the entire overall learning process. The learning
    process is generally task dependent. Hence, these first embedding layers depend
    on the final task.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入层通常是更复杂神经网络的第一层，负责将初始的局部表示转换为第一个内部分布式表示。与自编码器的主要区别在于，这些层由整个学习过程塑造。学习过程通常依赖于任务。因此，这些首层嵌入层取决于最终任务。
- en: It is argued that each layers learn a higher-level representation of its input.
    This is particularly visible with convolutional network (Krizhevsky et al., [2012](#bib.bib42))
    applied to computer vision tasks. In these suggestive visualizations (Zeiler and
    Fergus, [2014b](#bib.bib81)), the hidden layers are seen to correspond to abstract
    feature of the image, starting from simple edges (in lower layers) up to faces
    in the higher ones.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 有人认为，每一层学习其输入的更高级别的表示。这在应用于计算机视觉任务的卷积网络（Krizhevsky 等，[2012](#bib.bib42)）中尤为明显。在这些具有启发性的可视化（Zeiler
    和 Fergus，[2014b](#bib.bib81)）中，隐藏层被视为对应于图像的抽象特征，从简单的边缘（在较低层）到更高层的面孔。
- en: However, these embedding layers produce encoding functions and, thus, distributed
    representations that are not interpretable when applied to symbols. In fact, these
    distributed representations are not human-interpretable as dimensions are not
    clearly related to specific aggregations of symbols. Moreover, these embedding
    layers do not naturally provide decoders. Hence, this distributed representation
    is not decodable.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些嵌入层产生的编码函数，因此，当应用于符号时，这些分布式表示是不可解释的。事实上，这些分布式表示在维度与符号的具体聚合关系不明确时，无法被人类解释。此外，这些嵌入层自然不提供解码器。因此，这种分布式表示是不可解码的。
- en: 6 *Distributional* Representations as another side of the coin
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 *分布式* 表示的另一面
- en: '*Distributional* semantics is an important area of research in natural language
    processing that aims to describe meaning of words and sentences with vectorial
    representations (see (Turney and Pantel, [2010](#bib.bib68)) for a survey). These
    representations are called *distributional representations*.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '*分布式* 语义是自然语言处理中的一个重要研究领域，旨在通过向量表示描述词汇和句子的意义（参见（Turney 和 Pantel，[2010](#bib.bib68)）的综述）。这些表示被称为*分布式表示*。'
- en: It is a strange historical accident that two similar sounding names – *distributed*
    and *distributional* – have been given to two concepts that should not be confused
    for many. Maybe, this has happened because the two concepts are definitely related.
    We argue that distributional representation are nothing more than a subset of
    distributed representations, and in fact can be categorized neatly into the divisions
    presented in the previous section
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 一个奇怪的历史巧合是，两个发音相似的名称——*分布式* 和 *分布*——被赋予了两个不应混淆的概念。也许，这种情况发生是因为这两个概念确实相关。我们认为，分布式表示不过是分布表示的一个子集，实际上可以整齐地归入前一节中提出的分类。
- en: Distributional semantics is based on a famous slogan – *“you shall judge a word
    by the company it keeps”* (Firth, [1957](#bib.bib22)) – and on the *distributional
    hypothesis* (Harris, [1964](#bib.bib33)) – words have similar meaning if used
    in similar contexts, that is, words with the same or similar *distribution*. Hence,
    the name distributional as well as the core hypothesis comes from a linguistic
    rather than computer science background.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式语义基于一个著名的口号——*“你可以通过一个词所处的环境来判断它”*（Firth，[1957](#bib.bib22)）——以及*分布假设*（Harris，[1964](#bib.bib33)）——如果词汇在相似的上下文中使用，则具有相似的意义，即具有相同或相似的*分布*。因此，分布式这一名称以及核心假设源于语言学而非计算机科学背景。
- en: Distributional vectors represent words by describing information related to
    the contexts in which they appear. Put in this way it is apparent that a distributional
    representation *is* a specific case of a distributed representation, and the different
    name is only an indicator of the context in which this techniques originated.
    Representations for sentences are generally obtained combining vectors representing
    words.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式向量通过描述词汇出现的上下文信息来表示词汇。这样看来，分布式表示*是*分布表示的一个特定案例，不同的名称只是指示了这些技术起源的上下文。句子的表示通常是通过结合表示词汇的向量来获得的。
- en: 'Hence, distributional semantics is a special case of distributed representations
    with a restriction on what can be used as features in vector spaces: features
    represent a bit of contextual information. Then, the largest body of research
    is on what should be used to represent contexts and how it should be taken into
    account. Once this is decided, large matrices $X$ representing words in context
    are collected and, then, dimensionality reduction techniques are applied to have
    treatable and more discriminative vectors.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，分布语义学是分布式表示的一种特殊情况，其限制了可以在向量空间中作为特征使用的内容：特征代表了一些上下文信息。然后，最大的研究领域集中在应使用什么来表示上下文以及如何考虑这些上下文。一旦决定了这些内容，就会收集大量的矩阵$X$来表示上下文中的词汇，然后应用降维技术以获得可处理和更具辨别性的向量。
- en: In the rest of the section, we present how to build matrices representing words
    in context, we will shortly recap on how dimensionality reduction techniques have
    been used in distributional semantics, and, finally, we report on word2vec (Mikolov
    et al., [2013](#bib.bib49)), which is a novel distributional semantic techniques
    based on deep learning.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的其余部分，我们展示了如何构建表示上下文中的词汇的矩阵，我们将简要回顾一下降维技术在分布语义学中的应用，最后，我们将介绍word2vec（Mikolov
    et al., [2013](#bib.bib49)），这是一种基于深度学习的新型分布语义学技术。
- en: 6.1 Building distributional representations for words from a corpus
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 从语料库中构建词汇的分布式表示
- en: 'The major issue in distributional semantics is how to build distributional
    representations for words by observing word contexts in a collection of documents.
    In this section, we will describe these techniques using the example of the corpus
    in Table [1](#S6.T1 "Table 1 ‣ 6.1 Building distributional representations for
    words from a corpus ‣ 6 Distributional Representations as another side of the
    coin ‣ Symbolic, Distributed and Distributional Representations for Natural Language
    Processing in the Era of Deep Learning: a Survey").'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '分布语义学中的主要问题是如何通过观察文档集合中的词汇上下文来构建词汇的分布式表示。在本节中，我们将以表[1](#S6.T1 "Table 1 ‣ 6.1
    Building distributional representations for words from a corpus ‣ 6 Distributional
    Representations as another side of the coin ‣ Symbolic, Distributed and Distributional
    Representations for Natural Language Processing in the Era of Deep Learning: a
    Survey")中的语料库为例来描述这些技术。'
- en: '| $s_{1}$ | *a cat catches a mouse* |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| $s_{1}$ | *一只猫抓住了一只老鼠* |'
- en: '| $s_{2}$ | *a dog eats a mouse* |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| $s_{2}$ | *一只狗吃了一只老鼠* |'
- en: '| $s_{3}$ | *a dog catches a cat* |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| $s_{3}$ | *一只狗抓住了一只猫* |'
- en: 'Table 1: A very small corpus'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：一个非常小的语料库
- en: A first and simple distributional semantic representations of words is given
    by word vs. document matrices as those typical in information retrieval (Salton,
    [1989](#bib.bib61)). Word context are represented by document indexes. Then, words
    are similar if these words similarly appear in documents. This is generally referred
    as *topical similarity* (Landauer and Dumais, [1997](#bib.bib43)) as words belonging
    to the same topic tend to be more similar. An example of this approach is given
    by the matrix in Eq. LABEL:first_distributional_representation. In fact, this
    matrix is already a distributional and distributed representation for words which
    are represented as vectors in rows.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 词汇的首个简单的分布语义表示是通过词汇与文档矩阵来实现的，这些矩阵在信息检索中很常见（Salton, [1989](#bib.bib61)）。词汇上下文通过文档索引来表示。然后，如果这些词汇在文档中出现的方式相似，那么这些词汇就被认为是相似的。这通常被称为*主题相似性*（Landauer
    and Dumais, [1997](#bib.bib43)），因为属于同一主题的词汇往往更相似。该方法的一个示例由公式 LABEL:first_distributional_representation
    中的矩阵给出。实际上，这个矩阵已经是一个分布式和分布式的词汇表示，其中词汇在行中作为向量表示。
- en: A second strategy to build distributional representations for words is to build
    word vs. contextual feature matrices. These contextual features represent *proxies*
    for semantic attributes of modeled words (Baroni and Lenci, [2010](#bib.bib5)).
    For example, contexts of the word *dog* will somehow have relation with the fact
    that a dog has four legs, barks, eats, and so on. In this case, these vectors
    capture a similarity that is more related to a co-hyponymy, that is, words sharing
    similar attributes are similar. For example, *dog* is more similar to *cat* than
    to *car* as *dog* and *cat* share more attributes than *dog* and *car*. This is
    often referred as *attributional similarity* (Turney, [2006](#bib.bib67)).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 构建词的分布式表示的第二种策略是建立词与上下文特征矩阵。这些上下文特征代表了建模词的*代理*语义属性（Baroni和Lenci，[2010](#bib.bib5)）。例如，*dog*（狗）的上下文将与狗有四条腿、吠叫、吃东西等事实有关。在这种情况下，这些向量捕捉到一种更相关的相似性，即共上位词性，即共享相似属性的词是相似的。例如，*dog*（狗）与*cat*（猫）的相似性要高于与*car*（车）的相似性，因为*dog*和*cat*共享的属性比*dog*和*car*更多。这通常被称为*属性相似性*（Turney，[2006](#bib.bib67)）。
- en: 'A simple example of this second strategy are word-to-word matrices obtained
    by observing n-word windows of target words. For example, a word-to-word matrix
    obtained for the corpus in Table [1](#S6.T1 "Table 1 ‣ 6.1 Building distributional
    representations for words from a corpus ‣ 6 Distributional Representations as
    another side of the coin ‣ Symbolic, Distributed and Distributional Representations
    for Natural Language Processing in the Era of Deep Learning: a Survey") by considering
    a 1-word window is the following:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这第二种策略的一个简单示例是通过观察目标词的n词窗口获得的词对词矩阵。例如，考虑一个1词窗口，对表格[1](#S6.T1 "表1 ‣ 6.1 从语料库构建词的分布式表示
    ‣ 6 分布式表示作为另一面 ‣ 深度学习时代自然语言处理中的符号、分布式和分布式表示：综述")中的语料库获得的词对词矩阵如下：
- en: '|  | <math id="S6.E2.m1.1" class="ltx_Math" alttext="X=\hbox{}\vbox{\kern 0.86108pt\hbox{$\kern
    0.0pt\kern 2.5pt\kern-5.0pt\left(\kern 0.0pt\kern-2.5pt\kern-6.66669pt\vbox{\kern-0.86108pt\vbox{\vbox{
    \halign{\kern\arraycolsep\hfil\@arstrut$\kbcolstyle#$\hfil\kern\arraycolsep&amp;'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math id="S6.E2.m1.1" class="ltx_Math" alttext="X=\hbox{}\vbox{\kern 0.86108pt\hbox{$\kern
    0.0pt\kern 2.5pt\kern-5.0pt\left(\kern 0.0pt\kern-2.5pt\kern-6.66669pt\vbox{\kern-0.86108pt\vbox{\vbox{
    \halign{\kern\arraycolsep\hfil\@arstrut$\kbcolstyle#$\hfil\kern\arraycolsep&amp;'
- en: \kern\arraycolsep\hfil$\@kbrowstyle#$\ifkbalignright\relax\else\hfil\fi\kern\arraycolsep&amp;&amp;
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: \kern\arraycolsep\hfil$\@kbrowstyle#$\ifkbalignright\relax\else\hfil\fi\kern\arraycolsep&amp;&amp;
- en: \kern\arraycolsep\hfil$\@kbrowstyle#$\ifkbalignright\relax\else\hfil\fi\kern\arraycolsep\cr
    5.0pt\hfil\@arstrut$\scriptstyle$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    a$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle cat$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    dog$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle mouse$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    catches$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle eats\\a$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 1$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    2$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 2$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    2$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 2\\cat$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    2$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    1$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0\\dog$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    2$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    1$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 1\\mouse$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    2$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0\\catches$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    2$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 1$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    1$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0\\eats$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    1$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    1$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&amp;5.0pt\hfil$\scriptstyle 0\\$\hfil\kern 5.0pt\crcr}}}}\right)$}}"
    display="block"><semantics id="S6.E2.m1.1a"><mrow id="S6.E2.m1.1.2" xref="S6.E2.m1.1.2.cmml"><mi
    id="S6.E2.m1.1.2.2" xref="S6.E2.m1.1.2.2.cmml">X</mi><mo id="S6.E2.m1.1.2.1" xref="S6.E2.m1.1.2.1.cmml">=</mo>
    <mrow id="S6.E2.m1.1.1" xref="S6.E2.m1.1.1hz.cmml"><mtext id="S6.E2.m1.1.1b" xref="S6.E2.m1.1.1hz.cmml"><xmath
    xmlns="http://dlmf.nist.gov/LaTeXML" id="S6.E2.m1.1.1f" fragid="S6.E2.m1.1.1.1.1.m1.43nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmdual id="S6.E2.m1.1.1g" fragid="S6.E2.m1.1.1.1.1.m1.43.44nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmref idref="S6.E2.m1.1.1.1.1.m1.43.43nest" id="S6.E2.m1.1.1h"
    fragid="S6.E2.m1.1.1.1.1.m1.43.44.1nest" xref="S6.E2.m1.1.1hz.cmml"><xmwrap id="S6.E2.m1.1.1i"
    fragid="S6.E2.m1.1.1.1.1.m1.43.44.2nest" xref="S6.E2.m1.1.1hz.cmml"><xmtok role="OPEN"
    stretchy="true" id="S6.E2.m1.1.1j" fragid="S6.E2.m1.1.1.1.1.m1.43.44.2.1nest"
    xref="S6.E2.m1.1.1hz.cmml">(</xmtok><xmarray vattach="bottom" id="S6.E2.m1.1.1k"
    fragid="S6.E2.m1.1.1.1.1.m1.43.43nest" xref="S6.E2.m1.1.1hz.cmml"><xmrow id="S6.E2.m1.1.1l"
    fragid="S6.E2.m1.1.1.1.1.m1.43.43.43.43.43.43.43nest" xref="S6.E2.m1.1.1hz.cmml"><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1m" fragid="S6.E2.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1n" fragid="S6.E2.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1o" fragid="S6.E2.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.2nest"
    xref="S6.E2.m1.1.1hz.cmml">\@arstrut</xmtext></xmtext></xmcell><xmcell align="left"
    class="ltx_nopad_r" id="S6.E2.m1.1.1r" fragid="S6.E2.m1.1.1.1.1.m1.2.2.2.2.2.2.2.2nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1s" fragid="S6.E2.m1.1.1.1.1.m1.2.2.2.2.2.2.2.2.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1t" fragid="S6.E2.m1.1.1.1.1.m1.2.2.2.2.2.2.2.2.2nest" xref="S6.E2.m1.1.1hz.cmml">a</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1v" fragid="S6.E2.m1.1.1.1.1.m1.3.3.3.3.3.3.3.3nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1w" fragid="S6.E2.m1.1.1.1.1.m1.3.3.3.3.3.3.3.3.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1x" fragid="S6.E2.m1.1.1.1.1.m1.3.3.3.3.3.3.3.3.2nest" xref="S6.E2.m1.1.1hz.cmml">c</xmtok><xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1y" fragid="S6.E2.m1.1.1.1.1.m1.3.3.3.3.3.3.3.3.3nest"
    xref="S6.E2.m1.1.1hz.cmml">a</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1z" fragid="S6.E2.m1.1.1.1.1.m1.3.3.3.3.3.3.3.3.4nest" xref="S6.E2.m1.1.1hz.cmml">t</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ab" fragid="S6.E2.m1.1.1.1.1.m1.4.4.4.4.4.4.4.4nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1ac" fragid="S6.E2.m1.1.1.1.1.m1.4.4.4.4.4.4.4.4.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1ad" fragid="S6.E2.m1.1.1.1.1.m1.4.4.4.4.4.4.4.4.2nest" xref="S6.E2.m1.1.1hz.cmml">d</xmtok><xmtok
    role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1ae" fragid="S6.E2.m1.1.1.1.1.m1.4.4.4.4.4.4.4.4.3nest"
    xref="S6.E2.m1.1.1hz.cmml">o</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1af" fragid="S6.E2.m1.1.1.1.1.m1.4.4.4.4.4.4.4.4.4nest" xref="S6.E2.m1.1.1hz.cmml">g</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ah" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1ai" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1aj" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5.2nest" xref="S6.E2.m1.1.1hz.cmml">m</xmtok><xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1ak" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5.3nest"
    xref="S6.E2.m1.1.1hz.cmml">o</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1al" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5.4nest" xref="S6.E2.m1.1.1hz.cmml">u</xmtok><xmtok
    role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1am" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5.5nest"
    xref="S6.E2.m1.1.1hz.cmml">s</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1an" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5.6nest" xref="S6.E2.m1.1.1hz.cmml">e</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ap" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1aq" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1ar" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.2nest" xref="S6.E2.m1.1.1hz.cmml">c</xmtok><xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1as" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.3nest"
    xref="S6.E2.m1.1.1hz.cmml">a</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1at" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.4nest" xref="S6.E2.m1.1.1hz.cmml">t</xmtok><xmtok
    role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1au" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.5nest"
    xref="S6.E2.m1.1.1hz.cmml">c</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1av" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.6nest" xref="S6.E2.m1.1.1hz.cmml">h</xmtok><xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1aw" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.7nest"
    xref="S6.E2.m1.1.1hz.cmml">e</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1ax" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.8nest" xref="S6.E2.m1.1.1hz.cmml">s</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1az" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1ba" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1bb" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7.2nest" xref="S6.E2.m1.1.1hz.cmml">e</xmtok><xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1bc" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7.3nest"
    xref="S6.E2.m1.1.1hz.cmml">a</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1bd" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7.4nest" xref="S6.E2.m1.1.1hz.cmml">t</xmtok><xmtok
    role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1be" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7.5nest"
    xref="S6.E2.m1.1.1hz.cmml">s</xmtok>\\<xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1bg" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7.7nest" xref="S6.E2.m1.1.1hz.cmml">a</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1bi" fragid="S6.E2.m1.1.1.1.1.m1.8.8.8.8.8.8.8.8nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1bj" fragid="S6.E2.m1.1.1.1.1.m1.8.8.8.8.8.8.8.8.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1bk"
    fragid="S6.E2.m1.1.1.1.1.m1.8.8.8.8.8.8.8.8.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1bm" fragid="S6.E2.m1.1.1.1.1.m1.9.9.9.9.9.9.9.9nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1bn" fragid="S6.E2.m1.1.1.1.1.m1.9.9.9.9.9.9.9.9.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1bo"
    fragid="S6.E2.m1.1.1.1.1.m1.9.9.9.9.9.9.9.9.2nest" xref="S6.E2.m1.1.1hz.cmml">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1bq" fragid="S6.E2.m1.1.1.1.1.m1.10.10.10.10.10.10.10.10nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1br" fragid="S6.E2.m1.1.1.1.1.m1.10.10.10.10.10.10.10.10.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1bs"
    fragid="S6.E2.m1.1.1.1.1.m1.10.10.10.10.10.10.10.10.2nest" xref="S6.E2.m1.1.1hz.cmml">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1bu" fragid="S6.E2.m1.1.1.1.1.m1.11.11.11.11.11.11.11.11nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1bv" fragid="S6.E2.m1.1.1.1.1.m1.11.11.11.11.11.11.11.11.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1bw"
    fragid="S6.E2.m1.1.1.1.1.m1.11.11.11.11.11.11.11.11.2nest" xref="S6.E2.m1.1.1hz.cmml">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1by" fragid="S6.E2.m1.1.1.1.1.m1.12.12.12.12.12.12.12.12nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1bz" fragid="S6.E2.m1.1.1.1.1.m1.12.12.12.12.12.12.12.12.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ca"
    fragid="S6.E2.m1.1.1.1.1.m1.12.12.12.12.12.12.12.12.2nest" xref="S6.E2.m1.1.1hz.cmml">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1cc" fragid="S6.E2.m1.1.1.1.1.m1.13.13.13.13.13.13.13.13nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1cd" fragid="S6.E2.m1.1.1.1.1.m1.13.13.13.13.13.13.13.13.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ce"
    fragid="S6.E2.m1.1.1.1.1.m1.13.13.13.13.13.13.13.13.2nest" xref="S6.E2.m1.1.1hz.cmml">2</xmtok>\\<xmtok
    role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1cg" fragid="S6.E2.m1.1.1.1.1.m1.13.13.13.13.13.13.13.13.4nest"
    xref="S6.E2.m1.1.1hz.cmml">c</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1ch" fragid="S6.E2.m1.1.1.1.1.m1.13.13.13.13.13.13.13.13.5nest"
    xref="S6.E2.m1.1.1hz.cmml">a</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1ci" fragid="S6.E2.m1.1.1.1.1.m1.13.13.13.13.13.13.13.13.6nest"
    xref="S6.E2.m1.1.1hz.cmml">t</xmtok></xmtext></xmcell><xmcell align="left" class="ltx_nopad_l
    ltx_nopad_r" id="S6.E2.m1.1.1ck" fragid="S6.E2.m1.1.1.1.1.m1.14.14.14.14.14.14.14.14nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1cl" fragid="S6.E2.m1.1.1.1.1.m1.14.14.14.14.14.14.14.14.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1cm"
    fragid="S6.E2.m1.1.1.1.1.m1.14.14.14.14.14.14.14.14.2nest" xref="S6.E2.m1.1.1hz.cmml">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1co" fragid="S6.E2.m1.1.1.1.1.m1.15.15.15.15.15.15.15.15nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1cp" fragid="S6.E2.m1.1.1.1.1.m1.15.15.15.15.15.15.15.15.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1cq"
    fragid="S6.E2.m1.1.1.1.1.m1.15.15.15.15.15.15.15.15.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1cs" fragid="S6.E2.m1.1.1.1.1.m1.16.16.16.16.16.16.16.16nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1ct" fragid="S6.E2.m1.1.1.1.1.m1.16.16.16.16.16.16.16.16.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1cu"
    fragid="S6.E2.m1.1.1.1.1.m1.16.16.16.16.16.16.16.16.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1cw" fragid="S6.E2.m1.1.1.1.1.m1.17.17.17.17.17.17.17.17nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1cx" fragid="S6.E2.m1.1.1.1.1.m1.17.17.17.17.17.17.17.17.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1cy"
    fragid="S6.E2.m1.1.1.1.1.m1.17.17.17.17.17.17.17.17.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1da" fragid="S6.E2.m1.1.1.1.1.m1.18.18.18.18.18.18.18.18nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1db" fragid="S6.E2.m1.1.1.1.1.m1.18.18.18.18.18.18.18.18.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1dc"
    fragid="S6.E2.m1.1.1.1.1.m1.18.18.18.18.18.18.18.18.2nest" xref="S6.E2.m1.1.1hz.cmml">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1de" fragid="S6.E2.m1.1.1.1.1.m1.19.19.19.19.19.19.19.19nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1df" fragid="S6.E2.m1.1.1.1.1.m1.19.19.19.19.19.19.19.19.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1dg"
    fragid="S6.E2.m1.1.1.1.1.m1.19.19.19.19.19.19.19.19.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok>\\<xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1di" fragid="S6.E2.m1.1.1.1.1.m1.19.19.19.19.19.19.19.19.4nest"
    xref="S6.E2.m1.1.1hz.cmml">d</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1dj" fragid="S6.E2.m1.1.1.1.1.m1.19.19.19.19.19.19.19.19.5nest"
    xref="S6.E2.m1.1.1hz.cmml">o</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1dk" fragid="S6.E2.m1.1.1.1.1.m1.19.19.19.19.19.19.19.19.6nest"
    xref="S6.E2.m1.1.1hz.cmml">g</xmtok></xmtext></xmcell><xmcell align="left" class="ltx_nopad_l
    ltx_nopad_r" id="S6.E2.m1.1.1dm" fragid="S6.E2.m1.1.1.1.1.m1.20.20.20.20.20.20.20.20nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1dn" fragid="S6.E2.m1.1.1.1.1.m1.20.20.20.20.20.20.20.20.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1do"
    fragid="S6.E2.m1.1.1.1.1.m1.20.20.20.20.20.20.20.20.2nest" xref="S6.E2.m1.1.1hz.cmml">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1dq" fragid="S6.E2.m1.1.1.1.1.m1.21.21.21.21.21.21.21.21nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1dr" fragid="S6.E2.m1.1.1.1.1.m1.21.21.21.21.21.21.21.21.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ds"
    fragid="S6.E2.m1.1.1.1.1.m1.21.21.21.21.21.21.21.21.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1du" fragid="S6.E2.m1.1.1.1.1.m1.22.22.22.22.22.22.22.22nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1dv" fragid="S6.E2.m1.1.1.1.1.m1.22.22.22.22.22.22.22.22.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1dw"
    fragid="S6.E2.m1.1.1.1.1.m1.22.22.22.22.22.22.22.22.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1dy" fragid="S6.E2.m1.1.1.1.1.m1.23.23.23.23.23.23.23.23nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1dz" fragid="S6.E2.m1.1.1.1.1.m1.23.23.23.23.23.23.23.23.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ea"
    fragid="S6.E2.m1.1.1.1.1.m1.23.23.23.23.23.23.23.23.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ec" fragid="S6.E2.m1.1.1.1.1.m1.24.24.24.24.24.24.24.24nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1ed" fragid="S6.E2.m1.1.1.1.1.m1.24.24.24.24.24.24.24.24.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ee"
    fragid="S6.E2.m1.1.1.1.1.m1.24.24.24.24.24.24.24.24.2nest" xref="S6.E2.m1.1.1hz.cmml">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1eg" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1eh" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ei"
    fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.2nest" xref="S6.E2.m1.1.1hz.cmml">1</xmtok>\\<xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1ek" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.4nest"
    xref="S6.E2.m1.1.1hz.cmml">m</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1el" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.5nest"
    xref="S6.E2.m1.1.1hz.cmml">o</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1em" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.6nest"
    xref="S6.E2.m1.1.1hz.cmml">u</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1en" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.7nest"
    xref="S6.E2.m1.1.1hz.cmml">s</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1eo" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.8nest"
    xref="S6.E2.m1.1.1hz.cmml">e</xmtok></xmtext></xmcell><xmcell align="left" class="ltx_nopad_l
    ltx_nopad_r" id="S6.E2.m1.1.1eq" fragid="S6.E2.m1.1.1.1.1.m1.26.26.26.26.26.26.26.26nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1er" fragid="S6.E2.m1.1.1.1.1.m1.26.26.26.26.26.26.26.26.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1es"
    fragid="S6.E2.m1.1.1.1.1.m1.26.26.26.26.26.26.26.26.2nest" xref="S6.E2.m1.1.1hz.cmml">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1eu" fragid="S6.E2.m1.1.1.1.1.m1.27.27.27.27.27.27.27.27nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1ev" fragid="S6.E2.m1.1.1.1.1.m1.27.27.27.27.27.27.27.27.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ew"
    fragid="S6.E2.m1.1.1.1.1.m1.27.27.27.27.27.27.27.27.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ey" fragid="S6.E2.m1.1.1.1.1.m1.28.28.28.28.28.28.28.28nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1ez" fragid="S6.E2.m1.1.1.1.1.m1.28.28.28.28.28.28.28.28.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1fa"
    fragid="S6.E2.m1.1.1.1.1.m1.28.28.28.28.28.28.28.28.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1fc" fragid="S6.E2.m1.1.1.1.1.m1.29.29.29.29.29.29.29.29nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1fd" fragid="S6.E2.m1.1.1.1.1.m1.29.29.29.29.29.29.29.29.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1fe"
    fragid="S6.E2.m1.1.1.1.1.m1.29.29.29.29.29.29.29.29.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1fg" fragid="S6.E2.m1.1.1.1.1.m1.30.30.30.30.30.30.30.30nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1fh" fragid="S6.E2.m1.1.1.1.1.m1.30.30.30.30.30.30.30.30.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1fi"
    fragid="S6.E2.m1.1.1.1.1.m1.30.30.30.30.30.30.30.30.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1fk" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1fl" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1fm"
    fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok>\\<xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1fo" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.4nest"
    xref="S6.E2.m1.1.1hz.cmml">c</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1fp" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.5nest"
    xref="S6.E2.m1.1.1hz.cmml">a</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1fq" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.6nest"
    xref="S6.E2.m1.1.1hz.cmml">t</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1fr" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.7nest"
    xref="S6.E2.m1.1.1hz.cmml">c</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1fs" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.8nest"
    xref="S6.E2.m1.1.1hz.cmml">h</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1ft" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.9nest"
    xref="S6.E2.m1.1.1hz.cmml">e</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1fu" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.10nest"
    xref="S6.E2.m1.1.1hz.cmml">s</xmtok></xmtext></xmcell><xmcell align="left" class="ltx_nopad_l
    ltx_nopad_r" id="S6.E2.m1.1.1fw" fragid="S6.E2.m1.1.1.1.1.m1.32.32.32.32.32.32.32.32nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1fx" fragid="S6.E2.m1.1.1.1.1.m1.32.32.32.32.32.32.32.32.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1fy"
    fragid="S6.E2.m1.1.1.1.1.m1.32.32.32.32.32.32.32.32.2nest" xref="S6.E2.m1.1.1hz.cmml">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ga" fragid="S6.E2.m1.1.1.1.1.m1.33.33.33.33.33.33.33.33nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1gb" fragid="S6.E2.m1.1.1.1.1.m1.33.33.33.33.33.33.33.33.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1gc"
    fragid="S6.E2.m1.1.1.1.1.m1.33.33.33.33.33.33.33.33.2nest" xref="S6.E2.m1.1.1hz.cmml">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ge" fragid="S6.E2.m1.1.1.1.1.m1.34.34.34.34.34.34.34.34nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1gf" fragid="S6.E2.m1.1.1.1.1.m1.34.34.34.34.34.34.34.34.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1gg"
    fragid="S6.E2.m1.1.1.1.1.m1.34.34.34.34.34.34.34.34.2nest" xref="S6.E2.m1.1.1hz.cmml">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1gi" fragid="S6.E2.m1.1.1.1.1.m1.35.35.35.35.35.35.35.35nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1gj" fragid="S6.E2.m1.1.1.1.1.m1.35.35.35.35.35.35.35.35.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1gk"
    fragid="S6.E2.m1.1.1.1.1.m1.35.35.35.35.35.35.35.35.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1gm" fragid="S6.E2.m1.1.1.1.1.m1.36.36.36.36.36.36.36.36nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1gn" fragid="S6.E2.m1.1.1.1.1.m1.36.36.36.36.36.36.36.36.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1go"
    fragid="S6.E2.m1.1.1.1.1.m1.36.36.36.36.36.36.36.36.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1gq" fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1gr" fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1gs"
    fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok>\\<xmtok
    role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1gu" fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37.4nest"
    xref="S6.E2.m1.1.1hz.cmml">e</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1gv" fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37.5nest"
    xref="S6.E2.m1.1.1hz.cmml">a</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1gw" fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37.6nest"
    xref="S6.E2.m1.1.1hz.cmml">t</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1gx" fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37.7nest"
    xref="S6.E2.m1.1.1hz.cmml">s</xmtok></xmtext></xmcell><xmcell align="left" class="ltx_nopad_l
    ltx_nopad_r" id="S6.E2.m1.1.1gz" fragid="S6.E2.m1.1.1.1.1.m1.38.38.38.38.38.38.38.38nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1ha" fragid="S6.E2.m1.1.1.1.1.m1.38.38.38.38.38.38.38.38.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1hb"
    fragid="S6.E2.m1.1.1.1.1.m1.38.38.38.38.38.38.38.38.2nest" xref="S6.E2.m1.1.1hz.cmml">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1hd" fragid="S6.E2.m1.1.1.1.1.m1.39.39.39.39.39.39.39.39nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1he" fragid="S6.E2.m1.1.1.1.1.m1.39.39.39.39.39.39.39.39.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1hf"
    fragid="S6.E2.m1.1.1.1.1.m1.39.39.39.39.39.39.39.39.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1hh" fragid="S6.E2.m1.1.1.1.1.m1.40.40.40.40.40.40.40.40nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1hi" fragid="S6.E2.m1.1.1.1.1.m1.40.40.40.40.40.40.40.40.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1hj"
    fragid="S6.E2.m1.1.1.1.1.m1.40.40.40.40.40.40.40.40.2nest" xref="S6.E2.m1.1.1hz.cmml">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1hl" fragid="S6.E2.m1.1.1.1.1.m1.41.41.41.41.41.41.41.41nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1hm" fragid="S6.E2.m1.1.1.1.1.m1.41.41.41.41.41.41.41.41.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1hn"
    fragid="S6.E2.m1.1.1.1.1.m1.41.41.41.41.41.41.41.41.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1hp" fragid="S6.E2.m1.1.1.1.1.m1.42.42.42.42.42.42.42.42nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1hq" fragid="S6.E2.m1.1.1.1.1.m1.42.42.42.42.42.42.42.42.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1hr"
    fragid="S6.E2.m1.1.1.1.1.m1.42.42.42.42.42.42.42.42.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ht" fragid="S6.E2.m1.1.1.1.1.m1.43.43.43.43.43.43.43.43nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtext id="S6.E2.m1.1.1hu" fragid="S6.E2.m1.1.1.1.1.m1.43.43.43.43.43.43.43.43.1nest"
    xref="S6.E2.m1.1.1hz.cmml"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1hv"
    fragid="S6.E2.m1.1.1.1.1.m1.43.43.43.43.43.43.43.43.2nest" xref="S6.E2.m1.1.1hz.cmml">0</xmtok>\\</xmtext></xmcell></xmrow></xmarray><xmtok
    role="CLOSE" stretchy="true" id="S6.E2.m1.1.1hy" fragid="S6.E2.m1.1.1.1.1.m1.43.44.2.2nest"
    xref="S6.E2.m1.1.1hz.cmml">)</xmtok></xmwrap></xmref></xmdual></xmath></mtext></mrow></mrow>
    <annotation-xml encoding="MathML-Content" id="S6.E2.m1.1b"><apply id="S6.E2.m1.1.2.cmml"
    xref="S6.E2.m1.1.2"><ci id="S6.E2.m1.1.2.2.cmml" xref="S6.E2.m1.1.2.2">𝑋</ci>
    <ci id="S6.E2.m1.1.1hz.cmml" xref="S6.E2.m1.1.1"><mrow id="S6.E2.m1.1.1.cmml"
    xref="S6.E2.m1.1.1"><mtext id="S6.E2.m1.1.1b.cmml" xref="S6.E2.m1.1.1"><xmath
    xmlns="http://dlmf.nist.gov/LaTeXML" id="S6.E2.m1.1.1f.cmml" fragid="S6.E2.m1.1.1.1.1.m1.43anest"
    xref="S6.E2.m1.1.1"><xmdual id="S6.E2.m1.1.1g.cmml" fragid="S6.E2.m1.1.1.1.1.m1.43.44anest"
    xref="S6.E2.m1.1.1"><xmref idref="S6.E2.m1.1.1.1.1.m1.43.43anest" id="S6.E2.m1.1.1h.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.43.44.1anest" xref="S6.E2.m1.1.1"><xmwrap id="S6.E2.m1.1.1i.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.43.44.2anest" xref="S6.E2.m1.1.1"><xmtok role="OPEN"
    stretchy="true" id="S6.E2.m1.1.1j.cmml" fragid="S6.E2.m1.1.1.1.1.m1.43.44.2.1anest"
    xref="S6.E2.m1.1.1">(</xmtok><xmarray vattach="bottom" id="S6.E2.m1.1.1k.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.43.43anest" xref="S6.E2.m1.1.1"><xmrow id="S6.E2.m1.1.1l.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.43.43.43.43.43.43.43anest" xref="S6.E2.m1.1.1"><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1m.cmml" fragid="S6.E2.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1n.cmml" fragid="S6.E2.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.1anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1o.cmml" fragid="S6.E2.m1.1.1.1.1.m1.1.1.1.1.1.1.1.1.2anest"
    xref="S6.E2.m1.1.1">\@arstrut</xmtext></xmtext></xmcell><xmcell align="left" class="ltx_nopad_r"
    id="S6.E2.m1.1.1r.cmml" fragid="S6.E2.m1.1.1.1.1.m1.2.2.2.2.2.2.2.2anest" xref="S6.E2.m1.1.1"><xmtext
    id="S6.E2.m1.1.1s.cmml" fragid="S6.E2.m1.1.1.1.1.m1.2.2.2.2.2.2.2.2.1anest" xref="S6.E2.m1.1.1"><xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1t.cmml" fragid="S6.E2.m1.1.1.1.1.m1.2.2.2.2.2.2.2.2.2anest"
    xref="S6.E2.m1.1.1">a</xmtok></xmtext></xmcell><xmcell align="left" class="ltx_nopad_l
    ltx_nopad_r" id="S6.E2.m1.1.1v.cmml" fragid="S6.E2.m1.1.1.1.1.m1.3.3.3.3.3.3.3.3anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1w.cmml" fragid="S6.E2.m1.1.1.1.1.m1.3.3.3.3.3.3.3.3.1anest"
    xref="S6.E2.m1.1.1"><xmtok role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1x.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.3.3.3.3.3.3.3.3.2anest" xref="S6.E2.m1.1.1">c</xmtok><xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1y.cmml" fragid="S6.E2.m1.1.1.1.1.m1.3.3.3.3.3.3.3.3.3anest"
    xref="S6.E2.m1.1.1">a</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1z.cmml" fragid="S6.E2.m1.1.1.1.1.m1.3.3.3.3.3.3.3.3.4anest" xref="S6.E2.m1.1.1">t</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ab.cmml" fragid="S6.E2.m1.1.1.1.1.m1.4.4.4.4.4.4.4.4anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1ac.cmml" fragid="S6.E2.m1.1.1.1.1.m1.4.4.4.4.4.4.4.4.1anest"
    xref="S6.E2.m1.1.1"><xmtok role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1ad.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.4.4.4.4.4.4.4.4.2anest" xref="S6.E2.m1.1.1">d</xmtok><xmtok
    role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1ae.cmml" fragid="S6.E2.m1.1.1.1.1.m1.4.4.4.4.4.4.4.4.3anest"
    xref="S6.E2.m1.1.1">o</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1af.cmml" fragid="S6.E2.m1.1.1.1.1.m1.4.4.4.4.4.4.4.4.4anest" xref="S6.E2.m1.1.1">g</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ah.cmml" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1ai.cmml" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5.1anest"
    xref="S6.E2.m1.1.1"><xmtok role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1aj.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5.2anest" xref="S6.E2.m1.1.1">m</xmtok><xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1ak.cmml" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5.3anest"
    xref="S6.E2.m1.1.1">o</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1al.cmml" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5.4anest" xref="S6.E2.m1.1.1">u</xmtok><xmtok
    role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1am.cmml" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5.5anest"
    xref="S6.E2.m1.1.1">s</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1an.cmml" fragid="S6.E2.m1.1.1.1.1.m1.5.5.5.5.5.5.5.5.6anest" xref="S6.E2.m1.1.1">e</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ap.cmml" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1aq.cmml" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.1anest"
    xref="S6.E2.m1.1.1"><xmtok role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1ar.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.2anest" xref="S6.E2.m1.1.1">c</xmtok><xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1as.cmml" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.3anest"
    xref="S6.E2.m1.1.1">a</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1at.cmml" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.4anest" xref="S6.E2.m1.1.1">t</xmtok><xmtok
    role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1au.cmml" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.5anest"
    xref="S6.E2.m1.1.1">c</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1av.cmml" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.6anest" xref="S6.E2.m1.1.1">h</xmtok><xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1aw.cmml" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.7anest"
    xref="S6.E2.m1.1.1">e</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1ax.cmml" fragid="S6.E2.m1.1.1.1.1.m1.6.6.6.6.6.6.6.6.8anest" xref="S6.E2.m1.1.1">s</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1az.cmml" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1ba.cmml" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7.1anest"
    xref="S6.E2.m1.1.1"><xmtok role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1bb.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7.2anest" xref="S6.E2.m1.1.1">e</xmtok><xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1bc.cmml" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7.3anest"
    xref="S6.E2.m1.1.1">a</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1bd.cmml" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7.4anest" xref="S6.E2.m1.1.1">t</xmtok><xmtok
    role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1be.cmml" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7.5anest"
    xref="S6.E2.m1.1.1">s</xmtok>\\<xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1bg.cmml" fragid="S6.E2.m1.1.1.1.1.m1.7.7.7.7.7.7.7.7.7anest" xref="S6.E2.m1.1.1">a</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1bi.cmml" fragid="S6.E2.m1.1.1.1.1.m1.8.8.8.8.8.8.8.8anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1bj.cmml" fragid="S6.E2.m1.1.1.1.1.m1.8.8.8.8.8.8.8.8.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1bk.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.8.8.8.8.8.8.8.8.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1bm.cmml" fragid="S6.E2.m1.1.1.1.1.m1.9.9.9.9.9.9.9.9anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1bn.cmml" fragid="S6.E2.m1.1.1.1.1.m1.9.9.9.9.9.9.9.9.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1bo.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.9.9.9.9.9.9.9.9.2anest" xref="S6.E2.m1.1.1">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1bq.cmml" fragid="S6.E2.m1.1.1.1.1.m1.10.10.10.10.10.10.10.10anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1br.cmml" fragid="S6.E2.m1.1.1.1.1.m1.10.10.10.10.10.10.10.10.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1bs.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.10.10.10.10.10.10.10.10.2anest" xref="S6.E2.m1.1.1">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1bu.cmml" fragid="S6.E2.m1.1.1.1.1.m1.11.11.11.11.11.11.11.11anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1bv.cmml" fragid="S6.E2.m1.1.1.1.1.m1.11.11.11.11.11.11.11.11.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1bw.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.11.11.11.11.11.11.11.11.2anest" xref="S6.E2.m1.1.1">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1by.cmml" fragid="S6.E2.m1.1.1.1.1.m1.12.12.12.12.12.12.12.12anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1bz.cmml" fragid="S6.E2.m1.1.1.1.1.m1.12.12.12.12.12.12.12.12.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ca.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.12.12.12.12.12.12.12.12.2anest" xref="S6.E2.m1.1.1">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1cc.cmml" fragid="S6.E2.m1.1.1.1.1.m1.13.13.13.13.13.13.13.13anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1cd.cmml" fragid="S6.E2.m1.1.1.1.1.m1.13.13.13.13.13.13.13.13.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ce.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.13.13.13.13.13.13.13.13.2anest" xref="S6.E2.m1.1.1">2</xmtok>\\<xmtok
    role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1cg.cmml" fragid="S6.E2.m1.1.1.1.1.m1.13.13.13.13.13.13.13.13.4anest"
    xref="S6.E2.m1.1.1">c</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1ch.cmml" fragid="S6.E2.m1.1.1.1.1.m1.13.13.13.13.13.13.13.13.5anest"
    xref="S6.E2.m1.1.1">a</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1ci.cmml" fragid="S6.E2.m1.1.1.1.1.m1.13.13.13.13.13.13.13.13.6anest"
    xref="S6.E2.m1.1.1">t</xmtok></xmtext></xmcell><xmcell align="left" class="ltx_nopad_l
    ltx_nopad_r" id="S6.E2.m1.1.1ck.cmml" fragid="S6.E2.m1.1.1.1.1.m1.14.14.14.14.14.14.14.14anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1cl.cmml" fragid="S6.E2.m1.1.1.1.1.m1.14.14.14.14.14.14.14.14.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1cm.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.14.14.14.14.14.14.14.14.2anest" xref="S6.E2.m1.1.1">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1co.cmml" fragid="S6.E2.m1.1.1.1.1.m1.15.15.15.15.15.15.15.15anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1cp.cmml" fragid="S6.E2.m1.1.1.1.1.m1.15.15.15.15.15.15.15.15.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1cq.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.15.15.15.15.15.15.15.15.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1cs.cmml" fragid="S6.E2.m1.1.1.1.1.m1.16.16.16.16.16.16.16.16anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1ct.cmml" fragid="S6.E2.m1.1.1.1.1.m1.16.16.16.16.16.16.16.16.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1cu.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.16.16.16.16.16.16.16.16.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1cw.cmml" fragid="S6.E2.m1.1.1.1.1.m1.17.17.17.17.17.17.17.17anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1cx.cmml" fragid="S6.E2.m1.1.1.1.1.m1.17.17.17.17.17.17.17.17.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1cy.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.17.17.17.17.17.17.17.17.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1da.cmml" fragid="S6.E2.m1.1.1.1.1.m1.18.18.18.18.18.18.18.18anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1db.cmml" fragid="S6.E2.m1.1.1.1.1.m1.18.18.18.18.18.18.18.18.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1dc.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.18.18.18.18.18.18.18.18.2anest" xref="S6.E2.m1.1.1">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1de.cmml" fragid="S6.E2.m1.1.1.1.1.m1.19.19.19.19.19.19.19.19anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1df.cmml" fragid="S6.E2.m1.1.1.1.1.m1.19.19.19.19.19.19.19.19.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1dg.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.19.19.19.19.19.19.19.19.2anest" xref="S6.E2.m1.1.1">0</xmtok>\\<xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1di.cmml" fragid="S6.E2.m1.1.1.1.1.m1.19.19.19.19.19.19.19.19.4anest"
    xref="S6.E2.m1.1.1">d</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1dj.cmml" fragid="S6.E2.m1.1.1.1.1.m1.19.19.19.19.19.19.19.19.5anest"
    xref="S6.E2.m1.1.1">o</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1dk.cmml" fragid="S6.E2.m1.1.1.1.1.m1.19.19.19.19.19.19.19.19.6anest"
    xref="S6.E2.m1.1.1">g</xmtok></xmtext></xmcell><xmcell align="left" class="ltx_nopad_l
    ltx_nopad_r" id="S6.E2.m1.1.1dm.cmml" fragid="S6.E2.m1.1.1.1.1.m1.20.20.20.20.20.20.20.20anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1dn.cmml" fragid="S6.E2.m1.1.1.1.1.m1.20.20.20.20.20.20.20.20.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1do.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.20.20.20.20.20.20.20.20.2anest" xref="S6.E2.m1.1.1">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1dq.cmml" fragid="S6.E2.m1.1.1.1.1.m1.21.21.21.21.21.21.21.21anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1dr.cmml" fragid="S6.E2.m1.1.1.1.1.m1.21.21.21.21.21.21.21.21.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ds.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.21.21.21.21.21.21.21.21.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1du.cmml" fragid="S6.E2.m1.1.1.1.1.m1.22.22.22.22.22.22.22.22anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1dv.cmml" fragid="S6.E2.m1.1.1.1.1.m1.22.22.22.22.22.22.22.22.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1dw.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.22.22.22.22.22.22.22.22.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1dy.cmml" fragid="S6.E2.m1.1.1.1.1.m1.23.23.23.23.23.23.23.23anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1dz.cmml" fragid="S6.E2.m1.1.1.1.1.m1.23.23.23.23.23.23.23.23.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ea.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.23.23.23.23.23.23.23.23.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ec.cmml" fragid="S6.E2.m1.1.1.1.1.m1.24.24.24.24.24.24.24.24anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1ed.cmml" fragid="S6.E2.m1.1.1.1.1.m1.24.24.24.24.24.24.24.24.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ee.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.24.24.24.24.24.24.24.24.2anest" xref="S6.E2.m1.1.1">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1eg.cmml" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1eh.cmml" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ei.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.2anest" xref="S6.E2.m1.1.1">1</xmtok>\\<xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1ek.cmml" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.4anest"
    xref="S6.E2.m1.1.1">m</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1el.cmml" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.5anest"
    xref="S6.E2.m1.1.1">o</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1em.cmml" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.6anest"
    xref="S6.E2.m1.1.1">u</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1en.cmml" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.7anest"
    xref="S6.E2.m1.1.1">s</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1eo.cmml" fragid="S6.E2.m1.1.1.1.1.m1.25.25.25.25.25.25.25.25.8anest"
    xref="S6.E2.m1.1.1">e</xmtok></xmtext></xmcell><xmcell align="left" class="ltx_nopad_l
    ltx_nopad_r" id="S6.E2.m1.1.1eq.cmml" fragid="S6.E2.m1.1.1.1.1.m1.26.26.26.26.26.26.26.26anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1er.cmml" fragid="S6.E2.m1.1.1.1.1.m1.26.26.26.26.26.26.26.26.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1es.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.26.26.26.26.26.26.26.26.2anest" xref="S6.E2.m1.1.1">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1eu.cmml" fragid="S6.E2.m1.1.1.1.1.m1.27.27.27.27.27.27.27.27anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1ev.cmml" fragid="S6.E2.m1.1.1.1.1.m1.27.27.27.27.27.27.27.27.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1ew.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.27.27.27.27.27.27.27.27.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ey.cmml" fragid="S6.E2.m1.1.1.1.1.m1.28.28.28.28.28.28.28.28anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1ez.cmml" fragid="S6.E2.m1.1.1.1.1.m1.28.28.28.28.28.28.28.28.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1fa.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.28.28.28.28.28.28.28.28.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1fc.cmml" fragid="S6.E2.m1.1.1.1.1.m1.29.29.29.29.29.29.29.29anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1fd.cmml" fragid="S6.E2.m1.1.1.1.1.m1.29.29.29.29.29.29.29.29.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1fe.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.29.29.29.29.29.29.29.29.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1fg.cmml" fragid="S6.E2.m1.1.1.1.1.m1.30.30.30.30.30.30.30.30anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1fh.cmml" fragid="S6.E2.m1.1.1.1.1.m1.30.30.30.30.30.30.30.30.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1fi.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.30.30.30.30.30.30.30.30.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1fk.cmml" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1fl.cmml" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1fm.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.2anest" xref="S6.E2.m1.1.1">0</xmtok>\\<xmtok
    role="UNKNOWN" fontsize="70%" font="italic" id="S6.E2.m1.1.1fo.cmml" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.4anest"
    xref="S6.E2.m1.1.1">c</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1fp.cmml" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.5anest"
    xref="S6.E2.m1.1.1">a</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1fq.cmml" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.6anest"
    xref="S6.E2.m1.1.1">t</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1fr.cmml" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.7anest"
    xref="S6.E2.m1.1.1">c</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1fs.cmml" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.8anest"
    xref="S6.E2.m1.1.1">h</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1ft.cmml" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.9anest"
    xref="S6.E2.m1.1.1">e</xmtok><xmtok role="UNKNOWN" fontsize="70%" font="italic"
    id="S6.E2.m1.1.1fu.cmml" fragid="S6.E2.m1.1.1.1.1.m1.31.31.31.31.31.31.31.31.10anest"
    xref="S6.E2.m1.1.1">s</xmtok></xmtext></xmcell><xmcell align="left" class="ltx_nopad_l
    ltx_nopad_r" id="S6.E2.m1.1.1fw.cmml" fragid="S6.E2.m1.1.1.1.1.m1.32.32.32.32.32.32.32.32anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1fx.cmml" fragid="S6.E2.m1.1.1.1.1.m1.32.32.32.32.32.32.32.32.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="2" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1fy.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.32.32.32.32.32.32.32.32.2anest" xref="S6.E2.m1.1.1">2</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ga.cmml" fragid="S6.E2.m1.1.1.1.1.m1.33.33.33.33.33.33.33.33anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1gb.cmml" fragid="S6.E2.m1.1.1.1.1.m1.33.33.33.33.33.33.33.33.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1gc.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.33.33.33.33.33.33.33.33.2anest" xref="S6.E2.m1.1.1">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ge.cmml" fragid="S6.E2.m1.1.1.1.1.m1.34.34.34.34.34.34.34.34anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1gf.cmml" fragid="S6.E2.m1.1.1.1.1.m1.34.34.34.34.34.34.34.34.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1gg.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.34.34.34.34.34.34.34.34.2anest" xref="S6.E2.m1.1.1">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1gi.cmml" fragid="S6.E2.m1.1.1.1.1.m1.35.35.35.35.35.35.35.35anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1gj.cmml" fragid="S6.E2.m1.1.1.1.1.m1.35.35.35.35.35.35.35.35.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1gk.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.35.35.35.35.35.35.35.35.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1gm.cmml" fragid="S6.E2.m1.1.1.1.1.m1.36.36.36.36.36.36.36.36anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1gn.cmml" fragid="S6.E2.m1.1.1.1.1.m1.36.36.36.36.36.36.36.36.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1go.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.36.36.36.36.36.36.36.36.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1gq.cmml" fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1gr.cmml" fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1gs.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37.2anest" xref="S6.E2.m1.1.1">0</xmtok>\\<xmtok
    role="UNKNOWN" font="italic" fontsize="70%" id="S6.E2.m1.1.1gu.cmml" fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37.4anest"
    xref="S6.E2.m1.1.1">e</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1gv.cmml" fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37.5anest"
    xref="S6.E2.m1.1.1">a</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1gw.cmml" fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37.6anest"
    xref="S6.E2.m1.1.1">t</xmtok><xmtok role="UNKNOWN" font="italic" fontsize="70%"
    id="S6.E2.m1.1.1gx.cmml" fragid="S6.E2.m1.1.1.1.1.m1.37.37.37.37.37.37.37.37.7anest"
    xref="S6.E2.m1.1.1">s</xmtok></xmtext></xmcell><xmcell align="left" class="ltx_nopad_l
    ltx_nopad_r" id="S6.E2.m1.1.1gz.cmml" fragid="S6.E2.m1.1.1.1.1.m1.38.38.38.38.38.38.38.38anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1ha.cmml" fragid="S6.E2.m1.1.1.1.1.m1.38.38.38.38.38.38.38.38.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1hb.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.38.38.38.38.38.38.38.38.2anest" xref="S6.E2.m1.1.1">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1hd.cmml" fragid="S6.E2.m1.1.1.1.1.m1.39.39.39.39.39.39.39.39anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1he.cmml" fragid="S6.E2.m1.1.1.1.1.m1.39.39.39.39.39.39.39.39.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1hf.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.39.39.39.39.39.39.39.39.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1hh.cmml" fragid="S6.E2.m1.1.1.1.1.m1.40.40.40.40.40.40.40.40anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1hi.cmml" fragid="S6.E2.m1.1.1.1.1.m1.40.40.40.40.40.40.40.40.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="1" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1hj.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.40.40.40.40.40.40.40.40.2anest" xref="S6.E2.m1.1.1">1</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1hl.cmml" fragid="S6.E2.m1.1.1.1.1.m1.41.41.41.41.41.41.41.41anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1hm.cmml" fragid="S6.E2.m1.1.1.1.1.m1.41.41.41.41.41.41.41.41.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1hn.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.41.41.41.41.41.41.41.41.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1hp.cmml" fragid="S6.E2.m1.1.1.1.1.m1.42.42.42.42.42.42.42.42anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1hq.cmml" fragid="S6.E2.m1.1.1.1.1.m1.42.42.42.42.42.42.42.42.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1hr.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.42.42.42.42.42.42.42.42.2anest" xref="S6.E2.m1.1.1">0</xmtok></xmtext></xmcell><xmcell
    align="left" class="ltx_nopad_l ltx_nopad_r" id="S6.E2.m1.1.1ht.cmml" fragid="S6.E2.m1.1.1.1.1.m1.43.43.43.43.43.43.43.43anest"
    xref="S6.E2.m1.1.1"><xmtext id="S6.E2.m1.1.1hu.cmml" fragid="S6.E2.m1.1.1.1.1.m1.43.43.43.43.43.43.43.43.1anest"
    xref="S6.E2.m1.1.1"><xmtok meaning="0" role="NUMBER" fontsize="70%" id="S6.E2.m1.1.1hv.cmml"
    fragid="S6.E2.m1.1.1.1.1.m1.43.43.43.43.43.43.43.43.2anest" xref="S6.E2.m1.1.1">0</xmtok>\\</xmtext></xmcell></xmrow></xmarray><xmtok
    role="CLOSE" stretchy="true" id="S6.E2.m1.1.1hy.cmml" fragid="S6.E2.m1.1.1.1.1.m1.43.44.2.2anest"
    xref="S6.E2.m1.1.1">)</xmtok></xmwrap></xmref></xmdual></xmath></mtext></mrow></ci></apply></annotation-xml>
    <annotation encoding="application/x-tex" id="S6.E2.m1.1c">X=\hbox{}\vbox{\kern
    0.86108pt\hbox{$\kern 0.0pt\kern 2.5pt\kern-5.0pt\left(\kern 0.0pt\kern-2.5pt\kern-6.66669pt\vbox{\kern-0.86108pt\vbox{\vbox{
    \halign{\kern\arraycolsep\hfil\@arstrut$\kbcolstyle#$\hfil\kern\arraycolsep& \kern\arraycolsep\hfil$\@kbrowstyle#$\ifkbalignright\relax\else\hfil\fi\kern\arraycolsep&&
    \kern\arraycolsep\hfil$\@kbrowstyle#$\ifkbalignright\relax\else\hfil\fi\kern\arraycolsep\cr
    5.0pt\hfil\@arstrut$\scriptstyle$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle a$\hfil\kern
    5.0pt&5.0pt\hfil$\scriptstyle cat$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle dog$\hfil\kern
    5.0pt&5.0pt\hfil$\scriptstyle mouse$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle catches$\hfil\kern
    5.0pt&5.0pt\hfil$\scriptstyle eats\\a$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 1$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    2$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 2$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    2$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 2\\cat$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    2$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    1$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0\\dog$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    2$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    1$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 1\\mouse$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    2$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0\\catches$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    2$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 1$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    1$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0\\eats$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    1$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    1$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle
    0$\hfil\kern 5.0pt&5.0pt\hfil$\scriptstyle 0\\$\hfil\kern 5.0pt\crcr}}}}\right)$}}</annotation></semantics></math>
    |  | (2) |
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Hence, the word *cat* is represented by the vector $\mathbf{cat}=\begin{pmatrix}2&amp;0&amp;0&amp;0&amp;1&amp;0\end{pmatrix}$
    and the similarity between *cat* and *dog* is higher than the similarity between
    *cat* and *mouse* as the cosine similarity $cos(\mathbf{cat},\mathbf{dog})$ is
    higher than the cosine similarity $cos(\mathbf{cat},\mathbf{mouse})$.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，单词*cat* 被表示为向量 $\mathbf{cat}=\begin{pmatrix}2&amp;0&amp;0&amp;0&amp;1&amp;0\end{pmatrix}$，并且*cat*
    与*dog* 之间的相似性高于*cat* 与*mouse* 之间的相似性，因为余弦相似性 $cos(\mathbf{cat},\mathbf{dog})$
    高于余弦相似性 $cos(\mathbf{cat},\mathbf{mouse})$。
- en: 'The research on distributional semantics focuses on two aspects: (1) the best
    features to represent contexts; (2) the best correlation measure among target
    words and features.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 对分布式语义的研究集中在两个方面：（1）表示上下文的最佳特征；（2）目标单词与特征之间的最佳相关性度量。
- en: How to represent contexts is a crucial problem in distributional semantics.
    This problem is strictly correlated to the classical question of feature definition
    and feature selection in machine learning. A wide variety of features have been
    tried. Contexts have been represented as set of relevant words, sets of relevant
    syntactic triples involving target words (Pado and Lapata, [2007](#bib.bib54);
    Rothenhäusler and Schütze, [2009](#bib.bib59)) and sets of labeled lexical triples
    (Baroni and Lenci, [2010](#bib.bib5)).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 如何表示上下文是分布式语义学中的一个关键问题。这个问题与机器学习中的特征定义和特征选择的经典问题密切相关。已经尝试了各种各样的特征。上下文被表示为相关单词的集合、涉及目标单词的相关句法三元组集合（Pado
    和 Lapata，[2007](#bib.bib54)；Rothenhäusler 和 Schütze，[2009](#bib.bib59)）以及标记的词汇三元组集合（Baroni
    和 Lenci，[2010](#bib.bib5)）。
- en: Finding the best correlation measure among target words and their contextual
    features is the other issue. Many correlation measures have been tried. The classical
    measures are *term frequency-inverse document frequency* (*tf-idf*) (Salton, [1989](#bib.bib61))
    and *point-wise mutual information* ($pmi$). These, among other measures, are
    used to better capture the importance of contextual features for representing
    distributional semantic of words.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是找到目标单词及其上下文特征之间的最佳相关性度量。已经尝试了许多相关性度量。经典度量包括*词频-逆文档频率*（*tf-idf*）（Salton，[1989](#bib.bib61)）和*点对点互信息*（$pmi$）。这些度量，及其他一些度量，用于更好地捕捉上下文特征在表示单词的分布式语义中的重要性。
- en: This first formulation of distributional semantics is a distributed representation
    that is *interpretable*. In fact, features represent contextual information which
    is a proxy for semantic attributes of target words (Baroni and Lenci, [2010](#bib.bib5)).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式语义的首次表述是一种*可解释*的分布式表示。事实上，特征表示的是上下文信息，它是目标单词语义属性的代理（Baroni 和 Lenci，[2010](#bib.bib5)）。
- en: 6.2 Compacting distributional representations
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 压缩分布式表示
- en: As distributed representations, *distributional representations* can undergo
    the process of dimensionality reduction with Principal Component Analysis and
    Random Indexing. This process is used for two issues. The first is the classical
    problem of reducing the dimensions of the representation to obtain more compact
    representations. The second instead want to help the representation to focus on
    more discriminative dimensions. This latter issue focuses on the feature selection
    and merging which is an important task in making these representations more effective
    on the final task of similarity detection.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 作为分布式表示，*分布式表示* 可以通过主成分分析和随机索引进行降维处理。这个过程用于两个问题。第一个是经典的将表示维度减少以获得更紧凑表示的问题。第二个则是帮助表示集中于更具区分性的维度。后者问题关注特征选择和合并，这是使这些表示在最终相似性检测任务中更有效的重要任务。
- en: 'Principal Component Analysis (PCA) is largely applied in compacting distributional
    representations: Latent Semantic Analysis (LSA) is a prominent example (Landauer
    and Dumais, [1997](#bib.bib43)). LSA were born in Information Retrieval with the
    idea of reducing word-to-document matrices. Hence, in this compact representation,
    word context are documents and distributional vectors of words report on the documents
    where words appear. This or similar matrix reduction techniques have been then
    applied to word-to-word matrices.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析（PCA）在压缩分布式表示方面得到了广泛应用：潜在语义分析（LSA）是一个突出的例子（Landauer 和 Dumais，[1997](#bib.bib43)）。LSA诞生于信息检索领域，旨在减少单词与文档的矩阵。因此，在这种紧凑表示中，单词上下文是文档，而单词的分布向量报告了单词出现的文档。这种或类似的矩阵降维技术随后也被应用于单词与单词的矩阵。
- en: Principal Component Analysis (PCA) (Markovsky, [2012](#bib.bib47); Pearson,
    [1901](#bib.bib55)) is a linear method which reduces the number of dimensions
    by projecting $\mathbb{R}^{n}$ into the *“best”* linear subspace of a given dimension
    $d$ by using the a set of data points. The *“best”* linear subspace is a subspace
    where dimensions maximize the variance of the data points in the set. PCA can
    be interpreted either as a probabilistic method or as a matrix approximation and
    is then usually known as *truncated singular value decomposition*. We are here
    interested in describing PCA as probabilistic method as it related to the *interpretability*
    of the related *distributed representation*.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: As a probabilistic method, PCA finds an orthogonal projection matrix $W_{d}\in\mathbb{R}^{n\times
    d}$ such that the variance of the projected set of data points is maximized. The
    set of data points is referred as a matrix $X\in\mathbb{R}^{m\times n}$ where
    each row $\mathbf{x}_{i}^{T}\in\mathbb{R}^{n}$ is a single observation. Hence,
    the variance that is maximized is $\widehat{X}_{d}=XW_{d}^{T}\in\mathbb{R}^{m\times
    d}$.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, let’s consider the first weight vector $\mathbf{w_{1}}$,
    which maps an element of the dataset $\mathbf{x}$ into a single number $\langle\mathbf{x},\mathbf{w_{1}}\rangle$.
    Maximizing the variance means that $\mathbf{w}$ is such that:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{w_{1}}=\operatorname*{arg\,max}_{\&#124;\mathbf{w}\&#124;=1}\sum_{i}\left(\langle\mathbf{x_{i}},\mathbf{w}\rangle\right)^{2}$
    |  |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
- en: 'and it can be shown that the optimal value is achieved when $\mathbf{w}$ is
    the eigenvector of $X^{T}X$ with largest eigenvalue. This then produces a projected
    dataset:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\widehat{X}_{1}=X^{T}W_{1}=X^{T}\mathbf{w_{1}}$ |  |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
- en: 'The algorithm can then compute iteratively the second and further components
    by first subtracting the components already computed from $X$:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $X-X\mathbf{w_{1}}\mathbf{w_{1}}^{T}$ |  |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
- en: and then proceed as before. However, it turns out that all subsequent components
    are related to the eigenvectors of the matrix $X^{T}X$, that is, the $d$-th weight
    vector is the eigenvector of $X^{T}X$ with the $d$-th largest corresponding eigenvalue.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'The encoding matrix for distributed representations derived with a PCA method
    is the matrix:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '|  | <math id="S6.Ex21.m1.1" class="ltx_Math" alttext="W_{d}=\left[\begin{array}[]{c}\mathbf{w}_{1}\\
    \mathbf{w}_{2}\\'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: \ldots\\
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: \mathbf{w}_{d}\end{array}\right]\in\mathbb{R}^{d\times n}" display="block"><semantics
    id="S6.Ex21.m1.1a"><mrow id="S6.Ex21.m1.1.2" xref="S6.Ex21.m1.1.2.cmml"><msub
    id="S6.Ex21.m1.1.2.2" xref="S6.Ex21.m1.1.2.2.cmml"><mi id="S6.Ex21.m1.1.2.2.2"
    xref="S6.Ex21.m1.1.2.2.2.cmml">W</mi><mi id="S6.Ex21.m1.1.2.2.3" xref="S6.Ex21.m1.1.2.2.3.cmml">d</mi></msub><mo
    id="S6.Ex21.m1.1.2.3" xref="S6.Ex21.m1.1.2.3.cmml">=</mo><mrow id="S6.Ex21.m1.1.2.4.2"
    xref="S6.Ex21.m1.1.2.4.1.cmml"><mo id="S6.Ex21.m1.1.2.4.2.1" xref="S6.Ex21.m1.1.2.4.1.1.cmml">[</mo><mtable
    displaystyle="true" rowspacing="0pt" id="S6.Ex21.m1.1.1" xref="S6.Ex21.m1.1.1.cmml"><mtr
    id="S6.Ex21.m1.1.1a" xref="S6.Ex21.m1.1.1.cmml"><mtd id="S6.Ex21.m1.1.1b" xref="S6.Ex21.m1.1.1.cmml"><msub
    id="S6.Ex21.m1.1.1.1.1.1" xref="S6.Ex21.m1.1.1.1.1.1.cmml"><mi id="S6.Ex21.m1.1.1.1.1.1.2"
    xref="S6.Ex21.m1.1.1.1.1.1.2.cmml">𝐰</mi><mn id="S6.Ex21.m1.1.1.1.1.1.3" xref="S6.Ex21.m1.1.1.1.1.1.3.cmml">1</mn></msub></mtd></mtr><mtr
    id="S6.Ex21.m1.1.1c" xref="S6.Ex21.m1.1.1.cmml"><mtd id="S6.Ex21.m1.1.1d" xref="S6.Ex21.m1.1.1.cmml"><msub
    id="S6.Ex21.m1.1.1.2.1.1" xref="S6.Ex21.m1.1.1.2.1.1.cmml"><mi id="S6.Ex21.m1.1.1.2.1.1.2"
    xref="S6.Ex21.m1.1.1.2.1.1.2.cmml">𝐰</mi><mn id="S6.Ex21.m1.1.1.2.1.1.3" xref="S6.Ex21.m1.1.1.2.1.1.3.cmml">2</mn></msub></mtd></mtr><mtr
    id="S6.Ex21.m1.1.1e" xref="S6.Ex21.m1.1.1.cmml"><mtd id="S6.Ex21.m1.1.1f" xref="S6.Ex21.m1.1.1.cmml"><mi
    mathvariant="normal" id="S6.Ex21.m1.1.1.3.1.1" xref="S6.Ex21.m1.1.1.3.1.1.cmml">…</mi></mtd></mtr><mtr
    id="S6.Ex21.m1.1.1g" xref="S6.Ex21.m1.1.1.cmml"><mtd id="S6.Ex21.m1.1.1h" xref="S6.Ex21.m1.1.1.cmml"><msub
    id="S6.Ex21.m1.1.1.4.1.1" xref="S6.Ex21.m1.1.1.4.1.1.cmml"><mi id="S6.Ex21.m1.1.1.4.1.1.2"
    xref="S6.Ex21.m1.1.1.4.1.1.2.cmml">𝐰</mi><mi id="S6.Ex21.m1.1.1.4.1.1.3" xref="S6.Ex21.m1.1.1.4.1.1.3.cmml">d</mi></msub></mtd></mtr></mtable><mo
    id="S6.Ex21.m1.1.2.4.2.2" xref="S6.Ex21.m1.1.2.4.1.1.cmml">]</mo></mrow><mo id="S6.Ex21.m1.1.2.5"
    xref="S6.Ex21.m1.1.2.5.cmml">∈</mo><msup id="S6.Ex21.m1.1.2.6" xref="S6.Ex21.m1.1.2.6.cmml"><mi
    id="S6.Ex21.m1.1.2.6.2" xref="S6.Ex21.m1.1.2.6.2.cmml">ℝ</mi><mrow id="S6.Ex21.m1.1.2.6.3"
    xref="S6.Ex21.m1.1.2.6.3.cmml"><mi id="S6.Ex21.m1.1.2.6.3.2" xref="S6.Ex21.m1.1.2.6.3.2.cmml">d</mi><mo
    lspace="0.222em" rspace="0.222em" id="S6.Ex21.m1.1.2.6.3.1" xref="S6.Ex21.m1.1.2.6.3.1.cmml">×</mo><mi
    id="S6.Ex21.m1.1.2.6.3.3" xref="S6.Ex21.m1.1.2.6.3.3.cmml">n</mi></mrow></msup></mrow><annotation-xml
    encoding="MathML-Content" id="S6.Ex21.m1.1b"><apply id="S6.Ex21.m1.1.2.cmml" xref="S6.Ex21.m1.1.2"><apply
    id="S6.Ex21.m1.1.2b.cmml" xref="S6.Ex21.m1.1.2"><apply id="S6.Ex21.m1.1.2.2.cmml"
    xref="S6.Ex21.m1.1.2.2"><csymbol cd="ambiguous" id="S6.Ex21.m1.1.2.2.1.cmml" xref="S6.Ex21.m1.1.2.2">subscript</csymbol><ci
    id="S6.Ex21.m1.1.2.2.2.cmml" xref="S6.Ex21.m1.1.2.2.2">𝑊</ci><ci id="S6.Ex21.m1.1.2.2.3.cmml"
    xref="S6.Ex21.m1.1.2.2.3">𝑑</ci></apply><apply id="S6.Ex21.m1.1.2.4.1.cmml" xref="S6.Ex21.m1.1.2.4.2"><csymbol
    cd="latexml" id="S6.Ex21.m1.1.2.4.1.1.cmml" xref="S6.Ex21.m1.1.2.4.2.1">delimited-[]</csymbol><matrix
    id="S6.Ex21.m1.1.1.cmml" xref="S6.Ex21.m1.1.1"><matrixrow id="S6.Ex21.m1.1.1a.cmml"
    xref="S6.Ex21.m1.1.1"><apply id="S6.Ex21.m1.1.1.1.1.1.cmml" xref="S6.Ex21.m1.1.1.1.1.1"><csymbol
    cd="ambiguous" id="S6.Ex21.m1.1.1.1.1.1.1.cmml" xref="S6.Ex21.m1.1.1.1.1.1">subscript</csymbol><ci
    id="S6.Ex21.m1.1.1.1.1.1.2.cmml" xref="S6.Ex21.m1.1.1.1.1.1.2">𝐰</ci><cn type="integer"
    id="S6.Ex21.m1.1.1.1.1.1.3.cmml" xref="S6.Ex21.m1.1.1.1.1.1.3">1</cn></apply></matrixrow><matrixrow
    id="S6.Ex21.m1.1.1b.cmml" xref="S6.Ex21.m1.1.1"><apply id="S6.Ex21.m1.1.1.2.1.1.cmml"
    xref="S6.Ex21.m1.1.1.2.1.1"><csymbol cd="ambiguous" id="S6.Ex21.m1.1.1.2.1.1.1.cmml"
    xref="S6.Ex21.m1.1.1.2.1.1">subscript</csymbol><ci id="S6.Ex21.m1.1.1.2.1.1.2.cmml"
    xref="S6.Ex21.m1.1.1.2.1.1.2">𝐰</ci><cn type="integer" id="S6.Ex21.m1.1.1.2.1.1.3.cmml"
    xref="S6.Ex21.m1.1.1.2.1.1.3">2</cn></apply></matrixrow><matrixrow id="S6.Ex21.m1.1.1c.cmml"
    xref="S6.Ex21.m1.1.1"><ci id="S6.Ex21.m1.1.1.3.1.1.cmml" xref="S6.Ex21.m1.1.1.3.1.1">…</ci></matrixrow><matrixrow
    id="S6.Ex21.m1.1.1d.cmml" xref="S6.Ex21.m1.1.1"><apply id="S6.Ex21.m1.1.1.4.1.1.cmml"
    xref="S6.Ex21.m1.1.1.4.1.1"><csymbol cd="ambiguous" id="S6.Ex21.m1.1.1.4.1.1.1.cmml"
    xref="S6.Ex21.m1.1.1.4.1.1">subscript</csymbol><ci id="S6.Ex21.m1.1.1.4.1.1.2.cmml"
    xref="S6.Ex21.m1.1.1.4.1.1.2">𝐰</ci><ci id="S6.Ex21.m1.1.1.4.1.1.3.cmml" xref="S6.Ex21.m1.1.1.4.1.1.3">𝑑</ci></apply></matrixrow></matrix></apply></apply><apply
    id="S6.Ex21.m1.1.2c.cmml" xref="S6.Ex21.m1.1.2"><apply id="S6.Ex21.m1.1.2.6.cmml"
    xref="S6.Ex21.m1.1.2.6"><csymbol cd="ambiguous" id="S6.Ex21.m1.1.2.6.1.cmml" xref="S6.Ex21.m1.1.2.6">superscript</csymbol><ci
    id="S6.Ex21.m1.1.2.6.2.cmml" xref="S6.Ex21.m1.1.2.6.2">ℝ</ci><apply id="S6.Ex21.m1.1.2.6.3.cmml"
    xref="S6.Ex21.m1.1.2.6.3"><ci id="S6.Ex21.m1.1.2.6.3.2.cmml" xref="S6.Ex21.m1.1.2.6.3.2">𝑑</ci><ci
    id="S6.Ex21.m1.1.2.6.3.3.cmml" xref="S6.Ex21.m1.1.2.6.3.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S6.Ex21.m1.1c">W_{d}=\left[\begin{array}[]{c}\mathbf{w}_{1}\\
    \mathbf{w}_{2}\\ \ldots\\ \mathbf{w}_{d}\end{array}\right]\in\mathbb{R}^{d\times
    n}</annotation></semantics></math> |  |
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: 'where $\mathbf{w}_{i}$ are eigenvectors with eigenvalues decreasing with $i$.
    Hence, local representations $\mathbf{v}\in\mathbb{R}^{n}$ are represented in
    distributed representations in $\mathbb{R}^{d}$ as:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\eta(\mathbf{v})=W_{d}\mathbf{v}$ |  |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
- en: Hence, vectors $\eta(\mathbf{v})$ are *human-interpretable* as their dimensions
    represent linear combinations of dimensions in the original local representation
    and these dimensions are ordered according to their importance in the dataset,
    that is, their variance. Moreover, each dimension is a linear combination of the
    original symbols. Then, the matrix $W_{d}$ reports on which combination of the
    original symbols is more important to distinguish data points in the set.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, vectors $\eta(\mathbf{v})$ are *decodable*. The decoding function
    is:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\delta(\mathbf{v^{\prime}})=W_{d}^{T}\mathbf{v^{\prime}}$ |  |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
- en: and $W_{d}^{T}W_{d}=I$ if $d$ is the rank of the matrix $X$, otherwise it is
    a degraded approximation (for more details refer to (Fodor, [2002](#bib.bib23);
    Sorzano et al., [2014](#bib.bib66))). Hence, distributed vectors in $\mathbb{R}^{d}$
    can be decoded back in the original symbolic representation with a degree of approximation
    that depends on the distance between $d$ and the rank of the matrix $X$.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: The compelling limit of PCA is that all the data points have to be used in order
    to obtain the encoding/decoding matrices. This is not feasible in two cases. First,
    when the model has to deal with big data. Second, when the set of symbols to be
    encoded in extremely large. In this latter case, local representations cannot
    be used to produce matrices $X$ for applying PCA.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: 'In Distributional Semantics, *random indexing* has been used to solve some
    issues that arise naturally with PCA when working with large vocabularies and
    large corpora. PCA has some scalability problems:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: •
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The original co-occurrence matrix is very costly to obtain and store, moreover,
    it is only needed to be later transformed;
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dimensionality reduction is also very costly, moreover, with the dimensions
    at hand it can only be done with iterative methods;
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The entire method is not incremental, if we want to add new words to our corpus
    we have to recompute the entire co-occurrence matrix and then re-perform the PCA
    step.
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Random Indexing (Sahlgren, [2005](#bib.bib60)) solves these problems: it is
    an incremental method (new words can be easily added any time at low computational
    cost) which creates word vector of reduced dimension without the need to create
    the full dimensional matrix.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Interpretability of compacted distributional semantic vectors is comparable
    to the interpretability of distributed representations obtained with the same
    techniques.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '6.3 Learning representations: word2vec'
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/45c0fc96cdbd9e87392d359d3b4dd9f1.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: word2vec: CBOW model'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'Recently, *distributional hypothesis* has invaded neural networks: *word2vec*
    (Mikolov et al., [2013](#bib.bib49)) uses contextual information to learn word
    vectors. Hence, we discuss this technique in the section devoted to *distributional
    semantics*.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: The name word2Vec comprises two similar techniques, called *skip grams* and
    *continuous bag of words* (CBOW). Both methods are neural networks, the former
    takes input a word and try to predict its context, while the latter does the reverse
    process, predicting a word from the words surrounding it. With this technique
    there is no explicitly computed co-occurrence matrix, and neither there is an
    explicit association feature between pairs of words, instead, the regularities
    and distribution of the words are learned implicitly by the network.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'We describe only CBOW because it is conceptually simpler and because the core
    ideas are the same in both cases. The full network is generally realized with
    two layers $W1_{n\times k}$ and $W2_{k\times n}$ plus a softmax layer to reconstruct
    the final vector representing the word. In the learning phase, the input and the
    output of the network are local representation for words. In CBOW, the network
    aims to predict a target word given context words. For example, given the sentence
    $s_{1}$ of the corpus in Table [1](#S6.T1 "Table 1 ‣ 6.1 Building distributional
    representations for words from a corpus ‣ 6 Distributional Representations as
    another side of the coin ‣ Symbolic, Distributed and Distributional Representations
    for Natural Language Processing in the Era of Deep Learning: a Survey"), the network
    has to predict *catches* given its context (see Figure [1](#S6.F1 "Figure 1 ‣
    6.3 Learning representations: word2vec ‣ 6 Distributional Representations as another
    side of the coin ‣ Symbolic, Distributed and Distributional Representations for
    Natural Language Processing in the Era of Deep Learning: a Survey")).'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Hence, CBOW offers an encoder $W1_{n\times k}$, that is, a linear word encoder
    from data where $n$ is the size of the vocabulary and $k$ is the size of the distributional
    vector. This encoder models contextual information learned by maximizing the prediction
    capability of the network. A nice description on how this approach is related
    to previous techniques is given in (Goldberg and Levy, [2014](#bib.bib28)).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: 'Clearly, CBOW distributional vectors are not easily human and machine *interpretable*.
    In fact, specific dimensions of vectors have not a particular meaning and, differently
    from what happens for auto-encoders (see Sec. [5.2.1](#S5.SS2.SSS1 "5.2.1 Autoencoder
    ‣ 5.2 Learned representation ‣ 5 Strategies to obtain distributed representations
    from symbols ‣ Symbolic, Distributed and Distributional Representations for Natural
    Language Processing in the Era of Deep Learning: a Survey")), these networks are
    not trained to be invertible.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 7 Composing distributed representations
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous sections, we described how one symbol or a bag-of-symbols can
    be transformed in distributed representations focusing on whether these distributed
    representations are *interpretable*. In this section, we want to investigate a
    second and important aspect of these representations, that is, have these representations
    *Concatenative Compositionality* as symbolic representations? And, if these representations
    are *composed*, are still *interpretable*?
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '*Concatenative Compositionality* is the ability of a symbolic representation
    to describe sequences or structures by composing symbols with specific rules.
    In this process, symbols remain distinct and composing rules are clear. Hence,
    final sequences and structures can be used for subsequent steps as knowledge repositories.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '*Concatenative Compositionality* is an important aspect for any representation
    and, then, for a distributed representation. Understanding to what extent a distributed
    representation has *concatenative compositionality* and how information can be
    recovered is then a critical issue. In fact, this issue has been strongly posed
    by Plate (Plate, [1995](#bib.bib57), [1994](#bib.bib56)) who analyzed how same
    specific distributed representations encode structural information and how this
    structural information can be recovered back.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: 'Current approaches for treating distributed/distributional representation of
    sequences and structures mix two aspects in one model: a *“semantic”* aspect and
    a *representational* aspect. Generally, the semantic aspect is the predominant
    and the representational aspect is left aside. For *“semantic”* aspect, we refer
    to the reason why distributed symbols are composed: a final task in neural network
    applications or the need to give a *distributional semantic vector* for sequences
    of words. This latter is the case for *compositional distributional semantics*
    (Clark et al., [2008](#bib.bib14); Baroni et al., [2014](#bib.bib4)). For the
    *representational* aspect, we refer to the fact that composed distributed representations
    are in fact representing structures and these representations can be decoded back
    in order to extract what is in these structures.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Although the *“semantic”* aspect seems to be predominant in *models-that-compose*,
    the *convolution conjecture* (Zanzotto et al., [2015](#bib.bib78)) hypothesizes
    that the two aspects coexist and the *representational* aspect plays always a
    crucial role. According to this conjecture, structural information is preserved
    in any model that composes and structural information emerges back when comparing
    two distributed representations with dot product to determine their similarity.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Hence, given the *convolution conjecture*, *models-that-compose* produce distributed
    representations for structures that can be interpreted back. *Interpretability*
    is a very important feature in these *models-that-compose* which will drive our
    analysis.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: In this section we will explore the issues faced with the compositionality of
    representations, and the main “trends”, which correspond somewhat to the categories
    already presented. In particular we will start from the work on compositional
    distributional semantics, then we revise the work on holographic reduced representations
    (Plate, [1995](#bib.bib57); Neumann, [2001](#bib.bib53)) and, finally, we analyze
    the recent approaches with recurrent and recursive neural networks. Again, these
    categories are not entirely disjoint, and methods presented in one class can be
    often interpreted to belonging into another class.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Compositional Distributional Semantics
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In distributional semantics, *models-that-compose* have the name of *compositional
    distributional semantics models* (CDSMs) (Baroni et al., [2014](#bib.bib4); Mitchell
    and Lapata, [2010](#bib.bib51)) and aim to apply the principle of compositionality
    (Frege, [1884](#bib.bib25); Montague, [1974](#bib.bib52)) to compute distributional
    semantic vectors for phrases. These CDSMs produce distributional semantic vectors
    of phrases by composing distributional vectors of words in these phrases. These
    models generally exploit *structured or syntactic representations* of phrases
    to derive their distributional meaning. Hence, CDSMs aim to give a complete semantic
    model for distributional semantics.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: As in distributional semantics for words, the aim of CDSMs is to produce similar
    vectors for semantically similar sentences regardless their lengths or structures.
    For example, words and word definitions in dictionaries should have similar vectors
    as discussed in (Zanzotto et al., [2010](#bib.bib79)). As usual in distributional
    semantics, similarity is captured with dot products (or similar metrics) among
    distributional vectors.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: The applications of these CDSMs encompass multi-document summarization, recognizing
    textual entailment (Dagan et al., [2013](#bib.bib17)) and, obviously, semantic
    textual similarity detection (Agirre et al., [2013](#bib.bib2)).
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Apparently, these CDSMs are far from having *concatenative compositionality*
    , since these distributed representations that can be *interpreted* back. In some
    sense, their nature wants that resulting vectors forget how these are obtained
    and focus on the final distributional meaning of phrases. There is some evidence
    that this is not exactly the case.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: The *convolution conjecture* (Zanzotto et al., [2015](#bib.bib78)) suggests
    that many CDSMs produce distributional vectors where structural information and
    vectors for individual words can be still *interpreted*. Hence, many CDSMs have
    the *concatenative compositionality* property and *interpretable*.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: In the rest of this section, we will show some classes of these CDSMs and we
    focus on describing how these morels are interpretable.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.1 Additive Models
  id: totrans-264
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Additive models* for compositional distributional semantics are important
    examples of *models-that-composes* where *semantic* and *representational* aspects
    is clearly separated. Hence, these models can be highly *interpretable*.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: 'These additive models have been formally captured in the general framework
    for two words sequences proposed by Mitchell&Lapata (Mitchell and Lapata, [2008](#bib.bib50)).
    The general framework for composing distributional vectors of two word sequences
    *“u v”* is the following:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{p}=f(\mathbf{u},\mathbf{v};R;K)$ |  | (3) |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
- en: 'where $\mathbf{p}\in\mathbb{R}^{n}$ is the composition vector, $\mathbf{u}$
    and $\mathbf{v}$ are the vectors for the two words *u* and *v*, $R$ is the grammatical
    relation linking the two words and $K$ is any other additional knowledge used
    in the composition operation. In the additive model, this equation has the following
    form:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{p}=f(\mathbf{u},\mathbf{v};R;K)=A_{R}\mathbf{u}+B_{R}\mathbf{v}$
    |  | (4) |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
- en: where $A_{R}$ and $B_{R}$ are two square matrices depending on the grammatical
    relation $R$ which may be learned from data (Zanzotto et al., [2010](#bib.bib79);
    Guevara, [2010](#bib.bib32)).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: 'Before investigating if these models are interpretable, let introduce a recursive
    formulation of additive models which can be applied to structural representations
    of sentences. For this purpose, we use dependency trees. A dependency tree can
    be defined as a tree whose nodes are words and the typed links are the relations
    between two words. The root of the tree represents the word that governs the meaning
    of the sentence. A dependency tree $T$ is then a word if it is a final node or
    it has a root $r_{T}$ and links $(r_{T},R,C_{i})$ where $C_{i}$ is the i-th subtree
    of the node $r_{T}$ and $R$ is the relation that links the node $r_{T}$ with $C_{i}$.
    The dependency trees of two example sentences are reported in Figure [2](#S7.F2
    "Figure 2 ‣ 7.1.1 Additive Models ‣ 7.1 Compositional Distributional Semantics
    ‣ 7 Composing distributed representations ‣ Symbolic, Distributed and Distributional
    Representations for Natural Language Processing in the Era of Deep Learning: a
    Survey"). The recursive formulation is then the following:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $f_{r}(T)=\sum_{i}(A_{R}\mathbf{r_{T}}+B_{R}f_{r}(C_{i}))$ |  |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
- en: 'According to the recursive definition of the additive model, the function $f_{r}(T)$
    results in a linear combination of elements $M_{s}\mathbf{w}_{s}$ where $M_{s}$
    is a product of matrices that *represents the structure* and $\mathbf{w}_{s}$
    is the *distributional meaning* of one word in this structure, that is:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $f_{r}(T)=\sum_{s\in S(T)}\mathbf{M}_{s}\mathbf{w}_{s}$ |  |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
- en: 'where $S(T)$ are the relevant substructures of $T$. In this case, $S(T)$ contains
    the link chains. For example, the first sentence in Fig. [2](#S7.F2 "Figure 2
    ‣ 7.1.1 Additive Models ‣ 7.1 Compositional Distributional Semantics ‣ 7 Composing
    distributed representations ‣ Symbolic, Distributed and Distributional Representations
    for Natural Language Processing in the Era of Deep Learning: a Survey") has a
    distributed vector defined in this way:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle f_{r}(\text{cows eat animal extracts})=$ |  |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle=A_{VN}\mathbf{eat}+B_{VN}\mathbf{cows}+A_{VN}\mathbf{eat}+$
    |  |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle+B_{VN}f_{r}(\text{animal extracts})=$ |  |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle=A_{VN}\mathbf{eat}+B_{VN}\mathbf{cows}+A_{VN}\mathbf{eat}+$
    |  |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle+B_{VN}A_{NN}\mathbf{extracts}+B_{VN}B_{NN}\mathbf{animal}$
    |  |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
- en: 'Each term of the sum has a part that represents the structure and a part that
    represents the meaning, for example:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\overbrace{B_{VN}B_{NN}}^{structure}\underbrace{\mathbf{beef}}_{meaning}$
    |  |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
- en: 'Hence, this recursive additive model for compositional semantics is a *model-that-composes*
    which, in principle, can be highly *interpretable*. By selecting matrices $\mathbf{M}_{s}$
    such that:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '|  | <math id="S7.E5.m1.4" class="ltx_Math" alttext="\mathbf{M}_{s_{1}}^{T}\mathbf{M}_{s_{2}}\approx\begin{cases}\mathbf{I}&amp;s_{1}=s_{2}\\
    \mathbf{0}&amp;s_{1}\neq s_{2}\\'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: \end{cases}" display="block"><semantics id="S7.E5.m1.4a"><mrow id="S7.E5.m1.4.5"
    xref="S7.E5.m1.4.5.cmml"><mrow id="S7.E5.m1.4.5.2" xref="S7.E5.m1.4.5.2.cmml"><msubsup
    id="S7.E5.m1.4.5.2.2" xref="S7.E5.m1.4.5.2.2.cmml"><mi id="S7.E5.m1.4.5.2.2.2.2"
    xref="S7.E5.m1.4.5.2.2.2.2.cmml">𝐌</mi><msub id="S7.E5.m1.4.5.2.2.2.3" xref="S7.E5.m1.4.5.2.2.2.3.cmml"><mi
    id="S7.E5.m1.4.5.2.2.2.3.2" xref="S7.E5.m1.4.5.2.2.2.3.2.cmml">s</mi><mn id="S7.E5.m1.4.5.2.2.2.3.3"
    xref="S7.E5.m1.4.5.2.2.2.3.3.cmml">1</mn></msub><mi id="S7.E5.m1.4.5.2.2.3" xref="S7.E5.m1.4.5.2.2.3.cmml">T</mi></msubsup><mo
    lspace="0em" rspace="0em" id="S7.E5.m1.4.5.2.1" xref="S7.E5.m1.4.5.2.1.cmml">​</mo><msub
    id="S7.E5.m1.4.5.2.3" xref="S7.E5.m1.4.5.2.3.cmml"><mi id="S7.E5.m1.4.5.2.3.2"
    xref="S7.E5.m1.4.5.2.3.2.cmml">𝐌</mi><msub id="S7.E5.m1.4.5.2.3.3" xref="S7.E5.m1.4.5.2.3.3.cmml"><mi
    id="S7.E5.m1.4.5.2.3.3.2" xref="S7.E5.m1.4.5.2.3.3.2.cmml">s</mi><mn id="S7.E5.m1.4.5.2.3.3.3"
    xref="S7.E5.m1.4.5.2.3.3.3.cmml">2</mn></msub></msub></mrow><mo id="S7.E5.m1.4.5.1"
    xref="S7.E5.m1.4.5.1.cmml">≈</mo><mrow id="S7.E5.m1.4.4" xref="S7.E5.m1.4.5.3.1.cmml"><mo
    id="S7.E5.m1.4.4.5" xref="S7.E5.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt"
    displaystyle="true" rowspacing="0pt" id="S7.E5.m1.4.4.4" xref="S7.E5.m1.4.5.3.1.cmml"><mtr
    id="S7.E5.m1.4.4.4a" xref="S7.E5.m1.4.5.3.1.cmml"><mtd class="ltx_align_left"
    columnalign="left" id="S7.E5.m1.4.4.4b" xref="S7.E5.m1.4.5.3.1.cmml"><mi id="S7.E5.m1.1.1.1.1.1.1"
    xref="S7.E5.m1.1.1.1.1.1.1.cmml">𝐈</mi></mtd><mtd class="ltx_align_left" columnalign="left"
    id="S7.E5.m1.4.4.4c" xref="S7.E5.m1.4.5.3.1.cmml"><mrow id="S7.E5.m1.2.2.2.2.2.1"
    xref="S7.E5.m1.2.2.2.2.2.1.cmml"><msub id="S7.E5.m1.2.2.2.2.2.1.2" xref="S7.E5.m1.2.2.2.2.2.1.2.cmml"><mi
    id="S7.E5.m1.2.2.2.2.2.1.2.2" xref="S7.E5.m1.2.2.2.2.2.1.2.2.cmml">s</mi><mn id="S7.E5.m1.2.2.2.2.2.1.2.3"
    xref="S7.E5.m1.2.2.2.2.2.1.2.3.cmml">1</mn></msub><mo id="S7.E5.m1.2.2.2.2.2.1.1"
    xref="S7.E5.m1.2.2.2.2.2.1.1.cmml">=</mo><msub id="S7.E5.m1.2.2.2.2.2.1.3" xref="S7.E5.m1.2.2.2.2.2.1.3.cmml"><mi
    id="S7.E5.m1.2.2.2.2.2.1.3.2" xref="S7.E5.m1.2.2.2.2.2.1.3.2.cmml">s</mi><mn id="S7.E5.m1.2.2.2.2.2.1.3.3"
    xref="S7.E5.m1.2.2.2.2.2.1.3.3.cmml">2</mn></msub></mrow></mtd></mtr><mtr id="S7.E5.m1.4.4.4d"
    xref="S7.E5.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S7.E5.m1.4.4.4e"
    xref="S7.E5.m1.4.5.3.1.cmml"><mn id="S7.E5.m1.3.3.3.3.1.1" xref="S7.E5.m1.3.3.3.3.1.1.cmml">𝟎</mn></mtd><mtd
    class="ltx_align_left" columnalign="left" id="S7.E5.m1.4.4.4f" xref="S7.E5.m1.4.5.3.1.cmml"><mrow
    id="S7.E5.m1.4.4.4.4.2.1" xref="S7.E5.m1.4.4.4.4.2.1.cmml"><msub id="S7.E5.m1.4.4.4.4.2.1.2"
    xref="S7.E5.m1.4.4.4.4.2.1.2.cmml"><mi id="S7.E5.m1.4.4.4.4.2.1.2.2" xref="S7.E5.m1.4.4.4.4.2.1.2.2.cmml">s</mi><mn
    id="S7.E5.m1.4.4.4.4.2.1.2.3" xref="S7.E5.m1.4.4.4.4.2.1.2.3.cmml">1</mn></msub><mo
    id="S7.E5.m1.4.4.4.4.2.1.1" xref="S7.E5.m1.4.4.4.4.2.1.1.cmml">≠</mo><msub id="S7.E5.m1.4.4.4.4.2.1.3"
    xref="S7.E5.m1.4.4.4.4.2.1.3.cmml"><mi id="S7.E5.m1.4.4.4.4.2.1.3.2" xref="S7.E5.m1.4.4.4.4.2.1.3.2.cmml">s</mi><mn
    id="S7.E5.m1.4.4.4.4.2.1.3.3" xref="S7.E5.m1.4.4.4.4.2.1.3.3.cmml">2</mn></msub></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml
    encoding="MathML-Content" id="S7.E5.m1.4b"><apply id="S7.E5.m1.4.5.cmml" xref="S7.E5.m1.4.5"><apply
    id="S7.E5.m1.4.5.2.cmml" xref="S7.E5.m1.4.5.2"><apply id="S7.E5.m1.4.5.2.2.cmml"
    xref="S7.E5.m1.4.5.2.2"><csymbol cd="ambiguous" id="S7.E5.m1.4.5.2.2.1.cmml" xref="S7.E5.m1.4.5.2.2">superscript</csymbol><apply
    id="S7.E5.m1.4.5.2.2.2.cmml" xref="S7.E5.m1.4.5.2.2"><csymbol cd="ambiguous" id="S7.E5.m1.4.5.2.2.2.1.cmml"
    xref="S7.E5.m1.4.5.2.2">subscript</csymbol><ci id="S7.E5.m1.4.5.2.2.2.2.cmml"
    xref="S7.E5.m1.4.5.2.2.2.2">𝐌</ci><apply id="S7.E5.m1.4.5.2.2.2.3.cmml" xref="S7.E5.m1.4.5.2.2.2.3"><csymbol
    cd="ambiguous" id="S7.E5.m1.4.5.2.2.2.3.1.cmml" xref="S7.E5.m1.4.5.2.2.2.3">subscript</csymbol><ci
    id="S7.E5.m1.4.5.2.2.2.3.2.cmml" xref="S7.E5.m1.4.5.2.2.2.3.2">𝑠</ci><cn type="integer"
    id="S7.E5.m1.4.5.2.2.2.3.3.cmml" xref="S7.E5.m1.4.5.2.2.2.3.3">1</cn></apply></apply><ci
    id="S7.E5.m1.4.5.2.2.3.cmml" xref="S7.E5.m1.4.5.2.2.3">𝑇</ci></apply><apply id="S7.E5.m1.4.5.2.3.cmml"
    xref="S7.E5.m1.4.5.2.3"><csymbol cd="ambiguous" id="S7.E5.m1.4.5.2.3.1.cmml" xref="S7.E5.m1.4.5.2.3">subscript</csymbol><ci
    id="S7.E5.m1.4.5.2.3.2.cmml" xref="S7.E5.m1.4.5.2.3.2">𝐌</ci><apply id="S7.E5.m1.4.5.2.3.3.cmml"
    xref="S7.E5.m1.4.5.2.3.3"><csymbol cd="ambiguous" id="S7.E5.m1.4.5.2.3.3.1.cmml"
    xref="S7.E5.m1.4.5.2.3.3">subscript</csymbol><ci id="S7.E5.m1.4.5.2.3.3.2.cmml"
    xref="S7.E5.m1.4.5.2.3.3.2">𝑠</ci><cn type="integer" id="S7.E5.m1.4.5.2.3.3.3.cmml"
    xref="S7.E5.m1.4.5.2.3.3.3">2</cn></apply></apply></apply><apply id="S7.E5.m1.4.5.3.1.cmml"
    xref="S7.E5.m1.4.4"><csymbol cd="latexml" id="S7.E5.m1.4.5.3.1.1.cmml" xref="S7.E5.m1.4.4.5">cases</csymbol><ci
    id="S7.E5.m1.1.1.1.1.1.1.cmml" xref="S7.E5.m1.1.1.1.1.1.1">𝐈</ci><apply id="S7.E5.m1.2.2.2.2.2.1.cmml"
    xref="S7.E5.m1.2.2.2.2.2.1"><apply id="S7.E5.m1.2.2.2.2.2.1.2.cmml" xref="S7.E5.m1.2.2.2.2.2.1.2"><csymbol
    cd="ambiguous" id="S7.E5.m1.2.2.2.2.2.1.2.1.cmml" xref="S7.E5.m1.2.2.2.2.2.1.2">subscript</csymbol><ci
    id="S7.E5.m1.2.2.2.2.2.1.2.2.cmml" xref="S7.E5.m1.2.2.2.2.2.1.2.2">𝑠</ci><cn type="integer"
    id="S7.E5.m1.2.2.2.2.2.1.2.3.cmml" xref="S7.E5.m1.2.2.2.2.2.1.2.3">1</cn></apply><apply
    id="S7.E5.m1.2.2.2.2.2.1.3.cmml" xref="S7.E5.m1.2.2.2.2.2.1.3"><csymbol cd="ambiguous"
    id="S7.E5.m1.2.2.2.2.2.1.3.1.cmml" xref="S7.E5.m1.2.2.2.2.2.1.3">subscript</csymbol><ci
    id="S7.E5.m1.2.2.2.2.2.1.3.2.cmml" xref="S7.E5.m1.2.2.2.2.2.1.3.2">𝑠</ci><cn type="integer"
    id="S7.E5.m1.2.2.2.2.2.1.3.3.cmml" xref="S7.E5.m1.2.2.2.2.2.1.3.3">2</cn></apply></apply><cn
    type="integer" id="S7.E5.m1.3.3.3.3.1.1.cmml" xref="S7.E5.m1.3.3.3.3.1.1">0</cn><apply
    id="S7.E5.m1.4.4.4.4.2.1.cmml" xref="S7.E5.m1.4.4.4.4.2.1"><apply id="S7.E5.m1.4.4.4.4.2.1.2.cmml"
    xref="S7.E5.m1.4.4.4.4.2.1.2"><csymbol cd="ambiguous" id="S7.E5.m1.4.4.4.4.2.1.2.1.cmml"
    xref="S7.E5.m1.4.4.4.4.2.1.2">subscript</csymbol><ci id="S7.E5.m1.4.4.4.4.2.1.2.2.cmml"
    xref="S7.E5.m1.4.4.4.4.2.1.2.2">𝑠</ci><cn type="integer" id="S7.E5.m1.4.4.4.4.2.1.2.3.cmml"
    xref="S7.E5.m1.4.4.4.4.2.1.2.3">1</cn></apply><apply id="S7.E5.m1.4.4.4.4.2.1.3.cmml"
    xref="S7.E5.m1.4.4.4.4.2.1.3"><csymbol cd="ambiguous" id="S7.E5.m1.4.4.4.4.2.1.3.1.cmml"
    xref="S7.E5.m1.4.4.4.4.2.1.3">subscript</csymbol><ci id="S7.E5.m1.4.4.4.4.2.1.3.2.cmml"
    xref="S7.E5.m1.4.4.4.4.2.1.3.2">𝑠</ci><cn type="integer" id="S7.E5.m1.4.4.4.4.2.1.3.3.cmml"
    xref="S7.E5.m1.4.4.4.4.2.1.3.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S7.E5.m1.4c">\mathbf{M}_{s_{1}}^{T}\mathbf{M}_{s_{2}}\approx\begin{cases}\mathbf{I}&s_{1}=s_{2}\\
    \mathbf{0}&s_{1}\neq s_{2}\\ \end{cases}</annotation></semantics></math> |  |
    (5) |
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: 'it is possible to recover distributional semantic vectors related to words
    that are in specific parts of the structure. For example, the main verb of the
    sample sentence in Fig. [2](#S7.F2 "Figure 2 ‣ 7.1.1 Additive Models ‣ 7.1 Compositional
    Distributional Semantics ‣ 7 Composing distributed representations ‣ Symbolic,
    Distributed and Distributional Representations for Natural Language Processing
    in the Era of Deep Learning: a Survey") with a matrix $A_{VN}^{T}$, that is:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $A_{VN}^{T}f_{r}(\text{cows eat animal extracts})\approx 2\mathbf{eat}$
    |  |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
- en: In general, matrices derived for compositional distributional semantic models
    (Guevara, [2010](#bib.bib32); Zanzotto et al., [2010](#bib.bib79)) do not have
    this property but it is possible to obtain matrices with this property by applying
    thee Jonson-Linderstrauss Tranform (Johnson and Lindenstrauss, [1984](#bib.bib39))
    or similar techniques as discussed also in (Zanzotto et al., [2015](#bib.bib78)).
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '| ![Refer to caption](img/e4d6edc6dc130666802976a787b8cbf9.png) |  |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
- en: 'Figure 2: A sentence and its dependency graph'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.2 Lexical Functional Compositional Distributional Semantic Models
  id: totrans-291
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Lexical Functional Models are compositional distributional semantic models where
    words are tensors and each type of word is represented by tensors of different
    order. Composing meaning is then composing these tensors to obtain vectors. These
    models have solid mathematical background linking Lambek pregroup theory, formal
    semantics and distributional semantics (Coecke et al., [2010](#bib.bib15)). Lexical
    Function models are concatenative compositional, yet, in the following, we will
    examine whether these models produce vectors that my be *interpreted*.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: To determine whether these models produce *interpretable* vectors, we start
    from a simple Lexical Function model applied to two word sequences. This model
    has been largely analyzed in (Baroni and Zamparelli, [2010](#bib.bib6)) as matrices
    were considered better linear models to encode *adjectives*.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'In Lexical Functional models over two words sequences, there is one of the
    two words which as a tensor of order 2 (that is, a matrix) and one word that is
    represented by a vector. For example, *adjectives* are matrices and nouns are
    vectors (Baroni and Zamparelli, [2010](#bib.bib6)) in adjective-noun sequences.
    Hence, adjective-noun sequences like *“black cat”* or *“white dog”* are represented
    as:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $f(\text{black cat})=\mathbf{BLACK}\mathbf{cat}$ |  |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
- en: '|  | $f(\text{white dog})=\mathbf{WHITE}\mathbf{dog}$ |  |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{BLACK}$ and $\mathbf{WHITE}$ are matrices representing the two
    adjectives and $\mathbf{cat}$ and $\mathbf{dog}$ are the two vectors representing
    the two nouns.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: 'These two words models are *partially interpretable*: knowing the adjective
    it is possible to extract the noun but not vice-versa. In fact, if matrices for
    adjectives are invertible, there is the possibility of extracting which nouns
    has been related to particular adjectives. For example, if $\mathbf{BLACK}$ is
    invertible, the inverse matrix $\mathbf{BLACK}^{-1}$ can be used to extract the
    vector of *cat* from the vector $f(\text{black cat})$:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{cat}=\mathbf{BLACK}^{-1}f(\text{black cat})$ |  |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
- en: 'This contributes to the *interpretability* of this model. Moreover, if matrices
    for adjectives are built using Jonson-Lindestrauss Transforms (Johnson and Lindenstrauss,
    [1984](#bib.bib39)), that is matrices with the property in Eq. [5](#S7.E5 "In
    7.1.1 Additive Models ‣ 7.1 Compositional Distributional Semantics ‣ 7 Composing
    distributed representations ‣ Symbolic, Distributed and Distributional Representations
    for Natural Language Processing in the Era of Deep Learning: a Survey"), it is
    possible to pack different pieces of sentences in a single vector and, then, select
    only relevant information, for example:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{cat}\approx\mathbf{BLACK}^{T}(f(\text{black cat})+f(\text{white
    dog}))$ |  |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
- en: On the contrary, knowing noun vectors, it is not possible to extract back adjective
    matrices. This is a strong limitation in term of interpretability.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Lexical Functional models for larger structures are concatenative compositional
    but not interpretable at all. In fact, in general these models have tensors in
    the middle and these tensors are the only parts that can be inverted. Hence, in
    general these models are not interpretable. However, using the *convolution conjecture*
    (Zanzotto et al., [2015](#bib.bib78)), it is possible to know whether subparts
    are contained in some final vectors obtained with these models.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Holographic Representations
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Holographic reduced representations (HRRs) are *models-that-compose* expressly
    designed to be *interpretable* (Plate, [1995](#bib.bib57); Neumann, [2001](#bib.bib53)).
    In fact, these models to encode flat structures representing assertions and these
    assertions should be then searched in oder to recover pieces of knowledge that
    is in. For example, these representations have been used to encode logical propositions
    such as $eat(John,apple)$. In this case, each atomic element has an associated
    vector and the vector for the compound is obtained by combining these vectors.
    The major concern here is to build encoding functions that can be decoded, that
    is, it should be possible to retrieve composing elements from final distributed
    vectors such as the vector of $eat(John,apple)$.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: 'In HRRs, *nearly orthogonal unit vectors* (Johnson and Lindenstrauss, [1984](#bib.bib39))
    for basic symbols, *circular convolution* $\otimes$ and *circular correlation*
    $\oplus$ guarantees *composability* and *intepretability*. HRRs are the extension
    of Random Indexing (see Sec. [5.1](#S5.SS1 "5.1 Dimensionality reductio with Random
    Projections ‣ 5 Strategies to obtain distributed representations from symbols
    ‣ Symbolic, Distributed and Distributional Representations for Natural Language
    Processing in the Era of Deep Learning: a Survey")) to structures. Hence, symbols
    are represented with vectors sampled from a multivariate normal distribution $N(0,\frac{1}{d}I_{d})$.
    The composition function is the circular convolution indicated as $\otimes$ and
    defined as:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $z_{j}=(\mathbf{a}\otimes\mathbf{b})_{j}=\sum_{k=0}^{d-1}a_{k}b_{j-k}$
    |  |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
- en: 'where subscripts are modulo $d$. Circular convolution is commutative and bilinear.
    This operation can be also computed using *circulant matrices*:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{z}=(\mathbf{a}\otimes\mathbf{b})=\mathbf{A}_{\circ}\mathbf{b}=\mathbf{B}_{\circ}\mathbf{a}$
    |  |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
- en: 'where $\mathbf{A}_{\circ}$ and $\mathbf{B}_{\circ}$ are circulant matrices
    of the vectors $\mathbf{a}$ and $\mathbf{b}$. Given the properties of vectors
    $\mathbf{a}$ and $\mathbf{b}$, matrices $\mathbf{A}_{\circ}$ and $\mathbf{B}_{\circ}$
    have the property in Eq. [5](#S7.E5 "In 7.1.1 Additive Models ‣ 7.1 Compositional
    Distributional Semantics ‣ 7 Composing distributed representations ‣ Symbolic,
    Distributed and Distributional Representations for Natural Language Processing
    in the Era of Deep Learning: a Survey"). Hence, *circular convolution* is approximately
    invertible with the *circular correlation* function ($\oplus$) defined as follows:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $c_{j}=(\mathbf{z}\oplus\mathbf{b})_{j}=\sum_{k=0}^{d-1}z_{k}b_{j+k}$
    |  |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
- en: 'where again subscripts are modulo $d$. Circular correlation is related to inverse
    matrices of circulant matrices, that is $\mathbf{B}_{\circ}^{T}$. In the decoding
    with $\oplus$, parts of the structures can be derived in an approximated way,
    that is:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $(\mathbf{a}\otimes\mathbf{b})\oplus\mathbf{b}\approx\mathbf{a}$ |  |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
- en: 'Hence, circular convolution $\otimes$ and circular correlation $\oplus$ allow
    to build interpretable representations. For example, having the vectors $\mathbf{e}$,
    $\mathbf{J}$, and $\mathbf{a}$ for $eat$, $John$ and $apple$, respectively, the
    following encoding and decoding produces a vector that approximates the original
    vector for $John$:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{J}\approx(\mathbf{J}\otimes\mathbf{e}\otimes\mathbf{a})\oplus(\mathbf{e}\otimes\mathbf{a})$
    |  |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
- en: The “invertibility” of these representations is important because it allow us
    not to consider these representations as black boxes.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: However, holographic representations have severe limitations as these can encode
    and decode simple, flat structures. In fact, these representations are based on
    the circular convolution, which is a commutative function; this implies that the
    representation cannot keep track of composition of objects where the order matters
    and this phenomenon is particularly important when encoding nested structures.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: Distributed trees (Zanzotto and Dell’Arciprete, [2012](#bib.bib77)) have shown
    that the principles expressed in holographic representation can be applied to
    encode larger structures, overcoming the problem of reliably encoding the order
    in which elements are composed using the *shuffled circular convolution* function
    as the composition operator. Distributed trees are encoding functions that transform
    trees into low-dimensional vectors that also contain the encoding of every substructures
    of the tree. Thus, these distributed trees are particularly attractive as they
    can be used to represent structures in linear learning machines which are computationally
    efficient.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Distributed trees and, in particular, distributed smoothed trees (Ferrone and
    Zanzotto, [2014](#bib.bib20)) represent an interesting middle way between compositional
    distributional semantic models and holographic representation.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: 7.3 Compositional Models in Neural Networks
  id: totrans-320
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When neural networks are applied to sequences or structured data, these networks
    are in fact *models-that-compose*. However, these models result in *models-that-compose*
    which are not interpretable. In fact, composition functions are trained on specific
    tasks and not on the possibility of reconstructing the structured input, unless
    in some rare cases (Socher et al., [2011](#bib.bib64)). The input of these networks
    are sequences or structured data where basic symbols are embedded in *local* representations
    or *distributed* representations obtained with word embedding (see Sec. [6.3](#S6.SS3
    "6.3 Learning representations: word2vec ‣ 6 Distributional Representations as
    another side of the coin ‣ Symbolic, Distributed and Distributional Representations
    for Natural Language Processing in the Era of Deep Learning: a Survey")). The
    output are distributed vectors derived for specific tasks. Hence, these *models-that-compose*
    are not interpretable in our sense for their final aim and for the fact that *non
    linear* functions are adopted in the specification of the neural networks.'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we revise some prominent neural network architectures that
    can be interpreted as *models-that-compose*: the *recurrent neural networks* (Krizhevsky
    et al., [2012](#bib.bib42); He et al., [2016](#bib.bib34); Vinyals et al., [2015a](#bib.bib72);
    Graves, [2013](#bib.bib30)) and the *recursive neural networks* (Socher et al.,
    [2012](#bib.bib65)).'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.1 Recurrent Neural Networks
  id: totrans-323
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Recurrent neural networks form a very broad family of neural networks architectures
    that deal with the representation (and processing) of complex objects. At its
    core a recurrent neural network (RNN) is a network which takes in input the current
    element in the sequence and processes it based on an internal state which depends
    on previous inputs. At the moment the most powerful network architectures are
    convolutional neural networks (Krizhevsky et al., [2012](#bib.bib42); He et al.,
    [2016](#bib.bib34)) for vision related tasks and LSTM-type network for language
    related task (Vinyals et al., [2015a](#bib.bib72); Graves, [2013](#bib.bib30)).
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: A recurrent neural network takes as input a sequence $\mathbf{x}=\left(\mathbf{x_{1}}\
    \ldots\ \mathbf{x_{n}}\right)$ and produce as output a single vector $\mathbf{y}\in\mathbb{R}^{n}$
    which is a representation of the entire sequence. At each step ¹¹1we can usually
    think of this as a timestep, but not all applications of recurrent neural network
    have a temporal interpretation $t$ the network takes as input the current element
    $\mathbf{x_{t}}$, the previous output $\mathbf{h_{t-1}}$ and performs the following
    operation to produce the current output $\mathbf{h_{t}}$
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle h_{t}$ | $\displaystyle=$ | $\displaystyle\sigma(W\left[\mathbf{h_{t-1}}\
    \mathbf{x_{t}}\right]+b)$ |  | (6) |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
- en: where $\sigma$ is a non-linear function such as the logistic function or the
    hyperbolic tangent and $\left[\mathbf{h_{t-1}}\ \mathbf{x_{t}}\right]$ denotes
    the concatenation of the vectors $\mathbf{h_{t-1}}$ and $\mathbf{x_{t}}$. The
    parameters of the model are the matrix $W$ and the bias vector $b$.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, a recurrent neural network is effectively a learned composition function,
    which dynamically depends on its current input, all of its previous inputs and
    also on the dataset on which is trained. However, this learned composition function
    is basically impossible to analyze or interpret in any way. Sometime an “intuitive”
    explanation is given about what the learned weights represent: with some weights
    representing information that must be remembered or forgotten.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: Even more complex recurrent neural networks as long-short term memory (LSTM)
    (Hochreiter and Schmidhuber, [1997](#bib.bib36)) have the same problem of interpretability.
    LSTM are a recent and successful way for neural network to deal with longer sequences
    of inputs, overcoming some difficulty that RNN face in the training phase. As
    with RNN, LSTM network takes as input a sequence $\mathbf{x}=\left(\mathbf{x_{1}}\
    \ldots\ \mathbf{x_{n}}\right)$ and produce as output a single vector $\mathbf{y}\in\mathbb{R}^{n}$
    which is a representation of the entire sequence. At each step $t$ the network
    takes as input the current element $\mathbf{x_{t}}$, the previous output $\mathbf{h_{t-1}}$
    and performs the following operation to produce the current output $\mathbf{h_{t}}$
    and update the internal state $\mathbf{c_{t}}$.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle f_{t}$ | $\displaystyle=\sigma(W_{f}\left[\mathbf{h_{t-1}}\
    \mathbf{x_{t}}\right]+b_{f})$ |  |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle i_{t}$ | $\displaystyle=\sigma(W_{i}\left[\mathbf{h_{t-1}}\
    \mathbf{x_{t}}\right]+b_{i})$ |  |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle o_{t}$ | $\displaystyle=\sigma(W_{o}\left[\mathbf{h_{t-1}}\
    \mathbf{x_{t}}\right]+b_{o})$ |  |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\mathbf{\tilde{c_{t}}}$ | $\displaystyle=\tanh(W_{c}\left[\mathbf{h_{t-1}}\
    \mathbf{x_{t}}\right]+b_{c})$ |  |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\mathbf{c_{t}}$ | $\displaystyle=f_{t}\odot\mathbf{c_{t-i}}+i_{t}\odot\mathbf{\tilde{c_{t}}}$
    |  |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle h_{t}$ | $\displaystyle=o_{t}\odot\tanh(\mathbf{c_{t}})$
    |  |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
- en: where $\odot$ stands for element-wise multiplication, and the parameters of
    the model are the matrices $W_{f},W_{i},W_{o},W_{c}$ and the bias vectors $b_{f},b_{i},b_{o},b_{c}$.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, the interpretation offered for recursive neural networks is *functional*
    or *“psychological”* and not on the content of intermediate vectors. For example,
    an interpretation of the parameters of LSTM is the following:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: •
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '$f_{t}$ is the *forget gate*: at each step takes in consideration the new input
    and output computed so far to decide which information in the internal state must
    be *forgotten* (that is, set to $0$);'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '$i_{t}$ is the *input gate*: it decides which position in the internal state
    will be updated, and by how much;'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: $\tilde{c_{t}}$ is the proposed new internal state, which will then be updated
    effectively combining the previous gate;
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '$o_{t}$ is the *output gate*: it decides how to modulate the internal state
    to produce the output'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: These *models-that-compose* have high performance on final tasks but are definitely
    not interpretable.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.2 Recursive Neural Network
  id: totrans-347
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: \Tree
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '[.S [.cows ] [.VP [.eat ] [.NP [.animal ] [.extracts ] ] ] ]'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3: A simple binary tree'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/59cbb7affc4acb0b6326db80824d1c4a.png)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Recursive Neural Networks'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: The last class of *models-that-compose* that we present is the class of *recursive
    neural networks* (Socher et al., [2012](#bib.bib65)). These networks are applied
    to data structures as trees and are in fact applied recursively on the structure.
    Generally, the aim of the network is a final task as *sentiment analysis* or *paraphrase
    detection*.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: 'Recursive neural networks is then a basic block (see Fig. [4](#S7.F4 "Figure
    4 ‣ 7.3.2 Recursive Neural Network ‣ 7.3 Compositional Models in Neural Networks
    ‣ 7 Composing distributed representations ‣ Symbolic, Distributed and Distributional
    Representations for Natural Language Processing in the Era of Deep Learning: a
    Survey")) which is recursively applied on trees like the one in Fig. [3](#S7.F3
    "Figure 3 ‣ 7.3.2 Recursive Neural Network ‣ 7.3 Compositional Models in Neural
    Networks ‣ 7 Composing distributed representations ‣ Symbolic, Distributed and
    Distributional Representations for Natural Language Processing in the Era of Deep
    Learning: a Survey"). The formal definition is the following:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{p}=f_{U,V}(\mathbf{u},\mathbf{v})=f(V\mathbf{u},U\mathbf{v})=g(W\begin{pmatrix}V\mathbf{u}\\
    U\mathbf{v}\end{pmatrix})$ |  |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
- en: where $g$ is a component-wise sigmoid function or $\mathrm{tanh}$, and $W$ is
    a matrix that maps the concatenation vector<math id="S7.SS3.SSS2.p2.4.m4.1" class="ltx_Math"
    alttext="\begin{pmatrix}V\mathbf{u}\\
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: U\mathbf{v}\end{pmatrix}" display="inline"><semantics id="S7.SS3.SSS2.p2.4.m4.1a"><mrow
    id="S7.SS3.SSS2.p2.4.m4.1.1.3" xref="S7.SS3.SSS2.p2.4.m4.1.1.2.cmml"><mo id="S7.SS3.SSS2.p2.4.m4.1.1.3.1"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.2.1.cmml">(</mo><mtable rowspacing="0pt" id="S7.SS3.SSS2.p2.4.m4.1.1.1.1"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.cmml"><mtr id="S7.SS3.SSS2.p2.4.m4.1.1.1.1a"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.cmml"><mtd id="S7.SS3.SSS2.p2.4.m4.1.1.1.1b"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.cmml"><mrow id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1.cmml"><mi id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1.2"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1.2.cmml">V</mi><mo lspace="0em" rspace="0em"
    id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1.1" xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1.1.cmml">​</mo><mi
    id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1.3" xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1.3.cmml">𝐮</mi></mrow></mtd></mtr><mtr
    id="S7.SS3.SSS2.p2.4.m4.1.1.1.1c" xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.cmml"><mtd
    id="S7.SS3.SSS2.p2.4.m4.1.1.1.1d" xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.cmml"><mrow
    id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1" xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1.cmml"><mi
    id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1.2" xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1.2.cmml">U</mi><mo
    lspace="0em" rspace="0em" id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1.1" xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1.1.cmml">​</mo><mi
    id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1.3" xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1.3.cmml">𝐯</mi></mrow></mtd></mtr></mtable><mo
    id="S7.SS3.SSS2.p2.4.m4.1.1.3.2" xref="S7.SS3.SSS2.p2.4.m4.1.1.2.1.cmml">)</mo></mrow><annotation-xml
    encoding="MathML-Content" id="S7.SS3.SSS2.p2.4.m4.1b"><apply id="S7.SS3.SSS2.p2.4.m4.1.1.2.cmml"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.3"><csymbol cd="latexml" id="S7.SS3.SSS2.p2.4.m4.1.1.2.1.cmml"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.3.1">matrix</csymbol><matrix id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.cmml"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1"><matrixrow id="S7.SS3.SSS2.p2.4.m4.1.1.1.1a.cmml"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1"><apply id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1.cmml"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1"><ci id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1.2.cmml"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1.2">𝑉</ci><ci id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1.3.cmml"
    xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.1.1.1.3">𝐮</ci></apply></matrixrow><matrixrow
    id="S7.SS3.SSS2.p2.4.m4.1.1.1.1b.cmml" xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1"><apply
    id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1.cmml" xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1"><ci
    id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1.2.cmml" xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1.2">𝑈</ci><ci
    id="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1.3.cmml" xref="S7.SS3.SSS2.p2.4.m4.1.1.1.1.2.1.1.3">𝐯</ci></apply></matrixrow></matrix></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S7.SS3.SSS2.p2.4.m4.1c">\begin{pmatrix}V\mathbf{u}\\
    U\mathbf{v}\end{pmatrix}</annotation></semantics></math> to have the same dimension.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: 'This method deals naturally with recursion: given a binary parse tree of a
    sentence $s$, the algorithm creates vectors and matrices representation for each
    node, starting from the terminal nodes. Words are represented by distributed representations
    or local representations. For example, the tree in Fig. [3](#S7.F3 "Figure 3 ‣
    7.3.2 Recursive Neural Network ‣ 7.3 Compositional Models in Neural Networks ‣
    7 Composing distributed representations ‣ Symbolic, Distributed and Distributional
    Representations for Natural Language Processing in the Era of Deep Learning: a
    Survey") is processed by the recursive network in the following way. First, the
    network in Fig. [4](#S7.F4 "Figure 4 ‣ 7.3.2 Recursive Neural Network ‣ 7.3 Compositional
    Models in Neural Networks ‣ 7 Composing distributed representations ‣ Symbolic,
    Distributed and Distributional Representations for Natural Language Processing
    in the Era of Deep Learning: a Survey") is applied to the pair *(animal,extracts)*
    and $f_{UV}(\mathbf{animal},\mathbf{extract})$ is obtained. Then, the network
    is applied to the result and *eat* and $f_{UV}(\mathbf{eat},f_{UV}(\mathbf{animal},\mathbf{extract}))$
    is obtained and so on.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: 'Recursive neural networks are not easily interpretable even if quite similar
    to the additive *compositional distributional semantic models* as those presented
    in Sec. [7.1.1](#S7.SS1.SSS1 "7.1.1 Additive Models ‣ 7.1 Compositional Distributional
    Semantics ‣ 7 Composing distributed representations ‣ Symbolic, Distributed and
    Distributional Representations for Natural Language Processing in the Era of Deep
    Learning: a Survey"). In fact, the non-linear function $g$ is the one that makes
    final vectors less interpretable.'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: 8 Conclusions
  id: totrans-360
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Natural language is symbolic representation. Thinking to natural language understanding
    systems which are not based on symbols seems to be extremely odd. However, recent
    advances in machine learning (ML) and in natural language processing (NLP) seem
    to contradict the above intuition: symbols are fading away, erased by vectors
    or tensors called *distributed* and *distributional representations*.'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: We made this survey to show the not-surprising link between symbolic representations
    and distributed/distributional representations. This is the right time to revitalize
    the area of interpreting how symbols are represented inside neural networks. In
    our opinion, this survey will help to devise new deep neural networks that can
    exploit existing and novel symbolic models of classical natural language processing
    tasks. We believe that a clearer understanding of the strict link between distributed/distributional
    representations and symbols may lead to radically new deep learning networks.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-363
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Achlioptas (2003) Achlioptas, D. (2003). Database-friendly random projections:
    Johnson-lindenstrauss with binary coins. *Journal of computer and System Sciences*
    66, 671–687'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Agirre et al. (2013) Agirre, E., Cer, D., Diab, M., Gonzalez-Agirre, A., and
    Guo, W. (2013). *sem 2013 shared task: Semantic textual similarity. In *Second
    Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings
    of the Main Conference and the Shared Task: Semantic Textual Similarity* (Atlanta,
    Georgia, USA: Association for Computational Linguistics), 32–43'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bahdanau et al. (2014) Bahdanau, D., Cho, K., and Bengio, Y. (2014). Neural
    machine translation by jointly learning to align and translate. *arXiv preprint
    arXiv:1409.0473*
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Baroni et al. (2014) Baroni, M., Bernardi, R., and Zamparelli, R. (2014). Frege
    in space: A program of compositional distributional semantics. *LiLT (Linguistic
    Issues in Language Technology)* 9'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Baroni and Lenci (2010) Baroni, M. and Lenci, A. (2010). Distributional memory:
    A general framework for corpus-based semantics. *Comput. Linguist.* 36, 673–721.
    [10.1162/coli_a_00016](https:/doi.org/10.1162/coli_a_00016)'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Baroni and Zamparelli (2010) Baroni, M. and Zamparelli, R. (2010). Nouns are
    vectors, adjectives are matrices: Representing adjective-noun constructions in
    semantic space. In *Proceedings of the 2010 Conference on Empirical Methods in
    Natural Language Processing* (Cambridge, MA: Association for Computational Linguistics),
    1183–1193'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Belkin and Niyogi (2001) Belkin, M. and Niyogi, P. (2001). Laplacian eigenmaps
    and spectral techniques for embedding and clustering. In *NIPS*. vol. 14, 585–591
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bellman and Corporation (1957) Bellman, R. and Corporation, R. (1957). *Dynamic
    Programming*. Rand Corporation research study (Princeton University Press)
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bingham and Mannila (2001) Bingham, E. and Mannila, H. (2001). Random projection
    in dimensionality reduction: applications to image and text data. In *Proceedings
    of the seventh ACM SIGKDD international conference on Knowledge discovery and
    data mining* (ACM), 245–250'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blutner et al. (2003) Blutner, R., Hendriks, P., and de Hoop, H. (2003). A new
    hypothesis on compositionality. In *Proceedings of the joint international conference
    on cognitive science*
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chalmers (1992) Chalmers, D. J. (1992). *Syntactic Transformations on Distributed
    Representations* (Dordrecht: Springer Netherlands). 46–55. [10.1007/978-94-011-2624-3_3](https:/doi.org/10.1007/978-94-011-2624-3_3)'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chetlur et al. (2014) Chetlur, S., Woolley, C., Vandermersch, P., Cohen, J.,
    Tran, J., Catanzaro, B., et al. (2014). cudnn: Efficient primitives for deep learning.
    *arXiv preprint arXiv:1410.0759*'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chomsky (1957) Chomsky, N. (1957). *Aspect of Syntax Theory* (Cambridge, Massachussetts:
    MIT Press)'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clark et al. (2008) Clark, S., Coecke, B., and Sadrzadeh, M. (2008). A compositional
    distributional model of meaning. *Proceedings of the Second Symposium on Quantum
    Interaction (QI-2008)* , 133–140
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coecke et al. (2010) Coecke, B., Sadrzadeh, M., and Clark, S. (2010). Mathematical
    foundations for a compositional distributional model of meaning. *CoRR* abs/1003.4394
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cui et al. (2015) Cui, H., Ganger, G. R., and Gibbons, P. B. (2015). *Scalable
    deep learning on distributed GPUs with a GPU-specialized parameter server*. Tech.
    rep., CMU PDL Technical Report (CMU-PDL-15-107)
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dagan et al. (2013) Dagan, I., Roth, D., Sammons, M., and Zanzotto, F. M. (2013).
    *Recognizing Textual Entailment: Models and Applications*. Synthesis Lectures
    on Human Language Technologies (Morgan & Claypool Publishers)'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Daum and Huang (2003) Daum, F. and Huang, J. (2003). Curse of dimensionality
    and particle filters. In *Aerospace Conference, 2003\. Proceedings. 2003 IEEE*
    (IEEE), vol. 4, 4_1979–4_1993
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. (2018) Devlin, J., Chang, M., Lee, K., and Toutanova, K. (2018).
    BERT: pre-training of deep bidirectional transformers for language understanding.
    *CoRR* abs/1810.04805'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ferrone and Zanzotto (2014) Ferrone, L. and Zanzotto, F. M. (2014). Towards
    syntax-aware compositional distributional semantic models. In *Proceedings of
    COLING 2014, the 25th International Conference on Computational Linguistics: Technical
    Papers* (Dublin, Ireland: Dublin City University and Association for Computational
    Linguistics), 721–730'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ferrone et al. (2015) Ferrone, L., Zanzotto, F. M., and Carreras, X. (2015).
    Decoding distributed tree structures. In *Statistical Language and Speech Processing
    - Third International Conference, SLSP 2015, Budapest, Hungary, November 24-26,
    2015, Proceedings*. 73–83. [10.1007/978-3-319-25789-1_8](https:/doi.org/10.1007/978-3-319-25789-1_8)
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Firth (1957) Firth, J. R. (1957). *Papers in Linguistics.* (London: Oxford
    University Press.)'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fodor (2002) Fodor, I. (2002). *A Survey of Dimension Reduction Techniques*.
    Tech. rep.
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fodor and Pylyshyn (1988) Fodor, J. A. and Pylyshyn, Z. W. (1988). Connectionism
    and cognitive architecture: A critical analysis. *Cognition* 28, 3 – 71. [https://doi.org/10.1016/0010-0277(88)90031-5](https:/doi.org/https://doi.org/10.1016/0010-0277(88)90031-5)'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Frege (1884) Frege, G. (1884). *Die Grundlagen der Arithmetik (The Foundations
    of Arithmetic): eine logisch-mathematische Untersuchung über den Begriff der Zahl*
    (Breslau)'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Friedman (1997) Friedman, J. H. (1997). On bias, variance, 0/1—loss, and the
    curse-of-dimensionality. *Data mining and knowledge discovery* 1, 55–77
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gelder (1990) Gelder, T. V. (1990). Compositionality: A connectionist variation
    on a classical theme. *Cognitive Science* 384, 355–384. [10.1207/s15516709cog1403_2](https:/doi.org/10.1207/s15516709cog1403_2)'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Goldberg and Levy (2014) Goldberg, Y. and Levy, O. (2014). word2vec explained:
    deriving mikolov et al.’s negative-sampling word-embedding method. *arXiv preprint
    arXiv:1402.3722*'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2014) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,
    Warde-Farley, D., Ozair, S., et al. (2014). Generative adversarial nets. In *Advances
    in Neural Information Processing Systems*. 2672–2680
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graves (2013) Graves, A. (2013). Generating sequences with recurrent neural
    networks. *CoRR* abs/1308.0850
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Grefenstette and Sadrzadeh (2011) Grefenstette, E. and Sadrzadeh, M. (2011).
    Experimental support for a categorical compositional distributional model of meaning.
    In *Proceedings of the Conference on Empirical Methods in Natural Language Processing*
    (Stroudsburg, PA, USA: Association for Computational Linguistics), EMNLP ’11,
    1394–1404'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guevara (2010) Guevara, E. (2010). A regression model of adjective-noun compositionality
    in distributional semantics. In *Proceedings of the 2010 Workshop on GEometrical
    Models of Natural Language Semantics* (Uppsala, Sweden: Association for Computational
    Linguistics), 33–37'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Harris (1964) Harris, Z. (1964). Distributional structure. In *The Philosophy
    of Linguistics*, eds. J. J. Katz and J. A. Fodor (New York: Oxford University
    Press)'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2016) He, K., Zhang, X., Ren, S., and Sun, J. (2016). Identity mappings
    in deep residual networks. *arXiv preprint arXiv:1603.05027*
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hinton et al. (1986) Hinton, G. E., McClelland, J. L., and Rumelhart, D. E.
    (1986). Distributed representations. In *Parallel Distributed Processing: Explorations
    in the Microstructure of Cognition. Volume 1: Foundations*, eds. D. E. Rumelhart
    and J. L. McClelland (MIT Press, Cambridge, MA.)'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hochreiter and Schmidhuber (1997) Hochreiter, S. and Schmidhuber, J. (1997).
    Long short-term memory. *Neural computation* 9, 1735–1780
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jacovi et al. (2018) Jacovi, A., Shalom, O. S., and Goldberg, Y. (2018). Understanding
    Convolutional Neural Networks for Text Classification , 56–65[doi:10.1046/j.1365-3040.2003.01027.x](https:/doi.org/doi:10.1046/j.1365-3040.2003.01027.x)
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jang et al. (2018) Jang, K.-r., Kim, S.-b., and Corp, N. (2018). Interpretable
    Word Embedding Contextualization , 341–343
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Johnson and Lindenstrauss (1984) Johnson, W. and Lindenstrauss, J. (1984). Extensions
    of lipschitz mappings into a hilbert space. *Contemp. Math.* 26, 189–206
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kalchbrenner and Blunsom (2013) Kalchbrenner, N. and Blunsom, P. (2013). Recurrent
    convolutional neural networks for discourse compositionality. *Proceedings of
    the 2013 Workshop on Continuous Vector Space Models and their Compositionality*
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keogh and Mueen (2011) Keogh, E. and Mueen, A. (2011). Curse of dimensionality.
    In *Encyclopedia of Machine Learning* (Springer). 257–258
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky et al. (2012) Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012).
    Imagenet classification with deep convolutional neural networks. In *Advances
    in neural information processing systems*. 1097–1105
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Landauer and Dumais (1997) Landauer, T. K. and Dumais, S. T. (1997). A solution
    to plato’s problem: The latent semantic analysis theory of acquisition, induction,
    and representation of knowledge. *Psychological Review* 104, 211–240'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. (2015) LeCun, Y., Bengio, Y., and Hinton, G. (2015). Deep learning.
    *Nature* 521, 436–444
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liou et al. (2014) Liou, C.-Y., Cheng, W.-C., Liou, J.-W., and Liou, D.-R. (2014).
    Autoencoder for words. *Neurocomputing* 139, 84 – 96. [http://dx.doi.org/10.1016/j.neucom.2013.09.055](https:/doi.org/http://dx.doi.org/10.1016/j.neucom.2013.09.055)
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lipton (2016) Lipton, Z. C. (2016). The Mythos of Model Interpretability [10.1145/3233231](https:/doi.org/10.1145/3233231)
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Markovsky (2012) Markovsky, I. (2012). Low rank approximation: Algorithms,
    implementation, applications'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Masci et al. (2011) Masci, J., Meier, U., Cireşan, D., and Schmidhuber, J. (2011).
    Stacked convolutional auto-encoders for hierarchical feature extraction. In *International
    Conference on Artificial Neural Networks* (Springer), 52–59
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mikolov et al. (2013) Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013).
    Efficient estimation of word representations in vector space. *CoRR* abs/1301.3781
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mitchell and Lapata (2008) Mitchell, J. and Lapata, M. (2008). Vector-based
    models of semantic composition. In *Proceedings of ACL-08: HLT* (Columbus, Ohio:
    Association for Computational Linguistics), 236–244'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mitchell and Lapata (2010) Mitchell, J. and Lapata, M. (2010). Composition in
    distributional models of semantics. *Cognitive Science* [10.1111/j.1551-6709.2010.01106.x](https:/doi.org/10.1111/j.1551-6709.2010.01106.x)
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Montague (1974) Montague, R. (1974). English as a formal language. In *Formal
    Philosophy: Selected Papers of Richard Montague*, ed. R. Thomason (New Haven:
    Yale University Press). 188–221'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neumann (2001) Neumann, J. (2001). *Holistic processing of hierarchical structures
    in connectionist networks*. Ph.D. thesis, University of Edinburgh
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pado and Lapata (2007) Pado, S. and Lapata, M. (2007). Dependency-based construction
    of semantic space models. *Computational Linguistics* 33, 161–199
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pearson (1901) Pearson, K. (1901). Principal components analysis. *The London,
    Edinburgh and Dublin Philosophical Magazine and Journal* 6, 566
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plate (1994) Plate, T. A. (1994). *Distributed Representations and Nested Compositional
    Structure*. Ph.D. thesis
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plate (1995) Plate, T. A. (1995). Holographic reduced representations. *IEEE
    Transactions on Neural Networks* 6, 623–641. [10.1109/72.377968](https:/doi.org/10.1109/72.377968)
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rosenblatt (1958) Rosenblatt, F. (1958). The perceptron: a probabilistic model
    for information storage and organization in the brain. *Psychological Reviews*
    65, 386–408'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rothenhäusler and Schütze (2009) Rothenhäusler, K. and Schütze, H. (2009).
    Unsupervised classification with dependency based word spaces. In *Proceedings
    of the Workshop on Geometrical Models of Natural Language Semantics* (Stroudsburg,
    PA, USA: Association for Computational Linguistics), GEMS ’09, 17–24'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sahlgren (2005) Sahlgren, M. (2005). An introduction to random indexing. In
    *Proceedings of the Methods and Applications of Semantic Indexing Workshop at
    the 7th International Conference on Terminology and Knowledge Engineering TKE*
    (Copenhagen, Denmark)
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Salton (1989) Salton, G. (1989). *Automatic text processing: the transformation,
    analysis and retrieval of information by computer* (Addison-Wesley)'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schmidhuber (2015) Schmidhuber, J. (2015). Deep learning in neural networks:
    An overview. *Neural Networks* 61, 85–117'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schuster and Paliwal (1997) Schuster, M. and Paliwal, K. (1997). Bidirectional
    recurrent neural networks. *Trans. Sig. Proc.* 45, 2673–2681. [10.1109/78.650093](https:/doi.org/10.1109/78.650093)
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Socher et al. (2011) Socher, R., Huang, E. H., Pennington, J., Ng, A. Y., and
    Manning, C. D. (2011). Dynamic pooling and unfolding recursive autoencoders for
    paraphrase detection. In *Advances in Neural Information Processing Systems 24*
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Socher et al. (2012) Socher, R., Huval, B., Manning, C. D., and Ng, A. Y. (2012).
    Semantic Compositionality Through Recursive Matrix-Vector Spaces. In *Proceedings
    of the 2012 Conference on Empirical Methods in Natural Language Processing (EMNLP)*
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sorzano et al. (2014) Sorzano, C. O. S., Vargas, J., and Montano, A. P. (2014).
    A survey of dimensionality reduction techniques. *arXiv preprint arXiv:1403.2877*
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Turney (2006) Turney, P. D. (2006). Similarity of semantic relations. *Comput.
    Linguist.* 32, 379–416. [http://dx.doi.org/10.1162/coli.2006.32.3.379](https:/doi.org/http://dx.doi.org/10.1162/coli.2006.32.3.379)
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Turney and Pantel (2010) Turney, P. D. and Pantel, P. (2010). From frequency
    to meaning: Vector space models of semantics. *J. Artif. Intell. Res. (JAIR)*
    37, 141–188'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vaswani et al. (2017) Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,
    L., Gomez, A. N., et al. (2017). Attention is all you need. In *Advances in Neural
    Information Processing Systems 30*, eds. I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
    R. Fergus, S. Vishwanathan, and R. Garnett (Curran Associates, Inc.). 5998–6008
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vincent et al. (2008) Vincent, P., Larochelle, H., Bengio, Y., and Manzagol,
    P.-A. (2008). Extracting and composing robust features with denoising autoencoders.
    In *Proceedings of the 25th international conference on Machine learning* (ACM),
    1096–1103
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vincent et al. (2010) Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y.,
    and Manzagol, P.-A. (2010). Stacked denoising autoencoders: Learning useful representations
    in a deep network with a local denoising criterion. *J. Mach. Learn. Res.* 11,
    3371–3408'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vinyals et al. (2015a) Vinyals, O., Kaiser, L. u., Koo, T., Petrov, S., Sutskever,
    I., and Hinton, G. (2015a). Grammar as a foreign language. In *Advances in Neural
    Information Processing Systems 28*, eds. C. Cortes, N. D. Lawrence, D. D. Lee,
    M. Sugiyama, and R. Garnett (Curran Associates, Inc.). 2755–2763
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vinyals et al. (2015b) Vinyals, O., Toshev, A., Bengio, S., and Erhan, D. (2015b).
    Show and tell: A neural image caption generator. In *Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition*. 3156–3164'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weiss et al. (2015) Weiss, D., Alberti, C., Collins, M., and Petrov, S. (2015).
    Structured training for neural network transition-based parsing. *arXiv preprint
    arXiv:1506.06158*
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Werbos (1974) Werbos, P. (1974). Beyond regression: New tools for prediction
    and analysis in the behavioral sciences'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2015) Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhutdinov,
    R., et al. (2015). Show, attend and tell: Neural image caption generation with
    visual attention. *arXiv preprint arXiv:1502.03044* 2, 5'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zanzotto and Dell’Arciprete (2012) Zanzotto, F. M. and Dell’Arciprete, L. (2012).
    Distributed tree kernels. In *Proceedings of International Conference on Machine
    Learning*. –
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zanzotto et al. (2015) Zanzotto, F. M., Ferrone, L., and Baroni, M. (2015).
    When the whole is not greater than the combination of its parts: A ”decompositional”
    look at compositional distributional semantics. *Comput. Linguist.* 41, 165–173.
    [10.1162/COLI_a_00215](https:/doi.org/10.1162/COLI_a_00215)'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zanzotto et al. (2010) Zanzotto, F. M., Korkontzelos, I., Fallucchi, F., and
    Manandhar, S. (2010). Estimating linear models for compositional distributional
    semantics. In *Proceedings of the 23rd International Conference on Computational
    Linguistics (COLING)*
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zeiler and Fergus (2014a) Zeiler, M. D. and Fergus, R. (2014a). Visualizing
    and understanding convolutional networks. In *Computer Vision – ECCV 2014*, eds.
    D. Fleet, T. Pajdla, B. Schiele, and T. Tuytelaars (Cham: Springer International
    Publishing), 818–833'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zeiler and Fergus (2014b) Zeiler, M. D. and Fergus, R. (2014b). Visualizing
    and understanding convolutional networks. In *European Conference on Computer
    Vision* (Springer), 818–833
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zou et al. (2013) Zou, W. Y., Socher, R., Cer, D. M., and Manning, C. D. (2013).
    Bilingual word embeddings for phrase-based machine translation. In *EMNLP*. 1393–1398
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
